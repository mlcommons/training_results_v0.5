Beginning trial 1 of 1
Clearing caches
:::MLPv0.5.0 gnmt 1541784028.263795137 (<string>:1) run_clear_caches
Launching on node xpl-dvt-70
+ pids+=($!)
+ set +x
++ eval echo
+++ echo
+ docker exec -e DGXSYSTEM=DGX2_alt -e MULTI_NODE= -e SLURM_JOB_ID=1541784001 -e SLURM_NTASKS_PER_NODE= cont_1541784001 ./run_and_time.sh
Run vars: id 1541784001 gpus 16 mparams 
STARTING TIMING RUN AT 2018-11-09 05:20:28 PM
running benchmark
+ DATASET_DIR=/data
+ RESULTS_DIR=gnmt_wmt16
+ BATCH=64
+ TEST_BATCH_SIZE=128
+ LR=1.25e-3
+ TARGET=21.80
+ WARMUP_ITERS=200
+ REMAIN_STEPS=6000
+ DECAY_STEPS=500
+ echo 'running benchmark'
+ python -m torch.distributed.launch --nproc_per_node 16 train.py --save gnmt_wmt16 --dataset-dir /data --target-bleu 21.80 --epochs 20 --math fp16 --print-freq 10 --batch-size 64 --test-batch-size 128 --model-config '{'\''num_layers'\'': 4, '\''hidden_size'\'': 1024, '\''dropout'\'':0.2, '\''share_embedding'\'': True}' --optimization-config '{'\''optimizer'\'': '\''FusedAdam'\'', '\''lr'\'': 1.25e-3}' --scheduler-config '{'\''lr_method'\'':'\''mlperf'\'', '\''warmup_iters'\'':200, '\''remain_steps'\'':6000, '\''decay_steps'\'':500}'
2: Saving results to: results/gnmt_wmt16
4: Saving results to: results/gnmt_wmt16
3: Saving results to: results/gnmt_wmt16
5: Saving results to: results/gnmt_wmt16
2: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=2, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=2, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
4: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=4, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=4, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
6: Saving results to: results/gnmt_wmt16
3: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=3, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=3, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
5: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=5, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=5, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
8: Saving results to: results/gnmt_wmt16
1: Saving results to: results/gnmt_wmt16
6: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=6, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=6, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
13: Saving results to: results/gnmt_wmt16
11: Saving results to: results/gnmt_wmt16
8: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=8, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=8, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
1: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=1, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=1, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
15: Saving results to: results/gnmt_wmt16
10: Saving results to: results/gnmt_wmt16
13: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=13, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=13, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
11: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=11, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=11, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
9: Saving results to: results/gnmt_wmt16
15: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=15, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=15, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
10: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=10, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=10, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
9: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=9, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=9, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
12: Saving results to: results/gnmt_wmt16
2: L2 promotion: 128B
7: Saving results to: results/gnmt_wmt16
12: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=12, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=12, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
4: L2 promotion: 128B
7: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=7, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=7, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
3: L2 promotion: 128B
14: Saving results to: results/gnmt_wmt16
5: L2 promotion: 128B
14: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=14, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=14, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
6: L2 promotion: 128B
1: L2 promotion: 128B
8: L2 promotion: 128B
13: L2 promotion: 128B
11: L2 promotion: 128B
15: L2 promotion: 128B
10: L2 promotion: 128B
9: L2 promotion: 128B
12: L2 promotion: 128B
7: L2 promotion: 128B
14: L2 promotion: 128B
:::MLPv0.5.0 gnmt 1541784065.167080641 (train.py:242) run_start
0: Saving results to: results/gnmt_wmt16
0: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=0, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=0, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
0: L2 promotion: 128B
:::MLPv0.5.0 gnmt 1541784065.168944836 (train.py:265) run_set_random_seed
0: Using random master seed: 10008104
0: Worker 0 is using worker seed: 3674797495
5: Worker 5 is using worker seed: 2867549968
7: Worker 7 is using worker seed: 1755750076
6: Worker 6 is using worker seed: 2281773403
3: Worker 3 is using worker seed: 752562344
2: Worker 2 is using worker seed: 3037572984
4: Worker 4 is using worker seed: 1689545416
1: Worker 1 is using worker seed: 731352050
9: Worker 9 is using worker seed: 81172761
8: Worker 8 is using worker seed: 669268933
13: Worker 13 is using worker seed: 4198473791
10: Worker 10 is using worker seed: 183505843
12: Worker 12 is using worker seed: 1809164645
0: Building vocabulary from /data/vocab.bpe.32000
5: Building vocabulary from /data/vocab.bpe.32000
2: Building vocabulary from /data/vocab.bpe.32000
15: Worker 15 is using worker seed: 4157518155
3: Building vocabulary from /data/vocab.bpe.32000
1: Building vocabulary from /data/vocab.bpe.32000
11: Worker 11 is using worker seed: 2484331728
14: Worker 14 is using worker seed: 3274667686
9: Building vocabulary from /data/vocab.bpe.32000
12: Building vocabulary from /data/vocab.bpe.32000
7: Building vocabulary from /data/vocab.bpe.32000
15: Building vocabulary from /data/vocab.bpe.32000
10: Building vocabulary from /data/vocab.bpe.32000
4: Building vocabulary from /data/vocab.bpe.32000
6: Building vocabulary from /data/vocab.bpe.32000
13: Building vocabulary from /data/vocab.bpe.32000
8: Building vocabulary from /data/vocab.bpe.32000
11: Building vocabulary from /data/vocab.bpe.32000
14: Building vocabulary from /data/vocab.bpe.32000
0: Size of vocabulary: 32320
2: Size of vocabulary: 32320
13: Size of vocabulary: 32320
8: Size of vocabulary: 32320
4: Size of vocabulary: 32320
1: Size of vocabulary: 32320
15: Size of vocabulary: 32320
6: Size of vocabulary: 32320
3: Size of vocabulary: 32320
5: Size of vocabulary: 32320
14: Size of vocabulary: 32320
12: Size of vocabulary: 32320
9: Size of vocabulary: 32320
7: Size of vocabulary: 32320
11: Size of vocabulary: 32320
10: Size of vocabulary: 32320
:::MLPv0.5.0 gnmt 1541784065.194397926 (train.py:302) preproc_tokenize_training
5: Processing data from /data/train.tok.clean.bpe.32000.en
3: Processing data from /data/train.tok.clean.bpe.32000.en
2: Processing data from /data/train.tok.clean.bpe.32000.en
4: Processing data from /data/train.tok.clean.bpe.32000.en
9: Processing data from /data/train.tok.clean.bpe.32000.en
6: Processing data from /data/train.tok.clean.bpe.32000.en
10: Processing data from /data/train.tok.clean.bpe.32000.en
8: Processing data from /data/train.tok.clean.bpe.32000.en
12: Processing data from /data/train.tok.clean.bpe.32000.en
11: Processing data from /data/train.tok.clean.bpe.32000.en
7: Processing data from /data/train.tok.clean.bpe.32000.en
1: Processing data from /data/train.tok.clean.bpe.32000.en
15: Processing data from /data/train.tok.clean.bpe.32000.en
13: Processing data from /data/train.tok.clean.bpe.32000.en
14: Processing data from /data/train.tok.clean.bpe.32000.en
:::MLPv0.5.0 gnmt 1541784065.194929123 (train.py:304) train_hp_max_sequence_length: 50
0: Processing data from /data/train.tok.clean.bpe.32000.en
1: Processing data from /data/train.tok.clean.bpe.32000.de
9: Processing data from /data/train.tok.clean.bpe.32000.de
6: Processing data from /data/train.tok.clean.bpe.32000.de
10: Processing data from /data/train.tok.clean.bpe.32000.de
7: Processing data from /data/train.tok.clean.bpe.32000.de
3: Processing data from /data/train.tok.clean.bpe.32000.de
4: Processing data from /data/train.tok.clean.bpe.32000.de
2: Processing data from /data/train.tok.clean.bpe.32000.de
0: Processing data from /data/train.tok.clean.bpe.32000.de
11: Processing data from /data/train.tok.clean.bpe.32000.de
13: Processing data from /data/train.tok.clean.bpe.32000.de
8: Processing data from /data/train.tok.clean.bpe.32000.de
14: Processing data from /data/train.tok.clean.bpe.32000.de
5: Processing data from /data/train.tok.clean.bpe.32000.de
15: Processing data from /data/train.tok.clean.bpe.32000.de
12: Processing data from /data/train.tok.clean.bpe.32000.de
7: Filtering data, min len: 0, max len: 50
8: Filtering data, min len: 0, max len: 50
0: Filtering data, min len: 0, max len: 50
10: Filtering data, min len: 0, max len: 50
13: Filtering data, min len: 0, max len: 50
4: Filtering data, min len: 0, max len: 50
1: Filtering data, min len: 0, max len: 50
2: Filtering data, min len: 0, max len: 50
6: Filtering data, min len: 0, max len: 50
5: Filtering data, min len: 0, max len: 50
3: Filtering data, min len: 0, max len: 50
9: Filtering data, min len: 0, max len: 50
14: Filtering data, min len: 0, max len: 50
15: Filtering data, min len: 0, max len: 50
12: Filtering data, min len: 0, max len: 50
11: Filtering data, min len: 0, max len: 50
5: Pairs before: 4068191, after: 3498161
2: Pairs before: 4068191, after: 3498161
7: Pairs before: 4068191, after: 3498161
3: Pairs before: 4068191, after: 3498161
0: Pairs before: 4068191, after: 3498161
4: Pairs before: 4068191, after: 3498161
12: Pairs before: 4068191, after: 3498161
14: Pairs before: 4068191, after: 3498161
13: Pairs before: 4068191, after: 3498161
8: Pairs before: 4068191, after: 3498161
1: Pairs before: 4068191, after: 3498161
9: Pairs before: 4068191, after: 3498161
10: Pairs before: 4068191, after: 3498161
15: Pairs before: 4068191, after: 3498161
6: Pairs before: 4068191, after: 3498161
11: Pairs before: 4068191, after: 3498161
8: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
7: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
9: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
5: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
4: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
3: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
14: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
2: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
1: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
11: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
12: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
15: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
6: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
:::MLPv0.5.0 gnmt 1541784075.008358002 (train.py:316) preproc_num_train_examples: 3498161
10: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
0: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
13: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
5: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
3: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
4: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
2: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
0: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
1: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
12: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
13: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
15: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
10: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
7: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
6: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
14: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
8: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
11: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
9: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
5: Filtering data, min len: 0, max len: 150
5: Pairs before: 5100, after: 5100
3: Filtering data, min len: 0, max len: 150
3: Pairs before: 5100, after: 5100
2: Filtering data, min len: 0, max len: 150
4: Filtering data, min len: 0, max len: 150
2: Pairs before: 5100, after: 5100
15: Filtering data, min len: 0, max len: 150
4: Pairs before: 5100, after: 5100
13: Filtering data, min len: 0, max len: 150
12: Filtering data, min len: 0, max len: 150
7: Filtering data, min len: 0, max len: 150
15: Pairs before: 5100, after: 5100
10: Filtering data, min len: 0, max len: 150
13: Pairs before: 5100, after: 5100
12: Pairs before: 5100, after: 5100
7: Pairs before: 5100, after: 5100
10: Pairs before: 5100, after: 5100
14: Filtering data, min len: 0, max len: 150
0: Filtering data, min len: 0, max len: 150
14: Pairs before: 5100, after: 5100
0: Pairs before: 5100, after: 5100
1: Filtering data, min len: 0, max len: 150
1: Pairs before: 5100, after: 5100
9: Filtering data, min len: 0, max len: 150
9: Pairs before: 5100, after: 5100
6: Filtering data, min len: 0, max len: 150
11: Filtering data, min len: 0, max len: 150
6: Pairs before: 5100, after: 5100
11: Pairs before: 5100, after: 5100
8: Filtering data, min len: 0, max len: 150
8: Pairs before: 5100, after: 5100
8: Processing data from /data/newstest2014.tok.bpe.32000.en
11: Processing data from /data/newstest2014.tok.bpe.32000.en
6: Processing data from /data/newstest2014.tok.bpe.32000.en
9: Processing data from /data/newstest2014.tok.bpe.32000.en
1: Processing data from /data/newstest2014.tok.bpe.32000.en
13: Processing data from /data/newstest2014.tok.bpe.32000.en
2: Processing data from /data/newstest2014.tok.bpe.32000.en
10: Processing data from /data/newstest2014.tok.bpe.32000.en
4: Processing data from /data/newstest2014.tok.bpe.32000.en
7: Processing data from /data/newstest2014.tok.bpe.32000.en
3: Processing data from /data/newstest2014.tok.bpe.32000.en
5: Processing data from /data/newstest2014.tok.bpe.32000.en
15: Processing data from /data/newstest2014.tok.bpe.32000.en
14: Processing data from /data/newstest2014.tok.bpe.32000.en
12: Processing data from /data/newstest2014.tok.bpe.32000.en
:::MLPv0.5.0 gnmt 1541784076.302789688 (train.py:326) preproc_tokenize_eval
0: Processing data from /data/newstest2014.tok.bpe.32000.en
8: Filtering data, min len: 0, max len: 150
9: Filtering data, min len: 0, max len: 150
10: Filtering data, min len: 0, max len: 150
6: Filtering data, min len: 0, max len: 150
0: Filtering data, min len: 0, max len: 150
4: Filtering data, min len: 0, max len: 150
1: Filtering data, min len: 0, max len: 150
8: Pairs before: 3003, after: 3003
9: Pairs before: 3003, after: 3003
5: Filtering data, min len: 0, max len: 150
10: Pairs before: 3003, after: 3003
2: Filtering data, min len: 0, max len: 150
3: Filtering data, min len: 0, max len: 150
6: Pairs before: 3003, after: 3003
15: Filtering data, min len: 0, max len: 150
7: Filtering data, min len: 0, max len: 150
11: Filtering data, min len: 0, max len: 150
0: Pairs before: 3003, after: 3003
14: Filtering data, min len: 0, max len: 150
4: Pairs before: 3003, after: 3003
1: Pairs before: 3003, after: 3003
5: Pairs before: 3003, after: 3003
13: Filtering data, min len: 0, max len: 150
2: Pairs before: 3003, after: 3003
3: Pairs before: 3003, after: 3003
12: Filtering data, min len: 0, max len: 150
7: Pairs before: 3003, after: 3003
11: Pairs before: 3003, after: 3003
15: Pairs before: 3003, after: 3003
14: Pairs before: 3003, after: 3003
13: Pairs before: 3003, after: 3003
12: Pairs before: 3003, after: 3003
:::MLPv0.5.0 gnmt 1541784076.344094753 (train.py:336) preproc_num_eval_examples: 3003
:::MLPv0.5.0 gnmt 1541784076.344483852 (train.py:341) preproc_vocab_size: 32320
:::MLPv0.5.0 gnmt 1541784076.345378160 (seq2seq/models/gnmt.py:37) model_hp_num_layers: 4
:::MLPv0.5.0 gnmt 1541784076.345744848 (seq2seq/models/gnmt.py:39) model_hp_hidden_size: 1024
:::MLPv0.5.0 gnmt 1541784076.346086502 (seq2seq/models/gnmt.py:41) model_hp_dropout: 0.2
8: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
8: Building LabelSmoothingLoss (smoothing: 0.1)
3: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
1: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
3: Building LabelSmoothingLoss (smoothing: 0.1)
1: Building LabelSmoothingLoss (smoothing: 0.1)
11: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
11: Building LabelSmoothingLoss (smoothing: 0.1)
10: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
10: Building LabelSmoothingLoss (smoothing: 0.1)
9: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
9: Building LabelSmoothingLoss (smoothing: 0.1)
13: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
13: Building LabelSmoothingLoss (smoothing: 0.1)
6: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
6: Building LabelSmoothingLoss (smoothing: 0.1)
0: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
0: Building LabelSmoothingLoss (smoothing: 0.1)
15: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
15: Building LabelSmoothingLoss (smoothing: 0.1)
4: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
4: Building LabelSmoothingLoss (smoothing: 0.1)
14: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
14: Building LabelSmoothingLoss (smoothing: 0.1)
5: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
5: Building LabelSmoothingLoss (smoothing: 0.1)
2: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
2: Building LabelSmoothingLoss (smoothing: 0.1)
12: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
12: Building LabelSmoothingLoss (smoothing: 0.1)
7: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
7: Building LabelSmoothingLoss (smoothing: 0.1)
:::MLPv0.5.0 gnmt 1541784077.767832041 (train.py:208) model_hp_loss_fn: "Cross Entropy with label smoothing"
6: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
2: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
4: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
14: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
15: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
5: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
1: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
11: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
8: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
2: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
6: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
4: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
12: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
3: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
14: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
15: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
5: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
9: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
1: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
13: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
11: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
7: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
8: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
12: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
3: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
13: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
9: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
7: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
:::MLPv0.5.0 gnmt 1541784077.768326759 (train.py:210) model_hp_loss_smoothing: 0.1
6: Number of parameters: 160671297
2: Number of parameters: 160671297
15: Number of parameters: 160671297
4: Number of parameters: 160671297
0: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
14: Number of parameters: 160671297
8: Number of parameters: 160671297
1: Number of parameters: 160671297
5: Number of parameters: 160671297
11: Number of parameters: 160671297
12: Number of parameters: 160671297
0: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
9: Number of parameters: 160671297
3: Number of parameters: 160671297
7: Number of parameters: 160671297
13: Number of parameters: 160671297
0: Number of parameters: 160671297
10: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
10: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
10: Number of parameters: 160671297
:::MLPv0.5.0 gnmt 1541784077.770973206 (train.py:370) input_batch_size: 1024
:::MLPv0.5.0 gnmt 1541784077.771318197 (train.py:372) input_size: 3497984
:::MLPv0.5.0 gnmt 1541784077.802675962 (train.py:386) eval_size: 3003
:::MLPv0.5.0 gnmt 1541784077.803501368 (seq2seq/inference/beam_search.py:43) eval_hp_beam_size: 5
:::MLPv0.5.0 gnmt 1541784077.803936720 (seq2seq/inference/beam_search.py:45) eval_hp_max_sequence_length: 150
:::MLPv0.5.0 gnmt 1541784077.804381371 (seq2seq/inference/beam_search.py:47) eval_hp_length_normalization_constant: 5.0
:::MLPv0.5.0 gnmt 1541784077.806374073 (seq2seq/inference/beam_search.py:49) eval_hp_length_normalization_factor: 0.6
6: Saving state of the tokenizer
11: Saving state of the tokenizer
5: Saving state of the tokenizer
1: Saving state of the tokenizer
2: Saving state of the tokenizer
15: Saving state of the tokenizer
9: Saving state of the tokenizer
4: Saving state of the tokenizer
7: Saving state of the tokenizer
10: Saving state of the tokenizer
13: Saving state of the tokenizer
14: Saving state of the tokenizer
3: Saving state of the tokenizer
8: Saving state of the tokenizer
12: Saving state of the tokenizer
:::MLPv0.5.0 gnmt 1541784077.806734085 (seq2seq/inference/beam_search.py:51) eval_hp_coverage_penalty_factor: 0.1
0: Saving state of the tokenizer
4: Initializing fp16 optimizer
4: Initializing fp32 clone weights
6: Initializing fp16 optimizer
6: Initializing fp32 clone weights
2: Initializing fp16 optimizer
2: Initializing fp32 clone weights
1: Initializing fp16 optimizer
1: Initializing fp32 clone weights
10: Initializing fp16 optimizer
10: Initializing fp32 clone weights
11: Initializing fp16 optimizer
11: Initializing fp32 clone weights
14: Initializing fp16 optimizer
14: Initializing fp32 clone weights
0: Initializing fp16 optimizer
0: Initializing fp32 clone weights
15: Initializing fp16 optimizer
15: Initializing fp32 clone weights
5: Initializing fp16 optimizer
5: Initializing fp32 clone weights
9: Initializing fp16 optimizer
9: Initializing fp32 clone weights
3: Initializing fp16 optimizer
3: Initializing fp32 clone weights
8: Initializing fp16 optimizer
8: Initializing fp32 clone weights
7: Initializing fp16 optimizer
7: Initializing fp32 clone weights
13: Initializing fp16 optimizer
13: Initializing fp32 clone weights
12: Initializing fp16 optimizer
12: Initializing fp32 clone weights
:::MLPv0.5.0 gnmt 1541784081.542663097 (seq2seq/train/trainer.py:99) opt_name: "adam"
:::MLPv0.5.0 gnmt 1541784081.543134928 (seq2seq/train/trainer.py:101) opt_learning_rate: 0.00125
:::MLPv0.5.0 gnmt 1541784081.543495655 (seq2seq/train/trainer.py:103) opt_hp_Adam_beta1: 0.9
:::MLPv0.5.0 gnmt 1541784081.543841362 (seq2seq/train/trainer.py:105) opt_hp_Adam_beta2: 0.999
3: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
5: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
2: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)10: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)13: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)7: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)11: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)




:::MLPv0.5.0 gnmt 1541784081.544186115 (seq2seq/train/trainer.py:107) opt_hp_Adam_epsilon: 1e-08
15: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)4: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
1: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)

9: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)12: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
8: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
6: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)

14: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
0: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
8: Starting epoch 0
2: Starting epoch 0
11: Starting epoch 0
3: Starting epoch 0
10: Starting epoch 0
13: Starting epoch 0
1: Starting epoch 0
7: Starting epoch 0
12: Starting epoch 0
4: Starting epoch 0
5: Starting epoch 0
9: Starting epoch 0
14: Starting epoch 0
15: Starting epoch 0
6: Starting epoch 0
:::MLPv0.5.0 gnmt 1541784081.544756174 (train.py:438) train_loop
0: Starting epoch 0
:::MLPv0.5.0 gnmt 1541784081.545156240 (train.py:443) train_epoch: 0
6: Sampler for epoch 0 uses seed 1021532236
11: Sampler for epoch 0 uses seed 1021532236
9: Sampler for epoch 0 uses seed 1021532236
14: Sampler for epoch 0 uses seed 1021532236
4: Sampler for epoch 0 uses seed 1021532236
7: Sampler for epoch 0 uses seed 1021532236
1: Sampler for epoch 0 uses seed 1021532236
12: Sampler for epoch 0 uses seed 1021532236
2: Sampler for epoch 0 uses seed 1021532236
10: Sampler for epoch 0 uses seed 1021532236
8: Sampler for epoch 0 uses seed 1021532236
13: Sampler for epoch 0 uses seed 1021532236
3: Sampler for epoch 0 uses seed 1021532236
5: Sampler for epoch 0 uses seed 1021532236
15: Sampler for epoch 0 uses seed 1021532236
:::MLPv0.5.0 gnmt 1541784084.764770508 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 0 uses seed 1021532236
:::MLPv0.5.0 gnmt 1541784084.928526878 (seq2seq/data/sampler.py:66) input_shard: 81920
11: Gradient norm: inf
12: Gradient norm: inf
11: Skipped batch, new scale: 4096.0
13: Gradient norm: inf
12: Skipped batch, new scale: 4096.0
10: Gradient norm: inf
9: Gradient norm: inf
13: Skipped batch, new scale: 4096.0
10: Skipped batch, new scale: 4096.0
9: Skipped batch, new scale: 4096.0
6: Gradient norm: inf
8: Gradient norm: inf
7: Gradient norm: inf
1: Gradient norm: inf
15: Gradient norm: inf
4: Gradient norm: inf
6: Skipped batch, new scale: 4096.0
11: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 2.72198 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3862 (0.0000)	Learning Rate [1.2499999999999968e-05]
8: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
15: Skipped batch, new scale: 4096.0
5: Gradient norm: inf
3: Gradient norm: inf
7: Skipped batch, new scale: 4096.0
4: Skipped batch, new scale: 4096.0
2: Gradient norm: inf
5: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
13: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 2.69759 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3853 (0.0000)	Learning Rate [1.2499999999999968e-05]
3: Skipped batch, new scale: 4096.0
12: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 3.56024 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3857 (0.0000)	Learning Rate [1.2499999999999968e-05]
9: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 2.70441 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3846 (0.0000)	Learning Rate [1.2499999999999968e-05]
0: Gradient norm: inf
10: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 3.22052 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3845 (0.0000)	Learning Rate [1.2499999999999968e-05]
6: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 2.49168 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3849 (0.0000)	Learning Rate [1.2499999999999968e-05]
0: Skipped batch, new scale: 4096.0
1: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 3.57287 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3862 (0.0000)	Learning Rate [1.2499999999999968e-05]
8: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 3.28954 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3861 (0.0000)	Learning Rate [1.2499999999999968e-05]
15: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 3.04367 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3851 (0.0000)	Learning Rate [1.2499999999999968e-05]
14: Gradient norm: inf
4: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 3.69674 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3855 (0.0000)	Learning Rate [1.2499999999999968e-05]
5: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 2.11381 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3857 (0.0000)	Learning Rate [1.2499999999999968e-05]
7: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 3.44448 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3839 (0.0000)	Learning Rate [1.2499999999999968e-05]
14: Skipped batch, new scale: 4096.0
2: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 3.36284 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3841 (0.0000)	Learning Rate [1.2499999999999968e-05]
3: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 2.70912 (0.00000)	Tok/s 462 (0)	Loss/tok 10.3836 (0.0000)	Learning Rate [1.2499999999999968e-05]
0: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 3.52493 (0.00000)	Tok/s 461 (0)	Loss/tok 10.3840 (0.0000)	Learning Rate [1.2499999999999968e-05]
14: TRAIN [0][0/3416]	Time 3.744 (0.000)	Data 1.51666 (0.00000)	Tok/s 461 (0)	Loss/tok 10.3843 (0.0000)	Learning Rate [1.2499999999999968e-05]
7: Gradient norm: inf
6: Gradient norm: inf
7: Skipped batch, new scale: 2048.0
6: Skipped batch, new scale: 2048.0
8: Gradient norm: inf
9: Gradient norm: inf
5: Gradient norm: inf
8: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
3: Gradient norm: inf
4: Gradient norm: inf
10: Gradient norm: inf
11: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
4: Skipped batch, new scale: 2048.0
10: Skipped batch, new scale: 2048.0
12: Gradient norm: inf
1: Gradient norm: inf
11: Skipped batch, new scale: 2048.0
2: Gradient norm: inf
12: Skipped batch, new scale: 2048.0
13: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
14: Gradient norm: inf
2: Skipped batch, new scale: 2048.0
13: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
14: Skipped batch, new scale: 2048.0
15: Skipped batch, new scale: 2048.0
0: TRAIN [0][10/3416]	Time 0.044 (0.063)	Data 0.00078 (0.00098)	Tok/s 49405 (46562)	Loss/tok 10.3606 (10.3768)	Learning Rate [1.5028305432717627e-05]
1: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00088 (0.00105)	Tok/s 49432 (46584)	Loss/tok 10.3600 (10.3768)	Learning Rate [1.5028305432717627e-05]
15: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00095 (0.00113)	Tok/s 49352 (47501)	Loss/tok 10.3623 (10.3765)	Learning Rate [1.5028305432717627e-05]
14: TRAIN [0][10/3416]	Time 0.044 (0.063)	Data 0.00091 (0.00082)	Tok/s 49332 (47504)	Loss/tok 10.3591 (10.3770)	Learning Rate [1.5028305432717627e-05]
2: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00097 (0.00085)	Tok/s 49428 (46628)	Loss/tok 10.3604 (10.3769)	Learning Rate [1.5028305432717627e-05]
13: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00085 (0.00108)	Tok/s 49339 (47217)	Loss/tok 10.3593 (10.3767)	Learning Rate [1.5028305432717627e-05]
3: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00104 (0.00115)	Tok/s 49435 (46715)	Loss/tok 10.3609 (10.3766)	Learning Rate [1.5028305432717627e-05]
12: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00094 (0.00111)	Tok/s 49333 (47019)	Loss/tok 10.3615 (10.3767)	Learning Rate [1.5028305432717627e-05]
11: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00092 (0.00105)	Tok/s 49298 (46990)	Loss/tok 10.3609 (10.3768)	Learning Rate [1.5028305432717627e-05]
5: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00096 (0.00081)	Tok/s 49484 (46887)	Loss/tok 10.3599 (10.3772)	Learning Rate [1.5028305432717627e-05]
4: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00104 (0.00154)	Tok/s 49508 (46816)	Loss/tok 10.3604 (10.3763)	Learning Rate [1.5028305432717627e-05]
6: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00103 (0.00115)	Tok/s 49600 (47060)	Loss/tok 10.3598 (10.3766)	Learning Rate [1.5028305432717627e-05]
10: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00096 (0.00113)	Tok/s 49353 (47097)	Loss/tok 10.3606 (10.3768)	Learning Rate [1.5028305432717627e-05]
7: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00110 (0.00115)	Tok/s 49378 (47070)	Loss/tok 10.3627 (10.3775)	Learning Rate [1.5028305432717627e-05]
8: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00090 (0.00086)	Tok/s 49335 (47132)	Loss/tok 10.3605 (10.3770)	Learning Rate [1.5028305432717627e-05]
9: TRAIN [0][10/3416]	Time 0.044 (0.064)	Data 0.00132 (0.00098)	Tok/s 49505 (47073)	Loss/tok 10.3617 (10.3769)	Learning Rate [1.5028305432717627e-05]
12: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
10: Gradient norm: inf
14: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
15: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
0: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
2: Gradient norm: inf
5: Gradient norm: inf
7: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
13: TRAIN [0][20/3416]	Time 0.051 (0.061)	Data 0.00085 (0.00101)	Tok/s 36475 (50737)	Loss/tok 10.3124 (10.3605)	Learning Rate [1.848885485210255e-05]
14: TRAIN [0][20/3416]	Time 0.051 (0.061)	Data 0.00090 (0.00089)	Tok/s 36377 (50908)	Loss/tok 10.3110 (10.3606)	Learning Rate [1.848885485210255e-05]
11: TRAIN [0][20/3416]	Time 0.051 (0.061)	Data 0.00090 (0.00100)	Tok/s 36449 (50580)	Loss/tok 10.3100 (10.3603)	Learning Rate [1.848885485210255e-05]
1: TRAIN [0][20/3416]	Time 0.051 (0.061)	Data 0.00090 (0.00099)	Tok/s 36214 (50049)	Loss/tok 10.3135 (10.3602)	Learning Rate [1.848885485210255e-05]
0: TRAIN [0][20/3416]	Time 0.051 (0.061)	Data 0.00091 (0.00094)	Tok/s 35497 (50002)	Loss/tok 10.3054 (10.3600)	Learning Rate [1.848885485210255e-05]
15: TRAIN [0][20/3416]	Time 0.051 (0.061)	Data 0.00092 (0.00106)	Tok/s 36288 (50959)	Loss/tok 10.3117 (10.3607)	Learning Rate [1.848885485210255e-05]
9: TRAIN [0][20/3416]	Time 0.051 (0.061)	Data 0.00094 (0.00100)	Tok/s 36361 (50547)	Loss/tok 10.3093 (10.3608)	Learning Rate [1.848885485210255e-05]
12: TRAIN [0][20/3416]	Time 0.051 (0.061)	Data 0.00091 (0.00106)	Tok/s 36456 (50636)	Loss/tok 10.3147 (10.3605)	Learning Rate [1.848885485210255e-05]
7: TRAIN [0][20/3416]	Time 0.051 (0.061)	Data 0.00096 (0.00105)	Tok/s 36253 (50458)	Loss/tok 10.3121 (10.3609)	Learning Rate [1.848885485210255e-05]
2: TRAIN [0][20/3416]	Time 0.052 (0.061)	Data 0.00094 (0.00091)	Tok/s 36022 (50068)	Loss/tok 10.3111 (10.3605)	Learning Rate [1.848885485210255e-05]
8: TRAIN [0][20/3416]	Time 0.051 (0.061)	Data 0.00093 (0.00089)	Tok/s 36294 (50540)	Loss/tok 10.3091 (10.3605)	Learning Rate [1.848885485210255e-05]
3: TRAIN [0][20/3416]	Time 0.051 (0.061)	Data 0.00095 (0.00107)	Tok/s 36068 (50133)	Loss/tok 10.3074 (10.3597)	Learning Rate [1.848885485210255e-05]
5: TRAIN [0][20/3416]	Time 0.051 (0.061)	Data 0.00097 (0.00088)	Tok/s 36117 (50361)	Loss/tok 10.3059 (10.3606)	Learning Rate [1.848885485210255e-05]
6: TRAIN [0][20/3416]	Time 0.051 (0.061)	Data 0.00094 (0.00106)	Tok/s 36064 (50461)	Loss/tok 10.3140 (10.3599)	Learning Rate [1.848885485210255e-05]
4: TRAIN [0][20/3416]	Time 0.052 (0.061)	Data 0.00107 (0.00128)	Tok/s 36006 (50257)	Loss/tok 10.3120 (10.3602)	Learning Rate [1.848885485210255e-05]
10: TRAIN [0][20/3416]	Time 0.053 (0.061)	Data 0.00096 (0.00105)	Tok/s 35189 (50563)	Loss/tok 10.3127 (10.3597)	Learning Rate [1.848885485210255e-05]
11: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00100 (0.00098)	Tok/s 36610 (51359)	Loss/tok 10.1366 (10.3274)	Learning Rate [2.3276089208285794e-05]
10: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00120 (0.00103)	Tok/s 36532 (51407)	Loss/tok 10.1365 (10.3265)	Learning Rate [2.3276089208285794e-05]
12: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00126 (0.00108)	Tok/s 36616 (51403)	Loss/tok 10.1403 (10.3266)	Learning Rate [2.3276089208285794e-05]
13: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00107 (0.00100)	Tok/s 36613 (51491)	Loss/tok 10.1410 (10.3277)	Learning Rate [2.3276089208285794e-05]
7: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00115 (0.00104)	Tok/s 36373 (51279)	Loss/tok 10.1430 (10.3267)	Learning Rate [2.3276089208285794e-05]
0: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00099 (0.00100)	Tok/s 35327 (50853)	Loss/tok 10.1343 (10.3275)	Learning Rate [2.3276089208285794e-05]
6: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00112 (0.00103)	Tok/s 36377 (51284)	Loss/tok 10.1400 (10.3273)	Learning Rate [2.3276089208285794e-05]
14: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00097 (0.00095)	Tok/s 36611 (51663)	Loss/tok 10.1417 (10.3266)	Learning Rate [2.3276089208285794e-05]
8: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00107 (0.00090)	Tok/s 36391 (51338)	Loss/tok 10.1333 (10.3265)	Learning Rate [2.3276089208285794e-05]
15: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00089 (0.00109)	Tok/s 36610 (51716)	Loss/tok 10.1385 (10.3279)	Learning Rate [2.3276089208285794e-05]
1: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00101 (0.00106)	Tok/s 35953 (50907)	Loss/tok 10.1514 (10.3266)	Learning Rate [2.3276089208285794e-05]
5: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00100 (0.00097)	Tok/s 36304 (51202)	Loss/tok 10.1368 (10.3272)	Learning Rate [2.3276089208285794e-05]
4: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00129 (0.00121)	Tok/s 36456 (51145)	Loss/tok 10.1152 (10.3261)	Learning Rate [2.3276089208285794e-05]
9: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00121 (0.00099)	Tok/s 36165 (51330)	Loss/tok 10.1360 (10.3272)	Learning Rate [2.3276089208285794e-05]
2: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00127 (0.00098)	Tok/s 36444 (50955)	Loss/tok 10.1409 (10.3257)	Learning Rate [2.3276089208285794e-05]
3: TRAIN [0][30/3416]	Time 0.051 (0.061)	Data 0.00102 (0.00105)	Tok/s 36315 (51052)	Loss/tok 10.1464 (10.3262)	Learning Rate [2.3276089208285794e-05]
12: Gradient norm: inf
14: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 512.0
15: Gradient norm: inf
14: Skipped batch, new scale: 512.0
11: Skipped batch, new scale: 512.0
15: Skipped batch, new scale: 512.0
0: Gradient norm: inf
13: Gradient norm: inf
9: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 512.0
9: Skipped batch, new scale: 512.0
12: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00102 (0.00105)	Tok/s 60965 (51512)	Loss/tok 9.3721 (10.1662)	Learning Rate [2.8635845659597103e-05]
8: Gradient norm: inf
11: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00085 (0.00096)	Tok/s 60861 (51441)	Loss/tok 9.4363 (10.1711)	Learning Rate [2.8635845659597103e-05]
14: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00084 (0.00096)	Tok/s 62038 (51798)	Loss/tok 9.5056 (10.1731)	Learning Rate [2.8635845659597103e-05]
1: Skipped batch, new scale: 512.0
13: Skipped batch, new scale: 512.0
2: Gradient norm: inf
7: Gradient norm: inf
8: Skipped batch, new scale: 512.0
10: Gradient norm: inf
15: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00095 (0.00104)	Tok/s 62013 (51864)	Loss/tok 9.4925 (10.1725)	Learning Rate [2.8635845659597103e-05]
2: Skipped batch, new scale: 512.0
7: Skipped batch, new scale: 512.0
6: Gradient norm: inf
0: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00090 (0.00098)	Tok/s 61028 (50828)	Loss/tok 9.4706 (10.1729)	Learning Rate [2.8635845659597103e-05]
3: Gradient norm: inf
4: Gradient norm: inf
9: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00082 (0.00101)	Tok/s 61155 (51402)	Loss/tok 9.4715 (10.1722)	Learning Rate [2.8635845659597103e-05]
5: Gradient norm: inf
6: Skipped batch, new scale: 512.0
1: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00088 (0.00101)	Tok/s 61021 (50873)	Loss/tok 9.3805 (10.1659)	Learning Rate [2.8635845659597103e-05]
3: Skipped batch, new scale: 512.0
10: Skipped batch, new scale: 512.0
4: Skipped batch, new scale: 512.0
5: Skipped batch, new scale: 512.0
8: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00087 (0.00090)	Tok/s 60775 (51394)	Loss/tok 9.3988 (10.1662)	Learning Rate [2.8635845659597103e-05]
2: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00102 (0.00098)	Tok/s 61148 (50913)	Loss/tok 9.4178 (10.1692)	Learning Rate [2.8635845659597103e-05]
7: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00094 (0.00102)	Tok/s 60843 (51316)	Loss/tok 9.4467 (10.1695)	Learning Rate [2.8635845659597103e-05]
13: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00081 (0.00100)	Tok/s 61168 (51618)	Loss/tok 9.4796 (10.1726)	Learning Rate [2.8635845659597103e-05]
6: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00098 (0.00100)	Tok/s 60846 (51297)	Loss/tok 9.4187 (10.1701)	Learning Rate [2.8635845659597103e-05]
3: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00088 (0.00108)	Tok/s 61019 (50997)	Loss/tok 9.4595 (10.1716)	Learning Rate [2.8635845659597103e-05]
4: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00100 (0.00121)	Tok/s 61000 (51085)	Loss/tok 9.4662 (10.1714)	Learning Rate [2.8635845659597103e-05]
10: TRAIN [0][40/3416]	Time 0.068 (0.059)	Data 0.00085 (0.00102)	Tok/s 60627 (51464)	Loss/tok 9.4286 (10.1701)	Learning Rate [2.8635845659597103e-05]
5: TRAIN [0][40/3416]	Time 0.067 (0.059)	Data 0.00102 (0.00098)	Tok/s 60863 (51205)	Loss/tok 9.5004 (10.1685)	Learning Rate [2.8635845659597103e-05]
2: Gradient norm: inf
3: Gradient norm: inf
2: Skipped batch, new scale: 256.0
1: Gradient norm: inf
1: Skipped batch, new scale: 256.0
3: Skipped batch, new scale: 256.0
0: Gradient norm: inf
4: Gradient norm: inf
0: Skipped batch, new scale: 256.0
15: Gradient norm: inf
4: Skipped batch, new scale: 256.0
5: Gradient norm: inf
15: Skipped batch, new scale: 256.0
14: Gradient norm: inf
5: Skipped batch, new scale: 256.0
6: Gradient norm: inf
14: Skipped batch, new scale: 256.0
6: Skipped batch, new scale: 256.0
7: Gradient norm: inf
13: Gradient norm: inf
12: Gradient norm: inf
8: Gradient norm: inf
7: Skipped batch, new scale: 256.0
11: Gradient norm: inf
12: Skipped batch, new scale: 256.0
13: Skipped batch, new scale: 256.0
8: Skipped batch, new scale: 256.0
9: Gradient norm: inf
11: Skipped batch, new scale: 256.0
9: Skipped batch, new scale: 256.0
10: Gradient norm: inf
10: Skipped batch, new scale: 256.0
5: Gradient norm: inf
4: Gradient norm: inf
6: Gradient norm: inf
5: Skipped batch, new scale: 128.0
3: Gradient norm: inf
4: Skipped batch, new scale: 128.0
6: Skipped batch, new scale: 128.0
7: Gradient norm: inf
2: Gradient norm: inf
3: Skipped batch, new scale: 128.0
8: Gradient norm: inf
7: Skipped batch, new scale: 128.0
2: Skipped batch, new scale: 128.0
1: Gradient norm: inf
8: Skipped batch, new scale: 128.0
9: Gradient norm: inf
1: Skipped batch, new scale: 128.0
0: Gradient norm: inf
9: Skipped batch, new scale: 128.0
10: Gradient norm: inf
0: Skipped batch, new scale: 128.0
15: Gradient norm: inf
10: Skipped batch, new scale: 128.0
11: Gradient norm: inf
12: Gradient norm: inf
14: Gradient norm: inf
11: Skipped batch, new scale: 128.0
13: Gradient norm: inf
15: Skipped batch, new scale: 128.0
12: Skipped batch, new scale: 128.0
13: Skipped batch, new scale: 128.0
14: Skipped batch, new scale: 128.0
4: TRAIN [0][50/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00116)	Tok/s 70576 (51326)	Loss/tok 9.6065 (10.0496)	Learning Rate [3.442785879172701e-05]
7: TRAIN [0][50/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00102)	Tok/s 70420 (51535)	Loss/tok 9.6529 (10.0522)	Learning Rate [3.442785879172701e-05]
3: TRAIN [0][50/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00106)	Tok/s 70467 (51228)	Loss/tok 9.6917 (10.0560)	Learning Rate [3.442785879172701e-05]
2: TRAIN [0][50/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 70354 (51140)	Loss/tok 9.6178 (10.0517)	Learning Rate [3.442785879172701e-05]
8: TRAIN [0][50/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00091)	Tok/s 70275 (51596)	Loss/tok 9.6233 (10.0479)	Learning Rate [3.442785879172701e-05]
1: TRAIN [0][50/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00100)	Tok/s 70226 (51103)	Loss/tok 9.7686 (10.0499)	Learning Rate [3.442785879172701e-05]
6: TRAIN [0][50/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00100)	Tok/s 70512 (51522)	Loss/tok 9.6532 (10.0559)	Learning Rate [3.442785879172701e-05]
5: TRAIN [0][50/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 70558 (51432)	Loss/tok 9.7897 (10.0543)	Learning Rate [3.442785879172701e-05]
15: TRAIN [0][50/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00103)	Tok/s 70995 (52070)	Loss/tok 9.6725 (10.0585)	Learning Rate [3.442785879172701e-05]
10: TRAIN [0][50/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00103)	Tok/s 70163 (51647)	Loss/tok 9.6837 (10.0536)	Learning Rate [3.442785879172701e-05]
0: TRAIN [0][50/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 69693 (51056)	Loss/tok 9.6809 (10.0550)	Learning Rate [3.442785879172701e-05]
11: TRAIN [0][50/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00095)	Tok/s 69999 (51644)	Loss/tok 9.6567 (10.0585)	Learning Rate [3.442785879172701e-05]
12: TRAIN [0][50/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00104)	Tok/s 69856 (51728)	Loss/tok 9.7107 (10.0546)	Learning Rate [3.442785879172701e-05]
13: TRAIN [0][50/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00100)	Tok/s 70578 (51840)	Loss/tok 9.7650 (10.0627)	Learning Rate [3.442785879172701e-05]
9: TRAIN [0][50/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 70146 (51594)	Loss/tok 9.7482 (10.0501)	Learning Rate [3.442785879172701e-05]
14: TRAIN [0][50/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 70839 (51982)	Loss/tok 9.7211 (10.0574)	Learning Rate [3.442785879172701e-05]
13: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00099)	Tok/s 55416 (52528)	Loss/tok 8.5506 (9.8435)	Learning Rate [4.334210630656638e-05]
11: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00094)	Tok/s 55285 (52302)	Loss/tok 8.5871 (9.8413)	Learning Rate [4.334210630656638e-05]
12: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00103)	Tok/s 55291 (52408)	Loss/tok 8.5890 (9.8311)	Learning Rate [4.334210630656638e-05]
10: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00101)	Tok/s 55267 (52289)	Loss/tok 8.5832 (9.8338)	Learning Rate [4.334210630656638e-05]
14: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00097)	Tok/s 55268 (52655)	Loss/tok 8.5526 (9.8371)	Learning Rate [4.334210630656638e-05]
1: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00084 (0.00098)	Tok/s 55101 (51760)	Loss/tok 8.5642 (9.8306)	Learning Rate [4.334210630656638e-05]
15: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00101)	Tok/s 55191 (52730)	Loss/tok 8.5077 (9.8376)	Learning Rate [4.334210630656638e-05]
0: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00097)	Tok/s 55144 (51721)	Loss/tok 8.5584 (9.8301)	Learning Rate [4.334210630656638e-05]
8: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00091)	Tok/s 54993 (52243)	Loss/tok 8.4642 (9.8245)	Learning Rate [4.334210630656638e-05]
2: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00097)	Tok/s 54943 (51790)	Loss/tok 8.6139 (9.8308)	Learning Rate [4.334210630656638e-05]
4: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00113)	Tok/s 54842 (51984)	Loss/tok 8.5657 (9.8313)	Learning Rate [4.334210630656638e-05]
7: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00101)	Tok/s 54859 (52191)	Loss/tok 8.5920 (9.8330)	Learning Rate [4.334210630656638e-05]
6: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00099)	Tok/s 54777 (52170)	Loss/tok 8.5461 (9.8309)	Learning Rate [4.334210630656638e-05]
3: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00104)	Tok/s 54797 (51892)	Loss/tok 8.5007 (9.8325)	Learning Rate [4.334210630656638e-05]
5: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00098)	Tok/s 54628 (52084)	Loss/tok 8.5272 (9.8350)	Learning Rate [4.334210630656638e-05]
9: TRAIN [0][60/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00098)	Tok/s 55083 (52244)	Loss/tok 8.5606 (9.8314)	Learning Rate [4.334210630656638e-05]
14: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00097)	Tok/s 35224 (53130)	Loss/tok 7.8854 (9.6027)	Learning Rate [5.4564479030020655e-05]
15: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00100)	Tok/s 35226 (53202)	Loss/tok 8.1209 (9.6088)	Learning Rate [5.4564479030020655e-05]
13: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00098)	Tok/s 35134 (53002)	Loss/tok 8.0668 (9.6081)	Learning Rate [5.4564479030020655e-05]
0: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 33964 (52178)	Loss/tok 7.8852 (9.6024)	Learning Rate [5.4564479030020655e-05]
12: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00102)	Tok/s 35068 (52879)	Loss/tok 7.8629 (9.5971)	Learning Rate [5.4564479030020655e-05]
1: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00097)	Tok/s 33950 (52210)	Loss/tok 7.9434 (9.5998)	Learning Rate [5.4564479030020655e-05]
11: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00094)	Tok/s 34014 (52767)	Loss/tok 7.9331 (9.6089)	Learning Rate [5.4564479030020655e-05]
2: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00097)	Tok/s 33951 (52238)	Loss/tok 8.0536 (9.6052)	Learning Rate [5.4564479030020655e-05]
3: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00103)	Tok/s 33961 (52350)	Loss/tok 7.9683 (9.6073)	Learning Rate [5.4564479030020655e-05]
8: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00091)	Tok/s 33764 (52694)	Loss/tok 8.0572 (9.5971)	Learning Rate [5.4564479030020655e-05]
6: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00100)	Tok/s 33826 (52612)	Loss/tok 8.0135 (9.6039)	Learning Rate [5.4564479030020655e-05]
4: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00136 (0.00111)	Tok/s 33952 (52443)	Loss/tok 7.9072 (9.5964)	Learning Rate [5.4564479030020655e-05]
7: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00100)	Tok/s 33809 (52631)	Loss/tok 7.9046 (9.6089)	Learning Rate [5.4564479030020655e-05]
5: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00097)	Tok/s 33855 (52540)	Loss/tok 8.0166 (9.6102)	Learning Rate [5.4564479030020655e-05]
9: TRAIN [0][70/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00097)	Tok/s 33821 (52703)	Loss/tok 7.9794 (9.6048)	Learning Rate [5.4564479030020655e-05]
10: TRAIN [0][70/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00100)	Tok/s 33137 (52733)	Loss/tok 7.8291 (9.6066)	Learning Rate [5.4564479030020655e-05]
6: TRAIN [0][80/3416]	Time 0.055 (0.059)	Data 0.00100 (0.00099)	Tok/s 53169 (53232)	Loss/tok 8.0505 (9.3963)	Learning Rate [6.869260923220296e-05]
4: TRAIN [0][80/3416]	Time 0.055 (0.059)	Data 0.00101 (0.00109)	Tok/s 53195 (53061)	Loss/tok 8.1217 (9.3908)	Learning Rate [6.869260923220296e-05]
7: TRAIN [0][80/3416]	Time 0.055 (0.059)	Data 0.00104 (0.00099)	Tok/s 53322 (53255)	Loss/tok 7.9429 (9.4017)	Learning Rate [6.869260923220296e-05]
5: TRAIN [0][80/3416]	Time 0.055 (0.059)	Data 0.00095 (0.00096)	Tok/s 53166 (53155)	Loss/tok 8.1439 (9.4048)	Learning Rate [6.869260923220296e-05]
8: TRAIN [0][80/3416]	Time 0.055 (0.059)	Data 0.00104 (0.00091)	Tok/s 53289 (53316)	Loss/tok 7.9823 (9.3898)	Learning Rate [6.869260923220296e-05]
1: TRAIN [0][80/3416]	Time 0.056 (0.059)	Data 0.00106 (0.00096)	Tok/s 52865 (52845)	Loss/tok 7.9713 (9.3879)	Learning Rate [6.869260923220296e-05]
10: TRAIN [0][80/3416]	Time 0.055 (0.059)	Data 0.00096 (0.00099)	Tok/s 53152 (53376)	Loss/tok 8.1057 (9.3988)	Learning Rate [6.869260923220296e-05]
3: TRAIN [0][80/3416]	Time 0.056 (0.059)	Data 0.00106 (0.00102)	Tok/s 52989 (52968)	Loss/tok 7.9835 (9.3915)	Learning Rate [6.869260923220296e-05]
12: TRAIN [0][80/3416]	Time 0.055 (0.059)	Data 0.00099 (0.00101)	Tok/s 53049 (53501)	Loss/tok 8.0158 (9.3880)	Learning Rate [6.869260923220296e-05]
15: TRAIN [0][80/3416]	Time 0.056 (0.059)	Data 0.00101 (0.00099)	Tok/s 54094 (53812)	Loss/tok 8.1276 (9.4027)	Learning Rate [6.869260923220296e-05]
0: TRAIN [0][80/3416]	Time 0.056 (0.059)	Data 0.00090 (0.00097)	Tok/s 52836 (52812)	Loss/tok 7.9267 (9.3891)	Learning Rate [6.869260923220296e-05]
2: TRAIN [0][80/3416]	Time 0.056 (0.059)	Data 0.00099 (0.00097)	Tok/s 52893 (52869)	Loss/tok 8.0776 (9.3934)	Learning Rate [6.869260923220296e-05]
9: TRAIN [0][80/3416]	Time 0.055 (0.059)	Data 0.00094 (0.00097)	Tok/s 53225 (53339)	Loss/tok 8.0134 (9.3953)	Learning Rate [6.869260923220296e-05]
13: TRAIN [0][80/3416]	Time 0.056 (0.059)	Data 0.00100 (0.00097)	Tok/s 52824 (53616)	Loss/tok 8.0579 (9.4079)	Learning Rate [6.869260923220296e-05]
14: TRAIN [0][80/3416]	Time 0.056 (0.059)	Data 0.00101 (0.00097)	Tok/s 53607 (53742)	Loss/tok 8.0194 (9.3996)	Learning Rate [6.869260923220296e-05]
11: TRAIN [0][80/3416]	Time 0.056 (0.059)	Data 0.00100 (0.00094)	Tok/s 52831 (53391)	Loss/tok 8.1074 (9.4011)	Learning Rate [6.869260923220296e-05]
11: TRAIN [0][90/3416]	Time 0.073 (0.058)	Data 0.00087 (0.00094)	Tok/s 76063 (52703)	Loss/tok 7.9706 (9.2605)	Learning Rate [8.647887136486693e-05]
10: TRAIN [0][90/3416]	Time 0.073 (0.058)	Data 0.00109 (0.00099)	Tok/s 76099 (52679)	Loss/tok 8.0370 (9.2628)	Learning Rate [8.647887136486693e-05]
12: TRAIN [0][90/3416]	Time 0.073 (0.058)	Data 0.00094 (0.00100)	Tok/s 75895 (52819)	Loss/tok 8.0232 (9.2456)	Learning Rate [8.647887136486693e-05]
9: TRAIN [0][90/3416]	Time 0.073 (0.058)	Data 0.00091 (0.00096)	Tok/s 75587 (52622)	Loss/tok 7.9220 (9.2515)	Learning Rate [8.647887136486693e-05]
13: TRAIN [0][90/3416]	Time 0.073 (0.058)	Data 0.00093 (0.00096)	Tok/s 75819 (52923)	Loss/tok 7.9410 (9.2681)	Learning Rate [8.647887136486693e-05]
8: TRAIN [0][90/3416]	Time 0.073 (0.058)	Data 0.00095 (0.00091)	Tok/s 75175 (52587)	Loss/tok 7.9036 (9.2488)	Learning Rate [8.647887136486693e-05]
14: TRAIN [0][90/3416]	Time 0.074 (0.058)	Data 0.00091 (0.00098)	Tok/s 75662 (53055)	Loss/tok 8.0515 (9.2619)	Learning Rate [8.647887136486693e-05]
0: TRAIN [0][90/3416]	Time 0.074 (0.058)	Data 0.00098 (0.00097)	Tok/s 73747 (51981)	Loss/tok 8.0080 (9.2530)	Learning Rate [8.647887136486693e-05]
6: TRAIN [0][90/3416]	Time 0.073 (0.058)	Data 0.00091 (0.00099)	Tok/s 74918 (52489)	Loss/tok 8.0583 (9.2575)	Learning Rate [8.647887136486693e-05]
1: TRAIN [0][90/3416]	Time 0.074 (0.058)	Data 0.00095 (0.00095)	Tok/s 73873 (52031)	Loss/tok 8.0163 (9.2506)	Learning Rate [8.647887136486693e-05]
5: TRAIN [0][90/3416]	Time 0.074 (0.058)	Data 0.00098 (0.00096)	Tok/s 74844 (52408)	Loss/tok 8.0782 (9.2694)	Learning Rate [8.647887136486693e-05]
4: TRAIN [0][90/3416]	Time 0.074 (0.058)	Data 0.00097 (0.00107)	Tok/s 74783 (52315)	Loss/tok 7.9751 (9.2546)	Learning Rate [8.647887136486693e-05]
2: TRAIN [0][90/3416]	Time 0.074 (0.058)	Data 0.00098 (0.00097)	Tok/s 74599 (52103)	Loss/tok 8.1291 (9.2602)	Learning Rate [8.647887136486693e-05]
3: TRAIN [0][90/3416]	Time 0.074 (0.058)	Data 0.00091 (0.00101)	Tok/s 74606 (52209)	Loss/tok 8.0419 (9.2531)	Learning Rate [8.647887136486693e-05]
7: TRAIN [0][90/3416]	Time 0.073 (0.058)	Data 0.00106 (0.00099)	Tok/s 75015 (52520)	Loss/tok 7.9201 (9.2586)	Learning Rate [8.647887136486693e-05]
15: TRAIN [0][90/3416]	Time 0.074 (0.058)	Data 0.00085 (0.00098)	Tok/s 75384 (53127)	Loss/tok 8.0096 (9.2602)	Learning Rate [8.647887136486693e-05]
13: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00096)	Tok/s 67072 (52331)	Loss/tok 8.1157 (9.1508)	Learning Rate [0.00010887044874450993]
11: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00093)	Tok/s 66911 (52099)	Loss/tok 8.0160 (9.1405)	Learning Rate [0.00010887044874450993]
14: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00109 (0.00098)	Tok/s 67088 (52475)	Loss/tok 8.1157 (9.1430)	Learning Rate [0.00010887044874450993]
15: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00098)	Tok/s 67028 (52554)	Loss/tok 8.0078 (9.1399)	Learning Rate [0.00010887044874450993]
0: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00097)	Tok/s 66022 (51416)	Loss/tok 8.0922 (9.1352)	Learning Rate [0.00010887044874450993]
12: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00101 (0.00100)	Tok/s 66914 (52215)	Loss/tok 8.0398 (9.1257)	Learning Rate [0.00010887044874450993]
10: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00099)	Tok/s 66794 (52062)	Loss/tok 7.9648 (9.1411)	Learning Rate [0.00010887044874450993]
1: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00087 (0.00095)	Tok/s 65919 (51460)	Loss/tok 8.0566 (9.1353)	Learning Rate [0.00010887044874450993]
8: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00088 (0.00091)	Tok/s 66042 (51974)	Loss/tok 8.0133 (9.1284)	Learning Rate [0.00010887044874450993]
2: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00097)	Tok/s 65827 (51530)	Loss/tok 8.1309 (9.1415)	Learning Rate [0.00010887044874450993]
7: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00105 (0.00099)	Tok/s 65536 (51912)	Loss/tok 8.0496 (9.1393)	Learning Rate [0.00010887044874450993]
3: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00100)	Tok/s 65744 (51632)	Loss/tok 8.0647 (9.1355)	Learning Rate [0.00010887044874450993]
6: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00099)	Tok/s 65535 (51883)	Loss/tok 8.1255 (9.1404)	Learning Rate [0.00010887044874450993]
4: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00106)	Tok/s 65609 (51725)	Loss/tok 8.1623 (9.1385)	Learning Rate [0.00010887044874450993]
9: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00096)	Tok/s 66654 (52010)	Loss/tok 8.0532 (9.1327)	Learning Rate [0.00010887044874450993]
5: TRAIN [0][100/3416]	Time 0.071 (0.058)	Data 0.00103 (0.00096)	Tok/s 65562 (51809)	Loss/tok 8.1198 (9.1490)	Learning Rate [0.00010887044874450993]
2: TRAIN [0][110/3416]	Time 0.069 (0.059)	Data 0.00095 (0.00097)	Tok/s 68174 (52465)	Loss/tok 7.9826 (9.0079)	Learning Rate [0.00013705977451789795]
1: TRAIN [0][110/3416]	Time 0.069 (0.059)	Data 0.00086 (0.00095)	Tok/s 68253 (52401)	Loss/tok 7.9627 (9.0007)	Learning Rate [0.00013705977451789795]
4: TRAIN [0][110/3416]	Time 0.070 (0.059)	Data 0.00088 (0.00105)	Tok/s 68126 (52658)	Loss/tok 7.9857 (9.0029)	Learning Rate [0.00013705977451789795]
5: TRAIN [0][110/3416]	Time 0.069 (0.059)	Data 0.00088 (0.00096)	Tok/s 68617 (52739)	Loss/tok 8.0206 (9.0131)	Learning Rate [0.00013705977451789795]
6: TRAIN [0][110/3416]	Time 0.069 (0.059)	Data 0.00084 (0.00099)	Tok/s 69096 (52808)	Loss/tok 7.9308 (9.0050)	Learning Rate [0.00013705977451789795]
14: TRAIN [0][110/3416]	Time 0.069 (0.059)	Data 0.00088 (0.00098)	Tok/s 69127 (53431)	Loss/tok 7.9972 (9.0063)	Learning Rate [0.00013705977451789795]
15: TRAIN [0][110/3416]	Time 0.070 (0.059)	Data 0.00081 (0.00097)	Tok/s 69019 (53511)	Loss/tok 7.9977 (9.0015)	Learning Rate [0.00013705977451789795]
3: TRAIN [0][110/3416]	Time 0.070 (0.059)	Data 0.00085 (0.00099)	Tok/s 68096 (52571)	Loss/tok 8.0134 (9.0018)	Learning Rate [0.00013705977451789795]
0: TRAIN [0][110/3416]	Time 0.069 (0.059)	Data 0.00077 (0.00097)	Tok/s 68153 (52359)	Loss/tok 7.9233 (9.0006)	Learning Rate [0.00013705977451789795]
13: TRAIN [0][110/3416]	Time 0.070 (0.059)	Data 0.00096 (0.00096)	Tok/s 69048 (53277)	Loss/tok 8.0220 (9.0153)	Learning Rate [0.00013705977451789795]
7: TRAIN [0][110/3416]	Time 0.070 (0.059)	Data 0.00084 (0.00098)	Tok/s 69012 (52847)	Loss/tok 7.9062 (8.9980)	Learning Rate [0.00013705977451789795]
9: TRAIN [0][110/3416]	Time 0.070 (0.059)	Data 0.00092 (0.00096)	Tok/s 68912 (52949)	Loss/tok 7.9769 (8.9976)	Learning Rate [0.00013705977451789795]
11: TRAIN [0][110/3416]	Time 0.070 (0.059)	Data 0.00080 (0.00093)	Tok/s 68978 (53042)	Loss/tok 7.8620 (9.0055)	Learning Rate [0.00013705977451789795]
12: TRAIN [0][110/3416]	Time 0.070 (0.059)	Data 0.00089 (0.00100)	Tok/s 68977 (53155)	Loss/tok 7.9900 (8.9886)	Learning Rate [0.00013705977451789795]
8: TRAIN [0][110/3416]	Time 0.070 (0.059)	Data 0.00090 (0.00092)	Tok/s 68980 (52913)	Loss/tok 8.0510 (8.9922)	Learning Rate [0.00013705977451789795]
10: TRAIN [0][110/3416]	Time 0.070 (0.059)	Data 0.00089 (0.00098)	Tok/s 68809 (52998)	Loss/tok 7.9472 (9.0072)	Learning Rate [0.00013705977451789795]
3: TRAIN [0][120/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00099)	Tok/s 52947 (52455)	Loss/tok 7.9099 (8.9067)	Learning Rate [0.00017254803307536042]
2: TRAIN [0][120/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00097)	Tok/s 52960 (52350)	Loss/tok 7.8801 (8.9142)	Learning Rate [0.00017254803307536042]
5: TRAIN [0][120/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00097)	Tok/s 53967 (52629)	Loss/tok 7.9269 (8.9209)	Learning Rate [0.00017254803307536042]
6: TRAIN [0][120/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00098)	Tok/s 53931 (52692)	Loss/tok 7.7762 (8.9144)	Learning Rate [0.00017254803307536042]
4: TRAIN [0][120/3416]	Time 0.054 (0.058)	Data 0.00132 (0.00105)	Tok/s 53968 (52555)	Loss/tok 7.8230 (8.9098)	Learning Rate [0.00017254803307536042]
9: TRAIN [0][120/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00096)	Tok/s 54160 (52848)	Loss/tok 7.8505 (8.9029)	Learning Rate [0.00017254803307536042]
1: TRAIN [0][120/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00097)	Tok/s 52958 (52288)	Loss/tok 7.8756 (8.9082)	Learning Rate [0.00017254803307536042]
11: TRAIN [0][120/3416]	Time 0.054 (0.059)	Data 0.00088 (0.00093)	Tok/s 54232 (52941)	Loss/tok 7.7200 (8.9135)	Learning Rate [0.00017254803307536042]
10: TRAIN [0][120/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00098)	Tok/s 54259 (52902)	Loss/tok 7.8725 (8.9160)	Learning Rate [0.00017254803307536042]
8: TRAIN [0][120/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00091)	Tok/s 54039 (52804)	Loss/tok 7.8355 (8.8987)	Learning Rate [0.00017254803307536042]
7: TRAIN [0][120/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00097)	Tok/s 53994 (52729)	Loss/tok 7.7831 (8.9033)	Learning Rate [0.00017254803307536042]
15: TRAIN [0][120/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00097)	Tok/s 54164 (53437)	Loss/tok 7.9178 (8.9078)	Learning Rate [0.00017254803307536042]
12: TRAIN [0][120/3416]	Time 0.054 (0.058)	Data 0.00083 (0.00099)	Tok/s 54262 (53046)	Loss/tok 7.9187 (8.8967)	Learning Rate [0.00017254803307536042]
13: TRAIN [0][120/3416]	Time 0.054 (0.059)	Data 0.00092 (0.00095)	Tok/s 54227 (53160)	Loss/tok 7.9529 (8.9213)	Learning Rate [0.00017254803307536042]
14: TRAIN [0][120/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00098)	Tok/s 54180 (53332)	Loss/tok 7.8428 (8.9123)	Learning Rate [0.00017254803307536042]
0: TRAIN [0][120/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00097)	Tok/s 52690 (52246)	Loss/tok 7.8611 (8.9085)	Learning Rate [0.00017254803307536042]
4: TRAIN [0][130/3416]	Time 0.059 (0.059)	Data 0.00097 (0.00104)	Tok/s 55371 (52522)	Loss/tok 7.8041 (8.8251)	Learning Rate [0.00021722510359367173]
5: TRAIN [0][130/3416]	Time 0.059 (0.059)	Data 0.00104 (0.00097)	Tok/s 55425 (52594)	Loss/tok 7.7970 (8.8349)	Learning Rate [0.00021722510359367173]
8: TRAIN [0][130/3416]	Time 0.059 (0.059)	Data 0.00087 (0.00091)	Tok/s 55294 (52762)	Loss/tok 7.8012 (8.8134)	Learning Rate [0.00021722510359367173]
7: TRAIN [0][130/3416]	Time 0.059 (0.059)	Data 0.00089 (0.00097)	Tok/s 55336 (52692)	Loss/tok 7.8304 (8.8184)	Learning Rate [0.00021722510359367173]
2: TRAIN [0][130/3416]	Time 0.059 (0.059)	Data 0.00102 (0.00097)	Tok/s 55158 (52322)	Loss/tok 7.9110 (8.8311)	Learning Rate [0.00021722510359367173]
3: TRAIN [0][130/3416]	Time 0.059 (0.059)	Data 0.00090 (0.00099)	Tok/s 55187 (52425)	Loss/tok 7.8590 (8.8235)	Learning Rate [0.00021722510359367173]
1: TRAIN [0][130/3416]	Time 0.059 (0.059)	Data 0.00091 (0.00096)	Tok/s 55048 (52256)	Loss/tok 7.8184 (8.8276)	Learning Rate [0.00021722510359367173]
9: TRAIN [0][130/3416]	Time 0.058 (0.059)	Data 0.00096 (0.00096)	Tok/s 55905 (52802)	Loss/tok 7.9467 (8.8198)	Learning Rate [0.00021722510359367173]
6: TRAIN [0][130/3416]	Time 0.059 (0.059)	Data 0.00088 (0.00098)	Tok/s 55360 (52657)	Loss/tok 7.8245 (8.8308)	Learning Rate [0.00021722510359367173]
15: TRAIN [0][130/3416]	Time 0.059 (0.059)	Data 0.00088 (0.00097)	Tok/s 56021 (53381)	Loss/tok 7.8320 (8.8245)	Learning Rate [0.00021722510359367173]
0: TRAIN [0][130/3416]	Time 0.059 (0.059)	Data 0.00093 (0.00097)	Tok/s 54968 (52220)	Loss/tok 7.7976 (8.8246)	Learning Rate [0.00021722510359367173]
10: TRAIN [0][130/3416]	Time 0.059 (0.059)	Data 0.00093 (0.00098)	Tok/s 54994 (52854)	Loss/tok 7.7248 (8.8332)	Learning Rate [0.00021722510359367173]
11: TRAIN [0][130/3416]	Time 0.060 (0.059)	Data 0.00089 (0.00092)	Tok/s 54843 (52897)	Loss/tok 7.7799 (8.8283)	Learning Rate [0.00021722510359367173]
13: TRAIN [0][130/3416]	Time 0.060 (0.059)	Data 0.00093 (0.00095)	Tok/s 55919 (53108)	Loss/tok 7.8551 (8.8368)	Learning Rate [0.00021722510359367173]
12: TRAIN [0][130/3416]	Time 0.060 (0.059)	Data 0.00080 (0.00099)	Tok/s 55605 (53000)	Loss/tok 7.8444 (8.8175)	Learning Rate [0.00021722510359367173]
14: TRAIN [0][130/3416]	Time 0.060 (0.059)	Data 0.00091 (0.00098)	Tok/s 55905 (53271)	Loss/tok 7.9287 (8.8317)	Learning Rate [0.00021722510359367173]
1: TRAIN [0][140/3416]	Time 0.070 (0.059)	Data 0.00104 (0.00096)	Tok/s 74936 (52280)	Loss/tok 7.8330 (8.7516)	Learning Rate [0.00027347020299369384]
2: TRAIN [0][140/3416]	Time 0.070 (0.059)	Data 0.00098 (0.00098)	Tok/s 74625 (52340)	Loss/tok 7.8638 (8.7532)	Learning Rate [0.00027347020299369384]
3: TRAIN [0][140/3416]	Time 0.070 (0.059)	Data 0.00096 (0.00098)	Tok/s 74562 (52440)	Loss/tok 7.7955 (8.7483)	Learning Rate [0.00027347020299369384]
0: TRAIN [0][140/3416]	Time 0.071 (0.059)	Data 0.00092 (0.00096)	Tok/s 74427 (52246)	Loss/tok 7.9726 (8.7520)	Learning Rate [0.00027347020299369384]
6: TRAIN [0][140/3416]	Time 0.071 (0.059)	Data 0.00101 (0.00098)	Tok/s 74375 (52667)	Loss/tok 7.9411 (8.7581)	Learning Rate [0.00027347020299369384]
4: TRAIN [0][140/3416]	Time 0.070 (0.059)	Data 0.00099 (0.00104)	Tok/s 74447 (52540)	Loss/tok 7.8627 (8.7515)	Learning Rate [0.00027347020299369384]
15: TRAIN [0][140/3416]	Time 0.071 (0.059)	Data 0.00094 (0.00097)	Tok/s 75201 (53376)	Loss/tok 7.7954 (8.7503)	Learning Rate [0.00027347020299369384]
5: TRAIN [0][140/3416]	Time 0.071 (0.059)	Data 0.00101 (0.00098)	Tok/s 74328 (52607)	Loss/tok 7.8576 (8.7582)	Learning Rate [0.00027347020299369384]
11: TRAIN [0][140/3416]	Time 0.071 (0.059)	Data 0.00095 (0.00092)	Tok/s 74864 (52898)	Loss/tok 7.9855 (8.7564)	Learning Rate [0.00027347020299369384]
7: TRAIN [0][140/3416]	Time 0.071 (0.059)	Data 0.00091 (0.00097)	Tok/s 74143 (52698)	Loss/tok 7.9416 (8.7451)	Learning Rate [0.00027347020299369384]
13: TRAIN [0][140/3416]	Time 0.071 (0.059)	Data 0.00095 (0.00095)	Tok/s 74971 (53099)	Loss/tok 7.9048 (8.7623)	Learning Rate [0.00027347020299369384]
10: TRAIN [0][140/3416]	Time 0.071 (0.059)	Data 0.00094 (0.00098)	Tok/s 74901 (52856)	Loss/tok 7.8672 (8.7581)	Learning Rate [0.00027347020299369384]
8: TRAIN [0][140/3416]	Time 0.071 (0.059)	Data 0.00091 (0.00091)	Tok/s 74227 (52763)	Loss/tok 7.8084 (8.7378)	Learning Rate [0.00027347020299369384]
12: TRAIN [0][140/3416]	Time 0.071 (0.059)	Data 0.00090 (0.00099)	Tok/s 74812 (52998)	Loss/tok 7.8631 (8.7445)	Learning Rate [0.00027347020299369384]
9: TRAIN [0][140/3416]	Time 0.071 (0.059)	Data 0.00092 (0.00095)	Tok/s 74841 (52806)	Loss/tok 7.8470 (8.7441)	Learning Rate [0.00027347020299369384]
14: TRAIN [0][140/3416]	Time 0.071 (0.059)	Data 0.00094 (0.00098)	Tok/s 74964 (53260)	Loss/tok 7.8239 (8.7583)	Learning Rate [0.00027347020299369384]
4: TRAIN [0][150/3416]	Time 0.069 (0.059)	Data 0.00098 (0.00104)	Tok/s 83610 (53163)	Loss/tok 7.8541 (8.6703)	Learning Rate [0.0003442785879172706]
6: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00108 (0.00099)	Tok/s 83601 (53296)	Loss/tok 7.7442 (8.6765)	Learning Rate [0.0003442785879172706]
3: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00102 (0.00098)	Tok/s 82741 (53052)	Loss/tok 7.6415 (8.6653)	Learning Rate [0.0003442785879172706]
2: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00094 (0.00098)	Tok/s 82732 (52954)	Loss/tok 7.6458 (8.6729)	Learning Rate [0.0003442785879172706]
1: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00094 (0.00096)	Tok/s 82748 (52898)	Loss/tok 7.7021 (8.6721)	Learning Rate [0.0003442785879172706]
7: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00096 (0.00096)	Tok/s 83338 (53328)	Loss/tok 7.8078 (8.6650)	Learning Rate [0.0003442785879172706]
8: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00095 (0.00091)	Tok/s 83411 (53401)	Loss/tok 7.8177 (8.6596)	Learning Rate [0.0003442785879172706]
0: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00087 (0.00096)	Tok/s 82748 (52866)	Loss/tok 7.7234 (8.6676)	Learning Rate [0.0003442785879172706]
9: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00102 (0.00095)	Tok/s 83659 (53447)	Loss/tok 7.7966 (8.6624)	Learning Rate [0.0003442785879172706]
10: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00099 (0.00098)	Tok/s 84325 (53502)	Loss/tok 7.7384 (8.6756)	Learning Rate [0.0003442785879172706]
11: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00090 (0.00092)	Tok/s 84331 (53541)	Loss/tok 7.7656 (8.6785)	Learning Rate [0.0003442785879172706]
15: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00091 (0.00097)	Tok/s 85449 (54012)	Loss/tok 7.7385 (8.6669)	Learning Rate [0.0003442785879172706]
12: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00084 (0.00098)	Tok/s 84389 (53635)	Loss/tok 7.8058 (8.6685)	Learning Rate [0.0003442785879172706]
14: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00088 (0.00098)	Tok/s 84547 (53883)	Loss/tok 7.7958 (8.6792)	Learning Rate [0.0003442785879172706]
13: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00094 (0.00095)	Tok/s 84468 (53729)	Loss/tok 7.7678 (8.6776)	Learning Rate [0.0003442785879172706]
5: TRAIN [0][150/3416]	Time 0.070 (0.059)	Data 0.00090 (0.00098)	Tok/s 83697 (53226)	Loss/tok 7.7762 (8.6769)	Learning Rate [0.0003442785879172706]
3: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00082 (0.00097)	Tok/s 17151 (52623)	Loss/tok 5.6203 (8.6105)	Learning Rate [0.0004334210630656643]
4: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00087 (0.00103)	Tok/s 19165 (52748)	Loss/tok 6.1626 (8.6179)	Learning Rate [0.0004334210630656643]
1: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00101 (0.00096)	Tok/s 12329 (52421)	Loss/tok 6.1117 (8.6184)	Learning Rate [0.0004334210630656643]
0: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00090 (0.00096)	Tok/s 9415 (52358)	Loss/tok 5.2716 (8.6156)	Learning Rate [0.0004334210630656643]
6: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00091 (0.00099)	Tok/s 22167 (52925)	Loss/tok 6.4163 (8.6240)	Learning Rate [0.0004334210630656643]
2: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00091 (0.00098)	Tok/s 15674 (52518)	Loss/tok 6.4012 (8.6210)	Learning Rate [0.0004334210630656643]
7: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00086 (0.00096)	Tok/s 23222 (52975)	Loss/tok 6.0947 (8.6099)	Learning Rate [0.0004334210630656643]
15: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00087 (0.00096)	Tok/s 28217 (53724)	Loss/tok 6.0665 (8.6096)	Learning Rate [0.0004334210630656643]
14: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00113 (0.00098)	Tok/s 27179 (53585)	Loss/tok 6.2247 (8.6201)	Learning Rate [0.0004334210630656643]
8: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00083 (0.00091)	Tok/s 24513 (53066)	Loss/tok 5.3603 (8.6016)	Learning Rate [0.0004334210630656643]
11: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00082 (0.00092)	Tok/s 24676 (53225)	Loss/tok 5.6077 (8.6199)	Learning Rate [0.0004334210630656643]
12: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00088 (0.00098)	Tok/s 26231 (53335)	Loss/tok 6.2195 (8.6108)	Learning Rate [0.0004334210630656643]
9: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00086 (0.00095)	Tok/s 24422 (53123)	Loss/tok 5.5186 (8.6038)	Learning Rate [0.0004334210630656643]
13: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00095 (0.00095)	Tok/s 26223 (53432)	Loss/tok 6.2040 (8.6201)	Learning Rate [0.0004334210630656643]
10: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00100 (0.00098)	Tok/s 24390 (53177)	Loss/tok 5.5694 (8.6175)	Learning Rate [0.0004334210630656643]
5: TRAIN [0][160/3416]	Time 0.034 (0.059)	Data 0.00086 (0.00098)	Tok/s 20910 (52840)	Loss/tok 6.5563 (8.6180)	Learning Rate [0.0004334210630656643]
3: TRAIN [0][170/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00097)	Tok/s 50293 (52396)	Loss/tok 7.4780 (8.5605)	Learning Rate [0.0005456447903002072]
4: TRAIN [0][170/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00103)	Tok/s 50253 (52527)	Loss/tok 7.5033 (8.5663)	Learning Rate [0.0005456447903002072]
2: TRAIN [0][170/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00098)	Tok/s 50230 (52291)	Loss/tok 7.6591 (8.5688)	Learning Rate [0.0005456447903002072]
0: TRAIN [0][170/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 50071 (52140)	Loss/tok 7.4742 (8.5630)	Learning Rate [0.0005456447903002072]
1: TRAIN [0][170/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00095)	Tok/s 50180 (52199)	Loss/tok 7.5288 (8.5654)	Learning Rate [0.0005456447903002072]
6: TRAIN [0][170/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00099)	Tok/s 49967 (52706)	Loss/tok 7.4617 (8.5717)	Learning Rate [0.0005456447903002072]
7: TRAIN [0][170/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00096)	Tok/s 50720 (52758)	Loss/tok 7.4826 (8.5570)	Learning Rate [0.0005456447903002072]
11: TRAIN [0][170/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00091)	Tok/s 50934 (53020)	Loss/tok 7.6801 (8.5688)	Learning Rate [0.0005456447903002072]
8: TRAIN [0][170/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00091)	Tok/s 51016 (52854)	Loss/tok 7.4882 (8.5515)	Learning Rate [0.0005456447903002072]
9: TRAIN [0][170/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00095)	Tok/s 50981 (52912)	Loss/tok 7.4094 (8.5541)	Learning Rate [0.0005456447903002072]
15: TRAIN [0][170/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00096)	Tok/s 51136 (53505)	Loss/tok 7.3774 (8.5571)	Learning Rate [0.0005456447903002072]
12: TRAIN [0][170/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00098)	Tok/s 50927 (53124)	Loss/tok 7.4973 (8.5579)	Learning Rate [0.0005456447903002072]
14: TRAIN [0][170/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00098)	Tok/s 51005 (53371)	Loss/tok 7.5369 (8.5682)	Learning Rate [0.0005456447903002072]
13: TRAIN [0][170/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00095)	Tok/s 50930 (53215)	Loss/tok 7.3969 (8.5679)	Learning Rate [0.0005456447903002072]
5: TRAIN [0][170/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00098)	Tok/s 51681 (52622)	Loss/tok 7.5601 (8.5648)	Learning Rate [0.0005456447903002072]
10: TRAIN [0][170/3416]	Time 0.053 (0.058)	Data 0.00102 (0.00098)	Tok/s 50651 (52969)	Loss/tok 7.3811 (8.5665)	Learning Rate [0.0005456447903002072]
3: Upscaling, new scale: 256.0
2: Upscaling, new scale: 256.0
1: Upscaling, new scale: 256.0
0: Upscaling, new scale: 256.0
6: Upscaling, new scale: 256.0
7: Upscaling, new scale: 256.0
15: Upscaling, new scale: 256.0
8: Upscaling, new scale: 256.0
14: Upscaling, new scale: 256.0
11: Upscaling, new scale: 256.0
13: Upscaling, new scale: 256.0
12: Upscaling, new scale: 256.0
10: Upscaling, new scale: 256.0
5: Upscaling, new scale: 256.0
9: Upscaling, new scale: 256.0
4: Upscaling, new scale: 256.0
8: TRAIN [0][180/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00091)	Tok/s 79296 (52868)	Loss/tok 7.8754 (8.4937)	Learning Rate [0.0006869260923220305]
6: TRAIN [0][180/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00099)	Tok/s 79070 (52714)	Loss/tok 7.7680 (8.5159)	Learning Rate [0.0006869260923220305]
2: TRAIN [0][180/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 79225 (52284)	Loss/tok 7.8711 (8.5126)	Learning Rate [0.0006869260923220305]
13: TRAIN [0][180/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00095)	Tok/s 80518 (53250)	Loss/tok 7.8530 (8.5117)	Learning Rate [0.0006869260923220305]
7: TRAIN [0][180/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00095)	Tok/s 79223 (52770)	Loss/tok 7.8436 (8.5033)	Learning Rate [0.0006869260923220305]
4: TRAIN [0][180/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00103)	Tok/s 79103 (52521)	Loss/tok 7.7633 (8.5093)	Learning Rate [0.0006869260923220305]
3: TRAIN [0][180/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 79132 (52394)	Loss/tok 7.7721 (8.5036)	Learning Rate [0.0006869260923220305]
9: TRAIN [0][180/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00095)	Tok/s 79932 (52931)	Loss/tok 7.9002 (8.4980)	Learning Rate [0.0006869260923220305]
0: TRAIN [0][180/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 78428 (52089)	Loss/tok 7.8423 (8.5110)	Learning Rate [0.0006869260923220305]
1: TRAIN [0][180/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00095)	Tok/s 78647 (52165)	Loss/tok 7.8290 (8.5072)	Learning Rate [0.0006869260923220305]
15: TRAIN [0][180/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00096)	Tok/s 80329 (53539)	Loss/tok 7.7766 (8.4998)	Learning Rate [0.0006869260923220305]
14: TRAIN [0][180/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00098)	Tok/s 81774 (53401)	Loss/tok 7.8684 (8.5124)	Learning Rate [0.0006869260923220305]
10: TRAIN [0][180/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00098)	Tok/s 80330 (52992)	Loss/tok 7.8794 (8.5098)	Learning Rate [0.0006869260923220305]
12: TRAIN [0][180/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 80441 (53150)	Loss/tok 7.7905 (8.4973)	Learning Rate [0.0006869260923220305]
11: TRAIN [0][180/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 80377 (53043)	Loss/tok 7.8401 (8.5111)	Learning Rate [0.0006869260923220305]
5: TRAIN [0][180/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 78981 (52630)	Loss/tok 7.8576 (8.5107)	Learning Rate [0.0006869260923220305]
6: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00099)	Tok/s 53089 (52937)	Loss/tok 7.4012 (8.4572)	Learning Rate [0.0008647887136486704]
7: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00095)	Tok/s 53150 (52999)	Loss/tok 7.3130 (8.4461)	Learning Rate [0.0008647887136486704]
4: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00102)	Tok/s 52897 (52745)	Loss/tok 7.3648 (8.4537)	Learning Rate [0.0008647887136486704]
8: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00091)	Tok/s 53116 (53092)	Loss/tok 7.5448 (8.4369)	Learning Rate [0.0008647887136486704]
9: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00085 (0.00095)	Tok/s 53137 (53154)	Loss/tok 7.5864 (8.4432)	Learning Rate [0.0008647887136486704]
3: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00096)	Tok/s 52852 (52620)	Loss/tok 7.3486 (8.4455)	Learning Rate [0.0008647887136486704]
2: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00099)	Tok/s 52782 (52510)	Loss/tok 7.2757 (8.4570)	Learning Rate [0.0008647887136486704]
11: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00091)	Tok/s 52940 (53272)	Loss/tok 7.2365 (8.4531)	Learning Rate [0.0008647887136486704]
1: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00106 (0.00095)	Tok/s 52672 (52389)	Loss/tok 7.4128 (8.4478)	Learning Rate [0.0008647887136486704]
13: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00095)	Tok/s 52875 (53472)	Loss/tok 7.3622 (8.4537)	Learning Rate [0.0008647887136486704]
15: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00095)	Tok/s 53255 (53750)	Loss/tok 7.5121 (8.4414)	Learning Rate [0.0008647887136486704]
14: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00098)	Tok/s 52811 (53616)	Loss/tok 7.4303 (8.4540)	Learning Rate [0.0008647887136486704]
10: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00103 (0.00098)	Tok/s 52996 (53214)	Loss/tok 7.3791 (8.4530)	Learning Rate [0.0008647887136486704]
0: TRAIN [0][190/3416]	Time 0.054 (0.058)	Data 0.00102 (0.00097)	Tok/s 52635 (52312)	Loss/tok 7.3552 (8.4523)	Learning Rate [0.0008647887136486704]
12: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00098)	Tok/s 52910 (53375)	Loss/tok 7.4199 (8.4424)	Learning Rate [0.0008647887136486704]
5: TRAIN [0][190/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00098)	Tok/s 53071 (52852)	Loss/tok 7.2827 (8.4537)	Learning Rate [0.0008647887136486704]
3: TRAIN [0][200/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00096)	Tok/s 51596 (52771)	Loss/tok 7.2702 (8.3858)	Learning Rate [0.0010887044874451008]
2: TRAIN [0][200/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00099)	Tok/s 51577 (52666)	Loss/tok 7.2105 (8.3953)	Learning Rate [0.0010887044874451008]
6: TRAIN [0][200/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00099)	Tok/s 52701 (53081)	Loss/tok 7.1424 (8.3958)	Learning Rate [0.0010887044874451008]
1: TRAIN [0][200/3416]	Time 0.058 (0.058)	Data 0.00102 (0.00095)	Tok/s 51505 (52551)	Loss/tok 7.3406 (8.3882)	Learning Rate [0.0010887044874451008]
0: TRAIN [0][200/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00097)	Tok/s 51372 (52477)	Loss/tok 7.3052 (8.3919)	Learning Rate [0.0010887044874451008]
4: TRAIN [0][200/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00102)	Tok/s 51654 (52894)	Loss/tok 7.1768 (8.3911)	Learning Rate [0.0010887044874451008]
15: TRAIN [0][200/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00095)	Tok/s 52292 (53872)	Loss/tok 7.1409 (8.3824)	Learning Rate [0.0010887044874451008]
7: TRAIN [0][200/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00095)	Tok/s 52550 (53139)	Loss/tok 7.1829 (8.3865)	Learning Rate [0.0010887044874451008]
8: TRAIN [0][200/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00091)	Tok/s 52433 (53230)	Loss/tok 7.1476 (8.3763)	Learning Rate [0.0010887044874451008]
13: TRAIN [0][200/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00094)	Tok/s 52182 (53604)	Loss/tok 7.2025 (8.3921)	Learning Rate [0.0010887044874451008]
9: TRAIN [0][200/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00095)	Tok/s 52279 (53296)	Loss/tok 7.2658 (8.3804)	Learning Rate [0.0010887044874451008]
5: TRAIN [0][200/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00098)	Tok/s 51869 (52996)	Loss/tok 7.2145 (8.3917)	Learning Rate [0.0010887044874451008]
12: TRAIN [0][200/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00098)	Tok/s 52192 (53511)	Loss/tok 7.3255 (8.3848)	Learning Rate [0.0010887044874451008]
11: TRAIN [0][200/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00091)	Tok/s 52139 (53413)	Loss/tok 7.3043 (8.3918)	Learning Rate [0.0010887044874451008]
10: TRAIN [0][200/3416]	Time 0.059 (0.058)	Data 0.00107 (0.00098)	Tok/s 52160 (53358)	Loss/tok 7.0674 (8.3911)	Learning Rate [0.0010887044874451008]
14: TRAIN [0][200/3416]	Time 0.059 (0.058)	Data 0.00109 (0.00098)	Tok/s 52117 (53741)	Loss/tok 7.1569 (8.3910)	Learning Rate [0.0010887044874451008]
14: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00096 (0.00098)	Tok/s 62190 (53903)	Loss/tok 7.2333 (8.3294)	Learning Rate [0.00125]
15: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00087 (0.00095)	Tok/s 62063 (54026)	Loss/tok 7.2384 (8.3226)	Learning Rate [0.00125]
13: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00086 (0.00094)	Tok/s 62146 (53763)	Loss/tok 7.3137 (8.3278)	Learning Rate [0.00125]
0: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00089 (0.00097)	Tok/s 61033 (52620)	Loss/tok 7.3047 (8.3301)	Learning Rate [0.00125]
1: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00099 (0.00095)	Tok/s 61142 (52690)	Loss/tok 7.1712 (8.3240)	Learning Rate [0.00125]
11: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00085 (0.00091)	Tok/s 62004 (53562)	Loss/tok 7.1721 (8.3275)	Learning Rate [0.00125]
2: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00096 (0.00099)	Tok/s 61772 (52809)	Loss/tok 7.3439 (8.3332)	Learning Rate [0.00125]
12: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00087 (0.00098)	Tok/s 62130 (53668)	Loss/tok 7.2870 (8.3253)	Learning Rate [0.00125]
9: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00088 (0.00095)	Tok/s 61879 (53442)	Loss/tok 7.2315 (8.3191)	Learning Rate [0.00125]
8: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00093 (0.00091)	Tok/s 61869 (53375)	Loss/tok 7.3047 (8.3111)	Learning Rate [0.00125]
10: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00094 (0.00098)	Tok/s 61876 (53502)	Loss/tok 7.1967 (8.3295)	Learning Rate [0.00125]
4: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00086 (0.00102)	Tok/s 61762 (53044)	Loss/tok 7.2478 (8.3287)	Learning Rate [0.00125]
7: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00092 (0.00095)	Tok/s 61817 (53284)	Loss/tok 7.2073 (8.3227)	Learning Rate [0.00125]
3: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00078 (0.00096)	Tok/s 61755 (52920)	Loss/tok 7.3257 (8.3261)	Learning Rate [0.00125]
6: TRAIN [0][210/3416]	Time 0.069 (0.059)	Data 0.00094 (0.00098)	Tok/s 61656 (53223)	Loss/tok 7.2246 (8.3334)	Learning Rate [0.00125]
5: TRAIN [0][210/3416]	Time 0.068 (0.059)	Data 0.00091 (0.00098)	Tok/s 61745 (53142)	Loss/tok 7.2620 (8.3309)	Learning Rate [0.00125]
2: TRAIN [0][220/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 62749 (52517)	Loss/tok 7.0944 (8.2848)	Learning Rate [0.00125]
4: TRAIN [0][220/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00101)	Tok/s 62588 (52754)	Loss/tok 7.1811 (8.2799)	Learning Rate [0.00125]
3: TRAIN [0][220/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00096)	Tok/s 62641 (52633)	Loss/tok 7.0698 (8.2749)	Learning Rate [0.00125]
1: TRAIN [0][220/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00096)	Tok/s 62805 (52389)	Loss/tok 7.0557 (8.2752)	Learning Rate [0.00125]
15: TRAIN [0][220/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00095)	Tok/s 63575 (53764)	Loss/tok 7.1092 (8.2739)	Learning Rate [0.00125]
6: TRAIN [0][220/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 62470 (52942)	Loss/tok 7.1122 (8.2823)	Learning Rate [0.00125]
0: TRAIN [0][220/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 62826 (52308)	Loss/tok 7.1283 (8.2808)	Learning Rate [0.00125]
14: TRAIN [0][220/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00098)	Tok/s 62776 (53639)	Loss/tok 6.9731 (8.2766)	Learning Rate [0.00125]
12: TRAIN [0][220/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00098)	Tok/s 62809 (53393)	Loss/tok 7.0359 (8.2755)	Learning Rate [0.00125]
11: TRAIN [0][220/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 62729 (53282)	Loss/tok 7.1215 (8.2770)	Learning Rate [0.00125]
7: TRAIN [0][220/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00095)	Tok/s 62489 (53004)	Loss/tok 7.1271 (8.2737)	Learning Rate [0.00125]
13: TRAIN [0][220/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00094)	Tok/s 62795 (53497)	Loss/tok 7.3357 (8.2797)	Learning Rate [0.00125]
10: TRAIN [0][220/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00099)	Tok/s 62628 (53221)	Loss/tok 6.9662 (8.2782)	Learning Rate [0.00125]
9: TRAIN [0][220/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00094)	Tok/s 62539 (53163)	Loss/tok 7.0206 (8.2680)	Learning Rate [0.00125]
5: TRAIN [0][220/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 62481 (52859)	Loss/tok 7.0240 (8.2817)	Learning Rate [0.00125]
8: TRAIN [0][220/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 62341 (53095)	Loss/tok 7.0092 (8.2609)	Learning Rate [0.00125]
4: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00101)	Tok/s 52974 (52810)	Loss/tok 6.9269 (8.2225)	Learning Rate [0.00125]
3: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00079 (0.00095)	Tok/s 52694 (52693)	Loss/tok 6.6873 (8.2173)	Learning Rate [0.00125]
2: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00099)	Tok/s 51861 (52577)	Loss/tok 6.7075 (8.2258)	Learning Rate [0.00125]
6: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00098)	Tok/s 52756 (52995)	Loss/tok 6.8530 (8.2211)	Learning Rate [0.00125]
1: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00095)	Tok/s 51843 (52452)	Loss/tok 7.0530 (8.2179)	Learning Rate [0.00125]
7: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00094)	Tok/s 52669 (53058)	Loss/tok 6.8132 (8.2154)	Learning Rate [0.00125]
8: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00091)	Tok/s 52531 (53149)	Loss/tok 6.7329 (8.2027)	Learning Rate [0.00125]
0: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00096)	Tok/s 51695 (52374)	Loss/tok 7.0080 (8.2230)	Learning Rate [0.00125]
9: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00094)	Tok/s 52559 (53215)	Loss/tok 7.0126 (8.2117)	Learning Rate [0.00125]
10: TRAIN [0][230/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00099)	Tok/s 52513 (53269)	Loss/tok 6.8348 (8.2210)	Learning Rate [0.00125]
13: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00094)	Tok/s 52542 (53544)	Loss/tok 6.9399 (8.2225)	Learning Rate [0.00125]
5: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00097)	Tok/s 52864 (52912)	Loss/tok 7.0088 (8.2259)	Learning Rate [0.00125]
11: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00074 (0.00091)	Tok/s 52523 (53330)	Loss/tok 6.8464 (8.2181)	Learning Rate [0.00125]
12: TRAIN [0][230/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00098)	Tok/s 52453 (53445)	Loss/tok 6.8307 (8.2164)	Learning Rate [0.00125]
15: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00095)	Tok/s 52709 (53814)	Loss/tok 6.7612 (8.2146)	Learning Rate [0.00125]
14: TRAIN [0][230/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00098)	Tok/s 52628 (53688)	Loss/tok 6.7505 (8.2171)	Learning Rate [0.00125]
15: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00095)	Tok/s 52426 (53684)	Loss/tok 6.4643 (8.1605)	Learning Rate [0.00125]
14: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00107 (0.00098)	Tok/s 52426 (53565)	Loss/tok 6.7697 (8.1607)	Learning Rate [0.00125]
0: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00096)	Tok/s 50979 (52254)	Loss/tok 6.7012 (8.1669)	Learning Rate [0.00125]
1: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00095)	Tok/s 50828 (52328)	Loss/tok 6.7130 (8.1626)	Learning Rate [0.00125]
13: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00094)	Tok/s 52410 (53422)	Loss/tok 6.3427 (8.1655)	Learning Rate [0.00125]
2: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00099)	Tok/s 50693 (52451)	Loss/tok 6.7065 (8.1696)	Learning Rate [0.00125]
12: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00098)	Tok/s 52389 (53324)	Loss/tok 6.4139 (8.1605)	Learning Rate [0.00125]
3: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00095)	Tok/s 50761 (52565)	Loss/tok 6.7296 (8.1641)	Learning Rate [0.00125]
11: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00091)	Tok/s 52416 (53212)	Loss/tok 6.7730 (8.1639)	Learning Rate [0.00125]
10: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00111 (0.00099)	Tok/s 52434 (53147)	Loss/tok 6.6469 (8.1666)	Learning Rate [0.00125]
4: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00101)	Tok/s 50759 (52685)	Loss/tok 6.6486 (8.1682)	Learning Rate [0.00125]
9: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00094)	Tok/s 52277 (53090)	Loss/tok 6.8156 (8.1560)	Learning Rate [0.00125]
5: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00101 (0.00098)	Tok/s 50804 (52791)	Loss/tok 6.5097 (8.1697)	Learning Rate [0.00125]
8: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00092)	Tok/s 52271 (53027)	Loss/tok 6.6535 (8.1484)	Learning Rate [0.00125]
6: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00098)	Tok/s 50731 (52870)	Loss/tok 6.7028 (8.1651)	Learning Rate [0.00125]
7: TRAIN [0][240/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00095)	Tok/s 51669 (52938)	Loss/tok 6.6032 (8.1598)	Learning Rate [0.00125]
5: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00098)	Tok/s 33031 (52906)	Loss/tok 6.1163 (8.1089)	Learning Rate [0.00125]
6: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00098)	Tok/s 32960 (52984)	Loss/tok 6.0732 (8.1005)	Learning Rate [0.00125]
4: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00100)	Tok/s 32986 (52803)	Loss/tok 6.3835 (8.1043)	Learning Rate [0.00125]
3: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00080 (0.00095)	Tok/s 33037 (52680)	Loss/tok 6.1914 (8.1023)	Learning Rate [0.00125]
2: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00099)	Tok/s 33077 (52569)	Loss/tok 6.2700 (8.1043)	Learning Rate [0.00125]
7: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00095)	Tok/s 32934 (53051)	Loss/tok 6.2442 (8.0972)	Learning Rate [0.00125]
8: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00091)	Tok/s 32940 (53136)	Loss/tok 6.1434 (8.0874)	Learning Rate [0.00125]
1: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00095)	Tok/s 33003 (52450)	Loss/tok 6.0465 (8.0974)	Learning Rate [0.00125]
9: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00094)	Tok/s 32986 (53197)	Loss/tok 6.1292 (8.0961)	Learning Rate [0.00125]
0: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00096)	Tok/s 33034 (52378)	Loss/tok 6.2418 (8.1049)	Learning Rate [0.00125]
10: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00098)	Tok/s 32968 (53257)	Loss/tok 6.3510 (8.1037)	Learning Rate [0.00125]
11: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00091)	Tok/s 32986 (53323)	Loss/tok 6.2852 (8.1023)	Learning Rate [0.00125]
15: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00095)	Tok/s 34038 (53799)	Loss/tok 6.0967 (8.0996)	Learning Rate [0.00125]
14: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00098)	Tok/s 33109 (53675)	Loss/tok 6.2402 (8.0980)	Learning Rate [0.00125]
13: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00094)	Tok/s 33001 (53534)	Loss/tok 6.2402 (8.1019)	Learning Rate [0.00125]
12: TRAIN [0][250/3416]	Time 0.052 (0.058)	Data 0.00082 (0.00097)	Tok/s 32973 (53438)	Loss/tok 6.3523 (8.0982)	Learning Rate [0.00125]
8: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 61184 (53071)	Loss/tok 6.7846 (8.0317)	Learning Rate [0.00125]
9: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 61110 (53132)	Loss/tok 6.7606 (8.0398)	Learning Rate [0.00125]
14: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00099)	Tok/s 61024 (53605)	Loss/tok 6.6670 (8.0412)	Learning Rate [0.00125]
15: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00095)	Tok/s 61638 (53727)	Loss/tok 6.6183 (8.0441)	Learning Rate [0.00125]
13: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00094)	Tok/s 61000 (53469)	Loss/tok 6.7252 (8.0448)	Learning Rate [0.00125]
7: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00095)	Tok/s 61170 (52990)	Loss/tok 6.7751 (8.0400)	Learning Rate [0.00125]
6: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00098)	Tok/s 61495 (52925)	Loss/tok 6.5362 (8.0421)	Learning Rate [0.00125]
0: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 60981 (52319)	Loss/tok 6.7099 (8.0492)	Learning Rate [0.00125]
10: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 60997 (53192)	Loss/tok 6.5856 (8.0468)	Learning Rate [0.00125]
11: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00091)	Tok/s 60952 (53257)	Loss/tok 6.6596 (8.0452)	Learning Rate [0.00125]
12: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 61016 (53371)	Loss/tok 6.6202 (8.0421)	Learning Rate [0.00125]
5: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 61149 (52850)	Loss/tok 6.8427 (8.0529)	Learning Rate [0.00125]
1: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00121 (0.00095)	Tok/s 60994 (52392)	Loss/tok 6.8361 (8.0414)	Learning Rate [0.00125]
4: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 61112 (52747)	Loss/tok 6.7087 (8.0467)	Learning Rate [0.00125]
3: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00095)	Tok/s 61005 (52622)	Loss/tok 6.7896 (8.0474)	Learning Rate [0.00125]
2: TRAIN [0][260/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00099)	Tok/s 60991 (52510)	Loss/tok 6.3063 (8.0472)	Learning Rate [0.00125]
3: TRAIN [0][270/3416]	Time 0.061 (0.058)	Data 0.00108 (0.00095)	Tok/s 54132 (52809)	Loss/tok 6.3378 (7.9806)	Learning Rate [0.00125]
4: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00100)	Tok/s 54100 (52941)	Loss/tok 6.5381 (7.9819)	Learning Rate [0.00125]
2: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00099)	Tok/s 54046 (52690)	Loss/tok 6.6056 (7.9827)	Learning Rate [0.00125]
1: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00108 (0.00095)	Tok/s 53850 (52560)	Loss/tok 6.4042 (7.9770)	Learning Rate [0.00125]
6: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00097)	Tok/s 53874 (53129)	Loss/tok 6.6656 (7.9754)	Learning Rate [0.00125]
0: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00096)	Tok/s 52823 (52476)	Loss/tok 6.4610 (7.9862)	Learning Rate [0.00125]
5: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00109 (0.00098)	Tok/s 54025 (53050)	Loss/tok 6.5401 (7.9844)	Learning Rate [0.00125]
15: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00096)	Tok/s 53763 (53950)	Loss/tok 6.5205 (7.9785)	Learning Rate [0.00125]
7: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00095)	Tok/s 53811 (53197)	Loss/tok 6.5849 (7.9732)	Learning Rate [0.00125]
8: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00092)	Tok/s 53721 (53283)	Loss/tok 6.4775 (7.9674)	Learning Rate [0.00125]
14: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00115 (0.00098)	Tok/s 53689 (53822)	Loss/tok 6.6207 (7.9759)	Learning Rate [0.00125]
13: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00094)	Tok/s 53548 (53686)	Loss/tok 6.6070 (7.9775)	Learning Rate [0.00125]
10: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00112 (0.00098)	Tok/s 53552 (53403)	Loss/tok 6.4675 (7.9820)	Learning Rate [0.00125]
12: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00097)	Tok/s 53463 (53587)	Loss/tok 6.3748 (7.9766)	Learning Rate [0.00125]
11: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00091)	Tok/s 53424 (53467)	Loss/tok 6.6840 (7.9781)	Learning Rate [0.00125]
9: TRAIN [0][270/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00094)	Tok/s 53621 (53342)	Loss/tok 6.5501 (7.9749)	Learning Rate [0.00125]
12: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00115 (0.00097)	Tok/s 74793 (53524)	Loss/tok 6.5122 (7.9226)	Learning Rate [0.00125]
13: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00094)	Tok/s 74670 (53623)	Loss/tok 6.4820 (7.9213)	Learning Rate [0.00125]
11: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00091)	Tok/s 74753 (53404)	Loss/tok 6.3597 (7.9215)	Learning Rate [0.00125]
10: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00102 (0.00098)	Tok/s 74152 (53335)	Loss/tok 6.4498 (7.9255)	Learning Rate [0.00125]
14: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00099 (0.00098)	Tok/s 74514 (53761)	Loss/tok 6.5083 (7.9209)	Learning Rate [0.00125]
9: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00088 (0.00094)	Tok/s 73838 (53276)	Loss/tok 6.5779 (7.9213)	Learning Rate [0.00125]
15: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00088 (0.00096)	Tok/s 74388 (53886)	Loss/tok 6.4912 (7.9231)	Learning Rate [0.00125]
0: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00096)	Tok/s 72616 (52398)	Loss/tok 6.6371 (7.9319)	Learning Rate [0.00125]
1: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00095)	Tok/s 72949 (52480)	Loss/tok 6.5451 (7.9234)	Learning Rate [0.00125]
7: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00095)	Tok/s 73868 (53127)	Loss/tok 6.5810 (7.9179)	Learning Rate [0.00125]
8: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00116 (0.00092)	Tok/s 73984 (53219)	Loss/tok 6.4414 (7.9124)	Learning Rate [0.00125]
2: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00099)	Tok/s 73537 (52611)	Loss/tok 6.4060 (7.9273)	Learning Rate [0.00125]
6: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00097)	Tok/s 73772 (53058)	Loss/tok 6.4867 (7.9198)	Learning Rate [0.00125]
3: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00095)	Tok/s 73526 (52737)	Loss/tok 6.5092 (7.9279)	Learning Rate [0.00125]
4: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00100)	Tok/s 73559 (52871)	Loss/tok 6.3734 (7.9248)	Learning Rate [0.00125]
5: TRAIN [0][280/3416]	Time 0.071 (0.058)	Data 0.00101 (0.00097)	Tok/s 73577 (52979)	Loss/tok 6.4596 (7.9301)	Learning Rate [0.00125]
0: TRAIN [0][290/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00096)	Tok/s 53872 (52336)	Loss/tok 6.3545 (7.8810)	Learning Rate [0.00125]
1: TRAIN [0][290/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00095)	Tok/s 53764 (52419)	Loss/tok 6.2217 (7.8724)	Learning Rate [0.00125]
2: TRAIN [0][290/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00099)	Tok/s 53669 (52546)	Loss/tok 6.3597 (7.8767)	Learning Rate [0.00125]
15: TRAIN [0][290/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00095)	Tok/s 53870 (53814)	Loss/tok 6.3754 (7.8718)	Learning Rate [0.00125]
14: TRAIN [0][290/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00098)	Tok/s 53853 (53690)	Loss/tok 6.2350 (7.8719)	Learning Rate [0.00125]
3: TRAIN [0][290/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00095)	Tok/s 53575 (52671)	Loss/tok 6.3596 (7.8784)	Learning Rate [0.00125]
13: TRAIN [0][290/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00094)	Tok/s 53833 (53553)	Loss/tok 6.2407 (7.8714)	Learning Rate [0.00125]
4: TRAIN [0][290/3416]	Time 0.060 (0.058)	Data 0.00104 (0.00099)	Tok/s 53482 (52803)	Loss/tok 6.1687 (7.8735)	Learning Rate [0.00125]
12: TRAIN [0][290/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00097)	Tok/s 53840 (53455)	Loss/tok 6.4537 (7.8716)	Learning Rate [0.00125]
11: TRAIN [0][290/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00091)	Tok/s 53796 (53338)	Loss/tok 6.3858 (7.8711)	Learning Rate [0.00125]
6: TRAIN [0][290/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00097)	Tok/s 53545 (52987)	Loss/tok 6.1168 (7.8684)	Learning Rate [0.00125]
10: TRAIN [0][290/3416]	Time 0.060 (0.058)	Data 0.00106 (0.00098)	Tok/s 53776 (53272)	Loss/tok 6.3136 (7.8736)	Learning Rate [0.00125]
5: TRAIN [0][290/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00097)	Tok/s 53496 (52910)	Loss/tok 6.4883 (7.8791)	Learning Rate [0.00125]
7: TRAIN [0][290/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00095)	Tok/s 53487 (53055)	Loss/tok 6.2460 (7.8670)	Learning Rate [0.00125]
8: TRAIN [0][290/3416]	Time 0.060 (0.058)	Data 0.00103 (0.00092)	Tok/s 53556 (53151)	Loss/tok 6.4418 (7.8625)	Learning Rate [0.00125]
9: TRAIN [0][290/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00095)	Tok/s 53593 (53212)	Loss/tok 6.4368 (7.8709)	Learning Rate [0.00125]
15: Upscaling, new scale: 512.0
0: Upscaling, new scale: 512.0
1: Upscaling, new scale: 512.0
14: Upscaling, new scale: 512.0
13: Upscaling, new scale: 512.0
12: Upscaling, new scale: 512.0
2: Upscaling, new scale: 512.0
15: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00080 (0.00095)	Tok/s 52145 (53546)	Loss/tok 6.2256 (7.8252)	Learning Rate [0.00125]
0: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00082 (0.00096)	Tok/s 51114 (52092)	Loss/tok 6.2816 (7.8338)	Learning Rate [0.00125]
1: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00095)	Tok/s 51161 (52174)	Loss/tok 6.3520 (7.8240)	Learning Rate [0.00125]
14: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00098)	Tok/s 52078 (53422)	Loss/tok 5.9759 (7.8243)	Learning Rate [0.00125]
11: Upscaling, new scale: 512.0
3: Upscaling, new scale: 512.0
13: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00094)	Tok/s 51990 (53285)	Loss/tok 6.2728 (7.8235)	Learning Rate [0.00125]
4: Upscaling, new scale: 512.0
9: Upscaling, new scale: 512.0
2: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00099)	Tok/s 51124 (52299)	Loss/tok 6.3074 (7.8294)	Learning Rate [0.00125]
12: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00082 (0.00097)	Tok/s 51841 (53190)	Loss/tok 6.2346 (7.8259)	Learning Rate [0.00125]
10: Upscaling, new scale: 512.0
8: Upscaling, new scale: 512.0
6: Upscaling, new scale: 512.0
5: Upscaling, new scale: 512.0
7: Upscaling, new scale: 512.0
3: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00095)	Tok/s 51115 (52424)	Loss/tok 6.1839 (7.8308)	Learning Rate [0.00125]
4: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00099)	Tok/s 51186 (52553)	Loss/tok 6.0188 (7.8245)	Learning Rate [0.00125]
9: TRAIN [0][300/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00095)	Tok/s 52539 (52952)	Loss/tok 6.2096 (7.8236)	Learning Rate [0.00125]
11: TRAIN [0][300/3416]	Time 0.062 (0.058)	Data 0.00118 (0.00091)	Tok/s 52477 (53073)	Loss/tok 6.4774 (7.8262)	Learning Rate [0.00125]
10: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00098)	Tok/s 51834 (53010)	Loss/tok 6.2999 (7.8269)	Learning Rate [0.00125]
8: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00091)	Tok/s 51842 (52893)	Loss/tok 6.2923 (7.8165)	Learning Rate [0.00125]
5: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00097)	Tok/s 51985 (52660)	Loss/tok 6.4542 (7.8324)	Learning Rate [0.00125]
6: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00097)	Tok/s 51912 (52734)	Loss/tok 6.2143 (7.8231)	Learning Rate [0.00125]
7: TRAIN [0][300/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00095)	Tok/s 51834 (52800)	Loss/tok 6.2324 (7.8187)	Learning Rate [0.00125]
13: TRAIN [0][310/3416]	Time 0.057 (0.058)	Data 0.00084 (0.00094)	Tok/s 51242 (53075)	Loss/tok 5.8296 (7.7769)	Learning Rate [0.00125]
12: TRAIN [0][310/3416]	Time 0.057 (0.058)	Data 0.00086 (0.00097)	Tok/s 51242 (52976)	Loss/tok 6.1234 (7.7801)	Learning Rate [0.00125]
15: TRAIN [0][310/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00095)	Tok/s 52140 (53340)	Loss/tok 6.2780 (7.7799)	Learning Rate [0.00125]
0: TRAIN [0][310/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00097)	Tok/s 50870 (51898)	Loss/tok 6.0142 (7.7883)	Learning Rate [0.00125]
10: TRAIN [0][310/3416]	Time 0.057 (0.058)	Data 0.00086 (0.00098)	Tok/s 51222 (52792)	Loss/tok 6.1133 (7.7826)	Learning Rate [0.00125]
9: TRAIN [0][310/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00095)	Tok/s 51181 (52735)	Loss/tok 5.9803 (7.7779)	Learning Rate [0.00125]
1: TRAIN [0][310/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00095)	Tok/s 50833 (51978)	Loss/tok 6.2210 (7.7793)	Learning Rate [0.00125]
14: TRAIN [0][310/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00098)	Tok/s 51801 (53216)	Loss/tok 6.1720 (7.7787)	Learning Rate [0.00125]
11: TRAIN [0][310/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00091)	Tok/s 51186 (52856)	Loss/tok 6.1319 (7.7795)	Learning Rate [0.00125]
8: TRAIN [0][310/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00091)	Tok/s 51082 (52678)	Loss/tok 6.0876 (7.7712)	Learning Rate [0.00125]
2: TRAIN [0][310/3416]	Time 0.058 (0.058)	Data 0.00103 (0.00099)	Tok/s 50741 (52099)	Loss/tok 6.0683 (7.7836)	Learning Rate [0.00125]
7: TRAIN [0][310/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00095)	Tok/s 50970 (52589)	Loss/tok 6.1477 (7.7721)	Learning Rate [0.00125]
4: TRAIN [0][310/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00099)	Tok/s 50700 (52350)	Loss/tok 6.0375 (7.7787)	Learning Rate [0.00125]
3: TRAIN [0][310/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00095)	Tok/s 50688 (52224)	Loss/tok 6.0620 (7.7862)	Learning Rate [0.00125]
5: TRAIN [0][310/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00097)	Tok/s 50833 (52453)	Loss/tok 6.2603 (7.7881)	Learning Rate [0.00125]
6: TRAIN [0][310/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00097)	Tok/s 50778 (52525)	Loss/tok 6.0857 (7.7771)	Learning Rate [0.00125]
15: Gradient norm: inf
14: Gradient norm: inf
15: Skipped batch, new scale: 256.0
0: Gradient norm: inf
14: Skipped batch, new scale: 256.0
0: Skipped batch, new scale: 256.0
1: Gradient norm: inf
12: Gradient norm: inf
1: Skipped batch, new scale: 256.0
2: Gradient norm: inf
15: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00084 (0.00095)	Tok/s 56617 (53298)	Loss/tok 6.1808 (7.7265)	Learning Rate [0.00125]
12: Skipped batch, new scale: 256.0
11: Gradient norm: inf
13: Gradient norm: inf
3: Gradient norm: inf
2: Skipped batch, new scale: 256.0
14: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00098)	Tok/s 56598 (53173)	Loss/tok 6.4515 (7.7278)	Learning Rate [0.00125]
11: Skipped batch, new scale: 256.0
10: Gradient norm: inf
0: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00097)	Tok/s 55535 (51863)	Loss/tok 6.4793 (7.7350)	Learning Rate [0.00125]
13: Skipped batch, new scale: 256.0
3: Skipped batch, new scale: 256.0
9: Gradient norm: inf
4: Gradient norm: inf
10: Skipped batch, new scale: 256.0
1: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00095)	Tok/s 55417 (51940)	Loss/tok 6.6112 (7.7274)	Learning Rate [0.00125]
12: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00097)	Tok/s 56362 (52933)	Loss/tok 6.4034 (7.7281)	Learning Rate [0.00125]
9: Skipped batch, new scale: 256.0
5: Gradient norm: inf
4: Skipped batch, new scale: 256.0
8: Gradient norm: inf
2: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00099)	Tok/s 55306 (52058)	Loss/tok 6.1823 (7.7290)	Learning Rate [0.00125]
7: Gradient norm: inf
11: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00091)	Tok/s 55321 (52814)	Loss/tok 6.4241 (7.7271)	Learning Rate [0.00125]
5: Skipped batch, new scale: 256.0
13: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00094)	Tok/s 56405 (53028)	Loss/tok 6.3788 (7.7252)	Learning Rate [0.00125]
8: Skipped batch, new scale: 256.0
3: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00095)	Tok/s 55280 (52188)	Loss/tok 6.2865 (7.7363)	Learning Rate [0.00125]
6: Gradient norm: inf
10: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00098)	Tok/s 55250 (52752)	Loss/tok 6.3946 (7.7310)	Learning Rate [0.00125]
7: Skipped batch, new scale: 256.0
4: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00099)	Tok/s 55186 (52313)	Loss/tok 6.3478 (7.7278)	Learning Rate [0.00125]
9: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00084 (0.00095)	Tok/s 55111 (52696)	Loss/tok 6.3310 (7.7253)	Learning Rate [0.00125]
6: Skipped batch, new scale: 256.0
8: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00091)	Tok/s 55011 (52640)	Loss/tok 6.2040 (7.7214)	Learning Rate [0.00125]
5: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00097)	Tok/s 55101 (52413)	Loss/tok 6.3137 (7.7366)	Learning Rate [0.00125]
7: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00095)	Tok/s 54894 (52549)	Loss/tok 6.3550 (7.7223)	Learning Rate [0.00125]
6: TRAIN [0][320/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00097)	Tok/s 54926 (52482)	Loss/tok 6.2086 (7.7276)	Learning Rate [0.00125]
11: TRAIN [0][330/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00092)	Tok/s 51476 (53039)	Loss/tok 6.0006 (7.6713)	Learning Rate [0.00125]
9: TRAIN [0][330/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00095)	Tok/s 51546 (52922)	Loss/tok 5.7954 (7.6719)	Learning Rate [0.00125]
12: TRAIN [0][330/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00097)	Tok/s 51412 (53156)	Loss/tok 5.7813 (7.6744)	Learning Rate [0.00125]
10: TRAIN [0][330/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00098)	Tok/s 51543 (52978)	Loss/tok 5.6057 (7.6747)	Learning Rate [0.00125]
8: TRAIN [0][330/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00091)	Tok/s 51611 (52866)	Loss/tok 5.7118 (7.6641)	Learning Rate [0.00125]
13: TRAIN [0][330/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00094)	Tok/s 51304 (53250)	Loss/tok 5.8910 (7.6695)	Learning Rate [0.00125]
14: TRAIN [0][330/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00098)	Tok/s 51199 (53391)	Loss/tok 5.6115 (7.6742)	Learning Rate [0.00125]
7: TRAIN [0][330/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00095)	Tok/s 51200 (52771)	Loss/tok 5.9901 (7.6672)	Learning Rate [0.00125]
15: TRAIN [0][330/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00095)	Tok/s 51071 (53521)	Loss/tok 5.8060 (7.6707)	Learning Rate [0.00125]
0: TRAIN [0][330/3416]	Time 0.048 (0.058)	Data 0.00111 (0.00097)	Tok/s 49605 (52087)	Loss/tok 5.8494 (7.6800)	Learning Rate [0.00125]
1: TRAIN [0][330/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00095)	Tok/s 49625 (52162)	Loss/tok 5.6936 (7.6727)	Learning Rate [0.00125]
5: TRAIN [0][330/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00097)	Tok/s 49913 (52631)	Loss/tok 5.8138 (7.6847)	Learning Rate [0.00125]
4: TRAIN [0][330/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00099)	Tok/s 49824 (52528)	Loss/tok 5.9250 (7.6741)	Learning Rate [0.00125]
6: TRAIN [0][330/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00097)	Tok/s 50019 (52701)	Loss/tok 5.8597 (7.6750)	Learning Rate [0.00125]
2: TRAIN [0][330/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00099)	Tok/s 49636 (52277)	Loss/tok 5.8106 (7.6730)	Learning Rate [0.00125]
3: TRAIN [0][330/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00095)	Tok/s 49652 (52405)	Loss/tok 5.8933 (7.6788)	Learning Rate [0.00125]
15: TRAIN [0][340/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00095)	Tok/s 52244 (53572)	Loss/tok 5.6790 (7.6183)	Learning Rate [0.00125]
14: TRAIN [0][340/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00098)	Tok/s 52105 (53442)	Loss/tok 5.9892 (7.6240)	Learning Rate [0.00125]
0: TRAIN [0][340/3416]	Time 0.055 (0.058)	Data 0.00112 (0.00097)	Tok/s 51906 (52146)	Loss/tok 5.7506 (7.6284)	Learning Rate [0.00125]
1: TRAIN [0][340/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00095)	Tok/s 52163 (52220)	Loss/tok 5.8618 (7.6201)	Learning Rate [0.00125]
13: TRAIN [0][340/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00094)	Tok/s 52029 (53305)	Loss/tok 6.0375 (7.6177)	Learning Rate [0.00125]
2: TRAIN [0][340/3416]	Time 0.055 (0.058)	Data 0.00110 (0.00099)	Tok/s 52065 (52334)	Loss/tok 5.8633 (7.6203)	Learning Rate [0.00125]
4: TRAIN [0][340/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00099)	Tok/s 51819 (52582)	Loss/tok 5.8571 (7.6214)	Learning Rate [0.00125]
11: TRAIN [0][340/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00091)	Tok/s 51769 (53092)	Loss/tok 5.6267 (7.6175)	Learning Rate [0.00125]
10: TRAIN [0][340/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00098)	Tok/s 51763 (53031)	Loss/tok 5.9478 (7.6216)	Learning Rate [0.00125]
9: TRAIN [0][340/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00095)	Tok/s 51685 (52973)	Loss/tok 6.0457 (7.6223)	Learning Rate [0.00125]
12: TRAIN [0][340/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00097)	Tok/s 51795 (53212)	Loss/tok 5.8529 (7.6221)	Learning Rate [0.00125]
8: TRAIN [0][340/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00091)	Tok/s 51740 (52917)	Loss/tok 5.8472 (7.6128)	Learning Rate [0.00125]
3: TRAIN [0][340/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00095)	Tok/s 51932 (52459)	Loss/tok 5.9885 (7.6285)	Learning Rate [0.00125]
5: TRAIN [0][340/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00097)	Tok/s 51811 (52684)	Loss/tok 5.6871 (7.6328)	Learning Rate [0.00125]
7: TRAIN [0][340/3416]	Time 0.056 (0.058)	Data 0.00118 (0.00096)	Tok/s 51609 (52821)	Loss/tok 5.9553 (7.6165)	Learning Rate [0.00125]
6: TRAIN [0][340/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00097)	Tok/s 51533 (52753)	Loss/tok 5.9304 (7.6235)	Learning Rate [0.00125]
6: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00096)	Tok/s 53402 (52592)	Loss/tok 5.8996 (7.5813)	Learning Rate [0.00125]
5: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00097)	Tok/s 53469 (52525)	Loss/tok 5.9303 (7.5914)	Learning Rate [0.00125]
4: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00099)	Tok/s 53474 (52425)	Loss/tok 5.6511 (7.5787)	Learning Rate [0.00125]
3: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00095)	Tok/s 53457 (52306)	Loss/tok 5.7917 (7.5870)	Learning Rate [0.00125]
7: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00096)	Tok/s 53363 (52658)	Loss/tok 5.9030 (7.5755)	Learning Rate [0.00125]
2: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00106 (0.00099)	Tok/s 53225 (52183)	Loss/tok 5.7119 (7.5763)	Learning Rate [0.00125]
8: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00091)	Tok/s 53374 (52751)	Loss/tok 5.7917 (7.5703)	Learning Rate [0.00125]
1: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00095)	Tok/s 52230 (52069)	Loss/tok 5.6734 (7.5778)	Learning Rate [0.00125]
9: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00095)	Tok/s 53362 (52808)	Loss/tok 5.6995 (7.5808)	Learning Rate [0.00125]
0: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 52168 (51996)	Loss/tok 5.9372 (7.5863)	Learning Rate [0.00125]
10: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00098)	Tok/s 53391 (52869)	Loss/tok 5.8728 (7.5803)	Learning Rate [0.00125]
15: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00095)	Tok/s 53514 (53414)	Loss/tok 5.9054 (7.5770)	Learning Rate [0.00125]
11: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00091)	Tok/s 53324 (52929)	Loss/tok 5.8324 (7.5747)	Learning Rate [0.00125]
14: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00098)	Tok/s 53474 (53285)	Loss/tok 5.9019 (7.5828)	Learning Rate [0.00125]
12: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00096)	Tok/s 53407 (53053)	Loss/tok 5.6843 (7.5795)	Learning Rate [0.00125]
13: TRAIN [0][350/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00094)	Tok/s 53472 (53149)	Loss/tok 5.7305 (7.5767)	Learning Rate [0.00125]
14: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00098)	Tok/s 55469 (53355)	Loss/tok 5.9651 (7.5345)	Learning Rate [0.00125]
12: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00096)	Tok/s 55419 (53128)	Loss/tok 5.8661 (7.5317)	Learning Rate [0.00125]
13: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00094)	Tok/s 55487 (53222)	Loss/tok 5.7606 (7.5287)	Learning Rate [0.00125]
15: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00095)	Tok/s 55237 (53484)	Loss/tok 5.8834 (7.5276)	Learning Rate [0.00125]
11: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00091)	Tok/s 55483 (53005)	Loss/tok 5.8498 (7.5240)	Learning Rate [0.00125]
10: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00098)	Tok/s 55208 (52943)	Loss/tok 5.8425 (7.5307)	Learning Rate [0.00125]
2: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00116 (0.00099)	Tok/s 53959 (52270)	Loss/tok 5.9404 (7.5265)	Learning Rate [0.00125]
0: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00097)	Tok/s 54160 (52086)	Loss/tok 5.6994 (7.5390)	Learning Rate [0.00125]
9: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00094)	Tok/s 54320 (52880)	Loss/tok 6.0116 (7.5321)	Learning Rate [0.00125]
8: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00091)	Tok/s 54227 (52824)	Loss/tok 5.7681 (7.5223)	Learning Rate [0.00125]
7: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00096)	Tok/s 54193 (52731)	Loss/tok 5.8476 (7.5269)	Learning Rate [0.00125]
3: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00110 (0.00095)	Tok/s 53948 (52389)	Loss/tok 5.8233 (7.5383)	Learning Rate [0.00125]
1: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00095)	Tok/s 54027 (52159)	Loss/tok 5.8946 (7.5294)	Learning Rate [0.00125]
6: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00096)	Tok/s 53967 (52667)	Loss/tok 6.0639 (7.5317)	Learning Rate [0.00125]
5: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00096)	Tok/s 54002 (52602)	Loss/tok 5.6592 (7.5412)	Learning Rate [0.00125]
4: TRAIN [0][360/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00099)	Tok/s 53916 (52505)	Loss/tok 5.7423 (7.5272)	Learning Rate [0.00125]
1: TRAIN [0][370/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00095)	Tok/s 50881 (52416)	Loss/tok 5.6610 (7.4714)	Learning Rate [0.00125]
0: TRAIN [0][370/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00097)	Tok/s 51018 (52344)	Loss/tok 5.8664 (7.4836)	Learning Rate [0.00125]
2: TRAIN [0][370/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00099)	Tok/s 50785 (52526)	Loss/tok 5.4315 (7.4701)	Learning Rate [0.00125]
13: TRAIN [0][370/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00094)	Tok/s 50927 (53467)	Loss/tok 5.5832 (7.4727)	Learning Rate [0.00125]
14: TRAIN [0][370/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00098)	Tok/s 50935 (53597)	Loss/tok 5.4919 (7.4776)	Learning Rate [0.00125]
8: TRAIN [0][370/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00091)	Tok/s 50869 (53070)	Loss/tok 5.7309 (7.4662)	Learning Rate [0.00125]
6: TRAIN [0][370/3416]	Time 0.047 (0.058)	Data 0.00081 (0.00096)	Tok/s 50825 (52917)	Loss/tok 5.5827 (7.4780)	Learning Rate [0.00125]
4: TRAIN [0][370/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00099)	Tok/s 50776 (52757)	Loss/tok 5.6281 (7.4697)	Learning Rate [0.00125]
7: TRAIN [0][370/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00096)	Tok/s 50823 (52978)	Loss/tok 5.3871 (7.4724)	Learning Rate [0.00125]
15: TRAIN [0][370/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00095)	Tok/s 51000 (53731)	Loss/tok 5.6972 (7.4730)	Learning Rate [0.00125]
10: TRAIN [0][370/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00098)	Tok/s 50930 (53190)	Loss/tok 5.8755 (7.4757)	Learning Rate [0.00125]
12: TRAIN [0][370/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00096)	Tok/s 50926 (53371)	Loss/tok 5.8015 (7.4747)	Learning Rate [0.00125]
3: TRAIN [0][370/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00095)	Tok/s 50779 (52643)	Loss/tok 5.5010 (7.4835)	Learning Rate [0.00125]
9: TRAIN [0][370/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00094)	Tok/s 51013 (53128)	Loss/tok 5.5601 (7.4747)	Learning Rate [0.00125]
11: TRAIN [0][370/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00091)	Tok/s 50926 (53250)	Loss/tok 5.5710 (7.4664)	Learning Rate [0.00125]
5: TRAIN [0][370/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00096)	Tok/s 50809 (52851)	Loss/tok 5.4494 (7.4833)	Learning Rate [0.00125]
4: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00099)	Tok/s 45219 (52840)	Loss/tok 5.3119 (7.4209)	Learning Rate [0.00125]
5: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00096)	Tok/s 45132 (52932)	Loss/tok 5.3868 (7.4324)	Learning Rate [0.00125]
3: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00095)	Tok/s 45227 (52728)	Loss/tok 5.2474 (7.4335)	Learning Rate [0.00125]
6: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00096)	Tok/s 45077 (53000)	Loss/tok 5.3865 (7.4273)	Learning Rate [0.00125]
2: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00120 (0.00099)	Tok/s 45239 (52563)	Loss/tok 5.4736 (7.4203)	Learning Rate [0.00125]
1: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00080 (0.00095)	Tok/s 45260 (52455)	Loss/tok 5.3202 (7.4206)	Learning Rate [0.00125]
8: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00092)	Tok/s 45107 (53149)	Loss/tok 5.3926 (7.4188)	Learning Rate [0.00125]
0: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 45268 (52384)	Loss/tok 5.1945 (7.4321)	Learning Rate [0.00125]
15: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00095)	Tok/s 45267 (53804)	Loss/tok 5.5017 (7.4242)	Learning Rate [0.00125]
14: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00098)	Tok/s 45273 (53671)	Loss/tok 5.4239 (7.4284)	Learning Rate [0.00125]
7: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00096)	Tok/s 45026 (53060)	Loss/tok 5.1076 (7.4217)	Learning Rate [0.00125]
10: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00098)	Tok/s 45096 (53270)	Loss/tok 5.3975 (7.4260)	Learning Rate [0.00125]
13: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00095)	Tok/s 45223 (53543)	Loss/tok 5.1349 (7.4237)	Learning Rate [0.00125]
9: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00094)	Tok/s 45064 (53209)	Loss/tok 5.3099 (7.4253)	Learning Rate [0.00125]
12: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00083 (0.00096)	Tok/s 45105 (53450)	Loss/tok 5.3958 (7.4251)	Learning Rate [0.00125]
11: TRAIN [0][380/3416]	Time 0.045 (0.058)	Data 0.00083 (0.00091)	Tok/s 45068 (53332)	Loss/tok 5.4463 (7.4174)	Learning Rate [0.00125]
3: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00096)	Tok/s 47624 (52599)	Loss/tok 5.2788 (7.3930)	Learning Rate [0.00125]
5: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00096)	Tok/s 47574 (52805)	Loss/tok 5.4583 (7.3940)	Learning Rate [0.00125]
6: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00096)	Tok/s 47511 (52871)	Loss/tok 5.7284 (7.3891)	Learning Rate [0.00125]
1: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00095)	Tok/s 47383 (52326)	Loss/tok 5.4792 (7.3817)	Learning Rate [0.00125]
4: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00099)	Tok/s 47733 (52715)	Loss/tok 5.4427 (7.3809)	Learning Rate [0.00125]
7: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00095)	Tok/s 47480 (52937)	Loss/tok 5.4039 (7.3817)	Learning Rate [0.00125]
2: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00127 (0.00100)	Tok/s 47621 (52435)	Loss/tok 5.2820 (7.3812)	Learning Rate [0.00125]
8: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00092)	Tok/s 48158 (53025)	Loss/tok 5.4614 (7.3799)	Learning Rate [0.00125]
0: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00097)	Tok/s 47314 (52256)	Loss/tok 5.3935 (7.3930)	Learning Rate [0.00125]
15: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00095)	Tok/s 48649 (53668)	Loss/tok 5.5762 (7.3837)	Learning Rate [0.00125]
9: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00094)	Tok/s 48922 (53085)	Loss/tok 5.5012 (7.3851)	Learning Rate [0.00125]
14: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00097)	Tok/s 48664 (53537)	Loss/tok 5.4819 (7.3875)	Learning Rate [0.00125]
13: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00095)	Tok/s 48741 (53411)	Loss/tok 5.4049 (7.3848)	Learning Rate [0.00125]
10: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00111 (0.00098)	Tok/s 48758 (53145)	Loss/tok 5.2992 (7.3864)	Learning Rate [0.00125]
11: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00091)	Tok/s 48745 (53205)	Loss/tok 5.1813 (7.3766)	Learning Rate [0.00125]
12: TRAIN [0][390/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00096)	Tok/s 48791 (53320)	Loss/tok 5.4356 (7.3871)	Learning Rate [0.00125]
0: TRAIN [0][400/3416]	Time 0.057 (0.058)	Data 0.00086 (0.00097)	Tok/s 50349 (52288)	Loss/tok 5.4490 (7.3455)	Learning Rate [0.00125]
1: TRAIN [0][400/3416]	Time 0.057 (0.058)	Data 0.00087 (0.00095)	Tok/s 50216 (52358)	Loss/tok 5.5215 (7.3336)	Learning Rate [0.00125]
13: TRAIN [0][400/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00095)	Tok/s 50442 (53425)	Loss/tok 5.1929 (7.3374)	Learning Rate [0.00125]
2: TRAIN [0][400/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00100)	Tok/s 50097 (52466)	Loss/tok 5.5840 (7.3355)	Learning Rate [0.00125]
15: TRAIN [0][400/3416]	Time 0.057 (0.058)	Data 0.00087 (0.00095)	Tok/s 50429 (53691)	Loss/tok 5.4586 (7.3368)	Learning Rate [0.00125]
12: TRAIN [0][400/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00096)	Tok/s 50455 (53337)	Loss/tok 5.4054 (7.3404)	Learning Rate [0.00125]
11: TRAIN [0][400/3416]	Time 0.057 (0.058)	Data 0.00087 (0.00091)	Tok/s 50314 (53224)	Loss/tok 5.4235 (7.3330)	Learning Rate [0.00125]
3: TRAIN [0][400/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00096)	Tok/s 49998 (52625)	Loss/tok 5.5665 (7.3467)	Learning Rate [0.00125]
9: TRAIN [0][400/3416]	Time 0.057 (0.058)	Data 0.00087 (0.00094)	Tok/s 50163 (53105)	Loss/tok 5.4371 (7.3375)	Learning Rate [0.00125]
5: TRAIN [0][400/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00096)	Tok/s 49895 (52826)	Loss/tok 5.4037 (7.3464)	Learning Rate [0.00125]
6: TRAIN [0][400/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00096)	Tok/s 49924 (52890)	Loss/tok 5.6330 (7.3432)	Learning Rate [0.00125]
10: TRAIN [0][400/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00098)	Tok/s 50237 (53163)	Loss/tok 5.5399 (7.3407)	Learning Rate [0.00125]
8: TRAIN [0][400/3416]	Time 0.058 (0.058)	Data 0.00081 (0.00092)	Tok/s 50049 (53046)	Loss/tok 5.4169 (7.3319)	Learning Rate [0.00125]
4: TRAIN [0][400/3416]	Time 0.058 (0.058)	Data 0.00120 (0.00099)	Tok/s 49905 (52737)	Loss/tok 5.4572 (7.3345)	Learning Rate [0.00125]
14: TRAIN [0][400/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00098)	Tok/s 50427 (53556)	Loss/tok 5.6146 (7.3415)	Learning Rate [0.00125]
7: TRAIN [0][400/3416]	Time 0.058 (0.058)	Data 0.00113 (0.00095)	Tok/s 49935 (52956)	Loss/tok 5.5263 (7.3364)	Learning Rate [0.00125]
10: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00112 (0.00098)	Tok/s 51880 (53084)	Loss/tok 5.2878 (7.2968)	Learning Rate [0.00125]
9: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00094)	Tok/s 51944 (53023)	Loss/tok 5.5588 (7.2934)	Learning Rate [0.00125]
8: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00101 (0.00092)	Tok/s 51948 (52966)	Loss/tok 5.6583 (7.2891)	Learning Rate [0.00125]
7: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00101 (0.00095)	Tok/s 51876 (52878)	Loss/tok 5.2954 (7.2928)	Learning Rate [0.00125]
12: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00104 (0.00096)	Tok/s 51845 (53257)	Loss/tok 5.2634 (7.2966)	Learning Rate [0.00125]
6: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00112 (0.00096)	Tok/s 51866 (52811)	Loss/tok 5.2162 (7.2983)	Learning Rate [0.00125]
13: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00112 (0.00095)	Tok/s 51830 (53347)	Loss/tok 5.2999 (7.2939)	Learning Rate [0.00125]
14: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00107 (0.00097)	Tok/s 51829 (53479)	Loss/tok 5.3460 (7.2965)	Learning Rate [0.00125]
5: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00123 (0.00096)	Tok/s 51867 (52743)	Loss/tok 5.3648 (7.3022)	Learning Rate [0.00125]
1: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00108 (0.00095)	Tok/s 51900 (52278)	Loss/tok 5.2753 (7.2901)	Learning Rate [0.00125]
4: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00099)	Tok/s 51835 (52655)	Loss/tok 5.5338 (7.2912)	Learning Rate [0.00125]
0: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00111 (0.00097)	Tok/s 51844 (52210)	Loss/tok 5.3487 (7.3016)	Learning Rate [0.00125]
2: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00109 (0.00100)	Tok/s 51886 (52386)	Loss/tok 5.5527 (7.2926)	Learning Rate [0.00125]
3: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00110 (0.00096)	Tok/s 51918 (52543)	Loss/tok 5.4880 (7.3032)	Learning Rate [0.00125]
11: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00106 (0.00091)	Tok/s 51462 (53145)	Loss/tok 5.3019 (7.2895)	Learning Rate [0.00125]
15: TRAIN [0][410/3416]	Time 0.053 (0.058)	Data 0.00102 (0.00095)	Tok/s 51568 (53607)	Loss/tok 5.5726 (7.2942)	Learning Rate [0.00125]
3: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 60626 (52630)	Loss/tok 5.6005 (7.2524)	Learning Rate [0.00125]
4: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00099)	Tok/s 60591 (52739)	Loss/tok 5.8201 (7.2437)	Learning Rate [0.00125]
6: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 60431 (52893)	Loss/tok 5.4162 (7.2497)	Learning Rate [0.00125]
2: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00101)	Tok/s 60413 (52475)	Loss/tok 5.3084 (7.2429)	Learning Rate [0.00125]
1: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00095)	Tok/s 60318 (52367)	Loss/tok 5.3172 (7.2400)	Learning Rate [0.00125]
5: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00115 (0.00096)	Tok/s 60577 (52826)	Loss/tok 5.5729 (7.2532)	Learning Rate [0.00125]
8: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 60320 (53045)	Loss/tok 5.4685 (7.2407)	Learning Rate [0.00125]
0: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 60222 (52299)	Loss/tok 5.3607 (7.2524)	Learning Rate [0.00125]
7: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00096)	Tok/s 60381 (52958)	Loss/tok 5.7170 (7.2443)	Learning Rate [0.00125]
15: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00095)	Tok/s 61086 (53693)	Loss/tok 5.4524 (7.2463)	Learning Rate [0.00125]
9: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00094)	Tok/s 60191 (53102)	Loss/tok 5.4171 (7.2461)	Learning Rate [0.00125]
14: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 60254 (53561)	Loss/tok 5.5494 (7.2463)	Learning Rate [0.00125]
10: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00098)	Tok/s 60109 (53163)	Loss/tok 5.6188 (7.2472)	Learning Rate [0.00125]
13: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00095)	Tok/s 60012 (53430)	Loss/tok 5.4742 (7.2446)	Learning Rate [0.00125]
12: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 60038 (53338)	Loss/tok 5.5480 (7.2485)	Learning Rate [0.00125]
11: TRAIN [0][420/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00091)	Tok/s 60068 (53224)	Loss/tok 5.6151 (7.2404)	Learning Rate [0.00125]
5: TRAIN [0][430/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00096)	Tok/s 54004 (52831)	Loss/tok 5.6071 (7.2087)	Learning Rate [0.00125]
6: TRAIN [0][430/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00095)	Tok/s 53952 (52898)	Loss/tok 5.4512 (7.2073)	Learning Rate [0.00125]
7: TRAIN [0][430/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00096)	Tok/s 54027 (52967)	Loss/tok 5.6635 (7.2018)	Learning Rate [0.00125]
4: TRAIN [0][430/3416]	Time 0.067 (0.058)	Data 0.00102 (0.00099)	Tok/s 53873 (52746)	Loss/tok 5.6406 (7.1998)	Learning Rate [0.00125]
3: TRAIN [0][430/3416]	Time 0.067 (0.058)	Data 0.00108 (0.00096)	Tok/s 53765 (52639)	Loss/tok 5.5988 (7.2086)	Learning Rate [0.00125]
2: TRAIN [0][430/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00100)	Tok/s 53781 (52481)	Loss/tok 5.7963 (7.1986)	Learning Rate [0.00125]
9: TRAIN [0][430/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00094)	Tok/s 54779 (53120)	Loss/tok 5.4037 (7.1994)	Learning Rate [0.00125]
1: TRAIN [0][430/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00095)	Tok/s 53786 (52373)	Loss/tok 5.4270 (7.1948)	Learning Rate [0.00125]
8: TRAIN [0][430/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00092)	Tok/s 53921 (53059)	Loss/tok 5.5330 (7.1954)	Learning Rate [0.00125]
0: TRAIN [0][430/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00097)	Tok/s 53740 (52303)	Loss/tok 5.3055 (7.2083)	Learning Rate [0.00125]
10: TRAIN [0][430/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00098)	Tok/s 54898 (53179)	Loss/tok 5.5570 (7.2022)	Learning Rate [0.00125]
12: TRAIN [0][430/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00096)	Tok/s 54791 (53352)	Loss/tok 5.5176 (7.2058)	Learning Rate [0.00125]
13: TRAIN [0][430/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00095)	Tok/s 54728 (53445)	Loss/tok 5.4931 (7.2024)	Learning Rate [0.00125]
15: TRAIN [0][430/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00095)	Tok/s 54828 (53706)	Loss/tok 5.5945 (7.2047)	Learning Rate [0.00125]
14: TRAIN [0][430/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00098)	Tok/s 54729 (53576)	Loss/tok 5.3887 (7.2027)	Learning Rate [0.00125]
11: TRAIN [0][430/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00091)	Tok/s 54921 (53239)	Loss/tok 5.5390 (7.1969)	Learning Rate [0.00125]
13: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00095)	Tok/s 41060 (53427)	Loss/tok 5.0458 (7.1593)	Learning Rate [0.00125]
12: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00096)	Tok/s 39878 (53330)	Loss/tok 4.8243 (7.1650)	Learning Rate [0.00125]
14: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00097)	Tok/s 40975 (53558)	Loss/tok 5.2025 (7.1609)	Learning Rate [0.00125]
15: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00095)	Tok/s 40879 (53688)	Loss/tok 4.9790 (7.1630)	Learning Rate [0.00125]
0: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00097)	Tok/s 39603 (52284)	Loss/tok 4.8259 (7.1655)	Learning Rate [0.00125]
9: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00094)	Tok/s 39790 (53095)	Loss/tok 4.9454 (7.1573)	Learning Rate [0.00125]
10: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00097)	Tok/s 39828 (53155)	Loss/tok 5.0521 (7.1609)	Learning Rate [0.00125]
1: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00080 (0.00095)	Tok/s 39624 (52354)	Loss/tok 5.1721 (7.1558)	Learning Rate [0.00125]
8: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00091)	Tok/s 39831 (53035)	Loss/tok 5.1142 (7.1545)	Learning Rate [0.00125]
2: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00100)	Tok/s 39643 (52459)	Loss/tok 5.0703 (7.1558)	Learning Rate [0.00125]
7: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00096)	Tok/s 39825 (52945)	Loss/tok 5.1587 (7.1609)	Learning Rate [0.00125]
3: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00096)	Tok/s 39654 (52614)	Loss/tok 5.1885 (7.1676)	Learning Rate [0.00125]
4: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00099)	Tok/s 39714 (52721)	Loss/tok 5.0553 (7.1576)	Learning Rate [0.00125]
6: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00095)	Tok/s 39764 (52876)	Loss/tok 5.0607 (7.1661)	Learning Rate [0.00125]
5: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00096)	Tok/s 39684 (52808)	Loss/tok 5.0844 (7.1667)	Learning Rate [0.00125]
11: TRAIN [0][440/3416]	Time 0.050 (0.058)	Data 0.00081 (0.00091)	Tok/s 39813 (53216)	Loss/tok 4.9695 (7.1569)	Learning Rate [0.00125]
8: Upscaling, new scale: 512.0
9: Upscaling, new scale: 512.0
7: Upscaling, new scale: 512.0
6: Upscaling, new scale: 512.0
5: Upscaling, new scale: 512.0
10: Upscaling, new scale: 512.0
4: Upscaling, new scale: 512.0
12: Upscaling, new scale: 512.0
3: Upscaling, new scale: 512.0
2: Upscaling, new scale: 512.0
1: Upscaling, new scale: 512.0
14: Upscaling, new scale: 512.0
0: Upscaling, new scale: 512.0
13: Upscaling, new scale: 512.0
15: Upscaling, new scale: 512.0
11: Upscaling, new scale: 512.0
1: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00086 (0.00094)	Tok/s 29707 (52221)	Loss/tok 4.3712 (7.1173)	Learning Rate [0.00125]
2: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00100)	Tok/s 29683 (52328)	Loss/tok 4.1318 (7.1192)	Learning Rate [0.00125]
0: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00098 (0.00097)	Tok/s 29615 (52152)	Loss/tok 4.0619 (7.1292)	Learning Rate [0.00125]
3: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00106 (0.00096)	Tok/s 29684 (52480)	Loss/tok 4.1688 (7.1291)	Learning Rate [0.00125]
4: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00096 (0.00099)	Tok/s 29717 (52584)	Loss/tok 4.2454 (7.1192)	Learning Rate [0.00125]
14: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00101 (0.00097)	Tok/s 31076 (53424)	Loss/tok 4.1318 (7.1233)	Learning Rate [0.00125]
13: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00095)	Tok/s 31094 (53295)	Loss/tok 4.1892 (7.1218)	Learning Rate [0.00125]
5: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00096)	Tok/s 29696 (52671)	Loss/tok 4.2540 (7.1293)	Learning Rate [0.00125]
12: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00090 (0.00096)	Tok/s 31045 (53200)	Loss/tok 4.2738 (7.1260)	Learning Rate [0.00125]
6: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00095)	Tok/s 30348 (52740)	Loss/tok 4.5134 (7.1269)	Learning Rate [0.00125]
8: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00088 (0.00091)	Tok/s 31136 (52901)	Loss/tok 4.2230 (7.1149)	Learning Rate [0.00125]
7: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00099 (0.00096)	Tok/s 31170 (52812)	Loss/tok 4.3305 (7.1235)	Learning Rate [0.00125]
10: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00097)	Tok/s 31112 (53025)	Loss/tok 4.2855 (7.1229)	Learning Rate [0.00125]
9: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00094)	Tok/s 31088 (52962)	Loss/tok 4.3715 (7.1189)	Learning Rate [0.00125]
15: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00113 (0.00095)	Tok/s 30964 (53549)	Loss/tok 4.0711 (7.1249)	Learning Rate [0.00125]
11: TRAIN [0][450/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00091)	Tok/s 31052 (53088)	Loss/tok 4.0002 (7.1193)	Learning Rate [0.00125]
9: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00094)	Tok/s 37211 (52946)	Loss/tok 4.7560 (7.0799)	Learning Rate [0.00125]
10: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00097)	Tok/s 37163 (53008)	Loss/tok 4.7309 (7.0816)	Learning Rate [0.00125]
12: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00096)	Tok/s 37198 (53183)	Loss/tok 4.8733 (7.0867)	Learning Rate [0.00125]
13: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00095)	Tok/s 37171 (53282)	Loss/tok 4.6300 (7.0817)	Learning Rate [0.00125]
8: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00091)	Tok/s 37129 (52887)	Loss/tok 4.4767 (7.0747)	Learning Rate [0.00125]
14: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00097)	Tok/s 37027 (53411)	Loss/tok 4.3986 (7.0833)	Learning Rate [0.00125]
7: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00096)	Tok/s 37058 (52799)	Loss/tok 4.8452 (7.0843)	Learning Rate [0.00125]
6: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00095)	Tok/s 36996 (52727)	Loss/tok 4.5797 (7.0840)	Learning Rate [0.00125]
15: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00094)	Tok/s 36937 (53537)	Loss/tok 4.5306 (7.0854)	Learning Rate [0.00125]
0: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00097)	Tok/s 36865 (52148)	Loss/tok 4.6888 (7.0875)	Learning Rate [0.00125]
1: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00094)	Tok/s 36776 (52218)	Loss/tok 4.8198 (7.0758)	Learning Rate [0.00125]
5: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00096)	Tok/s 36929 (52660)	Loss/tok 4.6976 (7.0902)	Learning Rate [0.00125]
2: TRAIN [0][460/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00100)	Tok/s 36697 (52324)	Loss/tok 4.5382 (7.0785)	Learning Rate [0.00125]
4: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00099)	Tok/s 36852 (52575)	Loss/tok 4.5606 (7.0783)	Learning Rate [0.00125]
11: TRAIN [0][460/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00091)	Tok/s 37198 (53070)	Loss/tok 4.7677 (7.0800)	Learning Rate [0.00125]
3: TRAIN [0][460/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00096)	Tok/s 36742 (52472)	Loss/tok 4.8711 (7.0893)	Learning Rate [0.00125]
13: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00095)	Tok/s 51228 (53243)	Loss/tok 5.2113 (7.0434)	Learning Rate [0.00125]
0: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00097)	Tok/s 51096 (52124)	Loss/tok 4.8300 (7.0454)	Learning Rate [0.00125]
1: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00085 (0.00094)	Tok/s 51034 (52192)	Loss/tok 4.9127 (7.0376)	Learning Rate [0.00125]
14: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00097)	Tok/s 52170 (53372)	Loss/tok 5.3406 (7.0441)	Learning Rate [0.00125]
15: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00094)	Tok/s 52216 (53497)	Loss/tok 5.1271 (7.0460)	Learning Rate [0.00125]
12: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00096)	Tok/s 51123 (53144)	Loss/tok 5.1459 (7.0479)	Learning Rate [0.00125]
10: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00097)	Tok/s 51260 (52968)	Loss/tok 5.0444 (7.0426)	Learning Rate [0.00125]
2: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00100)	Tok/s 51113 (52295)	Loss/tok 4.8576 (7.0400)	Learning Rate [0.00125]
9: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00094)	Tok/s 51113 (52907)	Loss/tok 5.2048 (7.0414)	Learning Rate [0.00125]
8: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00091)	Tok/s 51237 (52849)	Loss/tok 5.2435 (7.0366)	Learning Rate [0.00125]
4: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00099)	Tok/s 51124 (52541)	Loss/tok 5.0522 (7.0404)	Learning Rate [0.00125]
3: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00085 (0.00096)	Tok/s 51112 (52441)	Loss/tok 5.0790 (7.0493)	Learning Rate [0.00125]
7: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00096)	Tok/s 51229 (52762)	Loss/tok 5.2731 (7.0463)	Learning Rate [0.00125]
6: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00095)	Tok/s 51194 (52689)	Loss/tok 4.9671 (7.0452)	Learning Rate [0.00125]
5: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00111 (0.00096)	Tok/s 51124 (52624)	Loss/tok 5.1261 (7.0520)	Learning Rate [0.00125]
11: TRAIN [0][470/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00091)	Tok/s 51156 (53031)	Loss/tok 5.0561 (7.0419)	Learning Rate [0.00125]
4: Gradient norm: inf
3: Gradient norm: inf
4: Skipped batch, new scale: 256.0
5: Gradient norm: inf
3: Skipped batch, new scale: 256.0
2: Gradient norm: inf
5: Skipped batch, new scale: 256.0
2: Skipped batch, new scale: 256.0
1: Gradient norm: inf
7: Gradient norm: inf
1: Skipped batch, new scale: 256.0
0: Gradient norm: inf
8: Gradient norm: inf
7: Skipped batch, new scale: 256.0
0: Skipped batch, new scale: 256.0
15: Gradient norm: inf
8: Skipped batch, new scale: 256.0
6: Gradient norm: inf
9: Gradient norm: inf
15: Skipped batch, new scale: 256.0
14: Gradient norm: inf
9: Skipped batch, new scale: 256.0
10: Gradient norm: inf
6: Skipped batch, new scale: 256.0
14: Skipped batch, new scale: 256.0
13: Gradient norm: inf
10: Skipped batch, new scale: 256.0
11: Gradient norm: inf
12: Gradient norm: inf
13: Skipped batch, new scale: 256.0
11: Skipped batch, new scale: 256.0
12: Skipped batch, new scale: 256.0
4: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00099)	Tok/s 77045 (52619)	Loss/tok 5.0333 (6.9968)	Learning Rate [0.00125]
6: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00095)	Tok/s 77191 (52769)	Loss/tok 5.1406 (7.0014)	Learning Rate [0.00125]
2: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 76148 (52377)	Loss/tok 5.2436 (6.9976)	Learning Rate [0.00125]
3: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 76642 (52521)	Loss/tok 5.3142 (7.0055)	Learning Rate [0.00125]
10: TRAIN [0][480/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 77390 (53052)	Loss/tok 5.4579 (7.0005)	Learning Rate [0.00125]
9: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 77192 (52990)	Loss/tok 5.0876 (6.9973)	Learning Rate [0.00125]
1: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00094)	Tok/s 76140 (52276)	Loss/tok 5.3986 (6.9930)	Learning Rate [0.00125]
8: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 77187 (52930)	Loss/tok 5.1737 (6.9934)	Learning Rate [0.00125]
5: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00096)	Tok/s 77050 (52700)	Loss/tok 5.3812 (7.0099)	Learning Rate [0.00125]
7: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 77096 (52842)	Loss/tok 5.0924 (7.0025)	Learning Rate [0.00125]
0: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 76170 (52208)	Loss/tok 5.4276 (7.0019)	Learning Rate [0.00125]
11: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 77658 (53117)	Loss/tok 5.2609 (6.9980)	Learning Rate [0.00125]
12: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 78234 (53228)	Loss/tok 5.3245 (7.0034)	Learning Rate [0.00125]
13: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00095)	Tok/s 78171 (53325)	Loss/tok 5.1296 (6.9999)	Learning Rate [0.00125]
15: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00094)	Tok/s 77908 (53576)	Loss/tok 5.3103 (7.0039)	Learning Rate [0.00125]
14: TRAIN [0][480/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 78014 (53451)	Loss/tok 5.2612 (7.0004)	Learning Rate [0.00125]
8: TRAIN [0][490/3416]	Time 0.065 (0.058)	Data 0.00099 (0.00091)	Tok/s 55723 (53013)	Loss/tok 5.0247 (6.9515)	Learning Rate [0.00125]
9: TRAIN [0][490/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00093)	Tok/s 55720 (53072)	Loss/tok 4.8802 (6.9521)	Learning Rate [0.00125]
7: TRAIN [0][490/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00096)	Tok/s 55726 (52927)	Loss/tok 5.2444 (6.9591)	Learning Rate [0.00125]
6: TRAIN [0][490/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00095)	Tok/s 55604 (52852)	Loss/tok 5.0799 (6.9584)	Learning Rate [0.00125]
5: TRAIN [0][490/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00095)	Tok/s 55539 (52785)	Loss/tok 5.2605 (6.9654)	Learning Rate [0.00125]
10: TRAIN [0][490/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00097)	Tok/s 55812 (53135)	Loss/tok 5.2865 (6.9579)	Learning Rate [0.00125]
11: TRAIN [0][490/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00091)	Tok/s 55934 (53200)	Loss/tok 4.9598 (6.9548)	Learning Rate [0.00125]
4: TRAIN [0][490/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00099)	Tok/s 55548 (52706)	Loss/tok 5.2437 (6.9536)	Learning Rate [0.00125]
2: TRAIN [0][490/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00100)	Tok/s 55513 (52466)	Loss/tok 5.0156 (6.9536)	Learning Rate [0.00125]
13: TRAIN [0][490/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00095)	Tok/s 55781 (53405)	Loss/tok 5.1433 (6.9555)	Learning Rate [0.00125]
3: TRAIN [0][490/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00096)	Tok/s 55504 (52609)	Loss/tok 5.0452 (6.9623)	Learning Rate [0.00125]
1: TRAIN [0][490/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00094)	Tok/s 55527 (52365)	Loss/tok 5.0704 (6.9499)	Learning Rate [0.00125]
12: TRAIN [0][490/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00096)	Tok/s 55713 (53310)	Loss/tok 5.2216 (6.9608)	Learning Rate [0.00125]
0: TRAIN [0][490/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00097)	Tok/s 55554 (52297)	Loss/tok 5.1940 (6.9583)	Learning Rate [0.00125]
14: TRAIN [0][490/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00097)	Tok/s 55680 (53531)	Loss/tok 5.1500 (6.9588)	Learning Rate [0.00125]
15: TRAIN [0][490/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00094)	Tok/s 55590 (53655)	Loss/tok 5.1307 (6.9613)	Learning Rate [0.00125]
3: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 72626 (52654)	Loss/tok 4.8029 (6.9177)	Learning Rate [0.00125]
6: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00095)	Tok/s 72711 (52896)	Loss/tok 4.9789 (6.9147)	Learning Rate [0.00125]
2: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00100)	Tok/s 72440 (52513)	Loss/tok 4.6297 (6.9097)	Learning Rate [0.00125]
5: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00095)	Tok/s 72656 (52829)	Loss/tok 5.0004 (6.9229)	Learning Rate [0.00125]
4: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00099)	Tok/s 72563 (52749)	Loss/tok 5.1931 (6.9110)	Learning Rate [0.00125]
1: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00094)	Tok/s 72334 (52411)	Loss/tok 5.1408 (6.9075)	Learning Rate [0.00125]
13: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00095)	Tok/s 73483 (53449)	Loss/tok 4.9089 (6.9101)	Learning Rate [0.00125]
0: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 71512 (52341)	Loss/tok 5.2244 (6.9171)	Learning Rate [0.00125]
15: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00094)	Tok/s 73315 (53695)	Loss/tok 5.1615 (6.9201)	Learning Rate [0.00125]
14: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 73386 (53572)	Loss/tok 5.1185 (6.9152)	Learning Rate [0.00125]
8: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 72657 (53054)	Loss/tok 5.1683 (6.9081)	Learning Rate [0.00125]
7: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00096)	Tok/s 72634 (52970)	Loss/tok 5.2167 (6.9164)	Learning Rate [0.00125]
9: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 72601 (53115)	Loss/tok 4.9281 (6.9079)	Learning Rate [0.00125]
12: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00096)	Tok/s 73438 (53355)	Loss/tok 5.3460 (6.9185)	Learning Rate [0.00125]
11: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 73062 (53245)	Loss/tok 5.0899 (6.9121)	Learning Rate [0.00125]
10: TRAIN [0][500/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 71922 (53178)	Loss/tok 5.0578 (6.9149)	Learning Rate [0.00125]
13: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00108 (0.00095)	Tok/s 53517 (53460)	Loss/tok 4.9090 (6.8727)	Learning Rate [0.00125]
14: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00097)	Tok/s 53466 (53581)	Loss/tok 4.9339 (6.8774)	Learning Rate [0.00125]
12: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00096)	Tok/s 53532 (53369)	Loss/tok 4.7971 (6.8806)	Learning Rate [0.00125]
15: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00094)	Tok/s 53414 (53702)	Loss/tok 4.8906 (6.8831)	Learning Rate [0.00125]
11: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00091)	Tok/s 53494 (53260)	Loss/tok 4.9525 (6.8734)	Learning Rate [0.00125]
10: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00104 (0.00097)	Tok/s 53439 (53191)	Loss/tok 5.2686 (6.8782)	Learning Rate [0.00125]
0: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00107 (0.00098)	Tok/s 52359 (52354)	Loss/tok 5.0193 (6.8809)	Learning Rate [0.00125]
9: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00093)	Tok/s 53426 (53125)	Loss/tok 4.7250 (6.8688)	Learning Rate [0.00125]
8: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00102 (0.00091)	Tok/s 52858 (53061)	Loss/tok 4.9327 (6.8698)	Learning Rate [0.00125]
1: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00110 (0.00094)	Tok/s 52272 (52423)	Loss/tok 5.0784 (6.8687)	Learning Rate [0.00125]
2: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00103 (0.00100)	Tok/s 52176 (52524)	Loss/tok 5.1515 (6.8728)	Learning Rate [0.00125]
7: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00112 (0.00096)	Tok/s 52298 (52976)	Loss/tok 4.9546 (6.8780)	Learning Rate [0.00125]
6: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00095)	Tok/s 52230 (52902)	Loss/tok 5.1592 (6.8768)	Learning Rate [0.00125]
3: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00095)	Tok/s 52090 (52662)	Loss/tok 4.9333 (6.8793)	Learning Rate [0.00125]
4: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00104 (0.00099)	Tok/s 52148 (52758)	Loss/tok 4.8406 (6.8723)	Learning Rate [0.00125]
5: TRAIN [0][510/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00095)	Tok/s 52131 (52836)	Loss/tok 5.3116 (6.8854)	Learning Rate [0.00125]
6: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00095)	Tok/s 63735 (52946)	Loss/tok 5.0952 (6.8363)	Learning Rate [0.00125]
15: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00094)	Tok/s 64782 (53743)	Loss/tok 4.8345 (6.8439)	Learning Rate [0.00125]
5: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00095)	Tok/s 63746 (52877)	Loss/tok 5.1011 (6.8440)	Learning Rate [0.00125]
0: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00098)	Tok/s 63759 (52397)	Loss/tok 4.9051 (6.8405)	Learning Rate [0.00125]
7: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00096)	Tok/s 63808 (53021)	Loss/tok 4.9142 (6.8374)	Learning Rate [0.00125]
4: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00099)	Tok/s 63583 (52797)	Loss/tok 5.0491 (6.8318)	Learning Rate [0.00125]
1: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00094)	Tok/s 63719 (52464)	Loss/tok 4.9571 (6.8275)	Learning Rate [0.00125]
8: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00091)	Tok/s 63843 (53103)	Loss/tok 5.2287 (6.8309)	Learning Rate [0.00125]
14: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00097)	Tok/s 64028 (53621)	Loss/tok 5.3486 (6.8383)	Learning Rate [0.00125]
2: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00100)	Tok/s 63643 (52565)	Loss/tok 5.1375 (6.8325)	Learning Rate [0.00125]
3: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00095)	Tok/s 63607 (52701)	Loss/tok 5.0697 (6.8392)	Learning Rate [0.00125]
13: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00095)	Tok/s 63861 (53501)	Loss/tok 5.1138 (6.8315)	Learning Rate [0.00125]
11: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00091)	Tok/s 63852 (53303)	Loss/tok 5.2348 (6.8349)	Learning Rate [0.00125]
12: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00096)	Tok/s 63851 (53412)	Loss/tok 5.0150 (6.8414)	Learning Rate [0.00125]
10: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00097)	Tok/s 63767 (53236)	Loss/tok 5.0713 (6.8383)	Learning Rate [0.00125]
9: TRAIN [0][520/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 63779 (53167)	Loss/tok 4.9699 (6.8286)	Learning Rate [0.00125]
6: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00095)	Tok/s 64377 (52977)	Loss/tok 5.0363 (6.7978)	Learning Rate [0.00125]
5: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00095)	Tok/s 64391 (52907)	Loss/tok 4.9520 (6.8049)	Learning Rate [0.00125]
7: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00096)	Tok/s 64314 (53055)	Loss/tok 5.0940 (6.7982)	Learning Rate [0.00125]
8: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00091)	Tok/s 64319 (53138)	Loss/tok 5.2818 (6.7921)	Learning Rate [0.00125]
3: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00095)	Tok/s 64377 (52732)	Loss/tok 5.4347 (6.8012)	Learning Rate [0.00125]
2: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 64280 (52594)	Loss/tok 5.1586 (6.7939)	Learning Rate [0.00125]
9: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 64330 (53201)	Loss/tok 4.9835 (6.7907)	Learning Rate [0.00125]
1: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00094)	Tok/s 64361 (52496)	Loss/tok 5.2364 (6.7886)	Learning Rate [0.00125]
10: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 64245 (53268)	Loss/tok 4.9348 (6.8008)	Learning Rate [0.00125]
4: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 64374 (52827)	Loss/tok 4.8184 (6.7913)	Learning Rate [0.00125]
0: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 64345 (52429)	Loss/tok 4.9021 (6.8028)	Learning Rate [0.00125]
11: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00091)	Tok/s 64301 (53334)	Loss/tok 5.2607 (6.7985)	Learning Rate [0.00125]
12: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 65060 (53446)	Loss/tok 5.2658 (6.8032)	Learning Rate [0.00125]
15: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00094)	Tok/s 65139 (53775)	Loss/tok 4.9289 (6.8050)	Learning Rate [0.00125]
13: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00095)	Tok/s 65199 (53535)	Loss/tok 5.2240 (6.7941)	Learning Rate [0.00125]
14: TRAIN [0][530/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00097)	Tok/s 65178 (53654)	Loss/tok 5.3392 (6.8004)	Learning Rate [0.00125]
6: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00076 (0.00094)	Tok/s 78965 (52948)	Loss/tok 4.8612 (6.7635)	Learning Rate [0.00125]
2: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00100)	Tok/s 78138 (52567)	Loss/tok 4.7874 (6.7594)	Learning Rate [0.00125]
5: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00095)	Tok/s 78958 (52879)	Loss/tok 5.0011 (6.7708)	Learning Rate [0.00125]
4: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00099)	Tok/s 78580 (52800)	Loss/tok 5.0585 (6.7591)	Learning Rate [0.00125]
7: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 79095 (53024)	Loss/tok 4.9377 (6.7642)	Learning Rate [0.00125]
3: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00095)	Tok/s 78124 (52706)	Loss/tok 4.9168 (6.7659)	Learning Rate [0.00125]
9: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 79149 (53168)	Loss/tok 4.6936 (6.7561)	Learning Rate [0.00125]
8: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00091)	Tok/s 79087 (53105)	Loss/tok 5.0894 (6.7578)	Learning Rate [0.00125]
0: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 78198 (52405)	Loss/tok 4.7783 (6.7665)	Learning Rate [0.00125]
10: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 79170 (53233)	Loss/tok 4.9471 (6.7675)	Learning Rate [0.00125]
1: TRAIN [0][540/3416]	Time 0.069 (0.058)	Data 0.00125 (0.00094)	Tok/s 78309 (52470)	Loss/tok 4.8609 (6.7541)	Learning Rate [0.00125]
11: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00091)	Tok/s 79281 (53300)	Loss/tok 4.6974 (6.7643)	Learning Rate [0.00125]
12: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 80094 (53414)	Loss/tok 4.9414 (6.7710)	Learning Rate [0.00125]
15: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00094)	Tok/s 80071 (53747)	Loss/tok 4.8846 (6.7705)	Learning Rate [0.00125]
14: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 80075 (53623)	Loss/tok 4.7700 (6.7677)	Learning Rate [0.00125]
13: TRAIN [0][540/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00095)	Tok/s 80093 (53502)	Loss/tok 4.9101 (6.7598)	Learning Rate [0.00125]
11: TRAIN [0][550/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00091)	Tok/s 39454 (53319)	Loss/tok 4.4354 (6.7261)	Learning Rate [0.00125]
9: TRAIN [0][550/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00093)	Tok/s 39517 (53188)	Loss/tok 4.5102 (6.7193)	Learning Rate [0.00125]
8: TRAIN [0][550/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00091)	Tok/s 39345 (53126)	Loss/tok 4.1682 (6.7208)	Learning Rate [0.00125]
7: TRAIN [0][550/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00096)	Tok/s 38111 (53043)	Loss/tok 4.2297 (6.7271)	Learning Rate [0.00125]
13: TRAIN [0][550/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00095)	Tok/s 39244 (53520)	Loss/tok 4.2492 (6.7209)	Learning Rate [0.00125]
6: TRAIN [0][550/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00094)	Tok/s 38037 (52966)	Loss/tok 4.0179 (6.7257)	Learning Rate [0.00125]
4: TRAIN [0][550/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00099)	Tok/s 37916 (52821)	Loss/tok 4.2436 (6.7217)	Learning Rate [0.00125]
15: TRAIN [0][550/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00094)	Tok/s 39134 (53761)	Loss/tok 4.5159 (6.7346)	Learning Rate [0.00125]
5: TRAIN [0][550/3416]	Time 0.051 (0.058)	Data 0.00112 (0.00095)	Tok/s 37932 (52898)	Loss/tok 4.2929 (6.7336)	Learning Rate [0.00125]
2: TRAIN [0][550/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00100)	Tok/s 37742 (52590)	Loss/tok 4.3213 (6.7221)	Learning Rate [0.00125]
1: TRAIN [0][550/3416]	Time 0.051 (0.058)	Data 0.00109 (0.00094)	Tok/s 37669 (52494)	Loss/tok 4.3099 (6.7174)	Learning Rate [0.00125]
0: TRAIN [0][550/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00098)	Tok/s 37735 (52428)	Loss/tok 4.4441 (6.7289)	Learning Rate [0.00125]
3: TRAIN [0][550/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00095)	Tok/s 37789 (52726)	Loss/tok 4.1457 (6.7290)	Learning Rate [0.00125]
14: TRAIN [0][550/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00097)	Tok/s 38810 (53638)	Loss/tok 4.3866 (6.7300)	Learning Rate [0.00125]
10: TRAIN [0][550/3416]	Time 0.050 (0.058)	Data 0.00126 (0.00097)	Tok/s 39584 (53251)	Loss/tok 4.4102 (6.7308)	Learning Rate [0.00125]
12: TRAIN [0][550/3416]	Time 0.050 (0.058)	Data 0.00110 (0.00096)	Tok/s 39418 (53430)	Loss/tok 4.5171 (6.7330)	Learning Rate [0.00125]
11: TRAIN [0][560/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00091)	Tok/s 55097 (53426)	Loss/tok 4.8834 (6.6861)	Learning Rate [0.00125]
10: TRAIN [0][560/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00097)	Tok/s 54881 (53359)	Loss/tok 4.6336 (6.6917)	Learning Rate [0.00125]
12: TRAIN [0][560/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00096)	Tok/s 55773 (53539)	Loss/tok 4.6239 (6.6905)	Learning Rate [0.00125]
8: TRAIN [0][560/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00091)	Tok/s 54707 (53231)	Loss/tok 4.9459 (6.6802)	Learning Rate [0.00125]
9: TRAIN [0][560/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00093)	Tok/s 54702 (53293)	Loss/tok 4.7890 (6.6792)	Learning Rate [0.00125]
0: TRAIN [0][560/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00098)	Tok/s 54441 (52537)	Loss/tok 4.8567 (6.6879)	Learning Rate [0.00125]
1: TRAIN [0][560/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00094)	Tok/s 54334 (52603)	Loss/tok 4.6233 (6.6760)	Learning Rate [0.00125]
13: TRAIN [0][560/3416]	Time 0.062 (0.058)	Data 0.00083 (0.00095)	Tok/s 55686 (53626)	Loss/tok 4.6436 (6.6789)	Learning Rate [0.00125]
7: TRAIN [0][560/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00096)	Tok/s 54588 (53149)	Loss/tok 4.8779 (6.6867)	Learning Rate [0.00125]
14: TRAIN [0][560/3416]	Time 0.062 (0.058)	Data 0.00083 (0.00097)	Tok/s 55569 (53744)	Loss/tok 4.9035 (6.6893)	Learning Rate [0.00125]
6: TRAIN [0][560/3416]	Time 0.062 (0.058)	Data 0.00077 (0.00094)	Tok/s 54434 (53074)	Loss/tok 4.9035 (6.6844)	Learning Rate [0.00125]
2: TRAIN [0][560/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00100)	Tok/s 54212 (52701)	Loss/tok 4.8504 (6.6831)	Learning Rate [0.00125]
4: TRAIN [0][560/3416]	Time 0.063 (0.058)	Data 0.00083 (0.00098)	Tok/s 54240 (52929)	Loss/tok 4.8708 (6.6813)	Learning Rate [0.00125]
5: TRAIN [0][560/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00095)	Tok/s 54353 (53005)	Loss/tok 4.5880 (6.6931)	Learning Rate [0.00125]
3: TRAIN [0][560/3416]	Time 0.063 (0.058)	Data 0.00083 (0.00095)	Tok/s 54226 (52835)	Loss/tok 4.9046 (6.6877)	Learning Rate [0.00125]
15: TRAIN [0][560/3416]	Time 0.062 (0.058)	Data 0.00082 (0.00094)	Tok/s 55508 (53870)	Loss/tok 4.6596 (6.6922)	Learning Rate [0.00125]
14: TRAIN [0][570/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00097)	Tok/s 48473 (53838)	Loss/tok 4.1155 (6.6498)	Learning Rate [0.00125]
15: TRAIN [0][570/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00094)	Tok/s 48536 (53965)	Loss/tok 4.3171 (6.6532)	Learning Rate [0.00125]
0: TRAIN [0][570/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00097)	Tok/s 46981 (52630)	Loss/tok 4.4887 (6.6489)	Learning Rate [0.00125]
1: TRAIN [0][570/3416]	Time 0.045 (0.058)	Data 0.00105 (0.00094)	Tok/s 46946 (52696)	Loss/tok 4.6177 (6.6386)	Learning Rate [0.00125]
13: TRAIN [0][570/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00095)	Tok/s 48345 (53719)	Loss/tok 4.4479 (6.6419)	Learning Rate [0.00125]
2: TRAIN [0][570/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00100)	Tok/s 46845 (52792)	Loss/tok 4.4967 (6.6442)	Learning Rate [0.00125]
11: TRAIN [0][570/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00091)	Tok/s 48092 (53521)	Loss/tok 4.5441 (6.6483)	Learning Rate [0.00125]
12: TRAIN [0][570/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00096)	Tok/s 48179 (53632)	Loss/tok 4.0598 (6.6494)	Learning Rate [0.00125]
3: TRAIN [0][570/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00095)	Tok/s 46723 (52927)	Loss/tok 4.3200 (6.6492)	Learning Rate [0.00125]
4: TRAIN [0][570/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00098)	Tok/s 46611 (53020)	Loss/tok 4.3961 (6.6440)	Learning Rate [0.00125]
10: TRAIN [0][570/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00097)	Tok/s 47927 (53454)	Loss/tok 4.3508 (6.6521)	Learning Rate [0.00125]
6: TRAIN [0][570/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00094)	Tok/s 46494 (53165)	Loss/tok 4.3684 (6.6457)	Learning Rate [0.00125]
8: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00092)	Tok/s 46328 (53321)	Loss/tok 4.5615 (6.6417)	Learning Rate [0.00125]
9: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00093)	Tok/s 46559 (53384)	Loss/tok 4.6087 (6.6415)	Learning Rate [0.00125]
5: TRAIN [0][570/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00095)	Tok/s 46507 (53096)	Loss/tok 4.1896 (6.6524)	Learning Rate [0.00125]
7: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00096)	Tok/s 46326 (53241)	Loss/tok 4.2713 (6.6485)	Learning Rate [0.00125]
15: Gradient norm: inf
14: Gradient norm: inf
15: Skipped batch, new scale: 128.0
0: Gradient norm: inf
14: Skipped batch, new scale: 128.0
13: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 128.0
8: Gradient norm: inf
9: Gradient norm: inf
12: Gradient norm: inf
1: Skipped batch, new scale: 128.0
13: Skipped batch, new scale: 128.0
2: Gradient norm: inf
8: Skipped batch, new scale: 128.0
11: Gradient norm: inf
7: Gradient norm: inf
10: Gradient norm: inf
9: Skipped batch, new scale: 128.0
12: Skipped batch, new scale: 128.0
3: Gradient norm: inf
2: Skipped batch, new scale: 128.0
11: Skipped batch, new scale: 128.0
7: Skipped batch, new scale: 128.0
6: Gradient norm: inf
10: Skipped batch, new scale: 128.0
3: Skipped batch, new scale: 128.0
4: Gradient norm: inf
5: Gradient norm: inf
6: Skipped batch, new scale: 128.0
4: Skipped batch, new scale: 128.0
5: Skipped batch, new scale: 128.0
4: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00098)	Tok/s 51921 (53164)	Loss/tok 4.6007 (6.6034)	Learning Rate [0.00125]
3: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00095)	Tok/s 51947 (53072)	Loss/tok 4.5244 (6.6081)	Learning Rate [0.00125]
2: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00100)	Tok/s 51961 (52936)	Loss/tok 4.6274 (6.6034)	Learning Rate [0.00125]
6: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00080 (0.00094)	Tok/s 51964 (53307)	Loss/tok 4.5458 (6.6048)	Learning Rate [0.00125]
1: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00094)	Tok/s 51940 (52840)	Loss/tok 4.6914 (6.6003)	Learning Rate [0.00125]
5: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00082 (0.00095)	Tok/s 51884 (53239)	Loss/tok 4.4388 (6.6111)	Learning Rate [0.00125]
0: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00097)	Tok/s 51967 (52774)	Loss/tok 4.3060 (6.6085)	Learning Rate [0.00125]
11: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00091)	Tok/s 52142 (53665)	Loss/tok 4.6168 (6.6095)	Learning Rate [0.00125]
7: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00096)	Tok/s 51882 (53383)	Loss/tok 4.6257 (6.6067)	Learning Rate [0.00125]
15: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00082 (0.00094)	Tok/s 51974 (54109)	Loss/tok 4.6908 (6.6123)	Learning Rate [0.00125]
10: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00097)	Tok/s 52011 (53597)	Loss/tok 4.5654 (6.6113)	Learning Rate [0.00125]
12: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00096)	Tok/s 52117 (53775)	Loss/tok 5.0901 (6.6097)	Learning Rate [0.00125]
8: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00092)	Tok/s 51909 (53464)	Loss/tok 4.3844 (6.6012)	Learning Rate [0.00125]
14: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00085 (0.00097)	Tok/s 51957 (53982)	Loss/tok 4.8223 (6.6112)	Learning Rate [0.00125]
13: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00080 (0.00095)	Tok/s 52006 (53862)	Loss/tok 4.4457 (6.6027)	Learning Rate [0.00125]
9: TRAIN [0][580/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00093)	Tok/s 51866 (53526)	Loss/tok 4.6139 (6.6028)	Learning Rate [0.00125]
4: TRAIN [0][590/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00098)	Tok/s 31801 (53194)	Loss/tok 3.8537 (6.5687)	Learning Rate [0.00125]
6: TRAIN [0][590/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00094)	Tok/s 31589 (53336)	Loss/tok 4.0858 (6.5695)	Learning Rate [0.00125]
3: TRAIN [0][590/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00095)	Tok/s 31752 (53103)	Loss/tok 4.0283 (6.5731)	Learning Rate [0.00125]
5: TRAIN [0][590/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00095)	Tok/s 31711 (53268)	Loss/tok 3.8334 (6.5768)	Learning Rate [0.00125]
7: TRAIN [0][590/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00096)	Tok/s 31628 (53413)	Loss/tok 3.6964 (6.5709)	Learning Rate [0.00125]
8: TRAIN [0][590/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 31580 (53492)	Loss/tok 3.7143 (6.5658)	Learning Rate [0.00125]
9: TRAIN [0][590/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00093)	Tok/s 31589 (53556)	Loss/tok 3.6033 (6.5670)	Learning Rate [0.00125]
1: TRAIN [0][590/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00094)	Tok/s 31632 (52873)	Loss/tok 3.7257 (6.5651)	Learning Rate [0.00125]
2: TRAIN [0][590/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00100)	Tok/s 31678 (52968)	Loss/tok 3.5584 (6.5684)	Learning Rate [0.00125]
0: TRAIN [0][590/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00097)	Tok/s 31591 (52805)	Loss/tok 3.8915 (6.5727)	Learning Rate [0.00125]
10: TRAIN [0][590/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 31508 (53626)	Loss/tok 3.8890 (6.5759)	Learning Rate [0.00125]
11: TRAIN [0][590/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00091)	Tok/s 31490 (53692)	Loss/tok 3.7166 (6.5742)	Learning Rate [0.00125]
15: TRAIN [0][590/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00094)	Tok/s 32993 (54131)	Loss/tok 4.1709 (6.5771)	Learning Rate [0.00125]
14: TRAIN [0][590/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 32967 (54006)	Loss/tok 3.9882 (6.5750)	Learning Rate [0.00125]
12: TRAIN [0][590/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00096)	Tok/s 32636 (53802)	Loss/tok 3.8111 (6.5748)	Learning Rate [0.00125]
13: TRAIN [0][590/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00095)	Tok/s 32936 (53889)	Loss/tok 3.7738 (6.5681)	Learning Rate [0.00125]
6: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00094)	Tok/s 76843 (53405)	Loss/tok 4.6634 (6.5329)	Learning Rate [0.00125]
5: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00095)	Tok/s 76797 (53338)	Loss/tok 4.7510 (6.5395)	Learning Rate [0.00125]
4: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 76586 (53263)	Loss/tok 4.7260 (6.5302)	Learning Rate [0.00125]
3: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00095)	Tok/s 75894 (53172)	Loss/tok 4.6784 (6.5350)	Learning Rate [0.00125]
2: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00100)	Tok/s 75643 (53039)	Loss/tok 4.5369 (6.5301)	Learning Rate [0.00125]
8: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 76825 (53562)	Loss/tok 4.8378 (6.5283)	Learning Rate [0.00125]
1: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00094)	Tok/s 75685 (52945)	Loss/tok 4.6227 (6.5276)	Learning Rate [0.00125]
9: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00093)	Tok/s 76817 (53625)	Loss/tok 4.6448 (6.5306)	Learning Rate [0.00125]
10: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 76880 (53697)	Loss/tok 4.6301 (6.5373)	Learning Rate [0.00125]
0: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 75710 (52878)	Loss/tok 4.9140 (6.5358)	Learning Rate [0.00125]
15: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00094)	Tok/s 77485 (54203)	Loss/tok 4.6433 (6.5389)	Learning Rate [0.00125]
11: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00091)	Tok/s 76752 (53763)	Loss/tok 4.7722 (6.5366)	Learning Rate [0.00125]
14: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 77480 (54078)	Loss/tok 4.7492 (6.5383)	Learning Rate [0.00125]
12: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00095)	Tok/s 77390 (53874)	Loss/tok 4.8174 (6.5378)	Learning Rate [0.00125]
7: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00114 (0.00096)	Tok/s 76990 (53480)	Loss/tok 4.7092 (6.5340)	Learning Rate [0.00125]
13: TRAIN [0][600/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00095)	Tok/s 77680 (53960)	Loss/tok 4.6554 (6.5315)	Learning Rate [0.00125]
3: TRAIN [0][610/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00095)	Tok/s 75678 (53158)	Loss/tok 4.5677 (6.5016)	Learning Rate [0.00125]
1: TRAIN [0][610/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00094)	Tok/s 75472 (52934)	Loss/tok 4.7930 (6.4949)	Learning Rate [0.00125]
2: TRAIN [0][610/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00100)	Tok/s 75492 (53027)	Loss/tok 4.4772 (6.4966)	Learning Rate [0.00125]
4: TRAIN [0][610/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 75577 (53248)	Loss/tok 4.6821 (6.4968)	Learning Rate [0.00125]
6: TRAIN [0][610/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00094)	Tok/s 75599 (53389)	Loss/tok 4.6372 (6.4998)	Learning Rate [0.00125]
0: TRAIN [0][610/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00097)	Tok/s 74900 (52866)	Loss/tok 4.7701 (6.5017)	Learning Rate [0.00125]
5: TRAIN [0][610/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00095)	Tok/s 75681 (53322)	Loss/tok 4.5629 (6.5057)	Learning Rate [0.00125]
14: TRAIN [0][610/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00097)	Tok/s 76248 (54061)	Loss/tok 4.5744 (6.5040)	Learning Rate [0.00125]
7: TRAIN [0][610/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00096)	Tok/s 75587 (53464)	Loss/tok 4.7250 (6.5009)	Learning Rate [0.00125]
13: TRAIN [0][610/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00096)	Tok/s 76225 (53945)	Loss/tok 4.4858 (6.4983)	Learning Rate [0.00125]
9: TRAIN [0][610/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 75603 (53606)	Loss/tok 4.6956 (6.4986)	Learning Rate [0.00125]
11: TRAIN [0][610/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 76297 (53747)	Loss/tok 4.7389 (6.5044)	Learning Rate [0.00125]
12: TRAIN [0][610/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 76250 (53860)	Loss/tok 4.7598 (6.5034)	Learning Rate [0.00125]
8: TRAIN [0][610/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 75586 (53544)	Loss/tok 4.5492 (6.4945)	Learning Rate [0.00125]
10: TRAIN [0][610/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00097)	Tok/s 76266 (53680)	Loss/tok 4.5301 (6.5041)	Learning Rate [0.00125]
15: TRAIN [0][610/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00094)	Tok/s 76163 (54186)	Loss/tok 4.5043 (6.5062)	Learning Rate [0.00125]
14: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00097)	Tok/s 56619 (53988)	Loss/tok 4.6416 (6.4754)	Learning Rate [0.00125]
13: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00096)	Tok/s 56600 (53872)	Loss/tok 4.6142 (6.4700)	Learning Rate [0.00125]
0: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00097)	Tok/s 55567 (52799)	Loss/tok 4.6103 (6.4723)	Learning Rate [0.00125]
11: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00091)	Tok/s 56649 (53673)	Loss/tok 4.6381 (6.4761)	Learning Rate [0.00125]
12: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00113 (0.00096)	Tok/s 56538 (53784)	Loss/tok 4.7308 (6.4741)	Learning Rate [0.00125]
1: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00094)	Tok/s 55498 (52865)	Loss/tok 4.7357 (6.4662)	Learning Rate [0.00125]
10: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00097)	Tok/s 56535 (53607)	Loss/tok 4.6294 (6.4749)	Learning Rate [0.00125]
8: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 56558 (53473)	Loss/tok 4.5731 (6.4647)	Learning Rate [0.00125]
2: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00100)	Tok/s 55504 (52957)	Loss/tok 4.5964 (6.4674)	Learning Rate [0.00125]
9: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00093)	Tok/s 56625 (53534)	Loss/tok 4.5436 (6.4692)	Learning Rate [0.00125]
4: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00098)	Tok/s 56431 (53177)	Loss/tok 4.6889 (6.4687)	Learning Rate [0.00125]
6: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00094)	Tok/s 56435 (53319)	Loss/tok 4.5159 (6.4707)	Learning Rate [0.00125]
15: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00094)	Tok/s 56518 (54112)	Loss/tok 4.7167 (6.4767)	Learning Rate [0.00125]
3: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00095)	Tok/s 55498 (53088)	Loss/tok 4.5271 (6.4720)	Learning Rate [0.00125]
7: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00096)	Tok/s 56552 (53393)	Loss/tok 4.5440 (6.4709)	Learning Rate [0.00125]
5: TRAIN [0][620/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00095)	Tok/s 56456 (53253)	Loss/tok 4.7440 (6.4774)	Learning Rate [0.00125]
9: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00093)	Tok/s 54522 (53502)	Loss/tok 4.4019 (6.4379)	Learning Rate [0.00125]
3: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00095)	Tok/s 54613 (53058)	Loss/tok 4.4797 (6.4411)	Learning Rate [0.00125]
2: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00100)	Tok/s 54691 (52929)	Loss/tok 4.6356 (6.4376)	Learning Rate [0.00125]
11: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00091)	Tok/s 54599 (53641)	Loss/tok 4.5136 (6.4457)	Learning Rate [0.00125]
10: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00097)	Tok/s 54538 (53576)	Loss/tok 4.6365 (6.4445)	Learning Rate [0.00125]
8: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00092)	Tok/s 54386 (53440)	Loss/tok 4.6069 (6.4343)	Learning Rate [0.00125]
5: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00095)	Tok/s 54446 (53223)	Loss/tok 4.4370 (6.4478)	Learning Rate [0.00125]
6: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00100 (0.00094)	Tok/s 54386 (53288)	Loss/tok 4.4536 (6.4403)	Learning Rate [0.00125]
7: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00096)	Tok/s 54336 (53361)	Loss/tok 4.6462 (6.4415)	Learning Rate [0.00125]
4: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00123 (0.00098)	Tok/s 54478 (53146)	Loss/tok 4.6772 (6.4394)	Learning Rate [0.00125]
12: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00096)	Tok/s 54567 (53751)	Loss/tok 4.4759 (6.4442)	Learning Rate [0.00125]
14: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00097)	Tok/s 54643 (53952)	Loss/tok 4.1965 (6.4459)	Learning Rate [0.00125]
13: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00105 (0.00096)	Tok/s 54603 (53838)	Loss/tok 4.5143 (6.4398)	Learning Rate [0.00125]
15: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00094)	Tok/s 55487 (54077)	Loss/tok 4.2948 (6.4459)	Learning Rate [0.00125]
1: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00119 (0.00094)	Tok/s 54735 (52836)	Loss/tok 4.5512 (6.4363)	Learning Rate [0.00125]
0: TRAIN [0][630/3416]	Time 0.060 (0.058)	Data 0.00109 (0.00097)	Tok/s 54708 (52769)	Loss/tok 4.3754 (6.4425)	Learning Rate [0.00125]
14: TRAIN [0][640/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00097)	Tok/s 38842 (53929)	Loss/tok 3.8257 (6.4150)	Learning Rate [0.00125]
11: TRAIN [0][640/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00091)	Tok/s 38819 (53622)	Loss/tok 4.2746 (6.4153)	Learning Rate [0.00125]
0: TRAIN [0][640/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00098)	Tok/s 37368 (52754)	Loss/tok 4.4274 (6.4130)	Learning Rate [0.00125]
13: TRAIN [0][640/3416]	Time 0.051 (0.058)	Data 0.00114 (0.00096)	Tok/s 38789 (53816)	Loss/tok 3.9210 (6.4110)	Learning Rate [0.00125]
12: TRAIN [0][640/3416]	Time 0.051 (0.058)	Data 0.00119 (0.00096)	Tok/s 38831 (53730)	Loss/tok 4.2543 (6.4144)	Learning Rate [0.00125]
1: TRAIN [0][640/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00095)	Tok/s 37289 (52821)	Loss/tok 3.8876 (6.4070)	Learning Rate [0.00125]
3: TRAIN [0][640/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00095)	Tok/s 37235 (53039)	Loss/tok 4.0639 (6.4121)	Learning Rate [0.00125]
9: TRAIN [0][640/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 38055 (53482)	Loss/tok 4.2287 (6.4095)	Learning Rate [0.00125]
10: TRAIN [0][640/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00097)	Tok/s 38758 (53557)	Loss/tok 4.0397 (6.4144)	Learning Rate [0.00125]
2: TRAIN [0][640/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00100)	Tok/s 37223 (52912)	Loss/tok 4.2420 (6.4094)	Learning Rate [0.00125]
6: TRAIN [0][640/3416]	Time 0.051 (0.058)	Data 0.00112 (0.00094)	Tok/s 37342 (53266)	Loss/tok 3.9347 (6.4107)	Learning Rate [0.00125]
15: TRAIN [0][640/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00094)	Tok/s 38771 (54053)	Loss/tok 4.1492 (6.4156)	Learning Rate [0.00125]
4: TRAIN [0][640/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00098)	Tok/s 37214 (53126)	Loss/tok 4.2055 (6.4097)	Learning Rate [0.00125]
5: TRAIN [0][640/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00095)	Tok/s 37244 (53201)	Loss/tok 3.9045 (6.4167)	Learning Rate [0.00125]
8: TRAIN [0][640/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00092)	Tok/s 37389 (53419)	Loss/tok 4.1393 (6.4044)	Learning Rate [0.00125]
7: TRAIN [0][640/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00096)	Tok/s 37333 (53339)	Loss/tok 4.1963 (6.4121)	Learning Rate [0.00125]
3: TRAIN [0][650/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00095)	Tok/s 32468 (52928)	Loss/tok 4.0176 (6.3858)	Learning Rate [0.00125]
4: TRAIN [0][650/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00099)	Tok/s 32542 (53014)	Loss/tok 3.8633 (6.3835)	Learning Rate [0.00125]
2: TRAIN [0][650/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00100)	Tok/s 32451 (52801)	Loss/tok 3.7395 (6.3837)	Learning Rate [0.00125]
5: TRAIN [0][650/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00095)	Tok/s 32494 (53091)	Loss/tok 3.9815 (6.3916)	Learning Rate [0.00125]
6: TRAIN [0][650/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00094)	Tok/s 33420 (53156)	Loss/tok 3.6577 (6.3861)	Learning Rate [0.00125]
0: TRAIN [0][650/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00098)	Tok/s 32300 (52644)	Loss/tok 3.9282 (6.3886)	Learning Rate [0.00125]
7: TRAIN [0][650/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00096)	Tok/s 32356 (53229)	Loss/tok 3.6399 (6.3860)	Learning Rate [0.00125]
8: TRAIN [0][650/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00092)	Tok/s 32374 (53307)	Loss/tok 3.6963 (6.3770)	Learning Rate [0.00125]
14: TRAIN [0][650/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00097)	Tok/s 33459 (53820)	Loss/tok 4.3837 (6.3896)	Learning Rate [0.00125]
13: TRAIN [0][650/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00096)	Tok/s 33488 (53707)	Loss/tok 3.9678 (6.3856)	Learning Rate [0.00125]
9: TRAIN [0][650/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00093)	Tok/s 32192 (53370)	Loss/tok 3.8707 (6.3841)	Learning Rate [0.00125]
1: TRAIN [0][650/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00095)	Tok/s 32205 (52710)	Loss/tok 3.8117 (6.3817)	Learning Rate [0.00125]
12: TRAIN [0][650/3416]	Time 0.050 (0.058)	Data 0.00113 (0.00096)	Tok/s 33465 (53623)	Loss/tok 4.1215 (6.3896)	Learning Rate [0.00125]
11: TRAIN [0][650/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00091)	Tok/s 33388 (53513)	Loss/tok 3.7617 (6.3894)	Learning Rate [0.00125]
10: TRAIN [0][650/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 32224 (53445)	Loss/tok 4.3628 (6.3889)	Learning Rate [0.00125]
15: TRAIN [0][650/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00094)	Tok/s 33453 (53943)	Loss/tok 4.0059 (6.3900)	Learning Rate [0.00125]
6: TRAIN [0][660/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00094)	Tok/s 56261 (53093)	Loss/tok 4.6801 (6.3588)	Learning Rate [0.00125]
1: TRAIN [0][660/3416]	Time 0.068 (0.058)	Data 0.00110 (0.00095)	Tok/s 56215 (52625)	Loss/tok 4.6855 (6.3561)	Learning Rate [0.00125]
0: TRAIN [0][660/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00098)	Tok/s 56235 (52547)	Loss/tok 4.5980 (6.3628)	Learning Rate [0.00125]
14: TRAIN [0][660/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00096)	Tok/s 57216 (53769)	Loss/tok 4.7484 (6.3631)	Learning Rate [0.00125]
11: TRAIN [0][660/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00091)	Tok/s 57099 (53458)	Loss/tok 4.5952 (6.3618)	Learning Rate [0.00125]
9: TRAIN [0][660/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 56990 (53312)	Loss/tok 4.6846 (6.3578)	Learning Rate [0.00125]
2: TRAIN [0][660/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00100)	Tok/s 56053 (52721)	Loss/tok 4.8687 (6.3581)	Learning Rate [0.00125]
13: TRAIN [0][660/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00096)	Tok/s 57284 (53657)	Loss/tok 4.5866 (6.3599)	Learning Rate [0.00125]
12: TRAIN [0][660/3416]	Time 0.068 (0.058)	Data 0.00108 (0.00096)	Tok/s 57471 (53569)	Loss/tok 4.7442 (6.3640)	Learning Rate [0.00125]
3: TRAIN [0][660/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00095)	Tok/s 55922 (52853)	Loss/tok 4.6514 (6.3597)	Learning Rate [0.00125]
8: TRAIN [0][660/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 56894 (53248)	Loss/tok 4.4053 (6.3500)	Learning Rate [0.00125]
10: TRAIN [0][660/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00097)	Tok/s 57039 (53389)	Loss/tok 4.7388 (6.3626)	Learning Rate [0.00125]
15: TRAIN [0][660/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00094)	Tok/s 57255 (53892)	Loss/tok 4.3976 (6.3625)	Learning Rate [0.00125]
4: TRAIN [0][660/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00099)	Tok/s 56146 (52943)	Loss/tok 4.7022 (6.3569)	Learning Rate [0.00125]
7: TRAIN [0][660/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 56686 (53167)	Loss/tok 4.8978 (6.3601)	Learning Rate [0.00125]
5: TRAIN [0][660/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00095)	Tok/s 54973 (53025)	Loss/tok 4.4957 (6.3658)	Learning Rate [0.00125]
5: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00095)	Tok/s 50735 (53113)	Loss/tok 4.4799 (6.3341)	Learning Rate [0.00125]
6: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00094)	Tok/s 50666 (53180)	Loss/tok 4.1569 (6.3263)	Learning Rate [0.00125]
4: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00099)	Tok/s 50764 (53031)	Loss/tok 3.8747 (6.3257)	Learning Rate [0.00125]
3: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00095)	Tok/s 50758 (52941)	Loss/tok 4.4917 (6.3264)	Learning Rate [0.00125]
7: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00096)	Tok/s 50501 (53255)	Loss/tok 4.0478 (6.3265)	Learning Rate [0.00125]
8: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00093)	Tok/s 50546 (53335)	Loss/tok 4.4645 (6.3168)	Learning Rate [0.00125]
2: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00100)	Tok/s 50753 (52810)	Loss/tok 4.5834 (6.3263)	Learning Rate [0.00125]
11: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00091)	Tok/s 50721 (53543)	Loss/tok 4.1777 (6.3286)	Learning Rate [0.00125]
9: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00093)	Tok/s 50489 (53399)	Loss/tok 4.0975 (6.3258)	Learning Rate [0.00125]
1: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00095)	Tok/s 50776 (52715)	Loss/tok 4.1978 (6.3239)	Learning Rate [0.00125]
12: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00096)	Tok/s 50777 (53653)	Loss/tok 4.4057 (6.3310)	Learning Rate [0.00125]
10: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 50628 (53475)	Loss/tok 4.2630 (6.3300)	Learning Rate [0.00125]
14: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00096)	Tok/s 50789 (53849)	Loss/tok 4.3321 (6.3304)	Learning Rate [0.00125]
15: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00094)	Tok/s 50720 (53973)	Loss/tok 4.3539 (6.3304)	Learning Rate [0.00125]
13: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00096)	Tok/s 50824 (53738)	Loss/tok 4.2035 (6.3283)	Learning Rate [0.00125]
0: TRAIN [0][670/3416]	Time 0.047 (0.058)	Data 0.00113 (0.00098)	Tok/s 50825 (52635)	Loss/tok 4.2299 (6.3322)	Learning Rate [0.00125]
12: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00096)	Tok/s 50527 (53677)	Loss/tok 4.0117 (6.3006)	Learning Rate [0.00125]
11: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00091)	Tok/s 50508 (53565)	Loss/tok 4.1464 (6.2980)	Learning Rate [0.00125]
10: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00097)	Tok/s 50514 (53497)	Loss/tok 4.3653 (6.3002)	Learning Rate [0.00125]
13: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00114 (0.00096)	Tok/s 50513 (53765)	Loss/tok 4.0416 (6.2975)	Learning Rate [0.00125]
14: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00096)	Tok/s 50476 (53873)	Loss/tok 4.2969 (6.2992)	Learning Rate [0.00125]
0: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00098)	Tok/s 50286 (52665)	Loss/tok 4.2285 (6.3023)	Learning Rate [0.00125]
6: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00095)	Tok/s 50351 (53205)	Loss/tok 4.1539 (6.2961)	Learning Rate [0.00125]
9: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00093)	Tok/s 50420 (53421)	Loss/tok 4.2924 (6.2954)	Learning Rate [0.00125]
7: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00096)	Tok/s 50389 (53279)	Loss/tok 4.0229 (6.2967)	Learning Rate [0.00125]
1: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00095)	Tok/s 50185 (52742)	Loss/tok 4.1568 (6.2944)	Learning Rate [0.00125]
2: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00100)	Tok/s 50087 (52836)	Loss/tok 4.3074 (6.2969)	Learning Rate [0.00125]
4: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00099)	Tok/s 50069 (53056)	Loss/tok 4.2278 (6.2963)	Learning Rate [0.00125]
5: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00095)	Tok/s 50229 (53138)	Loss/tok 4.2463 (6.3029)	Learning Rate [0.00125]
3: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00095)	Tok/s 50041 (52966)	Loss/tok 4.2350 (6.2971)	Learning Rate [0.00125]
15: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00094)	Tok/s 50338 (53995)	Loss/tok 3.9165 (6.3001)	Learning Rate [0.00125]
8: TRAIN [0][680/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00093)	Tok/s 50143 (53358)	Loss/tok 3.9298 (6.2858)	Learning Rate [0.00125]
10: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00097)	Tok/s 55706 (53511)	Loss/tok 4.3153 (6.2716)	Learning Rate [0.00125]
12: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00097)	Tok/s 55841 (53691)	Loss/tok 4.6011 (6.2717)	Learning Rate [0.00125]
9: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00093)	Tok/s 55602 (53435)	Loss/tok 4.2118 (6.2658)	Learning Rate [0.00125]
8: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00093)	Tok/s 55503 (53372)	Loss/tok 4.2927 (6.2562)	Learning Rate [0.00125]
13: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00096)	Tok/s 55610 (53777)	Loss/tok 4.2450 (6.2688)	Learning Rate [0.00125]
7: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00096)	Tok/s 55405 (53294)	Loss/tok 4.3618 (6.2681)	Learning Rate [0.00125]
14: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00096)	Tok/s 55544 (53884)	Loss/tok 4.4641 (6.2701)	Learning Rate [0.00125]
6: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00095)	Tok/s 55243 (53221)	Loss/tok 4.6206 (6.2676)	Learning Rate [0.00125]
0: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00098)	Tok/s 55336 (52682)	Loss/tok 4.2104 (6.2733)	Learning Rate [0.00125]
11: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00091)	Tok/s 55706 (53581)	Loss/tok 4.3068 (6.2686)	Learning Rate [0.00125]
15: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00094)	Tok/s 55414 (54005)	Loss/tok 4.4373 (6.2709)	Learning Rate [0.00125]
1: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00095)	Tok/s 55261 (52759)	Loss/tok 4.3178 (6.2653)	Learning Rate [0.00125]
5: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00095)	Tok/s 55173 (53155)	Loss/tok 4.5627 (6.2741)	Learning Rate [0.00125]
2: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00100)	Tok/s 55174 (52855)	Loss/tok 4.2130 (6.2672)	Learning Rate [0.00125]
4: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00099)	Tok/s 55073 (53073)	Loss/tok 4.5346 (6.2674)	Learning Rate [0.00125]
3: TRAIN [0][690/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00095)	Tok/s 55037 (52984)	Loss/tok 4.7472 (6.2682)	Learning Rate [0.00125]
8: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00086 (0.00093)	Tok/s 67872 (53416)	Loss/tok 4.4336 (6.2273)	Learning Rate [0.00125]
7: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00096)	Tok/s 67751 (53338)	Loss/tok 4.4268 (6.2390)	Learning Rate [0.00125]
9: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00093)	Tok/s 67849 (53480)	Loss/tok 4.6894 (6.2374)	Learning Rate [0.00125]
10: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00097)	Tok/s 67890 (53555)	Loss/tok 4.6294 (6.2430)	Learning Rate [0.00125]
4: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00099)	Tok/s 67158 (53119)	Loss/tok 4.5431 (6.2393)	Learning Rate [0.00125]
11: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00108 (0.00091)	Tok/s 67849 (53623)	Loss/tok 4.6331 (6.2405)	Learning Rate [0.00125]
5: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00095)	Tok/s 67723 (53201)	Loss/tok 4.4543 (6.2460)	Learning Rate [0.00125]
6: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00095)	Tok/s 67735 (53266)	Loss/tok 4.4148 (6.2399)	Learning Rate [0.00125]
12: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00103 (0.00097)	Tok/s 67835 (53732)	Loss/tok 4.5973 (6.2428)	Learning Rate [0.00125]
2: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00099 (0.00100)	Tok/s 66859 (52902)	Loss/tok 4.3896 (6.2378)	Learning Rate [0.00125]
1: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00095)	Tok/s 66807 (52805)	Loss/tok 4.7138 (6.2372)	Learning Rate [0.00125]
0: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00098)	Tok/s 66856 (52726)	Loss/tok 4.5990 (6.2450)	Learning Rate [0.00125]
3: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00087 (0.00095)	Tok/s 66741 (53029)	Loss/tok 4.8110 (6.2406)	Learning Rate [0.00125]
13: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00096)	Tok/s 67891 (53817)	Loss/tok 4.5149 (6.2411)	Learning Rate [0.00125]
15: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00084 (0.00094)	Tok/s 67799 (54045)	Loss/tok 4.4485 (6.2418)	Learning Rate [0.00125]
14: TRAIN [0][700/3416]	Time 0.071 (0.058)	Data 0.00087 (0.00096)	Tok/s 67754 (53923)	Loss/tok 4.4930 (6.2422)	Learning Rate [0.00125]
7: Upscaling, new scale: 256.0
6: Upscaling, new scale: 256.0
8: Upscaling, new scale: 256.0
4: Upscaling, new scale: 256.0
9: Upscaling, new scale: 256.0
5: Upscaling, new scale: 256.0
10: Upscaling, new scale: 256.0
2: Upscaling, new scale: 256.0
11: Upscaling, new scale: 256.0
3: Upscaling, new scale: 256.0
1: Upscaling, new scale: 256.0
12: Upscaling, new scale: 256.0
0: Upscaling, new scale: 256.0
13: Upscaling, new scale: 256.0
15: Upscaling, new scale: 256.0
14: Upscaling, new scale: 256.0
3: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00095)	Tok/s 61320 (52973)	Loss/tok 4.5159 (6.2170)	Learning Rate [0.00125]
4: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00099)	Tok/s 61218 (53061)	Loss/tok 4.5706 (6.2164)	Learning Rate [0.00125]
6: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00095)	Tok/s 61115 (53206)	Loss/tok 4.6131 (6.2158)	Learning Rate [0.00125]
2: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 61312 (52847)	Loss/tok 4.5943 (6.2141)	Learning Rate [0.00125]
5: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00095)	Tok/s 61208 (53142)	Loss/tok 4.4885 (6.2229)	Learning Rate [0.00125]
1: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00095)	Tok/s 61326 (52751)	Loss/tok 4.4683 (6.2126)	Learning Rate [0.00125]
7: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 61066 (53276)	Loss/tok 4.5366 (6.2160)	Learning Rate [0.00125]
8: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 61077 (53354)	Loss/tok 4.4134 (6.2041)	Learning Rate [0.00125]
0: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 60854 (52673)	Loss/tok 4.3594 (6.2211)	Learning Rate [0.00125]
9: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 61092 (53418)	Loss/tok 4.4022 (6.2139)	Learning Rate [0.00125]
14: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 61266 (53858)	Loss/tok 4.4882 (6.2185)	Learning Rate [0.00125]
15: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00094)	Tok/s 61358 (53980)	Loss/tok 4.5450 (6.2192)	Learning Rate [0.00125]
13: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00096)	Tok/s 61145 (53754)	Loss/tok 4.4594 (6.2174)	Learning Rate [0.00125]
10: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 61027 (53494)	Loss/tok 4.6963 (6.2201)	Learning Rate [0.00125]
11: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00091)	Tok/s 61043 (53561)	Loss/tok 4.6947 (6.2180)	Learning Rate [0.00125]
12: TRAIN [0][710/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 61069 (53670)	Loss/tok 4.7161 (6.2198)	Learning Rate [0.00125]
4: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 71329 (53143)	Loss/tok 4.5707 (6.1862)	Learning Rate [0.00125]
2: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 71239 (52931)	Loss/tok 4.3269 (6.1839)	Learning Rate [0.00125]
3: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00095)	Tok/s 71308 (53056)	Loss/tok 4.5779 (6.1882)	Learning Rate [0.00125]
1: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00095)	Tok/s 71146 (52835)	Loss/tok 4.4996 (6.1824)	Learning Rate [0.00125]
6: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00095)	Tok/s 71329 (53287)	Loss/tok 4.5767 (6.1863)	Learning Rate [0.00125]
5: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00095)	Tok/s 71370 (53224)	Loss/tok 4.4084 (6.1924)	Learning Rate [0.00125]
0: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 71078 (52758)	Loss/tok 4.8361 (6.1921)	Learning Rate [0.00125]
15: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00094)	Tok/s 71983 (54063)	Loss/tok 4.5918 (6.1899)	Learning Rate [0.00125]
7: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 71750 (53358)	Loss/tok 4.4091 (6.1853)	Learning Rate [0.00125]
8: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 72130 (53435)	Loss/tok 4.2671 (6.1739)	Learning Rate [0.00125]
14: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 72002 (53941)	Loss/tok 4.4270 (6.1883)	Learning Rate [0.00125]
13: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00096)	Tok/s 72001 (53837)	Loss/tok 4.6366 (6.1875)	Learning Rate [0.00125]
12: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00120 (0.00097)	Tok/s 71868 (53751)	Loss/tok 4.7072 (6.1906)	Learning Rate [0.00125]
9: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 72172 (53499)	Loss/tok 4.4031 (6.1829)	Learning Rate [0.00125]
10: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 72088 (53574)	Loss/tok 4.7536 (6.1919)	Learning Rate [0.00125]
11: TRAIN [0][720/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00091)	Tok/s 71989 (53642)	Loss/tok 4.4469 (6.1875)	Learning Rate [0.00125]
1: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00081 (0.00095)	Tok/s 55340 (52854)	Loss/tok 4.3135 (6.1566)	Learning Rate [0.00125]
0: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00098)	Tok/s 55314 (52776)	Loss/tok 4.4781 (6.1651)	Learning Rate [0.00125]
6: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00095)	Tok/s 55383 (53300)	Loss/tok 4.3492 (6.1595)	Learning Rate [0.00125]
2: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00100)	Tok/s 55286 (52948)	Loss/tok 4.4610 (6.1600)	Learning Rate [0.00125]
5: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00095)	Tok/s 55300 (53237)	Loss/tok 4.2423 (6.1662)	Learning Rate [0.00125]
4: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00099)	Tok/s 55266 (53158)	Loss/tok 4.3387 (6.1600)	Learning Rate [0.00125]
3: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00095)	Tok/s 55253 (53072)	Loss/tok 4.2931 (6.1626)	Learning Rate [0.00125]
7: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00109 (0.00096)	Tok/s 55757 (53370)	Loss/tok 4.3298 (6.1609)	Learning Rate [0.00125]
15: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00082 (0.00094)	Tok/s 56270 (54076)	Loss/tok 4.0198 (6.1634)	Learning Rate [0.00125]
14: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00096)	Tok/s 56288 (53955)	Loss/tok 4.3507 (6.1619)	Learning Rate [0.00125]
8: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00093)	Tok/s 56379 (53448)	Loss/tok 4.4735 (6.1485)	Learning Rate [0.00125]
13: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00096)	Tok/s 56241 (53851)	Loss/tok 4.5204 (6.1617)	Learning Rate [0.00125]
9: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00093)	Tok/s 56385 (53513)	Loss/tok 4.4717 (6.1574)	Learning Rate [0.00125]
12: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00097)	Tok/s 56305 (53766)	Loss/tok 4.5923 (6.1643)	Learning Rate [0.00125]
11: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00091)	Tok/s 56294 (53657)	Loss/tok 4.5745 (6.1625)	Learning Rate [0.00125]
10: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00097)	Tok/s 56333 (53588)	Loss/tok 4.3700 (6.1658)	Learning Rate [0.00125]
13: TRAIN [0][740/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00096)	Tok/s 50989 (53829)	Loss/tok 4.2617 (6.1383)	Learning Rate [0.00125]
14: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00096)	Tok/s 50908 (53932)	Loss/tok 4.3513 (6.1388)	Learning Rate [0.00125]
11: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00091)	Tok/s 50784 (53636)	Loss/tok 3.8444 (6.1388)	Learning Rate [0.00125]
12: TRAIN [0][740/3416]	Time 0.051 (0.058)	Data 0.00116 (0.00097)	Tok/s 51692 (53745)	Loss/tok 4.2255 (6.1405)	Learning Rate [0.00125]
15: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00094)	Tok/s 50818 (54052)	Loss/tok 4.3021 (6.1399)	Learning Rate [0.00125]
0: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00098)	Tok/s 50729 (52762)	Loss/tok 4.1970 (6.1424)	Learning Rate [0.00125]
10: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00097)	Tok/s 50679 (53566)	Loss/tok 4.2377 (6.1427)	Learning Rate [0.00125]
1: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00095)	Tok/s 50620 (52838)	Loss/tok 4.2992 (6.1325)	Learning Rate [0.00125]
9: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00093)	Tok/s 50566 (53493)	Loss/tok 4.2298 (6.1342)	Learning Rate [0.00125]
8: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00093)	Tok/s 50465 (53429)	Loss/tok 3.9741 (6.1241)	Learning Rate [0.00125]
7: TRAIN [0][740/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00096)	Tok/s 51181 (53351)	Loss/tok 3.9542 (6.1366)	Learning Rate [0.00125]
2: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00100)	Tok/s 50499 (52932)	Loss/tok 4.1143 (6.1365)	Learning Rate [0.00125]
6: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00095)	Tok/s 50254 (53280)	Loss/tok 4.1053 (6.1353)	Learning Rate [0.00125]
4: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00099)	Tok/s 50343 (53140)	Loss/tok 4.2220 (6.1370)	Learning Rate [0.00125]
3: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00095)	Tok/s 50341 (53055)	Loss/tok 4.2488 (6.1391)	Learning Rate [0.00125]
5: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00095)	Tok/s 50256 (53218)	Loss/tok 4.1364 (6.1426)	Learning Rate [0.00125]
6: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00095)	Tok/s 60382 (53166)	Loss/tok 4.2422 (6.1142)	Learning Rate [0.00125]
5: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00095)	Tok/s 60323 (53104)	Loss/tok 4.5425 (6.1225)	Learning Rate [0.00125]
7: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00096)	Tok/s 60293 (53241)	Loss/tok 4.6073 (6.1164)	Learning Rate [0.00125]
4: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00098)	Tok/s 60379 (53021)	Loss/tok 4.6386 (6.1170)	Learning Rate [0.00125]
8: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00093)	Tok/s 60163 (53321)	Loss/tok 4.3641 (6.1039)	Learning Rate [0.00125]
9: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00093)	Tok/s 60052 (53386)	Loss/tok 4.5078 (6.1142)	Learning Rate [0.00125]
3: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00095)	Tok/s 60346 (52937)	Loss/tok 4.5450 (6.1191)	Learning Rate [0.00125]
2: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00100)	Tok/s 60326 (52811)	Loss/tok 4.3322 (6.1167)	Learning Rate [0.00125]
1: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00095)	Tok/s 60276 (52714)	Loss/tok 4.6099 (6.1131)	Learning Rate [0.00125]
0: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00098)	Tok/s 60191 (52636)	Loss/tok 4.6645 (6.1233)	Learning Rate [0.00125]
11: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00091)	Tok/s 59998 (53530)	Loss/tok 4.4104 (6.1171)	Learning Rate [0.00125]
12: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00097)	Tok/s 59973 (53639)	Loss/tok 4.4157 (6.1189)	Learning Rate [0.00125]
10: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00097)	Tok/s 59968 (53460)	Loss/tok 4.6158 (6.1217)	Learning Rate [0.00125]
15: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00094)	Tok/s 61024 (53949)	Loss/tok 4.4844 (6.1188)	Learning Rate [0.00125]
13: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00096)	Tok/s 59984 (53724)	Loss/tok 4.6067 (6.1183)	Learning Rate [0.00125]
14: TRAIN [0][750/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00096)	Tok/s 60545 (53826)	Loss/tok 4.5602 (6.1182)	Learning Rate [0.00125]
0: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00098)	Tok/s 50611 (52641)	Loss/tok 4.2554 (6.0995)	Learning Rate [0.00125]
1: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00095)	Tok/s 50675 (52719)	Loss/tok 4.5529 (6.0889)	Learning Rate [0.00125]
8: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00093)	Tok/s 50721 (53324)	Loss/tok 4.0870 (6.0816)	Learning Rate [0.00125]
2: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00100)	Tok/s 50657 (52815)	Loss/tok 4.2588 (6.0921)	Learning Rate [0.00125]
15: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00094)	Tok/s 50586 (53950)	Loss/tok 3.8703 (6.0944)	Learning Rate [0.00125]
7: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00096)	Tok/s 50665 (53244)	Loss/tok 4.2236 (6.0918)	Learning Rate [0.00125]
9: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00093)	Tok/s 50491 (53388)	Loss/tok 4.1999 (6.0895)	Learning Rate [0.00125]
6: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00095)	Tok/s 50628 (53170)	Loss/tok 4.2922 (6.0892)	Learning Rate [0.00125]
5: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00095)	Tok/s 50723 (53105)	Loss/tok 4.3156 (6.0999)	Learning Rate [0.00125]
10: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00097)	Tok/s 50430 (53462)	Loss/tok 4.3595 (6.0986)	Learning Rate [0.00125]
4: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00098)	Tok/s 50646 (53022)	Loss/tok 4.1679 (6.0916)	Learning Rate [0.00125]
3: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00095)	Tok/s 50640 (52939)	Loss/tok 3.9707 (6.0949)	Learning Rate [0.00125]
13: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00096)	Tok/s 50494 (53725)	Loss/tok 4.1952 (6.0941)	Learning Rate [0.00125]
11: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00091)	Tok/s 50355 (53531)	Loss/tok 4.0820 (6.0928)	Learning Rate [0.00125]
12: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00097)	Tok/s 50471 (53640)	Loss/tok 4.0883 (6.0943)	Learning Rate [0.00125]
14: TRAIN [0][760/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00096)	Tok/s 50546 (53828)	Loss/tok 4.1978 (6.0943)	Learning Rate [0.00125]
14: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00096)	Tok/s 55640 (53835)	Loss/tok 4.4520 (6.0704)	Learning Rate [0.00125]
11: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00091)	Tok/s 55571 (53537)	Loss/tok 4.3438 (6.0693)	Learning Rate [0.00125]
13: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00096)	Tok/s 55517 (53732)	Loss/tok 4.1961 (6.0699)	Learning Rate [0.00125]
0: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00098)	Tok/s 54707 (52653)	Loss/tok 4.4108 (6.0770)	Learning Rate [0.00125]
12: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00097)	Tok/s 55502 (53646)	Loss/tok 4.3431 (6.0703)	Learning Rate [0.00125]
1: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00095)	Tok/s 55629 (52732)	Loss/tok 4.3706 (6.0652)	Learning Rate [0.00125]
15: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00094)	Tok/s 55656 (53956)	Loss/tok 4.3867 (6.0709)	Learning Rate [0.00125]
10: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00097)	Tok/s 55605 (53467)	Loss/tok 4.4595 (6.0736)	Learning Rate [0.00125]
4: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00098)	Tok/s 55670 (53031)	Loss/tok 4.6020 (6.0688)	Learning Rate [0.00125]
9: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00093)	Tok/s 55557 (53393)	Loss/tok 4.2893 (6.0654)	Learning Rate [0.00125]
8: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00093)	Tok/s 55549 (53329)	Loss/tok 4.4304 (6.0581)	Learning Rate [0.00125]
3: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00095)	Tok/s 55648 (52949)	Loss/tok 4.4561 (6.0710)	Learning Rate [0.00125]
7: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00096)	Tok/s 55549 (53250)	Loss/tok 4.5320 (6.0678)	Learning Rate [0.00125]
2: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00100)	Tok/s 55606 (52827)	Loss/tok 4.4732 (6.0690)	Learning Rate [0.00125]
5: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00095)	Tok/s 55516 (53113)	Loss/tok 4.3729 (6.0764)	Learning Rate [0.00125]
6: TRAIN [0][770/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00095)	Tok/s 55569 (53177)	Loss/tok 4.2276 (6.0652)	Learning Rate [0.00125]
15: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00084 (0.00094)	Tok/s 56274 (53949)	Loss/tok 4.3534 (6.0474)	Learning Rate [0.00125]
14: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00083 (0.00096)	Tok/s 56262 (53827)	Loss/tok 4.2788 (6.0459)	Learning Rate [0.00125]
1: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00095)	Tok/s 55071 (52720)	Loss/tok 4.4062 (6.0408)	Learning Rate [0.00125]
13: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00096)	Tok/s 56293 (53722)	Loss/tok 4.3611 (6.0457)	Learning Rate [0.00125]
0: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00082 (0.00098)	Tok/s 55089 (52642)	Loss/tok 4.3791 (6.0533)	Learning Rate [0.00125]
12: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00097)	Tok/s 56276 (53636)	Loss/tok 4.2623 (6.0461)	Learning Rate [0.00125]
2: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00100)	Tok/s 54874 (52814)	Loss/tok 4.5125 (6.0453)	Learning Rate [0.00125]
11: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00091)	Tok/s 56200 (53528)	Loss/tok 4.2986 (6.0452)	Learning Rate [0.00125]
4: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00098)	Tok/s 54790 (53021)	Loss/tok 4.4807 (6.0454)	Learning Rate [0.00125]
3: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00095)	Tok/s 54833 (52937)	Loss/tok 4.3563 (6.0462)	Learning Rate [0.00125]
9: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00079 (0.00093)	Tok/s 56056 (53384)	Loss/tok 4.3921 (6.0417)	Learning Rate [0.00125]
8: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00093)	Tok/s 55931 (53321)	Loss/tok 4.2525 (6.0349)	Learning Rate [0.00125]
10: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00097)	Tok/s 56023 (53458)	Loss/tok 4.4058 (6.0493)	Learning Rate [0.00125]
5: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00095)	Tok/s 54770 (53102)	Loss/tok 4.3110 (6.0525)	Learning Rate [0.00125]
6: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00094)	Tok/s 54746 (53165)	Loss/tok 4.3241 (6.0413)	Learning Rate [0.00125]
7: TRAIN [0][780/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00096)	Tok/s 55023 (53239)	Loss/tok 4.4308 (6.0440)	Learning Rate [0.00125]
15: TRAIN [0][790/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00094)	Tok/s 49845 (53921)	Loss/tok 4.0006 (6.0255)	Learning Rate [0.00125]
0: TRAIN [0][790/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00098)	Tok/s 49447 (52616)	Loss/tok 3.8256 (6.0314)	Learning Rate [0.00125]
13: TRAIN [0][790/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00096)	Tok/s 49425 (53696)	Loss/tok 3.8464 (6.0233)	Learning Rate [0.00125]
1: TRAIN [0][790/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00095)	Tok/s 49348 (52693)	Loss/tok 3.9471 (6.0183)	Learning Rate [0.00125]
14: TRAIN [0][790/3416]	Time 0.044 (0.058)	Data 0.00105 (0.00096)	Tok/s 49446 (53801)	Loss/tok 3.8642 (6.0242)	Learning Rate [0.00125]
2: TRAIN [0][790/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00100)	Tok/s 49358 (52788)	Loss/tok 3.7802 (6.0231)	Learning Rate [0.00125]
11: TRAIN [0][790/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00092)	Tok/s 49194 (53502)	Loss/tok 4.0946 (6.0234)	Learning Rate [0.00125]
12: TRAIN [0][790/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00097)	Tok/s 49179 (53610)	Loss/tok 4.0694 (6.0235)	Learning Rate [0.00125]
3: TRAIN [0][790/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00095)	Tok/s 49243 (52910)	Loss/tok 3.7671 (6.0232)	Learning Rate [0.00125]
10: TRAIN [0][790/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00097)	Tok/s 49003 (53432)	Loss/tok 4.0085 (6.0269)	Learning Rate [0.00125]
8: TRAIN [0][790/3416]	Time 0.045 (0.058)	Data 0.00105 (0.00093)	Tok/s 48862 (53293)	Loss/tok 3.8345 (6.0126)	Learning Rate [0.00125]
9: TRAIN [0][790/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00093)	Tok/s 48904 (53357)	Loss/tok 3.9943 (6.0195)	Learning Rate [0.00125]
6: TRAIN [0][790/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00094)	Tok/s 48876 (53137)	Loss/tok 4.0179 (6.0193)	Learning Rate [0.00125]
5: TRAIN [0][790/3416]	Time 0.044 (0.058)	Data 0.00102 (0.00095)	Tok/s 48978 (53075)	Loss/tok 3.8327 (6.0297)	Learning Rate [0.00125]
4: TRAIN [0][790/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00098)	Tok/s 49049 (52994)	Loss/tok 3.9720 (6.0235)	Learning Rate [0.00125]
7: TRAIN [0][790/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00096)	Tok/s 48835 (53211)	Loss/tok 4.2587 (6.0213)	Learning Rate [0.00125]
0: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00098)	Tok/s 63046 (52549)	Loss/tok 4.3559 (6.0113)	Learning Rate [0.00125]
1: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00095)	Tok/s 63543 (52628)	Loss/tok 4.3698 (5.9986)	Learning Rate [0.00125]
2: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00100)	Tok/s 63809 (52722)	Loss/tok 4.2449 (6.0034)	Learning Rate [0.00125]
11: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 64138 (53434)	Loss/tok 4.0930 (6.0024)	Learning Rate [0.00125]
9: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00093)	Tok/s 64075 (53288)	Loss/tok 4.3465 (5.9994)	Learning Rate [0.00125]
15: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00094)	Tok/s 63969 (53853)	Loss/tok 4.3622 (6.0058)	Learning Rate [0.00125]
14: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00096)	Tok/s 64007 (53733)	Loss/tok 4.2496 (6.0045)	Learning Rate [0.00125]
10: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00097)	Tok/s 64117 (53363)	Loss/tok 4.4152 (6.0079)	Learning Rate [0.00125]
12: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00096)	Tok/s 64053 (53543)	Loss/tok 4.3118 (6.0037)	Learning Rate [0.00125]
13: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00096)	Tok/s 64044 (53629)	Loss/tok 4.4009 (6.0033)	Learning Rate [0.00125]
8: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00093)	Tok/s 64043 (53225)	Loss/tok 4.2943 (5.9935)	Learning Rate [0.00125]
3: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00095)	Tok/s 63752 (52843)	Loss/tok 4.5393 (6.0038)	Learning Rate [0.00125]
4: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00098)	Tok/s 63768 (52928)	Loss/tok 4.5722 (6.0048)	Learning Rate [0.00125]
6: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00094)	Tok/s 63810 (53071)	Loss/tok 4.3770 (5.9998)	Learning Rate [0.00125]
7: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00096)	Tok/s 63939 (53144)	Loss/tok 4.4686 (6.0010)	Learning Rate [0.00125]
5: TRAIN [0][800/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00095)	Tok/s 63771 (53008)	Loss/tok 4.3746 (6.0090)	Learning Rate [0.00125]
1: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00095)	Tok/s 73693 (52656)	Loss/tok 4.1768 (5.9750)	Learning Rate [0.00125]
2: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 73691 (52749)	Loss/tok 4.3649 (5.9803)	Learning Rate [0.00125]
0: TRAIN [0][810/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 73577 (52576)	Loss/tok 4.2325 (5.9890)	Learning Rate [0.00125]
4: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00098)	Tok/s 73720 (52952)	Loss/tok 3.9833 (5.9800)	Learning Rate [0.00125]
15: TRAIN [0][810/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00094)	Tok/s 74699 (53877)	Loss/tok 4.4744 (5.9834)	Learning Rate [0.00125]
14: TRAIN [0][810/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 74240 (53757)	Loss/tok 4.1442 (5.9811)	Learning Rate [0.00125]
3: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00095)	Tok/s 73701 (52869)	Loss/tok 4.2429 (5.9814)	Learning Rate [0.00125]
13: TRAIN [0][810/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 74211 (53653)	Loss/tok 4.2787 (5.9796)	Learning Rate [0.00125]
5: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00095)	Tok/s 73670 (53031)	Loss/tok 4.2530 (5.9862)	Learning Rate [0.00125]
6: TRAIN [0][810/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00094)	Tok/s 74369 (53095)	Loss/tok 4.2429 (5.9763)	Learning Rate [0.00125]
11: TRAIN [0][810/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 74179 (53457)	Loss/tok 4.2158 (5.9798)	Learning Rate [0.00125]
12: TRAIN [0][810/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 74205 (53566)	Loss/tok 4.4373 (5.9812)	Learning Rate [0.00125]
10: TRAIN [0][810/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 74312 (53386)	Loss/tok 4.4452 (5.9848)	Learning Rate [0.00125]
8: TRAIN [0][810/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00093)	Tok/s 74313 (53250)	Loss/tok 4.4715 (5.9708)	Learning Rate [0.00125]
7: TRAIN [0][810/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 74418 (53169)	Loss/tok 4.2012 (5.9774)	Learning Rate [0.00125]
9: TRAIN [0][810/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 74357 (53311)	Loss/tok 4.3309 (5.9769)	Learning Rate [0.00125]
0: TRAIN [0][820/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00098)	Tok/s 56064 (52557)	Loss/tok 4.2479 (5.9678)	Learning Rate [0.00125]
14: TRAIN [0][820/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00096)	Tok/s 56932 (53734)	Loss/tok 3.8385 (5.9587)	Learning Rate [0.00125]
15: TRAIN [0][820/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00094)	Tok/s 56981 (53856)	Loss/tok 4.3161 (5.9614)	Learning Rate [0.00125]
1: TRAIN [0][820/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00095)	Tok/s 56019 (52636)	Loss/tok 4.4433 (5.9536)	Learning Rate [0.00125]
13: TRAIN [0][820/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00096)	Tok/s 56854 (53631)	Loss/tok 4.3801 (5.9581)	Learning Rate [0.00125]
2: TRAIN [0][820/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00099)	Tok/s 55930 (52728)	Loss/tok 4.2422 (5.9593)	Learning Rate [0.00125]
12: TRAIN [0][820/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00096)	Tok/s 56791 (53543)	Loss/tok 4.3684 (5.9596)	Learning Rate [0.00125]
3: TRAIN [0][820/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00095)	Tok/s 55816 (52846)	Loss/tok 4.3320 (5.9593)	Learning Rate [0.00125]
11: TRAIN [0][820/3416]	Time 0.068 (0.058)	Data 0.00080 (0.00091)	Tok/s 56807 (53437)	Loss/tok 4.0938 (5.9575)	Learning Rate [0.00125]
10: TRAIN [0][820/3416]	Time 0.068 (0.058)	Data 0.00081 (0.00097)	Tok/s 56837 (53366)	Loss/tok 4.0963 (5.9622)	Learning Rate [0.00125]
8: TRAIN [0][820/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00093)	Tok/s 56796 (53229)	Loss/tok 4.4966 (5.9493)	Learning Rate [0.00125]
4: TRAIN [0][820/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00098)	Tok/s 56086 (52931)	Loss/tok 4.4173 (5.9580)	Learning Rate [0.00125]
6: TRAIN [0][820/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00094)	Tok/s 56678 (53073)	Loss/tok 4.1920 (5.9543)	Learning Rate [0.00125]
5: TRAIN [0][820/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00095)	Tok/s 56628 (53010)	Loss/tok 4.5455 (5.9637)	Learning Rate [0.00125]
7: TRAIN [0][820/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00096)	Tok/s 56688 (53147)	Loss/tok 4.4159 (5.9560)	Learning Rate [0.00125]
9: TRAIN [0][820/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00093)	Tok/s 56814 (53291)	Loss/tok 4.4215 (5.9559)	Learning Rate [0.00125]
8: Upscaling, new scale: 512.0
7: Upscaling, new scale: 512.0
6: Upscaling, new scale: 512.0
5: Upscaling, new scale: 512.0
4: Upscaling, new scale: 512.0
8: TRAIN [0][830/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00093)	Tok/s 33153 (53134)	Loss/tok 3.7443 (5.9327)	Learning Rate [0.00125]
6: TRAIN [0][830/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00094)	Tok/s 33081 (52976)	Loss/tok 3.6772 (5.9382)	Learning Rate [0.00125]
7: TRAIN [0][830/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00096)	Tok/s 33179 (53051)	Loss/tok 3.7061 (5.9399)	Learning Rate [0.00125]
10: Upscaling, new scale: 512.0
3: Upscaling, new scale: 512.0
11: Upscaling, new scale: 512.0
1: Upscaling, new scale: 512.0
2: Upscaling, new scale: 512.0
12: Upscaling, new scale: 512.0
5: TRAIN [0][830/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00095)	Tok/s 33017 (52914)	Loss/tok 3.6021 (5.9472)	Learning Rate [0.00125]
0: Upscaling, new scale: 512.0
4: TRAIN [0][830/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00098)	Tok/s 32957 (52834)	Loss/tok 3.8260 (5.9414)	Learning Rate [0.00125]
10: TRAIN [0][830/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00097)	Tok/s 34231 (53270)	Loss/tok 3.7262 (5.9457)	Learning Rate [0.00125]
3: TRAIN [0][830/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00095)	Tok/s 32880 (52749)	Loss/tok 3.6433 (5.9429)	Learning Rate [0.00125]
11: TRAIN [0][830/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00091)	Tok/s 34184 (53340)	Loss/tok 3.5599 (5.9413)	Learning Rate [0.00125]
1: TRAIN [0][830/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00095)	Tok/s 32752 (52539)	Loss/tok 3.6530 (5.9370)	Learning Rate [0.00125]
15: Upscaling, new scale: 512.0
14: Upscaling, new scale: 512.0
2: TRAIN [0][830/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00099)	Tok/s 32796 (52630)	Loss/tok 3.8212 (5.9430)	Learning Rate [0.00125]
12: TRAIN [0][830/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00096)	Tok/s 34087 (53447)	Loss/tok 3.7940 (5.9439)	Learning Rate [0.00125]
9: Upscaling, new scale: 512.0
0: TRAIN [0][830/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00098)	Tok/s 32661 (52461)	Loss/tok 3.7061 (5.9511)	Learning Rate [0.00125]
13: Upscaling, new scale: 512.0
15: TRAIN [0][830/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00094)	Tok/s 33923 (53757)	Loss/tok 3.5072 (5.9443)	Learning Rate [0.00125]
14: TRAIN [0][830/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00096)	Tok/s 33964 (53638)	Loss/tok 3.7009 (5.9426)	Learning Rate [0.00125]
9: TRAIN [0][830/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00093)	Tok/s 33204 (53195)	Loss/tok 3.6165 (5.9400)	Learning Rate [0.00125]
13: TRAIN [0][830/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00096)	Tok/s 33932 (53534)	Loss/tok 3.9445 (5.9422)	Learning Rate [0.00125]
4: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00098)	Tok/s 41081 (52730)	Loss/tok 4.0815 (5.9246)	Learning Rate [0.00125]
3: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00095)	Tok/s 41115 (52645)	Loss/tok 4.0232 (5.9264)	Learning Rate [0.00125]
2: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00099)	Tok/s 41099 (52528)	Loss/tok 3.6977 (5.9262)	Learning Rate [0.00125]
5: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00095)	Tok/s 40991 (52809)	Loss/tok 3.8068 (5.9299)	Learning Rate [0.00125]
6: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00094)	Tok/s 41058 (52873)	Loss/tok 3.8458 (5.9207)	Learning Rate [0.00125]
1: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00095)	Tok/s 41086 (52437)	Loss/tok 3.9217 (5.9200)	Learning Rate [0.00125]
0: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00098)	Tok/s 41044 (52361)	Loss/tok 3.7615 (5.9340)	Learning Rate [0.00125]
7: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00096)	Tok/s 41000 (52949)	Loss/tok 3.8249 (5.9232)	Learning Rate [0.00125]
8: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00093)	Tok/s 41008 (53031)	Loss/tok 3.9472 (5.9157)	Learning Rate [0.00125]
15: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00094)	Tok/s 42249 (53654)	Loss/tok 3.7186 (5.9278)	Learning Rate [0.00125]
14: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00096)	Tok/s 41986 (53535)	Loss/tok 4.0983 (5.9265)	Learning Rate [0.00125]
11: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00091)	Tok/s 40975 (53238)	Loss/tok 3.8229 (5.9239)	Learning Rate [0.00125]
10: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00096)	Tok/s 40998 (53168)	Loss/tok 3.6438 (5.9293)	Learning Rate [0.00125]
13: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00096)	Tok/s 40933 (53431)	Loss/tok 4.0307 (5.9258)	Learning Rate [0.00125]
12: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00125 (0.00096)	Tok/s 40948 (53345)	Loss/tok 3.8416 (5.9266)	Learning Rate [0.00125]
9: TRAIN [0][840/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 41004 (53092)	Loss/tok 3.6187 (5.9227)	Learning Rate [0.00125]
15: TRAIN [0][850/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00094)	Tok/s 81442 (53658)	Loss/tok 4.0577 (5.9059)	Learning Rate [0.00125]
14: TRAIN [0][850/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 80936 (53539)	Loss/tok 4.2059 (5.9054)	Learning Rate [0.00125]
0: TRAIN [0][850/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00098)	Tok/s 79225 (52369)	Loss/tok 4.3542 (5.9127)	Learning Rate [0.00125]
13: TRAIN [0][850/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 80866 (53436)	Loss/tok 4.3921 (5.9051)	Learning Rate [0.00125]
12: TRAIN [0][850/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00096)	Tok/s 80593 (53350)	Loss/tok 4.1071 (5.9057)	Learning Rate [0.00125]
11: TRAIN [0][850/3416]	Time 0.071 (0.058)	Data 0.00083 (0.00091)	Tok/s 80669 (53244)	Loss/tok 4.0896 (5.9034)	Learning Rate [0.00125]
1: TRAIN [0][850/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00095)	Tok/s 79213 (52444)	Loss/tok 4.2528 (5.8992)	Learning Rate [0.00125]
3: TRAIN [0][850/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00095)	Tok/s 80137 (52651)	Loss/tok 4.1351 (5.9048)	Learning Rate [0.00125]
4: TRAIN [0][850/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00098)	Tok/s 80106 (52737)	Loss/tok 4.1239 (5.9033)	Learning Rate [0.00125]
5: TRAIN [0][850/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00095)	Tok/s 80022 (52816)	Loss/tok 4.2016 (5.9077)	Learning Rate [0.00125]
10: TRAIN [0][850/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00096)	Tok/s 80590 (53175)	Loss/tok 4.1968 (5.9084)	Learning Rate [0.00125]
8: TRAIN [0][850/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00093)	Tok/s 79696 (53038)	Loss/tok 4.2574 (5.8939)	Learning Rate [0.00125]
6: TRAIN [0][850/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00094)	Tok/s 79804 (52880)	Loss/tok 4.2981 (5.9007)	Learning Rate [0.00125]
7: TRAIN [0][850/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00096)	Tok/s 79796 (52956)	Loss/tok 4.1397 (5.9015)	Learning Rate [0.00125]
2: TRAIN [0][850/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 79882 (52534)	Loss/tok 3.9701 (5.9048)	Learning Rate [0.00125]
9: TRAIN [0][850/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00093)	Tok/s 80451 (53099)	Loss/tok 4.0645 (5.9017)	Learning Rate [0.00125]
12: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 256.0
13: Gradient norm: inf
11: Skipped batch, new scale: 256.0
10: Gradient norm: inf
13: Skipped batch, new scale: 256.0
14: Gradient norm: inf
10: Skipped batch, new scale: 256.0
9: Gradient norm: inf
14: Skipped batch, new scale: 256.0
15: Gradient norm: inf
9: Skipped batch, new scale: 256.0
8: Gradient norm: inf
15: Skipped batch, new scale: 256.0
0: Gradient norm: inf
8: Skipped batch, new scale: 256.0
7: Gradient norm: inf
0: Skipped batch, new scale: 256.0
1: Gradient norm: inf
7: Skipped batch, new scale: 256.0
6: Gradient norm: inf
2: Gradient norm: inf
1: Skipped batch, new scale: 256.0
2: Skipped batch, new scale: 256.0
5: Gradient norm: inf
6: Skipped batch, new scale: 256.0
4: Gradient norm: inf
3: Gradient norm: inf
5: Skipped batch, new scale: 256.0
4: Skipped batch, new scale: 256.0
3: Skipped batch, new scale: 256.0
3: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00095)	Tok/s 50503 (52747)	Loss/tok 4.0480 (5.8808)	Learning Rate [0.00125]
2: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00100)	Tok/s 50384 (52632)	Loss/tok 3.8423 (5.8810)	Learning Rate [0.00125]
4: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00098)	Tok/s 50473 (52834)	Loss/tok 4.0304 (5.8797)	Learning Rate [0.00125]
1: TRAIN [0][860/3416]	Time 0.046 (0.058)	Data 0.00116 (0.00095)	Tok/s 51186 (52542)	Loss/tok 3.9511 (5.8747)	Learning Rate [0.00125]
0: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00098)	Tok/s 50372 (52466)	Loss/tok 4.0069 (5.8876)	Learning Rate [0.00125]
5: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00095)	Tok/s 50483 (52913)	Loss/tok 4.3498 (5.8848)	Learning Rate [0.00125]
6: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00094)	Tok/s 50483 (52976)	Loss/tok 3.7939 (5.8764)	Learning Rate [0.00125]
7: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00096)	Tok/s 50496 (53053)	Loss/tok 3.9167 (5.8767)	Learning Rate [0.00125]
15: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00094)	Tok/s 50389 (53755)	Loss/tok 3.8731 (5.8819)	Learning Rate [0.00125]
8: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00093)	Tok/s 50508 (53134)	Loss/tok 3.8719 (5.8690)	Learning Rate [0.00125]
14: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00096)	Tok/s 50387 (53635)	Loss/tok 3.9549 (5.8807)	Learning Rate [0.00125]
9: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00093)	Tok/s 50541 (53194)	Loss/tok 3.8181 (5.8777)	Learning Rate [0.00125]
10: TRAIN [0][860/3416]	Time 0.046 (0.058)	Data 0.00116 (0.00096)	Tok/s 51379 (53270)	Loss/tok 4.0817 (5.8835)	Learning Rate [0.00125]
13: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00096)	Tok/s 50380 (53532)	Loss/tok 3.8560 (5.8800)	Learning Rate [0.00125]
11: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00091)	Tok/s 50443 (53340)	Loss/tok 3.9600 (5.8804)	Learning Rate [0.00125]
12: TRAIN [0][860/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00096)	Tok/s 50384 (53446)	Loss/tok 4.0235 (5.8818)	Learning Rate [0.00125]
12: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00096)	Tok/s 49526 (53386)	Loss/tok 4.2808 (5.8649)	Learning Rate [0.00125]
13: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00096)	Tok/s 49610 (53470)	Loss/tok 4.0084 (5.8629)	Learning Rate [0.00125]
11: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00079 (0.00091)	Tok/s 49421 (53280)	Loss/tok 3.8771 (5.8629)	Learning Rate [0.00125]
14: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00096)	Tok/s 49608 (53572)	Loss/tok 3.8176 (5.8635)	Learning Rate [0.00125]
15: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00094)	Tok/s 49606 (53691)	Loss/tok 3.7775 (5.8642)	Learning Rate [0.00125]
10: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00096)	Tok/s 49291 (53210)	Loss/tok 4.0824 (5.8660)	Learning Rate [0.00125]
0: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00098)	Tok/s 49539 (52406)	Loss/tok 4.3043 (5.8699)	Learning Rate [0.00125]
1: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00095)	Tok/s 49467 (52482)	Loss/tok 3.7654 (5.8565)	Learning Rate [0.00125]
8: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00093)	Tok/s 49031 (53072)	Loss/tok 3.9462 (5.8518)	Learning Rate [0.00125]
2: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00100)	Tok/s 49338 (52572)	Loss/tok 4.0688 (5.8634)	Learning Rate [0.00125]
7: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00096)	Tok/s 49007 (52991)	Loss/tok 3.6914 (5.8591)	Learning Rate [0.00125]
6: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00094)	Tok/s 49066 (52915)	Loss/tok 4.0495 (5.8593)	Learning Rate [0.00125]
4: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00098)	Tok/s 49118 (52772)	Loss/tok 3.8637 (5.8626)	Learning Rate [0.00125]
5: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00095)	Tok/s 49066 (52850)	Loss/tok 3.9513 (5.8668)	Learning Rate [0.00125]
3: TRAIN [0][870/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00095)	Tok/s 49232 (52686)	Loss/tok 3.8367 (5.8639)	Learning Rate [0.00125]
9: TRAIN [0][870/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00093)	Tok/s 48176 (53132)	Loss/tok 3.9511 (5.8592)	Learning Rate [0.00125]
8: TRAIN [0][880/3416]	Time 0.067 (0.058)	Data 0.00106 (0.00093)	Tok/s 57848 (53112)	Loss/tok 4.1109 (5.8304)	Learning Rate [0.00125]
7: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00096)	Tok/s 57793 (53030)	Loss/tok 3.9998 (5.8390)	Learning Rate [0.00125]
6: TRAIN [0][880/3416]	Time 0.067 (0.058)	Data 0.00108 (0.00094)	Tok/s 57847 (52954)	Loss/tok 4.1777 (5.8377)	Learning Rate [0.00125]
10: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00120 (0.00096)	Tok/s 57627 (53248)	Loss/tok 4.1199 (5.8448)	Learning Rate [0.00125]
11: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00091)	Tok/s 57521 (53317)	Loss/tok 4.2292 (5.8432)	Learning Rate [0.00125]
5: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00095)	Tok/s 57329 (52888)	Loss/tok 4.5255 (5.8451)	Learning Rate [0.00125]
4: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00109 (0.00098)	Tok/s 56830 (52810)	Loss/tok 4.1424 (5.8412)	Learning Rate [0.00125]
9: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00107 (0.00093)	Tok/s 57726 (53173)	Loss/tok 4.3443 (5.8384)	Learning Rate [0.00125]
12: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00118 (0.00096)	Tok/s 57429 (53423)	Loss/tok 4.1475 (5.8437)	Learning Rate [0.00125]
3: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00095)	Tok/s 56696 (52725)	Loss/tok 4.3781 (5.8438)	Learning Rate [0.00125]
2: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00115 (0.00100)	Tok/s 56625 (52611)	Loss/tok 4.3516 (5.8432)	Learning Rate [0.00125]
1: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00095)	Tok/s 56551 (52523)	Loss/tok 4.5899 (5.8360)	Learning Rate [0.00125]
0: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00098)	Tok/s 56469 (52446)	Loss/tok 4.2224 (5.8491)	Learning Rate [0.00125]
14: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00117 (0.00096)	Tok/s 57373 (53610)	Loss/tok 4.2667 (5.8419)	Learning Rate [0.00125]
13: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00113 (0.00096)	Tok/s 57329 (53508)	Loss/tok 4.3180 (5.8419)	Learning Rate [0.00125]
15: TRAIN [0][880/3416]	Time 0.068 (0.058)	Data 0.00110 (0.00094)	Tok/s 57377 (53729)	Loss/tok 4.5798 (5.8428)	Learning Rate [0.00125]
14: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00096)	Tok/s 73847 (53680)	Loss/tok 4.2677 (5.8198)	Learning Rate [0.00125]
15: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00083 (0.00093)	Tok/s 73143 (53797)	Loss/tok 4.0472 (5.8206)	Learning Rate [0.00125]
13: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00096)	Tok/s 72992 (53578)	Loss/tok 4.2838 (5.8195)	Learning Rate [0.00125]
0: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00098)	Tok/s 71994 (52519)	Loss/tok 4.3408 (5.8280)	Learning Rate [0.00125]
12: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00096)	Tok/s 72992 (53493)	Loss/tok 4.1744 (5.8224)	Learning Rate [0.00125]
1: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00095)	Tok/s 71989 (52597)	Loss/tok 4.2406 (5.8144)	Learning Rate [0.00125]
11: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00084 (0.00091)	Tok/s 73020 (53387)	Loss/tok 4.1618 (5.8217)	Learning Rate [0.00125]
2: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00100)	Tok/s 71999 (52686)	Loss/tok 4.2008 (5.8207)	Learning Rate [0.00125]
10: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00099 (0.00096)	Tok/s 73002 (53318)	Loss/tok 4.2082 (5.8229)	Learning Rate [0.00125]
9: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00085 (0.00093)	Tok/s 72975 (53244)	Loss/tok 4.0412 (5.8159)	Learning Rate [0.00125]
3: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00083 (0.00095)	Tok/s 72065 (52799)	Loss/tok 4.1923 (5.8212)	Learning Rate [0.00125]
8: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00084 (0.00093)	Tok/s 73014 (53183)	Loss/tok 4.3296 (5.8088)	Learning Rate [0.00125]
4: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00102 (0.00098)	Tok/s 71997 (52883)	Loss/tok 4.0330 (5.8186)	Learning Rate [0.00125]
7: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00096)	Tok/s 73033 (53102)	Loss/tok 4.2754 (5.8172)	Learning Rate [0.00125]
6: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00094)	Tok/s 73683 (53027)	Loss/tok 4.1513 (5.8146)	Learning Rate [0.00125]
5: TRAIN [0][890/3416]	Time 0.071 (0.058)	Data 0.00088 (0.00095)	Tok/s 71997 (52961)	Loss/tok 4.0532 (5.8218)	Learning Rate [0.00125]
15: TRAIN [0][900/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00093)	Tok/s 46104 (53835)	Loss/tok 3.8470 (5.7991)	Learning Rate [0.00125]
0: TRAIN [0][900/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00098)	Tok/s 46083 (52560)	Loss/tok 3.7767 (5.8063)	Learning Rate [0.00125]
14: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00096)	Tok/s 45985 (53719)	Loss/tok 3.7881 (5.7996)	Learning Rate [0.00125]
1: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00095)	Tok/s 45989 (52639)	Loss/tok 3.6574 (5.7929)	Learning Rate [0.00125]
13: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00109 (0.00096)	Tok/s 45823 (53617)	Loss/tok 3.8162 (5.7982)	Learning Rate [0.00125]
2: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00100)	Tok/s 45858 (52726)	Loss/tok 3.7414 (5.8000)	Learning Rate [0.00125]
12: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00096)	Tok/s 45676 (53531)	Loss/tok 3.7490 (5.8003)	Learning Rate [0.00125]
11: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00091)	Tok/s 45564 (53425)	Loss/tok 3.6476 (5.8004)	Learning Rate [0.00125]
3: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00108 (0.00095)	Tok/s 45794 (52839)	Loss/tok 3.7619 (5.7985)	Learning Rate [0.00125]
4: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00105 (0.00098)	Tok/s 45652 (52923)	Loss/tok 3.9407 (5.7956)	Learning Rate [0.00125]
10: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00096)	Tok/s 45448 (53356)	Loss/tok 3.8022 (5.8020)	Learning Rate [0.00125]
6: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00094)	Tok/s 45448 (53066)	Loss/tok 3.8043 (5.7942)	Learning Rate [0.00125]
9: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00108 (0.00093)	Tok/s 45306 (53282)	Loss/tok 3.6039 (5.7936)	Learning Rate [0.00125]
8: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00093)	Tok/s 45318 (53222)	Loss/tok 3.9872 (5.7884)	Learning Rate [0.00125]
5: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00095)	Tok/s 45535 (53002)	Loss/tok 4.0321 (5.8011)	Learning Rate [0.00125]
7: TRAIN [0][900/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00096)	Tok/s 45352 (53141)	Loss/tok 3.8069 (5.7966)	Learning Rate [0.00125]
6: TRAIN [0][910/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00094)	Tok/s 53448 (53152)	Loss/tok 4.0783 (5.7716)	Learning Rate [0.00125]
5: TRAIN [0][910/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00095)	Tok/s 53489 (53088)	Loss/tok 4.2689 (5.7795)	Learning Rate [0.00125]
9: TRAIN [0][910/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00093)	Tok/s 53286 (53368)	Loss/tok 3.8775 (5.7706)	Learning Rate [0.00125]
3: TRAIN [0][910/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00095)	Tok/s 53466 (52927)	Loss/tok 3.7725 (5.7755)	Learning Rate [0.00125]
8: TRAIN [0][910/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00093)	Tok/s 53233 (53307)	Loss/tok 4.0002 (5.7674)	Learning Rate [0.00125]
12: TRAIN [0][910/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00096)	Tok/s 53140 (53616)	Loss/tok 4.1661 (5.7781)	Learning Rate [0.00125]
2: TRAIN [0][910/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00100)	Tok/s 53391 (52814)	Loss/tok 4.2546 (5.7785)	Learning Rate [0.00125]
4: TRAIN [0][910/3416]	Time 0.061 (0.058)	Data 0.00114 (0.00098)	Tok/s 53619 (53010)	Loss/tok 4.0780 (5.7739)	Learning Rate [0.00125]
7: TRAIN [0][910/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00095)	Tok/s 53338 (53226)	Loss/tok 4.1207 (5.7757)	Learning Rate [0.00125]
1: TRAIN [0][910/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00095)	Tok/s 53295 (52727)	Loss/tok 3.9177 (5.7715)	Learning Rate [0.00125]
10: TRAIN [0][910/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00096)	Tok/s 53023 (53442)	Loss/tok 4.3102 (5.7810)	Learning Rate [0.00125]
0: TRAIN [0][910/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00098)	Tok/s 53216 (52649)	Loss/tok 4.3368 (5.7841)	Learning Rate [0.00125]
15: TRAIN [0][910/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00093)	Tok/s 54212 (53920)	Loss/tok 4.1984 (5.7769)	Learning Rate [0.00125]
13: TRAIN [0][910/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00096)	Tok/s 53753 (53702)	Loss/tok 3.6561 (5.7756)	Learning Rate [0.00125]
14: TRAIN [0][910/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00096)	Tok/s 54117 (53805)	Loss/tok 4.0075 (5.7780)	Learning Rate [0.00125]
11: TRAIN [0][910/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00091)	Tok/s 52962 (53510)	Loss/tok 4.1920 (5.7785)	Learning Rate [0.00125]
15: TRAIN [0][920/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00093)	Tok/s 55113 (53931)	Loss/tok 4.1357 (5.7584)	Learning Rate [0.00125]
0: TRAIN [0][920/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00098)	Tok/s 55018 (52664)	Loss/tok 4.1043 (5.7667)	Learning Rate [0.00125]
14: TRAIN [0][920/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00096)	Tok/s 55133 (53816)	Loss/tok 4.3080 (5.7593)	Learning Rate [0.00125]
13: TRAIN [0][920/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00096)	Tok/s 55089 (53714)	Loss/tok 4.1991 (5.7575)	Learning Rate [0.00125]
1: TRAIN [0][920/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00095)	Tok/s 54924 (52742)	Loss/tok 4.3901 (5.7530)	Learning Rate [0.00125]
12: TRAIN [0][920/3416]	Time 0.065 (0.058)	Data 0.00086 (0.00096)	Tok/s 55073 (53628)	Loss/tok 4.4690 (5.7603)	Learning Rate [0.00125]
2: TRAIN [0][920/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00100)	Tok/s 54838 (52829)	Loss/tok 4.2344 (5.7602)	Learning Rate [0.00125]
4: TRAIN [0][920/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00098)	Tok/s 54799 (53022)	Loss/tok 3.9608 (5.7539)	Learning Rate [0.00125]
11: TRAIN [0][920/3416]	Time 0.065 (0.058)	Data 0.00078 (0.00091)	Tok/s 55007 (53521)	Loss/tok 4.1276 (5.7609)	Learning Rate [0.00125]
10: TRAIN [0][920/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00096)	Tok/s 54933 (53453)	Loss/tok 4.3995 (5.7631)	Learning Rate [0.00125]
8: TRAIN [0][920/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00093)	Tok/s 54888 (53317)	Loss/tok 4.0315 (5.7488)	Learning Rate [0.00125]
6: TRAIN [0][920/3416]	Time 0.065 (0.058)	Data 0.00076 (0.00094)	Tok/s 54773 (53163)	Loss/tok 4.4217 (5.7542)	Learning Rate [0.00125]
7: TRAIN [0][920/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00095)	Tok/s 54791 (53237)	Loss/tok 4.2407 (5.7566)	Learning Rate [0.00125]
5: TRAIN [0][920/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00095)	Tok/s 54705 (53099)	Loss/tok 4.4186 (5.7606)	Learning Rate [0.00125]
3: TRAIN [0][920/3416]	Time 0.066 (0.058)	Data 0.00100 (0.00095)	Tok/s 53995 (52939)	Loss/tok 4.0311 (5.7570)	Learning Rate [0.00125]
9: TRAIN [0][920/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 52629 (53376)	Loss/tok 4.2054 (5.7525)	Learning Rate [0.00125]
11: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00091)	Tok/s 67620 (53519)	Loss/tok 4.2661 (5.7429)	Learning Rate [0.00125]
15: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 67731 (53929)	Loss/tok 4.0180 (5.7405)	Learning Rate [0.00125]
1: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00095)	Tok/s 66682 (52728)	Loss/tok 4.2365 (5.7349)	Learning Rate [0.00125]
12: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 67783 (53625)	Loss/tok 4.3583 (5.7428)	Learning Rate [0.00125]
13: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00096)	Tok/s 67796 (53711)	Loss/tok 4.1719 (5.7397)	Learning Rate [0.00125]
9: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 66878 (53376)	Loss/tok 4.2621 (5.7346)	Learning Rate [0.00125]
14: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00096)	Tok/s 67780 (53815)	Loss/tok 4.3563 (5.7418)	Learning Rate [0.00125]
10: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 67709 (53449)	Loss/tok 4.2726 (5.7457)	Learning Rate [0.00125]
8: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 66652 (53313)	Loss/tok 4.2242 (5.7306)	Learning Rate [0.00125]
7: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00095)	Tok/s 66590 (53233)	Loss/tok 4.3027 (5.7381)	Learning Rate [0.00125]
4: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 66399 (53014)	Loss/tok 4.2503 (5.7368)	Learning Rate [0.00125]
2: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00100)	Tok/s 66516 (52817)	Loss/tok 4.3802 (5.7420)	Learning Rate [0.00125]
5: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00095)	Tok/s 66419 (53092)	Loss/tok 4.2083 (5.7416)	Learning Rate [0.00125]
3: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00095)	Tok/s 66436 (52930)	Loss/tok 4.3795 (5.7390)	Learning Rate [0.00125]
0: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00098)	Tok/s 66692 (52647)	Loss/tok 4.1872 (5.7489)	Learning Rate [0.00125]
6: TRAIN [0][930/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00094)	Tok/s 66417 (53157)	Loss/tok 4.5176 (5.7371)	Learning Rate [0.00125]
6: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00094)	Tok/s 32872 (53111)	Loss/tok 3.5780 (5.7220)	Learning Rate [0.00125]
7: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00095)	Tok/s 32851 (53186)	Loss/tok 3.6316 (5.7225)	Learning Rate [0.00125]
8: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00093)	Tok/s 32736 (53266)	Loss/tok 3.3598 (5.7151)	Learning Rate [0.00125]
9: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00078 (0.00093)	Tok/s 32690 (53328)	Loss/tok 3.4513 (5.7194)	Learning Rate [0.00125]
1: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00095)	Tok/s 32722 (52685)	Loss/tok 3.7908 (5.7193)	Learning Rate [0.00125]
4: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00098)	Tok/s 32830 (52968)	Loss/tok 3.5587 (5.7209)	Learning Rate [0.00125]
2: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00100)	Tok/s 32774 (52774)	Loss/tok 3.6558 (5.7267)	Learning Rate [0.00125]
10: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00081 (0.00096)	Tok/s 32620 (53401)	Loss/tok 3.5470 (5.7299)	Learning Rate [0.00125]
0: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00108 (0.00098)	Tok/s 32673 (52604)	Loss/tok 3.4254 (5.7326)	Learning Rate [0.00125]
5: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00095)	Tok/s 32814 (53045)	Loss/tok 3.3736 (5.7263)	Learning Rate [0.00125]
3: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00094)	Tok/s 32802 (52885)	Loss/tok 3.2087 (5.7238)	Learning Rate [0.00125]
11: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00091)	Tok/s 32535 (53471)	Loss/tok 3.5885 (5.7269)	Learning Rate [0.00125]
15: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00093)	Tok/s 34014 (53880)	Loss/tok 3.2282 (5.7255)	Learning Rate [0.00125]
12: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00096)	Tok/s 32800 (53577)	Loss/tok 3.6136 (5.7269)	Learning Rate [0.00125]
13: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00096)	Tok/s 33884 (53663)	Loss/tok 3.7171 (5.7249)	Learning Rate [0.00125]
14: TRAIN [0][940/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00096)	Tok/s 33925 (53767)	Loss/tok 3.6839 (5.7273)	Learning Rate [0.00125]
11: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00091)	Tok/s 54338 (53499)	Loss/tok 3.9906 (5.7080)	Learning Rate [0.00125]
12: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00096)	Tok/s 54326 (53605)	Loss/tok 4.2194 (5.7087)	Learning Rate [0.00125]
9: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00093)	Tok/s 54383 (53357)	Loss/tok 4.3643 (5.7004)	Learning Rate [0.00125]
10: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00096)	Tok/s 54351 (53429)	Loss/tok 4.0499 (5.7114)	Learning Rate [0.00125]
13: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00096)	Tok/s 54277 (53692)	Loss/tok 3.9756 (5.7056)	Learning Rate [0.00125]
8: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00093)	Tok/s 54347 (53294)	Loss/tok 4.0234 (5.6960)	Learning Rate [0.00125]
7: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00095)	Tok/s 54355 (53215)	Loss/tok 4.0148 (5.7041)	Learning Rate [0.00125]
6: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00094)	Tok/s 54309 (53140)	Loss/tok 4.1466 (5.7026)	Learning Rate [0.00125]
14: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00096)	Tok/s 54403 (53794)	Loss/tok 4.5823 (5.7092)	Learning Rate [0.00125]
15: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00093)	Tok/s 55202 (53909)	Loss/tok 4.3664 (5.7072)	Learning Rate [0.00125]
5: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00095)	Tok/s 54402 (53076)	Loss/tok 4.1865 (5.7069)	Learning Rate [0.00125]
0: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00110 (0.00098)	Tok/s 54236 (52635)	Loss/tok 4.1271 (5.7139)	Learning Rate [0.00125]
4: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00098)	Tok/s 54318 (52999)	Loss/tok 4.2924 (5.7021)	Learning Rate [0.00125]
1: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00095)	Tok/s 54261 (52717)	Loss/tok 3.9935 (5.6996)	Learning Rate [0.00125]
2: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00100)	Tok/s 54276 (52806)	Loss/tok 4.3288 (5.7078)	Learning Rate [0.00125]
3: TRAIN [0][950/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00094)	Tok/s 54291 (52916)	Loss/tok 4.2739 (5.7052)	Learning Rate [0.00125]
2: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00100)	Tok/s 64212 (52809)	Loss/tok 4.1379 (5.6890)	Learning Rate [0.00125]
3: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00078 (0.00094)	Tok/s 64285 (52919)	Loss/tok 4.4849 (5.6879)	Learning Rate [0.00125]
4: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 64298 (53004)	Loss/tok 4.4413 (5.6834)	Learning Rate [0.00125]
1: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00095)	Tok/s 64058 (52717)	Loss/tok 4.0979 (5.6808)	Learning Rate [0.00125]
0: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 64062 (52631)	Loss/tok 4.3791 (5.6951)	Learning Rate [0.00125]
5: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00095)	Tok/s 64285 (53083)	Loss/tok 4.3791 (5.6878)	Learning Rate [0.00125]
15: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00093)	Tok/s 65012 (53924)	Loss/tok 4.2989 (5.6889)	Learning Rate [0.00125]
7: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00095)	Tok/s 64263 (53224)	Loss/tok 4.2944 (5.6856)	Learning Rate [0.00125]
14: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 64908 (53808)	Loss/tok 4.1878 (5.6904)	Learning Rate [0.00125]
8: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 64276 (53305)	Loss/tok 4.0785 (5.6768)	Learning Rate [0.00125]
13: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 64108 (53702)	Loss/tok 4.1031 (5.6862)	Learning Rate [0.00125]
9: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 64223 (53367)	Loss/tok 4.2598 (5.6814)	Learning Rate [0.00125]
12: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00096)	Tok/s 64072 (53616)	Loss/tok 4.6837 (5.6900)	Learning Rate [0.00125]
10: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 64115 (53439)	Loss/tok 4.2929 (5.6917)	Learning Rate [0.00125]
11: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00091)	Tok/s 64069 (53509)	Loss/tok 4.1293 (5.6898)	Learning Rate [0.00125]
6: TRAIN [0][960/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00094)	Tok/s 64270 (53148)	Loss/tok 4.1909 (5.6844)	Learning Rate [0.00125]
5: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00095)	Tok/s 61009 (53038)	Loss/tok 4.3478 (5.6726)	Learning Rate [0.00125]
4: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 60883 (52955)	Loss/tok 4.1844 (5.6683)	Learning Rate [0.00125]
1: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00095)	Tok/s 60790 (52663)	Loss/tok 4.3003 (5.6658)	Learning Rate [0.00125]
3: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00094)	Tok/s 60797 (52869)	Loss/tok 4.4881 (5.6726)	Learning Rate [0.00125]
7: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00095)	Tok/s 61016 (53180)	Loss/tok 4.2936 (5.6700)	Learning Rate [0.00125]
2: TRAIN [0][970/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00100)	Tok/s 60686 (52758)	Loss/tok 4.3321 (5.6745)	Learning Rate [0.00125]
8: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00093)	Tok/s 60998 (53262)	Loss/tok 4.4027 (5.6613)	Learning Rate [0.00125]
11: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 60975 (53465)	Loss/tok 4.2535 (5.6742)	Learning Rate [0.00125]
9: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 60980 (53325)	Loss/tok 4.3161 (5.6661)	Learning Rate [0.00125]
0: TRAIN [0][970/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00098)	Tok/s 60718 (52575)	Loss/tok 4.2462 (5.6802)	Learning Rate [0.00125]
12: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 60867 (53572)	Loss/tok 4.3557 (5.6742)	Learning Rate [0.00125]
10: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 60898 (53396)	Loss/tok 4.3548 (5.6767)	Learning Rate [0.00125]
15: TRAIN [0][970/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 60730 (53882)	Loss/tok 4.1573 (5.6738)	Learning Rate [0.00125]
6: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00094)	Tok/s 61060 (53104)	Loss/tok 4.0351 (5.6684)	Learning Rate [0.00125]
13: TRAIN [0][970/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00096)	Tok/s 60751 (53659)	Loss/tok 4.4432 (5.6707)	Learning Rate [0.00125]
14: TRAIN [0][970/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00096)	Tok/s 60708 (53764)	Loss/tok 4.0803 (5.6749)	Learning Rate [0.00125]
6: Upscaling, new scale: 512.0
7: Upscaling, new scale: 512.0
5: Upscaling, new scale: 512.0
4: Upscaling, new scale: 512.0
8: Upscaling, new scale: 512.0
3: Upscaling, new scale: 512.0
9: Upscaling, new scale: 512.0
2: Upscaling, new scale: 512.0
1: Upscaling, new scale: 512.0
10: Upscaling, new scale: 512.0
11: Upscaling, new scale: 512.0
0: Upscaling, new scale: 512.0
12: Upscaling, new scale: 512.0
15: Upscaling, new scale: 512.0
13: Upscaling, new scale: 512.0
14: Upscaling, new scale: 512.0
6: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00094 (0.00094)	Tok/s 27907 (53079)	Loss/tok 2.9606 (5.6518)	Learning Rate [0.00125]
7: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00095 (0.00095)	Tok/s 29388 (53157)	Loss/tok 2.8166 (5.6549)	Learning Rate [0.00125]
8: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00090 (0.00093)	Tok/s 29391 (53238)	Loss/tok 2.9481 (5.6457)	Learning Rate [0.00125]
4: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00102 (0.00098)	Tok/s 27635 (52929)	Loss/tok 2.7368 (5.6523)	Learning Rate [0.00125]
5: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00091 (0.00095)	Tok/s 27613 (53012)	Loss/tok 2.8074 (5.6553)	Learning Rate [0.00125]
9: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00102 (0.00093)	Tok/s 29413 (53301)	Loss/tok 2.8640 (5.6500)	Learning Rate [0.00125]
3: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00088 (0.00094)	Tok/s 27428 (52842)	Loss/tok 3.1548 (5.6557)	Learning Rate [0.00125]
1: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00098 (0.00095)	Tok/s 25904 (52636)	Loss/tok 2.7988 (5.6501)	Learning Rate [0.00125]
10: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00103 (0.00096)	Tok/s 29397 (53372)	Loss/tok 2.8149 (5.6596)	Learning Rate [0.00125]
2: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00097 (0.00100)	Tok/s 25870 (52731)	Loss/tok 2.5174 (5.6586)	Learning Rate [0.00125]
11: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00087 (0.00091)	Tok/s 29353 (53440)	Loss/tok 2.9463 (5.6584)	Learning Rate [0.00125]
12: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00091 (0.00096)	Tok/s 29379 (53546)	Loss/tok 2.7932 (5.6584)	Learning Rate [0.00125]
13: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00108 (0.00096)	Tok/s 30458 (53636)	Loss/tok 2.9825 (5.6545)	Learning Rate [0.00125]
0: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00104 (0.00098)	Tok/s 25865 (52548)	Loss/tok 2.5610 (5.6634)	Learning Rate [0.00125]
14: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00111 (0.00096)	Tok/s 31202 (53742)	Loss/tok 2.8123 (5.6585)	Learning Rate [0.00125]
15: TRAIN [0][980/3416]	Time 0.037 (0.058)	Data 0.00093 (0.00093)	Tok/s 31079 (53859)	Loss/tok 2.9746 (5.6568)	Learning Rate [0.00125]
11: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00091)	Tok/s 35935 (53428)	Loss/tok 3.7003 (5.6426)	Learning Rate [0.00125]
9: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00093)	Tok/s 35913 (53289)	Loss/tok 3.6927 (5.6341)	Learning Rate [0.00125]
10: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00096)	Tok/s 36017 (53360)	Loss/tok 3.8220 (5.6440)	Learning Rate [0.00125]
8: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00093)	Tok/s 35865 (53226)	Loss/tok 3.6497 (5.6310)	Learning Rate [0.00125]
7: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00095)	Tok/s 35754 (53146)	Loss/tok 3.6669 (5.6398)	Learning Rate [0.00125]
13: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00096)	Tok/s 35811 (53623)	Loss/tok 3.7349 (5.6389)	Learning Rate [0.00125]
14: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00096)	Tok/s 35740 (53728)	Loss/tok 3.5033 (5.6428)	Learning Rate [0.00125]
6: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00082 (0.00094)	Tok/s 35630 (53069)	Loss/tok 3.5335 (5.6364)	Learning Rate [0.00125]
5: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00095)	Tok/s 35615 (53003)	Loss/tok 3.5410 (5.6398)	Learning Rate [0.00125]
15: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00093)	Tok/s 35665 (53845)	Loss/tok 3.6356 (5.6406)	Learning Rate [0.00125]
0: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00098)	Tok/s 34378 (52540)	Loss/tok 3.7241 (5.6474)	Learning Rate [0.00125]
1: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00095)	Tok/s 34741 (52629)	Loss/tok 3.6082 (5.6343)	Learning Rate [0.00125]
12: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00096)	Tok/s 35841 (53533)	Loss/tok 3.7563 (5.6439)	Learning Rate [0.00125]
2: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00100)	Tok/s 35503 (52723)	Loss/tok 3.6994 (5.6426)	Learning Rate [0.00125]
4: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00109 (0.00098)	Tok/s 35447 (52921)	Loss/tok 3.5058 (5.6364)	Learning Rate [0.00125]
3: TRAIN [0][990/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00094)	Tok/s 36021 (52834)	Loss/tok 3.7260 (5.6407)	Learning Rate [0.00125]
1: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00084 (0.00095)	Tok/s 50577 (52660)	Loss/tok 4.0386 (5.6175)	Learning Rate [0.00125]
0: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00109 (0.00098)	Tok/s 50492 (52570)	Loss/tok 3.9002 (5.6303)	Learning Rate [0.00125]
4: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00104 (0.00098)	Tok/s 50706 (52949)	Loss/tok 3.8399 (5.6195)	Learning Rate [0.00125]
5: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00099 (0.00095)	Tok/s 50633 (53031)	Loss/tok 4.0138 (5.6227)	Learning Rate [0.00125]
3: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00103 (0.00094)	Tok/s 50669 (52864)	Loss/tok 3.9199 (5.6237)	Learning Rate [0.00125]
6: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00081 (0.00094)	Tok/s 50414 (53097)	Loss/tok 3.8467 (5.6184)	Learning Rate [0.00125]
2: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00100)	Tok/s 50595 (52753)	Loss/tok 4.2953 (5.6247)	Learning Rate [0.00125]
15: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00093)	Tok/s 51667 (53872)	Loss/tok 3.7435 (5.6236)	Learning Rate [0.00125]
7: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00095)	Tok/s 50393 (53173)	Loss/tok 3.9565 (5.6231)	Learning Rate [0.00125]
11: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00091)	Tok/s 50909 (53455)	Loss/tok 4.2046 (5.6261)	Learning Rate [0.00125]
14: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00105 (0.00096)	Tok/s 51438 (53755)	Loss/tok 4.1497 (5.6261)	Learning Rate [0.00125]
8: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00086 (0.00093)	Tok/s 50312 (53254)	Loss/tok 3.9597 (5.6131)	Learning Rate [0.00125]
9: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00093)	Tok/s 50232 (53317)	Loss/tok 4.0324 (5.6179)	Learning Rate [0.00125]
12: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00086 (0.00096)	Tok/s 51140 (53560)	Loss/tok 3.7969 (5.6263)	Learning Rate [0.00125]
10: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00100 (0.00096)	Tok/s 50164 (53387)	Loss/tok 3.9419 (5.6266)	Learning Rate [0.00125]
13: TRAIN [0][1000/3416]	Time 0.056 (0.058)	Data 0.00104 (0.00096)	Tok/s 51363 (53650)	Loss/tok 4.1692 (5.6221)	Learning Rate [0.00125]
3: TRAIN [0][1010/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00094)	Tok/s 52085 (52846)	Loss/tok 3.9056 (5.6085)	Learning Rate [0.00125]
4: TRAIN [0][1010/3416]	Time 0.049 (0.058)	Data 0.00102 (0.00098)	Tok/s 51821 (52932)	Loss/tok 3.9714 (5.6045)	Learning Rate [0.00125]
2: TRAIN [0][1010/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00100)	Tok/s 51895 (52736)	Loss/tok 4.0139 (5.6096)	Learning Rate [0.00125]
1: TRAIN [0][1010/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00095)	Tok/s 51842 (52644)	Loss/tok 4.1718 (5.6019)	Learning Rate [0.00125]
0: TRAIN [0][1010/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00098)	Tok/s 51746 (52556)	Loss/tok 3.7155 (5.6147)	Learning Rate [0.00125]
5: TRAIN [0][1010/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00095)	Tok/s 51690 (53014)	Loss/tok 3.8703 (5.6079)	Learning Rate [0.00125]
6: TRAIN [0][1010/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00094)	Tok/s 51576 (53079)	Loss/tok 3.8796 (5.6035)	Learning Rate [0.00125]
15: TRAIN [0][1010/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00093)	Tok/s 52924 (53854)	Loss/tok 3.8773 (5.6078)	Learning Rate [0.00125]
7: TRAIN [0][1010/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00095)	Tok/s 51445 (53155)	Loss/tok 4.0217 (5.6080)	Learning Rate [0.00125]
14: TRAIN [0][1010/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00096)	Tok/s 52822 (53737)	Loss/tok 3.9804 (5.6111)	Learning Rate [0.00125]
8: TRAIN [0][1010/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00093)	Tok/s 51316 (53234)	Loss/tok 3.7723 (5.5985)	Learning Rate [0.00125]
13: TRAIN [0][1010/3416]	Time 0.050 (0.058)	Data 0.00118 (0.00096)	Tok/s 51680 (53631)	Loss/tok 3.8989 (5.6078)	Learning Rate [0.00125]
9: TRAIN [0][1010/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00093)	Tok/s 51196 (53297)	Loss/tok 4.0215 (5.6026)	Learning Rate [0.00125]
12: TRAIN [0][1010/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00096)	Tok/s 51294 (53541)	Loss/tok 3.8855 (5.6119)	Learning Rate [0.00125]
11: TRAIN [0][1010/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00091)	Tok/s 51209 (53436)	Loss/tok 4.2582 (5.6112)	Learning Rate [0.00125]
10: TRAIN [0][1010/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00096)	Tok/s 51114 (53368)	Loss/tok 4.1771 (5.6120)	Learning Rate [0.00125]
12: Gradient norm: inf
13: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 256.0
14: Gradient norm: inf
10: Gradient norm: inf
13: Skipped batch, new scale: 256.0
11: Skipped batch, new scale: 256.0
9: Gradient norm: inf
15: Gradient norm: inf
14: Skipped batch, new scale: 256.0
10: Skipped batch, new scale: 256.0
8: Gradient norm: inf
0: Gradient norm: inf
15: Skipped batch, new scale: 256.0
9: Skipped batch, new scale: 256.0
8: Skipped batch, new scale: 256.0
7: Gradient norm: inf
0: Skipped batch, new scale: 256.0
1: Gradient norm: inf
6: Gradient norm: inf
7: Skipped batch, new scale: 256.0
1: Skipped batch, new scale: 256.0
2: Gradient norm: inf
6: Skipped batch, new scale: 256.0
5: Gradient norm: inf
4: Gradient norm: inf
2: Skipped batch, new scale: 256.0
3: Gradient norm: inf
4: Skipped batch, new scale: 256.0
5: Skipped batch, new scale: 256.0
3: Skipped batch, new scale: 256.0
7: TRAIN [0][1020/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00095)	Tok/s 77324 (53258)	Loss/tok 3.9590 (5.5871)	Learning Rate [0.00125]
8: TRAIN [0][1020/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 77226 (53338)	Loss/tok 4.0215 (5.5789)	Learning Rate [0.00125]
6: TRAIN [0][1020/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 77372 (53182)	Loss/tok 4.1084 (5.5835)	Learning Rate [0.00125]
11: TRAIN [0][1020/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 77946 (53541)	Loss/tok 4.1383 (5.5911)	Learning Rate [0.00125]
12: TRAIN [0][1020/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00096)	Tok/s 78059 (53646)	Loss/tok 4.0236 (5.5908)	Learning Rate [0.00125]
0: TRAIN [0][1020/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00098)	Tok/s 76413 (52658)	Loss/tok 4.0035 (5.5930)	Learning Rate [0.00125]
13: TRAIN [0][1020/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00096)	Tok/s 78054 (53736)	Loss/tok 4.1991 (5.5877)	Learning Rate [0.00125]
9: TRAIN [0][1020/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 77132 (53400)	Loss/tok 4.1129 (5.5827)	Learning Rate [0.00125]
5: TRAIN [0][1020/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00095)	Tok/s 77395 (53116)	Loss/tok 4.1160 (5.5874)	Learning Rate [0.00125]
15: TRAIN [0][1020/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 78206 (53961)	Loss/tok 4.0334 (5.5876)	Learning Rate [0.00125]
4: TRAIN [0][1020/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 77365 (53035)	Loss/tok 4.2159 (5.5839)	Learning Rate [0.00125]
2: TRAIN [0][1020/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 76555 (52838)	Loss/tok 4.2021 (5.5892)	Learning Rate [0.00125]
1: TRAIN [0][1020/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00095)	Tok/s 76371 (52746)	Loss/tok 4.1521 (5.5818)	Learning Rate [0.00125]
3: TRAIN [0][1020/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00094)	Tok/s 77418 (52948)	Loss/tok 3.8483 (5.5874)	Learning Rate [0.00125]
14: TRAIN [0][1020/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00096)	Tok/s 78080 (53842)	Loss/tok 3.9302 (5.5907)	Learning Rate [0.00125]
10: TRAIN [0][1020/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00096)	Tok/s 77021 (53472)	Loss/tok 4.1445 (5.5922)	Learning Rate [0.00125]
6: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00094)	Tok/s 32060 (53212)	Loss/tok 3.5279 (5.5664)	Learning Rate [0.00125]
7: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00095)	Tok/s 32081 (53289)	Loss/tok 3.3422 (5.5700)	Learning Rate [0.00125]
5: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00095)	Tok/s 32034 (53146)	Loss/tok 3.4653 (5.5714)	Learning Rate [0.00125]
8: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00093)	Tok/s 32057 (53368)	Loss/tok 3.4439 (5.5611)	Learning Rate [0.00125]
4: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00098)	Tok/s 32061 (53065)	Loss/tok 3.6381 (5.5658)	Learning Rate [0.00125]
3: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00106 (0.00094)	Tok/s 32048 (52980)	Loss/tok 3.1008 (5.5711)	Learning Rate [0.00125]
9: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00093)	Tok/s 32033 (53431)	Loss/tok 3.3374 (5.5668)	Learning Rate [0.00125]
1: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00095)	Tok/s 32039 (52779)	Loss/tok 3.6673 (5.5654)	Learning Rate [0.00125]
10: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00107 (0.00096)	Tok/s 32040 (53503)	Loss/tok 3.4064 (5.5755)	Learning Rate [0.00125]
0: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00114 (0.00098)	Tok/s 32041 (52691)	Loss/tok 3.5694 (5.5761)	Learning Rate [0.00125]
11: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00091)	Tok/s 32517 (53572)	Loss/tok 3.5971 (5.5744)	Learning Rate [0.00125]
2: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00100)	Tok/s 32033 (52869)	Loss/tok 3.3695 (5.5726)	Learning Rate [0.00125]
15: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00093)	Tok/s 33387 (53989)	Loss/tok 3.5602 (5.5705)	Learning Rate [0.00125]
12: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00096)	Tok/s 33370 (53676)	Loss/tok 3.5289 (5.5749)	Learning Rate [0.00125]
13: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00110 (0.00096)	Tok/s 33397 (53766)	Loss/tok 3.5464 (5.5702)	Learning Rate [0.00125]
14: TRAIN [0][1030/3416]	Time 0.048 (0.058)	Data 0.00109 (0.00096)	Tok/s 33386 (53872)	Loss/tok 3.1918 (5.5743)	Learning Rate [0.00125]
10: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00107 (0.00096)	Tok/s 37901 (53517)	Loss/tok 3.7552 (5.5589)	Learning Rate [0.00125]
9: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00093)	Tok/s 37886 (53445)	Loss/tok 3.6480 (5.5506)	Learning Rate [0.00125]
11: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00091)	Tok/s 37846 (53587)	Loss/tok 3.9434 (5.5581)	Learning Rate [0.00125]
12: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00096)	Tok/s 37762 (53693)	Loss/tok 3.4977 (5.5589)	Learning Rate [0.00125]
13: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00096)	Tok/s 37735 (53783)	Loss/tok 3.4565 (5.5533)	Learning Rate [0.00125]
15: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00093)	Tok/s 37591 (54006)	Loss/tok 3.6052 (5.5541)	Learning Rate [0.00125]
7: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00095)	Tok/s 37755 (53304)	Loss/tok 3.6279 (5.5543)	Learning Rate [0.00125]
6: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00094)	Tok/s 37706 (53227)	Loss/tok 3.5899 (5.5502)	Learning Rate [0.00125]
4: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00098)	Tok/s 37606 (53081)	Loss/tok 3.8217 (5.5500)	Learning Rate [0.00125]
14: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00096)	Tok/s 37749 (53889)	Loss/tok 3.5290 (5.5576)	Learning Rate [0.00125]
8: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00093)	Tok/s 37853 (53383)	Loss/tok 3.7283 (5.5449)	Learning Rate [0.00125]
3: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00094)	Tok/s 36420 (52994)	Loss/tok 3.6659 (5.5546)	Learning Rate [0.00125]
5: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00095)	Tok/s 37631 (53162)	Loss/tok 3.6838 (5.5553)	Learning Rate [0.00125]
0: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00098)	Tok/s 36210 (52705)	Loss/tok 3.8678 (5.5606)	Learning Rate [0.00125]
2: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00100)	Tok/s 36187 (52882)	Loss/tok 3.7713 (5.5562)	Learning Rate [0.00125]
1: TRAIN [0][1040/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00095)	Tok/s 36117 (52792)	Loss/tok 3.5157 (5.5493)	Learning Rate [0.00125]
12: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00096)	Tok/s 32388 (53745)	Loss/tok 3.1417 (5.5413)	Learning Rate [0.00125]
13: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00096)	Tok/s 32902 (53836)	Loss/tok 3.2701 (5.5362)	Learning Rate [0.00125]
11: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00091)	Tok/s 31596 (53638)	Loss/tok 3.4123 (5.5407)	Learning Rate [0.00125]
10: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00096)	Tok/s 31639 (53569)	Loss/tok 3.3321 (5.5410)	Learning Rate [0.00125]
14: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00096)	Tok/s 32800 (53943)	Loss/tok 3.4211 (5.5400)	Learning Rate [0.00125]
9: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00093)	Tok/s 31590 (53495)	Loss/tok 3.3236 (5.5335)	Learning Rate [0.00125]
15: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00093)	Tok/s 32727 (54059)	Loss/tok 3.5310 (5.5366)	Learning Rate [0.00125]
8: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00093)	Tok/s 31599 (53434)	Loss/tok 3.3936 (5.5278)	Learning Rate [0.00125]
0: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00113 (0.00098)	Tok/s 31351 (52760)	Loss/tok 3.2713 (5.5431)	Learning Rate [0.00125]
1: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00095)	Tok/s 31366 (52846)	Loss/tok 3.5154 (5.5323)	Learning Rate [0.00125]
7: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00095)	Tok/s 31580 (53356)	Loss/tok 3.5998 (5.5359)	Learning Rate [0.00125]
6: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00094)	Tok/s 31577 (53280)	Loss/tok 3.0967 (5.5323)	Learning Rate [0.00125]
2: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00100)	Tok/s 31362 (52936)	Loss/tok 3.3597 (5.5384)	Learning Rate [0.00125]
4: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00098)	Tok/s 31437 (53134)	Loss/tok 3.5944 (5.5326)	Learning Rate [0.00125]
3: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00094)	Tok/s 31383 (53047)	Loss/tok 3.2811 (5.5375)	Learning Rate [0.00125]
5: TRAIN [0][1050/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00095)	Tok/s 31481 (53215)	Loss/tok 3.4989 (5.5380)	Learning Rate [0.00125]
6: TRAIN [0][1060/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 77084 (53298)	Loss/tok 3.9502 (5.5177)	Learning Rate [0.00125]
9: TRAIN [0][1060/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 77557 (53511)	Loss/tok 4.0103 (5.5192)	Learning Rate [0.00125]
0: TRAIN [0][1060/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 76374 (52779)	Loss/tok 4.0828 (5.5276)	Learning Rate [0.00125]
1: TRAIN [0][1060/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00095)	Tok/s 76747 (52865)	Loss/tok 4.0721 (5.5177)	Learning Rate [0.00125]
7: TRAIN [0][1060/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00095)	Tok/s 77126 (53373)	Loss/tok 4.1488 (5.5207)	Learning Rate [0.00125]
15: TRAIN [0][1060/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 78281 (54075)	Loss/tok 3.9079 (5.5208)	Learning Rate [0.00125]
8: TRAIN [0][1060/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00093)	Tok/s 77133 (53450)	Loss/tok 4.2538 (5.5128)	Learning Rate [0.00125]
5: TRAIN [0][1060/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00095)	Tok/s 76974 (53233)	Loss/tok 3.9727 (5.5230)	Learning Rate [0.00125]
4: TRAIN [0][1060/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 76961 (53153)	Loss/tok 4.3062 (5.5173)	Learning Rate [0.00125]
14: TRAIN [0][1060/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 78297 (53959)	Loss/tok 3.9147 (5.5246)	Learning Rate [0.00125]
10: TRAIN [0][1060/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 78154 (53586)	Loss/tok 4.0672 (5.5260)	Learning Rate [0.00125]
3: TRAIN [0][1060/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00094)	Tok/s 77009 (53066)	Loss/tok 4.1034 (5.5220)	Learning Rate [0.00125]
2: TRAIN [0][1060/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00100)	Tok/s 77080 (52956)	Loss/tok 4.0166 (5.5238)	Learning Rate [0.00125]
13: TRAIN [0][1060/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 78276 (53854)	Loss/tok 4.0621 (5.5209)	Learning Rate [0.00125]
11: TRAIN [0][1060/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 78179 (53657)	Loss/tok 3.8722 (5.5251)	Learning Rate [0.00125]
12: TRAIN [0][1060/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 78259 (53763)	Loss/tok 4.0752 (5.5263)	Learning Rate [0.00125]
0: TRAIN [0][1070/3416]	Time 0.053 (0.058)	Data 0.00082 (0.00098)	Tok/s 51701 (52828)	Loss/tok 3.7887 (5.5113)	Learning Rate [0.00125]
1: TRAIN [0][1070/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00095)	Tok/s 51615 (52914)	Loss/tok 3.9005 (5.5017)	Learning Rate [0.00125]
14: TRAIN [0][1070/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00096)	Tok/s 52901 (54006)	Loss/tok 3.8340 (5.5082)	Learning Rate [0.00125]
13: TRAIN [0][1070/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00096)	Tok/s 52816 (53901)	Loss/tok 3.9570 (5.5047)	Learning Rate [0.00125]
12: TRAIN [0][1070/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00096)	Tok/s 52675 (53811)	Loss/tok 3.8959 (5.5095)	Learning Rate [0.00125]
11: TRAIN [0][1070/3416]	Time 0.054 (0.058)	Data 0.00086 (0.00091)	Tok/s 52613 (53704)	Loss/tok 4.1206 (5.5092)	Learning Rate [0.00125]
2: TRAIN [0][1070/3416]	Time 0.053 (0.058)	Data 0.00102 (0.00100)	Tok/s 51513 (53004)	Loss/tok 3.8828 (5.5067)	Learning Rate [0.00125]
3: TRAIN [0][1070/3416]	Time 0.054 (0.058)	Data 0.00083 (0.00094)	Tok/s 51387 (53114)	Loss/tok 3.8660 (5.5058)	Learning Rate [0.00125]
4: TRAIN [0][1070/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00098)	Tok/s 51289 (53201)	Loss/tok 3.9348 (5.5017)	Learning Rate [0.00125]
10: TRAIN [0][1070/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00096)	Tok/s 52479 (53633)	Loss/tok 4.1101 (5.5100)	Learning Rate [0.00125]
6: TRAIN [0][1070/3416]	Time 0.054 (0.058)	Data 0.00081 (0.00093)	Tok/s 52345 (53346)	Loss/tok 3.9899 (5.5014)	Learning Rate [0.00125]
9: TRAIN [0][1070/3416]	Time 0.054 (0.058)	Data 0.00086 (0.00093)	Tok/s 52355 (53559)	Loss/tok 3.8415 (5.5021)	Learning Rate [0.00125]
8: TRAIN [0][1070/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00093)	Tok/s 52255 (53498)	Loss/tok 4.1317 (5.4973)	Learning Rate [0.00125]
15: TRAIN [0][1070/3416]	Time 0.053 (0.058)	Data 0.00101 (0.00093)	Tok/s 52971 (54120)	Loss/tok 3.8199 (5.5045)	Learning Rate [0.00125]
7: TRAIN [0][1070/3416]	Time 0.054 (0.058)	Data 0.00109 (0.00095)	Tok/s 52207 (53421)	Loss/tok 3.9971 (5.5051)	Learning Rate [0.00125]
5: TRAIN [0][1070/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00095)	Tok/s 51303 (53282)	Loss/tok 3.7938 (5.5069)	Learning Rate [0.00125]
4: TRAIN [0][1080/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00098)	Tok/s 85227 (53280)	Loss/tok 3.8961 (5.4840)	Learning Rate [0.00125]
3: TRAIN [0][1080/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00094)	Tok/s 85441 (53193)	Loss/tok 4.0113 (5.4882)	Learning Rate [0.00125]
5: TRAIN [0][1080/3416]	Time 0.071 (0.058)	Data 0.00100 (0.00095)	Tok/s 85278 (53359)	Loss/tok 3.7544 (5.4895)	Learning Rate [0.00125]
1: TRAIN [0][1080/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00095)	Tok/s 84506 (52992)	Loss/tok 3.7750 (5.4839)	Learning Rate [0.00125]
6: TRAIN [0][1080/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00093)	Tok/s 85312 (53426)	Loss/tok 3.7734 (5.4848)	Learning Rate [0.00125]
2: TRAIN [0][1080/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00100)	Tok/s 84958 (53081)	Loss/tok 3.7477 (5.4894)	Learning Rate [0.00125]
0: TRAIN [0][1080/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 84477 (52906)	Loss/tok 3.7649 (5.4943)	Learning Rate [0.00125]
7: TRAIN [0][1080/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00095)	Tok/s 86115 (53502)	Loss/tok 3.9816 (5.4876)	Learning Rate [0.00125]
8: TRAIN [0][1080/3416]	Time 0.071 (0.058)	Data 0.00099 (0.00093)	Tok/s 86115 (53578)	Loss/tok 3.9558 (5.4801)	Learning Rate [0.00125]
14: TRAIN [0][1080/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00096)	Tok/s 88985 (54086)	Loss/tok 3.9190 (5.4917)	Learning Rate [0.00125]
13: TRAIN [0][1080/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00096)	Tok/s 88176 (53981)	Loss/tok 3.8285 (5.4875)	Learning Rate [0.00125]
9: TRAIN [0][1080/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00093)	Tok/s 86141 (53638)	Loss/tok 4.0794 (5.4857)	Learning Rate [0.00125]
12: TRAIN [0][1080/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00096)	Tok/s 87709 (53891)	Loss/tok 3.9957 (5.4920)	Learning Rate [0.00125]
10: TRAIN [0][1080/3416]	Time 0.071 (0.058)	Data 0.00102 (0.00096)	Tok/s 86992 (53712)	Loss/tok 3.9329 (5.4928)	Learning Rate [0.00125]
15: TRAIN [0][1080/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00093)	Tok/s 89576 (54200)	Loss/tok 3.7616 (5.4868)	Learning Rate [0.00125]
11: TRAIN [0][1080/3416]	Time 0.071 (0.058)	Data 0.00107 (0.00091)	Tok/s 87093 (53784)	Loss/tok 3.6338 (5.4915)	Learning Rate [0.00125]
14: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00096)	Tok/s 60335 (54088)	Loss/tok 4.0539 (5.4786)	Learning Rate [0.00125]
13: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 60372 (53983)	Loss/tok 4.0330 (5.4735)	Learning Rate [0.00125]
12: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00096)	Tok/s 60315 (53894)	Loss/tok 4.2341 (5.4790)	Learning Rate [0.00125]
0: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 60221 (52910)	Loss/tok 4.0372 (5.4803)	Learning Rate [0.00125]
11: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00091)	Tok/s 60335 (53787)	Loss/tok 4.1667 (5.4774)	Learning Rate [0.00125]
1: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00095)	Tok/s 60216 (52995)	Loss/tok 4.2645 (5.4700)	Learning Rate [0.00125]
9: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 60376 (53640)	Loss/tok 4.0036 (5.4713)	Learning Rate [0.00125]
3: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00094)	Tok/s 60192 (53195)	Loss/tok 4.4623 (5.4743)	Learning Rate [0.00125]
10: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00096)	Tok/s 60334 (53714)	Loss/tok 4.2765 (5.4789)	Learning Rate [0.00125]
2: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00100)	Tok/s 60161 (53084)	Loss/tok 3.9708 (5.4755)	Learning Rate [0.00125]
8: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 60336 (53580)	Loss/tok 4.2940 (5.4665)	Learning Rate [0.00125]
6: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 60334 (53427)	Loss/tok 4.0766 (5.4704)	Learning Rate [0.00125]
5: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00095)	Tok/s 60250 (53361)	Loss/tok 3.9862 (5.4760)	Learning Rate [0.00125]
15: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 60202 (54201)	Loss/tok 4.2679 (5.4734)	Learning Rate [0.00125]
4: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 60258 (53281)	Loss/tok 4.0843 (5.4706)	Learning Rate [0.00125]
7: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00095)	Tok/s 60402 (53503)	Loss/tok 3.7925 (5.4739)	Learning Rate [0.00125]
8: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 65616 (53647)	Loss/tok 4.2440 (5.4495)	Learning Rate [0.00125]
10: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 65600 (53781)	Loss/tok 4.0046 (5.4634)	Learning Rate [0.00125]
2: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00114 (0.00100)	Tok/s 65537 (53154)	Loss/tok 3.9504 (5.4584)	Learning Rate [0.00125]
11: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 65598 (53854)	Loss/tok 3.9882 (5.4604)	Learning Rate [0.00125]
6: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 65416 (53495)	Loss/tok 4.0009 (5.4538)	Learning Rate [0.00125]
7: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00095)	Tok/s 65507 (53571)	Loss/tok 4.1834 (5.4569)	Learning Rate [0.00125]
9: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00093)	Tok/s 65739 (53707)	Loss/tok 4.1096 (5.4544)	Learning Rate [0.00125]
1: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00095)	Tok/s 65413 (53065)	Loss/tok 3.9634 (5.4540)	Learning Rate [0.00125]
4: TRAIN [0][1100/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 65365 (53350)	Loss/tok 4.3969 (5.4542)	Learning Rate [0.00125]
0: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 65551 (52979)	Loss/tok 4.1100 (5.4636)	Learning Rate [0.00125]
5: TRAIN [0][1100/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00095)	Tok/s 65348 (53430)	Loss/tok 3.8284 (5.4589)	Learning Rate [0.00125]
12: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 65534 (53960)	Loss/tok 4.0227 (5.4613)	Learning Rate [0.00125]
13: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 66317 (54049)	Loss/tok 4.0355 (5.4567)	Learning Rate [0.00125]
3: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00094)	Tok/s 65433 (53264)	Loss/tok 4.0511 (5.4577)	Learning Rate [0.00125]
14: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 66441 (54154)	Loss/tok 3.8683 (5.4615)	Learning Rate [0.00125]
15: TRAIN [0][1100/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 66368 (54268)	Loss/tok 4.2839 (5.4563)	Learning Rate [0.00125]
7: TRAIN [0][1110/3416]	Time 0.042 (0.058)	Data 0.00086 (0.00095)	Tok/s 31768 (53637)	Loss/tok 3.0031 (5.4390)	Learning Rate [0.00125]
8: TRAIN [0][1110/3416]	Time 0.042 (0.058)	Data 0.00086 (0.00093)	Tok/s 31635 (53713)	Loss/tok 3.1542 (5.4332)	Learning Rate [0.00125]
5: TRAIN [0][1110/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00095)	Tok/s 30041 (53494)	Loss/tok 2.9831 (5.4420)	Learning Rate [0.00125]
4: TRAIN [0][1110/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00098)	Tok/s 30028 (53412)	Loss/tok 2.9306 (5.4372)	Learning Rate [0.00125]
10: TRAIN [0][1110/3416]	Time 0.042 (0.058)	Data 0.00088 (0.00096)	Tok/s 31647 (53846)	Loss/tok 3.0808 (5.4465)	Learning Rate [0.00125]
3: TRAIN [0][1110/3416]	Time 0.043 (0.058)	Data 0.00091 (0.00094)	Tok/s 30018 (53327)	Loss/tok 3.2290 (5.4405)	Learning Rate [0.00125]
11: TRAIN [0][1110/3416]	Time 0.043 (0.058)	Data 0.00089 (0.00092)	Tok/s 31564 (53919)	Loss/tok 3.4452 (5.4438)	Learning Rate [0.00125]
2: TRAIN [0][1110/3416]	Time 0.043 (0.058)	Data 0.00105 (0.00100)	Tok/s 30029 (53218)	Loss/tok 3.3172 (5.4419)	Learning Rate [0.00125]
1: TRAIN [0][1110/3416]	Time 0.043 (0.058)	Data 0.00098 (0.00095)	Tok/s 30039 (53129)	Loss/tok 3.1522 (5.4372)	Learning Rate [0.00125]
13: TRAIN [0][1110/3416]	Time 0.043 (0.058)	Data 0.00102 (0.00096)	Tok/s 31566 (54115)	Loss/tok 3.0431 (5.4402)	Learning Rate [0.00125]
12: TRAIN [0][1110/3416]	Time 0.043 (0.058)	Data 0.00088 (0.00096)	Tok/s 31547 (54025)	Loss/tok 3.3827 (5.4449)	Learning Rate [0.00125]
0: TRAIN [0][1110/3416]	Time 0.043 (0.058)	Data 0.00087 (0.00098)	Tok/s 30024 (53043)	Loss/tok 3.3698 (5.4470)	Learning Rate [0.00125]
14: TRAIN [0][1110/3416]	Time 0.043 (0.058)	Data 0.00085 (0.00096)	Tok/s 31536 (54220)	Loss/tok 3.3935 (5.4455)	Learning Rate [0.00125]
15: TRAIN [0][1110/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00093)	Tok/s 31501 (54334)	Loss/tok 3.1027 (5.4385)	Learning Rate [0.00125]
6: TRAIN [0][1110/3416]	Time 0.042 (0.058)	Data 0.00134 (0.00093)	Tok/s 30606 (53559)	Loss/tok 3.1005 (5.4369)	Learning Rate [0.00125]
9: TRAIN [0][1110/3416]	Time 0.042 (0.058)	Data 0.00125 (0.00093)	Tok/s 31685 (53771)	Loss/tok 3.2929 (5.4375)	Learning Rate [0.00125]
1: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00095)	Tok/s 36342 (53141)	Loss/tok 3.3976 (5.4229)	Learning Rate [0.00125]
2: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00100)	Tok/s 36365 (53230)	Loss/tok 3.3587 (5.4279)	Learning Rate [0.00125]
0: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00098)	Tok/s 35190 (53054)	Loss/tok 3.3604 (5.4330)	Learning Rate [0.00125]
3: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00094)	Tok/s 36343 (53340)	Loss/tok 3.4679 (5.4261)	Learning Rate [0.00125]
14: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00096)	Tok/s 36139 (54230)	Loss/tok 3.6923 (5.4317)	Learning Rate [0.00125]
4: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00098)	Tok/s 36299 (53424)	Loss/tok 3.7672 (5.4245)	Learning Rate [0.00125]
13: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00096)	Tok/s 36103 (54125)	Loss/tok 3.4637 (5.4264)	Learning Rate [0.00125]
12: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00096)	Tok/s 36136 (54035)	Loss/tok 3.4385 (5.4310)	Learning Rate [0.00125]
11: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 36157 (53929)	Loss/tok 3.6933 (5.4303)	Learning Rate [0.00125]
6: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00093)	Tok/s 36207 (53571)	Loss/tok 3.8655 (5.4228)	Learning Rate [0.00125]
5: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00095)	Tok/s 36274 (53505)	Loss/tok 3.8414 (5.4282)	Learning Rate [0.00125]
8: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00093)	Tok/s 36077 (53723)	Loss/tok 4.0662 (5.4201)	Learning Rate [0.00125]
9: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 36104 (53781)	Loss/tok 3.7197 (5.4237)	Learning Rate [0.00125]
7: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00095)	Tok/s 36116 (53647)	Loss/tok 3.4800 (5.4252)	Learning Rate [0.00125]
15: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00093)	Tok/s 36187 (54347)	Loss/tok 4.0959 (5.4252)	Learning Rate [0.00125]
10: TRAIN [0][1120/3416]	Time 0.051 (0.058)	Data 0.00123 (0.00096)	Tok/s 36152 (53855)	Loss/tok 3.6470 (5.4326)	Learning Rate [0.00125]
4: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00098)	Tok/s 82222 (53477)	Loss/tok 3.8668 (5.4089)	Learning Rate [0.00125]
10: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 83279 (53909)	Loss/tok 3.6867 (5.4164)	Learning Rate [0.00125]
7: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00095)	Tok/s 82906 (53700)	Loss/tok 3.9165 (5.4101)	Learning Rate [0.00125]
8: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00093)	Tok/s 82934 (53777)	Loss/tok 3.5479 (5.4033)	Learning Rate [0.00125]
5: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00095)	Tok/s 82665 (53558)	Loss/tok 3.6337 (5.4120)	Learning Rate [0.00125]
9: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00093)	Tok/s 82931 (53835)	Loss/tok 3.8992 (5.4081)	Learning Rate [0.00125]
11: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 83738 (53983)	Loss/tok 3.9477 (5.4141)	Learning Rate [0.00125]
2: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00114 (0.00100)	Tok/s 82022 (53284)	Loss/tok 4.0610 (5.4119)	Learning Rate [0.00125]
1: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00095)	Tok/s 81998 (53195)	Loss/tok 3.7174 (5.4067)	Learning Rate [0.00125]
3: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00094)	Tok/s 81984 (53393)	Loss/tok 3.8682 (5.4097)	Learning Rate [0.00125]
12: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00115 (0.00096)	Tok/s 83644 (54088)	Loss/tok 3.7938 (5.4152)	Learning Rate [0.00125]
6: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00093)	Tok/s 82846 (53623)	Loss/tok 3.9629 (5.4066)	Learning Rate [0.00125]
0: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00098)	Tok/s 81996 (53108)	Loss/tok 3.6311 (5.4166)	Learning Rate [0.00125]
13: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00096)	Tok/s 83632 (54178)	Loss/tok 3.6498 (5.4101)	Learning Rate [0.00125]
14: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00096)	Tok/s 83657 (54284)	Loss/tok 3.9117 (5.4165)	Learning Rate [0.00125]
15: TRAIN [0][1130/3416]	Time 0.070 (0.058)	Data 0.00116 (0.00093)	Tok/s 83864 (54400)	Loss/tok 3.7876 (5.4097)	Learning Rate [0.00125]
4: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00098)	Tok/s 32177 (53494)	Loss/tok 3.4716 (5.3949)	Learning Rate [0.00125]
3: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00094)	Tok/s 32224 (53410)	Loss/tok 3.5713 (5.3954)	Learning Rate [0.00125]
5: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00095)	Tok/s 32225 (53576)	Loss/tok 3.5315 (5.3984)	Learning Rate [0.00125]
2: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00109 (0.00100)	Tok/s 32219 (53299)	Loss/tok 3.3592 (5.3975)	Learning Rate [0.00125]
6: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00093)	Tok/s 32184 (53641)	Loss/tok 3.5275 (5.3925)	Learning Rate [0.00125]
1: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00095)	Tok/s 32179 (53211)	Loss/tok 3.7670 (5.3931)	Learning Rate [0.00125]
0: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00077 (0.00097)	Tok/s 32210 (53125)	Loss/tok 3.4487 (5.4030)	Learning Rate [0.00125]
8: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00093)	Tok/s 32200 (53795)	Loss/tok 3.3468 (5.3893)	Learning Rate [0.00125]
9: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00093)	Tok/s 32182 (53855)	Loss/tok 3.4512 (5.3933)	Learning Rate [0.00125]
14: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00081 (0.00096)	Tok/s 33469 (54305)	Loss/tok 3.4283 (5.4020)	Learning Rate [0.00125]
7: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00095)	Tok/s 32216 (53717)	Loss/tok 3.3368 (5.3965)	Learning Rate [0.00125]
10: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00096)	Tok/s 32186 (53929)	Loss/tok 3.4538 (5.4014)	Learning Rate [0.00125]
13: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00096)	Tok/s 33465 (54198)	Loss/tok 3.5026 (5.3964)	Learning Rate [0.00125]
11: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00092)	Tok/s 33209 (54003)	Loss/tok 3.4636 (5.4000)	Learning Rate [0.00125]
12: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00096)	Tok/s 33498 (54108)	Loss/tok 3.5892 (5.4012)	Learning Rate [0.00125]
15: TRAIN [0][1140/3416]	Time 0.050 (0.058)	Data 0.00078 (0.00093)	Tok/s 33482 (54420)	Loss/tok 3.9078 (5.3962)	Learning Rate [0.00125]
8: Upscaling, new scale: 512.0
9: Upscaling, new scale: 512.0
6: Upscaling, new scale: 512.0
7: Upscaling, new scale: 512.0
4: Upscaling, new scale: 512.0
10: Upscaling, new scale: 512.0
5: Upscaling, new scale: 512.0
11: Upscaling, new scale: 512.0
12: Upscaling, new scale: 512.0
3: Upscaling, new scale: 512.0
13: Upscaling, new scale: 512.0
2: Upscaling, new scale: 512.0
1: Upscaling, new scale: 512.0
0: Upscaling, new scale: 512.0
14: Upscaling, new scale: 512.0
15: Upscaling, new scale: 512.0
1: TRAIN [0][1150/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00095)	Tok/s 53338 (53218)	Loss/tok 3.9235 (5.3793)	Learning Rate [0.00125]
2: TRAIN [0][1150/3416]	Time 0.062 (0.058)	Data 0.00104 (0.00100)	Tok/s 53341 (53306)	Loss/tok 3.8029 (5.3846)	Learning Rate [0.00125]
0: TRAIN [0][1150/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00097)	Tok/s 53240 (53132)	Loss/tok 3.9745 (5.3902)	Learning Rate [0.00125]
3: TRAIN [0][1150/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00094)	Tok/s 53278 (53416)	Loss/tok 3.9194 (5.3821)	Learning Rate [0.00125]
4: TRAIN [0][1150/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00098)	Tok/s 53405 (53501)	Loss/tok 4.1025 (5.3815)	Learning Rate [0.00125]
6: TRAIN [0][1150/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00093)	Tok/s 54389 (53650)	Loss/tok 3.9303 (5.3791)	Learning Rate [0.00125]
14: TRAIN [0][1150/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00096)	Tok/s 54128 (54316)	Loss/tok 3.8416 (5.3887)	Learning Rate [0.00125]
13: TRAIN [0][1150/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00096)	Tok/s 54133 (54209)	Loss/tok 4.1271 (5.3831)	Learning Rate [0.00125]
5: TRAIN [0][1150/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00095)	Tok/s 54309 (53584)	Loss/tok 4.1011 (5.3852)	Learning Rate [0.00125]
12: TRAIN [0][1150/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00096)	Tok/s 54063 (54117)	Loss/tok 3.9754 (5.3876)	Learning Rate [0.00125]
11: TRAIN [0][1150/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00092)	Tok/s 54118 (54013)	Loss/tok 3.9051 (5.3867)	Learning Rate [0.00125]
7: TRAIN [0][1150/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00095)	Tok/s 54207 (53727)	Loss/tok 3.7953 (5.3831)	Learning Rate [0.00125]
8: TRAIN [0][1150/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00093)	Tok/s 54178 (53804)	Loss/tok 4.0118 (5.3761)	Learning Rate [0.00125]
10: TRAIN [0][1150/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00096)	Tok/s 54117 (53939)	Loss/tok 4.1050 (5.3882)	Learning Rate [0.00125]
9: TRAIN [0][1150/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00093)	Tok/s 54106 (53864)	Loss/tok 4.0541 (5.3796)	Learning Rate [0.00125]
15: TRAIN [0][1150/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00093)	Tok/s 54175 (54431)	Loss/tok 4.0138 (5.3829)	Learning Rate [0.00125]
13: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 61054 (54217)	Loss/tok 4.0999 (5.3702)	Learning Rate [0.00125]
12: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00096)	Tok/s 61142 (54125)	Loss/tok 4.0499 (5.3746)	Learning Rate [0.00125]
11: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 61159 (54020)	Loss/tok 4.1683 (5.3743)	Learning Rate [0.00125]
10: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00096)	Tok/s 61181 (53947)	Loss/tok 4.1192 (5.3761)	Learning Rate [0.00125]
9: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 61202 (53872)	Loss/tok 3.8890 (5.3667)	Learning Rate [0.00125]
14: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 60954 (54323)	Loss/tok 4.0091 (5.3755)	Learning Rate [0.00125]
8: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 61174 (53812)	Loss/tok 4.0573 (5.3633)	Learning Rate [0.00125]
0: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 60797 (53128)	Loss/tok 4.0260 (5.3783)	Learning Rate [0.00125]
1: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00095)	Tok/s 60804 (53217)	Loss/tok 4.1927 (5.3664)	Learning Rate [0.00125]
6: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00093)	Tok/s 60972 (53657)	Loss/tok 4.0358 (5.3662)	Learning Rate [0.00125]
5: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00095)	Tok/s 60918 (53590)	Loss/tok 4.1021 (5.3728)	Learning Rate [0.00125]
7: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00095)	Tok/s 61053 (53734)	Loss/tok 3.8345 (5.3701)	Learning Rate [0.00125]
4: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 60812 (53505)	Loss/tok 4.3604 (5.3698)	Learning Rate [0.00125]
3: TRAIN [0][1160/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00094)	Tok/s 60765 (53419)	Loss/tok 3.9676 (5.3695)	Learning Rate [0.00125]
15: TRAIN [0][1160/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00093)	Tok/s 60853 (54439)	Loss/tok 4.1170 (5.3704)	Learning Rate [0.00125]
2: TRAIN [0][1160/3416]	Time 0.070 (0.058)	Data 0.00113 (0.00100)	Tok/s 60762 (53307)	Loss/tok 4.0715 (5.3724)	Learning Rate [0.00125]
4: TRAIN [0][1170/3416]	Time 0.067 (0.058)	Data 0.00115 (0.00098)	Tok/s 57184 (53505)	Loss/tok 3.9933 (5.3576)	Learning Rate [0.00125]
3: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00094)	Tok/s 56485 (53420)	Loss/tok 3.9507 (5.3560)	Learning Rate [0.00125]
6: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00093)	Tok/s 56487 (53657)	Loss/tok 4.2891 (5.3538)	Learning Rate [0.00125]
5: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00095)	Tok/s 56496 (53589)	Loss/tok 4.0018 (5.3614)	Learning Rate [0.00125]
2: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00100)	Tok/s 56511 (53309)	Loss/tok 4.0130 (5.3597)	Learning Rate [0.00125]
1: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00095)	Tok/s 56508 (53218)	Loss/tok 4.3737 (5.3545)	Learning Rate [0.00125]
0: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00097)	Tok/s 56494 (53130)	Loss/tok 4.0833 (5.3656)	Learning Rate [0.00125]
8: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00093)	Tok/s 56308 (53813)	Loss/tok 4.2682 (5.3514)	Learning Rate [0.00125]
7: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00095)	Tok/s 56394 (53735)	Loss/tok 4.0445 (5.3571)	Learning Rate [0.00125]
9: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00093)	Tok/s 56331 (53872)	Loss/tok 4.1138 (5.3547)	Learning Rate [0.00125]
14: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00096)	Tok/s 56490 (54321)	Loss/tok 3.9920 (5.3631)	Learning Rate [0.00125]
13: TRAIN [0][1170/3416]	Time 0.067 (0.058)	Data 0.00111 (0.00096)	Tok/s 57104 (54216)	Loss/tok 3.9012 (5.3575)	Learning Rate [0.00125]
10: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00096)	Tok/s 56310 (53946)	Loss/tok 3.7380 (5.3633)	Learning Rate [0.00125]
11: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 56317 (54020)	Loss/tok 3.7376 (5.3619)	Learning Rate [0.00125]
12: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00096)	Tok/s 56387 (54124)	Loss/tok 4.0567 (5.3623)	Learning Rate [0.00125]
15: TRAIN [0][1170/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00093)	Tok/s 56493 (54437)	Loss/tok 3.9012 (5.3575)	Learning Rate [0.00125]
13: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 67991 (54236)	Loss/tok 3.9293 (5.3440)	Learning Rate [0.00125]
12: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 67889 (54145)	Loss/tok 3.8991 (5.3500)	Learning Rate [0.00125]
14: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 68043 (54341)	Loss/tok 4.0169 (5.3500)	Learning Rate [0.00125]
0: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 67090 (53153)	Loss/tok 4.0620 (5.3529)	Learning Rate [0.00125]
1: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00095)	Tok/s 67082 (53241)	Loss/tok 4.0175 (5.3420)	Learning Rate [0.00125]
10: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00096)	Tok/s 67565 (53968)	Loss/tok 3.7734 (5.3496)	Learning Rate [0.00125]
9: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00123 (0.00093)	Tok/s 67602 (53892)	Loss/tok 4.1862 (5.3424)	Learning Rate [0.00125]
8: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 67606 (53833)	Loss/tok 4.0762 (5.3380)	Learning Rate [0.00125]
4: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 67296 (53525)	Loss/tok 4.2663 (5.3450)	Learning Rate [0.00125]
2: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00100)	Tok/s 67008 (53330)	Loss/tok 4.0077 (5.3466)	Learning Rate [0.00125]
3: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00121 (0.00094)	Tok/s 66947 (53441)	Loss/tok 3.9785 (5.3432)	Learning Rate [0.00125]
6: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 67561 (53677)	Loss/tok 4.2879 (5.3420)	Learning Rate [0.00125]
11: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 67682 (54041)	Loss/tok 4.1098 (5.3490)	Learning Rate [0.00125]
7: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00095)	Tok/s 68044 (53755)	Loss/tok 3.9829 (5.3445)	Learning Rate [0.00125]
5: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00095)	Tok/s 67693 (53609)	Loss/tok 4.0780 (5.3483)	Learning Rate [0.00125]
15: TRAIN [0][1180/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00093)	Tok/s 68041 (54457)	Loss/tok 3.9498 (5.3443)	Learning Rate [0.00125]
14: TRAIN [0][1190/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00096)	Tok/s 39362 (54360)	Loss/tok 3.5012 (5.3369)	Learning Rate [0.00125]
0: TRAIN [0][1190/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 37927 (53174)	Loss/tok 3.5581 (5.3395)	Learning Rate [0.00125]
1: TRAIN [0][1190/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00095)	Tok/s 37886 (53262)	Loss/tok 3.6518 (5.3283)	Learning Rate [0.00125]
13: TRAIN [0][1190/3416]	Time 0.050 (0.058)	Data 0.00081 (0.00096)	Tok/s 39326 (54255)	Loss/tok 3.5055 (5.3313)	Learning Rate [0.00125]
12: TRAIN [0][1190/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00096)	Tok/s 39358 (54164)	Loss/tok 3.6069 (5.3373)	Learning Rate [0.00125]
15: TRAIN [0][1190/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00094)	Tok/s 39632 (54477)	Loss/tok 3.5108 (5.3316)	Learning Rate [0.00125]
2: TRAIN [0][1190/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00100)	Tok/s 37802 (53352)	Loss/tok 3.4797 (5.3345)	Learning Rate [0.00125]
11: TRAIN [0][1190/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00092)	Tok/s 39321 (54060)	Loss/tok 3.7910 (5.3364)	Learning Rate [0.00125]
3: TRAIN [0][1190/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00094)	Tok/s 37787 (53461)	Loss/tok 3.7898 (5.3295)	Learning Rate [0.00125]
10: TRAIN [0][1190/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00096)	Tok/s 39307 (53987)	Loss/tok 3.8399 (5.3363)	Learning Rate [0.00125]
9: TRAIN [0][1190/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00093)	Tok/s 39264 (53912)	Loss/tok 3.4679 (5.3294)	Learning Rate [0.00125]
8: TRAIN [0][1190/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 39182 (53852)	Loss/tok 3.6572 (5.3256)	Learning Rate [0.00125]
5: TRAIN [0][1190/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00095)	Tok/s 37804 (53628)	Loss/tok 3.8742 (5.3348)	Learning Rate [0.00125]
6: TRAIN [0][1190/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00093)	Tok/s 38273 (53696)	Loss/tok 3.8255 (5.3293)	Learning Rate [0.00125]
7: TRAIN [0][1190/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00095)	Tok/s 39106 (53775)	Loss/tok 3.4791 (5.3315)	Learning Rate [0.00125]
4: TRAIN [0][1190/3416]	Time 0.051 (0.058)	Data 0.00113 (0.00098)	Tok/s 37807 (53545)	Loss/tok 3.6661 (5.3325)	Learning Rate [0.00125]
6: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00093)	Tok/s 52831 (53681)	Loss/tok 3.9534 (5.3171)	Learning Rate [0.00125]
7: TRAIN [0][1200/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00095)	Tok/s 53101 (53762)	Loss/tok 4.0225 (5.3189)	Learning Rate [0.00125]
8: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00093)	Tok/s 52922 (53840)	Loss/tok 3.9429 (5.3125)	Learning Rate [0.00125]
5: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00095)	Tok/s 51872 (53612)	Loss/tok 3.6787 (5.3223)	Learning Rate [0.00125]
4: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00104 (0.00099)	Tok/s 51888 (53527)	Loss/tok 3.7471 (5.3206)	Learning Rate [0.00125]
9: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00093)	Tok/s 52784 (53901)	Loss/tok 3.9600 (5.3164)	Learning Rate [0.00125]
3: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00094)	Tok/s 51728 (53443)	Loss/tok 3.8108 (5.3175)	Learning Rate [0.00125]
10: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00096)	Tok/s 52713 (53976)	Loss/tok 4.0562 (5.3238)	Learning Rate [0.00125]
11: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00092)	Tok/s 52574 (54050)	Loss/tok 3.8071 (5.3241)	Learning Rate [0.00125]
1: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00086 (0.00095)	Tok/s 51496 (53241)	Loss/tok 3.5464 (5.3161)	Learning Rate [0.00125]
2: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00100)	Tok/s 51612 (53333)	Loss/tok 4.1403 (5.3225)	Learning Rate [0.00125]
12: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00096)	Tok/s 52476 (54153)	Loss/tok 3.9473 (5.3250)	Learning Rate [0.00125]
0: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00099 (0.00097)	Tok/s 51389 (53150)	Loss/tok 4.2141 (5.3276)	Learning Rate [0.00125]
13: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00096)	Tok/s 52389 (54244)	Loss/tok 3.8658 (5.3185)	Learning Rate [0.00125]
15: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00093)	Tok/s 52439 (54466)	Loss/tok 4.0166 (5.3194)	Learning Rate [0.00125]
14: TRAIN [0][1200/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00096)	Tok/s 52367 (54350)	Loss/tok 3.6897 (5.3246)	Learning Rate [0.00125]
6: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00084 (0.00093)	Tok/s 51801 (53707)	Loss/tok 3.9298 (5.3036)	Learning Rate [0.00125]
5: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00082 (0.00095)	Tok/s 51831 (53639)	Loss/tok 3.9943 (5.3107)	Learning Rate [0.00125]
7: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00083 (0.00095)	Tok/s 52268 (53788)	Loss/tok 4.0916 (5.3065)	Learning Rate [0.00125]
8: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00093)	Tok/s 52669 (53867)	Loss/tok 4.0432 (5.2997)	Learning Rate [0.00125]
3: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00094)	Tok/s 51796 (53469)	Loss/tok 3.9687 (5.3055)	Learning Rate [0.00125]
9: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00093)	Tok/s 52573 (53927)	Loss/tok 3.7992 (5.3037)	Learning Rate [0.00125]
2: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00100)	Tok/s 51793 (53360)	Loss/tok 4.1623 (5.3111)	Learning Rate [0.00125]
4: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00109 (0.00099)	Tok/s 51794 (53554)	Loss/tok 3.9270 (5.3078)	Learning Rate [0.00125]
1: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00094)	Tok/s 51720 (53269)	Loss/tok 3.9254 (5.3036)	Learning Rate [0.00125]
10: TRAIN [0][1210/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00096)	Tok/s 52496 (54002)	Loss/tok 4.1404 (5.3112)	Learning Rate [0.00125]
11: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00092)	Tok/s 52515 (54075)	Loss/tok 3.8509 (5.3126)	Learning Rate [0.00125]
0: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00097)	Tok/s 51645 (53178)	Loss/tok 3.9471 (5.3152)	Learning Rate [0.00125]
15: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00093)	Tok/s 52637 (54489)	Loss/tok 3.9988 (5.3078)	Learning Rate [0.00125]
12: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00096)	Tok/s 52567 (54178)	Loss/tok 3.7715 (5.3121)	Learning Rate [0.00125]
14: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00122 (0.00096)	Tok/s 52567 (54374)	Loss/tok 4.1323 (5.3123)	Learning Rate [0.00125]
13: TRAIN [0][1210/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00096)	Tok/s 52527 (54269)	Loss/tok 4.1369 (5.3070)	Learning Rate [0.00125]
9: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00080 (0.00093)	Tok/s 52438 (53903)	Loss/tok 4.0428 (5.2925)	Learning Rate [0.00125]
10: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00096)	Tok/s 52503 (53977)	Loss/tok 3.7809 (5.2994)	Learning Rate [0.00125]
11: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00092)	Tok/s 52486 (54050)	Loss/tok 3.7855 (5.3008)	Learning Rate [0.00125]
8: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00093)	Tok/s 52348 (53843)	Loss/tok 3.8557 (5.2882)	Learning Rate [0.00125]
12: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00096)	Tok/s 52419 (54152)	Loss/tok 3.9774 (5.3002)	Learning Rate [0.00125]
7: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00095)	Tok/s 52221 (53765)	Loss/tok 3.9278 (5.2956)	Learning Rate [0.00125]
6: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00093)	Tok/s 52103 (53683)	Loss/tok 4.0574 (5.2922)	Learning Rate [0.00125]
13: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00096)	Tok/s 52353 (54242)	Loss/tok 3.9804 (5.2954)	Learning Rate [0.00125]
5: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00095)	Tok/s 51984 (53614)	Loss/tok 4.1606 (5.2995)	Learning Rate [0.00125]
4: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00099)	Tok/s 51915 (53530)	Loss/tok 3.8892 (5.2967)	Learning Rate [0.00125]
15: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00082 (0.00093)	Tok/s 52146 (54462)	Loss/tok 4.0351 (5.2969)	Learning Rate [0.00125]
3: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00094)	Tok/s 51922 (53445)	Loss/tok 3.8470 (5.2935)	Learning Rate [0.00125]
0: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00097)	Tok/s 50975 (53155)	Loss/tok 3.9137 (5.3039)	Learning Rate [0.00125]
14: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00096)	Tok/s 52332 (54347)	Loss/tok 3.8670 (5.3006)	Learning Rate [0.00125]
1: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00094)	Tok/s 50858 (53245)	Loss/tok 3.9556 (5.2922)	Learning Rate [0.00125]
2: TRAIN [0][1220/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00100)	Tok/s 51713 (53336)	Loss/tok 4.0412 (5.2995)	Learning Rate [0.00125]
8: TRAIN [0][1230/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 70226 (53810)	Loss/tok 4.1147 (5.2782)	Learning Rate [0.00125]
9: TRAIN [0][1230/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00093)	Tok/s 70228 (53870)	Loss/tok 3.9195 (5.2814)	Learning Rate [0.00125]
5: TRAIN [0][1230/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00095)	Tok/s 70013 (53580)	Loss/tok 3.9729 (5.2888)	Learning Rate [0.00125]
6: TRAIN [0][1230/3416]	Time 0.069 (0.058)	Data 0.00078 (0.00093)	Tok/s 69994 (53650)	Loss/tok 3.9478 (5.2822)	Learning Rate [0.00125]
7: TRAIN [0][1230/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00095)	Tok/s 70114 (53731)	Loss/tok 3.7520 (5.2845)	Learning Rate [0.00125]
10: TRAIN [0][1230/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 70924 (53945)	Loss/tok 3.9248 (5.2889)	Learning Rate [0.00125]
11: TRAIN [0][1230/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 70936 (54018)	Loss/tok 4.1156 (5.2914)	Learning Rate [0.00125]
12: TRAIN [0][1230/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 71052 (54119)	Loss/tok 3.9721 (5.2898)	Learning Rate [0.00125]
4: TRAIN [0][1230/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00099)	Tok/s 69777 (53493)	Loss/tok 4.0258 (5.2870)	Learning Rate [0.00125]
3: TRAIN [0][1230/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00094)	Tok/s 69682 (53408)	Loss/tok 4.0614 (5.2838)	Learning Rate [0.00125]
1: TRAIN [0][1230/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00094)	Tok/s 69540 (53206)	Loss/tok 4.1363 (5.2819)	Learning Rate [0.00125]
2: TRAIN [0][1230/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00100)	Tok/s 69491 (53299)	Loss/tok 3.9998 (5.2891)	Learning Rate [0.00125]
0: TRAIN [0][1230/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 69566 (53113)	Loss/tok 3.8180 (5.2935)	Learning Rate [0.00125]
14: TRAIN [0][1230/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 70609 (54317)	Loss/tok 4.0374 (5.2904)	Learning Rate [0.00125]
15: TRAIN [0][1230/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00093)	Tok/s 70557 (54432)	Loss/tok 3.9384 (5.2860)	Learning Rate [0.00125]
13: TRAIN [0][1230/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00096)	Tok/s 70774 (54212)	Loss/tok 3.7562 (5.2850)	Learning Rate [0.00125]
10: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00096)	Tok/s 54503 (53919)	Loss/tok 4.0887 (5.2781)	Learning Rate [0.00125]
11: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00092)	Tok/s 54445 (53992)	Loss/tok 3.8441 (5.2797)	Learning Rate [0.00125]
8: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00093)	Tok/s 54281 (53784)	Loss/tok 3.9373 (5.2673)	Learning Rate [0.00125]
6: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00105 (0.00093)	Tok/s 54312 (53622)	Loss/tok 3.9701 (5.2710)	Learning Rate [0.00125]
9: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00107 (0.00093)	Tok/s 54260 (53844)	Loss/tok 3.9047 (5.2704)	Learning Rate [0.00125]
12: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00096)	Tok/s 54429 (54095)	Loss/tok 3.5992 (5.2779)	Learning Rate [0.00125]
13: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00096)	Tok/s 54459 (54187)	Loss/tok 4.1083 (5.2741)	Learning Rate [0.00125]
7: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00095)	Tok/s 54257 (53704)	Loss/tok 3.9006 (5.2729)	Learning Rate [0.00125]
14: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00104 (0.00096)	Tok/s 54457 (54294)	Loss/tok 4.1337 (5.2793)	Learning Rate [0.00125]
3: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00107 (0.00094)	Tok/s 54349 (53376)	Loss/tok 3.8105 (5.2733)	Learning Rate [0.00125]
5: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00105 (0.00095)	Tok/s 54238 (53551)	Loss/tok 3.8375 (5.2774)	Learning Rate [0.00125]
4: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00114 (0.00099)	Tok/s 54250 (53463)	Loss/tok 4.0001 (5.2758)	Learning Rate [0.00125]
15: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00093)	Tok/s 54471 (54409)	Loss/tok 3.9491 (5.2754)	Learning Rate [0.00125]
0: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00102 (0.00097)	Tok/s 54427 (53076)	Loss/tok 4.0777 (5.2837)	Learning Rate [0.00125]
1: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00094)	Tok/s 54321 (53172)	Loss/tok 4.0261 (5.2712)	Learning Rate [0.00125]
2: TRAIN [0][1240/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00100)	Tok/s 54211 (53268)	Loss/tok 4.0415 (5.2787)	Learning Rate [0.00125]
12: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00095)	Tok/s 52926 (54063)	Loss/tok 4.1448 (5.2676)	Learning Rate [0.00125]
11: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00092)	Tok/s 52829 (53961)	Loss/tok 3.8154 (5.2696)	Learning Rate [0.00125]
13: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00096)	Tok/s 52812 (54156)	Loss/tok 3.6949 (5.2641)	Learning Rate [0.00125]
10: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00096)	Tok/s 52652 (53888)	Loss/tok 3.9572 (5.2682)	Learning Rate [0.00125]
9: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00093)	Tok/s 52618 (53814)	Loss/tok 3.7520 (5.2599)	Learning Rate [0.00125]
8: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00092)	Tok/s 52525 (53753)	Loss/tok 3.6696 (5.2566)	Learning Rate [0.00125]
15: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00085 (0.00093)	Tok/s 53933 (54378)	Loss/tok 3.9670 (5.2656)	Learning Rate [0.00125]
0: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00103 (0.00097)	Tok/s 52770 (53047)	Loss/tok 3.8620 (5.2739)	Learning Rate [0.00125]
1: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00094)	Tok/s 52554 (53142)	Loss/tok 4.0894 (5.2612)	Learning Rate [0.00125]
6: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00093)	Tok/s 52417 (53591)	Loss/tok 3.6055 (5.2610)	Learning Rate [0.00125]
7: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00095)	Tok/s 52472 (53673)	Loss/tok 4.0216 (5.2631)	Learning Rate [0.00125]
5: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00095)	Tok/s 52363 (53520)	Loss/tok 3.6794 (5.2669)	Learning Rate [0.00125]
4: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00103 (0.00099)	Tok/s 52422 (53433)	Loss/tok 3.7384 (5.2656)	Learning Rate [0.00125]
2: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00100)	Tok/s 52508 (53239)	Loss/tok 3.7539 (5.2681)	Learning Rate [0.00125]
14: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00119 (0.00096)	Tok/s 52862 (54261)	Loss/tok 3.8889 (5.2691)	Learning Rate [0.00125]
3: TRAIN [0][1250/3416]	Time 0.057 (0.058)	Data 0.00117 (0.00094)	Tok/s 52381 (53346)	Loss/tok 4.0126 (5.2632)	Learning Rate [0.00125]
4: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00110 (0.00099)	Tok/s 31999 (53388)	Loss/tok 3.4298 (5.2558)	Learning Rate [0.00125]
5: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00095)	Tok/s 32059 (53475)	Loss/tok 3.2325 (5.2571)	Learning Rate [0.00125]
3: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00094)	Tok/s 31965 (53302)	Loss/tok 3.4205 (5.2539)	Learning Rate [0.00125]
6: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00121 (0.00093)	Tok/s 32052 (53546)	Loss/tok 3.3235 (5.2511)	Learning Rate [0.00125]
1: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00094)	Tok/s 31818 (53099)	Loss/tok 3.4484 (5.2521)	Learning Rate [0.00125]
2: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00100)	Tok/s 31883 (53195)	Loss/tok 3.2539 (5.2582)	Learning Rate [0.00125]
7: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00095)	Tok/s 32056 (53628)	Loss/tok 3.3576 (5.2524)	Learning Rate [0.00125]
0: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00111 (0.00097)	Tok/s 31697 (53005)	Loss/tok 3.1064 (5.2640)	Learning Rate [0.00125]
9: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00093)	Tok/s 31943 (53767)	Loss/tok 3.2808 (5.2506)	Learning Rate [0.00125]
8: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00093)	Tok/s 31972 (53707)	Loss/tok 3.1720 (5.2465)	Learning Rate [0.00125]
15: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00093)	Tok/s 33023 (54330)	Loss/tok 3.5644 (5.2556)	Learning Rate [0.00125]
10: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00096)	Tok/s 31852 (53840)	Loss/tok 3.2674 (5.2580)	Learning Rate [0.00125]
14: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00096)	Tok/s 33023 (54215)	Loss/tok 3.1870 (5.2594)	Learning Rate [0.00125]
13: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00096)	Tok/s 33003 (54109)	Loss/tok 3.3747 (5.2543)	Learning Rate [0.00125]
11: TRAIN [0][1260/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00092)	Tok/s 31755 (53913)	Loss/tok 3.2364 (5.2604)	Learning Rate [0.00125]
12: TRAIN [0][1260/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00095)	Tok/s 32845 (54016)	Loss/tok 3.3874 (5.2577)	Learning Rate [0.00125]
9: Gradient norm: inf
10: Gradient norm: inf
11: Gradient norm: inf
9: Skipped batch, new scale: 256.0
10: Skipped batch, new scale: 256.0
0: Gradient norm: inf
12: Gradient norm: inf
11: Skipped batch, new scale: 256.0
7: Gradient norm: inf
1: Gradient norm: inf
15: Gradient norm: inf
0: Skipped batch, new scale: 256.0
12: Skipped batch, new scale: 256.0
7: Skipped batch, new scale: 256.0
8: Gradient norm: inf
14: Gradient norm: inf
6: Gradient norm: inf
13: Gradient norm: inf
1: Skipped batch, new scale: 256.0
2: Gradient norm: inf
15: Skipped batch, new scale: 256.0
5: Gradient norm: inf
14: Skipped batch, new scale: 256.0
6: Skipped batch, new scale: 256.0
13: Skipped batch, new scale: 256.0
8: Skipped batch, new scale: 256.0
4: Gradient norm: inf
2: Skipped batch, new scale: 256.0
3: Gradient norm: inf
5: Skipped batch, new scale: 256.0
4: Skipped batch, new scale: 256.0
3: Skipped batch, new scale: 256.0
7: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00095)	Tok/s 48446 (53677)	Loss/tok 3.4921 (5.2398)	Learning Rate [0.00125]
6: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00093)	Tok/s 48366 (53594)	Loss/tok 3.7653 (5.2387)	Learning Rate [0.00125]
8: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00093)	Tok/s 48391 (53758)	Loss/tok 3.6863 (5.2339)	Learning Rate [0.00125]
9: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00093)	Tok/s 48275 (53818)	Loss/tok 3.5705 (5.2375)	Learning Rate [0.00125]
4: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00116 (0.00099)	Tok/s 48056 (53437)	Loss/tok 3.4337 (5.2428)	Learning Rate [0.00125]
5: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00095)	Tok/s 48229 (53524)	Loss/tok 3.7265 (5.2446)	Learning Rate [0.00125]
10: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00096)	Tok/s 48236 (53891)	Loss/tok 3.5637 (5.2451)	Learning Rate [0.00125]
3: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00094)	Tok/s 47952 (53352)	Loss/tok 3.5219 (5.2415)	Learning Rate [0.00125]
11: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00110 (0.00092)	Tok/s 48184 (53964)	Loss/tok 3.8381 (5.2477)	Learning Rate [0.00125]
12: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00095)	Tok/s 48210 (54067)	Loss/tok 3.6531 (5.2451)	Learning Rate [0.00125]
1: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00094)	Tok/s 47961 (53148)	Loss/tok 3.5358 (5.2401)	Learning Rate [0.00125]
0: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00104 (0.00097)	Tok/s 47986 (53054)	Loss/tok 3.8042 (5.2516)	Learning Rate [0.00125]
13: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00096)	Tok/s 49226 (54161)	Loss/tok 3.3141 (5.2414)	Learning Rate [0.00125]
2: TRAIN [0][1270/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00100)	Tok/s 47817 (53245)	Loss/tok 3.5651 (5.2457)	Learning Rate [0.00125]
15: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00093)	Tok/s 49384 (54383)	Loss/tok 3.8304 (5.2431)	Learning Rate [0.00125]
14: TRAIN [0][1270/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00096)	Tok/s 49418 (54267)	Loss/tok 3.5575 (5.2470)	Learning Rate [0.00125]
12: TRAIN [0][1280/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00095)	Tok/s 36202 (54025)	Loss/tok 3.6174 (5.2358)	Learning Rate [0.00125]
11: TRAIN [0][1280/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 36186 (53923)	Loss/tok 3.5751 (5.2380)	Learning Rate [0.00125]
13: TRAIN [0][1280/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00096)	Tok/s 36196 (54118)	Loss/tok 3.4743 (5.2323)	Learning Rate [0.00125]
10: TRAIN [0][1280/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00096)	Tok/s 36123 (53849)	Loss/tok 3.5062 (5.2355)	Learning Rate [0.00125]
14: TRAIN [0][1280/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00096)	Tok/s 36156 (54224)	Loss/tok 3.3201 (5.2372)	Learning Rate [0.00125]
9: TRAIN [0][1280/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00093)	Tok/s 36034 (53776)	Loss/tok 3.7977 (5.2285)	Learning Rate [0.00125]
15: TRAIN [0][1280/3416]	Time 0.051 (0.058)	Data 0.00080 (0.00093)	Tok/s 36078 (54340)	Loss/tok 3.5414 (5.2338)	Learning Rate [0.00125]
8: TRAIN [0][1280/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00093)	Tok/s 35937 (53716)	Loss/tok 3.5806 (5.2251)	Learning Rate [0.00125]
0: TRAIN [0][1280/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00097)	Tok/s 35410 (53016)	Loss/tok 3.3899 (5.2430)	Learning Rate [0.00125]
1: TRAIN [0][1280/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00094)	Tok/s 35911 (53109)	Loss/tok 3.6233 (5.2308)	Learning Rate [0.00125]
7: TRAIN [0][1280/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00095)	Tok/s 35855 (53634)	Loss/tok 3.4887 (5.2309)	Learning Rate [0.00125]
6: TRAIN [0][1280/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00093)	Tok/s 35757 (53552)	Loss/tok 3.8279 (5.2294)	Learning Rate [0.00125]
5: TRAIN [0][1280/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00095)	Tok/s 35710 (53482)	Loss/tok 3.6470 (5.2357)	Learning Rate [0.00125]
4: TRAIN [0][1280/3416]	Time 0.052 (0.058)	Data 0.00111 (0.00099)	Tok/s 35695 (53396)	Loss/tok 3.5151 (5.2336)	Learning Rate [0.00125]
3: TRAIN [0][1280/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00094)	Tok/s 35753 (53311)	Loss/tok 3.1852 (5.2318)	Learning Rate [0.00125]
2: TRAIN [0][1280/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00100)	Tok/s 35839 (53205)	Loss/tok 3.6143 (5.2363)	Learning Rate [0.00125]
4: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00115 (0.00099)	Tok/s 57307 (53419)	Loss/tok 4.2138 (5.2223)	Learning Rate [0.00125]
3: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00094)	Tok/s 56407 (53334)	Loss/tok 4.1286 (5.2207)	Learning Rate [0.00125]
5: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00095)	Tok/s 57347 (53505)	Loss/tok 3.9823 (5.2248)	Learning Rate [0.00125]
2: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00100)	Tok/s 56164 (53229)	Loss/tok 3.9272 (5.2245)	Learning Rate [0.00125]
6: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00093)	Tok/s 57310 (53574)	Loss/tok 4.0044 (5.2186)	Learning Rate [0.00125]
1: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00094)	Tok/s 56068 (53133)	Loss/tok 4.0553 (5.2195)	Learning Rate [0.00125]
7: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00095)	Tok/s 57318 (53657)	Loss/tok 3.8865 (5.2199)	Learning Rate [0.00125]
8: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00092)	Tok/s 57330 (53738)	Loss/tok 4.0186 (5.2137)	Learning Rate [0.00125]
0: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00108 (0.00097)	Tok/s 56037 (53040)	Loss/tok 3.8937 (5.2325)	Learning Rate [0.00125]
15: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00093)	Tok/s 57021 (54365)	Loss/tok 3.8257 (5.2222)	Learning Rate [0.00125]
9: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00093)	Tok/s 57231 (53800)	Loss/tok 4.0229 (5.2181)	Learning Rate [0.00125]
11: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00092)	Tok/s 57121 (53947)	Loss/tok 4.1484 (5.2270)	Learning Rate [0.00125]
10: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00096)	Tok/s 57195 (53873)	Loss/tok 3.9428 (5.2242)	Learning Rate [0.00125]
13: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00096)	Tok/s 57013 (54143)	Loss/tok 3.9218 (5.2206)	Learning Rate [0.00125]
12: TRAIN [0][1290/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00095)	Tok/s 56993 (54050)	Loss/tok 3.9346 (5.2243)	Learning Rate [0.00125]
14: TRAIN [0][1290/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00096)	Tok/s 56751 (54248)	Loss/tok 4.0598 (5.2266)	Learning Rate [0.00125]
8: TRAIN [0][1300/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00092)	Tok/s 53909 (53746)	Loss/tok 4.0412 (5.2034)	Learning Rate [0.00125]
9: TRAIN [0][1300/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00093)	Tok/s 53975 (53808)	Loss/tok 3.9850 (5.2078)	Learning Rate [0.00125]
7: TRAIN [0][1300/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00095)	Tok/s 53838 (53665)	Loss/tok 4.2260 (5.2097)	Learning Rate [0.00125]
11: TRAIN [0][1300/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00092)	Tok/s 53769 (53954)	Loss/tok 3.7607 (5.2162)	Learning Rate [0.00125]
6: TRAIN [0][1300/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00093)	Tok/s 53632 (53584)	Loss/tok 4.0101 (5.2090)	Learning Rate [0.00125]
12: TRAIN [0][1300/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00095)	Tok/s 53704 (54057)	Loss/tok 3.8156 (5.2138)	Learning Rate [0.00125]
13: TRAIN [0][1300/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00096)	Tok/s 53614 (54150)	Loss/tok 3.9593 (5.2105)	Learning Rate [0.00125]
5: TRAIN [0][1300/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00094)	Tok/s 53649 (53514)	Loss/tok 3.9874 (5.2144)	Learning Rate [0.00125]
4: TRAIN [0][1300/3416]	Time 0.059 (0.058)	Data 0.00114 (0.00099)	Tok/s 53540 (53429)	Loss/tok 3.7945 (5.2120)	Learning Rate [0.00125]
14: TRAIN [0][1300/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00096)	Tok/s 53472 (54255)	Loss/tok 4.0045 (5.2166)	Learning Rate [0.00125]
15: TRAIN [0][1300/3416]	Time 0.059 (0.058)	Data 0.00079 (0.00093)	Tok/s 53397 (54372)	Loss/tok 3.7340 (5.2111)	Learning Rate [0.00125]
3: TRAIN [0][1300/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00094)	Tok/s 53397 (53343)	Loss/tok 3.6869 (5.2100)	Learning Rate [0.00125]
2: TRAIN [0][1300/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00100)	Tok/s 53268 (53238)	Loss/tok 4.1314 (5.2139)	Learning Rate [0.00125]
1: TRAIN [0][1300/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00094)	Tok/s 53196 (53144)	Loss/tok 4.0813 (5.2092)	Learning Rate [0.00125]
0: TRAIN [0][1300/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00097)	Tok/s 53265 (53051)	Loss/tok 3.8968 (5.2220)	Learning Rate [0.00125]
10: TRAIN [0][1300/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00096)	Tok/s 53482 (53880)	Loss/tok 3.9657 (5.2138)	Learning Rate [0.00125]
9: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00093)	Tok/s 61903 (53803)	Loss/tok 3.8995 (5.1977)	Learning Rate [0.00125]
8: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 61835 (53741)	Loss/tok 3.9156 (5.1928)	Learning Rate [0.00125]
7: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00095)	Tok/s 61872 (53659)	Loss/tok 3.8361 (5.1993)	Learning Rate [0.00125]
11: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 61911 (53949)	Loss/tok 4.0064 (5.2061)	Learning Rate [0.00125]
10: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 61915 (53875)	Loss/tok 4.0326 (5.2040)	Learning Rate [0.00125]
6: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00094)	Tok/s 61849 (53577)	Loss/tok 4.1088 (5.1989)	Learning Rate [0.00125]
12: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00095)	Tok/s 61980 (54053)	Loss/tok 3.8771 (5.2034)	Learning Rate [0.00125]
13: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00096)	Tok/s 62008 (54145)	Loss/tok 4.0072 (5.1995)	Learning Rate [0.00125]
4: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00099)	Tok/s 61880 (53419)	Loss/tok 4.0633 (5.2016)	Learning Rate [0.00125]
3: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00094)	Tok/s 61860 (53333)	Loss/tok 3.9467 (5.2001)	Learning Rate [0.00125]
14: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00096)	Tok/s 62555 (54250)	Loss/tok 3.8365 (5.2058)	Learning Rate [0.00125]
15: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00093)	Tok/s 62875 (54368)	Loss/tok 3.8754 (5.2005)	Learning Rate [0.00125]
2: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00100)	Tok/s 61882 (53227)	Loss/tok 3.7060 (5.2034)	Learning Rate [0.00125]
1: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00094)	Tok/s 61885 (53130)	Loss/tok 4.0193 (5.1991)	Learning Rate [0.00125]
0: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 61952 (53037)	Loss/tok 4.1690 (5.2128)	Learning Rate [0.00125]
5: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00094)	Tok/s 61772 (53507)	Loss/tok 3.9598 (5.2042)	Learning Rate [0.00125]
6: TRAIN [0][1320/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00094)	Tok/s 54586 (53581)	Loss/tok 3.9292 (5.1889)	Learning Rate [0.00125]
5: TRAIN [0][1320/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00094)	Tok/s 54587 (53512)	Loss/tok 4.0564 (5.1931)	Learning Rate [0.00125]
7: TRAIN [0][1320/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00095)	Tok/s 54462 (53664)	Loss/tok 3.9659 (5.1885)	Learning Rate [0.00125]
8: TRAIN [0][1320/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00092)	Tok/s 54365 (53746)	Loss/tok 3.9247 (5.1826)	Learning Rate [0.00125]
3: TRAIN [0][1320/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00094)	Tok/s 54570 (53339)	Loss/tok 4.0213 (5.1891)	Learning Rate [0.00125]
9: TRAIN [0][1320/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00093)	Tok/s 54290 (53807)	Loss/tok 4.0643 (5.1872)	Learning Rate [0.00125]
1: TRAIN [0][1320/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00094)	Tok/s 54560 (53137)	Loss/tok 4.0959 (5.1883)	Learning Rate [0.00125]
4: TRAIN [0][1320/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00099)	Tok/s 54458 (53424)	Loss/tok 3.8620 (5.1908)	Learning Rate [0.00125]
2: TRAIN [0][1320/3416]	Time 0.064 (0.058)	Data 0.00108 (0.00100)	Tok/s 54620 (53234)	Loss/tok 3.8631 (5.1921)	Learning Rate [0.00125]
11: TRAIN [0][1320/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00092)	Tok/s 54271 (53953)	Loss/tok 4.0933 (5.1955)	Learning Rate [0.00125]
0: TRAIN [0][1320/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00097)	Tok/s 54522 (53044)	Loss/tok 3.8801 (5.2020)	Learning Rate [0.00125]
15: TRAIN [0][1320/3416]	Time 0.065 (0.058)	Data 0.00107 (0.00093)	Tok/s 54521 (54371)	Loss/tok 3.9183 (5.1901)	Learning Rate [0.00125]
14: TRAIN [0][1320/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00096)	Tok/s 54838 (54253)	Loss/tok 3.9739 (5.1951)	Learning Rate [0.00125]
13: TRAIN [0][1320/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00096)	Tok/s 54378 (54148)	Loss/tok 3.8572 (5.1890)	Learning Rate [0.00125]
10: TRAIN [0][1320/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00096)	Tok/s 54362 (53879)	Loss/tok 4.1531 (5.1932)	Learning Rate [0.00125]
12: TRAIN [0][1320/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00095)	Tok/s 54302 (54056)	Loss/tok 4.1151 (5.1931)	Learning Rate [0.00125]
3: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00094)	Tok/s 49472 (53366)	Loss/tok 3.7753 (5.1785)	Learning Rate [0.00125]
4: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00099)	Tok/s 49557 (53451)	Loss/tok 3.6032 (5.1801)	Learning Rate [0.00125]
1: TRAIN [0][1330/3416]	Time 0.055 (0.058)	Data 0.00085 (0.00094)	Tok/s 49681 (53165)	Loss/tok 3.6552 (5.1774)	Learning Rate [0.00125]
6: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00094)	Tok/s 49346 (53607)	Loss/tok 3.8143 (5.1784)	Learning Rate [0.00125]
5: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00094)	Tok/s 49387 (53538)	Loss/tok 3.8368 (5.1824)	Learning Rate [0.00125]
2: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00101 (0.00100)	Tok/s 49566 (53261)	Loss/tok 3.8179 (5.1813)	Learning Rate [0.00125]
7: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00095)	Tok/s 49743 (53690)	Loss/tok 3.6124 (5.1778)	Learning Rate [0.00125]
15: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00093)	Tok/s 50396 (54398)	Loss/tok 3.9573 (5.1796)	Learning Rate [0.00125]
8: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00110 (0.00092)	Tok/s 50272 (53771)	Loss/tok 3.6531 (5.1718)	Learning Rate [0.00125]
14: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00103 (0.00096)	Tok/s 50312 (54280)	Loss/tok 3.8438 (5.1852)	Learning Rate [0.00125]
9: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00093)	Tok/s 50244 (53833)	Loss/tok 3.7152 (5.1767)	Learning Rate [0.00125]
13: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00109 (0.00096)	Tok/s 50261 (54175)	Loss/tok 3.5419 (5.1781)	Learning Rate [0.00125]
11: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00092)	Tok/s 50174 (53980)	Loss/tok 3.8139 (5.1847)	Learning Rate [0.00125]
12: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00095)	Tok/s 50134 (54084)	Loss/tok 3.8143 (5.1825)	Learning Rate [0.00125]
10: TRAIN [0][1330/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00096)	Tok/s 50158 (53905)	Loss/tok 3.7963 (5.1825)	Learning Rate [0.00125]
0: TRAIN [0][1330/3416]	Time 0.057 (0.058)	Data 0.00132 (0.00097)	Tok/s 48613 (53071)	Loss/tok 3.7501 (5.1919)	Learning Rate [0.00125]
4: TRAIN [0][1340/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00099)	Tok/s 54188 (53525)	Loss/tok 3.5588 (5.1680)	Learning Rate [0.00125]
5: TRAIN [0][1340/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00094)	Tok/s 54160 (53613)	Loss/tok 4.0443 (5.1699)	Learning Rate [0.00125]
3: TRAIN [0][1340/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00094)	Tok/s 54009 (53440)	Loss/tok 3.8123 (5.1667)	Learning Rate [0.00125]
6: TRAIN [0][1340/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00094)	Tok/s 54113 (53682)	Loss/tok 3.6401 (5.1656)	Learning Rate [0.00125]
2: TRAIN [0][1340/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00100)	Tok/s 53985 (53336)	Loss/tok 3.8671 (5.1687)	Learning Rate [0.00125]
7: TRAIN [0][1340/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00095)	Tok/s 54209 (53764)	Loss/tok 3.9137 (5.1661)	Learning Rate [0.00125]
1: TRAIN [0][1340/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00094)	Tok/s 53888 (53239)	Loss/tok 3.9072 (5.1642)	Learning Rate [0.00125]
8: TRAIN [0][1340/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00092)	Tok/s 54148 (53845)	Loss/tok 3.7669 (5.1600)	Learning Rate [0.00125]
0: TRAIN [0][1340/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00097)	Tok/s 53764 (53146)	Loss/tok 3.6393 (5.1794)	Learning Rate [0.00125]
13: TRAIN [0][1340/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00096)	Tok/s 54969 (54249)	Loss/tok 3.8923 (5.1657)	Learning Rate [0.00125]
15: TRAIN [0][1340/3416]	Time 0.060 (0.058)	Data 0.00083 (0.00093)	Tok/s 54781 (54471)	Loss/tok 3.9651 (5.1671)	Learning Rate [0.00125]
11: TRAIN [0][1340/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00092)	Tok/s 54880 (54056)	Loss/tok 3.9675 (5.1720)	Learning Rate [0.00125]
14: TRAIN [0][1340/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00096)	Tok/s 54792 (54353)	Loss/tok 3.8072 (5.1721)	Learning Rate [0.00125]
10: TRAIN [0][1340/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00096)	Tok/s 55045 (53981)	Loss/tok 3.6830 (5.1699)	Learning Rate [0.00125]
9: TRAIN [0][1340/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00093)	Tok/s 54056 (53907)	Loss/tok 3.9077 (5.1643)	Learning Rate [0.00125]
12: TRAIN [0][1340/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00095)	Tok/s 54922 (54158)	Loss/tok 3.8323 (5.1695)	Learning Rate [0.00125]
1: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00094)	Tok/s 80110 (53221)	Loss/tok 3.8557 (5.1553)	Learning Rate [0.00125]
4: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00099)	Tok/s 80860 (53507)	Loss/tok 3.9412 (5.1592)	Learning Rate [0.00125]
2: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00100)	Tok/s 80294 (53317)	Loss/tok 3.8497 (5.1595)	Learning Rate [0.00125]
7: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00095)	Tok/s 80623 (53746)	Loss/tok 4.0065 (5.1568)	Learning Rate [0.00125]
6: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00094)	Tok/s 80623 (53663)	Loss/tok 3.7845 (5.1560)	Learning Rate [0.00125]
3: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00094)	Tok/s 80938 (53422)	Loss/tok 3.7973 (5.1576)	Learning Rate [0.00125]
8: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 80485 (53826)	Loss/tok 4.0220 (5.1510)	Learning Rate [0.00125]
0: TRAIN [0][1350/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 81246 (53129)	Loss/tok 3.7306 (5.1702)	Learning Rate [0.00125]
10: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 81497 (53962)	Loss/tok 3.7602 (5.1612)	Learning Rate [0.00125]
5: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00094)	Tok/s 80721 (53594)	Loss/tok 3.8911 (5.1616)	Learning Rate [0.00125]
13: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 81716 (54228)	Loss/tok 3.8182 (5.1559)	Learning Rate [0.00125]
14: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00096)	Tok/s 81810 (54332)	Loss/tok 3.7716 (5.1627)	Learning Rate [0.00125]
15: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00093)	Tok/s 82517 (54450)	Loss/tok 3.6804 (5.1575)	Learning Rate [0.00125]
9: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 80837 (53888)	Loss/tok 3.8631 (5.1554)	Learning Rate [0.00125]
12: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00095)	Tok/s 81531 (54138)	Loss/tok 3.7243 (5.1602)	Learning Rate [0.00125]
11: TRAIN [0][1350/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 81418 (54036)	Loss/tok 3.9806 (5.1627)	Learning Rate [0.00125]
6: TRAIN [0][1360/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00094)	Tok/s 55161 (53618)	Loss/tok 4.0904 (5.1476)	Learning Rate [0.00125]
5: TRAIN [0][1360/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00094)	Tok/s 55211 (53548)	Loss/tok 3.7534 (5.1530)	Learning Rate [0.00125]
7: TRAIN [0][1360/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00095)	Tok/s 55168 (53702)	Loss/tok 3.7902 (5.1485)	Learning Rate [0.00125]
4: TRAIN [0][1360/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00099)	Tok/s 55148 (53460)	Loss/tok 3.8430 (5.1511)	Learning Rate [0.00125]
8: TRAIN [0][1360/3416]	Time 0.062 (0.058)	Data 0.00081 (0.00092)	Tok/s 54989 (53784)	Loss/tok 4.0441 (5.1423)	Learning Rate [0.00125]
3: TRAIN [0][1360/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00094)	Tok/s 55170 (53373)	Loss/tok 3.9745 (5.1494)	Learning Rate [0.00125]
9: TRAIN [0][1360/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00093)	Tok/s 54968 (53848)	Loss/tok 4.0492 (5.1474)	Learning Rate [0.00125]
2: TRAIN [0][1360/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00100)	Tok/s 55144 (53267)	Loss/tok 3.3792 (5.1506)	Learning Rate [0.00125]
1: TRAIN [0][1360/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00094)	Tok/s 55157 (53170)	Loss/tok 3.6087 (5.1467)	Learning Rate [0.00125]
11: TRAIN [0][1360/3416]	Time 0.062 (0.058)	Data 0.00085 (0.00091)	Tok/s 54990 (53995)	Loss/tok 3.8338 (5.1542)	Learning Rate [0.00125]
0: TRAIN [0][1360/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00097)	Tok/s 55138 (53076)	Loss/tok 3.8948 (5.1622)	Learning Rate [0.00125]
12: TRAIN [0][1360/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00095)	Tok/s 55009 (54096)	Loss/tok 3.8750 (5.1519)	Learning Rate [0.00125]
15: TRAIN [0][1360/3416]	Time 0.062 (0.058)	Data 0.00084 (0.00093)	Tok/s 55113 (54410)	Loss/tok 3.7568 (5.1495)	Learning Rate [0.00125]
13: TRAIN [0][1360/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00096)	Tok/s 54953 (54187)	Loss/tok 3.8063 (5.1475)	Learning Rate [0.00125]
14: TRAIN [0][1360/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00096)	Tok/s 55175 (54292)	Loss/tok 4.0563 (5.1543)	Learning Rate [0.00125]
10: TRAIN [0][1360/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00096)	Tok/s 54900 (53921)	Loss/tok 3.8918 (5.1527)	Learning Rate [0.00125]
5: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00094)	Tok/s 45617 (53549)	Loss/tok 3.7506 (5.1436)	Learning Rate [0.00125]
6: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00103 (0.00094)	Tok/s 45601 (53620)	Loss/tok 3.6375 (5.1387)	Learning Rate [0.00125]
4: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00112 (0.00099)	Tok/s 45441 (53461)	Loss/tok 3.8322 (5.1418)	Learning Rate [0.00125]
3: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00106 (0.00094)	Tok/s 45405 (53375)	Loss/tok 3.5605 (5.1402)	Learning Rate [0.00125]
2: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00104 (0.00100)	Tok/s 45367 (53270)	Loss/tok 3.4759 (5.1415)	Learning Rate [0.00125]
7: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00095)	Tok/s 45477 (53703)	Loss/tok 3.6872 (5.1388)	Learning Rate [0.00125]
8: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00092)	Tok/s 45536 (53785)	Loss/tok 3.3350 (5.1326)	Learning Rate [0.00125]
1: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00094)	Tok/s 45320 (53172)	Loss/tok 3.7779 (5.1373)	Learning Rate [0.00125]
9: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00104 (0.00093)	Tok/s 45470 (53848)	Loss/tok 3.7298 (5.1381)	Learning Rate [0.00125]
0: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00097)	Tok/s 45381 (53079)	Loss/tok 3.4599 (5.1525)	Learning Rate [0.00125]
15: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00093)	Tok/s 45355 (54409)	Loss/tok 3.6843 (5.1402)	Learning Rate [0.00125]
11: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00109 (0.00091)	Tok/s 45547 (53996)	Loss/tok 3.6022 (5.1440)	Learning Rate [0.00125]
14: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00104 (0.00096)	Tok/s 45382 (54291)	Loss/tok 3.6901 (5.1451)	Learning Rate [0.00125]
13: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00120 (0.00096)	Tok/s 45359 (54187)	Loss/tok 3.6408 (5.1381)	Learning Rate [0.00125]
12: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00109 (0.00095)	Tok/s 45425 (54096)	Loss/tok 3.3994 (5.1428)	Learning Rate [0.00125]
10: TRAIN [0][1370/3416]	Time 0.045 (0.058)	Data 0.00109 (0.00096)	Tok/s 45577 (53922)	Loss/tok 3.8282 (5.1433)	Learning Rate [0.00125]
6: TRAIN [0][1380/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 64495 (53650)	Loss/tok 3.8851 (5.1281)	Learning Rate [0.00125]
5: TRAIN [0][1380/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00094)	Tok/s 64507 (53579)	Loss/tok 3.9643 (5.1329)	Learning Rate [0.00125]
4: TRAIN [0][1380/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00099)	Tok/s 64562 (53491)	Loss/tok 3.7236 (5.1302)	Learning Rate [0.00125]
2: TRAIN [0][1380/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00100)	Tok/s 64577 (53300)	Loss/tok 3.9236 (5.1310)	Learning Rate [0.00125]
8: TRAIN [0][1380/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 64450 (53815)	Loss/tok 4.0400 (5.1219)	Learning Rate [0.00125]
1: TRAIN [0][1380/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00094)	Tok/s 64481 (53203)	Loss/tok 4.2711 (5.1272)	Learning Rate [0.00125]
3: TRAIN [0][1380/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00094)	Tok/s 64567 (53405)	Loss/tok 3.9514 (5.1299)	Learning Rate [0.00125]
9: TRAIN [0][1380/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 64469 (53879)	Loss/tok 3.8032 (5.1274)	Learning Rate [0.00125]
7: TRAIN [0][1380/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00095)	Tok/s 64447 (53733)	Loss/tok 4.0283 (5.1282)	Learning Rate [0.00125]
0: TRAIN [0][1380/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 64532 (53110)	Loss/tok 3.8480 (5.1422)	Learning Rate [0.00125]
15: TRAIN [0][1380/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00093)	Tok/s 65459 (54439)	Loss/tok 3.9901 (5.1297)	Learning Rate [0.00125]
11: TRAIN [0][1380/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00091)	Tok/s 64466 (54026)	Loss/tok 4.1587 (5.1338)	Learning Rate [0.00125]
10: TRAIN [0][1380/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00096)	Tok/s 64413 (53953)	Loss/tok 3.9890 (5.1327)	Learning Rate [0.00125]
14: TRAIN [0][1380/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 65082 (54321)	Loss/tok 4.0655 (5.1350)	Learning Rate [0.00125]
13: TRAIN [0][1380/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00096)	Tok/s 64420 (54217)	Loss/tok 3.8379 (5.1279)	Learning Rate [0.00125]
12: TRAIN [0][1380/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00095)	Tok/s 64404 (54127)	Loss/tok 3.8039 (5.1321)	Learning Rate [0.00125]
6: TRAIN [0][1390/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00094)	Tok/s 52920 (53665)	Loss/tok 4.0407 (5.1185)	Learning Rate [0.00125]
5: TRAIN [0][1390/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00094)	Tok/s 52992 (53594)	Loss/tok 3.8635 (5.1235)	Learning Rate [0.00125]
4: TRAIN [0][1390/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00099)	Tok/s 53056 (53506)	Loss/tok 3.8951 (5.1204)	Learning Rate [0.00125]
7: TRAIN [0][1390/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00095)	Tok/s 52821 (53748)	Loss/tok 4.0636 (5.1188)	Learning Rate [0.00125]
8: TRAIN [0][1390/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00092)	Tok/s 52695 (53829)	Loss/tok 3.8716 (5.1124)	Learning Rate [0.00125]
9: TRAIN [0][1390/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00093)	Tok/s 52651 (53894)	Loss/tok 3.6183 (5.1181)	Learning Rate [0.00125]
3: TRAIN [0][1390/3416]	Time 0.060 (0.058)	Data 0.00084 (0.00094)	Tok/s 52988 (53421)	Loss/tok 3.8588 (5.1197)	Learning Rate [0.00125]
2: TRAIN [0][1390/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00100)	Tok/s 53024 (53317)	Loss/tok 3.9226 (5.1216)	Learning Rate [0.00125]
1: TRAIN [0][1390/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00094)	Tok/s 52996 (53220)	Loss/tok 4.0651 (5.1178)	Learning Rate [0.00125]
10: TRAIN [0][1390/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00096)	Tok/s 52725 (53967)	Loss/tok 3.9890 (5.1239)	Learning Rate [0.00125]
11: TRAIN [0][1390/3416]	Time 0.061 (0.058)	Data 0.00082 (0.00091)	Tok/s 52704 (54041)	Loss/tok 3.8343 (5.1244)	Learning Rate [0.00125]
15: TRAIN [0][1390/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00093)	Tok/s 53082 (54452)	Loss/tok 3.7369 (5.1199)	Learning Rate [0.00125]
0: TRAIN [0][1390/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00097)	Tok/s 51922 (53126)	Loss/tok 3.7919 (5.1324)	Learning Rate [0.00125]
12: TRAIN [0][1390/3416]	Time 0.061 (0.058)	Data 0.00105 (0.00095)	Tok/s 52621 (54142)	Loss/tok 3.9021 (5.1229)	Learning Rate [0.00125]
14: TRAIN [0][1390/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00096)	Tok/s 52859 (54334)	Loss/tok 3.8842 (5.1257)	Learning Rate [0.00125]
13: TRAIN [0][1390/3416]	Time 0.061 (0.058)	Data 0.00104 (0.00096)	Tok/s 52732 (54231)	Loss/tok 4.0283 (5.1189)	Learning Rate [0.00125]
9: Upscaling, new scale: 512.0
10: Upscaling, new scale: 512.0
11: Upscaling, new scale: 512.0
8: Upscaling, new scale: 512.0
13: Upscaling, new scale: 512.0
14: Upscaling, new scale: 512.0
15: Upscaling, new scale: 512.0
0: Upscaling, new scale: 512.0
4: Upscaling, new scale: 512.0
1: Upscaling, new scale: 512.0
2: Upscaling, new scale: 512.0
7: Upscaling, new scale: 512.0
3: Upscaling, new scale: 512.0
6: Upscaling, new scale: 512.0
5: Upscaling, new scale: 512.0
12: Upscaling, new scale: 512.0
1: TRAIN [0][1400/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00094)	Tok/s 52680 (53233)	Loss/tok 4.3191 (5.1088)	Learning Rate [0.00125]
2: TRAIN [0][1400/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00100)	Tok/s 52578 (53331)	Loss/tok 3.9378 (5.1113)	Learning Rate [0.00125]
0: TRAIN [0][1400/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00097)	Tok/s 52653 (53139)	Loss/tok 4.0177 (5.1230)	Learning Rate [0.00125]
3: TRAIN [0][1400/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00094)	Tok/s 52465 (53434)	Loss/tok 3.9850 (5.1096)	Learning Rate [0.00125]
15: TRAIN [0][1400/3416]	Time 0.063 (0.058)	Data 0.00081 (0.00093)	Tok/s 53604 (54463)	Loss/tok 3.8196 (5.1096)	Learning Rate [0.00125]
4: TRAIN [0][1400/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00099)	Tok/s 52366 (53519)	Loss/tok 3.8305 (5.1110)	Learning Rate [0.00125]
14: TRAIN [0][1400/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00096)	Tok/s 53687 (54346)	Loss/tok 3.7847 (5.1156)	Learning Rate [0.00125]
6: TRAIN [0][1400/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00094)	Tok/s 53092 (53678)	Loss/tok 4.0855 (5.1091)	Learning Rate [0.00125]
13: TRAIN [0][1400/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00096)	Tok/s 53581 (54243)	Loss/tok 4.1067 (5.1094)	Learning Rate [0.00125]
5: TRAIN [0][1400/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00094)	Tok/s 52346 (53607)	Loss/tok 3.7613 (5.1137)	Learning Rate [0.00125]
12: TRAIN [0][1400/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00095)	Tok/s 53499 (54153)	Loss/tok 3.9411 (5.1132)	Learning Rate [0.00125]
11: TRAIN [0][1400/3416]	Time 0.064 (0.058)	Data 0.00083 (0.00091)	Tok/s 53395 (54052)	Loss/tok 3.7723 (5.1150)	Learning Rate [0.00125]
7: TRAIN [0][1400/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00095)	Tok/s 53300 (53761)	Loss/tok 3.8250 (5.1093)	Learning Rate [0.00125]
9: TRAIN [0][1400/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00093)	Tok/s 53228 (53905)	Loss/tok 3.8053 (5.1086)	Learning Rate [0.00125]
8: TRAIN [0][1400/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00092)	Tok/s 53197 (53841)	Loss/tok 3.9128 (5.1025)	Learning Rate [0.00125]
10: TRAIN [0][1400/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00096)	Tok/s 53323 (53978)	Loss/tok 3.7534 (5.1150)	Learning Rate [0.00125]
13: TRAIN [0][1410/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00096)	Tok/s 52909 (54219)	Loss/tok 4.1777 (5.1013)	Learning Rate [0.00125]
4: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00099)	Tok/s 51299 (53497)	Loss/tok 3.9312 (5.1026)	Learning Rate [0.00125]
5: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00082 (0.00094)	Tok/s 51354 (53586)	Loss/tok 3.9471 (5.1054)	Learning Rate [0.00125]
3: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00094)	Tok/s 51280 (53413)	Loss/tok 3.8226 (5.1013)	Learning Rate [0.00125]
14: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00096)	Tok/s 52763 (54322)	Loss/tok 4.0321 (5.1075)	Learning Rate [0.00125]
6: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00085 (0.00094)	Tok/s 51312 (53656)	Loss/tok 3.6514 (5.1007)	Learning Rate [0.00125]
15: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00093)	Tok/s 52691 (54439)	Loss/tok 3.7226 (5.1007)	Learning Rate [0.00125]
12: TRAIN [0][1410/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00095)	Tok/s 52844 (54130)	Loss/tok 3.4888 (5.1046)	Learning Rate [0.00125]
11: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00091)	Tok/s 52784 (54030)	Loss/tok 3.9384 (5.1061)	Learning Rate [0.00125]
2: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00100)	Tok/s 51284 (53309)	Loss/tok 3.5689 (5.1023)	Learning Rate [0.00125]
1: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00081 (0.00094)	Tok/s 51343 (53211)	Loss/tok 3.7588 (5.0999)	Learning Rate [0.00125]
7: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00095)	Tok/s 51362 (53739)	Loss/tok 3.8522 (5.1009)	Learning Rate [0.00125]
9: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00093)	Tok/s 52612 (53884)	Loss/tok 4.0986 (5.1008)	Learning Rate [0.00125]
0: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00097)	Tok/s 51368 (53117)	Loss/tok 3.7906 (5.1148)	Learning Rate [0.00125]
8: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00092)	Tok/s 51542 (53819)	Loss/tok 3.8419 (5.0940)	Learning Rate [0.00125]
10: TRAIN [0][1410/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00096)	Tok/s 52640 (53956)	Loss/tok 3.8148 (5.1063)	Learning Rate [0.00125]
13: TRAIN [0][1420/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00096)	Tok/s 50646 (54185)	Loss/tok 3.4366 (5.0934)	Learning Rate [0.00125]
12: TRAIN [0][1420/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00095)	Tok/s 50619 (54097)	Loss/tok 3.3639 (5.0968)	Learning Rate [0.00125]
11: TRAIN [0][1420/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00091)	Tok/s 50674 (53996)	Loss/tok 3.7465 (5.0982)	Learning Rate [0.00125]
8: TRAIN [0][1420/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00092)	Tok/s 50521 (53786)	Loss/tok 3.7137 (5.0859)	Learning Rate [0.00125]
9: TRAIN [0][1420/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00093)	Tok/s 50525 (53850)	Loss/tok 3.6753 (5.0927)	Learning Rate [0.00125]
14: TRAIN [0][1420/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00096)	Tok/s 50529 (54288)	Loss/tok 3.5472 (5.0999)	Learning Rate [0.00125]
15: TRAIN [0][1420/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00093)	Tok/s 50464 (54406)	Loss/tok 3.7476 (5.0930)	Learning Rate [0.00125]
10: TRAIN [0][1420/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00096)	Tok/s 50659 (53922)	Loss/tok 3.7492 (5.0977)	Learning Rate [0.00125]
0: TRAIN [0][1420/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00097)	Tok/s 48903 (53075)	Loss/tok 3.6684 (5.1073)	Learning Rate [0.00125]
6: TRAIN [0][1420/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00094)	Tok/s 50282 (53622)	Loss/tok 3.4870 (5.0930)	Learning Rate [0.00125]
7: TRAIN [0][1420/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00095)	Tok/s 50345 (53705)	Loss/tok 3.9479 (5.0928)	Learning Rate [0.00125]
2: TRAIN [0][1420/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00100)	Tok/s 49349 (53270)	Loss/tok 3.6675 (5.0939)	Learning Rate [0.00125]
1: TRAIN [0][1420/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00094)	Tok/s 48804 (53169)	Loss/tok 3.5310 (5.0928)	Learning Rate [0.00125]
5: TRAIN [0][1420/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00094)	Tok/s 50161 (53551)	Loss/tok 3.5863 (5.0973)	Learning Rate [0.00125]
3: TRAIN [0][1420/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00094)	Tok/s 49930 (53375)	Loss/tok 3.7031 (5.0938)	Learning Rate [0.00125]
4: TRAIN [0][1420/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00099)	Tok/s 49961 (53462)	Loss/tok 3.7453 (5.0944)	Learning Rate [0.00125]
5: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00081 (0.00094)	Tok/s 55452 (53498)	Loss/tok 3.9754 (5.0897)	Learning Rate [0.00125]
6: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00081 (0.00094)	Tok/s 55335 (53570)	Loss/tok 4.0091 (5.0858)	Learning Rate [0.00125]
4: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00099)	Tok/s 55473 (53408)	Loss/tok 3.8810 (5.0868)	Learning Rate [0.00125]
3: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00094)	Tok/s 55474 (53318)	Loss/tok 3.7324 (5.0861)	Learning Rate [0.00125]
2: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00100)	Tok/s 55480 (53213)	Loss/tok 3.9455 (5.0863)	Learning Rate [0.00125]
1: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00094)	Tok/s 55528 (53111)	Loss/tok 3.8456 (5.0858)	Learning Rate [0.00125]
7: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00095)	Tok/s 55216 (53654)	Loss/tok 3.6719 (5.0849)	Learning Rate [0.00125]
8: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00092)	Tok/s 55242 (53735)	Loss/tok 3.4195 (5.0780)	Learning Rate [0.00125]
9: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00093)	Tok/s 55286 (53799)	Loss/tok 3.8246 (5.0854)	Learning Rate [0.00125]
0: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00097)	Tok/s 55473 (53014)	Loss/tok 3.7618 (5.1000)	Learning Rate [0.00125]
15: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00080 (0.00093)	Tok/s 56549 (54357)	Loss/tok 3.8043 (5.0850)	Learning Rate [0.00125]
11: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00091)	Tok/s 55313 (53945)	Loss/tok 3.8657 (5.0904)	Learning Rate [0.00125]
10: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00096)	Tok/s 55260 (53871)	Loss/tok 3.7548 (5.0900)	Learning Rate [0.00125]
14: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00096)	Tok/s 56017 (54238)	Loss/tok 3.7620 (5.0927)	Learning Rate [0.00125]
13: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00096)	Tok/s 55462 (54136)	Loss/tok 3.8932 (5.0859)	Learning Rate [0.00125]
12: TRAIN [0][1430/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00095)	Tok/s 55282 (54047)	Loss/tok 3.7855 (5.0890)	Learning Rate [0.00125]
13: TRAIN [0][1440/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00096)	Tok/s 50080 (54119)	Loss/tok 3.7353 (5.0775)	Learning Rate [0.00125]
12: TRAIN [0][1440/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00095)	Tok/s 49978 (54030)	Loss/tok 3.6414 (5.0806)	Learning Rate [0.00125]
14: TRAIN [0][1440/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00096)	Tok/s 50119 (54222)	Loss/tok 3.9768 (5.0846)	Learning Rate [0.00125]
11: TRAIN [0][1440/3416]	Time 0.053 (0.058)	Data 0.00101 (0.00091)	Tok/s 49887 (53927)	Loss/tok 3.7971 (5.0827)	Learning Rate [0.00125]
15: TRAIN [0][1440/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00093)	Tok/s 50030 (54341)	Loss/tok 3.8279 (5.0767)	Learning Rate [0.00125]
10: TRAIN [0][1440/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00096)	Tok/s 49892 (53853)	Loss/tok 4.0738 (5.0817)	Learning Rate [0.00125]
0: TRAIN [0][1440/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00097)	Tok/s 50060 (52998)	Loss/tok 3.8142 (5.0916)	Learning Rate [0.00125]
9: TRAIN [0][1440/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00093)	Tok/s 49849 (53781)	Loss/tok 3.7405 (5.0771)	Learning Rate [0.00125]
1: TRAIN [0][1440/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00094)	Tok/s 50013 (53094)	Loss/tok 3.7758 (5.0779)	Learning Rate [0.00125]
8: TRAIN [0][1440/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00092)	Tok/s 49852 (53717)	Loss/tok 3.8597 (5.0695)	Learning Rate [0.00125]
7: TRAIN [0][1440/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00095)	Tok/s 49825 (53636)	Loss/tok 3.6809 (5.0767)	Learning Rate [0.00125]
6: TRAIN [0][1440/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00094)	Tok/s 49802 (53553)	Loss/tok 3.3983 (5.0772)	Learning Rate [0.00125]
3: TRAIN [0][1440/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00094)	Tok/s 49984 (53302)	Loss/tok 4.0014 (5.0780)	Learning Rate [0.00125]
2: TRAIN [0][1440/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00100)	Tok/s 50042 (53196)	Loss/tok 3.8559 (5.0785)	Learning Rate [0.00125]
5: TRAIN [0][1440/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00094)	Tok/s 49846 (53481)	Loss/tok 4.1817 (5.0813)	Learning Rate [0.00125]
4: TRAIN [0][1440/3416]	Time 0.053 (0.058)	Data 0.00102 (0.00099)	Tok/s 49890 (53391)	Loss/tok 3.9257 (5.0785)	Learning Rate [0.00125]
5: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00094)	Tok/s 51621 (53483)	Loss/tok 3.5476 (5.0716)	Learning Rate [0.00125]
4: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00096 (0.00099)	Tok/s 51725 (53394)	Loss/tok 3.6854 (5.0700)	Learning Rate [0.00125]
3: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00081 (0.00094)	Tok/s 51612 (53304)	Loss/tok 3.4527 (5.0686)	Learning Rate [0.00125]
7: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00100 (0.00095)	Tok/s 51442 (53638)	Loss/tok 3.9026 (5.0677)	Learning Rate [0.00125]
8: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00092)	Tok/s 51442 (53720)	Loss/tok 3.8264 (5.0603)	Learning Rate [0.00125]
9: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00093)	Tok/s 51431 (53784)	Loss/tok 3.7273 (5.0677)	Learning Rate [0.00125]
2: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00103 (0.00100)	Tok/s 51627 (53198)	Loss/tok 3.7901 (5.0695)	Learning Rate [0.00125]
1: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00094)	Tok/s 51636 (53096)	Loss/tok 3.7110 (5.0692)	Learning Rate [0.00125]
0: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00097)	Tok/s 51647 (53001)	Loss/tok 3.6372 (5.0826)	Learning Rate [0.00125]
15: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00079 (0.00093)	Tok/s 51612 (54344)	Loss/tok 3.9268 (5.0676)	Learning Rate [0.00125]
11: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00106 (0.00091)	Tok/s 51452 (53929)	Loss/tok 3.8521 (5.0732)	Learning Rate [0.00125]
10: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00096)	Tok/s 51394 (53856)	Loss/tok 3.7672 (5.0727)	Learning Rate [0.00125]
14: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00111 (0.00096)	Tok/s 51589 (54225)	Loss/tok 3.7303 (5.0760)	Learning Rate [0.00125]
6: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00096 (0.00094)	Tok/s 51537 (53555)	Loss/tok 3.6784 (5.0677)	Learning Rate [0.00125]
13: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00096)	Tok/s 51674 (54121)	Loss/tok 3.6159 (5.0676)	Learning Rate [0.00125]
12: TRAIN [0][1450/3416]	Time 0.056 (0.058)	Data 0.00103 (0.00095)	Tok/s 51500 (54033)	Loss/tok 3.9072 (5.0713)	Learning Rate [0.00125]
4: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00115 (0.00099)	Tok/s 51142 (53400)	Loss/tok 3.5872 (5.0616)	Learning Rate [0.00125]
5: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00094)	Tok/s 51979 (53488)	Loss/tok 3.8649 (5.0633)	Learning Rate [0.00125]
7: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00095)	Tok/s 52022 (53643)	Loss/tok 3.8849 (5.0594)	Learning Rate [0.00125]
3: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00094)	Tok/s 50755 (53310)	Loss/tok 3.9414 (5.0606)	Learning Rate [0.00125]
8: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00117 (0.00092)	Tok/s 52002 (53724)	Loss/tok 3.4393 (5.0514)	Learning Rate [0.00125]
9: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00087 (0.00093)	Tok/s 51996 (53788)	Loss/tok 3.6310 (5.0596)	Learning Rate [0.00125]
2: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00099 (0.00100)	Tok/s 50688 (53204)	Loss/tok 3.5859 (5.0608)	Learning Rate [0.00125]
1: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00094)	Tok/s 50697 (53103)	Loss/tok 3.7436 (5.0608)	Learning Rate [0.00125]
11: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00110 (0.00092)	Tok/s 51844 (53932)	Loss/tok 3.8915 (5.0648)	Learning Rate [0.00125]
0: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00097)	Tok/s 50701 (53008)	Loss/tok 3.8640 (5.0738)	Learning Rate [0.00125]
10: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00096)	Tok/s 51864 (53859)	Loss/tok 3.5925 (5.0640)	Learning Rate [0.00125]
6: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00082 (0.00094)	Tok/s 52068 (53560)	Loss/tok 4.0374 (5.0595)	Learning Rate [0.00125]
15: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00087 (0.00093)	Tok/s 51867 (54348)	Loss/tok 3.9285 (5.0597)	Learning Rate [0.00125]
14: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00110 (0.00096)	Tok/s 51859 (54230)	Loss/tok 3.8415 (5.0672)	Learning Rate [0.00125]
13: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00100 (0.00096)	Tok/s 51796 (54126)	Loss/tok 3.7879 (5.0588)	Learning Rate [0.00125]
12: TRAIN [0][1460/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00095)	Tok/s 51799 (54038)	Loss/tok 3.9144 (5.0636)	Learning Rate [0.00125]
5: TRAIN [0][1470/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00094)	Tok/s 53541 (53489)	Loss/tok 3.7227 (5.0543)	Learning Rate [0.00125]
7: TRAIN [0][1470/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00095)	Tok/s 53426 (53643)	Loss/tok 3.7412 (5.0502)	Learning Rate [0.00125]
9: TRAIN [0][1470/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00093)	Tok/s 53275 (53789)	Loss/tok 3.8102 (5.0509)	Learning Rate [0.00125]
3: TRAIN [0][1470/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00094)	Tok/s 53386 (53311)	Loss/tok 3.8980 (5.0511)	Learning Rate [0.00125]
4: TRAIN [0][1470/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00099)	Tok/s 53484 (53400)	Loss/tok 3.9048 (5.0529)	Learning Rate [0.00125]
2: TRAIN [0][1470/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00100)	Tok/s 53284 (53204)	Loss/tok 4.1295 (5.0520)	Learning Rate [0.00125]
1: TRAIN [0][1470/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00094)	Tok/s 53190 (53103)	Loss/tok 3.6877 (5.0513)	Learning Rate [0.00125]
8: TRAIN [0][1470/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00092)	Tok/s 53340 (53725)	Loss/tok 4.0213 (5.0427)	Learning Rate [0.00125]
11: TRAIN [0][1470/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00092)	Tok/s 53087 (53933)	Loss/tok 3.8394 (5.0559)	Learning Rate [0.00125]
10: TRAIN [0][1470/3416]	Time 0.057 (0.058)	Data 0.00103 (0.00096)	Tok/s 53077 (53860)	Loss/tok 3.8821 (5.0548)	Learning Rate [0.00125]
0: TRAIN [0][1470/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00097)	Tok/s 53079 (53008)	Loss/tok 3.9370 (5.0655)	Learning Rate [0.00125]
6: TRAIN [0][1470/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00094)	Tok/s 53543 (53560)	Loss/tok 3.8717 (5.0505)	Learning Rate [0.00125]
12: TRAIN [0][1470/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00095)	Tok/s 52920 (54039)	Loss/tok 3.6382 (5.0547)	Learning Rate [0.00125]
15: TRAIN [0][1470/3416]	Time 0.057 (0.058)	Data 0.00082 (0.00093)	Tok/s 52992 (54350)	Loss/tok 3.6165 (5.0503)	Learning Rate [0.00125]
14: TRAIN [0][1470/3416]	Time 0.057 (0.058)	Data 0.00103 (0.00096)	Tok/s 52881 (54231)	Loss/tok 3.6295 (5.0586)	Learning Rate [0.00125]
13: TRAIN [0][1470/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00096)	Tok/s 52817 (54128)	Loss/tok 3.8359 (5.0490)	Learning Rate [0.00125]
12: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00095)	Tok/s 60138 (53986)	Loss/tok 3.6589 (5.0470)	Learning Rate [0.00125]
13: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00096)	Tok/s 60265 (54074)	Loss/tok 3.8689 (5.0416)	Learning Rate [0.00125]
11: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00092)	Tok/s 60136 (53879)	Loss/tok 3.7726 (5.0485)	Learning Rate [0.00125]
9: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00093)	Tok/s 60042 (53734)	Loss/tok 4.2047 (5.0436)	Learning Rate [0.00125]
10: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00096)	Tok/s 60053 (53806)	Loss/tok 3.8615 (5.0476)	Learning Rate [0.00125]
14: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00096)	Tok/s 60764 (54178)	Loss/tok 3.8132 (5.0510)	Learning Rate [0.00125]
8: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00092)	Tok/s 59938 (53671)	Loss/tok 3.8133 (5.0353)	Learning Rate [0.00125]
15: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00093)	Tok/s 61201 (54296)	Loss/tok 3.9530 (5.0429)	Learning Rate [0.00125]
2: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00112 (0.00100)	Tok/s 60130 (53153)	Loss/tok 3.9951 (5.0442)	Learning Rate [0.00125]
1: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00094)	Tok/s 60074 (53053)	Loss/tok 3.6630 (5.0432)	Learning Rate [0.00125]
0: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00097)	Tok/s 60209 (52957)	Loss/tok 3.9436 (5.0581)	Learning Rate [0.00125]
7: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00095)	Tok/s 59759 (53590)	Loss/tok 4.0464 (5.0431)	Learning Rate [0.00125]
3: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00094)	Tok/s 60019 (53259)	Loss/tok 3.8067 (5.0433)	Learning Rate [0.00125]
5: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00094)	Tok/s 59893 (53437)	Loss/tok 4.0985 (5.0473)	Learning Rate [0.00125]
4: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00099)	Tok/s 59837 (53348)	Loss/tok 4.0293 (5.0459)	Learning Rate [0.00125]
6: TRAIN [0][1480/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00094)	Tok/s 59780 (53507)	Loss/tok 3.7868 (5.0429)	Learning Rate [0.00125]
11: TRAIN [0][1490/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00092)	Tok/s 38247 (53853)	Loss/tok 3.3715 (5.0400)	Learning Rate [0.00125]
10: TRAIN [0][1490/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00096)	Tok/s 38282 (53781)	Loss/tok 3.6782 (5.0400)	Learning Rate [0.00125]
12: TRAIN [0][1490/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00095)	Tok/s 38171 (53960)	Loss/tok 3.5119 (5.0392)	Learning Rate [0.00125]
9: TRAIN [0][1490/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00093)	Tok/s 38172 (53709)	Loss/tok 3.4159 (5.0358)	Learning Rate [0.00125]
8: TRAIN [0][1490/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00092)	Tok/s 38096 (53646)	Loss/tok 3.5330 (5.0277)	Learning Rate [0.00125]
13: TRAIN [0][1490/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00096)	Tok/s 38060 (54049)	Loss/tok 3.5472 (5.0341)	Learning Rate [0.00125]
7: TRAIN [0][1490/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00095)	Tok/s 38027 (53564)	Loss/tok 3.5281 (5.0351)	Learning Rate [0.00125]
14: TRAIN [0][1490/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00096)	Tok/s 37967 (54152)	Loss/tok 3.3329 (5.0431)	Learning Rate [0.00125]
15: TRAIN [0][1490/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00093)	Tok/s 37869 (54270)	Loss/tok 3.7436 (5.0351)	Learning Rate [0.00125]
5: TRAIN [0][1490/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00094)	Tok/s 36589 (53412)	Loss/tok 3.5358 (5.0391)	Learning Rate [0.00125]
1: TRAIN [0][1490/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00094)	Tok/s 36453 (53028)	Loss/tok 3.4524 (5.0351)	Learning Rate [0.00125]
0: TRAIN [0][1490/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00097)	Tok/s 36526 (52933)	Loss/tok 3.6574 (5.0506)	Learning Rate [0.00125]
3: TRAIN [0][1490/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00094)	Tok/s 36427 (53235)	Loss/tok 3.2406 (5.0348)	Learning Rate [0.00125]
4: TRAIN [0][1490/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00099)	Tok/s 36432 (53324)	Loss/tok 3.5886 (5.0380)	Learning Rate [0.00125]
2: TRAIN [0][1490/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00100)	Tok/s 36381 (53129)	Loss/tok 3.4080 (5.0362)	Learning Rate [0.00125]
6: TRAIN [0][1490/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00094)	Tok/s 37656 (53482)	Loss/tok 3.4897 (5.0350)	Learning Rate [0.00125]
12: TRAIN [0][1500/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00095)	Tok/s 55350 (53952)	Loss/tok 3.9386 (5.0318)	Learning Rate [0.00125]
11: TRAIN [0][1500/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00092)	Tok/s 55326 (53846)	Loss/tok 3.6019 (5.0319)	Learning Rate [0.00125]
13: TRAIN [0][1500/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00096)	Tok/s 55233 (54041)	Loss/tok 3.7936 (5.0261)	Learning Rate [0.00125]
9: TRAIN [0][1500/3416]	Time 0.059 (0.058)	Data 0.00079 (0.00093)	Tok/s 54215 (53702)	Loss/tok 3.6978 (5.0279)	Learning Rate [0.00125]
14: TRAIN [0][1500/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00096)	Tok/s 55147 (54143)	Loss/tok 3.7170 (5.0354)	Learning Rate [0.00125]
10: TRAIN [0][1500/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00096)	Tok/s 54786 (53774)	Loss/tok 3.9678 (5.0324)	Learning Rate [0.00125]
15: TRAIN [0][1500/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00092)	Tok/s 55056 (54261)	Loss/tok 3.7253 (5.0268)	Learning Rate [0.00125]
8: TRAIN [0][1500/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00092)	Tok/s 54086 (53638)	Loss/tok 3.9645 (5.0202)	Learning Rate [0.00125]
0: TRAIN [0][1500/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00097)	Tok/s 53858 (52925)	Loss/tok 3.6827 (5.0427)	Learning Rate [0.00125]
7: TRAIN [0][1500/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00095)	Tok/s 53998 (53556)	Loss/tok 3.8438 (5.0270)	Learning Rate [0.00125]
1: TRAIN [0][1500/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00094)	Tok/s 53763 (53020)	Loss/tok 3.7530 (5.0269)	Learning Rate [0.00125]
2: TRAIN [0][1500/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00100)	Tok/s 53690 (53120)	Loss/tok 3.9386 (5.0284)	Learning Rate [0.00125]
4: TRAIN [0][1500/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00099)	Tok/s 53760 (53316)	Loss/tok 3.8871 (5.0304)	Learning Rate [0.00125]
5: TRAIN [0][1500/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00094)	Tok/s 53820 (53404)	Loss/tok 3.8087 (5.0310)	Learning Rate [0.00125]
3: TRAIN [0][1500/3416]	Time 0.060 (0.058)	Data 0.00083 (0.00094)	Tok/s 53668 (53227)	Loss/tok 3.7380 (5.0268)	Learning Rate [0.00125]
6: TRAIN [0][1500/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00094)	Tok/s 53905 (53475)	Loss/tok 3.8814 (5.0273)	Learning Rate [0.00125]
7: TRAIN [0][1510/3416]	Time 0.063 (0.058)	Data 0.00103 (0.00095)	Tok/s 53486 (53540)	Loss/tok 3.9585 (5.0193)	Learning Rate [0.00125]
8: TRAIN [0][1510/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00092)	Tok/s 53436 (53621)	Loss/tok 3.7092 (5.0119)	Learning Rate [0.00125]
6: TRAIN [0][1510/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00094)	Tok/s 53433 (53459)	Loss/tok 3.8623 (5.0191)	Learning Rate [0.00125]
9: TRAIN [0][1510/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00093)	Tok/s 53301 (53684)	Loss/tok 3.9731 (5.0206)	Learning Rate [0.00125]
5: TRAIN [0][1510/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00094)	Tok/s 53351 (53388)	Loss/tok 3.7114 (5.0237)	Learning Rate [0.00125]
4: TRAIN [0][1510/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00099)	Tok/s 53398 (53301)	Loss/tok 3.8852 (5.0225)	Learning Rate [0.00125]
10: TRAIN [0][1510/3416]	Time 0.064 (0.058)	Data 0.00116 (0.00096)	Tok/s 53263 (53756)	Loss/tok 3.8321 (5.0250)	Learning Rate [0.00125]
3: TRAIN [0][1510/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00094)	Tok/s 53352 (53211)	Loss/tok 3.8728 (5.0192)	Learning Rate [0.00125]
11: TRAIN [0][1510/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00092)	Tok/s 53911 (53829)	Loss/tok 3.7806 (5.0242)	Learning Rate [0.00125]
2: TRAIN [0][1510/3416]	Time 0.064 (0.058)	Data 0.00108 (0.00100)	Tok/s 53351 (53105)	Loss/tok 4.2421 (5.0205)	Learning Rate [0.00125]
1: TRAIN [0][1510/3416]	Time 0.064 (0.058)	Data 0.00102 (0.00094)	Tok/s 53308 (53005)	Loss/tok 3.7731 (5.0191)	Learning Rate [0.00125]
12: TRAIN [0][1510/3416]	Time 0.064 (0.058)	Data 0.00114 (0.00096)	Tok/s 54092 (53935)	Loss/tok 3.8216 (5.0244)	Learning Rate [0.00125]
15: TRAIN [0][1510/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00092)	Tok/s 54058 (54245)	Loss/tok 4.1102 (5.0195)	Learning Rate [0.00125]
14: TRAIN [0][1510/3416]	Time 0.064 (0.058)	Data 0.00118 (0.00096)	Tok/s 54131 (54127)	Loss/tok 3.9359 (5.0279)	Learning Rate [0.00125]
0: TRAIN [0][1510/3416]	Time 0.064 (0.058)	Data 0.00102 (0.00097)	Tok/s 53171 (52910)	Loss/tok 3.6799 (5.0347)	Learning Rate [0.00125]
13: TRAIN [0][1510/3416]	Time 0.064 (0.058)	Data 0.00110 (0.00096)	Tok/s 54039 (54024)	Loss/tok 3.9028 (5.0182)	Learning Rate [0.00125]
7: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00095)	Tok/s 61085 (53572)	Loss/tok 4.1872 (5.0106)	Learning Rate [0.00125]
8: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 60977 (53653)	Loss/tok 4.0002 (5.0032)	Learning Rate [0.00125]
6: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00094)	Tok/s 61060 (53492)	Loss/tok 4.3044 (5.0109)	Learning Rate [0.00125]
5: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00094)	Tok/s 61116 (53422)	Loss/tok 3.8346 (5.0145)	Learning Rate [0.00125]
9: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 60901 (53716)	Loss/tok 3.8643 (5.0120)	Learning Rate [0.00125]
14: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00096)	Tok/s 61126 (54159)	Loss/tok 3.8897 (5.0191)	Learning Rate [0.00125]
4: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00099)	Tok/s 61088 (53335)	Loss/tok 4.0000 (5.0138)	Learning Rate [0.00125]
15: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 61091 (54276)	Loss/tok 4.0431 (5.0103)	Learning Rate [0.00125]
11: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 60824 (53862)	Loss/tok 4.2366 (5.0152)	Learning Rate [0.00125]
0: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 61068 (52947)	Loss/tok 3.9480 (5.0259)	Learning Rate [0.00125]
3: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00093)	Tok/s 61074 (53246)	Loss/tok 4.0942 (5.0108)	Learning Rate [0.00125]
2: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00100)	Tok/s 61103 (53140)	Loss/tok 3.9877 (5.0111)	Learning Rate [0.00125]
13: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00096)	Tok/s 60930 (54058)	Loss/tok 4.0740 (5.0095)	Learning Rate [0.00125]
10: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00096)	Tok/s 60785 (53789)	Loss/tok 3.9901 (5.0163)	Learning Rate [0.00125]
12: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00096)	Tok/s 60960 (53968)	Loss/tok 4.1265 (5.0157)	Learning Rate [0.00125]
1: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00094)	Tok/s 61096 (53040)	Loss/tok 4.0318 (5.0101)	Learning Rate [0.00125]
4: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
9: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
0: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00097)	Tok/s 53435 (52943)	Loss/tok 3.7404 (5.0180)	Learning Rate [0.00125]
1: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00094)	Tok/s 53476 (53036)	Loss/tok 3.7958 (5.0022)	Learning Rate [0.00125]
15: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00080 (0.00092)	Tok/s 53550 (54269)	Loss/tok 3.7345 (5.0029)	Learning Rate [0.00125]
14: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00100 (0.00096)	Tok/s 53554 (54152)	Loss/tok 3.9109 (5.0116)	Learning Rate [0.00125]
2: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00100 (0.00100)	Tok/s 53482 (53135)	Loss/tok 3.9197 (5.0034)	Learning Rate [0.00125]
4: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00099)	Tok/s 53520 (53329)	Loss/tok 3.6015 (5.0059)	Learning Rate [0.00125]
13: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00096)	Tok/s 53566 (54051)	Loss/tok 3.7636 (5.0018)	Learning Rate [0.00125]
3: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00093)	Tok/s 53459 (53241)	Loss/tok 3.7566 (5.0032)	Learning Rate [0.00125]
11: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00092)	Tok/s 53570 (53856)	Loss/tok 3.8157 (5.0078)	Learning Rate [0.00125]
12: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00107 (0.00096)	Tok/s 53581 (53962)	Loss/tok 3.7880 (5.0083)	Learning Rate [0.00125]
6: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00093)	Tok/s 53498 (53486)	Loss/tok 3.8635 (5.0032)	Learning Rate [0.00125]
9: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00109 (0.00093)	Tok/s 53602 (53710)	Loss/tok 3.8887 (5.0043)	Learning Rate [0.00125]
5: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00094)	Tok/s 53449 (53416)	Loss/tok 3.5494 (5.0066)	Learning Rate [0.00125]
10: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00096)	Tok/s 53635 (53782)	Loss/tok 4.0411 (5.0090)	Learning Rate [0.00125]
7: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00095)	Tok/s 53471 (53565)	Loss/tok 4.0193 (5.0034)	Learning Rate [0.00125]
8: TRAIN [0][1530/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00092)	Tok/s 53499 (53647)	Loss/tok 3.5453 (4.9955)	Learning Rate [0.00125]
3: TRAIN [0][1540/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00093)	Tok/s 30586 (53231)	Loss/tok 3.1098 (4.9960)	Learning Rate [0.00125]
4: TRAIN [0][1540/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00099)	Tok/s 30489 (53319)	Loss/tok 3.1391 (4.9982)	Learning Rate [0.00125]
2: TRAIN [0][1540/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00100)	Tok/s 30558 (53126)	Loss/tok 2.8884 (4.9954)	Learning Rate [0.00125]
5: TRAIN [0][1540/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00094)	Tok/s 30438 (53406)	Loss/tok 3.2828 (4.9990)	Learning Rate [0.00125]
6: TRAIN [0][1540/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00093)	Tok/s 31537 (53476)	Loss/tok 3.0460 (4.9955)	Learning Rate [0.00125]
1: TRAIN [0][1540/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00094)	Tok/s 30486 (53028)	Loss/tok 3.1898 (4.9947)	Learning Rate [0.00125]
15: TRAIN [0][1540/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00092)	Tok/s 31785 (54259)	Loss/tok 3.4097 (4.9951)	Learning Rate [0.00125]
0: TRAIN [0][1540/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00097)	Tok/s 30374 (52935)	Loss/tok 3.2280 (5.0102)	Learning Rate [0.00125]
14: TRAIN [0][1540/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00096)	Tok/s 31748 (54142)	Loss/tok 3.2981 (5.0043)	Learning Rate [0.00125]
7: TRAIN [0][1540/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00095)	Tok/s 31622 (53556)	Loss/tok 3.2301 (4.9950)	Learning Rate [0.00125]
9: TRAIN [0][1540/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00093)	Tok/s 31530 (53699)	Loss/tok 3.3562 (4.9968)	Learning Rate [0.00125]
8: TRAIN [0][1540/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00092)	Tok/s 31546 (53636)	Loss/tok 3.2151 (4.9876)	Learning Rate [0.00125]
12: TRAIN [0][1540/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00096)	Tok/s 31587 (53951)	Loss/tok 2.8931 (5.0008)	Learning Rate [0.00125]
11: TRAIN [0][1540/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 31483 (53845)	Loss/tok 3.1483 (5.0001)	Learning Rate [0.00125]
13: TRAIN [0][1540/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00096)	Tok/s 31583 (54040)	Loss/tok 3.2670 (4.9940)	Learning Rate [0.00125]
10: TRAIN [0][1540/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00096)	Tok/s 31305 (53771)	Loss/tok 3.1822 (5.0004)	Learning Rate [0.00125]
6: TRAIN [0][1550/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00093)	Tok/s 52400 (53470)	Loss/tok 3.4954 (4.9880)	Learning Rate [0.00125]
5: TRAIN [0][1550/3416]	Time 0.056 (0.058)	Data 0.00104 (0.00094)	Tok/s 51842 (53399)	Loss/tok 3.8341 (4.9915)	Learning Rate [0.00125]
3: TRAIN [0][1550/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00093)	Tok/s 51280 (53226)	Loss/tok 3.8665 (4.9885)	Learning Rate [0.00125]
4: TRAIN [0][1550/3416]	Time 0.056 (0.058)	Data 0.00108 (0.00099)	Tok/s 51311 (53313)	Loss/tok 3.5489 (4.9906)	Learning Rate [0.00125]
7: TRAIN [0][1550/3416]	Time 0.056 (0.058)	Data 0.00107 (0.00095)	Tok/s 52387 (53549)	Loss/tok 3.7174 (4.9873)	Learning Rate [0.00125]
9: TRAIN [0][1550/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00093)	Tok/s 52125 (53693)	Loss/tok 3.4724 (4.9894)	Learning Rate [0.00125]
1: TRAIN [0][1550/3416]	Time 0.056 (0.058)	Data 0.00096 (0.00094)	Tok/s 51101 (53022)	Loss/tok 3.8397 (4.9871)	Learning Rate [0.00125]
8: TRAIN [0][1550/3416]	Time 0.056 (0.058)	Data 0.00116 (0.00092)	Tok/s 52202 (53630)	Loss/tok 3.8274 (4.9800)	Learning Rate [0.00125]
2: TRAIN [0][1550/3416]	Time 0.056 (0.058)	Data 0.00101 (0.00100)	Tok/s 51120 (53121)	Loss/tok 3.9943 (4.9884)	Learning Rate [0.00125]
0: TRAIN [0][1550/3416]	Time 0.056 (0.058)	Data 0.00106 (0.00097)	Tok/s 51024 (52929)	Loss/tok 3.6893 (5.0024)	Learning Rate [0.00125]
11: TRAIN [0][1550/3416]	Time 0.057 (0.058)	Data 0.00089 (0.00092)	Tok/s 51909 (53839)	Loss/tok 3.8805 (4.9923)	Learning Rate [0.00125]
14: TRAIN [0][1550/3416]	Time 0.057 (0.058)	Data 0.00099 (0.00097)	Tok/s 51951 (54135)	Loss/tok 3.5584 (4.9966)	Learning Rate [0.00125]
15: TRAIN [0][1550/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00092)	Tok/s 52088 (54252)	Loss/tok 3.5756 (4.9876)	Learning Rate [0.00125]
10: TRAIN [0][1550/3416]	Time 0.057 (0.058)	Data 0.00100 (0.00096)	Tok/s 51998 (53766)	Loss/tok 3.7362 (4.9924)	Learning Rate [0.00125]
12: TRAIN [0][1550/3416]	Time 0.057 (0.058)	Data 0.00111 (0.00096)	Tok/s 51792 (53944)	Loss/tok 3.7237 (4.9934)	Learning Rate [0.00125]
13: TRAIN [0][1550/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00096)	Tok/s 51886 (54033)	Loss/tok 4.0729 (4.9865)	Learning Rate [0.00125]
12: TRAIN [0][1560/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00096)	Tok/s 58381 (53928)	Loss/tok 3.8506 (4.9857)	Learning Rate [0.00125]
11: TRAIN [0][1560/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00092)	Tok/s 58402 (53822)	Loss/tok 3.9345 (4.9846)	Learning Rate [0.00125]
15: TRAIN [0][1560/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 58211 (54237)	Loss/tok 3.9009 (4.9802)	Learning Rate [0.00125]
10: TRAIN [0][1560/3416]	Time 0.068 (0.058)	Data 0.00123 (0.00096)	Tok/s 59155 (53749)	Loss/tok 3.7953 (4.9846)	Learning Rate [0.00125]
13: TRAIN [0][1560/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00096)	Tok/s 58252 (54016)	Loss/tok 3.8032 (4.9789)	Learning Rate [0.00125]
9: TRAIN [0][1560/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 58325 (53676)	Loss/tok 4.0617 (4.9816)	Learning Rate [0.00125]
14: TRAIN [0][1560/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00097)	Tok/s 58199 (54118)	Loss/tok 4.0979 (4.9895)	Learning Rate [0.00125]
8: TRAIN [0][1560/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 58268 (53613)	Loss/tok 3.8912 (4.9723)	Learning Rate [0.00125]
6: TRAIN [0][1560/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00093)	Tok/s 58161 (53453)	Loss/tok 3.7831 (4.9807)	Learning Rate [0.00125]
0: TRAIN [0][1560/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 57997 (52906)	Loss/tok 3.9514 (4.9946)	Learning Rate [0.00125]
7: TRAIN [0][1560/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00096)	Tok/s 58146 (53531)	Loss/tok 3.8583 (4.9795)	Learning Rate [0.00125]
1: TRAIN [0][1560/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00094)	Tok/s 57900 (53000)	Loss/tok 3.9890 (4.9797)	Learning Rate [0.00125]
2: TRAIN [0][1560/3416]	Time 0.069 (0.058)	Data 0.00115 (0.00100)	Tok/s 58599 (53101)	Loss/tok 3.9651 (4.9810)	Learning Rate [0.00125]
4: TRAIN [0][1560/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00099)	Tok/s 57892 (53295)	Loss/tok 4.1414 (4.9835)	Learning Rate [0.00125]
3: TRAIN [0][1560/3416]	Time 0.070 (0.058)	Data 0.00124 (0.00093)	Tok/s 57874 (53205)	Loss/tok 4.0586 (4.9811)	Learning Rate [0.00125]
5: TRAIN [0][1560/3416]	Time 0.070 (0.058)	Data 0.00115 (0.00094)	Tok/s 58007 (53381)	Loss/tok 3.8653 (4.9839)	Learning Rate [0.00125]
11: Gradient norm: inf
12: Gradient norm: inf
11: Skipped batch, new scale: 512.0
10: Gradient norm: inf
12: Skipped batch, new scale: 512.0
13: Gradient norm: inf
9: Gradient norm: inf
14: Gradient norm: inf
10: Skipped batch, new scale: 512.0
13: Skipped batch, new scale: 512.0
9: Skipped batch, new scale: 512.0
15: Gradient norm: inf
14: Skipped batch, new scale: 512.0
8: Gradient norm: inf
15: Skipped batch, new scale: 512.0
0: Gradient norm: inf
7: Gradient norm: inf
8: Skipped batch, new scale: 512.0
1: Gradient norm: inf
0: Skipped batch, new scale: 512.0
6: Gradient norm: inf
7: Skipped batch, new scale: 512.0
4: Gradient norm: inf
6: Skipped batch, new scale: 512.0
1: Skipped batch, new scale: 512.0
5: Gradient norm: inf
3: Gradient norm: inf
2: Gradient norm: inf
4: Skipped batch, new scale: 512.0
2: Skipped batch, new scale: 512.0
5: Skipped batch, new scale: 512.0
3: Skipped batch, new scale: 512.0
6: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 51185 (53443)	Loss/tok 3.5865 (4.9734)	Learning Rate [0.00125]
5: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00094)	Tok/s 51056 (53372)	Loss/tok 3.5961 (4.9768)	Learning Rate [0.00125]
7: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00106 (0.00096)	Tok/s 51163 (53522)	Loss/tok 3.7743 (4.9716)	Learning Rate [0.00125]
8: TRAIN [0][1570/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00092)	Tok/s 51220 (53603)	Loss/tok 3.6705 (4.9644)	Learning Rate [0.00125]
4: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00099)	Tok/s 51058 (53285)	Loss/tok 3.5042 (4.9759)	Learning Rate [0.00125]
3: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00094)	Tok/s 51098 (53196)	Loss/tok 3.7611 (4.9738)	Learning Rate [0.00125]
9: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00093)	Tok/s 51162 (53666)	Loss/tok 3.6581 (4.9742)	Learning Rate [0.00125]
1: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00094)	Tok/s 51106 (52991)	Loss/tok 3.4675 (4.9723)	Learning Rate [0.00125]
2: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00100)	Tok/s 51008 (53092)	Loss/tok 3.6769 (4.9729)	Learning Rate [0.00125]
11: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00092)	Tok/s 51131 (53811)	Loss/tok 3.6903 (4.9769)	Learning Rate [0.00125]
0: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00097)	Tok/s 51009 (52896)	Loss/tok 3.5760 (4.9873)	Learning Rate [0.00125]
10: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00096)	Tok/s 51155 (53739)	Loss/tok 3.8189 (4.9773)	Learning Rate [0.00125]
15: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00092)	Tok/s 52339 (54230)	Loss/tok 3.7963 (4.9727)	Learning Rate [0.00125]
14: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00097)	Tok/s 52247 (54111)	Loss/tok 3.9913 (4.9816)	Learning Rate [0.00125]
12: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00096)	Tok/s 50943 (53919)	Loss/tok 3.5443 (4.9782)	Learning Rate [0.00125]
13: TRAIN [0][1570/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00096)	Tok/s 51230 (54007)	Loss/tok 3.6471 (4.9712)	Learning Rate [0.00125]
10: TRAIN [0][1580/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 72822 (53781)	Loss/tok 3.7448 (4.9687)	Learning Rate [0.00125]
12: TRAIN [0][1580/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 72916 (53959)	Loss/tok 3.8058 (4.9697)	Learning Rate [0.00125]
9: TRAIN [0][1580/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 72778 (53707)	Loss/tok 3.9437 (4.9658)	Learning Rate [0.00125]
1: TRAIN [0][1580/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00094)	Tok/s 71998 (53032)	Loss/tok 3.8133 (4.9632)	Learning Rate [0.00125]
14: TRAIN [0][1580/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 73679 (54151)	Loss/tok 3.7647 (4.9726)	Learning Rate [0.00125]
15: TRAIN [0][1580/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 73710 (54269)	Loss/tok 3.8840 (4.9640)	Learning Rate [0.00125]
6: TRAIN [0][1580/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 72812 (53484)	Loss/tok 3.9454 (4.9646)	Learning Rate [0.00125]
5: TRAIN [0][1580/3416]	Time 0.069 (0.058)	Data 0.00118 (0.00094)	Tok/s 73026 (53413)	Loss/tok 3.9833 (4.9676)	Learning Rate [0.00125]
0: TRAIN [0][1580/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 71943 (52938)	Loss/tok 4.0786 (4.9785)	Learning Rate [0.00125]
8: TRAIN [0][1580/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 72711 (53644)	Loss/tok 3.9194 (4.9551)	Learning Rate [0.00125]
7: TRAIN [0][1580/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00096)	Tok/s 72822 (53563)	Loss/tok 3.7587 (4.9624)	Learning Rate [0.00125]
3: TRAIN [0][1580/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00094)	Tok/s 72889 (53238)	Loss/tok 3.7781 (4.9650)	Learning Rate [0.00125]
11: TRAIN [0][1580/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 72713 (53853)	Loss/tok 3.6470 (4.9681)	Learning Rate [0.00125]
13: TRAIN [0][1580/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00096)	Tok/s 73585 (54048)	Loss/tok 3.8164 (4.9622)	Learning Rate [0.00125]
4: TRAIN [0][1580/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00099)	Tok/s 72952 (53327)	Loss/tok 3.7005 (4.9669)	Learning Rate [0.00125]
2: TRAIN [0][1580/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00101)	Tok/s 71969 (53133)	Loss/tok 3.9096 (4.9644)	Learning Rate [0.00125]
6: TRAIN [0][1590/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00093)	Tok/s 51469 (53450)	Loss/tok 3.8798 (4.9582)	Learning Rate [0.00125]
7: TRAIN [0][1590/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00096)	Tok/s 51451 (53529)	Loss/tok 3.3906 (4.9555)	Learning Rate [0.00125]
8: TRAIN [0][1590/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00092)	Tok/s 51351 (53612)	Loss/tok 3.8436 (4.9489)	Learning Rate [0.00125]
9: TRAIN [0][1590/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00093)	Tok/s 51216 (53676)	Loss/tok 3.6993 (4.9593)	Learning Rate [0.00125]
4: TRAIN [0][1590/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00099)	Tok/s 51524 (53291)	Loss/tok 3.4824 (4.9607)	Learning Rate [0.00125]
5: TRAIN [0][1590/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00094)	Tok/s 51484 (53379)	Loss/tok 3.3941 (4.9608)	Learning Rate [0.00125]
10: TRAIN [0][1590/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00096)	Tok/s 51049 (53748)	Loss/tok 3.7229 (4.9619)	Learning Rate [0.00125]
3: TRAIN [0][1590/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00093)	Tok/s 51483 (53202)	Loss/tok 3.3884 (4.9579)	Learning Rate [0.00125]
11: TRAIN [0][1590/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00092)	Tok/s 51047 (53820)	Loss/tok 3.5529 (4.9615)	Learning Rate [0.00125]
2: TRAIN [0][1590/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00101)	Tok/s 51413 (53097)	Loss/tok 3.5662 (4.9578)	Learning Rate [0.00125]
1: TRAIN [0][1590/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00094)	Tok/s 51290 (52994)	Loss/tok 3.3564 (4.9566)	Learning Rate [0.00125]
0: TRAIN [0][1590/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00097)	Tok/s 51174 (52898)	Loss/tok 3.6825 (4.9721)	Learning Rate [0.00125]
15: TRAIN [0][1590/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00092)	Tok/s 51327 (54238)	Loss/tok 3.4906 (4.9568)	Learning Rate [0.00125]
12: TRAIN [0][1590/3416]	Time 0.048 (0.058)	Data 0.00109 (0.00096)	Tok/s 51015 (53927)	Loss/tok 3.4738 (4.9629)	Learning Rate [0.00125]
14: TRAIN [0][1590/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00096)	Tok/s 51043 (54119)	Loss/tok 3.3541 (4.9658)	Learning Rate [0.00125]
13: TRAIN [0][1590/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00096)	Tok/s 50997 (54016)	Loss/tok 3.5498 (4.9553)	Learning Rate [0.00125]
15: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00092)	Tok/s 52125 (54220)	Loss/tok 3.6866 (4.9498)	Learning Rate [0.00125]
0: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00094 (0.00097)	Tok/s 50844 (52872)	Loss/tok 3.6745 (4.9651)	Learning Rate [0.00125]
14: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00096)	Tok/s 52123 (54101)	Loss/tok 3.8324 (4.9586)	Learning Rate [0.00125]
1: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00105 (0.00094)	Tok/s 50826 (52970)	Loss/tok 3.4949 (4.9494)	Learning Rate [0.00125]
13: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00108 (0.00096)	Tok/s 52126 (53998)	Loss/tok 3.6681 (4.9483)	Learning Rate [0.00125]
2: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00101)	Tok/s 51646 (53074)	Loss/tok 3.6986 (4.9508)	Learning Rate [0.00125]
12: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00117 (0.00096)	Tok/s 52122 (53910)	Loss/tok 3.7425 (4.9555)	Learning Rate [0.00125]
11: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00092)	Tok/s 52071 (53802)	Loss/tok 3.4785 (4.9538)	Learning Rate [0.00125]
3: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00094 (0.00093)	Tok/s 52018 (53179)	Loss/tok 3.6760 (4.9510)	Learning Rate [0.00125]
10: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00096)	Tok/s 52097 (53730)	Loss/tok 3.5055 (4.9549)	Learning Rate [0.00125]
4: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00099)	Tok/s 52023 (53269)	Loss/tok 3.9785 (4.9539)	Learning Rate [0.00125]
5: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00099 (0.00094)	Tok/s 52045 (53357)	Loss/tok 3.9055 (4.9535)	Learning Rate [0.00125]
9: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00093)	Tok/s 52134 (53657)	Loss/tok 3.5185 (4.9521)	Learning Rate [0.00125]
6: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00101 (0.00093)	Tok/s 52048 (53429)	Loss/tok 3.5128 (4.9513)	Learning Rate [0.00125]
7: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00112 (0.00096)	Tok/s 52121 (53509)	Loss/tok 3.9663 (4.9489)	Learning Rate [0.00125]
8: TRAIN [0][1600/3416]	Time 0.054 (0.058)	Data 0.00103 (0.00092)	Tok/s 52046 (53593)	Loss/tok 3.7775 (4.9419)	Learning Rate [0.00125]
12: TRAIN [0][1610/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00096)	Tok/s 42692 (53948)	Loss/tok 3.3619 (4.9467)	Learning Rate [0.00125]
11: TRAIN [0][1610/3416]	Time 0.048 (0.058)	Data 0.00114 (0.00092)	Tok/s 42637 (53840)	Loss/tok 3.6183 (4.9449)	Learning Rate [0.00125]
13: TRAIN [0][1610/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00096)	Tok/s 42636 (54036)	Loss/tok 3.7883 (4.9403)	Learning Rate [0.00125]
9: TRAIN [0][1610/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00093)	Tok/s 42566 (53695)	Loss/tok 3.3141 (4.9444)	Learning Rate [0.00125]
10: TRAIN [0][1610/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00096)	Tok/s 42576 (53767)	Loss/tok 3.6178 (4.9469)	Learning Rate [0.00125]
14: TRAIN [0][1610/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00096)	Tok/s 42533 (54138)	Loss/tok 3.4682 (4.9501)	Learning Rate [0.00125]
15: TRAIN [0][1610/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00092)	Tok/s 42494 (54258)	Loss/tok 3.1757 (4.9414)	Learning Rate [0.00125]
0: TRAIN [0][1610/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00097)	Tok/s 42351 (52913)	Loss/tok 3.4680 (4.9565)	Learning Rate [0.00125]
8: TRAIN [0][1610/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 42481 (53631)	Loss/tok 3.4545 (4.9335)	Learning Rate [0.00125]
6: TRAIN [0][1610/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00093)	Tok/s 42276 (53468)	Loss/tok 3.5410 (4.9427)	Learning Rate [0.00125]
1: TRAIN [0][1610/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00094)	Tok/s 42246 (53010)	Loss/tok 3.7264 (4.9412)	Learning Rate [0.00125]
7: TRAIN [0][1610/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00096)	Tok/s 42369 (53547)	Loss/tok 3.5502 (4.9402)	Learning Rate [0.00125]
5: TRAIN [0][1610/3416]	Time 0.049 (0.058)	Data 0.00102 (0.00094)	Tok/s 42217 (53396)	Loss/tok 3.4807 (4.9445)	Learning Rate [0.00125]
2: TRAIN [0][1610/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00101)	Tok/s 42138 (53113)	Loss/tok 3.4538 (4.9424)	Learning Rate [0.00125]
4: TRAIN [0][1610/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00099)	Tok/s 42102 (53308)	Loss/tok 3.4866 (4.9454)	Learning Rate [0.00125]
3: TRAIN [0][1610/3416]	Time 0.049 (0.058)	Data 0.00081 (0.00093)	Tok/s 42063 (53218)	Loss/tok 3.7644 (4.9423)	Learning Rate [0.00125]
7: TRAIN [0][1620/3416]	Time 0.062 (0.058)	Data 0.00109 (0.00096)	Tok/s 54299 (53539)	Loss/tok 3.9275 (4.9333)	Learning Rate [0.00125]
4: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00110 (0.00099)	Tok/s 54114 (53301)	Loss/tok 3.6996 (4.9375)	Learning Rate [0.00125]
8: TRAIN [0][1620/3416]	Time 0.062 (0.058)	Data 0.00083 (0.00092)	Tok/s 54281 (53622)	Loss/tok 3.7214 (4.9265)	Learning Rate [0.00125]
3: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00093)	Tok/s 53047 (53211)	Loss/tok 3.6685 (4.9350)	Learning Rate [0.00125]
10: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00096)	Tok/s 54132 (53758)	Loss/tok 3.7236 (4.9394)	Learning Rate [0.00125]
11: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00092)	Tok/s 54075 (53830)	Loss/tok 3.7965 (4.9380)	Learning Rate [0.00125]
1: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00082 (0.00094)	Tok/s 52806 (53000)	Loss/tok 3.6516 (4.9338)	Learning Rate [0.00125]
9: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00093)	Tok/s 54250 (53686)	Loss/tok 3.7082 (4.9371)	Learning Rate [0.00125]
2: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00100)	Tok/s 52799 (53105)	Loss/tok 3.9058 (4.9350)	Learning Rate [0.00125]
6: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00093)	Tok/s 54256 (53459)	Loss/tok 3.7795 (4.9353)	Learning Rate [0.00125]
12: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00096)	Tok/s 54000 (53937)	Loss/tok 3.5935 (4.9395)	Learning Rate [0.00125]
15: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00092)	Tok/s 53764 (54246)	Loss/tok 3.9986 (4.9343)	Learning Rate [0.00125]
14: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00096)	Tok/s 53808 (54127)	Loss/tok 3.7200 (4.9427)	Learning Rate [0.00125]
0: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00097)	Tok/s 52699 (52903)	Loss/tok 3.6523 (4.9488)	Learning Rate [0.00125]
13: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00106 (0.00096)	Tok/s 53880 (54025)	Loss/tok 3.6457 (4.9329)	Learning Rate [0.00125]
5: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00094)	Tok/s 54197 (53388)	Loss/tok 3.9278 (4.9375)	Learning Rate [0.00125]
6: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00093)	Tok/s 49007 (53429)	Loss/tok 3.6515 (4.9286)	Learning Rate [0.00125]
3: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 49204 (53182)	Loss/tok 3.6247 (4.9282)	Learning Rate [0.00125]
4: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00115 (0.00099)	Tok/s 49142 (53271)	Loss/tok 3.4662 (4.9306)	Learning Rate [0.00125]
1: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00094)	Tok/s 49190 (52972)	Loss/tok 3.8031 (4.9274)	Learning Rate [0.00125]
2: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00100)	Tok/s 49161 (53076)	Loss/tok 3.5806 (4.9287)	Learning Rate [0.00125]
0: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00097)	Tok/s 49036 (52875)	Loss/tok 3.4320 (4.9414)	Learning Rate [0.00125]
9: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00093)	Tok/s 50334 (53655)	Loss/tok 3.3259 (4.9305)	Learning Rate [0.00125]
7: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00096)	Tok/s 49852 (53508)	Loss/tok 3.7431 (4.9264)	Learning Rate [0.00125]
8: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00092)	Tok/s 50247 (53591)	Loss/tok 3.5180 (4.9201)	Learning Rate [0.00125]
15: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 50250 (54217)	Loss/tok 3.4893 (4.9275)	Learning Rate [0.00125]
11: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00092)	Tok/s 50347 (53798)	Loss/tok 3.5220 (4.9318)	Learning Rate [0.00125]
14: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00096)	Tok/s 50318 (54098)	Loss/tok 3.1712 (4.9360)	Learning Rate [0.00125]
10: TRAIN [0][1630/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00096)	Tok/s 50137 (53726)	Loss/tok 3.7873 (4.9326)	Learning Rate [0.00125]
5: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00094)	Tok/s 49056 (53358)	Loss/tok 3.5394 (4.9304)	Learning Rate [0.00125]
13: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00096)	Tok/s 50336 (53995)	Loss/tok 3.3501 (4.9262)	Learning Rate [0.00125]
12: TRAIN [0][1630/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00096)	Tok/s 50301 (53906)	Loss/tok 3.7873 (4.9329)	Learning Rate [0.00125]
3: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00093)	Tok/s 54672 (53191)	Loss/tok 3.8528 (4.9211)	Learning Rate [0.00125]
2: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00100)	Tok/s 54641 (53086)	Loss/tok 3.7053 (4.9208)	Learning Rate [0.00125]
6: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00083 (0.00093)	Tok/s 54393 (53438)	Loss/tok 3.4332 (4.9207)	Learning Rate [0.00125]
4: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00104 (0.00099)	Tok/s 54676 (53280)	Loss/tok 3.4573 (4.9232)	Learning Rate [0.00125]
1: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00094)	Tok/s 54453 (52983)	Loss/tok 3.8140 (4.9196)	Learning Rate [0.00125]
0: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00099 (0.00097)	Tok/s 54352 (52886)	Loss/tok 3.6081 (4.9339)	Learning Rate [0.00125]
8: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00092)	Tok/s 54326 (53601)	Loss/tok 3.7024 (4.9122)	Learning Rate [0.00125]
7: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00096)	Tok/s 54388 (53517)	Loss/tok 3.7548 (4.9189)	Learning Rate [0.00125]
9: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00081 (0.00093)	Tok/s 54292 (53664)	Loss/tok 3.8848 (4.9229)	Learning Rate [0.00125]
10: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00096)	Tok/s 54082 (53735)	Loss/tok 3.7186 (4.9251)	Learning Rate [0.00125]
15: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00092)	Tok/s 55455 (54227)	Loss/tok 3.5690 (4.9200)	Learning Rate [0.00125]
11: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00092)	Tok/s 54484 (53807)	Loss/tok 3.6561 (4.9241)	Learning Rate [0.00125]
14: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00096)	Tok/s 55426 (54108)	Loss/tok 3.7430 (4.9283)	Learning Rate [0.00125]
13: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00100 (0.00096)	Tok/s 55332 (54005)	Loss/tok 3.7718 (4.9183)	Learning Rate [0.00125]
12: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00096)	Tok/s 55301 (53915)	Loss/tok 3.6758 (4.9253)	Learning Rate [0.00125]
5: TRAIN [0][1640/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00094)	Tok/s 54492 (53368)	Loss/tok 3.7849 (4.9226)	Learning Rate [0.00125]
6: TRAIN [0][1650/3416]	Time 0.034 (0.058)	Data 0.00089 (0.00093)	Tok/s 22570 (53374)	Loss/tok 2.7361 (4.9148)	Learning Rate [0.00125]
5: TRAIN [0][1650/3416]	Time 0.034 (0.058)	Data 0.00097 (0.00094)	Tok/s 20789 (53303)	Loss/tok 2.1452 (4.9167)	Learning Rate [0.00125]
4: TRAIN [0][1650/3416]	Time 0.034 (0.058)	Data 0.00108 (0.00099)	Tok/s 19859 (53215)	Loss/tok 2.5357 (4.9172)	Learning Rate [0.00125]
2: TRAIN [0][1650/3416]	Time 0.034 (0.058)	Data 0.00098 (0.00100)	Tok/s 16041 (53020)	Loss/tok 2.0032 (4.9152)	Learning Rate [0.00125]
7: TRAIN [0][1650/3416]	Time 0.034 (0.058)	Data 0.00100 (0.00096)	Tok/s 23503 (53454)	Loss/tok 2.2014 (4.9130)	Learning Rate [0.00125]
8: TRAIN [0][1650/3416]	Time 0.034 (0.058)	Data 0.00090 (0.00092)	Tok/s 24269 (53538)	Loss/tok 2.0895 (4.9065)	Learning Rate [0.00125]
9: TRAIN [0][1650/3416]	Time 0.034 (0.058)	Data 0.00088 (0.00093)	Tok/s 24198 (53600)	Loss/tok 2.2446 (4.9172)	Learning Rate [0.00125]
1: TRAIN [0][1650/3416]	Time 0.034 (0.058)	Data 0.00105 (0.00094)	Tok/s 12652 (52914)	Loss/tok 2.1939 (4.9137)	Learning Rate [0.00125]
0: TRAIN [0][1650/3416]	Time 0.035 (0.058)	Data 0.00112 (0.00097)	Tok/s 9250 (52816)	Loss/tok 1.5840 (4.9283)	Learning Rate [0.00125]
11: TRAIN [0][1650/3416]	Time 0.035 (0.058)	Data 0.00092 (0.00092)	Tok/s 25106 (53744)	Loss/tok 2.2632 (4.9179)	Learning Rate [0.00125]
15: TRAIN [0][1650/3416]	Time 0.035 (0.058)	Data 0.00087 (0.00092)	Tok/s 27671 (54165)	Loss/tok 2.6520 (4.9145)	Learning Rate [0.00125]
10: TRAIN [0][1650/3416]	Time 0.035 (0.058)	Data 0.00100 (0.00096)	Tok/s 24116 (53672)	Loss/tok 2.0284 (4.9190)	Learning Rate [0.00125]
14: TRAIN [0][1650/3416]	Time 0.035 (0.058)	Data 0.00101 (0.00096)	Tok/s 27130 (54047)	Loss/tok 2.6653 (4.9222)	Learning Rate [0.00125]
3: TRAIN [0][1650/3416]	Time 0.034 (0.058)	Data 0.00104 (0.00093)	Tok/s 17240 (53125)	Loss/tok 1.9958 (4.9152)	Learning Rate [0.00125]
13: TRAIN [0][1650/3416]	Time 0.035 (0.058)	Data 0.00091 (0.00096)	Tok/s 25767 (53942)	Loss/tok 2.4717 (4.9122)	Learning Rate [0.00125]
12: TRAIN [0][1650/3416]	Time 0.035 (0.058)	Data 0.00089 (0.00096)	Tok/s 25800 (53853)	Loss/tok 2.6363 (4.9194)	Learning Rate [0.00125]
5: Gradient norm: inf
6: Gradient norm: inf
4: Gradient norm: inf
5: Skipped batch, new scale: 256.0
6: Skipped batch, new scale: 256.0
3: Gradient norm: inf
4: Skipped batch, new scale: 256.0
7: Gradient norm: inf
8: Gradient norm: inf
2: Gradient norm: inf
15: Gradient norm: inf
3: Skipped batch, new scale: 256.0
9: Gradient norm: inf
1: Gradient norm: inf
0: Gradient norm: inf
2: Skipped batch, new scale: 256.0
14: Gradient norm: inf
7: Skipped batch, new scale: 256.0
15: Skipped batch, new scale: 256.0
8: Skipped batch, new scale: 256.0
9: Skipped batch, new scale: 256.0
10: Gradient norm: inf
0: Skipped batch, new scale: 256.0
1: Skipped batch, new scale: 256.0
14: Skipped batch, new scale: 256.0
13: Gradient norm: inf
11: Gradient norm: inf
12: Gradient norm: inf
10: Skipped batch, new scale: 256.0
13: Skipped batch, new scale: 256.0
12: Skipped batch, new scale: 256.0
11: Skipped batch, new scale: 256.0
6: TRAIN [0][1660/3416]	Time 0.040 (0.058)	Data 0.00075 (0.00093)	Tok/s 30061 (53339)	Loss/tok 2.9959 (4.9086)	Learning Rate [0.00125]
9: TRAIN [0][1660/3416]	Time 0.041 (0.058)	Data 0.00079 (0.00093)	Tok/s 29952 (53565)	Loss/tok 2.7436 (4.9111)	Learning Rate [0.00125]
5: TRAIN [0][1660/3416]	Time 0.040 (0.058)	Data 0.00092 (0.00094)	Tok/s 29427 (53268)	Loss/tok 2.8181 (4.9103)	Learning Rate [0.00125]
7: TRAIN [0][1660/3416]	Time 0.041 (0.058)	Data 0.00095 (0.00096)	Tok/s 29992 (53418)	Loss/tok 2.8086 (4.9071)	Learning Rate [0.00125]
10: TRAIN [0][1660/3416]	Time 0.041 (0.058)	Data 0.00090 (0.00096)	Tok/s 29954 (53637)	Loss/tok 2.9387 (4.9131)	Learning Rate [0.00125]
8: TRAIN [0][1660/3416]	Time 0.041 (0.058)	Data 0.00086 (0.00092)	Tok/s 29914 (53502)	Loss/tok 2.9587 (4.9003)	Learning Rate [0.00125]
11: TRAIN [0][1660/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00092)	Tok/s 29956 (53709)	Loss/tok 2.8381 (4.9121)	Learning Rate [0.00125]
4: TRAIN [0][1660/3416]	Time 0.041 (0.058)	Data 0.00109 (0.00099)	Tok/s 28385 (53180)	Loss/tok 2.9438 (4.9112)	Learning Rate [0.00125]
2: TRAIN [0][1660/3416]	Time 0.041 (0.058)	Data 0.00103 (0.00100)	Tok/s 28411 (52986)	Loss/tok 2.9580 (4.9087)	Learning Rate [0.00125]
1: TRAIN [0][1660/3416]	Time 0.041 (0.058)	Data 0.00106 (0.00094)	Tok/s 28419 (52881)	Loss/tok 2.7690 (4.9079)	Learning Rate [0.00125]
15: TRAIN [0][1660/3416]	Time 0.041 (0.058)	Data 0.00085 (0.00092)	Tok/s 31508 (54132)	Loss/tok 2.9684 (4.9084)	Learning Rate [0.00125]
12: TRAIN [0][1660/3416]	Time 0.041 (0.058)	Data 0.00099 (0.00096)	Tok/s 29823 (53817)	Loss/tok 2.9564 (4.9130)	Learning Rate [0.00125]
14: TRAIN [0][1660/3416]	Time 0.041 (0.058)	Data 0.00088 (0.00096)	Tok/s 31488 (54013)	Loss/tok 3.1681 (4.9155)	Learning Rate [0.00125]
0: TRAIN [0][1660/3416]	Time 0.041 (0.058)	Data 0.00105 (0.00097)	Tok/s 28386 (52782)	Loss/tok 2.8745 (4.9222)	Learning Rate [0.00125]
13: TRAIN [0][1660/3416]	Time 0.041 (0.058)	Data 0.00091 (0.00096)	Tok/s 30986 (53907)	Loss/tok 2.8254 (4.9062)	Learning Rate [0.00125]
3: TRAIN [0][1660/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00093)	Tok/s 28578 (53090)	Loss/tok 2.7597 (4.9094)	Learning Rate [0.00125]
11: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 33304 (53729)	Loss/tok 3.2094 (4.9048)	Learning Rate [0.00125]
13: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00096)	Tok/s 33438 (53927)	Loss/tok 3.2480 (4.8987)	Learning Rate [0.00125]
14: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00096)	Tok/s 34630 (54034)	Loss/tok 3.2245 (4.9077)	Learning Rate [0.00125]
12: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00096)	Tok/s 33349 (53836)	Loss/tok 3.1738 (4.9055)	Learning Rate [0.00125]
15: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00092)	Tok/s 34622 (54152)	Loss/tok 3.1074 (4.9011)	Learning Rate [0.00125]
1: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00094)	Tok/s 33341 (52902)	Loss/tok 3.2552 (4.8998)	Learning Rate [0.00125]
0: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00097)	Tok/s 33353 (52804)	Loss/tok 3.2188 (4.9149)	Learning Rate [0.00125]
9: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00093)	Tok/s 33236 (53585)	Loss/tok 3.3365 (4.9029)	Learning Rate [0.00125]
10: TRAIN [0][1670/3416]	Time 0.049 (0.058)	Data 0.00112 (0.00097)	Tok/s 33854 (53656)	Loss/tok 3.0651 (4.9051)	Learning Rate [0.00125]
8: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00092)	Tok/s 33268 (53523)	Loss/tok 3.4837 (4.8924)	Learning Rate [0.00125]
2: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00100)	Tok/s 33338 (53007)	Loss/tok 3.4072 (4.9014)	Learning Rate [0.00125]
6: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00093)	Tok/s 33245 (53360)	Loss/tok 3.6385 (4.9012)	Learning Rate [0.00125]
5: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00094)	Tok/s 33305 (53289)	Loss/tok 3.5963 (4.9031)	Learning Rate [0.00125]
4: TRAIN [0][1670/3416]	Time 0.049 (0.058)	Data 0.00124 (0.00099)	Tok/s 33830 (53201)	Loss/tok 3.6418 (4.9038)	Learning Rate [0.00125]
7: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00096)	Tok/s 33265 (53439)	Loss/tok 3.5216 (4.8995)	Learning Rate [0.00125]
3: TRAIN [0][1670/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00093)	Tok/s 33381 (53112)	Loss/tok 3.3818 (4.9019)	Learning Rate [0.00125]
0: TRAIN [0][1680/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00097)	Tok/s 52090 (52804)	Loss/tok 3.7260 (4.9075)	Learning Rate [0.00125]
1: TRAIN [0][1680/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00094)	Tok/s 52048 (52902)	Loss/tok 3.5189 (4.8936)	Learning Rate [0.00125]
15: TRAIN [0][1680/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00092)	Tok/s 53370 (54150)	Loss/tok 3.5845 (4.8946)	Learning Rate [0.00125]
2: TRAIN [0][1680/3416]	Time 0.049 (0.058)	Data 0.00101 (0.00100)	Tok/s 51908 (53007)	Loss/tok 3.6142 (4.8946)	Learning Rate [0.00125]
14: TRAIN [0][1680/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00096)	Tok/s 53384 (54032)	Loss/tok 3.8376 (4.9009)	Learning Rate [0.00125]
9: TRAIN [0][1680/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00093)	Tok/s 51917 (53584)	Loss/tok 3.6239 (4.8961)	Learning Rate [0.00125]
11: TRAIN [0][1680/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00092)	Tok/s 51931 (53726)	Loss/tok 3.6844 (4.8981)	Learning Rate [0.00125]
8: TRAIN [0][1680/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00092)	Tok/s 51817 (53521)	Loss/tok 3.9491 (4.8860)	Learning Rate [0.00125]
10: TRAIN [0][1680/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00097)	Tok/s 51930 (53655)	Loss/tok 3.7334 (4.8984)	Learning Rate [0.00125]
13: TRAIN [0][1680/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00096)	Tok/s 52647 (53924)	Loss/tok 3.5688 (4.8921)	Learning Rate [0.00125]
6: TRAIN [0][1680/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00093)	Tok/s 51616 (53358)	Loss/tok 3.6894 (4.8950)	Learning Rate [0.00125]
12: TRAIN [0][1680/3416]	Time 0.049 (0.058)	Data 0.00107 (0.00096)	Tok/s 52063 (53833)	Loss/tok 3.6404 (4.8989)	Learning Rate [0.00125]
7: TRAIN [0][1680/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00096)	Tok/s 51690 (53437)	Loss/tok 3.6038 (4.8928)	Learning Rate [0.00125]
5: TRAIN [0][1680/3416]	Time 0.050 (0.058)	Data 0.00106 (0.00094)	Tok/s 51571 (53288)	Loss/tok 3.8065 (4.8966)	Learning Rate [0.00125]
4: TRAIN [0][1680/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00099)	Tok/s 51681 (53201)	Loss/tok 3.6755 (4.8970)	Learning Rate [0.00125]
3: TRAIN [0][1680/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00093)	Tok/s 51891 (53112)	Loss/tok 3.8261 (4.8953)	Learning Rate [0.00125]
11: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 84437 (53727)	Loss/tok 3.5808 (4.8908)	Learning Rate [0.00125]
9: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 83654 (53585)	Loss/tok 3.5110 (4.8889)	Learning Rate [0.00125]
10: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 83950 (53656)	Loss/tok 3.5526 (4.8911)	Learning Rate [0.00125]
8: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 83670 (53523)	Loss/tok 3.6153 (4.8790)	Learning Rate [0.00125]
12: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 84400 (53834)	Loss/tok 3.6029 (4.8920)	Learning Rate [0.00125]
7: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 83624 (53439)	Loss/tok 3.7718 (4.8860)	Learning Rate [0.00125]
13: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00096)	Tok/s 84333 (53924)	Loss/tok 3.5023 (4.8850)	Learning Rate [0.00125]
14: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 84396 (54032)	Loss/tok 3.7024 (4.8939)	Learning Rate [0.00125]
15: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 85055 (54150)	Loss/tok 3.7326 (4.8880)	Learning Rate [0.00125]
6: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00093)	Tok/s 83512 (53360)	Loss/tok 3.6966 (4.8881)	Learning Rate [0.00125]
0: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 82437 (52806)	Loss/tok 3.6621 (4.9007)	Learning Rate [0.00125]
5: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00094)	Tok/s 83408 (53290)	Loss/tok 3.5915 (4.8891)	Learning Rate [0.00125]
1: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00094)	Tok/s 82330 (52904)	Loss/tok 3.6045 (4.8868)	Learning Rate [0.00125]
4: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00099)	Tok/s 82460 (53202)	Loss/tok 3.6587 (4.8899)	Learning Rate [0.00125]
2: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 82097 (53008)	Loss/tok 3.6499 (4.8878)	Learning Rate [0.00125]
3: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00093)	Tok/s 82249 (53113)	Loss/tok 3.7995 (4.8888)	Learning Rate [0.00125]
15: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00092)	Tok/s 55985 (54152)	Loss/tok 3.7856 (4.8812)	Learning Rate [0.00125]
0: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00097)	Tok/s 54925 (52813)	Loss/tok 3.6578 (4.8938)	Learning Rate [0.00125]
14: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00110 (0.00096)	Tok/s 55987 (54034)	Loss/tok 3.7797 (4.8871)	Learning Rate [0.00125]
1: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00105 (0.00094)	Tok/s 54847 (52910)	Loss/tok 3.6042 (4.8804)	Learning Rate [0.00125]
13: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00103 (0.00096)	Tok/s 55908 (53926)	Loss/tok 3.7920 (4.8783)	Learning Rate [0.00125]
4: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00099)	Tok/s 55626 (53208)	Loss/tok 3.9339 (4.8835)	Learning Rate [0.00125]
11: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00092)	Tok/s 55736 (53730)	Loss/tok 3.8610 (4.8841)	Learning Rate [0.00125]
2: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00117 (0.00100)	Tok/s 55495 (53015)	Loss/tok 3.9589 (4.8815)	Learning Rate [0.00125]
12: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00096)	Tok/s 55794 (53837)	Loss/tok 3.6661 (4.8856)	Learning Rate [0.00125]
10: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00096)	Tok/s 55634 (53659)	Loss/tok 3.6375 (4.8842)	Learning Rate [0.00125]
9: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00093)	Tok/s 55488 (53588)	Loss/tok 3.6703 (4.8825)	Learning Rate [0.00125]
5: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00115 (0.00094)	Tok/s 55454 (53295)	Loss/tok 3.8263 (4.8823)	Learning Rate [0.00125]
8: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00092)	Tok/s 55435 (53526)	Loss/tok 3.7076 (4.8723)	Learning Rate [0.00125]
6: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00093)	Tok/s 55442 (53365)	Loss/tok 3.6250 (4.8812)	Learning Rate [0.00125]
7: TRAIN [0][1700/3416]	Time 0.064 (0.058)	Data 0.00107 (0.00096)	Tok/s 55415 (53443)	Loss/tok 3.8043 (4.8795)	Learning Rate [0.00125]
3: TRAIN [0][1700/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00093)	Tok/s 55841 (53119)	Loss/tok 3.9127 (4.8820)	Learning Rate [0.00125]
6: TRAIN [0][1710/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00093)	Tok/s 57432 (53379)	Loss/tok 3.6733 (4.8737)	Learning Rate [0.00125]
5: TRAIN [0][1710/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00094)	Tok/s 57458 (53309)	Loss/tok 3.8144 (4.8753)	Learning Rate [0.00125]
4: TRAIN [0][1710/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00099)	Tok/s 57454 (53222)	Loss/tok 3.8299 (4.8761)	Learning Rate [0.00125]
2: TRAIN [0][1710/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00100)	Tok/s 57216 (53028)	Loss/tok 3.8730 (4.8745)	Learning Rate [0.00125]
7: TRAIN [0][1710/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00096)	Tok/s 57398 (53458)	Loss/tok 3.9407 (4.8720)	Learning Rate [0.00125]
9: TRAIN [0][1710/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00093)	Tok/s 57861 (53603)	Loss/tok 3.8542 (4.8753)	Learning Rate [0.00125]
8: TRAIN [0][1710/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00092)	Tok/s 57301 (53541)	Loss/tok 3.9082 (4.8655)	Learning Rate [0.00125]
1: TRAIN [0][1710/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00094)	Tok/s 57150 (52923)	Loss/tok 3.9065 (4.8735)	Learning Rate [0.00125]
0: TRAIN [0][1710/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00097)	Tok/s 57068 (52826)	Loss/tok 4.0793 (4.8864)	Learning Rate [0.00125]
11: TRAIN [0][1710/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 57978 (53745)	Loss/tok 3.9493 (4.8766)	Learning Rate [0.00125]
10: TRAIN [0][1710/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00096)	Tok/s 58027 (53674)	Loss/tok 3.6692 (4.8765)	Learning Rate [0.00125]
13: TRAIN [0][1710/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00096)	Tok/s 57749 (53941)	Loss/tok 3.9777 (4.8714)	Learning Rate [0.00125]
3: TRAIN [0][1710/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 57422 (53134)	Loss/tok 3.7741 (4.8750)	Learning Rate [0.00125]
12: TRAIN [0][1710/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00096)	Tok/s 57842 (53852)	Loss/tok 3.7914 (4.8782)	Learning Rate [0.00125]
15: TRAIN [0][1710/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00092)	Tok/s 57918 (54168)	Loss/tok 3.7852 (4.8735)	Learning Rate [0.00125]
14: TRAIN [0][1710/3416]	Time 0.069 (0.058)	Data 0.00120 (0.00096)	Tok/s 57807 (54049)	Loss/tok 3.7474 (4.8799)	Learning Rate [0.00125]
4: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00099)	Tok/s 50903 (53213)	Loss/tok 3.4266 (4.8696)	Learning Rate [0.00125]
2: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00100)	Tok/s 50762 (53019)	Loss/tok 3.3959 (4.8681)	Learning Rate [0.00125]
1: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00094)	Tok/s 50715 (52914)	Loss/tok 3.5266 (4.8668)	Learning Rate [0.00125]
0: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00106 (0.00097)	Tok/s 50749 (52817)	Loss/tok 3.3314 (4.8790)	Learning Rate [0.00125]
15: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00092)	Tok/s 52164 (54160)	Loss/tok 3.7537 (4.8665)	Learning Rate [0.00125]
5: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00108 (0.00094)	Tok/s 50936 (53299)	Loss/tok 3.1786 (4.8680)	Learning Rate [0.00125]
14: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00108 (0.00096)	Tok/s 52183 (54041)	Loss/tok 3.7038 (4.8736)	Learning Rate [0.00125]
6: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00093)	Tok/s 50834 (53369)	Loss/tok 3.3685 (4.8667)	Learning Rate [0.00125]
13: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00096)	Tok/s 52099 (53934)	Loss/tok 3.7455 (4.8647)	Learning Rate [0.00125]
7: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00096)	Tok/s 50820 (53448)	Loss/tok 3.2754 (4.8653)	Learning Rate [0.00125]
8: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00092)	Tok/s 50871 (53531)	Loss/tok 3.6613 (4.8591)	Learning Rate [0.00125]
9: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00093)	Tok/s 51099 (53593)	Loss/tok 3.7037 (4.8690)	Learning Rate [0.00125]
11: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00092)	Tok/s 52030 (53737)	Loss/tok 3.7480 (4.8699)	Learning Rate [0.00125]
12: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00096)	Tok/s 52111 (53844)	Loss/tok 3.5068 (4.8713)	Learning Rate [0.00125]
10: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00112 (0.00096)	Tok/s 52172 (53665)	Loss/tok 3.7705 (4.8699)	Learning Rate [0.00125]
3: TRAIN [0][1720/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00093)	Tok/s 50796 (53124)	Loss/tok 3.7057 (4.8687)	Learning Rate [0.00125]
6: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00093)	Tok/s 31048 (53371)	Loss/tok 2.9524 (4.8593)	Learning Rate [0.00125]
5: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00103 (0.00094)	Tok/s 31050 (53300)	Loss/tok 3.2095 (4.8616)	Learning Rate [0.00125]
4: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00099)	Tok/s 31086 (53213)	Loss/tok 3.1879 (4.8625)	Learning Rate [0.00125]
8: TRAIN [0][1730/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00092)	Tok/s 30914 (53531)	Loss/tok 3.1773 (4.8523)	Learning Rate [0.00125]
7: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00096)	Tok/s 30999 (53449)	Loss/tok 3.0589 (4.8580)	Learning Rate [0.00125]
9: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00093)	Tok/s 30950 (53593)	Loss/tok 3.1171 (4.8623)	Learning Rate [0.00125]
2: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00100)	Tok/s 30299 (53019)	Loss/tok 2.8191 (4.8607)	Learning Rate [0.00125]
1: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00094)	Tok/s 29593 (52915)	Loss/tok 3.0434 (4.8596)	Learning Rate [0.00125]
11: TRAIN [0][1730/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00092)	Tok/s 30941 (53737)	Loss/tok 3.1742 (4.8630)	Learning Rate [0.00125]
0: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00097)	Tok/s 29667 (52818)	Loss/tok 2.9627 (4.8717)	Learning Rate [0.00125]
15: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00092)	Tok/s 31560 (54160)	Loss/tok 3.1795 (4.8602)	Learning Rate [0.00125]
14: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00096)	Tok/s 31097 (54041)	Loss/tok 3.2457 (4.8665)	Learning Rate [0.00125]
10: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00117 (0.00096)	Tok/s 31040 (53665)	Loss/tok 3.0857 (4.8623)	Learning Rate [0.00125]
12: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00096)	Tok/s 30987 (53844)	Loss/tok 2.9154 (4.8641)	Learning Rate [0.00125]
13: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00096)	Tok/s 30994 (53934)	Loss/tok 3.1048 (4.8582)	Learning Rate [0.00125]
3: TRAIN [0][1730/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00093)	Tok/s 31105 (53124)	Loss/tok 3.1118 (4.8621)	Learning Rate [0.00125]
15: TRAIN [0][1740/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00092)	Tok/s 36981 (54183)	Loss/tok 3.2552 (4.8529)	Learning Rate [0.00125]
0: TRAIN [0][1740/3416]	Time 0.050 (0.058)	Data 0.00107 (0.00097)	Tok/s 37031 (52844)	Loss/tok 3.1775 (4.8637)	Learning Rate [0.00125]
14: TRAIN [0][1740/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00096)	Tok/s 36886 (54065)	Loss/tok 3.5996 (4.8592)	Learning Rate [0.00125]
1: TRAIN [0][1740/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00094)	Tok/s 37023 (52941)	Loss/tok 3.3925 (4.8524)	Learning Rate [0.00125]
13: TRAIN [0][1740/3416]	Time 0.050 (0.058)	Data 0.00110 (0.00096)	Tok/s 36844 (53959)	Loss/tok 3.4549 (4.8514)	Learning Rate [0.00125]
2: TRAIN [0][1740/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00100)	Tok/s 37032 (53045)	Loss/tok 3.4175 (4.8535)	Learning Rate [0.00125]
12: TRAIN [0][1740/3416]	Time 0.050 (0.058)	Data 0.00106 (0.00096)	Tok/s 36778 (53869)	Loss/tok 3.4520 (4.8566)	Learning Rate [0.00125]
11: TRAIN [0][1740/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 36718 (53762)	Loss/tok 3.5202 (4.8555)	Learning Rate [0.00125]
4: TRAIN [0][1740/3416]	Time 0.049 (0.058)	Data 0.00111 (0.00099)	Tok/s 37682 (53239)	Loss/tok 3.4026 (4.8553)	Learning Rate [0.00125]
9: TRAIN [0][1740/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00093)	Tok/s 36714 (53617)	Loss/tok 3.5798 (4.8551)	Learning Rate [0.00125]
6: TRAIN [0][1740/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00093)	Tok/s 36801 (53396)	Loss/tok 3.4337 (4.8517)	Learning Rate [0.00125]
10: TRAIN [0][1740/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00097)	Tok/s 36711 (53690)	Loss/tok 3.5437 (4.8552)	Learning Rate [0.00125]
5: TRAIN [0][1740/3416]	Time 0.050 (0.058)	Data 0.00106 (0.00094)	Tok/s 36894 (53325)	Loss/tok 3.3292 (4.8543)	Learning Rate [0.00125]
7: TRAIN [0][1740/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00096)	Tok/s 36815 (53473)	Loss/tok 3.4659 (4.8502)	Learning Rate [0.00125]
8: TRAIN [0][1740/3416]	Time 0.050 (0.058)	Data 0.00108 (0.00092)	Tok/s 37420 (53555)	Loss/tok 3.5619 (4.8449)	Learning Rate [0.00125]
3: TRAIN [0][1740/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00093)	Tok/s 37038 (53150)	Loss/tok 3.6343 (4.8542)	Learning Rate [0.00125]
7: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00108 (0.00096)	Tok/s 52424 (53482)	Loss/tok 3.9576 (4.8442)	Learning Rate [0.00125]
8: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00111 (0.00092)	Tok/s 52436 (53564)	Loss/tok 3.7404 (4.8384)	Learning Rate [0.00125]
6: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00109 (0.00093)	Tok/s 52315 (53405)	Loss/tok 3.6262 (4.8450)	Learning Rate [0.00125]
5: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00120 (0.00094)	Tok/s 52346 (53335)	Loss/tok 3.6010 (4.8474)	Learning Rate [0.00125]
9: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00093)	Tok/s 52362 (53626)	Loss/tok 3.8397 (4.8486)	Learning Rate [0.00125]
4: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00099)	Tok/s 52419 (53248)	Loss/tok 3.7997 (4.8487)	Learning Rate [0.00125]
11: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00092)	Tok/s 52390 (53771)	Loss/tok 3.6743 (4.8489)	Learning Rate [0.00125]
10: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00112 (0.00097)	Tok/s 52345 (53699)	Loss/tok 3.9269 (4.8489)	Learning Rate [0.00125]
2: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00100)	Tok/s 52427 (53055)	Loss/tok 3.7439 (4.8467)	Learning Rate [0.00125]
12: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00096)	Tok/s 52511 (53878)	Loss/tok 3.6363 (4.8493)	Learning Rate [0.00125]
1: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00114 (0.00094)	Tok/s 52904 (52951)	Loss/tok 4.0598 (4.8464)	Learning Rate [0.00125]
0: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00104 (0.00097)	Tok/s 52567 (52855)	Loss/tok 3.7380 (4.8570)	Learning Rate [0.00125]
15: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00103 (0.00092)	Tok/s 53448 (54192)	Loss/tok 3.8640 (4.8466)	Learning Rate [0.00125]
14: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00106 (0.00096)	Tok/s 52559 (54073)	Loss/tok 3.7855 (4.8524)	Learning Rate [0.00125]
13: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00096)	Tok/s 52494 (53968)	Loss/tok 3.5303 (4.8447)	Learning Rate [0.00125]
3: TRAIN [0][1750/3416]	Time 0.062 (0.058)	Data 0.00107 (0.00094)	Tok/s 52527 (53160)	Loss/tok 3.7723 (4.8475)	Learning Rate [0.00125]
14: TRAIN [0][1760/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00096)	Tok/s 54978 (54077)	Loss/tok 3.6990 (4.8457)	Learning Rate [0.00125]
15: TRAIN [0][1760/3416]	Time 0.059 (0.058)	Data 0.00082 (0.00092)	Tok/s 54894 (54195)	Loss/tok 3.6291 (4.8403)	Learning Rate [0.00125]
13: TRAIN [0][1760/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00096)	Tok/s 55060 (53972)	Loss/tok 3.8121 (4.8385)	Learning Rate [0.00125]
0: TRAIN [0][1760/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00097)	Tok/s 54977 (52861)	Loss/tok 3.8920 (4.8503)	Learning Rate [0.00125]
12: TRAIN [0][1760/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00096)	Tok/s 55124 (53881)	Loss/tok 3.9619 (4.8427)	Learning Rate [0.00125]
11: TRAIN [0][1760/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00092)	Tok/s 54977 (53775)	Loss/tok 3.4283 (4.8424)	Learning Rate [0.00125]
10: TRAIN [0][1760/3416]	Time 0.059 (0.058)	Data 0.00110 (0.00097)	Tok/s 55073 (53702)	Loss/tok 3.4293 (4.8421)	Learning Rate [0.00125]
9: TRAIN [0][1760/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00093)	Tok/s 54998 (53630)	Loss/tok 3.6847 (4.8425)	Learning Rate [0.00125]
8: TRAIN [0][1760/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00092)	Tok/s 55031 (53567)	Loss/tok 3.9799 (4.8319)	Learning Rate [0.00125]
4: TRAIN [0][1760/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00099)	Tok/s 54820 (53252)	Loss/tok 3.7398 (4.8426)	Learning Rate [0.00125]
7: TRAIN [0][1760/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00096)	Tok/s 55033 (53486)	Loss/tok 3.6391 (4.8373)	Learning Rate [0.00125]
6: TRAIN [0][1760/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00093)	Tok/s 54888 (53409)	Loss/tok 3.5552 (4.8382)	Learning Rate [0.00125]
5: TRAIN [0][1760/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00095)	Tok/s 54873 (53339)	Loss/tok 3.8224 (4.8410)	Learning Rate [0.00125]
3: TRAIN [0][1760/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00094)	Tok/s 54934 (53165)	Loss/tok 4.0187 (4.8412)	Learning Rate [0.00125]
1: TRAIN [0][1760/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00094)	Tok/s 54085 (52956)	Loss/tok 3.7779 (4.8399)	Learning Rate [0.00125]
2: TRAIN [0][1760/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00100)	Tok/s 54103 (53059)	Loss/tok 3.8989 (4.8400)	Learning Rate [0.00125]
5: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00109 (0.00095)	Tok/s 54655 (53388)	Loss/tok 3.6974 (4.8338)	Learning Rate [0.00125]
8: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00103 (0.00092)	Tok/s 54750 (53617)	Loss/tok 3.8785 (4.8244)	Learning Rate [0.00125]
4: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00108 (0.00099)	Tok/s 54597 (53301)	Loss/tok 4.0446 (4.8352)	Learning Rate [0.00125]
7: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00107 (0.00096)	Tok/s 54762 (53535)	Loss/tok 3.7516 (4.8298)	Learning Rate [0.00125]
9: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00093)	Tok/s 54669 (53680)	Loss/tok 3.4749 (4.8350)	Learning Rate [0.00125]
6: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00098 (0.00093)	Tok/s 54704 (53458)	Loss/tok 3.5763 (4.8309)	Learning Rate [0.00125]
2: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00116 (0.00100)	Tok/s 54389 (53110)	Loss/tok 3.6401 (4.8327)	Learning Rate [0.00125]
1: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00094)	Tok/s 54298 (53007)	Loss/tok 3.8384 (4.8324)	Learning Rate [0.00125]
11: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00092)	Tok/s 54450 (53825)	Loss/tok 3.6050 (4.8350)	Learning Rate [0.00125]
10: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00107 (0.00097)	Tok/s 54562 (53752)	Loss/tok 3.7269 (4.8337)	Learning Rate [0.00125]
12: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00105 (0.00096)	Tok/s 54435 (53931)	Loss/tok 3.9692 (4.8352)	Learning Rate [0.00125]
15: TRAIN [0][1770/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00092)	Tok/s 54090 (54242)	Loss/tok 3.8489 (4.8328)	Learning Rate [0.00125]
14: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00096)	Tok/s 54208 (54125)	Loss/tok 4.1424 (4.8379)	Learning Rate [0.00125]
13: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00096)	Tok/s 54288 (54020)	Loss/tok 3.9141 (4.8314)	Learning Rate [0.00125]
3: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00103 (0.00094)	Tok/s 54438 (53214)	Loss/tok 3.7362 (4.8337)	Learning Rate [0.00125]
0: TRAIN [0][1770/3416]	Time 0.061 (0.058)	Data 0.00115 (0.00097)	Tok/s 54143 (52912)	Loss/tok 4.0155 (4.8431)	Learning Rate [0.00125]
14: Upscaling, new scale: 512.0
15: Upscaling, new scale: 512.0
13: Upscaling, new scale: 512.0
11: Upscaling, new scale: 512.0
0: Upscaling, new scale: 512.0
12: Upscaling, new scale: 512.0
1: Upscaling, new scale: 512.0
10: Upscaling, new scale: 512.0
14: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00096)	Tok/s 32203 (54108)	Loss/tok 3.1896 (4.8324)	Learning Rate [0.00125]
9: Upscaling, new scale: 512.0
15: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00092)	Tok/s 32209 (54225)	Loss/tok 3.2038 (4.8265)	Learning Rate [0.00125]
2: Upscaling, new scale: 512.0
11: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 30704 (53807)	Loss/tok 2.9721 (4.8285)	Learning Rate [0.00125]
13: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00096)	Tok/s 32031 (54004)	Loss/tok 3.0428 (4.8257)	Learning Rate [0.00125]
0: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00097)	Tok/s 30830 (52889)	Loss/tok 3.2187 (4.8370)	Learning Rate [0.00125]
12: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00096)	Tok/s 30746 (53913)	Loss/tok 3.2085 (4.8292)	Learning Rate [0.00125]
1: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00108 (0.00094)	Tok/s 30820 (52987)	Loss/tok 3.0987 (4.8262)	Learning Rate [0.00125]
4: Upscaling, new scale: 512.0
8: Upscaling, new scale: 512.0
10: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00114 (0.00097)	Tok/s 30659 (53734)	Loss/tok 2.9467 (4.8279)	Learning Rate [0.00125]
7: Upscaling, new scale: 512.0
9: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 30579 (53663)	Loss/tok 3.2828 (4.8287)	Learning Rate [0.00125]
6: Upscaling, new scale: 512.0
5: Upscaling, new scale: 512.0
2: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00100)	Tok/s 30782 (53090)	Loss/tok 3.2695 (4.8263)	Learning Rate [0.00125]
4: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00099)	Tok/s 30672 (53282)	Loss/tok 3.2605 (4.8296)	Learning Rate [0.00125]
8: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00092)	Tok/s 30505 (53600)	Loss/tok 3.1352 (4.8181)	Learning Rate [0.00125]
7: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00096)	Tok/s 30560 (53517)	Loss/tok 2.9630 (4.8241)	Learning Rate [0.00125]
5: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00095)	Tok/s 30625 (53368)	Loss/tok 3.2209 (4.8273)	Learning Rate [0.00125]
6: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 30536 (53439)	Loss/tok 3.0628 (4.8250)	Learning Rate [0.00125]
3: Upscaling, new scale: 512.0
3: TRAIN [0][1780/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00094)	Tok/s 30826 (53194)	Loss/tok 3.3731 (4.8275)	Learning Rate [0.00125]
6: TRAIN [0][1790/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00093)	Tok/s 55678 (53450)	Loss/tok 3.5976 (4.8180)	Learning Rate [0.00125]
5: TRAIN [0][1790/3416]	Time 0.064 (0.058)	Data 0.00102 (0.00095)	Tok/s 55420 (53379)	Loss/tok 3.6559 (4.8205)	Learning Rate [0.00125]
4: TRAIN [0][1790/3416]	Time 0.064 (0.058)	Data 0.00099 (0.00099)	Tok/s 54750 (53292)	Loss/tok 4.0082 (4.8234)	Learning Rate [0.00125]
7: TRAIN [0][1790/3416]	Time 0.065 (0.058)	Data 0.00086 (0.00096)	Tok/s 55554 (53527)	Loss/tok 3.7051 (4.8179)	Learning Rate [0.00125]
2: TRAIN [0][1790/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00100)	Tok/s 54767 (53101)	Loss/tok 3.6306 (4.8196)	Learning Rate [0.00125]
9: TRAIN [0][1790/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00093)	Tok/s 55380 (53672)	Loss/tok 3.6511 (4.8230)	Learning Rate [0.00125]
1: TRAIN [0][1790/3416]	Time 0.064 (0.058)	Data 0.00099 (0.00094)	Tok/s 54669 (52998)	Loss/tok 3.7548 (4.8192)	Learning Rate [0.00125]
0: TRAIN [0][1790/3416]	Time 0.064 (0.058)	Data 0.00100 (0.00097)	Tok/s 54627 (52900)	Loss/tok 3.7506 (4.8305)	Learning Rate [0.00125]
8: TRAIN [0][1790/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00092)	Tok/s 55458 (53609)	Loss/tok 3.7545 (4.8118)	Learning Rate [0.00125]
10: TRAIN [0][1790/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00097)	Tok/s 55303 (53745)	Loss/tok 3.6826 (4.8215)	Learning Rate [0.00125]
15: TRAIN [0][1790/3416]	Time 0.065 (0.058)	Data 0.00081 (0.00092)	Tok/s 55484 (54234)	Loss/tok 3.9739 (4.8198)	Learning Rate [0.00125]
11: TRAIN [0][1790/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00092)	Tok/s 55243 (53817)	Loss/tok 3.6843 (4.8219)	Learning Rate [0.00125]
12: TRAIN [0][1790/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00096)	Tok/s 55328 (53923)	Loss/tok 3.9225 (4.8229)	Learning Rate [0.00125]
14: TRAIN [0][1790/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00096)	Tok/s 55373 (54117)	Loss/tok 3.8096 (4.8258)	Learning Rate [0.00125]
13: TRAIN [0][1790/3416]	Time 0.065 (0.058)	Data 0.00080 (0.00096)	Tok/s 55316 (54013)	Loss/tok 4.1911 (4.8196)	Learning Rate [0.00125]
3: TRAIN [0][1790/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00094)	Tok/s 54874 (53204)	Loss/tok 3.9100 (4.8213)	Learning Rate [0.00125]
1: TRAIN [0][1800/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00094)	Tok/s 32484 (52953)	Loss/tok 3.1449 (4.8135)	Learning Rate [0.00125]
2: TRAIN [0][1800/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00100)	Tok/s 32408 (53057)	Loss/tok 3.2897 (4.8143)	Learning Rate [0.00125]
5: TRAIN [0][1800/3416]	Time 0.046 (0.058)	Data 0.00110 (0.00095)	Tok/s 32296 (53335)	Loss/tok 3.1497 (4.8154)	Learning Rate [0.00125]
8: TRAIN [0][1800/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00092)	Tok/s 32417 (53564)	Loss/tok 3.1949 (4.8069)	Learning Rate [0.00125]
6: TRAIN [0][1800/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00093)	Tok/s 32298 (53405)	Loss/tok 2.9482 (4.8123)	Learning Rate [0.00125]
4: TRAIN [0][1800/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00099)	Tok/s 32330 (53248)	Loss/tok 2.8931 (4.8180)	Learning Rate [0.00125]
0: TRAIN [0][1800/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00097)	Tok/s 32429 (52855)	Loss/tok 3.0985 (4.8247)	Learning Rate [0.00125]
7: TRAIN [0][1800/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00096)	Tok/s 32261 (53482)	Loss/tok 3.5806 (4.8126)	Learning Rate [0.00125]
9: TRAIN [0][1800/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00093)	Tok/s 32300 (53627)	Loss/tok 3.1410 (4.8178)	Learning Rate [0.00125]
15: TRAIN [0][1800/3416]	Time 0.045 (0.058)	Data 0.00081 (0.00092)	Tok/s 33814 (54188)	Loss/tok 3.1094 (4.8143)	Learning Rate [0.00125]
3: TRAIN [0][1800/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00094)	Tok/s 32569 (53160)	Loss/tok 3.1803 (4.8160)	Learning Rate [0.00125]
14: TRAIN [0][1800/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00096)	Tok/s 33806 (54072)	Loss/tok 3.1130 (4.8204)	Learning Rate [0.00125]
11: TRAIN [0][1800/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00092)	Tok/s 32377 (53771)	Loss/tok 3.5107 (4.8166)	Learning Rate [0.00125]
10: TRAIN [0][1800/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00097)	Tok/s 32361 (53699)	Loss/tok 3.1697 (4.8163)	Learning Rate [0.00125]
12: TRAIN [0][1800/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00096)	Tok/s 32440 (53877)	Loss/tok 3.1691 (4.8176)	Learning Rate [0.00125]
13: TRAIN [0][1800/3416]	Time 0.045 (0.058)	Data 0.00083 (0.00096)	Tok/s 32427 (53968)	Loss/tok 3.1199 (4.8145)	Learning Rate [0.00125]
9: TRAIN [0][1810/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 34076 (53626)	Loss/tok 3.2748 (4.8108)	Learning Rate [0.00125]
15: TRAIN [0][1810/3416]	Time 0.050 (0.058)	Data 0.00078 (0.00092)	Tok/s 34265 (54187)	Loss/tok 3.2680 (4.8075)	Learning Rate [0.00125]
8: TRAIN [0][1810/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 34015 (53562)	Loss/tok 3.1677 (4.8005)	Learning Rate [0.00125]
14: TRAIN [0][1810/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00096)	Tok/s 34356 (54070)	Loss/tok 3.0841 (4.8137)	Learning Rate [0.00125]
6: TRAIN [0][1810/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00093)	Tok/s 33966 (53403)	Loss/tok 3.1630 (4.8058)	Learning Rate [0.00125]
1: TRAIN [0][1810/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00094)	Tok/s 34168 (52952)	Loss/tok 3.0719 (4.8073)	Learning Rate [0.00125]
7: TRAIN [0][1810/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00096)	Tok/s 33936 (53480)	Loss/tok 3.1533 (4.8064)	Learning Rate [0.00125]
11: TRAIN [0][1810/3416]	Time 0.051 (0.058)	Data 0.00078 (0.00092)	Tok/s 34090 (53771)	Loss/tok 3.2646 (4.8105)	Learning Rate [0.00125]
0: TRAIN [0][1810/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00097)	Tok/s 34200 (52855)	Loss/tok 3.2828 (4.8185)	Learning Rate [0.00125]
12: TRAIN [0][1810/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00096)	Tok/s 34115 (53877)	Loss/tok 3.4982 (4.8111)	Learning Rate [0.00125]
5: TRAIN [0][1810/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00095)	Tok/s 33997 (53333)	Loss/tok 3.5267 (4.8091)	Learning Rate [0.00125]
13: TRAIN [0][1810/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00096)	Tok/s 34774 (53966)	Loss/tok 3.3207 (4.8078)	Learning Rate [0.00125]
4: TRAIN [0][1810/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00099)	Tok/s 34016 (53246)	Loss/tok 3.4557 (4.8119)	Learning Rate [0.00125]
2: TRAIN [0][1810/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00100)	Tok/s 34069 (53056)	Loss/tok 3.2613 (4.8081)	Learning Rate [0.00125]
10: TRAIN [0][1810/3416]	Time 0.050 (0.058)	Data 0.00115 (0.00097)	Tok/s 34675 (53698)	Loss/tok 3.3301 (4.8101)	Learning Rate [0.00125]
3: TRAIN [0][1810/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00094)	Tok/s 34139 (53159)	Loss/tok 3.4935 (4.8096)	Learning Rate [0.00125]
4: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00099)	Tok/s 56393 (53283)	Loss/tok 3.7999 (4.8049)	Learning Rate [0.00125]
5: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00095)	Tok/s 56400 (53369)	Loss/tok 3.8393 (4.8021)	Learning Rate [0.00125]
2: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00102 (0.00101)	Tok/s 56342 (53092)	Loss/tok 4.0291 (4.8016)	Learning Rate [0.00125]
8: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00092)	Tok/s 57050 (53598)	Loss/tok 3.8525 (4.7937)	Learning Rate [0.00125]
6: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00093)	Tok/s 56194 (53439)	Loss/tok 3.8306 (4.7990)	Learning Rate [0.00125]
7: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00125 (0.00096)	Tok/s 56696 (53516)	Loss/tok 3.8816 (4.7990)	Learning Rate [0.00125]
0: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00097)	Tok/s 56202 (52892)	Loss/tok 3.9755 (4.8111)	Learning Rate [0.00125]
1: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00094)	Tok/s 56241 (52989)	Loss/tok 3.6924 (4.8006)	Learning Rate [0.00125]
15: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00092)	Tok/s 57026 (54225)	Loss/tok 4.0353 (4.8002)	Learning Rate [0.00125]
14: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00096)	Tok/s 56977 (54107)	Loss/tok 3.9557 (4.8066)	Learning Rate [0.00125]
13: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00096)	Tok/s 56933 (54003)	Loss/tok 3.6422 (4.8012)	Learning Rate [0.00125]
12: TRAIN [0][1820/3416]	Time 0.068 (0.058)	Data 0.00109 (0.00096)	Tok/s 56878 (53914)	Loss/tok 3.8293 (4.8044)	Learning Rate [0.00125]
10: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00097)	Tok/s 56889 (53734)	Loss/tok 4.0653 (4.8036)	Learning Rate [0.00125]
11: TRAIN [0][1820/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00092)	Tok/s 56700 (53807)	Loss/tok 3.8165 (4.8034)	Learning Rate [0.00125]
3: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00106 (0.00094)	Tok/s 56365 (53195)	Loss/tok 4.1795 (4.8024)	Learning Rate [0.00125]
9: TRAIN [0][1820/3416]	Time 0.067 (0.058)	Data 0.00108 (0.00093)	Tok/s 56951 (53661)	Loss/tok 3.7705 (4.8037)	Learning Rate [0.00125]
13: TRAIN [0][1830/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 71968 (54049)	Loss/tok 3.8153 (4.7938)	Learning Rate [0.00125]
2: TRAIN [0][1830/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00101)	Tok/s 71096 (53138)	Loss/tok 3.8596 (4.7945)	Learning Rate [0.00125]
3: TRAIN [0][1830/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00094)	Tok/s 71183 (53242)	Loss/tok 3.9810 (4.7955)	Learning Rate [0.00125]
4: TRAIN [0][1830/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00099)	Tok/s 71141 (53328)	Loss/tok 3.8619 (4.7975)	Learning Rate [0.00125]
12: TRAIN [0][1830/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00096)	Tok/s 72022 (53960)	Loss/tok 3.7913 (4.7966)	Learning Rate [0.00125]
5: TRAIN [0][1830/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00095)	Tok/s 71412 (53414)	Loss/tok 3.7457 (4.7948)	Learning Rate [0.00125]
11: TRAIN [0][1830/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00092)	Tok/s 71968 (53854)	Loss/tok 4.0214 (4.7965)	Learning Rate [0.00125]
1: TRAIN [0][1830/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00094)	Tok/s 70953 (53036)	Loss/tok 3.7749 (4.7933)	Learning Rate [0.00125]
7: TRAIN [0][1830/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00096)	Tok/s 72262 (53561)	Loss/tok 4.0695 (4.7917)	Learning Rate [0.00125]
0: TRAIN [0][1830/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 70844 (52939)	Loss/tok 3.9490 (4.8040)	Learning Rate [0.00125]
15: TRAIN [0][1830/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00092)	Tok/s 71687 (54270)	Loss/tok 3.7691 (4.7933)	Learning Rate [0.00125]
14: TRAIN [0][1830/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 71714 (54153)	Loss/tok 3.9047 (4.7995)	Learning Rate [0.00125]
6: TRAIN [0][1830/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00093)	Tok/s 71474 (53484)	Loss/tok 3.8274 (4.7918)	Learning Rate [0.00125]
8: TRAIN [0][1830/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 72027 (53643)	Loss/tok 3.9513 (4.7864)	Learning Rate [0.00125]
10: TRAIN [0][1830/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 71928 (53780)	Loss/tok 3.7732 (4.7960)	Learning Rate [0.00125]
9: TRAIN [0][1830/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 72001 (53706)	Loss/tok 3.7847 (4.7964)	Learning Rate [0.00125]
9: TRAIN [0][1840/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00093)	Tok/s 50029 (53747)	Loss/tok 3.5656 (4.7894)	Learning Rate [0.00125]
8: TRAIN [0][1840/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00092)	Tok/s 50065 (53684)	Loss/tok 3.5287 (4.7796)	Learning Rate [0.00125]
10: TRAIN [0][1840/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00097)	Tok/s 49954 (53821)	Loss/tok 3.5248 (4.7887)	Learning Rate [0.00125]
7: TRAIN [0][1840/3416]	Time 0.046 (0.058)	Data 0.00102 (0.00096)	Tok/s 50016 (53602)	Loss/tok 3.6833 (4.7847)	Learning Rate [0.00125]
11: TRAIN [0][1840/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00092)	Tok/s 49775 (53894)	Loss/tok 3.3720 (4.7896)	Learning Rate [0.00125]
6: TRAIN [0][1840/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00093)	Tok/s 49823 (53525)	Loss/tok 3.6977 (4.7853)	Learning Rate [0.00125]
12: TRAIN [0][1840/3416]	Time 0.046 (0.058)	Data 0.00105 (0.00096)	Tok/s 49655 (54000)	Loss/tok 3.7020 (4.7901)	Learning Rate [0.00125]
5: TRAIN [0][1840/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00095)	Tok/s 49811 (53455)	Loss/tok 3.7831 (4.7876)	Learning Rate [0.00125]
4: TRAIN [0][1840/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00099)	Tok/s 49624 (53370)	Loss/tok 3.7347 (4.7902)	Learning Rate [0.00125]
13: TRAIN [0][1840/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00096)	Tok/s 49604 (54089)	Loss/tok 3.9568 (4.7876)	Learning Rate [0.00125]
3: TRAIN [0][1840/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00094)	Tok/s 49591 (53283)	Loss/tok 3.4010 (4.7883)	Learning Rate [0.00125]
1: TRAIN [0][1840/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00094)	Tok/s 49384 (53077)	Loss/tok 3.5454 (4.7862)	Learning Rate [0.00125]
14: TRAIN [0][1840/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00096)	Tok/s 49399 (54192)	Loss/tok 3.6626 (4.7926)	Learning Rate [0.00125]
0: TRAIN [0][1840/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00097)	Tok/s 49289 (52981)	Loss/tok 3.6333 (4.7969)	Learning Rate [0.00125]
2: TRAIN [0][1840/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00101)	Tok/s 49497 (53180)	Loss/tok 3.3134 (4.7877)	Learning Rate [0.00125]
15: TRAIN [0][1840/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 50172 (54309)	Loss/tok 3.7281 (4.7863)	Learning Rate [0.00125]
8: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00092)	Tok/s 62065 (53688)	Loss/tok 3.5666 (4.7731)	Learning Rate [0.00125]
7: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00108 (0.00096)	Tok/s 62093 (53607)	Loss/tok 3.9512 (4.7787)	Learning Rate [0.00125]
9: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00093)	Tok/s 61960 (53751)	Loss/tok 3.9224 (4.7835)	Learning Rate [0.00125]
6: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00113 (0.00093)	Tok/s 62122 (53529)	Loss/tok 3.9393 (4.7793)	Learning Rate [0.00125]
10: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00097)	Tok/s 61862 (53825)	Loss/tok 3.8323 (4.7831)	Learning Rate [0.00125]
5: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00095)	Tok/s 62092 (53460)	Loss/tok 3.9449 (4.7814)	Learning Rate [0.00125]
3: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00094)	Tok/s 62172 (53289)	Loss/tok 3.6540 (4.7822)	Learning Rate [0.00125]
11: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00092)	Tok/s 61842 (53898)	Loss/tok 3.7278 (4.7833)	Learning Rate [0.00125]
4: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00099)	Tok/s 62011 (53375)	Loss/tok 3.9245 (4.7840)	Learning Rate [0.00125]
12: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00109 (0.00096)	Tok/s 61828 (54004)	Loss/tok 4.2471 (4.7845)	Learning Rate [0.00125]
13: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00096)	Tok/s 61902 (54093)	Loss/tok 4.0375 (4.7815)	Learning Rate [0.00125]
15: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00092)	Tok/s 61977 (54312)	Loss/tok 3.7044 (4.7802)	Learning Rate [0.00125]
1: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00094)	Tok/s 62036 (53083)	Loss/tok 3.8939 (4.7800)	Learning Rate [0.00125]
2: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00101)	Tok/s 62084 (53186)	Loss/tok 3.9445 (4.7813)	Learning Rate [0.00125]
0: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00097)	Tok/s 61839 (52987)	Loss/tok 4.1166 (4.7910)	Learning Rate [0.00125]
14: TRAIN [0][1850/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00096)	Tok/s 62011 (54196)	Loss/tok 3.8137 (4.7868)	Learning Rate [0.00125]
14: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00096)	Tok/s 51049 (54179)	Loss/tok 3.6047 (4.7815)	Learning Rate [0.00125]
13: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00096)	Tok/s 51082 (54077)	Loss/tok 3.5729 (4.7761)	Learning Rate [0.00125]
12: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00096)	Tok/s 51176 (53989)	Loss/tok 3.3983 (4.7790)	Learning Rate [0.00125]
15: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00092)	Tok/s 50867 (54295)	Loss/tok 3.5632 (4.7750)	Learning Rate [0.00125]
0: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00097)	Tok/s 49490 (52972)	Loss/tok 3.7010 (4.7856)	Learning Rate [0.00125]
1: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00079 (0.00094)	Tok/s 49240 (53070)	Loss/tok 3.7058 (4.7743)	Learning Rate [0.00125]
11: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00092)	Tok/s 50905 (53883)	Loss/tok 3.5371 (4.7777)	Learning Rate [0.00125]
9: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00093)	Tok/s 50770 (53736)	Loss/tok 3.2889 (4.7778)	Learning Rate [0.00125]
2: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00101)	Tok/s 49230 (53172)	Loss/tok 3.5791 (4.7762)	Learning Rate [0.00125]
10: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00108 (0.00097)	Tok/s 50884 (53810)	Loss/tok 3.4930 (4.7777)	Learning Rate [0.00125]
3: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00094)	Tok/s 49044 (53274)	Loss/tok 3.5953 (4.7770)	Learning Rate [0.00125]
8: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00092)	Tok/s 50626 (53673)	Loss/tok 3.3391 (4.7676)	Learning Rate [0.00125]
4: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00099)	Tok/s 48925 (53360)	Loss/tok 3.2848 (4.7786)	Learning Rate [0.00125]
7: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00111 (0.00096)	Tok/s 50516 (53592)	Loss/tok 3.6866 (4.7735)	Learning Rate [0.00125]
5: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00095)	Tok/s 48936 (53444)	Loss/tok 3.5770 (4.7756)	Learning Rate [0.00125]
6: TRAIN [0][1860/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00093)	Tok/s 49829 (53514)	Loss/tok 3.4135 (4.7739)	Learning Rate [0.00125]
2: TRAIN [0][1870/3416]	Time 0.033 (0.058)	Data 0.00093 (0.00101)	Tok/s 16153 (53187)	Loss/tok 1.9983 (4.7699)	Learning Rate [0.00125]
1: TRAIN [0][1870/3416]	Time 0.033 (0.058)	Data 0.00089 (0.00094)	Tok/s 12533 (53083)	Loss/tok 1.9717 (4.7682)	Learning Rate [0.00125]
3: TRAIN [0][1870/3416]	Time 0.033 (0.058)	Data 0.00079 (0.00094)	Tok/s 17388 (53290)	Loss/tok 1.6824 (4.7707)	Learning Rate [0.00125]
4: TRAIN [0][1870/3416]	Time 0.033 (0.058)	Data 0.00094 (0.00099)	Tok/s 20200 (53376)	Loss/tok 2.3629 (4.7725)	Learning Rate [0.00125]
0: TRAIN [0][1870/3416]	Time 0.033 (0.058)	Data 0.00093 (0.00097)	Tok/s 9595 (52984)	Loss/tok 1.7598 (4.7793)	Learning Rate [0.00125]
15: TRAIN [0][1870/3416]	Time 0.033 (0.058)	Data 0.00088 (0.00092)	Tok/s 28481 (54315)	Loss/tok 2.4361 (4.7688)	Learning Rate [0.00125]
5: TRAIN [0][1870/3416]	Time 0.033 (0.058)	Data 0.00096 (0.00095)	Tok/s 21317 (53460)	Loss/tok 2.2272 (4.7692)	Learning Rate [0.00125]
6: TRAIN [0][1870/3416]	Time 0.033 (0.058)	Data 0.00102 (0.00093)	Tok/s 22621 (53531)	Loss/tok 2.5371 (4.7679)	Learning Rate [0.00125]
14: TRAIN [0][1870/3416]	Time 0.034 (0.058)	Data 0.00093 (0.00096)	Tok/s 26688 (54199)	Loss/tok 2.8538 (4.7750)	Learning Rate [0.00125]
7: TRAIN [0][1870/3416]	Time 0.033 (0.058)	Data 0.00108 (0.00096)	Tok/s 23072 (53611)	Loss/tok 2.7044 (4.7671)	Learning Rate [0.00125]
8: TRAIN [0][1870/3416]	Time 0.033 (0.058)	Data 0.00091 (0.00092)	Tok/s 24402 (53692)	Loss/tok 2.1012 (4.7612)	Learning Rate [0.00125]
12: TRAIN [0][1870/3416]	Time 0.034 (0.058)	Data 0.00101 (0.00096)	Tok/s 25642 (54009)	Loss/tok 2.3731 (4.7726)	Learning Rate [0.00125]
9: TRAIN [0][1870/3416]	Time 0.034 (0.058)	Data 0.00081 (0.00093)	Tok/s 24825 (53755)	Loss/tok 2.2308 (4.7712)	Learning Rate [0.00125]
11: TRAIN [0][1870/3416]	Time 0.034 (0.058)	Data 0.00086 (0.00092)	Tok/s 24747 (53902)	Loss/tok 2.0730 (4.7719)	Learning Rate [0.00125]
13: TRAIN [0][1870/3416]	Time 0.034 (0.058)	Data 0.00089 (0.00096)	Tok/s 26680 (54097)	Loss/tok 2.4797 (4.7700)	Learning Rate [0.00125]
10: TRAIN [0][1870/3416]	Time 0.034 (0.058)	Data 0.00096 (0.00097)	Tok/s 24799 (53829)	Loss/tok 2.2020 (4.7714)	Learning Rate [0.00125]
11: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00074 (0.00092)	Tok/s 34639 (53910)	Loss/tok 3.4096 (4.7654)	Learning Rate [0.00125]
12: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00096)	Tok/s 34600 (54016)	Loss/tok 3.2987 (4.7657)	Learning Rate [0.00125]
14: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00096)	Tok/s 35565 (54209)	Loss/tok 3.5289 (4.7685)	Learning Rate [0.00125]
15: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00092)	Tok/s 35667 (54325)	Loss/tok 3.4639 (4.7621)	Learning Rate [0.00125]
10: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00097)	Tok/s 34595 (53837)	Loss/tok 3.3705 (4.7650)	Learning Rate [0.00125]
13: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00096)	Tok/s 34576 (54106)	Loss/tok 3.4594 (4.7637)	Learning Rate [0.00125]
9: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00093)	Tok/s 34496 (53763)	Loss/tok 3.1114 (4.7647)	Learning Rate [0.00125]
8: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00092)	Tok/s 34424 (53700)	Loss/tok 3.4981 (4.7547)	Learning Rate [0.00125]
0: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 34322 (52991)	Loss/tok 3.2796 (4.7735)	Learning Rate [0.00125]
7: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00081 (0.00096)	Tok/s 34357 (53619)	Loss/tok 3.1572 (4.7612)	Learning Rate [0.00125]
6: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00093)	Tok/s 34291 (53538)	Loss/tok 3.3234 (4.7616)	Learning Rate [0.00125]
1: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00094)	Tok/s 34228 (53089)	Loss/tok 3.6144 (4.7623)	Learning Rate [0.00125]
2: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00101)	Tok/s 34176 (53193)	Loss/tok 3.2685 (4.7636)	Learning Rate [0.00125]
5: TRAIN [0][1880/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00095)	Tok/s 34176 (53467)	Loss/tok 3.2753 (4.7629)	Learning Rate [0.00125]
3: TRAIN [0][1880/3416]	Time 0.053 (0.058)	Data 0.00077 (0.00094)	Tok/s 34065 (53296)	Loss/tok 3.4126 (4.7644)	Learning Rate [0.00125]
4: TRAIN [0][1880/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00099)	Tok/s 34119 (53382)	Loss/tok 3.5565 (4.7663)	Learning Rate [0.00125]
9: TRAIN [0][1890/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00093)	Tok/s 34889 (53703)	Loss/tok 3.4680 (4.7601)	Learning Rate [0.00125]
8: TRAIN [0][1890/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00092)	Tok/s 34886 (53640)	Loss/tok 3.2361 (4.7500)	Learning Rate [0.00125]
11: TRAIN [0][1890/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00092)	Tok/s 34724 (53850)	Loss/tok 3.4731 (4.7606)	Learning Rate [0.00125]
6: TRAIN [0][1890/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00093)	Tok/s 34904 (53478)	Loss/tok 3.3838 (4.7569)	Learning Rate [0.00125]
7: TRAIN [0][1890/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00096)	Tok/s 34909 (53559)	Loss/tok 3.2967 (4.7562)	Learning Rate [0.00125]
10: TRAIN [0][1890/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 34800 (53777)	Loss/tok 3.2884 (4.7603)	Learning Rate [0.00125]
5: TRAIN [0][1890/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00095)	Tok/s 34913 (53407)	Loss/tok 3.5102 (4.7583)	Learning Rate [0.00125]
12: TRAIN [0][1890/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00096)	Tok/s 34664 (53956)	Loss/tok 3.4088 (4.7610)	Learning Rate [0.00125]
4: TRAIN [0][1890/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00099)	Tok/s 34919 (53320)	Loss/tok 3.3797 (4.7616)	Learning Rate [0.00125]
13: TRAIN [0][1890/3416]	Time 0.052 (0.058)	Data 0.00110 (0.00096)	Tok/s 34642 (54046)	Loss/tok 3.2792 (4.7590)	Learning Rate [0.00125]
14: TRAIN [0][1890/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00096)	Tok/s 34660 (54149)	Loss/tok 3.6072 (4.7637)	Learning Rate [0.00125]
3: TRAIN [0][1890/3416]	Time 0.051 (0.058)	Data 0.00107 (0.00094)	Tok/s 34836 (53234)	Loss/tok 3.1394 (4.7599)	Learning Rate [0.00125]
15: TRAIN [0][1890/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00092)	Tok/s 34776 (54266)	Loss/tok 3.1493 (4.7575)	Learning Rate [0.00125]
1: TRAIN [0][1890/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00094)	Tok/s 34720 (53026)	Loss/tok 3.3881 (4.7577)	Learning Rate [0.00125]
2: TRAIN [0][1890/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00101)	Tok/s 34799 (53130)	Loss/tok 3.5967 (4.7588)	Learning Rate [0.00125]
0: TRAIN [0][1890/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00097)	Tok/s 34695 (52929)	Loss/tok 3.3069 (4.7687)	Learning Rate [0.00125]
14: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 67926 (54138)	Loss/tok 3.9329 (4.7585)	Learning Rate [0.00125]
13: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00096)	Tok/s 66949 (54034)	Loss/tok 3.9891 (4.7534)	Learning Rate [0.00125]
11: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00074 (0.00092)	Tok/s 66859 (53837)	Loss/tok 3.8763 (4.7552)	Learning Rate [0.00125]
12: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 66835 (53944)	Loss/tok 3.7862 (4.7552)	Learning Rate [0.00125]
15: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 67977 (54256)	Loss/tok 3.6434 (4.7518)	Learning Rate [0.00125]
9: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 66935 (53690)	Loss/tok 3.6521 (4.7545)	Learning Rate [0.00125]
0: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00079 (0.00097)	Tok/s 66440 (52908)	Loss/tok 3.9383 (4.7631)	Learning Rate [0.00125]
1: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00094)	Tok/s 67012 (53008)	Loss/tok 3.8162 (4.7520)	Learning Rate [0.00125]
8: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00079 (0.00092)	Tok/s 66887 (53627)	Loss/tok 3.9015 (4.7443)	Learning Rate [0.00125]
6: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 66978 (53465)	Loss/tok 3.6705 (4.7515)	Learning Rate [0.00125]
2: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00101)	Tok/s 66972 (53113)	Loss/tok 3.8408 (4.7533)	Learning Rate [0.00125]
3: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 67024 (53218)	Loss/tok 3.8416 (4.7544)	Learning Rate [0.00125]
10: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00097)	Tok/s 66915 (53764)	Loss/tok 3.6672 (4.7542)	Learning Rate [0.00125]
7: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00096)	Tok/s 66883 (53546)	Loss/tok 3.9733 (4.7507)	Learning Rate [0.00125]
5: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00095)	Tok/s 66969 (53392)	Loss/tok 4.0808 (4.7530)	Learning Rate [0.00125]
4: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00099)	Tok/s 66932 (53305)	Loss/tok 3.8317 (4.7562)	Learning Rate [0.00125]
9: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
3: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00093)	Tok/s 51871 (53201)	Loss/tok 3.5154 (4.7498)	Learning Rate [0.00125]
2: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00101)	Tok/s 51903 (53097)	Loss/tok 3.7201 (4.7483)	Learning Rate [0.00125]
4: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00099)	Tok/s 51750 (53288)	Loss/tok 3.2800 (4.7510)	Learning Rate [0.00125]
1: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00094)	Tok/s 51908 (52992)	Loss/tok 3.6786 (4.7467)	Learning Rate [0.00125]
0: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00097)	Tok/s 51890 (52892)	Loss/tok 3.7446 (4.7575)	Learning Rate [0.00125]
5: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00095)	Tok/s 51744 (53375)	Loss/tok 3.5421 (4.7479)	Learning Rate [0.00125]
6: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00093)	Tok/s 51642 (53447)	Loss/tok 3.7993 (4.7463)	Learning Rate [0.00125]
15: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00092)	Tok/s 51882 (54235)	Loss/tok 3.5277 (4.7469)	Learning Rate [0.00125]
7: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00096)	Tok/s 51763 (53528)	Loss/tok 3.6023 (4.7455)	Learning Rate [0.00125]
14: TRAIN [0][1910/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00096)	Tok/s 52043 (54119)	Loss/tok 3.4041 (4.7532)	Learning Rate [0.00125]
8: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00092)	Tok/s 51799 (53609)	Loss/tok 3.5340 (4.7394)	Learning Rate [0.00125]
9: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00093)	Tok/s 51686 (53672)	Loss/tok 3.7108 (4.7488)	Learning Rate [0.00125]
13: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00096)	Tok/s 51898 (54015)	Loss/tok 3.4575 (4.7480)	Learning Rate [0.00125]
10: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00097)	Tok/s 51679 (53746)	Loss/tok 3.7483 (4.7489)	Learning Rate [0.00125]
12: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00096)	Tok/s 51861 (53925)	Loss/tok 3.7053 (4.7502)	Learning Rate [0.00125]
11: TRAIN [0][1910/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00092)	Tok/s 51771 (53818)	Loss/tok 3.4853 (4.7499)	Learning Rate [0.00125]
5: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00095)	Tok/s 46529 (53364)	Loss/tok 3.5805 (4.7429)	Learning Rate [0.00125]
2: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00100)	Tok/s 46816 (53086)	Loss/tok 3.4908 (4.7436)	Learning Rate [0.00125]
6: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00093)	Tok/s 46644 (53435)	Loss/tok 3.2107 (4.7412)	Learning Rate [0.00125]
14: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00096)	Tok/s 48868 (54105)	Loss/tok 3.6286 (4.7486)	Learning Rate [0.00125]
15: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00092)	Tok/s 48609 (54222)	Loss/tok 3.7399 (4.7419)	Learning Rate [0.00125]
1: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00104 (0.00094)	Tok/s 46942 (52981)	Loss/tok 3.2685 (4.7418)	Learning Rate [0.00125]
3: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00093)	Tok/s 46734 (53190)	Loss/tok 3.6014 (4.7446)	Learning Rate [0.00125]
11: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00092)	Tok/s 48529 (53805)	Loss/tok 3.6890 (4.7452)	Learning Rate [0.00125]
9: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00093)	Tok/s 48258 (53660)	Loss/tok 3.4168 (4.7438)	Learning Rate [0.00125]
7: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00096)	Tok/s 46669 (53516)	Loss/tok 3.7137 (4.7404)	Learning Rate [0.00125]
4: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00099)	Tok/s 46674 (53276)	Loss/tok 3.3516 (4.7460)	Learning Rate [0.00125]
12: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00096)	Tok/s 48628 (53912)	Loss/tok 3.6469 (4.7449)	Learning Rate [0.00125]
13: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00096)	Tok/s 48760 (54002)	Loss/tok 3.3364 (4.7426)	Learning Rate [0.00125]
10: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00097)	Tok/s 48363 (53733)	Loss/tok 3.5195 (4.7440)	Learning Rate [0.00125]
0: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 47038 (52882)	Loss/tok 3.3661 (4.7522)	Learning Rate [0.00125]
8: TRAIN [0][1920/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00092)	Tok/s 46997 (53597)	Loss/tok 3.6780 (4.7346)	Learning Rate [0.00125]
2: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00100)	Tok/s 61372 (53107)	Loss/tok 3.6801 (4.7377)	Learning Rate [0.00125]
1: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00094)	Tok/s 60590 (53000)	Loss/tok 3.8432 (4.7364)	Learning Rate [0.00125]
3: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 61599 (53210)	Loss/tok 3.4949 (4.7390)	Learning Rate [0.00125]
0: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 60559 (52902)	Loss/tok 3.8002 (4.7463)	Learning Rate [0.00125]
4: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 61568 (53296)	Loss/tok 3.6843 (4.7403)	Learning Rate [0.00125]
11: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 61493 (53824)	Loss/tok 3.7822 (4.7387)	Learning Rate [0.00125]
15: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 61424 (54239)	Loss/tok 3.7362 (4.7359)	Learning Rate [0.00125]
12: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 61477 (53930)	Loss/tok 3.6074 (4.7386)	Learning Rate [0.00125]
5: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00095)	Tok/s 61508 (53383)	Loss/tok 4.0819 (4.7374)	Learning Rate [0.00125]
7: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00096)	Tok/s 61482 (53535)	Loss/tok 3.8910 (4.7347)	Learning Rate [0.00125]
14: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00096)	Tok/s 61361 (54123)	Loss/tok 3.5235 (4.7426)	Learning Rate [0.00125]
13: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 61439 (54020)	Loss/tok 3.7811 (4.7368)	Learning Rate [0.00125]
8: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 61411 (53616)	Loss/tok 3.8804 (4.7288)	Learning Rate [0.00125]
10: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 61361 (53752)	Loss/tok 3.7185 (4.7379)	Learning Rate [0.00125]
6: TRAIN [0][1930/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00093)	Tok/s 60602 (53455)	Loss/tok 3.9391 (4.7354)	Learning Rate [0.00125]
9: TRAIN [0][1930/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00093)	Tok/s 60524 (53678)	Loss/tok 4.0553 (4.7378)	Learning Rate [0.00125]
10: TRAIN [0][1940/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00097)	Tok/s 32513 (53757)	Loss/tok 2.9482 (4.7320)	Learning Rate [0.00125]
9: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00080 (0.00093)	Tok/s 32329 (53684)	Loss/tok 3.5865 (4.7325)	Learning Rate [0.00125]
11: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00092)	Tok/s 33565 (53829)	Loss/tok 3.3244 (4.7329)	Learning Rate [0.00125]
3: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00093)	Tok/s 32264 (53215)	Loss/tok 3.0823 (4.7336)	Learning Rate [0.00125]
8: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00092)	Tok/s 32289 (53621)	Loss/tok 3.5357 (4.7235)	Learning Rate [0.00125]
12: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00096)	Tok/s 33511 (53935)	Loss/tok 2.9731 (4.7331)	Learning Rate [0.00125]
6: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00093)	Tok/s 32247 (53460)	Loss/tok 3.5952 (4.7299)	Learning Rate [0.00125]
2: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00100)	Tok/s 32223 (53112)	Loss/tok 3.3050 (4.7325)	Learning Rate [0.00125]
7: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00096)	Tok/s 32280 (53540)	Loss/tok 3.2316 (4.7291)	Learning Rate [0.00125]
5: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00095)	Tok/s 32280 (53388)	Loss/tok 3.1303 (4.7319)	Learning Rate [0.00125]
1: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00094)	Tok/s 32137 (53006)	Loss/tok 3.1798 (4.7306)	Learning Rate [0.00125]
4: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00110 (0.00099)	Tok/s 32197 (53301)	Loss/tok 3.0314 (4.7348)	Learning Rate [0.00125]
0: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00097)	Tok/s 31718 (52908)	Loss/tok 3.3589 (4.7406)	Learning Rate [0.00125]
15: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00092)	Tok/s 33398 (54243)	Loss/tok 3.2310 (4.7302)	Learning Rate [0.00125]
14: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00096)	Tok/s 33340 (54127)	Loss/tok 2.9947 (4.7369)	Learning Rate [0.00125]
13: TRAIN [0][1940/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00096)	Tok/s 33375 (54024)	Loss/tok 3.1405 (4.7315)	Learning Rate [0.00125]
6: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 67033 (53454)	Loss/tok 3.9178 (4.7247)	Learning Rate [0.00125]
5: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00095)	Tok/s 67027 (53382)	Loss/tok 3.9775 (4.7266)	Learning Rate [0.00125]
8: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 66953 (53614)	Loss/tok 3.9911 (4.7181)	Learning Rate [0.00125]
9: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 67387 (53677)	Loss/tok 3.5351 (4.7269)	Learning Rate [0.00125]
4: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00099)	Tok/s 66946 (53295)	Loss/tok 3.9544 (4.7296)	Learning Rate [0.00125]
3: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 66991 (53210)	Loss/tok 3.7631 (4.7282)	Learning Rate [0.00125]
10: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 67870 (53750)	Loss/tok 3.8336 (4.7267)	Learning Rate [0.00125]
2: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 66951 (53107)	Loss/tok 3.7234 (4.7269)	Learning Rate [0.00125]
11: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00076 (0.00092)	Tok/s 67916 (53823)	Loss/tok 3.9536 (4.7276)	Learning Rate [0.00125]
12: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 67874 (53930)	Loss/tok 3.7704 (4.7278)	Learning Rate [0.00125]
0: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 66956 (52904)	Loss/tok 3.8717 (4.7349)	Learning Rate [0.00125]
13: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 67868 (54018)	Loss/tok 3.6969 (4.7259)	Learning Rate [0.00125]
15: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 67910 (54237)	Loss/tok 3.7544 (4.7248)	Learning Rate [0.00125]
14: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 68036 (54121)	Loss/tok 3.7663 (4.7316)	Learning Rate [0.00125]
7: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00113 (0.00096)	Tok/s 66980 (53533)	Loss/tok 3.8207 (4.7240)	Learning Rate [0.00125]
1: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00117 (0.00094)	Tok/s 66888 (53002)	Loss/tok 3.9015 (4.7252)	Learning Rate [0.00125]
6: TRAIN [0][1960/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00093)	Tok/s 33050 (53419)	Loss/tok 3.1715 (4.7199)	Learning Rate [0.00125]
7: TRAIN [0][1960/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00096)	Tok/s 33074 (53499)	Loss/tok 3.2951 (4.7198)	Learning Rate [0.00125]
5: TRAIN [0][1960/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00095)	Tok/s 32974 (53347)	Loss/tok 3.2723 (4.7219)	Learning Rate [0.00125]
8: TRAIN [0][1960/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00092)	Tok/s 33039 (53579)	Loss/tok 3.1308 (4.7135)	Learning Rate [0.00125]
9: TRAIN [0][1960/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00093)	Tok/s 32971 (53642)	Loss/tok 3.2051 (4.7222)	Learning Rate [0.00125]
4: TRAIN [0][1960/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00099)	Tok/s 32849 (53261)	Loss/tok 3.4621 (4.7250)	Learning Rate [0.00125]
10: TRAIN [0][1960/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00097)	Tok/s 32865 (53715)	Loss/tok 3.2219 (4.7217)	Learning Rate [0.00125]
3: TRAIN [0][1960/3416]	Time 0.053 (0.058)	Data 0.00103 (0.00093)	Tok/s 32797 (53176)	Loss/tok 3.1331 (4.7230)	Learning Rate [0.00125]
12: TRAIN [0][1960/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00096)	Tok/s 32868 (53895)	Loss/tok 3.4171 (4.7233)	Learning Rate [0.00125]
2: TRAIN [0][1960/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00100)	Tok/s 32827 (53072)	Loss/tok 3.3880 (4.7220)	Learning Rate [0.00125]
11: TRAIN [0][1960/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00092)	Tok/s 32819 (53789)	Loss/tok 3.0028 (4.7231)	Learning Rate [0.00125]
1: TRAIN [0][1960/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00094)	Tok/s 32825 (52968)	Loss/tok 3.2978 (4.7205)	Learning Rate [0.00125]
0: TRAIN [0][1960/3416]	Time 0.053 (0.058)	Data 0.00103 (0.00097)	Tok/s 32826 (52869)	Loss/tok 3.0474 (4.7301)	Learning Rate [0.00125]
13: TRAIN [0][1960/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00096)	Tok/s 33442 (53985)	Loss/tok 3.2582 (4.7212)	Learning Rate [0.00125]
14: TRAIN [0][1960/3416]	Time 0.053 (0.058)	Data 0.00123 (0.00096)	Tok/s 34065 (54087)	Loss/tok 3.1647 (4.7266)	Learning Rate [0.00125]
15: TRAIN [0][1960/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00092)	Tok/s 34041 (54202)	Loss/tok 3.0993 (4.7203)	Learning Rate [0.00125]
6: TRAIN [0][1970/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00093)	Tok/s 51643 (53442)	Loss/tok 3.6754 (4.7142)	Learning Rate [0.00125]
5: TRAIN [0][1970/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00095)	Tok/s 51209 (53370)	Loss/tok 3.6484 (4.7165)	Learning Rate [0.00125]
4: TRAIN [0][1970/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00099)	Tok/s 50081 (53284)	Loss/tok 3.1187 (4.7192)	Learning Rate [0.00125]
7: TRAIN [0][1970/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00096)	Tok/s 51552 (53522)	Loss/tok 3.5948 (4.7141)	Learning Rate [0.00125]
3: TRAIN [0][1970/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00093)	Tok/s 49947 (53199)	Loss/tok 3.6084 (4.7174)	Learning Rate [0.00125]
2: TRAIN [0][1970/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00100)	Tok/s 49783 (53096)	Loss/tok 3.4988 (4.7164)	Learning Rate [0.00125]
8: TRAIN [0][1970/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 51495 (53602)	Loss/tok 3.1776 (4.7076)	Learning Rate [0.00125]
1: TRAIN [0][1970/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00094)	Tok/s 49728 (52992)	Loss/tok 3.5600 (4.7145)	Learning Rate [0.00125]
0: TRAIN [0][1970/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00097)	Tok/s 49705 (52893)	Loss/tok 3.4212 (4.7240)	Learning Rate [0.00125]
9: TRAIN [0][1970/3416]	Time 0.047 (0.058)	Data 0.00079 (0.00093)	Tok/s 51376 (53665)	Loss/tok 3.4930 (4.7166)	Learning Rate [0.00125]
12: TRAIN [0][1970/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00096)	Tok/s 51291 (53917)	Loss/tok 3.5387 (4.7178)	Learning Rate [0.00125]
15: TRAIN [0][1970/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00092)	Tok/s 50978 (54224)	Loss/tok 3.5645 (4.7145)	Learning Rate [0.00125]
10: TRAIN [0][1970/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00097)	Tok/s 51869 (53738)	Loss/tok 3.5395 (4.7157)	Learning Rate [0.00125]
11: TRAIN [0][1970/3416]	Time 0.047 (0.058)	Data 0.00075 (0.00092)	Tok/s 51222 (53812)	Loss/tok 3.3615 (4.7172)	Learning Rate [0.00125]
14: TRAIN [0][1970/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00096)	Tok/s 51032 (54109)	Loss/tok 3.5884 (4.7208)	Learning Rate [0.00125]
13: TRAIN [0][1970/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00096)	Tok/s 51129 (54007)	Loss/tok 3.5059 (4.7154)	Learning Rate [0.00125]
5: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00081 (0.00095)	Tok/s 52294 (53394)	Loss/tok 3.5382 (4.7106)	Learning Rate [0.00125]
6: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00113 (0.00093)	Tok/s 52198 (53466)	Loss/tok 3.6741 (4.7087)	Learning Rate [0.00125]
3: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00093)	Tok/s 52205 (53222)	Loss/tok 3.5127 (4.7122)	Learning Rate [0.00125]
4: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00099)	Tok/s 52028 (53307)	Loss/tok 3.3623 (4.7129)	Learning Rate [0.00125]
9: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00079 (0.00093)	Tok/s 52221 (53688)	Loss/tok 3.5204 (4.7106)	Learning Rate [0.00125]
7: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00096)	Tok/s 52098 (53545)	Loss/tok 3.7407 (4.7083)	Learning Rate [0.00125]
2: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00100)	Tok/s 52079 (53119)	Loss/tok 3.7635 (4.7107)	Learning Rate [0.00125]
8: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00082 (0.00092)	Tok/s 52101 (53626)	Loss/tok 3.5525 (4.7019)	Learning Rate [0.00125]
1: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00094)	Tok/s 52062 (53015)	Loss/tok 3.4845 (4.7089)	Learning Rate [0.00125]
15: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00092)	Tok/s 52183 (54245)	Loss/tok 3.5791 (4.7086)	Learning Rate [0.00125]
0: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00097)	Tok/s 52053 (52917)	Loss/tok 3.4831 (4.7177)	Learning Rate [0.00125]
11: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00080 (0.00092)	Tok/s 51994 (53835)	Loss/tok 3.5476 (4.7120)	Learning Rate [0.00125]
14: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00096)	Tok/s 52137 (54131)	Loss/tok 3.4611 (4.7151)	Learning Rate [0.00125]
10: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00097)	Tok/s 51917 (53761)	Loss/tok 3.7616 (4.7101)	Learning Rate [0.00125]
13: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00096)	Tok/s 51921 (54029)	Loss/tok 3.7459 (4.7102)	Learning Rate [0.00125]
12: TRAIN [0][1980/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00096)	Tok/s 51828 (53940)	Loss/tok 3.6466 (4.7115)	Learning Rate [0.00125]
0: TRAIN [0][1990/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00097)	Tok/s 52269 (52934)	Loss/tok 3.4803 (4.7123)	Learning Rate [0.00125]
1: TRAIN [0][1990/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00094)	Tok/s 52292 (53031)	Loss/tok 3.6489 (4.7041)	Learning Rate [0.00125]
15: TRAIN [0][1990/3416]	Time 0.055 (0.058)	Data 0.00082 (0.00092)	Tok/s 53354 (54259)	Loss/tok 3.6686 (4.7033)	Learning Rate [0.00125]
2: TRAIN [0][1990/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00100)	Tok/s 52270 (53135)	Loss/tok 3.6872 (4.7047)	Learning Rate [0.00125]
14: TRAIN [0][1990/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00096)	Tok/s 53253 (54145)	Loss/tok 3.6984 (4.7097)	Learning Rate [0.00125]
3: TRAIN [0][1990/3416]	Time 0.055 (0.058)	Data 0.00592 (0.00094)	Tok/s 52353 (53238)	Loss/tok 3.5964 (4.7065)	Learning Rate [0.00125]
12: TRAIN [0][1990/3416]	Time 0.056 (0.058)	Data 0.00084 (0.00096)	Tok/s 53017 (53955)	Loss/tok 3.5213 (4.7063)	Learning Rate [0.00125]
4: TRAIN [0][1990/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00099)	Tok/s 53342 (53323)	Loss/tok 3.4541 (4.7075)	Learning Rate [0.00125]
11: TRAIN [0][1990/3416]	Time 0.056 (0.058)	Data 0.00082 (0.00092)	Tok/s 52979 (53850)	Loss/tok 3.7605 (4.7069)	Learning Rate [0.00125]
13: TRAIN [0][1990/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00096)	Tok/s 53140 (54044)	Loss/tok 3.5964 (4.7051)	Learning Rate [0.00125]
5: TRAIN [0][1990/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00095)	Tok/s 53215 (53409)	Loss/tok 3.6213 (4.7054)	Learning Rate [0.00125]
7: TRAIN [0][1990/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00096)	Tok/s 53110 (53560)	Loss/tok 3.5800 (4.7026)	Learning Rate [0.00125]
10: TRAIN [0][1990/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00097)	Tok/s 52859 (53777)	Loss/tok 3.6547 (4.7050)	Learning Rate [0.00125]
6: TRAIN [0][1990/3416]	Time 0.056 (0.058)	Data 0.00099 (0.00093)	Tok/s 53026 (53481)	Loss/tok 3.7339 (4.7031)	Learning Rate [0.00125]
9: TRAIN [0][1990/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00093)	Tok/s 52985 (53703)	Loss/tok 3.7101 (4.7049)	Learning Rate [0.00125]
8: TRAIN [0][1990/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00092)	Tok/s 52867 (53640)	Loss/tok 3.4475 (4.6969)	Learning Rate [0.00125]
6: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00093)	Tok/s 34071 (53465)	Loss/tok 3.4812 (4.6984)	Learning Rate [0.00125]
5: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00095)	Tok/s 34052 (53393)	Loss/tok 3.1353 (4.7000)	Learning Rate [0.00125]
7: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00096)	Tok/s 33943 (53544)	Loss/tok 3.2033 (4.6975)	Learning Rate [0.00125]
4: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00109 (0.00099)	Tok/s 34041 (53307)	Loss/tok 3.0944 (4.7024)	Learning Rate [0.00125]
8: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00092)	Tok/s 33885 (53623)	Loss/tok 3.3570 (4.6919)	Learning Rate [0.00125]
3: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00094)	Tok/s 34033 (53222)	Loss/tok 3.5096 (4.7011)	Learning Rate [0.00125]
9: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00093)	Tok/s 33819 (53686)	Loss/tok 3.2963 (4.6998)	Learning Rate [0.00125]
2: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00100)	Tok/s 34015 (53119)	Loss/tok 3.1420 (4.6996)	Learning Rate [0.00125]
1: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00094)	Tok/s 33990 (53015)	Loss/tok 3.3340 (4.6991)	Learning Rate [0.00125]
10: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00097)	Tok/s 33719 (53759)	Loss/tok 3.4963 (4.6996)	Learning Rate [0.00125]
11: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00092)	Tok/s 33742 (53832)	Loss/tok 3.4427 (4.7016)	Learning Rate [0.00125]
0: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00097)	Tok/s 33953 (52918)	Loss/tok 3.6061 (4.7070)	Learning Rate [0.00125]
15: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00092)	Tok/s 33855 (54240)	Loss/tok 3.1906 (4.6982)	Learning Rate [0.00125]
12: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00096)	Tok/s 33720 (53937)	Loss/tok 3.2487 (4.7014)	Learning Rate [0.00125]
14: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00096)	Tok/s 33805 (54127)	Loss/tok 3.1022 (4.7049)	Learning Rate [0.00125]
13: TRAIN [0][2000/3416]	Time 0.053 (0.058)	Data 0.00079 (0.00096)	Tok/s 33747 (54026)	Loss/tok 3.0810 (4.7002)	Learning Rate [0.00125]
1: TRAIN [0][2010/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00094)	Tok/s 55645 (52989)	Loss/tok 3.4305 (4.6937)	Learning Rate [0.00125]
0: TRAIN [0][2010/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00097)	Tok/s 55542 (52892)	Loss/tok 3.5975 (4.7016)	Learning Rate [0.00125]
3: TRAIN [0][2010/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00094)	Tok/s 55561 (53195)	Loss/tok 3.6905 (4.6961)	Learning Rate [0.00125]
4: TRAIN [0][2010/3416]	Time 0.068 (0.058)	Data 0.00121 (0.00099)	Tok/s 55509 (53281)	Loss/tok 3.8870 (4.6973)	Learning Rate [0.00125]
6: TRAIN [0][2010/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00093)	Tok/s 55373 (53439)	Loss/tok 3.8530 (4.6936)	Learning Rate [0.00125]
15: TRAIN [0][2010/3416]	Time 0.068 (0.058)	Data 0.00109 (0.00092)	Tok/s 55409 (54217)	Loss/tok 3.9870 (4.6930)	Learning Rate [0.00125]
5: TRAIN [0][2010/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00095)	Tok/s 55405 (53368)	Loss/tok 3.7446 (4.6951)	Learning Rate [0.00125]
14: TRAIN [0][2010/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00096)	Tok/s 55363 (54103)	Loss/tok 3.7339 (4.7000)	Learning Rate [0.00125]
2: TRAIN [0][2010/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00100)	Tok/s 55554 (53092)	Loss/tok 3.8746 (4.6944)	Learning Rate [0.00125]
13: TRAIN [0][2010/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00096)	Tok/s 55261 (54002)	Loss/tok 3.6308 (4.6951)	Learning Rate [0.00125]
7: TRAIN [0][2010/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00096)	Tok/s 55246 (53518)	Loss/tok 3.8023 (4.6922)	Learning Rate [0.00125]
12: TRAIN [0][2010/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00096)	Tok/s 55156 (53913)	Loss/tok 3.8324 (4.6967)	Learning Rate [0.00125]
8: TRAIN [0][2010/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00092)	Tok/s 55150 (53598)	Loss/tok 3.8027 (4.6872)	Learning Rate [0.00125]
11: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 55123 (53807)	Loss/tok 3.7010 (4.6967)	Learning Rate [0.00125]
9: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 55072 (53661)	Loss/tok 3.8196 (4.6947)	Learning Rate [0.00125]
10: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00097)	Tok/s 55082 (53734)	Loss/tok 3.7608 (4.6947)	Learning Rate [0.00125]
3: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00094)	Tok/s 82910 (53237)	Loss/tok 3.5644 (4.6898)	Learning Rate [0.00125]
4: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00099)	Tok/s 83564 (53322)	Loss/tok 3.6270 (4.6910)	Learning Rate [0.00125]
2: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00100)	Tok/s 82742 (53134)	Loss/tok 3.4784 (4.6881)	Learning Rate [0.00125]
7: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 83634 (53559)	Loss/tok 3.5020 (4.6865)	Learning Rate [0.00125]
8: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 83661 (53639)	Loss/tok 3.5307 (4.6811)	Learning Rate [0.00125]
1: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00094)	Tok/s 82787 (53031)	Loss/tok 3.6017 (4.6879)	Learning Rate [0.00125]
6: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 83439 (53481)	Loss/tok 3.4048 (4.6874)	Learning Rate [0.00125]
5: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00095)	Tok/s 83442 (53409)	Loss/tok 3.5083 (4.6887)	Learning Rate [0.00125]
9: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 83894 (53701)	Loss/tok 3.5995 (4.6887)	Learning Rate [0.00125]
0: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 82802 (52934)	Loss/tok 3.6183 (4.6956)	Learning Rate [0.00125]
15: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 85491 (54258)	Loss/tok 3.5833 (4.6870)	Learning Rate [0.00125]
11: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 84579 (53848)	Loss/tok 3.6280 (4.6904)	Learning Rate [0.00125]
10: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 84628 (53775)	Loss/tok 3.5592 (4.6882)	Learning Rate [0.00125]
13: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00095)	Tok/s 84583 (54042)	Loss/tok 3.5168 (4.6885)	Learning Rate [0.00125]
14: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 84949 (54144)	Loss/tok 3.5973 (4.6941)	Learning Rate [0.00125]
12: TRAIN [0][2020/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00096)	Tok/s 84638 (53953)	Loss/tok 3.5308 (4.6907)	Learning Rate [0.00125]
2: TRAIN [0][2030/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00100)	Tok/s 50667 (53149)	Loss/tok 3.3967 (4.6828)	Learning Rate [0.00125]
1: TRAIN [0][2030/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00094)	Tok/s 50568 (53046)	Loss/tok 3.7872 (4.6826)	Learning Rate [0.00125]
9: TRAIN [0][2030/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00093)	Tok/s 51960 (53716)	Loss/tok 3.4814 (4.6830)	Learning Rate [0.00125]
3: TRAIN [0][2030/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00094)	Tok/s 50687 (53251)	Loss/tok 3.3400 (4.6846)	Learning Rate [0.00125]
0: TRAIN [0][2030/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00097)	Tok/s 50410 (52949)	Loss/tok 3.8440 (4.6906)	Learning Rate [0.00125]
6: TRAIN [0][2030/3416]	Time 0.049 (0.058)	Data 0.00082 (0.00093)	Tok/s 52017 (53495)	Loss/tok 3.6567 (4.6822)	Learning Rate [0.00125]
8: TRAIN [0][2030/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00092)	Tok/s 51914 (53654)	Loss/tok 3.4705 (4.6754)	Learning Rate [0.00125]
15: TRAIN [0][2030/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00092)	Tok/s 51715 (54272)	Loss/tok 3.6303 (4.6815)	Learning Rate [0.00125]
4: TRAIN [0][2030/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00099)	Tok/s 50673 (53337)	Loss/tok 3.4500 (4.6856)	Learning Rate [0.00125]
10: TRAIN [0][2030/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00097)	Tok/s 51770 (53790)	Loss/tok 3.4543 (4.6828)	Learning Rate [0.00125]
7: TRAIN [0][2030/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00096)	Tok/s 51968 (53574)	Loss/tok 3.5819 (4.6813)	Learning Rate [0.00125]
11: TRAIN [0][2030/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00092)	Tok/s 51729 (53863)	Loss/tok 3.5680 (4.6853)	Learning Rate [0.00125]
5: TRAIN [0][2030/3416]	Time 0.049 (0.058)	Data 0.00083 (0.00095)	Tok/s 52007 (53424)	Loss/tok 3.6442 (4.6831)	Learning Rate [0.00125]
14: TRAIN [0][2030/3416]	Time 0.050 (0.058)	Data 0.00081 (0.00096)	Tok/s 51565 (54158)	Loss/tok 3.4494 (4.6887)	Learning Rate [0.00125]
13: TRAIN [0][2030/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00095)	Tok/s 51515 (54057)	Loss/tok 3.4932 (4.6834)	Learning Rate [0.00125]
12: TRAIN [0][2030/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00096)	Tok/s 51550 (53968)	Loss/tok 3.4289 (4.6857)	Learning Rate [0.00125]
7: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
3: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00094)	Tok/s 33464 (53241)	Loss/tok 3.3268 (4.6800)	Learning Rate [0.00125]
4: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00099)	Tok/s 33390 (53326)	Loss/tok 3.3191 (4.6807)	Learning Rate [0.00125]
1: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00094)	Tok/s 33339 (53037)	Loss/tok 3.5144 (4.6777)	Learning Rate [0.00125]
0: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00112 (0.00097)	Tok/s 33304 (52940)	Loss/tok 3.1345 (4.6854)	Learning Rate [0.00125]
2: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00100)	Tok/s 33408 (53139)	Loss/tok 3.3938 (4.6774)	Learning Rate [0.00125]
5: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00095)	Tok/s 33500 (53414)	Loss/tok 3.1830 (4.6784)	Learning Rate [0.00125]
15: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00092)	Tok/s 34547 (54260)	Loss/tok 3.3948 (4.6767)	Learning Rate [0.00125]
6: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00093)	Tok/s 33294 (53484)	Loss/tok 3.4257 (4.6770)	Learning Rate [0.00125]
14: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00096)	Tok/s 34470 (54147)	Loss/tok 3.1996 (4.6839)	Learning Rate [0.00125]
7: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00096)	Tok/s 33297 (53564)	Loss/tok 3.3662 (4.6769)	Learning Rate [0.00125]
13: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00095)	Tok/s 34335 (54046)	Loss/tok 3.1524 (4.6782)	Learning Rate [0.00125]
8: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00092)	Tok/s 33250 (53643)	Loss/tok 3.1819 (4.6707)	Learning Rate [0.00125]
9: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00093)	Tok/s 33167 (53705)	Loss/tok 3.3048 (4.6782)	Learning Rate [0.00125]
12: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00096)	Tok/s 33114 (53957)	Loss/tok 3.4505 (4.6809)	Learning Rate [0.00125]
11: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00092)	Tok/s 33114 (53852)	Loss/tok 3.0561 (4.6808)	Learning Rate [0.00125]
10: TRAIN [0][2040/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00097)	Tok/s 33131 (53779)	Loss/tok 3.3576 (4.6779)	Learning Rate [0.00125]
5: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
6: Gradient norm: inf
3: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
15: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
2: TRAIN [0][2050/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00100)	Tok/s 51578 (53169)	Loss/tok 3.6209 (4.6720)	Learning Rate [0.00125]
3: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00086 (0.00094)	Tok/s 51238 (53271)	Loss/tok 3.8689 (4.6743)	Learning Rate [0.00125]
0: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00104 (0.00097)	Tok/s 51411 (52971)	Loss/tok 3.3232 (4.6793)	Learning Rate [0.00125]
4: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00094 (0.00099)	Tok/s 51166 (53357)	Loss/tok 3.6296 (4.6749)	Learning Rate [0.00125]
1: TRAIN [0][2050/3416]	Time 0.053 (0.058)	Data 0.00117 (0.00094)	Tok/s 51795 (53067)	Loss/tok 3.6956 (4.6722)	Learning Rate [0.00125]
15: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00092)	Tok/s 52444 (54291)	Loss/tok 3.5580 (4.6710)	Learning Rate [0.00125]
5: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00095)	Tok/s 51036 (53443)	Loss/tok 3.5505 (4.6725)	Learning Rate [0.00125]
6: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00082 (0.00093)	Tok/s 52154 (53515)	Loss/tok 3.7757 (4.6709)	Learning Rate [0.00125]
14: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00096)	Tok/s 52518 (54177)	Loss/tok 3.4860 (4.6779)	Learning Rate [0.00125]
13: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00103 (0.00095)	Tok/s 52534 (54076)	Loss/tok 3.5723 (4.6726)	Learning Rate [0.00125]
12: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00096)	Tok/s 52445 (53987)	Loss/tok 3.3365 (4.6749)	Learning Rate [0.00125]
8: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00092)	Tok/s 52176 (53673)	Loss/tok 3.3997 (4.6648)	Learning Rate [0.00125]
11: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00092)	Tok/s 52356 (53881)	Loss/tok 3.3603 (4.6750)	Learning Rate [0.00125]
7: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00096)	Tok/s 52219 (53594)	Loss/tok 3.3904 (4.6708)	Learning Rate [0.00125]
9: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00093)	Tok/s 52226 (53735)	Loss/tok 3.7509 (4.6727)	Learning Rate [0.00125]
10: TRAIN [0][2050/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00097)	Tok/s 52172 (53809)	Loss/tok 3.6858 (4.6725)	Learning Rate [0.00125]
14: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00096)	Tok/s 52911 (54150)	Loss/tok 3.7509 (4.6737)	Learning Rate [0.00125]
15: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00092)	Tok/s 53513 (54265)	Loss/tok 3.6340 (4.6665)	Learning Rate [0.00125]
13: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00095)	Tok/s 52570 (54049)	Loss/tok 3.8578 (4.6682)	Learning Rate [0.00125]
0: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00097)	Tok/s 52425 (52946)	Loss/tok 3.6809 (4.6748)	Learning Rate [0.00125]
12: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00113 (0.00096)	Tok/s 52577 (53961)	Loss/tok 3.8423 (4.6709)	Learning Rate [0.00125]
1: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00094)	Tok/s 52424 (53042)	Loss/tok 3.5426 (4.6677)	Learning Rate [0.00125]
10: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00097)	Tok/s 52641 (53782)	Loss/tok 3.8754 (4.6682)	Learning Rate [0.00125]
11: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00092)	Tok/s 52550 (53855)	Loss/tok 3.5639 (4.6707)	Learning Rate [0.00125]
2: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00100)	Tok/s 52382 (53143)	Loss/tok 3.3935 (4.6674)	Learning Rate [0.00125]
9: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00093)	Tok/s 52519 (53709)	Loss/tok 3.5546 (4.6682)	Learning Rate [0.00125]
3: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00094)	Tok/s 52385 (53245)	Loss/tok 3.5301 (4.6701)	Learning Rate [0.00125]
8: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00092)	Tok/s 52500 (53647)	Loss/tok 3.8767 (4.6607)	Learning Rate [0.00125]
4: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00099)	Tok/s 52406 (53330)	Loss/tok 3.5901 (4.6706)	Learning Rate [0.00125]
7: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00096)	Tok/s 52392 (53568)	Loss/tok 3.5851 (4.6661)	Learning Rate [0.00125]
5: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00095)	Tok/s 52453 (53417)	Loss/tok 3.7803 (4.6683)	Learning Rate [0.00125]
6: TRAIN [0][2060/3416]	Time 0.062 (0.058)	Data 0.00085 (0.00093)	Tok/s 52318 (53489)	Loss/tok 3.4623 (4.6661)	Learning Rate [0.00125]
3: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00094)	Tok/s 50058 (53254)	Loss/tok 3.4052 (4.6656)	Learning Rate [0.00125]
2: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00100)	Tok/s 50115 (53153)	Loss/tok 3.4950 (4.6622)	Learning Rate [0.00125]
4: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00099)	Tok/s 50075 (53339)	Loss/tok 3.1805 (4.6657)	Learning Rate [0.00125]
1: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00094)	Tok/s 50132 (53052)	Loss/tok 3.6936 (4.6629)	Learning Rate [0.00125]
0: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00097)	Tok/s 50118 (52956)	Loss/tok 3.3809 (4.6698)	Learning Rate [0.00125]
5: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00113 (0.00095)	Tok/s 50124 (53426)	Loss/tok 3.4275 (4.6628)	Learning Rate [0.00125]
6: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00093)	Tok/s 50137 (53497)	Loss/tok 3.5472 (4.6610)	Learning Rate [0.00125]
15: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00092)	Tok/s 50184 (54273)	Loss/tok 3.8616 (4.6615)	Learning Rate [0.00125]
8: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00093)	Tok/s 50141 (53655)	Loss/tok 3.4907 (4.6555)	Learning Rate [0.00125]
14: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00096)	Tok/s 50144 (54159)	Loss/tok 3.4185 (4.6686)	Learning Rate [0.00125]
13: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00095)	Tok/s 50147 (54058)	Loss/tok 3.6156 (4.6628)	Learning Rate [0.00125]
9: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00093)	Tok/s 50150 (53717)	Loss/tok 3.6691 (4.6631)	Learning Rate [0.00125]
7: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00081 (0.00096)	Tok/s 50158 (53576)	Loss/tok 3.9019 (4.6611)	Learning Rate [0.00125]
12: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00096)	Tok/s 50145 (53970)	Loss/tok 3.7346 (4.6659)	Learning Rate [0.00125]
11: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00092)	Tok/s 50148 (53864)	Loss/tok 3.4934 (4.6657)	Learning Rate [0.00125]
10: TRAIN [0][2070/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00097)	Tok/s 50117 (53791)	Loss/tok 3.5143 (4.6628)	Learning Rate [0.00125]
11: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00092)	Tok/s 53918 (53875)	Loss/tok 3.4810 (4.6606)	Learning Rate [0.00125]
10: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00097)	Tok/s 53941 (53802)	Loss/tok 3.6982 (4.6580)	Learning Rate [0.00125]
9: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00093)	Tok/s 53894 (53729)	Loss/tok 3.6464 (4.6579)	Learning Rate [0.00125]
8: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00093)	Tok/s 53918 (53666)	Loss/tok 3.8275 (4.6506)	Learning Rate [0.00125]
13: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00095)	Tok/s 53730 (54068)	Loss/tok 3.9939 (4.6579)	Learning Rate [0.00125]
12: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00107 (0.00096)	Tok/s 53854 (53980)	Loss/tok 3.4680 (4.6608)	Learning Rate [0.00125]
14: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00096)	Tok/s 53716 (54170)	Loss/tok 3.9653 (4.6637)	Learning Rate [0.00125]
7: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00096)	Tok/s 53907 (53587)	Loss/tok 3.7515 (4.6562)	Learning Rate [0.00125]
6: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00093)	Tok/s 53842 (53508)	Loss/tok 3.6473 (4.6559)	Learning Rate [0.00125]
15: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00092)	Tok/s 53685 (54284)	Loss/tok 3.4850 (4.6566)	Learning Rate [0.00125]
0: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00097)	Tok/s 53687 (52967)	Loss/tok 3.5747 (4.6643)	Learning Rate [0.00125]
5: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00095)	Tok/s 53822 (53437)	Loss/tok 3.5601 (4.6579)	Learning Rate [0.00125]
1: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00094)	Tok/s 53681 (53063)	Loss/tok 3.8485 (4.6580)	Learning Rate [0.00125]
3: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00081 (0.00093)	Tok/s 53600 (53266)	Loss/tok 3.6733 (4.6602)	Learning Rate [0.00125]
2: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00100)	Tok/s 53556 (53164)	Loss/tok 3.4410 (4.6572)	Learning Rate [0.00125]
4: TRAIN [0][2080/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00099)	Tok/s 53662 (53351)	Loss/tok 3.5713 (4.6606)	Learning Rate [0.00125]
1: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00105 (0.00094)	Tok/s 56314 (53068)	Loss/tok 3.7658 (4.6533)	Learning Rate [0.00125]
0: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00107 (0.00097)	Tok/s 56268 (52972)	Loss/tok 4.0359 (4.6598)	Learning Rate [0.00125]
2: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00115 (0.00100)	Tok/s 56237 (53169)	Loss/tok 3.9879 (4.6529)	Learning Rate [0.00125]
4: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00099 (0.00099)	Tok/s 56046 (53355)	Loss/tok 3.7400 (4.6563)	Learning Rate [0.00125]
15: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00092)	Tok/s 57161 (54287)	Loss/tok 3.7822 (4.6523)	Learning Rate [0.00125]
5: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00111 (0.00095)	Tok/s 55963 (53441)	Loss/tok 3.8188 (4.6537)	Learning Rate [0.00125]
14: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00096)	Tok/s 57050 (54173)	Loss/tok 3.7148 (4.6587)	Learning Rate [0.00125]
6: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00093)	Tok/s 55923 (53511)	Loss/tok 3.7353 (4.6513)	Learning Rate [0.00125]
3: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00093)	Tok/s 56151 (53270)	Loss/tok 4.0001 (4.6553)	Learning Rate [0.00125]
13: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00095)	Tok/s 56997 (54071)	Loss/tok 3.7825 (4.6533)	Learning Rate [0.00125]
12: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00102 (0.00096)	Tok/s 56924 (53983)	Loss/tok 3.4006 (4.6558)	Learning Rate [0.00125]
8: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00093)	Tok/s 55775 (53670)	Loss/tok 3.5924 (4.6462)	Learning Rate [0.00125]
11: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00092)	Tok/s 56818 (53878)	Loss/tok 3.8153 (4.6561)	Learning Rate [0.00125]
9: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00093)	Tok/s 55709 (53732)	Loss/tok 3.9440 (4.6535)	Learning Rate [0.00125]
7: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00096)	Tok/s 55817 (53590)	Loss/tok 3.8223 (4.6516)	Learning Rate [0.00125]
10: TRAIN [0][2090/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00097)	Tok/s 56008 (53805)	Loss/tok 3.7765 (4.6534)	Learning Rate [0.00125]
2: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00100)	Tok/s 64995 (53164)	Loss/tok 3.5580 (4.6482)	Learning Rate [0.00125]
1: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00094)	Tok/s 64976 (53063)	Loss/tok 3.9342 (4.6489)	Learning Rate [0.00125]
3: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00093)	Tok/s 64961 (53265)	Loss/tok 3.7540 (4.6506)	Learning Rate [0.00125]
0: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 64966 (52968)	Loss/tok 3.8145 (4.6552)	Learning Rate [0.00125]
15: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 65876 (54281)	Loss/tok 3.9418 (4.6479)	Learning Rate [0.00125]
4: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00099)	Tok/s 64852 (53349)	Loss/tok 3.7592 (4.6516)	Learning Rate [0.00125]
5: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00095)	Tok/s 64868 (53435)	Loss/tok 4.0237 (4.6490)	Learning Rate [0.00125]
14: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 65842 (54168)	Loss/tok 3.6683 (4.6538)	Learning Rate [0.00125]
12: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00096)	Tok/s 65632 (53977)	Loss/tok 3.7177 (4.6508)	Learning Rate [0.00125]
13: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00095)	Tok/s 65752 (54066)	Loss/tok 3.5877 (4.6487)	Learning Rate [0.00125]
9: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 64513 (53726)	Loss/tok 3.9664 (4.6490)	Learning Rate [0.00125]
6: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00078 (0.00094)	Tok/s 64777 (53505)	Loss/tok 3.7494 (4.6462)	Learning Rate [0.00125]
11: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00092)	Tok/s 65392 (53872)	Loss/tok 3.6604 (4.6513)	Learning Rate [0.00125]
7: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00096)	Tok/s 64688 (53584)	Loss/tok 3.8667 (4.6470)	Learning Rate [0.00125]
8: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 64582 (53664)	Loss/tok 3.8301 (4.6416)	Learning Rate [0.00125]
10: TRAIN [0][2100/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 64529 (53799)	Loss/tok 4.0362 (4.6490)	Learning Rate [0.00125]
15: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00092)	Tok/s 55565 (54260)	Loss/tok 3.8557 (4.6434)	Learning Rate [0.00125]
14: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00096)	Tok/s 55495 (54147)	Loss/tok 3.6804 (4.6494)	Learning Rate [0.00125]
0: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00099 (0.00097)	Tok/s 54544 (52940)	Loss/tok 3.8433 (4.6508)	Learning Rate [0.00125]
1: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00099 (0.00094)	Tok/s 54506 (53036)	Loss/tok 3.4632 (4.6444)	Learning Rate [0.00125]
13: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00096)	Tok/s 55348 (54044)	Loss/tok 3.5366 (4.6439)	Learning Rate [0.00125]
11: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00092)	Tok/s 55265 (53851)	Loss/tok 3.6655 (4.6469)	Learning Rate [0.00125]
2: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00100)	Tok/s 54425 (53137)	Loss/tok 3.5956 (4.6440)	Learning Rate [0.00125]
4: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00099)	Tok/s 54309 (53324)	Loss/tok 3.4985 (4.6471)	Learning Rate [0.00125]
12: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00096)	Tok/s 55254 (53956)	Loss/tok 3.8374 (4.6463)	Learning Rate [0.00125]
3: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00093)	Tok/s 54339 (53239)	Loss/tok 3.9489 (4.6462)	Learning Rate [0.00125]
9: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00093)	Tok/s 55004 (53704)	Loss/tok 3.6272 (4.6442)	Learning Rate [0.00125]
10: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00097)	Tok/s 55085 (53777)	Loss/tok 3.8212 (4.6443)	Learning Rate [0.00125]
8: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00093)	Tok/s 54936 (53641)	Loss/tok 3.5244 (4.6368)	Learning Rate [0.00125]
6: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00094)	Tok/s 54640 (53481)	Loss/tok 3.6127 (4.6417)	Learning Rate [0.00125]
7: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00096)	Tok/s 55043 (53560)	Loss/tok 3.3860 (4.6424)	Learning Rate [0.00125]
5: TRAIN [0][2110/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00095)	Tok/s 54119 (53410)	Loss/tok 4.0021 (4.6448)	Learning Rate [0.00125]
7: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00077 (0.00096)	Tok/s 56672 (53560)	Loss/tok 3.8745 (4.6377)	Learning Rate [0.00125]
8: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00093)	Tok/s 56706 (53640)	Loss/tok 3.8188 (4.6321)	Learning Rate [0.00125]
6: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00094)	Tok/s 56529 (53480)	Loss/tok 3.7361 (4.6368)	Learning Rate [0.00125]
9: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00093)	Tok/s 56700 (53702)	Loss/tok 3.6394 (4.6394)	Learning Rate [0.00125]
0: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00097)	Tok/s 56285 (52940)	Loss/tok 3.6526 (4.6461)	Learning Rate [0.00125]
4: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00099)	Tok/s 56377 (53323)	Loss/tok 3.6411 (4.6424)	Learning Rate [0.00125]
1: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00094)	Tok/s 56303 (53036)	Loss/tok 3.6485 (4.6398)	Learning Rate [0.00125]
5: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00095)	Tok/s 56436 (53409)	Loss/tok 3.6330 (4.6402)	Learning Rate [0.00125]
10: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00097)	Tok/s 56586 (53776)	Loss/tok 3.5849 (4.6395)	Learning Rate [0.00125]
15: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00092)	Tok/s 56435 (54259)	Loss/tok 3.4478 (4.6386)	Learning Rate [0.00125]
11: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00092)	Tok/s 56531 (53849)	Loss/tok 3.3327 (4.6418)	Learning Rate [0.00125]
2: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00082 (0.00100)	Tok/s 56254 (53137)	Loss/tok 4.0567 (4.6392)	Learning Rate [0.00125]
3: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00093)	Tok/s 56243 (53239)	Loss/tok 3.6492 (4.6415)	Learning Rate [0.00125]
14: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00096)	Tok/s 56418 (54145)	Loss/tok 3.4157 (4.6449)	Learning Rate [0.00125]
13: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00096)	Tok/s 56425 (54044)	Loss/tok 3.6978 (4.6394)	Learning Rate [0.00125]
12: TRAIN [0][2120/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00096)	Tok/s 56480 (53954)	Loss/tok 3.6323 (4.6419)	Learning Rate [0.00125]
5: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00095)	Tok/s 72662 (53414)	Loss/tok 3.6638 (4.6356)	Learning Rate [0.00125]
4: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 72573 (53328)	Loss/tok 3.6010 (4.6377)	Learning Rate [0.00125]
6: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00094)	Tok/s 72641 (53484)	Loss/tok 3.6689 (4.6322)	Learning Rate [0.00125]
3: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 72494 (53243)	Loss/tok 3.5365 (4.6367)	Learning Rate [0.00125]
7: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00096)	Tok/s 72654 (53564)	Loss/tok 3.6981 (4.6332)	Learning Rate [0.00125]
2: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 71759 (53142)	Loss/tok 3.7027 (4.6345)	Learning Rate [0.00125]
8: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 72620 (53644)	Loss/tok 3.9123 (4.6277)	Learning Rate [0.00125]
1: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00094)	Tok/s 71591 (53041)	Loss/tok 3.8433 (4.6351)	Learning Rate [0.00125]
9: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 72626 (53706)	Loss/tok 3.8220 (4.6349)	Learning Rate [0.00125]
10: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00096)	Tok/s 72516 (53780)	Loss/tok 3.7568 (4.6347)	Learning Rate [0.00125]
11: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 72543 (53852)	Loss/tok 3.8839 (4.6375)	Learning Rate [0.00125]
15: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 73452 (54264)	Loss/tok 3.8662 (4.6346)	Learning Rate [0.00125]
0: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00097)	Tok/s 71636 (52945)	Loss/tok 3.8247 (4.6414)	Learning Rate [0.00125]
14: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 73401 (54150)	Loss/tok 3.7076 (4.6404)	Learning Rate [0.00125]
13: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 73026 (54047)	Loss/tok 3.6380 (4.6345)	Learning Rate [0.00125]
12: TRAIN [0][2130/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 72477 (53957)	Loss/tok 3.7458 (4.6372)	Learning Rate [0.00125]
10: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00112 (0.00096)	Tok/s 60818 (53780)	Loss/tok 3.9535 (4.6299)	Learning Rate [0.00125]
8: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00090 (0.00093)	Tok/s 60742 (53644)	Loss/tok 3.8236 (4.6228)	Learning Rate [0.00125]
11: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00093 (0.00092)	Tok/s 60641 (53853)	Loss/tok 3.6520 (4.6324)	Learning Rate [0.00125]
9: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00093 (0.00093)	Tok/s 60718 (53706)	Loss/tok 3.6000 (4.6301)	Learning Rate [0.00125]
7: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00085 (0.00096)	Tok/s 60673 (53564)	Loss/tok 3.6701 (4.6281)	Learning Rate [0.00125]
12: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00115 (0.00096)	Tok/s 60546 (53958)	Loss/tok 3.8915 (4.6324)	Learning Rate [0.00125]
13: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00085 (0.00096)	Tok/s 60437 (54047)	Loss/tok 3.6371 (4.6295)	Learning Rate [0.00125]
6: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00114 (0.00094)	Tok/s 60508 (53484)	Loss/tok 3.9580 (4.6275)	Learning Rate [0.00125]
14: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00083 (0.00096)	Tok/s 60539 (54150)	Loss/tok 3.9742 (4.6355)	Learning Rate [0.00125]
5: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00093 (0.00095)	Tok/s 60456 (53414)	Loss/tok 3.7103 (4.6303)	Learning Rate [0.00125]
15: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00083 (0.00092)	Tok/s 61120 (54264)	Loss/tok 3.9176 (4.6298)	Learning Rate [0.00125]
0: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00084 (0.00097)	Tok/s 60196 (52946)	Loss/tok 3.7554 (4.6371)	Learning Rate [0.00125]
4: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00096 (0.00099)	Tok/s 60375 (53328)	Loss/tok 3.8111 (4.6328)	Learning Rate [0.00125]
1: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00098 (0.00094)	Tok/s 60169 (53042)	Loss/tok 3.7983 (4.6303)	Learning Rate [0.00125]
3: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00104 (0.00093)	Tok/s 60270 (53244)	Loss/tok 3.5325 (4.6314)	Learning Rate [0.00125]
2: TRAIN [0][2140/3416]	Time 0.072 (0.058)	Data 0.00096 (0.00100)	Tok/s 60224 (53142)	Loss/tok 3.8276 (4.6297)	Learning Rate [0.00125]
6: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00093)	Tok/s 32799 (53487)	Loss/tok 2.9757 (4.6229)	Learning Rate [0.00125]
5: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00083 (0.00095)	Tok/s 32852 (53416)	Loss/tok 2.9804 (4.6258)	Learning Rate [0.00125]
4: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00099)	Tok/s 32767 (53331)	Loss/tok 2.9652 (4.6281)	Learning Rate [0.00125]
3: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00093)	Tok/s 32785 (53247)	Loss/tok 3.0068 (4.6269)	Learning Rate [0.00125]
7: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00096)	Tok/s 32659 (53567)	Loss/tok 3.1571 (4.6238)	Learning Rate [0.00125]
2: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00100)	Tok/s 32678 (53145)	Loss/tok 3.6617 (4.6250)	Learning Rate [0.00125]
9: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00093)	Tok/s 32773 (53708)	Loss/tok 3.0965 (4.6254)	Learning Rate [0.00125]
1: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00094)	Tok/s 32618 (53045)	Loss/tok 3.3309 (4.6261)	Learning Rate [0.00125]
8: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00093)	Tok/s 32573 (53647)	Loss/tok 3.2623 (4.6182)	Learning Rate [0.00125]
0: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00097)	Tok/s 32538 (52950)	Loss/tok 3.2243 (4.6324)	Learning Rate [0.00125]
15: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00092)	Tok/s 33832 (54266)	Loss/tok 2.9664 (4.6255)	Learning Rate [0.00125]
11: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00082 (0.00092)	Tok/s 33716 (53855)	Loss/tok 3.2577 (4.6279)	Learning Rate [0.00125]
14: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00096)	Tok/s 33783 (54152)	Loss/tok 3.3997 (4.6306)	Learning Rate [0.00125]
10: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00097)	Tok/s 33781 (53782)	Loss/tok 3.2218 (4.6251)	Learning Rate [0.00125]
12: TRAIN [0][2150/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00096)	Tok/s 33629 (53960)	Loss/tok 3.2644 (4.6281)	Learning Rate [0.00125]
13: TRAIN [0][2150/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00096)	Tok/s 33711 (54050)	Loss/tok 2.9854 (4.6248)	Learning Rate [0.00125]
9: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00093)	Tok/s 45132 (53673)	Loss/tok 3.3955 (4.6214)	Learning Rate [0.00125]
5: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00095)	Tok/s 45410 (53380)	Loss/tok 3.3511 (4.6221)	Learning Rate [0.00125]
4: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00099)	Tok/s 45392 (53294)	Loss/tok 3.3866 (4.6242)	Learning Rate [0.00125]
8: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00093)	Tok/s 45181 (53611)	Loss/tok 3.1269 (4.6143)	Learning Rate [0.00125]
6: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00093)	Tok/s 45328 (53450)	Loss/tok 3.4710 (4.6189)	Learning Rate [0.00125]
10: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00097)	Tok/s 45037 (53746)	Loss/tok 3.0963 (4.6212)	Learning Rate [0.00125]
3: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00093)	Tok/s 45327 (53209)	Loss/tok 3.4381 (4.6232)	Learning Rate [0.00125]
7: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00096)	Tok/s 45237 (53531)	Loss/tok 3.4930 (4.6200)	Learning Rate [0.00125]
11: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00092)	Tok/s 44917 (53819)	Loss/tok 3.2573 (4.6240)	Learning Rate [0.00125]
1: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00094)	Tok/s 45031 (53005)	Loss/tok 3.1334 (4.6226)	Learning Rate [0.00125]
2: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00100)	Tok/s 45203 (53107)	Loss/tok 3.4509 (4.6208)	Learning Rate [0.00125]
12: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00105 (0.00096)	Tok/s 44838 (53925)	Loss/tok 3.1576 (4.6241)	Learning Rate [0.00125]
13: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00096)	Tok/s 45667 (54015)	Loss/tok 3.4362 (4.6208)	Learning Rate [0.00125]
0: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00097)	Tok/s 44983 (52909)	Loss/tok 3.4813 (4.6287)	Learning Rate [0.00125]
14: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00096)	Tok/s 46296 (54119)	Loss/tok 3.3769 (4.6264)	Learning Rate [0.00125]
15: TRAIN [0][2160/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00092)	Tok/s 46214 (54233)	Loss/tok 3.2625 (4.6215)	Learning Rate [0.00125]
14: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
1: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00094)	Tok/s 76307 (53028)	Loss/tok 3.7064 (4.6176)	Learning Rate [0.00125]
2: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 76330 (53129)	Loss/tok 3.5411 (4.6159)	Learning Rate [0.00125]
0: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 76114 (52932)	Loss/tok 3.4769 (4.6238)	Learning Rate [0.00125]
3: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 76683 (53231)	Loss/tok 3.7147 (4.6179)	Learning Rate [0.00125]
4: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00099)	Tok/s 77180 (53315)	Loss/tok 3.9045 (4.6196)	Learning Rate [0.00125]
8: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 77234 (53631)	Loss/tok 3.5679 (4.6094)	Learning Rate [0.00125]
7: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00096)	Tok/s 77243 (53551)	Loss/tok 3.8481 (4.6152)	Learning Rate [0.00125]
15: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 77736 (54254)	Loss/tok 3.5280 (4.6158)	Learning Rate [0.00125]
6: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 77173 (53471)	Loss/tok 3.5822 (4.6140)	Learning Rate [0.00125]
9: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 76982 (53693)	Loss/tok 3.7231 (4.6163)	Learning Rate [0.00125]
5: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00095)	Tok/s 77186 (53401)	Loss/tok 3.6398 (4.6172)	Learning Rate [0.00125]
14: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00096)	Tok/s 77629 (54139)	Loss/tok 3.8064 (4.6215)	Learning Rate [0.00125]
10: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 76920 (53766)	Loss/tok 3.5583 (4.6162)	Learning Rate [0.00125]
13: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 77614 (54036)	Loss/tok 3.6298 (4.6154)	Learning Rate [0.00125]
11: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 77016 (53840)	Loss/tok 3.6836 (4.6190)	Learning Rate [0.00125]
12: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00096)	Tok/s 77601 (53945)	Loss/tok 3.8183 (4.6196)	Learning Rate [0.00125]
9: TRAIN [0][2180/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 65452 (53698)	Loss/tok 3.7601 (4.6118)	Learning Rate [0.00125]
6: TRAIN [0][2180/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 65091 (53476)	Loss/tok 3.7114 (4.6095)	Learning Rate [0.00125]
1: TRAIN [0][2180/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00094)	Tok/s 65373 (53033)	Loss/tok 3.7144 (4.6132)	Learning Rate [0.00125]
10: TRAIN [0][2180/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 65366 (53771)	Loss/tok 3.8221 (4.6118)	Learning Rate [0.00125]
11: TRAIN [0][2180/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00092)	Tok/s 65408 (53844)	Loss/tok 3.7790 (4.6145)	Learning Rate [0.00125]
15: TRAIN [0][2180/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 66321 (54259)	Loss/tok 3.7246 (4.6113)	Learning Rate [0.00125]
14: TRAIN [0][2180/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00096)	Tok/s 66373 (54144)	Loss/tok 3.8324 (4.6171)	Learning Rate [0.00125]
7: TRAIN [0][2180/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 65276 (53556)	Loss/tok 3.8278 (4.6106)	Learning Rate [0.00125]
13: TRAIN [0][2180/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00096)	Tok/s 66221 (54040)	Loss/tok 3.7443 (4.6110)	Learning Rate [0.00125]
8: TRAIN [0][2180/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 65303 (53636)	Loss/tok 3.6676 (4.6049)	Learning Rate [0.00125]
12: TRAIN [0][2180/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00097)	Tok/s 65403 (53950)	Loss/tok 3.8360 (4.6149)	Learning Rate [0.00125]
0: TRAIN [0][2180/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 65379 (52937)	Loss/tok 3.7343 (4.6194)	Learning Rate [0.00125]
4: TRAIN [0][2180/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 64996 (53320)	Loss/tok 3.8797 (4.6155)	Learning Rate [0.00125]
5: TRAIN [0][2180/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00095)	Tok/s 64921 (53406)	Loss/tok 3.7383 (4.6124)	Learning Rate [0.00125]
3: TRAIN [0][2180/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00093)	Tok/s 64979 (53235)	Loss/tok 3.8353 (4.6136)	Learning Rate [0.00125]
2: TRAIN [0][2180/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 65173 (53134)	Loss/tok 3.5714 (4.6111)	Learning Rate [0.00125]
4: Gradient norm: inf
3: Gradient norm: inf
5: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
1: Gradient norm: inf
4: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 82534 (53355)	Loss/tok 3.4945 (4.6104)	Learning Rate [0.00125]
0: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
3: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 82522 (53270)	Loss/tok 3.4509 (4.6080)	Learning Rate [0.00125]
5: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00095)	Tok/s 83478 (53441)	Loss/tok 3.4838 (4.6071)	Learning Rate [0.00125]
0: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
6: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 83510 (53511)	Loss/tok 3.5405 (4.6042)	Learning Rate [0.00125]
8: Gradient norm: inf
9: Gradient norm: inf
14: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
1: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00094)	Tok/s 82455 (53067)	Loss/tok 3.6165 (4.6081)	Learning Rate [0.00125]
14: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
7: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00096)	Tok/s 83504 (53590)	Loss/tok 3.5987 (4.6056)	Learning Rate [0.00125]
2: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 82504 (53169)	Loss/tok 3.6226 (4.6061)	Learning Rate [0.00125]
11: Gradient norm: inf
10: Gradient norm: inf
12: Gradient norm: inf
0: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 82461 (52972)	Loss/tok 3.3565 (4.6140)	Learning Rate [0.00125]
13: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
15: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00092)	Tok/s 85229 (54293)	Loss/tok 3.4986 (4.6057)	Learning Rate [0.00125]
9: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 83483 (53732)	Loss/tok 3.4724 (4.6068)	Learning Rate [0.00125]
14: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00096)	Tok/s 84464 (54177)	Loss/tok 3.5187 (4.6117)	Learning Rate [0.00125]
8: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 83349 (53670)	Loss/tok 3.8417 (4.6001)	Learning Rate [0.00125]
13: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00096)	Tok/s 84123 (54074)	Loss/tok 3.6012 (4.6061)	Learning Rate [0.00125]
11: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 84246 (53878)	Loss/tok 3.5217 (4.6094)	Learning Rate [0.00125]
12: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00097)	Tok/s 84200 (53984)	Loss/tok 3.4869 (4.6092)	Learning Rate [0.00125]
10: TRAIN [0][2190/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 84062 (53805)	Loss/tok 3.6034 (4.6066)	Learning Rate [0.00125]
3: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00093)	Tok/s 48719 (53247)	Loss/tok 3.4747 (4.6038)	Learning Rate [0.00125]
5: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00095)	Tok/s 48744 (53418)	Loss/tok 3.4685 (4.6032)	Learning Rate [0.00125]
6: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00093)	Tok/s 49882 (53488)	Loss/tok 3.5868 (4.6002)	Learning Rate [0.00125]
4: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00099)	Tok/s 48626 (53332)	Loss/tok 3.2113 (4.6063)	Learning Rate [0.00125]
2: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00100)	Tok/s 48711 (53146)	Loss/tok 3.6009 (4.6024)	Learning Rate [0.00125]
1: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00094)	Tok/s 48618 (53044)	Loss/tok 3.2614 (4.6041)	Learning Rate [0.00125]
7: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00096)	Tok/s 49829 (53567)	Loss/tok 3.5835 (4.6014)	Learning Rate [0.00125]
0: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00097)	Tok/s 48717 (52949)	Loss/tok 3.6219 (4.6100)	Learning Rate [0.00125]
8: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00093)	Tok/s 49858 (53647)	Loss/tok 3.5714 (4.5961)	Learning Rate [0.00125]
9: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00092)	Tok/s 49861 (53708)	Loss/tok 3.3578 (4.6029)	Learning Rate [0.00125]
15: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00092)	Tok/s 50006 (54269)	Loss/tok 3.4530 (4.6018)	Learning Rate [0.00125]
14: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00096)	Tok/s 50089 (54153)	Loss/tok 3.4671 (4.6081)	Learning Rate [0.00125]
13: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00096)	Tok/s 50000 (54050)	Loss/tok 3.3552 (4.6021)	Learning Rate [0.00125]
11: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00092)	Tok/s 49781 (53855)	Loss/tok 3.5462 (4.6054)	Learning Rate [0.00125]
12: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00097)	Tok/s 49991 (53960)	Loss/tok 3.6551 (4.6057)	Learning Rate [0.00125]
10: TRAIN [0][2200/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00097)	Tok/s 49882 (53782)	Loss/tok 3.3254 (4.6028)	Learning Rate [0.00125]
1: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00094)	Tok/s 53470 (53042)	Loss/tok 3.5988 (4.5998)	Learning Rate [0.00125]
2: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00100)	Tok/s 53457 (53143)	Loss/tok 3.8061 (4.5981)	Learning Rate [0.00125]
3: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00093)	Tok/s 53529 (53244)	Loss/tok 3.7054 (4.5994)	Learning Rate [0.00125]
0: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00106 (0.00097)	Tok/s 53301 (52947)	Loss/tok 3.6638 (4.6057)	Learning Rate [0.00125]
4: TRAIN [0][2210/3416]	Time 0.058 (0.058)	Data 0.00107 (0.00099)	Tok/s 53853 (53329)	Loss/tok 3.4538 (4.6018)	Learning Rate [0.00125]
15: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00092)	Tok/s 54303 (54264)	Loss/tok 3.5664 (4.5977)	Learning Rate [0.00125]
6: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00093)	Tok/s 53459 (53485)	Loss/tok 3.8442 (4.5962)	Learning Rate [0.00125]
5: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00095)	Tok/s 53490 (53415)	Loss/tok 3.4704 (4.5990)	Learning Rate [0.00125]
14: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00096)	Tok/s 54188 (54149)	Loss/tok 3.3963 (4.6041)	Learning Rate [0.00125]
11: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00092)	Tok/s 53124 (53850)	Loss/tok 3.5212 (4.6008)	Learning Rate [0.00125]
13: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00114 (0.00096)	Tok/s 54171 (54046)	Loss/tok 3.7641 (4.5976)	Learning Rate [0.00125]
9: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00092)	Tok/s 53173 (53704)	Loss/tok 3.5347 (4.5984)	Learning Rate [0.00125]
7: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00106 (0.00096)	Tok/s 53328 (53564)	Loss/tok 3.4917 (4.5969)	Learning Rate [0.00125]
12: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00108 (0.00097)	Tok/s 53319 (53956)	Loss/tok 3.5293 (4.6016)	Learning Rate [0.00125]
8: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00093)	Tok/s 53241 (53643)	Loss/tok 3.9359 (4.5918)	Learning Rate [0.00125]
10: TRAIN [0][2210/3416]	Time 0.059 (0.058)	Data 0.00110 (0.00096)	Tok/s 53101 (53778)	Loss/tok 3.6941 (4.5986)	Learning Rate [0.00125]
6: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00093)	Tok/s 53756 (53457)	Loss/tok 3.7038 (4.5922)	Learning Rate [0.00125]
5: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00095)	Tok/s 53679 (53387)	Loss/tok 3.8196 (4.5953)	Learning Rate [0.00125]
7: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00096)	Tok/s 53812 (53536)	Loss/tok 3.4033 (4.5930)	Learning Rate [0.00125]
4: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00099)	Tok/s 53737 (53300)	Loss/tok 3.6823 (4.5976)	Learning Rate [0.00125]
8: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00082 (0.00093)	Tok/s 53777 (53616)	Loss/tok 3.5156 (4.5878)	Learning Rate [0.00125]
9: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00092)	Tok/s 53761 (53677)	Loss/tok 3.7020 (4.5944)	Learning Rate [0.00125]
3: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00093)	Tok/s 53669 (53215)	Loss/tok 3.6752 (4.5955)	Learning Rate [0.00125]
2: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00100)	Tok/s 53749 (53114)	Loss/tok 3.6286 (4.5942)	Learning Rate [0.00125]
1: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00094)	Tok/s 53739 (53013)	Loss/tok 3.6472 (4.5957)	Learning Rate [0.00125]
11: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00092)	Tok/s 53799 (53823)	Loss/tok 3.4406 (4.5966)	Learning Rate [0.00125]
10: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00096)	Tok/s 53807 (53750)	Loss/tok 3.6551 (4.5947)	Learning Rate [0.00125]
0: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00097)	Tok/s 53652 (52918)	Loss/tok 4.0039 (4.6020)	Learning Rate [0.00125]
12: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00097)	Tok/s 53707 (53928)	Loss/tok 3.7656 (4.5978)	Learning Rate [0.00125]
15: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00092)	Tok/s 53657 (54236)	Loss/tok 3.5065 (4.5939)	Learning Rate [0.00125]
14: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00096)	Tok/s 53614 (54121)	Loss/tok 3.8566 (4.6000)	Learning Rate [0.00125]
13: TRAIN [0][2220/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00096)	Tok/s 53547 (54019)	Loss/tok 3.6425 (4.5939)	Learning Rate [0.00125]
3: TRAIN [0][2230/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 62699 (53222)	Loss/tok 3.8451 (4.5914)	Learning Rate [0.00125]
7: TRAIN [0][2230/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 62485 (53543)	Loss/tok 3.6870 (4.5889)	Learning Rate [0.00125]
6: TRAIN [0][2230/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 62569 (53464)	Loss/tok 3.7405 (4.5881)	Learning Rate [0.00125]
8: TRAIN [0][2230/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 62398 (53622)	Loss/tok 3.7298 (4.5838)	Learning Rate [0.00125]
1: TRAIN [0][2230/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00094)	Tok/s 62702 (53021)	Loss/tok 3.7416 (4.5915)	Learning Rate [0.00125]
5: TRAIN [0][2230/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00095)	Tok/s 62540 (53394)	Loss/tok 3.7335 (4.5913)	Learning Rate [0.00125]
2: TRAIN [0][2230/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 62663 (53122)	Loss/tok 3.8804 (4.5898)	Learning Rate [0.00125]
9: TRAIN [0][2230/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 62401 (53683)	Loss/tok 3.8211 (4.5901)	Learning Rate [0.00125]
4: TRAIN [0][2230/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 62651 (53307)	Loss/tok 3.9023 (4.5938)	Learning Rate [0.00125]
0: TRAIN [0][2230/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 62657 (52927)	Loss/tok 3.7584 (4.5978)	Learning Rate [0.00125]
11: TRAIN [0][2230/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 62407 (53829)	Loss/tok 3.8875 (4.5926)	Learning Rate [0.00125]
13: TRAIN [0][2230/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00096)	Tok/s 62440 (54024)	Loss/tok 3.8107 (4.5900)	Learning Rate [0.00125]
15: TRAIN [0][2230/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 63196 (54241)	Loss/tok 3.5191 (4.5896)	Learning Rate [0.00125]
10: TRAIN [0][2230/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00096)	Tok/s 62297 (53756)	Loss/tok 4.0318 (4.5907)	Learning Rate [0.00125]
12: TRAIN [0][2230/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00097)	Tok/s 62369 (53933)	Loss/tok 3.8039 (4.5935)	Learning Rate [0.00125]
14: TRAIN [0][2230/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 62439 (54127)	Loss/tok 3.4726 (4.5951)	Learning Rate [0.00125]
12: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 88143 (53947)	Loss/tok 3.3992 (4.5885)	Learning Rate [0.00125]
13: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00096)	Tok/s 88937 (54037)	Loss/tok 3.3260 (4.5852)	Learning Rate [0.00125]
11: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 87880 (53842)	Loss/tok 3.4251 (4.5877)	Learning Rate [0.00125]
14: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 89351 (54140)	Loss/tok 3.4967 (4.5904)	Learning Rate [0.00125]
15: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 90307 (54254)	Loss/tok 3.3028 (4.5847)	Learning Rate [0.00125]
0: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 85405 (52941)	Loss/tok 3.6487 (4.5934)	Learning Rate [0.00125]
9: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 86664 (53697)	Loss/tok 3.4554 (4.5854)	Learning Rate [0.00125]
10: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00096)	Tok/s 87433 (53770)	Loss/tok 3.5167 (4.5857)	Learning Rate [0.00125]
1: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00094)	Tok/s 85268 (53036)	Loss/tok 3.5373 (4.5869)	Learning Rate [0.00125]
8: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00093)	Tok/s 86658 (53636)	Loss/tok 3.5673 (4.5791)	Learning Rate [0.00125]
2: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 85138 (53137)	Loss/tok 3.6732 (4.5852)	Learning Rate [0.00125]
3: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 85353 (53237)	Loss/tok 3.5387 (4.5870)	Learning Rate [0.00125]
6: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 85755 (53478)	Loss/tok 3.5898 (4.5835)	Learning Rate [0.00125]
7: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 86331 (53557)	Loss/tok 3.4932 (4.5841)	Learning Rate [0.00125]
4: TRAIN [0][2240/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00099)	Tok/s 85830 (53322)	Loss/tok 3.4372 (4.5889)	Learning Rate [0.00125]
5: TRAIN [0][2240/3416]	Time 0.071 (0.058)	Data 0.00085 (0.00095)	Tok/s 84459 (53408)	Loss/tok 3.6479 (4.5866)	Learning Rate [0.00125]
6: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 59496 (53475)	Loss/tok 3.7037 (4.5791)	Learning Rate [0.00125]
5: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00095)	Tok/s 59456 (53404)	Loss/tok 3.9597 (4.5821)	Learning Rate [0.00125]
7: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 59517 (53554)	Loss/tok 3.8147 (4.5797)	Learning Rate [0.00125]
4: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00099)	Tok/s 59412 (53318)	Loss/tok 3.7404 (4.5847)	Learning Rate [0.00125]
8: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 59464 (53633)	Loss/tok 3.3146 (4.5747)	Learning Rate [0.00125]
3: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 59270 (53234)	Loss/tok 3.9293 (4.5828)	Learning Rate [0.00125]
2: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 59194 (53133)	Loss/tok 3.7541 (4.5808)	Learning Rate [0.00125]
1: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00094)	Tok/s 59038 (53032)	Loss/tok 3.9094 (4.5833)	Learning Rate [0.00125]
10: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 59325 (53767)	Loss/tok 3.8588 (4.5814)	Learning Rate [0.00125]
9: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 59379 (53694)	Loss/tok 3.8520 (4.5813)	Learning Rate [0.00125]
11: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 59136 (53839)	Loss/tok 3.6925 (4.5834)	Learning Rate [0.00125]
0: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 58977 (52938)	Loss/tok 3.8597 (4.5888)	Learning Rate [0.00125]
15: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 59894 (54251)	Loss/tok 4.1315 (4.5805)	Learning Rate [0.00125]
12: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 59098 (53943)	Loss/tok 3.7648 (4.5843)	Learning Rate [0.00125]
14: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 59881 (54137)	Loss/tok 3.8063 (4.5862)	Learning Rate [0.00125]
13: TRAIN [0][2250/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00096)	Tok/s 59026 (54034)	Loss/tok 3.7419 (4.5807)	Learning Rate [0.00125]
2: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00100)	Tok/s 78653 (53147)	Loss/tok 3.4866 (4.5759)	Learning Rate [0.00125]
1: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00094)	Tok/s 77704 (53047)	Loss/tok 3.5413 (4.5790)	Learning Rate [0.00125]
3: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 78696 (53247)	Loss/tok 3.8168 (4.5783)	Learning Rate [0.00125]
0: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00097)	Tok/s 77649 (52952)	Loss/tok 3.6122 (4.5843)	Learning Rate [0.00125]
4: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00099)	Tok/s 78699 (53332)	Loss/tok 3.6009 (4.5804)	Learning Rate [0.00125]
7: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 78867 (53567)	Loss/tok 3.6864 (4.5752)	Learning Rate [0.00125]
11: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 79684 (53853)	Loss/tok 3.5394 (4.5789)	Learning Rate [0.00125]
15: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 79490 (54264)	Loss/tok 3.4116 (4.5758)	Learning Rate [0.00125]
8: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00118 (0.00093)	Tok/s 78882 (53647)	Loss/tok 3.9301 (4.5707)	Learning Rate [0.00125]
6: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00093)	Tok/s 78703 (53488)	Loss/tok 3.8180 (4.5745)	Learning Rate [0.00125]
9: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 78922 (53707)	Loss/tok 3.6411 (4.5769)	Learning Rate [0.00125]
14: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00096)	Tok/s 79524 (54150)	Loss/tok 3.8271 (4.5822)	Learning Rate [0.00125]
10: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 79653 (53780)	Loss/tok 3.7908 (4.5770)	Learning Rate [0.00125]
13: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00096)	Tok/s 79533 (54047)	Loss/tok 3.5584 (4.5763)	Learning Rate [0.00125]
5: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00117 (0.00095)	Tok/s 78803 (53418)	Loss/tok 3.5094 (4.5778)	Learning Rate [0.00125]
12: TRAIN [0][2260/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00097)	Tok/s 79537 (53957)	Loss/tok 3.4400 (4.5802)	Learning Rate [0.00125]
0: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00097)	Tok/s 54893 (52921)	Loss/tok 3.4391 (4.5805)	Learning Rate [0.00125]
1: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00094)	Tok/s 54854 (53015)	Loss/tok 3.5955 (4.5754)	Learning Rate [0.00125]
15: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00092)	Tok/s 55922 (54231)	Loss/tok 3.6436 (4.5719)	Learning Rate [0.00125]
2: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00100)	Tok/s 54894 (53115)	Loss/tok 3.6118 (4.5722)	Learning Rate [0.00125]
14: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00096)	Tok/s 55915 (54118)	Loss/tok 3.4682 (4.5785)	Learning Rate [0.00125]
3: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00093)	Tok/s 54936 (53215)	Loss/tok 3.7355 (4.5749)	Learning Rate [0.00125]
5: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00095)	Tok/s 54976 (53385)	Loss/tok 4.0052 (4.5744)	Learning Rate [0.00125]
13: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00096)	Tok/s 55914 (54016)	Loss/tok 3.6963 (4.5726)	Learning Rate [0.00125]
4: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00099)	Tok/s 54909 (53299)	Loss/tok 3.7731 (4.5766)	Learning Rate [0.00125]
11: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00092)	Tok/s 55912 (53820)	Loss/tok 3.9142 (4.5758)	Learning Rate [0.00125]
6: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00093)	Tok/s 54967 (53456)	Loss/tok 3.6995 (4.5709)	Learning Rate [0.00125]
12: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00097)	Tok/s 55885 (53925)	Loss/tok 3.6545 (4.5765)	Learning Rate [0.00125]
9: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00112 (0.00092)	Tok/s 54930 (53674)	Loss/tok 3.8662 (4.5731)	Learning Rate [0.00125]
7: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00096)	Tok/s 54891 (53534)	Loss/tok 3.7685 (4.5716)	Learning Rate [0.00125]
10: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00096)	Tok/s 55763 (53748)	Loss/tok 3.9618 (4.5734)	Learning Rate [0.00125]
8: TRAIN [0][2270/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00093)	Tok/s 54880 (53613)	Loss/tok 3.9651 (4.5674)	Learning Rate [0.00125]
9: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00092)	Tok/s 52528 (53701)	Loss/tok 3.3469 (4.5683)	Learning Rate [0.00125]
6: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00094)	Tok/s 52610 (53483)	Loss/tok 3.3506 (4.5664)	Learning Rate [0.00125]
7: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00096)	Tok/s 52707 (53562)	Loss/tok 3.5813 (4.5673)	Learning Rate [0.00125]
8: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00093)	Tok/s 52502 (53641)	Loss/tok 3.5148 (4.5623)	Learning Rate [0.00125]
11: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00092)	Tok/s 52341 (53847)	Loss/tok 3.5430 (4.5710)	Learning Rate [0.00125]
5: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00095)	Tok/s 52560 (53411)	Loss/tok 3.5568 (4.5697)	Learning Rate [0.00125]
10: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00113 (0.00096)	Tok/s 52355 (53774)	Loss/tok 3.5385 (4.5686)	Learning Rate [0.00125]
15: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00092)	Tok/s 52521 (54257)	Loss/tok 3.5967 (4.5672)	Learning Rate [0.00125]
14: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00096)	Tok/s 52468 (54144)	Loss/tok 3.6458 (4.5733)	Learning Rate [0.00125]
12: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00097)	Tok/s 52323 (53951)	Loss/tok 3.5594 (4.5719)	Learning Rate [0.00125]
13: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00112 (0.00096)	Tok/s 52418 (54042)	Loss/tok 3.6996 (4.5680)	Learning Rate [0.00125]
1: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00094)	Tok/s 51312 (53042)	Loss/tok 3.5169 (4.5707)	Learning Rate [0.00125]
3: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00093)	Tok/s 52541 (53242)	Loss/tok 3.4817 (4.5697)	Learning Rate [0.00125]
0: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00097)	Tok/s 51300 (52948)	Loss/tok 3.4470 (4.5760)	Learning Rate [0.00125]
2: TRAIN [0][2280/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00100)	Tok/s 52270 (53142)	Loss/tok 3.5226 (4.5675)	Learning Rate [0.00125]
4: TRAIN [0][2280/3416]	Time 0.052 (0.058)	Data 0.00110 (0.00099)	Tok/s 51396 (53325)	Loss/tok 3.7100 (4.5719)	Learning Rate [0.00125]
12: TRAIN [0][2290/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00097)	Tok/s 51721 (53951)	Loss/tok 3.8693 (4.5679)	Learning Rate [0.00125]
13: TRAIN [0][2290/3416]	Time 0.058 (0.058)	Data 0.00112 (0.00096)	Tok/s 51745 (54042)	Loss/tok 3.6162 (4.5641)	Learning Rate [0.00125]
10: TRAIN [0][2290/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00096)	Tok/s 51569 (53774)	Loss/tok 3.3889 (4.5647)	Learning Rate [0.00125]
14: TRAIN [0][2290/3416]	Time 0.058 (0.058)	Data 0.00083 (0.00096)	Tok/s 51722 (54144)	Loss/tok 3.8411 (4.5693)	Learning Rate [0.00125]
11: TRAIN [0][2290/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00092)	Tok/s 51664 (53847)	Loss/tok 3.2824 (4.5669)	Learning Rate [0.00125]
9: TRAIN [0][2290/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00092)	Tok/s 51428 (53701)	Loss/tok 3.7383 (4.5646)	Learning Rate [0.00125]
15: TRAIN [0][2290/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00092)	Tok/s 51658 (54258)	Loss/tok 3.6856 (4.5630)	Learning Rate [0.00125]
0: TRAIN [0][2290/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00097)	Tok/s 51584 (52949)	Loss/tok 3.5187 (4.5719)	Learning Rate [0.00125]
8: TRAIN [0][2290/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00093)	Tok/s 51386 (53641)	Loss/tok 3.6343 (4.5587)	Learning Rate [0.00125]
7: TRAIN [0][2290/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00096)	Tok/s 51254 (53561)	Loss/tok 3.6454 (4.5631)	Learning Rate [0.00125]
1: TRAIN [0][2290/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00094)	Tok/s 51485 (53044)	Loss/tok 3.5959 (4.5665)	Learning Rate [0.00125]
6: TRAIN [0][2290/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00094)	Tok/s 51217 (53483)	Loss/tok 3.7260 (4.5625)	Learning Rate [0.00125]
2: TRAIN [0][2290/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00100)	Tok/s 51403 (53144)	Loss/tok 3.5649 (4.5634)	Learning Rate [0.00125]
5: TRAIN [0][2290/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00095)	Tok/s 51190 (53412)	Loss/tok 3.8254 (4.5657)	Learning Rate [0.00125]
4: TRAIN [0][2290/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00099)	Tok/s 51304 (53327)	Loss/tok 3.5437 (4.5678)	Learning Rate [0.00125]
3: TRAIN [0][2290/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00093)	Tok/s 51256 (53243)	Loss/tok 3.7827 (4.5656)	Learning Rate [0.00125]
14: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00096)	Tok/s 54853 (54163)	Loss/tok 3.6132 (4.5649)	Learning Rate [0.00125]
15: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 54800 (54276)	Loss/tok 3.7555 (4.5585)	Learning Rate [0.00125]
0: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 53792 (52969)	Loss/tok 3.6556 (4.5673)	Learning Rate [0.00125]
1: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00094)	Tok/s 53704 (53063)	Loss/tok 3.7285 (4.5622)	Learning Rate [0.00125]
13: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00096)	Tok/s 54844 (54061)	Loss/tok 4.0773 (4.5596)	Learning Rate [0.00125]
12: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00097)	Tok/s 54547 (53969)	Loss/tok 4.0005 (4.5635)	Learning Rate [0.00125]
11: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00092)	Tok/s 53766 (53865)	Loss/tok 3.5416 (4.5624)	Learning Rate [0.00125]
3: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00093)	Tok/s 53540 (53262)	Loss/tok 3.7453 (4.5609)	Learning Rate [0.00125]
4: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00099)	Tok/s 53464 (53346)	Loss/tok 3.7837 (4.5629)	Learning Rate [0.00125]
9: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 53598 (53720)	Loss/tok 3.5616 (4.5600)	Learning Rate [0.00125]
2: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00100)	Tok/s 53634 (53163)	Loss/tok 3.8129 (4.5589)	Learning Rate [0.00125]
10: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00096)	Tok/s 53636 (53792)	Loss/tok 3.7812 (4.5605)	Learning Rate [0.00125]
5: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00095)	Tok/s 53424 (53431)	Loss/tok 4.1297 (4.5611)	Learning Rate [0.00125]
6: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00094)	Tok/s 53413 (53502)	Loss/tok 3.8617 (4.5582)	Learning Rate [0.00125]
8: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00093)	Tok/s 53511 (53659)	Loss/tok 3.8946 (4.5543)	Learning Rate [0.00125]
7: TRAIN [0][2300/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00096)	Tok/s 53442 (53581)	Loss/tok 3.9690 (4.5587)	Learning Rate [0.00125]
0: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00097)	Tok/s 50737 (52963)	Loss/tok 3.3436 (4.5634)	Learning Rate [0.00125]
1: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00080 (0.00094)	Tok/s 50746 (53057)	Loss/tok 3.4012 (4.5579)	Learning Rate [0.00125]
15: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00092)	Tok/s 50618 (54269)	Loss/tok 3.6663 (4.5546)	Learning Rate [0.00125]
14: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00108 (0.00096)	Tok/s 50588 (54156)	Loss/tok 3.5379 (4.5610)	Learning Rate [0.00125]
12: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00097)	Tok/s 50457 (53963)	Loss/tok 3.3721 (4.5598)	Learning Rate [0.00125]
2: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00100)	Tok/s 50639 (53158)	Loss/tok 3.4108 (4.5548)	Learning Rate [0.00125]
11: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 50283 (53858)	Loss/tok 3.2701 (4.5588)	Learning Rate [0.00125]
13: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00096)	Tok/s 50530 (54055)	Loss/tok 3.3782 (4.5552)	Learning Rate [0.00125]
4: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00099)	Tok/s 50463 (53340)	Loss/tok 3.5947 (4.5590)	Learning Rate [0.00125]
3: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00093)	Tok/s 50511 (53256)	Loss/tok 3.5894 (4.5571)	Learning Rate [0.00125]
10: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00096)	Tok/s 50180 (53786)	Loss/tok 3.5681 (4.5565)	Learning Rate [0.00125]
6: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00094)	Tok/s 50322 (53496)	Loss/tok 3.4767 (4.5540)	Learning Rate [0.00125]
9: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 50121 (53713)	Loss/tok 3.7064 (4.5558)	Learning Rate [0.00125]
7: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00096)	Tok/s 50233 (53574)	Loss/tok 3.4337 (4.5548)	Learning Rate [0.00125]
8: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00093)	Tok/s 50201 (53653)	Loss/tok 3.5276 (4.5505)	Learning Rate [0.00125]
5: TRAIN [0][2310/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00095)	Tok/s 50306 (53425)	Loss/tok 3.5042 (4.5570)	Learning Rate [0.00125]
6: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
4: Gradient norm: inf
3: Gradient norm: inf
5: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
7: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
4: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00099)	Tok/s 78433 (53330)	Loss/tok 3.7938 (4.5550)	Learning Rate [0.00125]
8: Gradient norm: inf
15: Gradient norm: inf
3: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 78258 (53246)	Loss/tok 3.5791 (4.5531)	Learning Rate [0.00125]
9: Gradient norm: inf
5: TRAIN [0][2320/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00095)	Tok/s 78486 (53415)	Loss/tok 3.7153 (4.5528)	Learning Rate [0.00125]
0: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
6: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00094)	Tok/s 78343 (53486)	Loss/tok 3.5428 (4.5503)	Learning Rate [0.00125]
11: Gradient norm: inf
14: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
2: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00100)	Tok/s 77399 (53148)	Loss/tok 3.8499 (4.5507)	Learning Rate [0.00125]
11: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
12: Gradient norm: inf
1: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00094)	Tok/s 77340 (53047)	Loss/tok 3.5409 (4.5534)	Learning Rate [0.00125]
14: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
7: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 78415 (53564)	Loss/tok 3.7466 (4.5508)	Learning Rate [0.00125]
13: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
8: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 78437 (53642)	Loss/tok 3.7349 (4.5469)	Learning Rate [0.00125]
0: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 77353 (52953)	Loss/tok 3.4744 (4.5595)	Learning Rate [0.00125]
9: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 78448 (53702)	Loss/tok 3.6220 (4.5520)	Learning Rate [0.00125]
15: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 79251 (54258)	Loss/tok 3.4908 (4.5507)	Learning Rate [0.00125]
11: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 79394 (53848)	Loss/tok 3.5426 (4.5547)	Learning Rate [0.00125]
14: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 79268 (54146)	Loss/tok 3.6745 (4.5570)	Learning Rate [0.00125]
10: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 78553 (53775)	Loss/tok 3.5625 (4.5527)	Learning Rate [0.00125]
13: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 79271 (54044)	Loss/tok 3.5802 (4.5511)	Learning Rate [0.00125]
12: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 79313 (53952)	Loss/tok 3.6740 (4.5562)	Learning Rate [0.00125]
15: Gradient norm: inf
14: Gradient norm: inf
0: Gradient norm: inf
1: Gradient norm: inf
13: Gradient norm: inf
14: Skipped batch, new scale: 512.0
15: Skipped batch, new scale: 512.0
0: Skipped batch, new scale: 512.0
2: Gradient norm: inf
1: Skipped batch, new scale: 512.0
13: Skipped batch, new scale: 512.0
12: Gradient norm: inf
3: Gradient norm: inf
2: Skipped batch, new scale: 512.0
12: Skipped batch, new scale: 512.0
11: Gradient norm: inf
5: Gradient norm: inf
10: Gradient norm: inf
3: Skipped batch, new scale: 512.0
11: Skipped batch, new scale: 512.0
5: Skipped batch, new scale: 512.0
6: Gradient norm: inf
9: Gradient norm: inf
10: Skipped batch, new scale: 512.0
8: Gradient norm: inf
6: Skipped batch, new scale: 512.0
9: Skipped batch, new scale: 512.0
7: Gradient norm: inf
4: Gradient norm: inf
8: Skipped batch, new scale: 512.0
7: Skipped batch, new scale: 512.0
4: Skipped batch, new scale: 512.0
10: TRAIN [0][2330/3416]	Time 0.051 (0.058)	Data 0.00109 (0.00096)	Tok/s 52315 (53773)	Loss/tok 3.6646 (4.5488)	Learning Rate [0.00125]
9: TRAIN [0][2330/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00092)	Tok/s 52211 (53700)	Loss/tok 3.3008 (4.5475)	Learning Rate [0.00125]
11: TRAIN [0][2330/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00092)	Tok/s 52271 (53846)	Loss/tok 3.4254 (4.5505)	Learning Rate [0.00125]
15: TRAIN [0][2330/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00092)	Tok/s 53475 (54260)	Loss/tok 3.3540 (4.5467)	Learning Rate [0.00125]
8: TRAIN [0][2330/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00093)	Tok/s 52063 (53640)	Loss/tok 3.4298 (4.5425)	Learning Rate [0.00125]
0: TRAIN [0][2330/3416]	Time 0.052 (0.058)	Data 0.00110 (0.00097)	Tok/s 52115 (52945)	Loss/tok 3.8157 (4.5553)	Learning Rate [0.00125]
12: TRAIN [0][2330/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00097)	Tok/s 52317 (53951)	Loss/tok 3.5647 (4.5523)	Learning Rate [0.00125]
7: TRAIN [0][2330/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00096)	Tok/s 51941 (53561)	Loss/tok 3.4690 (4.5464)	Learning Rate [0.00125]
14: TRAIN [0][2330/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00096)	Tok/s 52300 (54146)	Loss/tok 3.5118 (4.5529)	Learning Rate [0.00125]
1: TRAIN [0][2330/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00094)	Tok/s 52020 (53040)	Loss/tok 3.5807 (4.5492)	Learning Rate [0.00125]
13: TRAIN [0][2330/3416]	Time 0.051 (0.058)	Data 0.00119 (0.00096)	Tok/s 52251 (54044)	Loss/tok 3.8694 (4.5470)	Learning Rate [0.00125]
6: TRAIN [0][2330/3416]	Time 0.052 (0.058)	Data 0.00116 (0.00094)	Tok/s 51837 (53482)	Loss/tok 3.4594 (4.5463)	Learning Rate [0.00125]
2: TRAIN [0][2330/3416]	Time 0.052 (0.058)	Data 0.00112 (0.00100)	Tok/s 51944 (53141)	Loss/tok 3.6486 (4.5464)	Learning Rate [0.00125]
3: TRAIN [0][2330/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00093)	Tok/s 51847 (53241)	Loss/tok 3.4435 (4.5490)	Learning Rate [0.00125]
5: TRAIN [0][2330/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00095)	Tok/s 51794 (53411)	Loss/tok 3.5587 (4.5487)	Learning Rate [0.00125]
4: TRAIN [0][2330/3416]	Time 0.052 (0.058)	Data 0.00132 (0.00099)	Tok/s 51821 (53326)	Loss/tok 3.5197 (4.5511)	Learning Rate [0.00125]
12: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00097)	Tok/s 51216 (53935)	Loss/tok 3.5904 (4.5486)	Learning Rate [0.00125]
13: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00096)	Tok/s 51322 (54028)	Loss/tok 3.3696 (4.5429)	Learning Rate [0.00125]
10: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00096)	Tok/s 51072 (53758)	Loss/tok 3.4379 (4.5447)	Learning Rate [0.00125]
9: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 51095 (53684)	Loss/tok 3.4624 (4.5434)	Learning Rate [0.00125]
14: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00096)	Tok/s 51188 (54131)	Loss/tok 3.6558 (4.5490)	Learning Rate [0.00125]
8: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 51198 (53624)	Loss/tok 3.5176 (4.5389)	Learning Rate [0.00125]
15: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 51175 (54245)	Loss/tok 3.6048 (4.5429)	Learning Rate [0.00125]
0: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00097)	Tok/s 51183 (52929)	Loss/tok 3.4254 (4.5513)	Learning Rate [0.00125]
7: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00096)	Tok/s 51081 (53544)	Loss/tok 3.5495 (4.5426)	Learning Rate [0.00125]
1: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00094)	Tok/s 51186 (53023)	Loss/tok 3.4027 (4.5456)	Learning Rate [0.00125]
6: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00094)	Tok/s 51075 (53466)	Loss/tok 3.3925 (4.5427)	Learning Rate [0.00125]
5: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00095)	Tok/s 51131 (53395)	Loss/tok 3.9017 (4.5450)	Learning Rate [0.00125]
2: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00100)	Tok/s 51211 (53124)	Loss/tok 3.7177 (4.5428)	Learning Rate [0.00125]
3: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00093)	Tok/s 51144 (53224)	Loss/tok 3.3931 (4.5453)	Learning Rate [0.00125]
4: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00099)	Tok/s 51122 (53309)	Loss/tok 3.5927 (4.5475)	Learning Rate [0.00125]
11: TRAIN [0][2340/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 51133 (53830)	Loss/tok 3.6765 (4.5471)	Learning Rate [0.00125]
4: TRAIN [0][2350/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00099)	Tok/s 32625 (53275)	Loss/tok 3.3666 (4.5440)	Learning Rate [0.00125]
6: TRAIN [0][2350/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00094)	Tok/s 32601 (53431)	Loss/tok 3.1426 (4.5389)	Learning Rate [0.00125]
3: TRAIN [0][2350/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00093)	Tok/s 32493 (53191)	Loss/tok 3.4743 (4.5418)	Learning Rate [0.00125]
5: TRAIN [0][2350/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00095)	Tok/s 32566 (53360)	Loss/tok 3.1090 (4.5416)	Learning Rate [0.00125]
1: TRAIN [0][2350/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00094)	Tok/s 32364 (52990)	Loss/tok 3.0675 (4.5422)	Learning Rate [0.00125]
2: TRAIN [0][2350/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00100)	Tok/s 32427 (53091)	Loss/tok 3.3802 (4.5393)	Learning Rate [0.00125]
7: TRAIN [0][2350/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00096)	Tok/s 32581 (53509)	Loss/tok 2.9148 (4.5389)	Learning Rate [0.00125]
0: TRAIN [0][2350/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00097)	Tok/s 32280 (52895)	Loss/tok 3.2870 (4.5477)	Learning Rate [0.00125]
9: TRAIN [0][2350/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00092)	Tok/s 32491 (53649)	Loss/tok 3.4809 (4.5402)	Learning Rate [0.00125]
8: TRAIN [0][2350/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00093)	Tok/s 32528 (53589)	Loss/tok 3.1703 (4.5358)	Learning Rate [0.00125]
15: TRAIN [0][2350/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 33517 (54210)	Loss/tok 3.1369 (4.5395)	Learning Rate [0.00125]
14: TRAIN [0][2350/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00096)	Tok/s 33523 (54096)	Loss/tok 3.3006 (4.5456)	Learning Rate [0.00125]
10: TRAIN [0][2350/3416]	Time 0.051 (0.058)	Data 0.00113 (0.00096)	Tok/s 32374 (53722)	Loss/tok 3.2864 (4.5417)	Learning Rate [0.00125]
13: TRAIN [0][2350/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00096)	Tok/s 33536 (53994)	Loss/tok 3.2325 (4.5397)	Learning Rate [0.00125]
12: TRAIN [0][2350/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00097)	Tok/s 33547 (53900)	Loss/tok 3.3508 (4.5455)	Learning Rate [0.00125]
11: TRAIN [0][2350/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00092)	Tok/s 32576 (53795)	Loss/tok 3.0539 (4.5437)	Learning Rate [0.00125]
8: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00093)	Tok/s 32423 (53612)	Loss/tok 3.3640 (4.5316)	Learning Rate [0.00125]
7: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00096)	Tok/s 32437 (53531)	Loss/tok 3.2029 (4.5342)	Learning Rate [0.00125]
9: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 32368 (53672)	Loss/tok 3.3054 (4.5359)	Learning Rate [0.00125]
6: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00094)	Tok/s 32425 (53453)	Loss/tok 3.0128 (4.5342)	Learning Rate [0.00125]
5: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00095)	Tok/s 32388 (53382)	Loss/tok 3.2311 (4.5371)	Learning Rate [0.00125]
10: TRAIN [0][2360/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00096)	Tok/s 32276 (53745)	Loss/tok 3.5125 (4.5378)	Learning Rate [0.00125]
4: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00099)	Tok/s 32421 (53297)	Loss/tok 3.1295 (4.5392)	Learning Rate [0.00125]
3: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 32361 (53213)	Loss/tok 3.2659 (4.5370)	Learning Rate [0.00125]
12: TRAIN [0][2360/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 32141 (53923)	Loss/tok 3.1503 (4.5411)	Learning Rate [0.00125]
13: TRAIN [0][2360/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00096)	Tok/s 32508 (54016)	Loss/tok 3.4598 (4.5354)	Learning Rate [0.00125]
2: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00100)	Tok/s 32331 (53114)	Loss/tok 3.2036 (4.5348)	Learning Rate [0.00125]
1: TRAIN [0][2360/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00094)	Tok/s 32235 (53013)	Loss/tok 3.3097 (4.5375)	Learning Rate [0.00125]
15: TRAIN [0][2360/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00092)	Tok/s 33385 (54233)	Loss/tok 3.2903 (4.5349)	Learning Rate [0.00125]
14: TRAIN [0][2360/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00096)	Tok/s 33376 (54119)	Loss/tok 3.2646 (4.5413)	Learning Rate [0.00125]
0: TRAIN [0][2360/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00097)	Tok/s 32178 (52917)	Loss/tok 3.3674 (4.5428)	Learning Rate [0.00125]
11: TRAIN [0][2360/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 32213 (53817)	Loss/tok 3.3377 (4.5394)	Learning Rate [0.00125]
15: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 67326 (54228)	Loss/tok 3.7781 (4.5306)	Learning Rate [0.00125]
0: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 66442 (52911)	Loss/tok 3.9129 (4.5387)	Learning Rate [0.00125]
1: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00094)	Tok/s 66462 (53007)	Loss/tok 3.8150 (4.5335)	Learning Rate [0.00125]
14: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00096)	Tok/s 67340 (54114)	Loss/tok 3.6278 (4.5371)	Learning Rate [0.00125]
2: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00100)	Tok/s 66452 (53108)	Loss/tok 3.7820 (4.5307)	Learning Rate [0.00125]
13: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00096)	Tok/s 67316 (54011)	Loss/tok 3.8552 (4.5315)	Learning Rate [0.00125]
12: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 67224 (53917)	Loss/tok 3.6509 (4.5368)	Learning Rate [0.00125]
11: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 67640 (53811)	Loss/tok 3.5526 (4.5353)	Learning Rate [0.00125]
3: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 66402 (53207)	Loss/tok 3.4704 (4.5331)	Learning Rate [0.00125]
4: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00099)	Tok/s 66403 (53292)	Loss/tok 3.8883 (4.5354)	Learning Rate [0.00125]
10: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00096)	Tok/s 67371 (53738)	Loss/tok 3.7212 (4.5336)	Learning Rate [0.00125]
9: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 67374 (53666)	Loss/tok 3.5725 (4.5316)	Learning Rate [0.00125]
5: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00095)	Tok/s 66388 (53377)	Loss/tok 4.0022 (4.5330)	Learning Rate [0.00125]
6: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00094)	Tok/s 66295 (53447)	Loss/tok 3.8899 (4.5301)	Learning Rate [0.00125]
8: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 67346 (53606)	Loss/tok 3.8195 (4.5274)	Learning Rate [0.00125]
7: TRAIN [0][2370/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 66550 (53526)	Loss/tok 3.9261 (4.5303)	Learning Rate [0.00125]
15: TRAIN [0][2380/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 71260 (54234)	Loss/tok 3.6733 (4.5268)	Learning Rate [0.00125]
14: TRAIN [0][2380/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00096)	Tok/s 71287 (54120)	Loss/tok 3.5049 (4.5330)	Learning Rate [0.00125]
0: TRAIN [0][2380/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 69311 (52919)	Loss/tok 4.0375 (4.5348)	Learning Rate [0.00125]
1: TRAIN [0][2380/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00094)	Tok/s 69597 (53014)	Loss/tok 3.6433 (4.5292)	Learning Rate [0.00125]
13: TRAIN [0][2380/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 71151 (54018)	Loss/tok 3.9164 (4.5277)	Learning Rate [0.00125]
2: TRAIN [0][2380/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 70036 (53114)	Loss/tok 3.6009 (4.5264)	Learning Rate [0.00125]
12: TRAIN [0][2380/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 70320 (53923)	Loss/tok 3.6790 (4.5333)	Learning Rate [0.00125]
11: TRAIN [0][2380/3416]	Time 0.069 (0.058)	Data 0.00079 (0.00092)	Tok/s 70297 (53818)	Loss/tok 3.6833 (4.5316)	Learning Rate [0.00125]
3: TRAIN [0][2380/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 69878 (53213)	Loss/tok 3.9909 (4.5291)	Learning Rate [0.00125]
4: TRAIN [0][2380/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00099)	Tok/s 69881 (53298)	Loss/tok 3.6056 (4.5313)	Learning Rate [0.00125]
9: TRAIN [0][2380/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 70149 (53671)	Loss/tok 3.5190 (4.5274)	Learning Rate [0.00125]
10: TRAIN [0][2380/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 70247 (53744)	Loss/tok 3.6567 (4.5297)	Learning Rate [0.00125]
5: TRAIN [0][2380/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00095)	Tok/s 69919 (53383)	Loss/tok 3.6249 (4.5288)	Learning Rate [0.00125]
8: TRAIN [0][2380/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 70092 (53612)	Loss/tok 3.6099 (4.5236)	Learning Rate [0.00125]
6: TRAIN [0][2380/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00094)	Tok/s 69870 (53453)	Loss/tok 3.5401 (4.5262)	Learning Rate [0.00125]
7: TRAIN [0][2380/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 69966 (53532)	Loss/tok 3.6530 (4.5268)	Learning Rate [0.00125]
6: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00094)	Tok/s 74252 (53445)	Loss/tok 3.3186 (4.5222)	Learning Rate [0.00125]
7: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 74317 (53523)	Loss/tok 3.6705 (4.5230)	Learning Rate [0.00125]
5: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00095)	Tok/s 73858 (53374)	Loss/tok 3.5468 (4.5248)	Learning Rate [0.00125]
8: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00093)	Tok/s 74028 (53603)	Loss/tok 3.5722 (4.5198)	Learning Rate [0.00125]
4: TRAIN [0][2390/3416]	Time 0.069 (0.058)	Data 0.00120 (0.00099)	Tok/s 74259 (53290)	Loss/tok 3.6828 (4.5276)	Learning Rate [0.00125]
1: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00094)	Tok/s 73409 (53007)	Loss/tok 3.7150 (4.5256)	Learning Rate [0.00125]
9: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 74041 (53663)	Loss/tok 3.7156 (4.5238)	Learning Rate [0.00125]
3: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00093)	Tok/s 73383 (53205)	Loss/tok 3.7781 (4.5258)	Learning Rate [0.00125]
2: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 73419 (53107)	Loss/tok 3.6552 (4.5227)	Learning Rate [0.00125]
0: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 73509 (52912)	Loss/tok 3.6238 (4.5311)	Learning Rate [0.00125]
11: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00092)	Tok/s 74107 (53809)	Loss/tok 3.5133 (4.5277)	Learning Rate [0.00125]
15: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 74810 (54225)	Loss/tok 3.7003 (4.5226)	Learning Rate [0.00125]
10: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00096)	Tok/s 74068 (53736)	Loss/tok 3.5843 (4.5261)	Learning Rate [0.00125]
12: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 74157 (53915)	Loss/tok 3.6314 (4.5295)	Learning Rate [0.00125]
14: TRAIN [0][2390/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00096)	Tok/s 74239 (54112)	Loss/tok 3.5467 (4.5290)	Learning Rate [0.00125]
13: TRAIN [0][2390/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00096)	Tok/s 75120 (54010)	Loss/tok 3.8160 (4.5240)	Learning Rate [0.00125]
9: TRAIN [0][2400/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 36212 (53662)	Loss/tok 3.2393 (4.5192)	Learning Rate [0.00125]
10: TRAIN [0][2400/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00096)	Tok/s 36265 (53735)	Loss/tok 3.1922 (4.5217)	Learning Rate [0.00125]
11: TRAIN [0][2400/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00092)	Tok/s 36228 (53808)	Loss/tok 3.3034 (4.5235)	Learning Rate [0.00125]
8: TRAIN [0][2400/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 36095 (53602)	Loss/tok 3.0305 (4.5152)	Learning Rate [0.00125]
7: TRAIN [0][2400/3416]	Time 0.052 (0.058)	Data 0.00106 (0.00096)	Tok/s 36008 (53523)	Loss/tok 3.2446 (4.5189)	Learning Rate [0.00125]
12: TRAIN [0][2400/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00097)	Tok/s 36243 (53914)	Loss/tok 3.3492 (4.5252)	Learning Rate [0.00125]
13: TRAIN [0][2400/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00096)	Tok/s 36233 (54010)	Loss/tok 3.2570 (4.5200)	Learning Rate [0.00125]
4: TRAIN [0][2400/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00099)	Tok/s 36047 (53289)	Loss/tok 3.3707 (4.5237)	Learning Rate [0.00125]
6: TRAIN [0][2400/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00094)	Tok/s 35926 (53445)	Loss/tok 3.1591 (4.5183)	Learning Rate [0.00125]
14: TRAIN [0][2400/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00096)	Tok/s 36219 (54112)	Loss/tok 3.4069 (4.5247)	Learning Rate [0.00125]
5: TRAIN [0][2400/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00095)	Tok/s 35977 (53374)	Loss/tok 3.2741 (4.5209)	Learning Rate [0.00125]
15: TRAIN [0][2400/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00092)	Tok/s 36176 (54225)	Loss/tok 3.3388 (4.5184)	Learning Rate [0.00125]
0: TRAIN [0][2400/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00097)	Tok/s 35144 (52911)	Loss/tok 3.5398 (4.5270)	Learning Rate [0.00125]
1: TRAIN [0][2400/3416]	Time 0.051 (0.058)	Data 0.00113 (0.00094)	Tok/s 36051 (53006)	Loss/tok 3.3726 (4.5214)	Learning Rate [0.00125]
3: TRAIN [0][2400/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00093)	Tok/s 35989 (53204)	Loss/tok 3.1996 (4.5217)	Learning Rate [0.00125]
2: TRAIN [0][2400/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00100)	Tok/s 36020 (53106)	Loss/tok 3.1211 (4.5188)	Learning Rate [0.00125]
6: TRAIN [0][2410/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00094)	Tok/s 66710 (53454)	Loss/tok 3.7299 (4.5145)	Learning Rate [0.00125]
7: TRAIN [0][2410/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 66752 (53532)	Loss/tok 3.8141 (4.5151)	Learning Rate [0.00125]
9: TRAIN [0][2410/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 66891 (53671)	Loss/tok 3.5341 (4.5152)	Learning Rate [0.00125]
5: TRAIN [0][2410/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00095)	Tok/s 65661 (53383)	Loss/tok 3.7632 (4.5171)	Learning Rate [0.00125]
8: TRAIN [0][2410/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 66763 (53611)	Loss/tok 3.5401 (4.5110)	Learning Rate [0.00125]
4: TRAIN [0][2410/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00099)	Tok/s 65541 (53299)	Loss/tok 3.9595 (4.5199)	Learning Rate [0.00125]
10: TRAIN [0][2410/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 66654 (53743)	Loss/tok 3.6770 (4.5177)	Learning Rate [0.00125]
11: TRAIN [0][2410/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00091)	Tok/s 66582 (53817)	Loss/tok 3.7284 (4.5195)	Learning Rate [0.00125]
12: TRAIN [0][2410/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 66534 (53923)	Loss/tok 3.7670 (4.5212)	Learning Rate [0.00125]
13: TRAIN [0][2410/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 66508 (54018)	Loss/tok 3.7589 (4.5160)	Learning Rate [0.00125]
3: TRAIN [0][2410/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 65455 (53215)	Loss/tok 3.5636 (4.5172)	Learning Rate [0.00125]
14: TRAIN [0][2410/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 66418 (54120)	Loss/tok 3.9001 (4.5211)	Learning Rate [0.00125]
15: TRAIN [0][2410/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 66314 (54233)	Loss/tok 3.5174 (4.5144)	Learning Rate [0.00125]
2: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00100)	Tok/s 65338 (53116)	Loss/tok 3.6530 (4.5146)	Learning Rate [0.00125]
0: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 65324 (52922)	Loss/tok 3.6629 (4.5232)	Learning Rate [0.00125]
1: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00094)	Tok/s 65264 (53016)	Loss/tok 3.7288 (4.5170)	Learning Rate [0.00125]
14: TRAIN [0][2420/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00096)	Tok/s 50364 (54106)	Loss/tok 3.5838 (4.5175)	Learning Rate [0.00125]
15: TRAIN [0][2420/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 51603 (54219)	Loss/tok 3.4340 (4.5108)	Learning Rate [0.00125]
6: TRAIN [0][2420/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00094)	Tok/s 50278 (53440)	Loss/tok 3.2184 (4.5106)	Learning Rate [0.00125]
7: TRAIN [0][2420/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00096)	Tok/s 50229 (53517)	Loss/tok 3.2321 (4.5115)	Learning Rate [0.00125]
13: TRAIN [0][2420/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00096)	Tok/s 50257 (54004)	Loss/tok 3.2761 (4.5124)	Learning Rate [0.00125]
0: TRAIN [0][2420/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00097)	Tok/s 51146 (52908)	Loss/tok 3.6131 (4.5194)	Learning Rate [0.00125]
3: TRAIN [0][2420/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00093)	Tok/s 50360 (53200)	Loss/tok 3.4777 (4.5141)	Learning Rate [0.00125]
1: TRAIN [0][2420/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00094)	Tok/s 50242 (53002)	Loss/tok 3.2703 (4.5132)	Learning Rate [0.00125]
5: TRAIN [0][2420/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00095)	Tok/s 50308 (53368)	Loss/tok 3.6266 (4.5134)	Learning Rate [0.00125]
8: TRAIN [0][2420/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00093)	Tok/s 50106 (53597)	Loss/tok 3.3058 (4.5073)	Learning Rate [0.00125]
2: TRAIN [0][2420/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00100)	Tok/s 50243 (53102)	Loss/tok 3.5704 (4.5110)	Learning Rate [0.00125]
11: TRAIN [0][2420/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00091)	Tok/s 50019 (53804)	Loss/tok 3.4031 (4.5157)	Learning Rate [0.00125]
12: TRAIN [0][2420/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00097)	Tok/s 50089 (53909)	Loss/tok 3.6906 (4.5177)	Learning Rate [0.00125]
9: TRAIN [0][2420/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00092)	Tok/s 50006 (53657)	Loss/tok 3.5723 (4.5117)	Learning Rate [0.00125]
10: TRAIN [0][2420/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00096)	Tok/s 49931 (53729)	Loss/tok 3.3562 (4.5139)	Learning Rate [0.00125]
4: TRAIN [0][2420/3416]	Time 0.048 (0.058)	Data 0.00116 (0.00099)	Tok/s 51155 (53284)	Loss/tok 3.5964 (4.5164)	Learning Rate [0.00125]
0: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00097)	Tok/s 52097 (52877)	Loss/tok 3.3983 (4.5158)	Learning Rate [0.00125]
15: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00092)	Tok/s 52133 (54187)	Loss/tok 3.6249 (4.5074)	Learning Rate [0.00125]
12: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00076 (0.00097)	Tok/s 52132 (53877)	Loss/tok 3.6706 (4.5145)	Learning Rate [0.00125]
13: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00096)	Tok/s 52136 (53972)	Loss/tok 3.5945 (4.5092)	Learning Rate [0.00125]
9: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00092)	Tok/s 52075 (53625)	Loss/tok 3.6253 (4.5085)	Learning Rate [0.00125]
14: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00096)	Tok/s 52105 (54074)	Loss/tok 3.6576 (4.5140)	Learning Rate [0.00125]
3: TRAIN [0][2430/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00093)	Tok/s 51878 (53168)	Loss/tok 3.7144 (4.5107)	Learning Rate [0.00125]
10: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00096)	Tok/s 52092 (53697)	Loss/tok 3.4252 (4.5106)	Learning Rate [0.00125]
4: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00099)	Tok/s 51942 (53252)	Loss/tok 3.4948 (4.5130)	Learning Rate [0.00125]
6: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00078 (0.00094)	Tok/s 51950 (53408)	Loss/tok 3.6385 (4.5074)	Learning Rate [0.00125]
5: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00095)	Tok/s 51900 (53337)	Loss/tok 3.7398 (4.5100)	Learning Rate [0.00125]
8: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00080 (0.00093)	Tok/s 52008 (53564)	Loss/tok 3.4011 (4.5040)	Learning Rate [0.00125]
11: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00091)	Tok/s 52112 (53772)	Loss/tok 3.7489 (4.5125)	Learning Rate [0.00125]
7: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00096)	Tok/s 51923 (53485)	Loss/tok 3.4215 (4.5084)	Learning Rate [0.00125]
2: TRAIN [0][2430/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00100)	Tok/s 51824 (53070)	Loss/tok 3.4396 (4.5075)	Learning Rate [0.00125]
1: TRAIN [0][2430/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00094)	Tok/s 51989 (52971)	Loss/tok 3.4949 (4.5099)	Learning Rate [0.00125]
6: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00094)	Tok/s 51612 (53382)	Loss/tok 3.6043 (4.5043)	Learning Rate [0.00125]
4: TRAIN [0][2440/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00099)	Tok/s 51788 (53226)	Loss/tok 3.4470 (4.5099)	Learning Rate [0.00125]
3: TRAIN [0][2440/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00093)	Tok/s 51737 (53142)	Loss/tok 3.2482 (4.5073)	Learning Rate [0.00125]
7: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00096)	Tok/s 51557 (53459)	Loss/tok 3.6551 (4.5051)	Learning Rate [0.00125]
8: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00093)	Tok/s 51382 (53538)	Loss/tok 3.5398 (4.5003)	Learning Rate [0.00125]
1: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00094)	Tok/s 50217 (52944)	Loss/tok 3.4460 (4.5067)	Learning Rate [0.00125]
0: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00097)	Tok/s 50163 (52846)	Loss/tok 3.4082 (4.5124)	Learning Rate [0.00125]
9: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00092)	Tok/s 51241 (53598)	Loss/tok 3.5860 (4.5054)	Learning Rate [0.00125]
2: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00108 (0.00100)	Tok/s 50676 (53044)	Loss/tok 3.6133 (4.5041)	Learning Rate [0.00125]
10: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00096)	Tok/s 51213 (53670)	Loss/tok 3.5980 (4.5075)	Learning Rate [0.00125]
11: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00091)	Tok/s 51087 (53745)	Loss/tok 3.6319 (4.5090)	Learning Rate [0.00125]
15: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00092)	Tok/s 51290 (54156)	Loss/tok 3.3448 (4.5041)	Learning Rate [0.00125]
13: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00096)	Tok/s 51035 (53946)	Loss/tok 3.6060 (4.5057)	Learning Rate [0.00125]
12: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00097)	Tok/s 50997 (53850)	Loss/tok 3.5976 (4.5111)	Learning Rate [0.00125]
14: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00110 (0.00096)	Tok/s 51139 (54048)	Loss/tok 3.3820 (4.5105)	Learning Rate [0.00125]
5: TRAIN [0][2440/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00095)	Tok/s 50808 (53310)	Loss/tok 3.8644 (4.5067)	Learning Rate [0.00125]
13: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
14: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00096)	Tok/s 51789 (54051)	Loss/tok 3.8141 (4.5069)	Learning Rate [0.00125]
13: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00096)	Tok/s 51709 (53949)	Loss/tok 3.4766 (4.5020)	Learning Rate [0.00125]
2: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
9: Upscaling, new scale: 1024.0
0: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00097)	Tok/s 50573 (52850)	Loss/tok 3.4283 (4.5085)	Learning Rate [0.00125]
12: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00096)	Tok/s 51599 (53853)	Loss/tok 3.4390 (4.5073)	Learning Rate [0.00125]
15: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00092)	Tok/s 51790 (54159)	Loss/tok 3.6229 (4.4999)	Learning Rate [0.00125]
4: Upscaling, new scale: 1024.0
11: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00091)	Tok/s 51594 (53748)	Loss/tok 3.4578 (4.5053)	Learning Rate [0.00125]
3: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
1: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00094)	Tok/s 50535 (52948)	Loss/tok 3.5462 (4.5031)	Learning Rate [0.00125]
10: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00096)	Tok/s 51587 (53673)	Loss/tok 3.5250 (4.5038)	Learning Rate [0.00125]
5: Upscaling, new scale: 1024.0
8: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00093)	Tok/s 51636 (53541)	Loss/tok 3.4542 (4.4964)	Learning Rate [0.00125]
2: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00100)	Tok/s 50554 (53047)	Loss/tok 3.4666 (4.5004)	Learning Rate [0.00125]
9: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 51551 (53601)	Loss/tok 3.1040 (4.5018)	Learning Rate [0.00125]
3: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00093)	Tok/s 50550 (53145)	Loss/tok 3.6906 (4.5035)	Learning Rate [0.00125]
6: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00094)	Tok/s 51648 (53385)	Loss/tok 3.4252 (4.5008)	Learning Rate [0.00125]
4: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00099)	Tok/s 50562 (53229)	Loss/tok 3.6237 (4.5062)	Learning Rate [0.00125]
7: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00096)	Tok/s 51633 (53462)	Loss/tok 3.3717 (4.5017)	Learning Rate [0.00125]
5: TRAIN [0][2450/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00095)	Tok/s 51597 (53313)	Loss/tok 3.5745 (4.5030)	Learning Rate [0.00125]
12: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 72777 (53842)	Loss/tok 3.7001 (4.5040)	Learning Rate [0.00125]
11: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 72443 (53737)	Loss/tok 3.6865 (4.5017)	Learning Rate [0.00125]
10: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00096)	Tok/s 72488 (53662)	Loss/tok 3.7137 (4.5003)	Learning Rate [0.00125]
13: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00096)	Tok/s 73227 (53938)	Loss/tok 3.5979 (4.4982)	Learning Rate [0.00125]
14: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 73251 (54039)	Loss/tok 3.4621 (4.5034)	Learning Rate [0.00125]
9: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 72475 (53590)	Loss/tok 3.8512 (4.4981)	Learning Rate [0.00125]
15: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 73262 (54148)	Loss/tok 3.6123 (4.4964)	Learning Rate [0.00125]
8: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00093)	Tok/s 72452 (53530)	Loss/tok 3.6479 (4.4930)	Learning Rate [0.00125]
7: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 72423 (53451)	Loss/tok 3.7485 (4.4984)	Learning Rate [0.00125]
1: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00094)	Tok/s 71414 (52937)	Loss/tok 3.8029 (4.4995)	Learning Rate [0.00125]
2: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00100)	Tok/s 71570 (53037)	Loss/tok 3.6486 (4.4968)	Learning Rate [0.00125]
5: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00094)	Tok/s 72411 (53303)	Loss/tok 3.7806 (4.4992)	Learning Rate [0.00125]
3: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 72338 (53134)	Loss/tok 3.6169 (4.5003)	Learning Rate [0.00125]
4: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00099)	Tok/s 72352 (53218)	Loss/tok 3.7950 (4.5027)	Learning Rate [0.00125]
6: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00094)	Tok/s 72426 (53374)	Loss/tok 3.7310 (4.4973)	Learning Rate [0.00125]
0: TRAIN [0][2460/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 71056 (52839)	Loss/tok 3.7381 (4.5051)	Learning Rate [0.00125]
14: Gradient norm: inf
13: Gradient norm: inf
15: Gradient norm: inf
14: Skipped batch, new scale: 512.0
12: Gradient norm: inf
13: Skipped batch, new scale: 512.0
0: Gradient norm: inf
15: Skipped batch, new scale: 512.0
11: Gradient norm: inf
12: Skipped batch, new scale: 512.0
0: Skipped batch, new scale: 512.0
10: Gradient norm: inf
1: Gradient norm: inf
9: Gradient norm: inf
8: Gradient norm: inf
7: Gradient norm: inf
11: Skipped batch, new scale: 512.0
2: Gradient norm: inf
10: Skipped batch, new scale: 512.0
6: Gradient norm: inf
1: Skipped batch, new scale: 512.0
9: Skipped batch, new scale: 512.0
7: Skipped batch, new scale: 512.0
8: Skipped batch, new scale: 512.0
5: Gradient norm: inf
4: Gradient norm: inf
2: Skipped batch, new scale: 512.0
6: Skipped batch, new scale: 512.0
5: Skipped batch, new scale: 512.0
4: Skipped batch, new scale: 512.0
3: Gradient norm: inf
3: Skipped batch, new scale: 512.0
1: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00094)	Tok/s 53952 (52938)	Loss/tok 3.5372 (4.4962)	Learning Rate [0.00125]
0: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00097)	Tok/s 52999 (52839)	Loss/tok 3.3203 (4.5016)	Learning Rate [0.00125]
15: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00092)	Tok/s 54286 (54147)	Loss/tok 3.5068 (4.4925)	Learning Rate [0.00125]
4: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00110 (0.00099)	Tok/s 54013 (53219)	Loss/tok 3.4468 (4.4990)	Learning Rate [0.00125]
2: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00100)	Tok/s 54093 (53038)	Loss/tok 3.4680 (4.4930)	Learning Rate [0.00125]
14: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00096)	Tok/s 54250 (54039)	Loss/tok 3.3841 (4.4995)	Learning Rate [0.00125]
3: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00093)	Tok/s 54006 (53135)	Loss/tok 3.6084 (4.4965)	Learning Rate [0.00125]
13: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00096)	Tok/s 54208 (53937)	Loss/tok 3.6041 (4.4947)	Learning Rate [0.00125]
12: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00096)	Tok/s 54279 (53842)	Loss/tok 3.4273 (4.5002)	Learning Rate [0.00125]
5: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00094)	Tok/s 54015 (53303)	Loss/tok 3.6963 (4.4956)	Learning Rate [0.00125]
6: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00094)	Tok/s 53998 (53374)	Loss/tok 3.6275 (4.4937)	Learning Rate [0.00125]
7: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00096)	Tok/s 54045 (53452)	Loss/tok 3.3909 (4.4942)	Learning Rate [0.00125]
11: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00091)	Tok/s 54223 (53737)	Loss/tok 3.6312 (4.4982)	Learning Rate [0.00125]
10: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00096)	Tok/s 54158 (53662)	Loss/tok 3.5336 (4.4964)	Learning Rate [0.00125]
9: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00092)	Tok/s 54075 (53590)	Loss/tok 3.2596 (4.4943)	Learning Rate [0.00125]
8: TRAIN [0][2470/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00093)	Tok/s 54058 (53530)	Loss/tok 3.4587 (4.4890)	Learning Rate [0.00125]
1: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00094)	Tok/s 59423 (52933)	Loss/tok 3.4301 (4.4929)	Learning Rate [0.00125]
2: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00100)	Tok/s 59470 (53032)	Loss/tok 3.6296 (4.4896)	Learning Rate [0.00125]
0: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00097)	Tok/s 59320 (52835)	Loss/tok 3.7258 (4.4984)	Learning Rate [0.00125]
15: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 60001 (54140)	Loss/tok 3.8777 (4.4891)	Learning Rate [0.00125]
4: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00111 (0.00099)	Tok/s 59374 (53213)	Loss/tok 3.6306 (4.4953)	Learning Rate [0.00125]
6: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00094)	Tok/s 59316 (53368)	Loss/tok 3.7618 (4.4903)	Learning Rate [0.00125]
14: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00096)	Tok/s 59157 (54032)	Loss/tok 3.8797 (4.4963)	Learning Rate [0.00125]
5: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00094)	Tok/s 59366 (53297)	Loss/tok 3.4924 (4.4920)	Learning Rate [0.00125]
13: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00096)	Tok/s 59047 (53930)	Loss/tok 3.6859 (4.4912)	Learning Rate [0.00125]
8: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 59176 (53524)	Loss/tok 3.7940 (4.4858)	Learning Rate [0.00125]
7: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00096)	Tok/s 59213 (53446)	Loss/tok 3.8730 (4.4907)	Learning Rate [0.00125]
11: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00091)	Tok/s 58973 (53731)	Loss/tok 3.8414 (4.4952)	Learning Rate [0.00125]
12: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00096)	Tok/s 58952 (53835)	Loss/tok 3.6523 (4.4967)	Learning Rate [0.00125]
10: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00080 (0.00096)	Tok/s 58999 (53656)	Loss/tok 3.7260 (4.4930)	Learning Rate [0.00125]
3: TRAIN [0][2480/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 59235 (53130)	Loss/tok 3.6877 (4.4929)	Learning Rate [0.00125]
9: TRAIN [0][2480/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 58784 (53584)	Loss/tok 3.6671 (4.4911)	Learning Rate [0.00125]
9: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00092)	Tok/s 48941 (53568)	Loss/tok 3.1361 (4.4880)	Learning Rate [0.00125]
8: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00411 (0.00093)	Tok/s 48786 (53508)	Loss/tok 3.4341 (4.4824)	Learning Rate [0.00125]
11: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00091)	Tok/s 48712 (53714)	Loss/tok 3.3181 (4.4920)	Learning Rate [0.00125]
7: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00096)	Tok/s 48913 (53430)	Loss/tok 3.4354 (4.4875)	Learning Rate [0.00125]
10: TRAIN [0][2490/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00096)	Tok/s 49323 (53639)	Loss/tok 3.5325 (4.4897)	Learning Rate [0.00125]
6: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00094)	Tok/s 48828 (53352)	Loss/tok 3.5157 (4.4872)	Learning Rate [0.00125]
12: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00115 (0.00097)	Tok/s 48600 (53818)	Loss/tok 3.5914 (4.4934)	Learning Rate [0.00125]
13: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00105 (0.00096)	Tok/s 48616 (53913)	Loss/tok 3.5909 (4.4880)	Learning Rate [0.00125]
14: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00112 (0.00096)	Tok/s 48620 (54014)	Loss/tok 3.3022 (4.4930)	Learning Rate [0.00125]
5: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00094)	Tok/s 48833 (53281)	Loss/tok 3.3034 (4.4887)	Learning Rate [0.00125]
0: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00097)	Tok/s 48641 (52820)	Loss/tok 3.5868 (4.4950)	Learning Rate [0.00125]
15: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00106 (0.00092)	Tok/s 48619 (54123)	Loss/tok 3.2862 (4.4856)	Learning Rate [0.00125]
3: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00093)	Tok/s 48760 (53114)	Loss/tok 3.3829 (4.4899)	Learning Rate [0.00125]
1: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00116 (0.00094)	Tok/s 48647 (52918)	Loss/tok 3.2013 (4.4895)	Learning Rate [0.00125]
2: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00107 (0.00100)	Tok/s 48724 (53017)	Loss/tok 3.3508 (4.4865)	Learning Rate [0.00125]
4: TRAIN [0][2490/3416]	Time 0.046 (0.058)	Data 0.00117 (0.00099)	Tok/s 48834 (53197)	Loss/tok 3.5133 (4.4921)	Learning Rate [0.00125]
6: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00094)	Tok/s 33361 (53334)	Loss/tok 3.3479 (4.4844)	Learning Rate [0.00125]
8: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00093)	Tok/s 33451 (53490)	Loss/tok 3.4025 (4.4789)	Learning Rate [0.00125]
10: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00096)	Tok/s 33525 (53621)	Loss/tok 2.9843 (4.4866)	Learning Rate [0.00125]
7: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00096)	Tok/s 33417 (53412)	Loss/tok 3.2233 (4.4840)	Learning Rate [0.00125]
4: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00100)	Tok/s 33404 (53180)	Loss/tok 3.1592 (4.4884)	Learning Rate [0.00125]
9: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 33435 (53550)	Loss/tok 3.4507 (4.4848)	Learning Rate [0.00125]
12: TRAIN [0][2500/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00097)	Tok/s 33624 (53799)	Loss/tok 3.1817 (4.4898)	Learning Rate [0.00125]
5: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00094)	Tok/s 33312 (53263)	Loss/tok 3.1838 (4.4855)	Learning Rate [0.00125]
11: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00091)	Tok/s 33436 (53696)	Loss/tok 3.1881 (4.4889)	Learning Rate [0.00125]
13: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00096)	Tok/s 34634 (53895)	Loss/tok 3.1932 (4.4848)	Learning Rate [0.00125]
3: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00093)	Tok/s 33305 (53097)	Loss/tok 3.3829 (4.4866)	Learning Rate [0.00125]
15: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00075 (0.00092)	Tok/s 34663 (54104)	Loss/tok 3.3383 (4.4822)	Learning Rate [0.00125]
14: TRAIN [0][2500/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00096)	Tok/s 34819 (53996)	Loss/tok 3.2851 (4.4900)	Learning Rate [0.00125]
2: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00100)	Tok/s 33316 (53000)	Loss/tok 3.2202 (4.4832)	Learning Rate [0.00125]
0: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 33379 (52804)	Loss/tok 3.2672 (4.4915)	Learning Rate [0.00125]
1: TRAIN [0][2500/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00094)	Tok/s 33354 (52901)	Loss/tok 3.2964 (4.4860)	Learning Rate [0.00125]
3: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 36594 (53089)	Loss/tok 3.3160 (4.4831)	Learning Rate [0.00125]
2: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00100)	Tok/s 36562 (52991)	Loss/tok 3.1407 (4.4798)	Learning Rate [0.00125]
4: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00109 (0.00100)	Tok/s 37716 (53172)	Loss/tok 3.1640 (4.4850)	Learning Rate [0.00125]
1: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00094)	Tok/s 36482 (52892)	Loss/tok 3.4951 (4.4827)	Learning Rate [0.00125]
6: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00094)	Tok/s 37629 (53325)	Loss/tok 3.4020 (4.4811)	Learning Rate [0.00125]
5: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00094)	Tok/s 37708 (53255)	Loss/tok 3.2236 (4.4818)	Learning Rate [0.00125]
0: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00097)	Tok/s 36386 (52795)	Loss/tok 3.4007 (4.4882)	Learning Rate [0.00125]
15: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00079 (0.00092)	Tok/s 37560 (54094)	Loss/tok 3.2809 (4.4786)	Learning Rate [0.00125]
7: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00096)	Tok/s 37533 (53402)	Loss/tok 3.5261 (4.4810)	Learning Rate [0.00125]
8: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00093)	Tok/s 37458 (53480)	Loss/tok 3.4915 (4.4754)	Learning Rate [0.00125]
14: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00096)	Tok/s 37473 (53986)	Loss/tok 3.2908 (4.4866)	Learning Rate [0.00125]
13: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00096)	Tok/s 37408 (53885)	Loss/tok 3.1134 (4.4813)	Learning Rate [0.00125]
12: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00109 (0.00097)	Tok/s 37319 (53789)	Loss/tok 2.9933 (4.4863)	Learning Rate [0.00125]
9: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00092)	Tok/s 37367 (53541)	Loss/tok 3.3272 (4.4817)	Learning Rate [0.00125]
10: TRAIN [0][2510/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00096)	Tok/s 37306 (53612)	Loss/tok 3.5527 (4.4834)	Learning Rate [0.00125]
11: TRAIN [0][2510/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00091)	Tok/s 37265 (53686)	Loss/tok 3.2338 (4.4854)	Learning Rate [0.00125]
10: TRAIN [0][2520/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00096)	Tok/s 48396 (53637)	Loss/tok 3.4187 (4.4795)	Learning Rate [0.00125]
9: TRAIN [0][2520/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00092)	Tok/s 47827 (53566)	Loss/tok 3.1862 (4.4776)	Learning Rate [0.00125]
8: TRAIN [0][2520/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00093)	Tok/s 46663 (53505)	Loss/tok 3.5289 (4.4718)	Learning Rate [0.00125]
11: TRAIN [0][2520/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00091)	Tok/s 48415 (53711)	Loss/tok 3.1626 (4.4812)	Learning Rate [0.00125]
13: TRAIN [0][2520/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00096)	Tok/s 48271 (53909)	Loss/tok 3.4268 (4.4771)	Learning Rate [0.00125]
6: TRAIN [0][2520/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00094)	Tok/s 46454 (53351)	Loss/tok 3.3985 (4.4771)	Learning Rate [0.00125]
4: TRAIN [0][2520/3416]	Time 0.046 (0.058)	Data 0.00118 (0.00100)	Tok/s 46287 (53196)	Loss/tok 3.2187 (4.4809)	Learning Rate [0.00125]
0: TRAIN [0][2520/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 46552 (52821)	Loss/tok 3.3233 (4.4842)	Learning Rate [0.00125]
14: TRAIN [0][2520/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00096)	Tok/s 48253 (54010)	Loss/tok 3.4953 (4.4823)	Learning Rate [0.00125]
12: TRAIN [0][2520/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00097)	Tok/s 48331 (53814)	Loss/tok 3.6355 (4.4824)	Learning Rate [0.00125]
15: TRAIN [0][2520/3416]	Time 0.045 (0.058)	Data 0.00080 (0.00092)	Tok/s 48016 (54118)	Loss/tok 3.6284 (4.4748)	Learning Rate [0.00125]
5: TRAIN [0][2520/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00094)	Tok/s 46402 (53279)	Loss/tok 3.0878 (4.4777)	Learning Rate [0.00125]
3: TRAIN [0][2520/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00093)	Tok/s 46330 (53114)	Loss/tok 3.2867 (4.4793)	Learning Rate [0.00125]
2: TRAIN [0][2520/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00100)	Tok/s 46327 (53016)	Loss/tok 3.3875 (4.4757)	Learning Rate [0.00125]
1: TRAIN [0][2520/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00094)	Tok/s 46453 (52918)	Loss/tok 3.2949 (4.4788)	Learning Rate [0.00125]
7: TRAIN [0][2520/3416]	Time 0.045 (0.058)	Data 0.00119 (0.00096)	Tok/s 46936 (53427)	Loss/tok 3.6712 (4.4769)	Learning Rate [0.00125]
0: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00097)	Tok/s 38142 (52818)	Loss/tok 3.4147 (4.4807)	Learning Rate [0.00125]
1: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00094)	Tok/s 38060 (52914)	Loss/tok 3.5542 (4.4751)	Learning Rate [0.00125]
15: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00092)	Tok/s 38277 (54115)	Loss/tok 3.2949 (4.4707)	Learning Rate [0.00125]
2: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00100)	Tok/s 38006 (53013)	Loss/tok 3.2643 (4.4723)	Learning Rate [0.00125]
14: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00096)	Tok/s 38153 (54006)	Loss/tok 3.4358 (4.4786)	Learning Rate [0.00125]
13: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00096)	Tok/s 38117 (53905)	Loss/tok 3.4344 (4.4734)	Learning Rate [0.00125]
4: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00100)	Tok/s 37988 (53193)	Loss/tok 3.4455 (4.4773)	Learning Rate [0.00125]
3: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00093)	Tok/s 38004 (53111)	Loss/tok 3.3411 (4.4756)	Learning Rate [0.00125]
11: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00091)	Tok/s 38106 (53707)	Loss/tok 3.1915 (4.4777)	Learning Rate [0.00125]
12: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00097)	Tok/s 38096 (53810)	Loss/tok 3.5262 (4.4790)	Learning Rate [0.00125]
6: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00094)	Tok/s 38007 (53347)	Loss/tok 3.2991 (4.4737)	Learning Rate [0.00125]
10: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00096)	Tok/s 38063 (53632)	Loss/tok 3.5309 (4.4761)	Learning Rate [0.00125]
5: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00094)	Tok/s 37969 (53276)	Loss/tok 3.2295 (4.4736)	Learning Rate [0.00125]
9: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00092)	Tok/s 38007 (53561)	Loss/tok 3.3717 (4.4741)	Learning Rate [0.00125]
8: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00614 (0.00094)	Tok/s 38018 (53501)	Loss/tok 3.4604 (4.4681)	Learning Rate [0.00125]
7: TRAIN [0][2530/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00096)	Tok/s 37974 (53423)	Loss/tok 3.1511 (4.4731)	Learning Rate [0.00125]
1: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00094)	Tok/s 31320 (52901)	Loss/tok 3.1487 (4.4718)	Learning Rate [0.00125]
0: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00097)	Tok/s 31360 (52804)	Loss/tok 3.0284 (4.4773)	Learning Rate [0.00125]
2: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00100)	Tok/s 31238 (52999)	Loss/tok 3.1376 (4.4690)	Learning Rate [0.00125]
4: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00100)	Tok/s 31200 (53181)	Loss/tok 3.1180 (4.4743)	Learning Rate [0.00125]
3: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00093)	Tok/s 31200 (53098)	Loss/tok 3.1015 (4.4724)	Learning Rate [0.00125]
15: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00092)	Tok/s 32717 (54100)	Loss/tok 3.1877 (4.4671)	Learning Rate [0.00125]
14: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00096)	Tok/s 32717 (53991)	Loss/tok 3.0725 (4.4752)	Learning Rate [0.00125]
13: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00096)	Tok/s 32681 (53891)	Loss/tok 3.1146 (4.4701)	Learning Rate [0.00125]
6: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00094)	Tok/s 31141 (53334)	Loss/tok 3.1267 (4.4702)	Learning Rate [0.00125]
5: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00111 (0.00094)	Tok/s 31109 (53264)	Loss/tok 2.9032 (4.4700)	Learning Rate [0.00125]
12: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00097)	Tok/s 32708 (53796)	Loss/tok 3.2753 (4.4754)	Learning Rate [0.00125]
7: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00096)	Tok/s 31135 (53410)	Loss/tok 2.9661 (4.4697)	Learning Rate [0.00125]
11: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00091)	Tok/s 32590 (53694)	Loss/tok 3.0008 (4.4742)	Learning Rate [0.00125]
10: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00096)	Tok/s 31227 (53619)	Loss/tok 3.1131 (4.4730)	Learning Rate [0.00125]
8: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00094)	Tok/s 31124 (53487)	Loss/tok 2.9837 (4.4649)	Learning Rate [0.00125]
9: TRAIN [0][2540/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00092)	Tok/s 31170 (53548)	Loss/tok 2.9632 (4.4706)	Learning Rate [0.00125]
12: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00085 (0.00097)	Tok/s 68021 (53797)	Loss/tok 3.4984 (4.4716)	Learning Rate [0.00125]
13: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00096)	Tok/s 67928 (53893)	Loss/tok 3.5596 (4.4664)	Learning Rate [0.00125]
11: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00091)	Tok/s 67996 (53694)	Loss/tok 3.7640 (4.4710)	Learning Rate [0.00125]
9: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00081 (0.00092)	Tok/s 68075 (53549)	Loss/tok 3.7817 (4.4670)	Learning Rate [0.00125]
10: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00096)	Tok/s 68024 (53619)	Loss/tok 3.8974 (4.4696)	Learning Rate [0.00125]
14: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00086 (0.00096)	Tok/s 67917 (53993)	Loss/tok 3.7600 (4.4714)	Learning Rate [0.00125]
8: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00084 (0.00094)	Tok/s 68075 (53489)	Loss/tok 3.9441 (4.4613)	Learning Rate [0.00125]
15: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00092)	Tok/s 67944 (54101)	Loss/tok 3.6137 (4.4637)	Learning Rate [0.00125]
0: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00097)	Tok/s 67055 (52805)	Loss/tok 3.6122 (4.4734)	Learning Rate [0.00125]
1: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00094)	Tok/s 67068 (52901)	Loss/tok 3.5806 (4.4681)	Learning Rate [0.00125]
6: TRAIN [0][2550/3416]	Time 0.070 (0.058)	Data 0.00078 (0.00094)	Tok/s 67188 (53335)	Loss/tok 3.6540 (4.4666)	Learning Rate [0.00125]
7: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00096)	Tok/s 67687 (53411)	Loss/tok 3.6891 (4.4664)	Learning Rate [0.00125]
3: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00093)	Tok/s 67047 (53099)	Loss/tok 3.4763 (4.4687)	Learning Rate [0.00125]
4: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00087 (0.00100)	Tok/s 67102 (53182)	Loss/tok 3.9120 (4.4707)	Learning Rate [0.00125]
5: TRAIN [0][2550/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00094)	Tok/s 67431 (53264)	Loss/tok 3.6857 (4.4666)	Learning Rate [0.00125]
2: TRAIN [0][2550/3416]	Time 0.071 (0.058)	Data 0.00088 (0.00100)	Tok/s 67020 (53000)	Loss/tok 3.5808 (4.4657)	Learning Rate [0.00125]
8: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00094)	Tok/s 30919 (53480)	Loss/tok 2.7408 (4.4576)	Learning Rate [0.00125]
9: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00092)	Tok/s 30933 (53541)	Loss/tok 2.9714 (4.4635)	Learning Rate [0.00125]
7: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00096)	Tok/s 30937 (53403)	Loss/tok 3.1697 (4.4632)	Learning Rate [0.00125]
6: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00094)	Tok/s 30920 (53326)	Loss/tok 3.0589 (4.4631)	Learning Rate [0.00125]
10: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00096)	Tok/s 30947 (53611)	Loss/tok 3.0525 (4.4662)	Learning Rate [0.00125]
11: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00091)	Tok/s 30967 (53685)	Loss/tok 2.9920 (4.4677)	Learning Rate [0.00125]
5: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00094)	Tok/s 30971 (53256)	Loss/tok 3.0802 (4.4634)	Learning Rate [0.00125]
4: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00100)	Tok/s 30959 (53174)	Loss/tok 3.0064 (4.4674)	Learning Rate [0.00125]
12: TRAIN [0][2560/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00097)	Tok/s 30990 (53788)	Loss/tok 3.0021 (4.4686)	Learning Rate [0.00125]
3: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00093)	Tok/s 30966 (53092)	Loss/tok 2.9713 (4.4657)	Learning Rate [0.00125]
2: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00100)	Tok/s 30949 (52993)	Loss/tok 3.1289 (4.4622)	Learning Rate [0.00125]
1: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00094)	Tok/s 30956 (52894)	Loss/tok 3.0798 (4.4646)	Learning Rate [0.00125]
14: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00096)	Tok/s 32306 (53984)	Loss/tok 3.2453 (4.4682)	Learning Rate [0.00125]
13: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00096)	Tok/s 32029 (53884)	Loss/tok 2.9423 (4.4632)	Learning Rate [0.00125]
15: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00107 (0.00092)	Tok/s 32323 (54092)	Loss/tok 3.2413 (4.4606)	Learning Rate [0.00125]
0: TRAIN [0][2560/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00097)	Tok/s 30962 (52798)	Loss/tok 2.7226 (4.4702)	Learning Rate [0.00125]
1: TRAIN [0][2570/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00094)	Tok/s 51279 (52884)	Loss/tok 3.3970 (4.4615)	Learning Rate [0.00125]
0: TRAIN [0][2570/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00097)	Tok/s 51223 (52787)	Loss/tok 3.3806 (4.4670)	Learning Rate [0.00125]
2: TRAIN [0][2570/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00100)	Tok/s 51103 (52983)	Loss/tok 3.6467 (4.4591)	Learning Rate [0.00125]
4: TRAIN [0][2570/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00100)	Tok/s 54119 (53164)	Loss/tok 3.2767 (4.4640)	Learning Rate [0.00125]
15: TRAIN [0][2570/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00092)	Tok/s 52560 (54080)	Loss/tok 3.4426 (4.4575)	Learning Rate [0.00125]
3: TRAIN [0][2570/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 50914 (53081)	Loss/tok 3.4997 (4.4624)	Learning Rate [0.00125]
5: TRAIN [0][2570/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00094)	Tok/s 50831 (53245)	Loss/tok 3.2636 (4.4601)	Learning Rate [0.00125]
6: TRAIN [0][2570/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00094)	Tok/s 50804 (53315)	Loss/tok 3.3663 (4.4598)	Learning Rate [0.00125]
14: TRAIN [0][2570/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00096)	Tok/s 51374 (53972)	Loss/tok 3.4293 (4.4649)	Learning Rate [0.00125]
11: TRAIN [0][2570/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00091)	Tok/s 51019 (53674)	Loss/tok 3.3823 (4.4646)	Learning Rate [0.00125]
8: TRAIN [0][2570/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00094)	Tok/s 50938 (53469)	Loss/tok 3.2692 (4.4545)	Learning Rate [0.00125]
13: TRAIN [0][2570/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00096)	Tok/s 51188 (53872)	Loss/tok 3.3131 (4.4602)	Learning Rate [0.00125]
7: TRAIN [0][2570/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00096)	Tok/s 50800 (53391)	Loss/tok 3.6365 (4.4603)	Learning Rate [0.00125]
10: TRAIN [0][2570/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00096)	Tok/s 51008 (53599)	Loss/tok 3.3602 (4.4632)	Learning Rate [0.00125]
12: TRAIN [0][2570/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00096)	Tok/s 51105 (53776)	Loss/tok 3.4716 (4.4653)	Learning Rate [0.00125]
9: TRAIN [0][2570/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00092)	Tok/s 50827 (53529)	Loss/tok 3.4944 (4.4605)	Learning Rate [0.00125]
13: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00096)	Tok/s 42361 (53883)	Loss/tok 3.1341 (4.4565)	Learning Rate [0.00125]
12: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00096)	Tok/s 41227 (53786)	Loss/tok 3.2546 (4.4614)	Learning Rate [0.00125]
0: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00097)	Tok/s 41107 (52799)	Loss/tok 3.3678 (4.4637)	Learning Rate [0.00125]
11: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00091)	Tok/s 41007 (53683)	Loss/tok 3.4569 (4.4607)	Learning Rate [0.00125]
14: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00096)	Tok/s 42344 (53982)	Loss/tok 3.3008 (4.4611)	Learning Rate [0.00125]
15: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 42352 (54090)	Loss/tok 3.5351 (4.4540)	Learning Rate [0.00125]
9: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00092)	Tok/s 41028 (53538)	Loss/tok 3.5730 (4.4569)	Learning Rate [0.00125]
10: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00096)	Tok/s 41029 (53609)	Loss/tok 3.0783 (4.4595)	Learning Rate [0.00125]
1: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00094)	Tok/s 41036 (52895)	Loss/tok 3.1254 (4.4575)	Learning Rate [0.00125]
8: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00094)	Tok/s 41050 (53478)	Loss/tok 3.4957 (4.4508)	Learning Rate [0.00125]
6: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00094)	Tok/s 41098 (53325)	Loss/tok 3.5404 (4.4559)	Learning Rate [0.00125]
2: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00100)	Tok/s 41076 (52993)	Loss/tok 3.4846 (4.4553)	Learning Rate [0.00125]
4: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00100)	Tok/s 41098 (53175)	Loss/tok 3.2447 (4.4604)	Learning Rate [0.00125]
3: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00108 (0.00093)	Tok/s 41027 (53092)	Loss/tok 3.3798 (4.4588)	Learning Rate [0.00125]
7: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00096)	Tok/s 40995 (53401)	Loss/tok 3.2849 (4.4565)	Learning Rate [0.00125]
5: TRAIN [0][2580/3416]	Time 0.048 (0.058)	Data 0.00474 (0.00095)	Tok/s 41044 (53256)	Loss/tok 3.1483 (4.4564)	Learning Rate [0.00125]
14: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00096)	Tok/s 39804 (54006)	Loss/tok 3.2737 (4.4567)	Learning Rate [0.00125]
15: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00092)	Tok/s 39738 (54115)	Loss/tok 3.4316 (4.4496)	Learning Rate [0.00125]
1: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00094)	Tok/s 38338 (52917)	Loss/tok 3.2497 (4.4532)	Learning Rate [0.00125]
0: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00097)	Tok/s 38400 (52820)	Loss/tok 3.4502 (4.4594)	Learning Rate [0.00125]
9: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00092)	Tok/s 39763 (53561)	Loss/tok 3.2749 (4.4528)	Learning Rate [0.00125]
10: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00096)	Tok/s 39874 (53631)	Loss/tok 3.0396 (4.4552)	Learning Rate [0.00125]
2: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00120 (0.00100)	Tok/s 38633 (53015)	Loss/tok 3.1228 (4.4512)	Learning Rate [0.00125]
11: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00091)	Tok/s 39721 (53706)	Loss/tok 3.0921 (4.4566)	Learning Rate [0.00125]
13: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00096)	Tok/s 39806 (53905)	Loss/tok 3.2708 (4.4523)	Learning Rate [0.00125]
3: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00093)	Tok/s 38187 (53114)	Loss/tok 3.3243 (4.4546)	Learning Rate [0.00125]
12: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00096)	Tok/s 39776 (53809)	Loss/tok 3.2051 (4.4573)	Learning Rate [0.00125]
7: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00096)	Tok/s 39588 (53424)	Loss/tok 3.1899 (4.4519)	Learning Rate [0.00125]
8: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00094)	Tok/s 39639 (53501)	Loss/tok 3.5141 (4.4468)	Learning Rate [0.00125]
6: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00094)	Tok/s 38231 (53347)	Loss/tok 3.2077 (4.4517)	Learning Rate [0.00125]
5: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00095)	Tok/s 38163 (53278)	Loss/tok 3.1615 (4.4520)	Learning Rate [0.00125]
4: TRAIN [0][2590/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00100)	Tok/s 38119 (53197)	Loss/tok 3.6671 (4.4560)	Learning Rate [0.00125]
10: Upscaling, new scale: 1024.0
9: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
3: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00088 (0.00093)	Tok/s 26941 (53094)	Loss/tok 2.8820 (4.4516)	Learning Rate [0.00125]
6: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00085 (0.00094)	Tok/s 27121 (53327)	Loss/tok 2.8404 (4.4488)	Learning Rate [0.00125]
5: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00096 (0.00095)	Tok/s 26839 (53257)	Loss/tok 2.6464 (4.4487)	Learning Rate [0.00125]
4: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00096 (0.00100)	Tok/s 26912 (53176)	Loss/tok 2.6619 (4.4528)	Learning Rate [0.00125]
2: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00104 (0.00100)	Tok/s 25452 (52995)	Loss/tok 2.5160 (4.4481)	Learning Rate [0.00125]
1: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00094 (0.00094)	Tok/s 25260 (52896)	Loss/tok 2.3800 (4.4501)	Learning Rate [0.00125]
0: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00100 (0.00097)	Tok/s 25234 (52800)	Loss/tok 2.3613 (4.4563)	Learning Rate [0.00125]
7: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00101 (0.00096)	Tok/s 28347 (53404)	Loss/tok 2.5440 (4.4487)	Learning Rate [0.00125]
15: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00095 (0.00092)	Tok/s 30236 (54095)	Loss/tok 2.6473 (4.4464)	Learning Rate [0.00125]
9: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00095 (0.00092)	Tok/s 28359 (53541)	Loss/tok 2.8157 (4.4497)	Learning Rate [0.00125]
11: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00091 (0.00091)	Tok/s 28417 (53686)	Loss/tok 2.4954 (4.4535)	Learning Rate [0.00125]
14: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00083 (0.00096)	Tok/s 30210 (53986)	Loss/tok 2.5172 (4.4536)	Learning Rate [0.00125]
8: TRAIN [0][2600/3416]	Time 0.039 (0.058)	Data 0.00093 (0.00094)	Tok/s 28254 (53481)	Loss/tok 2.4971 (4.4434)	Learning Rate [0.00125]
10: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00091 (0.00096)	Tok/s 28375 (53611)	Loss/tok 2.6109 (4.4522)	Learning Rate [0.00125]
13: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00105 (0.00096)	Tok/s 30123 (53886)	Loss/tok 2.7981 (4.4492)	Learning Rate [0.00125]
12: TRAIN [0][2600/3416]	Time 0.038 (0.058)	Data 0.00090 (0.00096)	Tok/s 29052 (53789)	Loss/tok 2.6269 (4.4540)	Learning Rate [0.00125]
13: TRAIN [0][2610/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00096)	Tok/s 38638 (53875)	Loss/tok 3.3582 (4.4461)	Learning Rate [0.00125]
12: TRAIN [0][2610/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00096)	Tok/s 38645 (53778)	Loss/tok 3.2418 (4.4506)	Learning Rate [0.00125]
14: TRAIN [0][2610/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00096)	Tok/s 38544 (53975)	Loss/tok 3.3774 (4.4506)	Learning Rate [0.00125]
11: TRAIN [0][2610/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00091)	Tok/s 38475 (53675)	Loss/tok 3.1782 (4.4504)	Learning Rate [0.00125]
15: TRAIN [0][2610/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 38455 (54084)	Loss/tok 3.1119 (4.4431)	Learning Rate [0.00125]
0: TRAIN [0][2610/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00097)	Tok/s 37113 (52789)	Loss/tok 3.5349 (4.4531)	Learning Rate [0.00125]
10: TRAIN [0][2610/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00096)	Tok/s 37366 (53599)	Loss/tok 3.3449 (4.4491)	Learning Rate [0.00125]
9: TRAIN [0][2610/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00092)	Tok/s 37338 (53529)	Loss/tok 2.9337 (4.4467)	Learning Rate [0.00125]
1: TRAIN [0][2610/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00094)	Tok/s 37029 (52885)	Loss/tok 3.4955 (4.4467)	Learning Rate [0.00125]
8: TRAIN [0][2610/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00094)	Tok/s 37233 (53469)	Loss/tok 3.3411 (4.4403)	Learning Rate [0.00125]
2: TRAIN [0][2610/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00100)	Tok/s 36954 (52984)	Loss/tok 3.1731 (4.4451)	Learning Rate [0.00125]
6: TRAIN [0][2610/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00094)	Tok/s 37084 (53315)	Loss/tok 3.2338 (4.4456)	Learning Rate [0.00125]
3: TRAIN [0][2610/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00093)	Tok/s 36976 (53082)	Loss/tok 3.3057 (4.4484)	Learning Rate [0.00125]
7: TRAIN [0][2610/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00096)	Tok/s 37167 (53392)	Loss/tok 3.3344 (4.4455)	Learning Rate [0.00125]
4: TRAIN [0][2610/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00100)	Tok/s 36960 (53165)	Loss/tok 3.0459 (4.4495)	Learning Rate [0.00125]
5: TRAIN [0][2610/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00095)	Tok/s 37040 (53245)	Loss/tok 3.5277 (4.4458)	Learning Rate [0.00125]
13: TRAIN [0][2620/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00096)	Tok/s 35116 (53869)	Loss/tok 3.2235 (4.4429)	Learning Rate [0.00125]
11: TRAIN [0][2620/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00091)	Tok/s 34075 (53669)	Loss/tok 3.1163 (4.4474)	Learning Rate [0.00125]
12: TRAIN [0][2620/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00096)	Tok/s 35118 (53773)	Loss/tok 3.3244 (4.4475)	Learning Rate [0.00125]
14: TRAIN [0][2620/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00096)	Tok/s 34985 (53970)	Loss/tok 3.1415 (4.4475)	Learning Rate [0.00125]
15: TRAIN [0][2620/3416]	Time 0.051 (0.058)	Data 0.00080 (0.00092)	Tok/s 34923 (54077)	Loss/tok 3.1848 (4.4400)	Learning Rate [0.00125]
0: TRAIN [0][2620/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00097)	Tok/s 33638 (52784)	Loss/tok 3.3948 (4.4498)	Learning Rate [0.00125]
10: TRAIN [0][2620/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00096)	Tok/s 33850 (53593)	Loss/tok 3.0712 (4.4460)	Learning Rate [0.00125]
1: TRAIN [0][2620/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00094)	Tok/s 33512 (52880)	Loss/tok 3.2610 (4.4435)	Learning Rate [0.00125]
8: TRAIN [0][2620/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00094)	Tok/s 33732 (53463)	Loss/tok 3.1583 (4.4374)	Learning Rate [0.00125]
6: TRAIN [0][2620/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00094)	Tok/s 33563 (53309)	Loss/tok 3.4049 (4.4423)	Learning Rate [0.00125]
7: TRAIN [0][2620/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00096)	Tok/s 33641 (53386)	Loss/tok 3.1158 (4.4423)	Learning Rate [0.00125]
3: TRAIN [0][2620/3416]	Time 0.052 (0.058)	Data 0.00082 (0.00093)	Tok/s 33452 (53077)	Loss/tok 3.1697 (4.4449)	Learning Rate [0.00125]
5: TRAIN [0][2620/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00095)	Tok/s 33505 (53239)	Loss/tok 3.2709 (4.4425)	Learning Rate [0.00125]
4: TRAIN [0][2620/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00100)	Tok/s 33478 (53159)	Loss/tok 3.4808 (4.4464)	Learning Rate [0.00125]
9: TRAIN [0][2620/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00092)	Tok/s 33704 (53523)	Loss/tok 3.2288 (4.4434)	Learning Rate [0.00125]
2: TRAIN [0][2620/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00100)	Tok/s 33249 (52978)	Loss/tok 3.3480 (4.4417)	Learning Rate [0.00125]
15: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00092)	Tok/s 51480 (54064)	Loss/tok 3.4795 (4.4369)	Learning Rate [0.00125]
14: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00096)	Tok/s 51493 (53956)	Loss/tok 3.2768 (4.4442)	Learning Rate [0.00125]
1: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00094)	Tok/s 51285 (52865)	Loss/tok 3.5353 (4.4404)	Learning Rate [0.00125]
0: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00097)	Tok/s 51363 (52769)	Loss/tok 3.7550 (4.4466)	Learning Rate [0.00125]
13: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00096 (0.00096)	Tok/s 51490 (53855)	Loss/tok 3.6500 (4.4399)	Learning Rate [0.00125]
11: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00078 (0.00091)	Tok/s 51416 (53655)	Loss/tok 3.5009 (4.4442)	Learning Rate [0.00125]
2: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00100)	Tok/s 51133 (52963)	Loss/tok 3.5586 (4.4385)	Learning Rate [0.00125]
3: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00082 (0.00093)	Tok/s 51135 (53062)	Loss/tok 3.3858 (4.4417)	Learning Rate [0.00125]
12: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00096)	Tok/s 51466 (53758)	Loss/tok 3.3237 (4.4441)	Learning Rate [0.00125]
4: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00100 (0.00100)	Tok/s 51215 (53144)	Loss/tok 3.7250 (4.4433)	Learning Rate [0.00125]
9: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00092)	Tok/s 51484 (53509)	Loss/tok 3.7237 (4.4403)	Learning Rate [0.00125]
5: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00095)	Tok/s 51168 (53225)	Loss/tok 3.4963 (4.4391)	Learning Rate [0.00125]
10: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00096)	Tok/s 51423 (53579)	Loss/tok 3.3468 (4.4426)	Learning Rate [0.00125]
6: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00082 (0.00094)	Tok/s 51164 (53295)	Loss/tok 3.8584 (4.4393)	Learning Rate [0.00125]
8: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00094)	Tok/s 51206 (53449)	Loss/tok 3.4681 (4.4341)	Learning Rate [0.00125]
7: TRAIN [0][2630/3416]	Time 0.056 (0.058)	Data 0.00086 (0.00096)	Tok/s 51230 (53373)	Loss/tok 3.6031 (4.4391)	Learning Rate [0.00125]
14: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00096)	Tok/s 57132 (53972)	Loss/tok 3.6816 (4.4403)	Learning Rate [0.00125]
13: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00105 (0.00096)	Tok/s 57168 (53871)	Loss/tok 3.5674 (4.4363)	Learning Rate [0.00125]
15: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00092)	Tok/s 57043 (54081)	Loss/tok 3.7701 (4.4330)	Learning Rate [0.00125]
0: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00097)	Tok/s 55946 (52780)	Loss/tok 3.7392 (4.4431)	Learning Rate [0.00125]
12: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00096)	Tok/s 57123 (53774)	Loss/tok 3.4071 (4.4399)	Learning Rate [0.00125]
11: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00091)	Tok/s 57079 (53671)	Loss/tok 3.8017 (4.4407)	Learning Rate [0.00125]
1: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00094)	Tok/s 55808 (52876)	Loss/tok 3.6145 (4.4366)	Learning Rate [0.00125]
2: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00100)	Tok/s 55755 (52976)	Loss/tok 3.7335 (4.4349)	Learning Rate [0.00125]
10: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00096)	Tok/s 56973 (53595)	Loss/tok 3.6292 (4.4383)	Learning Rate [0.00125]
3: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00093)	Tok/s 55634 (53075)	Loss/tok 3.7686 (4.4380)	Learning Rate [0.00125]
9: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00092)	Tok/s 56885 (53525)	Loss/tok 3.7112 (4.4369)	Learning Rate [0.00125]
8: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00103 (0.00094)	Tok/s 56781 (53465)	Loss/tok 3.7670 (4.4308)	Learning Rate [0.00125]
6: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00094)	Tok/s 55648 (53309)	Loss/tok 3.6409 (4.4356)	Learning Rate [0.00125]
7: TRAIN [0][2640/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00096)	Tok/s 56712 (53388)	Loss/tok 3.7268 (4.4352)	Learning Rate [0.00125]
5: TRAIN [0][2640/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00095)	Tok/s 55550 (53239)	Loss/tok 3.5302 (4.4357)	Learning Rate [0.00125]
4: TRAIN [0][2640/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00100)	Tok/s 55533 (53158)	Loss/tok 3.4440 (4.4394)	Learning Rate [0.00125]
6: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00094)	Tok/s 54483 (53316)	Loss/tok 3.5547 (4.4320)	Learning Rate [0.00125]
3: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00083 (0.00093)	Tok/s 54358 (53083)	Loss/tok 3.7126 (4.4350)	Learning Rate [0.00125]
5: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00095)	Tok/s 54446 (53246)	Loss/tok 3.7238 (4.4322)	Learning Rate [0.00125]
2: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00100)	Tok/s 54264 (52984)	Loss/tok 3.6157 (4.4316)	Learning Rate [0.00125]
1: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00094)	Tok/s 54271 (52885)	Loss/tok 3.6809 (4.4330)	Learning Rate [0.00125]
0: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00097)	Tok/s 54286 (52789)	Loss/tok 3.4562 (4.4392)	Learning Rate [0.00125]
7: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00096)	Tok/s 54445 (53395)	Loss/tok 3.7071 (4.4318)	Learning Rate [0.00125]
8: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00094)	Tok/s 54477 (53472)	Loss/tok 3.4161 (4.4274)	Learning Rate [0.00125]
4: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00100)	Tok/s 54405 (53166)	Loss/tok 3.7672 (4.4357)	Learning Rate [0.00125]
9: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00092)	Tok/s 54551 (53531)	Loss/tok 3.5938 (4.4332)	Learning Rate [0.00125]
15: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00083 (0.00092)	Tok/s 55355 (54087)	Loss/tok 3.9636 (4.4296)	Learning Rate [0.00125]
14: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00096)	Tok/s 54657 (53979)	Loss/tok 3.4321 (4.4368)	Learning Rate [0.00125]
11: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00079 (0.00091)	Tok/s 54365 (53677)	Loss/tok 3.7555 (4.4372)	Learning Rate [0.00125]
10: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00103 (0.00096)	Tok/s 54425 (53601)	Loss/tok 3.8135 (4.4352)	Learning Rate [0.00125]
13: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00081 (0.00096)	Tok/s 54305 (53878)	Loss/tok 3.6720 (4.4329)	Learning Rate [0.00125]
12: TRAIN [0][2650/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00096)	Tok/s 54307 (53780)	Loss/tok 3.7960 (4.4365)	Learning Rate [0.00125]
2: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00100)	Tok/s 52695 (52965)	Loss/tok 3.5073 (4.4287)	Learning Rate [0.00125]
3: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00079 (0.00093)	Tok/s 52749 (53064)	Loss/tok 3.7067 (4.4322)	Learning Rate [0.00125]
1: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00094)	Tok/s 52616 (52866)	Loss/tok 3.8723 (4.4303)	Learning Rate [0.00125]
4: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00100)	Tok/s 52756 (53147)	Loss/tok 3.8013 (4.4327)	Learning Rate [0.00125]
0: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00097)	Tok/s 52626 (52770)	Loss/tok 3.7319 (4.4363)	Learning Rate [0.00125]
9: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00103 (0.00092)	Tok/s 53913 (53512)	Loss/tok 3.4872 (4.4303)	Learning Rate [0.00125]
5: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00095)	Tok/s 52926 (53227)	Loss/tok 3.5837 (4.4292)	Learning Rate [0.00125]
6: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00094)	Tok/s 53870 (53297)	Loss/tok 3.4355 (4.4291)	Learning Rate [0.00125]
15: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00081 (0.00092)	Tok/s 53758 (54068)	Loss/tok 3.4219 (4.4267)	Learning Rate [0.00125]
8: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00094)	Tok/s 53758 (53453)	Loss/tok 3.9177 (4.4247)	Learning Rate [0.00125]
7: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00096)	Tok/s 53798 (53376)	Loss/tok 3.6256 (4.4289)	Learning Rate [0.00125]
14: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00106 (0.00096)	Tok/s 53740 (53960)	Loss/tok 3.8277 (4.4338)	Learning Rate [0.00125]
11: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00102 (0.00091)	Tok/s 54134 (53658)	Loss/tok 3.6301 (4.4341)	Learning Rate [0.00125]
13: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00096)	Tok/s 53740 (53859)	Loss/tok 3.5447 (4.4298)	Learning Rate [0.00125]
12: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00097)	Tok/s 53712 (53761)	Loss/tok 3.6617 (4.4336)	Learning Rate [0.00125]
10: TRAIN [0][2660/3416]	Time 0.058 (0.058)	Data 0.00117 (0.00096)	Tok/s 53904 (53582)	Loss/tok 3.4368 (4.4324)	Learning Rate [0.00125]
8: TRAIN [0][2670/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00094)	Tok/s 47685 (53453)	Loss/tok 3.2977 (4.4215)	Learning Rate [0.00125]
9: TRAIN [0][2670/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00092)	Tok/s 47619 (53512)	Loss/tok 3.4350 (4.4272)	Learning Rate [0.00125]
7: TRAIN [0][2670/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00096)	Tok/s 47643 (53377)	Loss/tok 3.1817 (4.4259)	Learning Rate [0.00125]
6: TRAIN [0][2670/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00094)	Tok/s 47531 (53298)	Loss/tok 3.1932 (4.4256)	Learning Rate [0.00125]
15: TRAIN [0][2670/3416]	Time 0.045 (0.058)	Data 0.00083 (0.00092)	Tok/s 48678 (54068)	Loss/tok 3.6382 (4.4235)	Learning Rate [0.00125]
0: TRAIN [0][2670/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00097)	Tok/s 47248 (52772)	Loss/tok 3.3439 (4.4333)	Learning Rate [0.00125]
10: TRAIN [0][2670/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00096)	Tok/s 47518 (53582)	Loss/tok 3.3094 (4.4292)	Learning Rate [0.00125]
14: TRAIN [0][2670/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00096)	Tok/s 48702 (53960)	Loss/tok 3.6206 (4.4305)	Learning Rate [0.00125]
1: TRAIN [0][2670/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00094)	Tok/s 47206 (52868)	Loss/tok 3.1976 (4.4272)	Learning Rate [0.00125]
13: TRAIN [0][2670/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00096)	Tok/s 48715 (53859)	Loss/tok 3.4329 (4.4263)	Learning Rate [0.00125]
4: TRAIN [0][2670/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00100)	Tok/s 47285 (53148)	Loss/tok 3.4041 (4.4299)	Learning Rate [0.00125]
2: TRAIN [0][2670/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00100)	Tok/s 47147 (52967)	Loss/tok 3.1496 (4.4257)	Learning Rate [0.00125]
3: TRAIN [0][2670/3416]	Time 0.045 (0.058)	Data 0.00077 (0.00093)	Tok/s 47193 (53065)	Loss/tok 3.3533 (4.4290)	Learning Rate [0.00125]
11: TRAIN [0][2670/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00091)	Tok/s 47387 (53657)	Loss/tok 3.1582 (4.4310)	Learning Rate [0.00125]
12: TRAIN [0][2670/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00097)	Tok/s 48608 (53761)	Loss/tok 3.8301 (4.4307)	Learning Rate [0.00125]
5: TRAIN [0][2670/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00095)	Tok/s 47405 (53228)	Loss/tok 3.3529 (4.4261)	Learning Rate [0.00125]
13: TRAIN [0][2680/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00096)	Tok/s 51899 (53865)	Loss/tok 3.2716 (4.4224)	Learning Rate [0.00125]
12: TRAIN [0][2680/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00097)	Tok/s 51741 (53767)	Loss/tok 3.0690 (4.4272)	Learning Rate [0.00125]
11: TRAIN [0][2680/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00091)	Tok/s 51651 (53663)	Loss/tok 3.6033 (4.4275)	Learning Rate [0.00125]
14: TRAIN [0][2680/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00096)	Tok/s 51856 (53966)	Loss/tok 3.8879 (4.4270)	Learning Rate [0.00125]
0: TRAIN [0][2680/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00097)	Tok/s 50440 (52776)	Loss/tok 3.6366 (4.4299)	Learning Rate [0.00125]
9: TRAIN [0][2680/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00092)	Tok/s 51358 (53517)	Loss/tok 3.5083 (4.4236)	Learning Rate [0.00125]
10: TRAIN [0][2680/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00096)	Tok/s 51564 (53587)	Loss/tok 3.6157 (4.4258)	Learning Rate [0.00125]
1: TRAIN [0][2680/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00094)	Tok/s 50315 (52871)	Loss/tok 3.3064 (4.4236)	Learning Rate [0.00125]
15: TRAIN [0][2680/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00092)	Tok/s 51783 (54073)	Loss/tok 3.7208 (4.4201)	Learning Rate [0.00125]
8: TRAIN [0][2680/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00094)	Tok/s 51247 (53458)	Loss/tok 3.4717 (4.4181)	Learning Rate [0.00125]
2: TRAIN [0][2680/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00100)	Tok/s 50220 (52970)	Loss/tok 3.4247 (4.4222)	Learning Rate [0.00125]
7: TRAIN [0][2680/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00096)	Tok/s 51171 (53381)	Loss/tok 3.3657 (4.4225)	Learning Rate [0.00125]
3: TRAIN [0][2680/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00093)	Tok/s 50141 (53069)	Loss/tok 3.4410 (4.4257)	Learning Rate [0.00125]
6: TRAIN [0][2680/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00094)	Tok/s 51172 (53302)	Loss/tok 3.2691 (4.4219)	Learning Rate [0.00125]
5: TRAIN [0][2680/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00095)	Tok/s 51213 (53232)	Loss/tok 3.6159 (4.4227)	Learning Rate [0.00125]
4: TRAIN [0][2680/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00100)	Tok/s 50070 (53152)	Loss/tok 3.3996 (4.4263)	Learning Rate [0.00125]
9: TRAIN [0][2690/3416]	Time 0.061 (0.058)	Data 0.00102 (0.00092)	Tok/s 53294 (53522)	Loss/tok 3.5301 (4.4203)	Learning Rate [0.00125]
11: TRAIN [0][2690/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00091)	Tok/s 53217 (53668)	Loss/tok 3.5962 (4.4240)	Learning Rate [0.00125]
10: TRAIN [0][2690/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00096)	Tok/s 53274 (53592)	Loss/tok 3.6662 (4.4224)	Learning Rate [0.00125]
8: TRAIN [0][2690/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00094)	Tok/s 53259 (53463)	Loss/tok 3.5724 (4.4145)	Learning Rate [0.00125]
12: TRAIN [0][2690/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00097)	Tok/s 53175 (53772)	Loss/tok 3.7470 (4.4235)	Learning Rate [0.00125]
7: TRAIN [0][2690/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00096)	Tok/s 53189 (53387)	Loss/tok 3.4331 (4.4191)	Learning Rate [0.00125]
6: TRAIN [0][2690/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00094)	Tok/s 53050 (53307)	Loss/tok 3.6495 (4.4183)	Learning Rate [0.00125]
13: TRAIN [0][2690/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00096)	Tok/s 53064 (53870)	Loss/tok 3.4557 (4.4185)	Learning Rate [0.00125]
4: TRAIN [0][2690/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00100)	Tok/s 52954 (53156)	Loss/tok 3.7115 (4.4227)	Learning Rate [0.00125]
14: TRAIN [0][2690/3416]	Time 0.062 (0.058)	Data 0.00082 (0.00096)	Tok/s 53974 (53971)	Loss/tok 3.4922 (4.4233)	Learning Rate [0.00125]
5: TRAIN [0][2690/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00095)	Tok/s 52987 (53236)	Loss/tok 3.5690 (4.4192)	Learning Rate [0.00125]
15: TRAIN [0][2690/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00092)	Tok/s 53930 (54079)	Loss/tok 3.7798 (4.4167)	Learning Rate [0.00125]
1: TRAIN [0][2690/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00094)	Tok/s 52793 (52876)	Loss/tok 3.4357 (4.4203)	Learning Rate [0.00125]
0: TRAIN [0][2690/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00097)	Tok/s 52817 (52780)	Loss/tok 3.5541 (4.4264)	Learning Rate [0.00125]
3: TRAIN [0][2690/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00093)	Tok/s 52816 (53073)	Loss/tok 3.3205 (4.4222)	Learning Rate [0.00125]
2: TRAIN [0][2690/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00100)	Tok/s 52720 (52974)	Loss/tok 3.4589 (4.4187)	Learning Rate [0.00125]
1: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00094)	Tok/s 51611 (52865)	Loss/tok 3.6490 (4.4173)	Learning Rate [0.00125]
3: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00093)	Tok/s 51406 (53062)	Loss/tok 3.4703 (4.4192)	Learning Rate [0.00125]
0: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00097)	Tok/s 51586 (52770)	Loss/tok 3.5226 (4.4231)	Learning Rate [0.00125]
4: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00100)	Tok/s 51366 (53146)	Loss/tok 3.4602 (4.4199)	Learning Rate [0.00125]
2: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00100)	Tok/s 51599 (52964)	Loss/tok 3.4023 (4.4156)	Learning Rate [0.00125]
15: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00092)	Tok/s 52801 (54068)	Loss/tok 3.4639 (4.4136)	Learning Rate [0.00125]
5: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00095)	Tok/s 51207 (53226)	Loss/tok 3.4054 (4.4162)	Learning Rate [0.00125]
6: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00094)	Tok/s 51104 (53296)	Loss/tok 3.4167 (4.4152)	Learning Rate [0.00125]
7: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00096)	Tok/s 51027 (53376)	Loss/tok 3.2421 (4.4161)	Learning Rate [0.00125]
12: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00097)	Tok/s 52589 (53761)	Loss/tok 3.2645 (4.4203)	Learning Rate [0.00125]
8: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00094)	Tok/s 51050 (53452)	Loss/tok 3.3614 (4.4116)	Learning Rate [0.00125]
11: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00091)	Tok/s 51194 (53657)	Loss/tok 3.0432 (4.4207)	Learning Rate [0.00125]
13: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00096)	Tok/s 52659 (53859)	Loss/tok 3.5603 (4.4152)	Learning Rate [0.00125]
9: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00092)	Tok/s 51022 (53511)	Loss/tok 3.5949 (4.4170)	Learning Rate [0.00125]
14: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00096)	Tok/s 52752 (53960)	Loss/tok 3.4223 (4.4205)	Learning Rate [0.00125]
10: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00096)	Tok/s 51064 (53581)	Loss/tok 3.5076 (4.4192)	Learning Rate [0.00125]
6: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00094)	Tok/s 79019 (53316)	Loss/tok 3.4054 (4.4119)	Learning Rate [0.00125]
7: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 78972 (53396)	Loss/tok 3.5122 (4.4123)	Learning Rate [0.00125]
13: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 79594 (53878)	Loss/tok 3.2981 (4.4112)	Learning Rate [0.00125]
5: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00095)	Tok/s 79039 (53245)	Loss/tok 3.4919 (4.4126)	Learning Rate [0.00125]
14: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00096)	Tok/s 79706 (53979)	Loss/tok 3.4235 (4.4170)	Learning Rate [0.00125]
11: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 79600 (53676)	Loss/tok 3.3790 (4.4175)	Learning Rate [0.00125]
8: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00094)	Tok/s 78845 (53472)	Loss/tok 3.5443 (4.4078)	Learning Rate [0.00125]
4: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 78891 (53164)	Loss/tok 3.3800 (4.4164)	Learning Rate [0.00125]
12: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 79613 (53781)	Loss/tok 3.5007 (4.4165)	Learning Rate [0.00125]
0: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 77850 (52790)	Loss/tok 3.6335 (4.4198)	Learning Rate [0.00125]
9: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 78816 (53531)	Loss/tok 3.5473 (4.4135)	Learning Rate [0.00125]
3: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 78051 (53081)	Loss/tok 3.7331 (4.4155)	Learning Rate [0.00125]
1: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00094)	Tok/s 77824 (52884)	Loss/tok 3.5493 (4.4135)	Learning Rate [0.00125]
10: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 78716 (53600)	Loss/tok 3.6045 (4.4155)	Learning Rate [0.00125]
2: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 77933 (52982)	Loss/tok 3.5962 (4.4123)	Learning Rate [0.00125]
15: TRAIN [0][2710/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 79423 (54087)	Loss/tok 3.3979 (4.4099)	Learning Rate [0.00125]
1: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00094)	Tok/s 50715 (52903)	Loss/tok 3.3618 (4.4100)	Learning Rate [0.00125]
0: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00097)	Tok/s 50812 (52808)	Loss/tok 3.3257 (4.4166)	Learning Rate [0.00125]
2: TRAIN [0][2720/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00100)	Tok/s 51759 (53001)	Loss/tok 3.1897 (4.4087)	Learning Rate [0.00125]
3: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00093)	Tok/s 50631 (53099)	Loss/tok 3.5985 (4.4120)	Learning Rate [0.00125]
15: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00092)	Tok/s 52077 (54104)	Loss/tok 3.5059 (4.4066)	Learning Rate [0.00125]
14: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00096)	Tok/s 51901 (53996)	Loss/tok 3.3697 (4.4134)	Learning Rate [0.00125]
4: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00100)	Tok/s 50604 (53182)	Loss/tok 3.3145 (4.4126)	Learning Rate [0.00125]
5: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00095)	Tok/s 50613 (53263)	Loss/tok 3.2451 (4.4091)	Learning Rate [0.00125]
13: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00096)	Tok/s 50776 (53895)	Loss/tok 3.2720 (4.4082)	Learning Rate [0.00125]
6: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00094)	Tok/s 50630 (53334)	Loss/tok 3.3199 (4.4084)	Learning Rate [0.00125]
11: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00091)	Tok/s 50737 (53694)	Loss/tok 3.4572 (4.4140)	Learning Rate [0.00125]
12: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00097)	Tok/s 50765 (53798)	Loss/tok 3.4088 (4.4130)	Learning Rate [0.00125]
9: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00093)	Tok/s 50737 (53549)	Loss/tok 3.4739 (4.4105)	Learning Rate [0.00125]
7: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00096)	Tok/s 50654 (53414)	Loss/tok 3.3945 (4.4086)	Learning Rate [0.00125]
10: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00096)	Tok/s 50793 (53618)	Loss/tok 3.3196 (4.4122)	Learning Rate [0.00125]
8: TRAIN [0][2720/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00094)	Tok/s 50620 (53490)	Loss/tok 3.4913 (4.4046)	Learning Rate [0.00125]
12: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
6: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00094)	Tok/s 61328 (53355)	Loss/tok 3.4505 (4.4047)	Learning Rate [0.00125]
5: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00095)	Tok/s 61299 (53285)	Loss/tok 3.8760 (4.4057)	Learning Rate [0.00125]
4: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00100)	Tok/s 61216 (53205)	Loss/tok 3.5443 (4.4090)	Learning Rate [0.00125]
7: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00096)	Tok/s 61336 (53435)	Loss/tok 3.5058 (4.4049)	Learning Rate [0.00125]
8: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00094)	Tok/s 61277 (53511)	Loss/tok 3.8278 (4.4013)	Learning Rate [0.00125]
3: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00093)	Tok/s 61292 (53121)	Loss/tok 3.7342 (4.4083)	Learning Rate [0.00125]
9: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00093)	Tok/s 61346 (53570)	Loss/tok 3.9617 (4.4070)	Learning Rate [0.00125]
2: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00100)	Tok/s 61248 (53023)	Loss/tok 3.7244 (4.4053)	Learning Rate [0.00125]
1: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00110 (0.00094)	Tok/s 61243 (52925)	Loss/tok 3.6526 (4.4065)	Learning Rate [0.00125]
0: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00097)	Tok/s 61244 (52831)	Loss/tok 3.6136 (4.4129)	Learning Rate [0.00125]
11: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00091)	Tok/s 61373 (53715)	Loss/tok 3.8415 (4.4105)	Learning Rate [0.00125]
10: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00096)	Tok/s 61344 (53639)	Loss/tok 3.4943 (4.4082)	Learning Rate [0.00125]
15: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00092)	Tok/s 61505 (54124)	Loss/tok 3.5435 (4.4032)	Learning Rate [0.00125]
14: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00096)	Tok/s 61307 (54017)	Loss/tok 3.7407 (4.4102)	Learning Rate [0.00125]
13: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00096)	Tok/s 61310 (53916)	Loss/tok 3.6766 (4.4047)	Learning Rate [0.00125]
12: TRAIN [0][2730/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00097)	Tok/s 61362 (53819)	Loss/tok 3.7267 (4.4096)	Learning Rate [0.00125]
1: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00088 (0.00094)	Tok/s 28234 (52920)	Loss/tok 2.6876 (4.4034)	Learning Rate [0.00125]
0: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00094 (0.00097)	Tok/s 28219 (52826)	Loss/tok 2.7830 (4.4097)	Learning Rate [0.00125]
3: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00083 (0.00093)	Tok/s 28288 (53116)	Loss/tok 2.6362 (4.4055)	Learning Rate [0.00125]
15: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00092)	Tok/s 31269 (54121)	Loss/tok 2.9479 (4.4002)	Learning Rate [0.00125]
14: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00088 (0.00096)	Tok/s 30455 (54013)	Loss/tok 3.0226 (4.4074)	Learning Rate [0.00125]
11: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00090 (0.00091)	Tok/s 29606 (53711)	Loss/tok 2.8738 (4.4074)	Learning Rate [0.00125]
12: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00093 (0.00097)	Tok/s 29625 (53814)	Loss/tok 2.6237 (4.4066)	Learning Rate [0.00125]
5: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00090 (0.00095)	Tok/s 28571 (53279)	Loss/tok 2.9362 (4.4025)	Learning Rate [0.00125]
13: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00092 (0.00096)	Tok/s 29569 (53911)	Loss/tok 2.7901 (4.4015)	Learning Rate [0.00125]
2: TRAIN [0][2740/3416]	Time 0.040 (0.058)	Data 0.00104 (0.00100)	Tok/s 28750 (53018)	Loss/tok 2.6220 (4.4021)	Learning Rate [0.00125]
6: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00095 (0.00094)	Tok/s 29652 (53351)	Loss/tok 3.0078 (4.4016)	Learning Rate [0.00125]
7: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00088 (0.00096)	Tok/s 29563 (53431)	Loss/tok 2.6567 (4.4014)	Learning Rate [0.00125]
9: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00105 (0.00093)	Tok/s 29545 (53566)	Loss/tok 2.7138 (4.4037)	Learning Rate [0.00125]
8: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00094)	Tok/s 29506 (53507)	Loss/tok 2.7631 (4.3981)	Learning Rate [0.00125]
10: TRAIN [0][2740/3416]	Time 0.041 (0.058)	Data 0.00103 (0.00096)	Tok/s 29563 (53636)	Loss/tok 2.7544 (4.4052)	Learning Rate [0.00125]
4: TRAIN [0][2740/3416]	Time 0.040 (0.058)	Data 0.00114 (0.00100)	Tok/s 28710 (53199)	Loss/tok 2.7130 (4.4060)	Learning Rate [0.00125]
6: TRAIN [0][2750/3416]	Time 0.064 (0.058)	Data 0.00084 (0.00094)	Tok/s 54026 (53330)	Loss/tok 3.5836 (4.3992)	Learning Rate [0.00125]
5: TRAIN [0][2750/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00095)	Tok/s 53981 (53259)	Loss/tok 3.5278 (4.3996)	Learning Rate [0.00125]
7: TRAIN [0][2750/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00096)	Tok/s 53933 (53411)	Loss/tok 3.5251 (4.3988)	Learning Rate [0.00125]
8: TRAIN [0][2750/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00094)	Tok/s 53820 (53487)	Loss/tok 3.4702 (4.3956)	Learning Rate [0.00125]
4: TRAIN [0][2750/3416]	Time 0.064 (0.058)	Data 0.00100 (0.00100)	Tok/s 53873 (53179)	Loss/tok 3.5746 (4.4034)	Learning Rate [0.00125]
3: TRAIN [0][2750/3416]	Time 0.064 (0.058)	Data 0.00080 (0.00093)	Tok/s 53797 (53095)	Loss/tok 3.5405 (4.4027)	Learning Rate [0.00125]
9: TRAIN [0][2750/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00093)	Tok/s 53752 (53546)	Loss/tok 3.7247 (4.4011)	Learning Rate [0.00125]
2: TRAIN [0][2750/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00100)	Tok/s 53679 (52997)	Loss/tok 3.4161 (4.3996)	Learning Rate [0.00125]
1: TRAIN [0][2750/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00094)	Tok/s 53590 (52900)	Loss/tok 3.6048 (4.4005)	Learning Rate [0.00125]
10: TRAIN [0][2750/3416]	Time 0.064 (0.058)	Data 0.00102 (0.00096)	Tok/s 53649 (53615)	Loss/tok 3.7167 (4.4024)	Learning Rate [0.00125]
11: TRAIN [0][2750/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00091)	Tok/s 53535 (53690)	Loss/tok 3.8289 (4.4050)	Learning Rate [0.00125]
0: TRAIN [0][2750/3416]	Time 0.065 (0.058)	Data 0.00083 (0.00097)	Tok/s 53499 (52805)	Loss/tok 3.8021 (4.4071)	Learning Rate [0.00125]
15: TRAIN [0][2750/3416]	Time 0.065 (0.058)	Data 0.00077 (0.00092)	Tok/s 54420 (54100)	Loss/tok 3.6816 (4.3976)	Learning Rate [0.00125]
12: TRAIN [0][2750/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00097)	Tok/s 53424 (53794)	Loss/tok 3.5780 (4.4040)	Learning Rate [0.00125]
14: TRAIN [0][2750/3416]	Time 0.065 (0.058)	Data 0.00082 (0.00096)	Tok/s 54329 (53993)	Loss/tok 3.8764 (4.4049)	Learning Rate [0.00125]
13: TRAIN [0][2750/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00096)	Tok/s 53386 (53891)	Loss/tok 3.6738 (4.3986)	Learning Rate [0.00125]
6: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00086 (0.00094)	Tok/s 30298 (53324)	Loss/tok 2.7385 (4.3964)	Learning Rate [0.00125]
5: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00089 (0.00095)	Tok/s 30296 (53253)	Loss/tok 2.8568 (4.3968)	Learning Rate [0.00125]
7: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00090 (0.00096)	Tok/s 30211 (53404)	Loss/tok 2.7220 (4.3960)	Learning Rate [0.00125]
4: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00092 (0.00100)	Tok/s 29563 (53173)	Loss/tok 2.6756 (4.4004)	Learning Rate [0.00125]
8: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00086 (0.00094)	Tok/s 30105 (53481)	Loss/tok 2.6958 (4.3924)	Learning Rate [0.00125]
3: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00084 (0.00093)	Tok/s 28703 (53089)	Loss/tok 2.7761 (4.3998)	Learning Rate [0.00125]
9: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00097 (0.00093)	Tok/s 30070 (53540)	Loss/tok 2.9064 (4.3982)	Learning Rate [0.00125]
2: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00097 (0.00100)	Tok/s 28705 (52991)	Loss/tok 2.5425 (4.3968)	Learning Rate [0.00125]
1: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00092 (0.00094)	Tok/s 28695 (52894)	Loss/tok 2.6476 (4.3979)	Learning Rate [0.00125]
10: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00110 (0.00096)	Tok/s 30036 (53609)	Loss/tok 2.7625 (4.3993)	Learning Rate [0.00125]
11: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00081 (0.00091)	Tok/s 30084 (53684)	Loss/tok 2.8694 (4.4023)	Learning Rate [0.00125]
0: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00097)	Tok/s 28679 (52800)	Loss/tok 2.5705 (4.4044)	Learning Rate [0.00125]
15: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00079 (0.00092)	Tok/s 31818 (54094)	Loss/tok 2.8535 (4.3948)	Learning Rate [0.00125]
14: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00090 (0.00096)	Tok/s 31731 (53987)	Loss/tok 3.1161 (4.4021)	Learning Rate [0.00125]
13: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00096)	Tok/s 31654 (53885)	Loss/tok 3.1436 (4.3959)	Learning Rate [0.00125]
12: TRAIN [0][2760/3416]	Time 0.040 (0.058)	Data 0.00097 (0.00097)	Tok/s 30470 (53788)	Loss/tok 3.0526 (4.4010)	Learning Rate [0.00125]
14: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00096)	Tok/s 52741 (53974)	Loss/tok 3.3606 (4.3995)	Learning Rate [0.00125]
15: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00092)	Tok/s 52629 (54081)	Loss/tok 3.2658 (4.3919)	Learning Rate [0.00125]
13: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00096)	Tok/s 52742 (53873)	Loss/tok 3.1963 (4.3933)	Learning Rate [0.00125]
0: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00096)	Tok/s 51247 (52788)	Loss/tok 3.6219 (4.4018)	Learning Rate [0.00125]
12: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00097)	Tok/s 52757 (53775)	Loss/tok 3.3089 (4.3981)	Learning Rate [0.00125]
2: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00100)	Tok/s 51353 (52978)	Loss/tok 3.3899 (4.3943)	Learning Rate [0.00125]
11: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00091)	Tok/s 52743 (53671)	Loss/tok 3.6031 (4.3997)	Learning Rate [0.00125]
1: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00094)	Tok/s 51277 (52881)	Loss/tok 3.6369 (4.3953)	Learning Rate [0.00125]
9: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00093)	Tok/s 52740 (53528)	Loss/tok 3.6301 (4.3955)	Learning Rate [0.00125]
3: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 51271 (53076)	Loss/tok 3.3723 (4.3971)	Learning Rate [0.00125]
4: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00100)	Tok/s 51347 (53160)	Loss/tok 3.9456 (4.3977)	Learning Rate [0.00125]
8: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00094)	Tok/s 52715 (53469)	Loss/tok 3.5005 (4.3897)	Learning Rate [0.00125]
6: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00094)	Tok/s 52590 (53312)	Loss/tok 3.5017 (4.3937)	Learning Rate [0.00125]
5: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00095)	Tok/s 51804 (53241)	Loss/tok 3.8369 (4.3944)	Learning Rate [0.00125]
10: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00096)	Tok/s 52462 (53596)	Loss/tok 3.4886 (4.3967)	Learning Rate [0.00125]
7: TRAIN [0][2770/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00096)	Tok/s 52673 (53392)	Loss/tok 3.5341 (4.3932)	Learning Rate [0.00125]
12: Gradient norm: inf
13: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
10: Gradient norm: inf
9: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
0: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
6: Gradient norm: inf
2: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
11: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00091)	Tok/s 61559 (53665)	Loss/tok 3.6782 (4.3970)	Learning Rate [0.00125]
15: TRAIN [0][2780/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 61675 (54075)	Loss/tok 3.7775 (4.3891)	Learning Rate [0.00125]
13: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 61591 (53866)	Loss/tok 3.4888 (4.3902)	Learning Rate [0.00125]
12: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00097)	Tok/s 61643 (53769)	Loss/tok 3.6133 (4.3951)	Learning Rate [0.00125]
0: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00096)	Tok/s 61044 (52782)	Loss/tok 3.8258 (4.3986)	Learning Rate [0.00125]
6: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 61450 (53306)	Loss/tok 3.8152 (4.3909)	Learning Rate [0.00125]
5: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00095)	Tok/s 61479 (53234)	Loss/tok 3.4020 (4.3913)	Learning Rate [0.00125]
14: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 61654 (53968)	Loss/tok 3.9119 (4.3969)	Learning Rate [0.00125]
7: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 61469 (53386)	Loss/tok 3.7198 (4.3904)	Learning Rate [0.00125]
8: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00094)	Tok/s 61410 (53463)	Loss/tok 3.5644 (4.3865)	Learning Rate [0.00125]
4: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00100)	Tok/s 61457 (53153)	Loss/tok 3.5923 (4.3946)	Learning Rate [0.00125]
3: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 61542 (53070)	Loss/tok 3.6392 (4.3941)	Learning Rate [0.00125]
9: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 61411 (53522)	Loss/tok 3.8272 (4.3925)	Learning Rate [0.00125]
1: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00094)	Tok/s 61646 (52876)	Loss/tok 3.6592 (4.3922)	Learning Rate [0.00125]
2: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00100)	Tok/s 61629 (52972)	Loss/tok 3.7432 (4.3913)	Learning Rate [0.00125]
10: TRAIN [0][2780/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 61478 (53590)	Loss/tok 3.9520 (4.3941)	Learning Rate [0.00125]
15: TRAIN [0][2790/3416]	Time 0.059 (0.058)	Data 0.00080 (0.00092)	Tok/s 51797 (54063)	Loss/tok 3.5443 (4.3863)	Learning Rate [0.00125]
0: TRAIN [0][2790/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00096)	Tok/s 50608 (52770)	Loss/tok 3.7830 (4.3957)	Learning Rate [0.00125]
14: TRAIN [0][2790/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00096)	Tok/s 51794 (53956)	Loss/tok 3.2678 (4.3937)	Learning Rate [0.00125]
13: TRAIN [0][2790/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00096)	Tok/s 51769 (53855)	Loss/tok 3.6642 (4.3874)	Learning Rate [0.00125]
1: TRAIN [0][2790/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00094)	Tok/s 50440 (52864)	Loss/tok 3.5012 (4.3893)	Learning Rate [0.00125]
12: TRAIN [0][2790/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00097)	Tok/s 51803 (53757)	Loss/tok 3.5900 (4.3924)	Learning Rate [0.00125]
11: TRAIN [0][2790/3416]	Time 0.059 (0.058)	Data 0.00077 (0.00091)	Tok/s 51745 (53654)	Loss/tok 3.3504 (4.3939)	Learning Rate [0.00125]
2: TRAIN [0][2790/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00100)	Tok/s 50457 (52960)	Loss/tok 3.5823 (4.3883)	Learning Rate [0.00125]
3: TRAIN [0][2790/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00093)	Tok/s 50507 (53058)	Loss/tok 3.5566 (4.3913)	Learning Rate [0.00125]
6: TRAIN [0][2790/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00093)	Tok/s 51635 (53294)	Loss/tok 3.7539 (4.3881)	Learning Rate [0.00125]
9: TRAIN [0][2790/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00093)	Tok/s 51759 (53510)	Loss/tok 3.4278 (4.3895)	Learning Rate [0.00125]
4: TRAIN [0][2790/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00100)	Tok/s 50801 (53142)	Loss/tok 3.6192 (4.3917)	Learning Rate [0.00125]
10: TRAIN [0][2790/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00096)	Tok/s 51765 (53578)	Loss/tok 3.5078 (4.3911)	Learning Rate [0.00125]
5: TRAIN [0][2790/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00095)	Tok/s 51591 (53222)	Loss/tok 3.1746 (4.3884)	Learning Rate [0.00125]
8: TRAIN [0][2790/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00094)	Tok/s 51699 (53451)	Loss/tok 3.4629 (4.3837)	Learning Rate [0.00125]
7: TRAIN [0][2790/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00096)	Tok/s 51565 (53374)	Loss/tok 3.8024 (4.3876)	Learning Rate [0.00125]
2: TRAIN [0][2800/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00100)	Tok/s 50052 (52972)	Loss/tok 3.2383 (4.3850)	Learning Rate [0.00125]
1: TRAIN [0][2800/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00094)	Tok/s 50118 (52876)	Loss/tok 3.4096 (4.3859)	Learning Rate [0.00125]
0: TRAIN [0][2800/3416]	Time 0.047 (0.058)	Data 0.00111 (0.00097)	Tok/s 50093 (52782)	Loss/tok 3.4020 (4.3926)	Learning Rate [0.00125]
4: TRAIN [0][2800/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00100)	Tok/s 50280 (53153)	Loss/tok 3.4159 (4.3882)	Learning Rate [0.00125]
3: TRAIN [0][2800/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00093)	Tok/s 49940 (53070)	Loss/tok 3.3460 (4.3879)	Learning Rate [0.00125]
15: TRAIN [0][2800/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00092)	Tok/s 51332 (54074)	Loss/tok 3.3924 (4.3834)	Learning Rate [0.00125]
5: TRAIN [0][2800/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00095)	Tok/s 51067 (53234)	Loss/tok 3.5240 (4.3855)	Learning Rate [0.00125]
14: TRAIN [0][2800/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00096)	Tok/s 51509 (53968)	Loss/tok 3.4495 (4.3904)	Learning Rate [0.00125]
6: TRAIN [0][2800/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 51110 (53305)	Loss/tok 3.5157 (4.3851)	Learning Rate [0.00125]
11: TRAIN [0][2800/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00091)	Tok/s 51343 (53666)	Loss/tok 3.8212 (4.3909)	Learning Rate [0.00125]
9: TRAIN [0][2800/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00093)	Tok/s 51268 (53522)	Loss/tok 3.3972 (4.3861)	Learning Rate [0.00125]
7: TRAIN [0][2800/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00096)	Tok/s 51094 (53386)	Loss/tok 3.3952 (4.3845)	Learning Rate [0.00125]
13: TRAIN [0][2800/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00096)	Tok/s 51401 (53867)	Loss/tok 3.5685 (4.3842)	Learning Rate [0.00125]
8: TRAIN [0][2800/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00094)	Tok/s 51140 (53463)	Loss/tok 3.2511 (4.3806)	Learning Rate [0.00125]
10: TRAIN [0][2800/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00096)	Tok/s 51208 (53590)	Loss/tok 3.3581 (4.3881)	Learning Rate [0.00125]
12: TRAIN [0][2800/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00097)	Tok/s 51230 (53770)	Loss/tok 3.6641 (4.3894)	Learning Rate [0.00125]
1: TRAIN [0][2810/3416]	Time 0.066 (0.058)	Data 0.00103 (0.00094)	Tok/s 53022 (52877)	Loss/tok 3.5749 (4.3827)	Learning Rate [0.00125]
0: TRAIN [0][2810/3416]	Time 0.066 (0.058)	Data 0.00112 (0.00097)	Tok/s 53033 (52783)	Loss/tok 3.6614 (4.3894)	Learning Rate [0.00125]
15: TRAIN [0][2810/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00092)	Tok/s 53986 (54075)	Loss/tok 3.6683 (4.3804)	Learning Rate [0.00125]
2: TRAIN [0][2810/3416]	Time 0.067 (0.058)	Data 0.00106 (0.00100)	Tok/s 52855 (52974)	Loss/tok 3.6018 (4.3820)	Learning Rate [0.00125]
14: TRAIN [0][2810/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00096)	Tok/s 53977 (53969)	Loss/tok 3.3534 (4.3873)	Learning Rate [0.00125]
12: TRAIN [0][2810/3416]	Time 0.066 (0.058)	Data 0.00106 (0.00097)	Tok/s 54159 (53771)	Loss/tok 3.5785 (4.3863)	Learning Rate [0.00125]
3: TRAIN [0][2810/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00093)	Tok/s 52810 (53071)	Loss/tok 3.6346 (4.3849)	Learning Rate [0.00125]
13: TRAIN [0][2810/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00096)	Tok/s 54008 (53868)	Loss/tok 3.5292 (4.3810)	Learning Rate [0.00125]
4: TRAIN [0][2810/3416]	Time 0.067 (0.058)	Data 0.00102 (0.00100)	Tok/s 52824 (53154)	Loss/tok 3.6686 (4.3851)	Learning Rate [0.00125]
11: TRAIN [0][2810/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00091)	Tok/s 53907 (53667)	Loss/tok 3.3732 (4.3879)	Learning Rate [0.00125]
5: TRAIN [0][2810/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00095)	Tok/s 52791 (53235)	Loss/tok 3.7898 (4.3827)	Learning Rate [0.00125]
6: TRAIN [0][2810/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00093)	Tok/s 52758 (53306)	Loss/tok 3.4552 (4.3819)	Learning Rate [0.00125]
9: TRAIN [0][2810/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00093)	Tok/s 53818 (53523)	Loss/tok 3.3460 (4.3827)	Learning Rate [0.00125]
7: TRAIN [0][2810/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00096)	Tok/s 53472 (53387)	Loss/tok 3.5449 (4.3816)	Learning Rate [0.00125]
10: TRAIN [0][2810/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00096)	Tok/s 53838 (53591)	Loss/tok 3.3488 (4.3852)	Learning Rate [0.00125]
8: TRAIN [0][2810/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00094)	Tok/s 53789 (53464)	Loss/tok 3.6880 (4.3778)	Learning Rate [0.00125]
3: TRAIN [0][2820/3416]	Time 0.049 (0.058)	Data 0.00124 (0.00093)	Tok/s 52578 (53062)	Loss/tok 3.4903 (4.3821)	Learning Rate [0.00125]
2: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00106 (0.00100)	Tok/s 51509 (52965)	Loss/tok 3.6339 (4.3793)	Learning Rate [0.00125]
4: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00100)	Tok/s 51527 (53145)	Loss/tok 3.2987 (4.3823)	Learning Rate [0.00125]
1: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00114 (0.00094)	Tok/s 51400 (52869)	Loss/tok 3.5907 (4.3800)	Learning Rate [0.00125]
5: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00095)	Tok/s 51525 (53226)	Loss/tok 3.4165 (4.3797)	Learning Rate [0.00125]
6: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00093)	Tok/s 51471 (53297)	Loss/tok 3.3325 (4.3792)	Learning Rate [0.00125]
0: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00106 (0.00097)	Tok/s 49984 (52775)	Loss/tok 3.3640 (4.3864)	Learning Rate [0.00125]
15: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00092)	Tok/s 51062 (54065)	Loss/tok 3.4820 (4.3777)	Learning Rate [0.00125]
8: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00094)	Tok/s 51483 (53455)	Loss/tok 3.5775 (4.3752)	Learning Rate [0.00125]
7: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00096)	Tok/s 51530 (53377)	Loss/tok 3.1386 (4.3786)	Learning Rate [0.00125]
14: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00096)	Tok/s 51084 (53959)	Loss/tok 3.4291 (4.3848)	Learning Rate [0.00125]
9: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00093)	Tok/s 51252 (53513)	Loss/tok 3.5160 (4.3801)	Learning Rate [0.00125]
13: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00096)	Tok/s 51150 (53858)	Loss/tok 3.5982 (4.3782)	Learning Rate [0.00125]
11: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00091)	Tok/s 51048 (53658)	Loss/tok 3.3983 (4.3851)	Learning Rate [0.00125]
12: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00111 (0.00097)	Tok/s 51013 (53761)	Loss/tok 3.3893 (4.3834)	Learning Rate [0.00125]
10: TRAIN [0][2820/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00096)	Tok/s 51220 (53581)	Loss/tok 3.2594 (4.3823)	Learning Rate [0.00125]
9: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00093)	Tok/s 36971 (53517)	Loss/tok 3.4493 (4.3769)	Learning Rate [0.00125]
11: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00091)	Tok/s 37052 (53661)	Loss/tok 2.9971 (4.3818)	Learning Rate [0.00125]
10: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00096)	Tok/s 37013 (53585)	Loss/tok 3.4704 (4.3793)	Learning Rate [0.00125]
8: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00094)	Tok/s 36851 (53457)	Loss/tok 3.3041 (4.3722)	Learning Rate [0.00125]
12: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00114 (0.00097)	Tok/s 36992 (53765)	Loss/tok 3.1879 (4.3801)	Learning Rate [0.00125]
13: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00096)	Tok/s 37052 (53862)	Loss/tok 3.2817 (4.3749)	Learning Rate [0.00125]
6: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00093)	Tok/s 36798 (53300)	Loss/tok 3.4058 (4.3760)	Learning Rate [0.00125]
7: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00096)	Tok/s 36778 (53380)	Loss/tok 3.3271 (4.3753)	Learning Rate [0.00125]
5: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00095)	Tok/s 36164 (53229)	Loss/tok 3.2696 (4.3767)	Learning Rate [0.00125]
15: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00092)	Tok/s 36992 (54069)	Loss/tok 3.1578 (4.3747)	Learning Rate [0.00125]
4: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00108 (0.00100)	Tok/s 35593 (53148)	Loss/tok 3.1696 (4.3788)	Learning Rate [0.00125]
0: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00097)	Tok/s 35694 (52779)	Loss/tok 3.2204 (4.3834)	Learning Rate [0.00125]
3: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00093)	Tok/s 35592 (53065)	Loss/tok 3.1349 (4.3788)	Learning Rate [0.00125]
2: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00116 (0.00100)	Tok/s 35612 (52968)	Loss/tok 3.1091 (4.3761)	Learning Rate [0.00125]
1: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00110 (0.00094)	Tok/s 35614 (52872)	Loss/tok 3.4127 (4.3769)	Learning Rate [0.00125]
14: TRAIN [0][2830/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00096)	Tok/s 37142 (53963)	Loss/tok 3.5353 (4.3818)	Learning Rate [0.00125]
6: TRAIN [0][2840/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 70830 (53312)	Loss/tok 3.7467 (4.3730)	Learning Rate [0.00125]
5: TRAIN [0][2840/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00095)	Tok/s 70754 (53240)	Loss/tok 3.5553 (4.3737)	Learning Rate [0.00125]
7: TRAIN [0][2840/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00096)	Tok/s 70914 (53392)	Loss/tok 3.5390 (4.3722)	Learning Rate [0.00125]
4: TRAIN [0][2840/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00100)	Tok/s 70711 (53160)	Loss/tok 3.4661 (4.3756)	Learning Rate [0.00125]
8: TRAIN [0][2840/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00094)	Tok/s 70878 (53469)	Loss/tok 3.4726 (4.3690)	Learning Rate [0.00125]
3: TRAIN [0][2840/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 70539 (53077)	Loss/tok 3.6653 (4.3758)	Learning Rate [0.00125]
9: TRAIN [0][2840/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 70866 (53528)	Loss/tok 3.5798 (4.3738)	Learning Rate [0.00125]
11: TRAIN [0][2840/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00091)	Tok/s 71802 (53673)	Loss/tok 3.5900 (4.3787)	Learning Rate [0.00125]
2: TRAIN [0][2840/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00100)	Tok/s 70932 (52980)	Loss/tok 3.5483 (4.3727)	Learning Rate [0.00125]
1: TRAIN [0][2840/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00094)	Tok/s 70684 (52884)	Loss/tok 3.6604 (4.3738)	Learning Rate [0.00125]
15: TRAIN [0][2840/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 71529 (54080)	Loss/tok 3.7374 (4.3720)	Learning Rate [0.00125]
10: TRAIN [0][2840/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 71842 (53596)	Loss/tok 3.5616 (4.3758)	Learning Rate [0.00125]
12: TRAIN [0][2840/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 71757 (53776)	Loss/tok 3.7040 (4.3770)	Learning Rate [0.00125]
14: TRAIN [0][2840/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 71575 (53974)	Loss/tok 3.4779 (4.3785)	Learning Rate [0.00125]
0: TRAIN [0][2840/3416]	Time 0.070 (0.058)	Data 0.00121 (0.00097)	Tok/s 70582 (52790)	Loss/tok 3.6701 (4.3804)	Learning Rate [0.00125]
13: TRAIN [0][2840/3416]	Time 0.070 (0.058)	Data 0.00117 (0.00096)	Tok/s 71656 (53873)	Loss/tok 3.5884 (4.3714)	Learning Rate [0.00125]
5: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00126 (0.00095)	Tok/s 28878 (53214)	Loss/tok 3.1489 (4.3708)	Learning Rate [0.00125]
6: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00093)	Tok/s 28766 (53285)	Loss/tok 2.6796 (4.3701)	Learning Rate [0.00125]
4: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00097 (0.00100)	Tok/s 27589 (53133)	Loss/tok 2.6805 (4.3730)	Learning Rate [0.00125]
7: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00094 (0.00096)	Tok/s 28737 (53366)	Loss/tok 2.6642 (4.3695)	Learning Rate [0.00125]
1: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00095 (0.00095)	Tok/s 27406 (52855)	Loss/tok 2.8480 (4.3713)	Learning Rate [0.00125]
8: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00094 (0.00094)	Tok/s 28702 (53443)	Loss/tok 2.8866 (4.3662)	Learning Rate [0.00125]
2: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00127 (0.00100)	Tok/s 27465 (52952)	Loss/tok 2.7578 (4.3700)	Learning Rate [0.00125]
3: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00100 (0.00093)	Tok/s 27348 (53049)	Loss/tok 2.7429 (4.3732)	Learning Rate [0.00125]
9: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00093 (0.00093)	Tok/s 28626 (53503)	Loss/tok 2.7606 (4.3710)	Learning Rate [0.00125]
0: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00114 (0.00097)	Tok/s 27373 (52761)	Loss/tok 2.8894 (4.3778)	Learning Rate [0.00125]
15: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00098 (0.00092)	Tok/s 30293 (54056)	Loss/tok 3.1448 (4.3692)	Learning Rate [0.00125]
11: TRAIN [0][2850/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00091)	Tok/s 28595 (53647)	Loss/tok 2.8973 (4.3759)	Learning Rate [0.00125]
14: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00092 (0.00096)	Tok/s 30228 (53950)	Loss/tok 2.9828 (4.3759)	Learning Rate [0.00125]
10: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00094 (0.00096)	Tok/s 28632 (53571)	Loss/tok 2.8001 (4.3730)	Learning Rate [0.00125]
13: TRAIN [0][2850/3416]	Time 0.043 (0.058)	Data 0.00091 (0.00096)	Tok/s 30091 (53849)	Loss/tok 2.7680 (4.3689)	Learning Rate [0.00125]
12: TRAIN [0][2850/3416]	Time 0.042 (0.058)	Data 0.00100 (0.00097)	Tok/s 28936 (53751)	Loss/tok 2.8911 (4.3742)	Learning Rate [0.00125]
6: TRAIN [0][2860/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00093)	Tok/s 50515 (53301)	Loss/tok 3.1831 (4.3675)	Learning Rate [0.00125]
7: TRAIN [0][2860/3416]	Time 0.049 (0.058)	Data 0.00106 (0.00096)	Tok/s 51620 (53382)	Loss/tok 3.7061 (4.3665)	Learning Rate [0.00125]
8: TRAIN [0][2860/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00094)	Tok/s 51843 (53459)	Loss/tok 3.4768 (4.3635)	Learning Rate [0.00125]
9: TRAIN [0][2860/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00093)	Tok/s 51657 (53518)	Loss/tok 3.6466 (4.3680)	Learning Rate [0.00125]
5: TRAIN [0][2860/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00095)	Tok/s 50409 (53230)	Loss/tok 3.5532 (4.3676)	Learning Rate [0.00125]
4: TRAIN [0][2860/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00100)	Tok/s 50287 (53149)	Loss/tok 3.5819 (4.3699)	Learning Rate [0.00125]
10: TRAIN [0][2860/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00096)	Tok/s 51702 (53586)	Loss/tok 3.3889 (4.3700)	Learning Rate [0.00125]
3: TRAIN [0][2860/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00093)	Tok/s 50197 (53065)	Loss/tok 3.5247 (4.3700)	Learning Rate [0.00125]
11: TRAIN [0][2860/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00091)	Tok/s 51436 (53662)	Loss/tok 3.5216 (4.3727)	Learning Rate [0.00125]
2: TRAIN [0][2860/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00100)	Tok/s 50135 (52968)	Loss/tok 3.6265 (4.3670)	Learning Rate [0.00125]
12: TRAIN [0][2860/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00097)	Tok/s 51378 (53766)	Loss/tok 3.4309 (4.3713)	Learning Rate [0.00125]
1: TRAIN [0][2860/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00095)	Tok/s 49915 (52871)	Loss/tok 3.6451 (4.3684)	Learning Rate [0.00125]
0: TRAIN [0][2860/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00097)	Tok/s 49919 (52776)	Loss/tok 3.6387 (4.3750)	Learning Rate [0.00125]
15: TRAIN [0][2860/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 51043 (54070)	Loss/tok 3.4468 (4.3662)	Learning Rate [0.00125]
14: TRAIN [0][2860/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00096)	Tok/s 51091 (53964)	Loss/tok 3.4153 (4.3729)	Learning Rate [0.00125]
13: TRAIN [0][2860/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00096)	Tok/s 51262 (53863)	Loss/tok 3.1990 (4.3658)	Learning Rate [0.00125]
3: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00093)	Tok/s 61161 (53064)	Loss/tok 3.7649 (4.3675)	Learning Rate [0.00125]
4: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00100)	Tok/s 61225 (53148)	Loss/tok 3.8229 (4.3673)	Learning Rate [0.00125]
1: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00095)	Tok/s 61072 (52871)	Loss/tok 3.7985 (4.3656)	Learning Rate [0.00125]
15: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00092)	Tok/s 61050 (54069)	Loss/tok 3.7927 (4.3635)	Learning Rate [0.00125]
0: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00097)	Tok/s 61009 (52776)	Loss/tok 3.8414 (4.3720)	Learning Rate [0.00125]
5: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00095)	Tok/s 61164 (53229)	Loss/tok 3.8205 (4.3648)	Learning Rate [0.00125]
6: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00093)	Tok/s 61097 (53300)	Loss/tok 3.5767 (4.3646)	Learning Rate [0.00125]
14: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00096)	Tok/s 61038 (53962)	Loss/tok 3.5989 (4.3699)	Learning Rate [0.00125]
9: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00093)	Tok/s 61152 (53517)	Loss/tok 3.7436 (4.3651)	Learning Rate [0.00125]
11: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00091)	Tok/s 61046 (53661)	Loss/tok 3.7452 (4.3698)	Learning Rate [0.00125]
13: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00097)	Tok/s 60901 (53862)	Loss/tok 3.5204 (4.3630)	Learning Rate [0.00125]
7: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00096)	Tok/s 61119 (53381)	Loss/tok 3.8161 (4.3637)	Learning Rate [0.00125]
12: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00106 (0.00097)	Tok/s 61008 (53764)	Loss/tok 3.8292 (4.3685)	Learning Rate [0.00125]
2: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00100)	Tok/s 60927 (52968)	Loss/tok 3.6384 (4.3639)	Learning Rate [0.00125]
8: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00094)	Tok/s 61048 (53458)	Loss/tok 3.4966 (4.3605)	Learning Rate [0.00125]
10: TRAIN [0][2870/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00096)	Tok/s 61027 (53585)	Loss/tok 3.7035 (4.3671)	Learning Rate [0.00125]
6: TRAIN [0][2880/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00093)	Tok/s 54331 (53303)	Loss/tok 3.6038 (4.3616)	Learning Rate [0.00125]
9: TRAIN [0][2880/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00093)	Tok/s 54195 (53520)	Loss/tok 3.4800 (4.3622)	Learning Rate [0.00125]
7: TRAIN [0][2880/3416]	Time 0.061 (0.058)	Data 0.00098 (0.00096)	Tok/s 54326 (53384)	Loss/tok 3.6526 (4.3609)	Learning Rate [0.00125]
8: TRAIN [0][2880/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00094)	Tok/s 54188 (53461)	Loss/tok 3.7191 (4.3579)	Learning Rate [0.00125]
5: TRAIN [0][2880/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00095)	Tok/s 54326 (53232)	Loss/tok 3.9594 (4.3623)	Learning Rate [0.00125]
10: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00096)	Tok/s 54049 (53588)	Loss/tok 3.6244 (4.3645)	Learning Rate [0.00125]
3: TRAIN [0][2880/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00093)	Tok/s 54245 (53068)	Loss/tok 3.6140 (4.3645)	Learning Rate [0.00125]
11: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00091)	Tok/s 53886 (53664)	Loss/tok 3.6412 (4.3669)	Learning Rate [0.00125]
2: TRAIN [0][2880/3416]	Time 0.061 (0.058)	Data 0.00103 (0.00100)	Tok/s 54148 (52971)	Loss/tok 3.5214 (4.3608)	Learning Rate [0.00125]
4: TRAIN [0][2880/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00100)	Tok/s 54225 (53151)	Loss/tok 3.6705 (4.3644)	Learning Rate [0.00125]
12: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00097)	Tok/s 53817 (53767)	Loss/tok 3.5616 (4.3657)	Learning Rate [0.00125]
15: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00103 (0.00092)	Tok/s 54957 (54071)	Loss/tok 3.8966 (4.3607)	Learning Rate [0.00125]
14: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00096)	Tok/s 54916 (53964)	Loss/tok 3.5234 (4.3672)	Learning Rate [0.00125]
0: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00097)	Tok/s 53944 (52780)	Loss/tok 3.7987 (4.3691)	Learning Rate [0.00125]
13: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00103 (0.00097)	Tok/s 54365 (53864)	Loss/tok 3.4614 (4.3601)	Learning Rate [0.00125]
1: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00113 (0.00095)	Tok/s 53719 (52874)	Loss/tok 3.6227 (4.3628)	Learning Rate [0.00125]
4: TRAIN [0][2890/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00100)	Tok/s 32426 (53138)	Loss/tok 2.9905 (4.3619)	Learning Rate [0.00125]
5: TRAIN [0][2890/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00095)	Tok/s 32320 (53219)	Loss/tok 2.9360 (4.3593)	Learning Rate [0.00125]
3: TRAIN [0][2890/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00093)	Tok/s 32368 (53054)	Loss/tok 2.9467 (4.3616)	Learning Rate [0.00125]
2: TRAIN [0][2890/3416]	Time 0.049 (0.058)	Data 0.00107 (0.00100)	Tok/s 32385 (52958)	Loss/tok 3.1004 (4.3581)	Learning Rate [0.00125]
1: TRAIN [0][2890/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00095)	Tok/s 32392 (52861)	Loss/tok 2.7789 (4.3599)	Learning Rate [0.00125]
7: TRAIN [0][2890/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00096)	Tok/s 32175 (53370)	Loss/tok 3.1546 (4.3580)	Learning Rate [0.00125]
6: TRAIN [0][2890/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00093)	Tok/s 32242 (53290)	Loss/tok 3.2571 (4.3589)	Learning Rate [0.00125]
8: TRAIN [0][2890/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00094)	Tok/s 32188 (53447)	Loss/tok 3.1103 (4.3552)	Learning Rate [0.00125]
0: TRAIN [0][2890/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00097)	Tok/s 32395 (52767)	Loss/tok 3.3773 (4.3663)	Learning Rate [0.00125]
9: TRAIN [0][2890/3416]	Time 0.050 (0.058)	Data 0.00078 (0.00093)	Tok/s 32188 (53506)	Loss/tok 2.9243 (4.3593)	Learning Rate [0.00125]
15: TRAIN [0][2890/3416]	Time 0.049 (0.058)	Data 0.00082 (0.00092)	Tok/s 33657 (54057)	Loss/tok 3.4544 (4.3581)	Learning Rate [0.00125]
11: TRAIN [0][2890/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00091)	Tok/s 33393 (53650)	Loss/tok 3.2034 (4.3641)	Learning Rate [0.00125]
14: TRAIN [0][2890/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00096)	Tok/s 33628 (53950)	Loss/tok 3.1893 (4.3645)	Learning Rate [0.00125]
13: TRAIN [0][2890/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00097)	Tok/s 33711 (53850)	Loss/tok 3.0828 (4.3576)	Learning Rate [0.00125]
12: TRAIN [0][2890/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00097)	Tok/s 33543 (53753)	Loss/tok 3.2181 (4.3630)	Learning Rate [0.00125]
10: TRAIN [0][2890/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00096)	Tok/s 32174 (53573)	Loss/tok 3.2356 (4.3618)	Learning Rate [0.00125]
2: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00118 (0.00100)	Tok/s 72279 (52953)	Loss/tok 3.6519 (4.3555)	Learning Rate [0.00125]
3: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 72226 (53049)	Loss/tok 3.4271 (4.3588)	Learning Rate [0.00125]
15: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 73367 (54053)	Loss/tok 3.5543 (4.3552)	Learning Rate [0.00125]
6: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 72282 (53286)	Loss/tok 3.9110 (4.3564)	Learning Rate [0.00125]
4: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 72191 (53134)	Loss/tok 3.7250 (4.3590)	Learning Rate [0.00125]
1: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00095)	Tok/s 72240 (52857)	Loss/tok 3.6687 (4.3572)	Learning Rate [0.00125]
0: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 72311 (52763)	Loss/tok 3.7039 (4.3637)	Learning Rate [0.00125]
11: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00091)	Tok/s 73403 (53646)	Loss/tok 3.7548 (4.3614)	Learning Rate [0.00125]
14: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 73358 (53946)	Loss/tok 3.5165 (4.3616)	Learning Rate [0.00125]
13: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 73420 (53847)	Loss/tok 3.3488 (4.3548)	Learning Rate [0.00125]
5: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00095)	Tok/s 72203 (53215)	Loss/tok 3.7187 (4.3564)	Learning Rate [0.00125]
9: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00093)	Tok/s 72347 (53502)	Loss/tok 3.8660 (4.3566)	Learning Rate [0.00125]
12: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00097)	Tok/s 73425 (53749)	Loss/tok 3.5493 (4.3599)	Learning Rate [0.00125]
7: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 72230 (53367)	Loss/tok 3.7501 (4.3552)	Learning Rate [0.00125]
10: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 73193 (53570)	Loss/tok 3.6504 (4.3591)	Learning Rate [0.00125]
8: TRAIN [0][2900/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00094)	Tok/s 72223 (53443)	Loss/tok 3.6569 (4.3523)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
9: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00093)	Tok/s 58761 (53534)	Loss/tok 3.7343 (4.3532)	Learning Rate [0.00125]
10: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00096)	Tok/s 58763 (53602)	Loss/tok 3.6497 (4.3554)	Learning Rate [0.00125]
11: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00081 (0.00091)	Tok/s 58713 (53678)	Loss/tok 3.6204 (4.3579)	Learning Rate [0.00125]
8: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00094)	Tok/s 58622 (53476)	Loss/tok 3.5557 (4.3487)	Learning Rate [0.00125]
7: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00096)	Tok/s 58574 (53399)	Loss/tok 3.6573 (4.3514)	Learning Rate [0.00125]
12: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00097)	Tok/s 58578 (53781)	Loss/tok 3.7321 (4.3561)	Learning Rate [0.00125]
6: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00093)	Tok/s 58435 (53318)	Loss/tok 3.7100 (4.3530)	Learning Rate [0.00125]
13: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00097)	Tok/s 59041 (53878)	Loss/tok 3.7582 (4.3514)	Learning Rate [0.00125]
14: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00095)	Tok/s 59511 (53978)	Loss/tok 3.3632 (4.3584)	Learning Rate [0.00125]
15: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 59459 (54084)	Loss/tok 3.5524 (4.3515)	Learning Rate [0.00125]
5: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00095)	Tok/s 58341 (53248)	Loss/tok 3.6567 (4.3528)	Learning Rate [0.00125]
4: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00100)	Tok/s 58273 (53166)	Loss/tok 3.8347 (4.3554)	Learning Rate [0.00125]
0: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00097)	Tok/s 58373 (52796)	Loss/tok 3.5785 (4.3601)	Learning Rate [0.00125]
3: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00093)	Tok/s 58267 (53081)	Loss/tok 3.8012 (4.3553)	Learning Rate [0.00125]
2: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00100)	Tok/s 58301 (52986)	Loss/tok 3.5628 (4.3521)	Learning Rate [0.00125]
1: TRAIN [0][2910/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00095)	Tok/s 58316 (52889)	Loss/tok 3.8699 (4.3538)	Learning Rate [0.00125]
2: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00100)	Tok/s 64996 (52974)	Loss/tok 3.6268 (4.3495)	Learning Rate [0.00125]
4: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 64992 (53154)	Loss/tok 3.3974 (4.3525)	Learning Rate [0.00125]
1: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00095)	Tok/s 64963 (52878)	Loss/tok 3.7841 (4.3513)	Learning Rate [0.00125]
0: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00097)	Tok/s 65119 (52785)	Loss/tok 3.7971 (4.3578)	Learning Rate [0.00125]
6: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 65145 (53306)	Loss/tok 3.5948 (4.3503)	Learning Rate [0.00125]
3: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 65103 (53070)	Loss/tok 3.7387 (4.3526)	Learning Rate [0.00125]
5: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00095)	Tok/s 65093 (53235)	Loss/tok 3.9448 (4.3503)	Learning Rate [0.00125]
9: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 65130 (53521)	Loss/tok 3.7088 (4.3506)	Learning Rate [0.00125]
15: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 65966 (54072)	Loss/tok 3.6648 (4.3491)	Learning Rate [0.00125]
11: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00091)	Tok/s 65216 (53666)	Loss/tok 3.7091 (4.3554)	Learning Rate [0.00125]
10: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 65227 (53589)	Loss/tok 3.7071 (4.3527)	Learning Rate [0.00125]
7: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 65033 (53387)	Loss/tok 3.5679 (4.3487)	Learning Rate [0.00125]
14: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00095)	Tok/s 65953 (53966)	Loss/tok 3.7977 (4.3560)	Learning Rate [0.00125]
8: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00094)	Tok/s 65101 (53463)	Loss/tok 3.5511 (4.3461)	Learning Rate [0.00125]
12: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 65038 (53769)	Loss/tok 3.6985 (4.3536)	Learning Rate [0.00125]
13: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00097)	Tok/s 65897 (53866)	Loss/tok 3.6248 (4.3488)	Learning Rate [0.00125]
6: TRAIN [0][2930/3416]	Time 0.035 (0.058)	Data 0.00081 (0.00093)	Tok/s 21581 (53299)	Loss/tok 2.1615 (4.3478)	Learning Rate [0.00125]
7: TRAIN [0][2930/3416]	Time 0.034 (0.058)	Data 0.00089 (0.00096)	Tok/s 22301 (53380)	Loss/tok 2.4465 (4.3463)	Learning Rate [0.00125]
8: TRAIN [0][2930/3416]	Time 0.034 (0.058)	Data 0.00092 (0.00094)	Tok/s 24119 (53457)	Loss/tok 1.9984 (4.3433)	Learning Rate [0.00125]
9: TRAIN [0][2930/3416]	Time 0.034 (0.058)	Data 0.00091 (0.00093)	Tok/s 24128 (53516)	Loss/tok 2.1845 (4.3479)	Learning Rate [0.00125]
5: TRAIN [0][2930/3416]	Time 0.035 (0.058)	Data 0.00082 (0.00095)	Tok/s 20273 (53229)	Loss/tok 2.1971 (4.3475)	Learning Rate [0.00125]
4: TRAIN [0][2930/3416]	Time 0.035 (0.058)	Data 0.00098 (0.00100)	Tok/s 18931 (53147)	Loss/tok 2.6486 (4.3502)	Learning Rate [0.00125]
11: TRAIN [0][2930/3416]	Time 0.035 (0.058)	Data 0.00081 (0.00091)	Tok/s 24093 (53660)	Loss/tok 2.0236 (4.3528)	Learning Rate [0.00125]
3: TRAIN [0][2930/3416]	Time 0.035 (0.058)	Data 0.00088 (0.00093)	Tok/s 16542 (53062)	Loss/tok 1.7187 (4.3497)	Learning Rate [0.00125]
10: TRAIN [0][2930/3416]	Time 0.034 (0.058)	Data 0.00081 (0.00096)	Tok/s 24131 (53583)	Loss/tok 2.0225 (4.3501)	Learning Rate [0.00125]
2: TRAIN [0][2930/3416]	Time 0.035 (0.058)	Data 0.00095 (0.00100)	Tok/s 15507 (52967)	Loss/tok 1.9669 (4.3467)	Learning Rate [0.00125]
12: TRAIN [0][2930/3416]	Time 0.035 (0.058)	Data 0.00095 (0.00097)	Tok/s 25626 (53763)	Loss/tok 2.5205 (4.3509)	Learning Rate [0.00125]
1: TRAIN [0][2930/3416]	Time 0.035 (0.058)	Data 0.00081 (0.00095)	Tok/s 12174 (52870)	Loss/tok 1.9031 (4.3489)	Learning Rate [0.00125]
0: TRAIN [0][2930/3416]	Time 0.035 (0.058)	Data 0.00096 (0.00097)	Tok/s 9224 (52775)	Loss/tok 1.8260 (4.3551)	Learning Rate [0.00125]
13: TRAIN [0][2930/3416]	Time 0.034 (0.058)	Data 0.00094 (0.00097)	Tok/s 25989 (53861)	Loss/tok 2.5499 (4.3463)	Learning Rate [0.00125]
15: TRAIN [0][2930/3416]	Time 0.035 (0.058)	Data 0.00082 (0.00092)	Tok/s 27645 (54067)	Loss/tok 2.7863 (4.3466)	Learning Rate [0.00125]
14: TRAIN [0][2930/3416]	Time 0.035 (0.058)	Data 0.00086 (0.00095)	Tok/s 25859 (53961)	Loss/tok 2.6715 (4.3533)	Learning Rate [0.00125]
4: TRAIN [0][2940/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00100)	Tok/s 55602 (53142)	Loss/tok 3.7958 (4.3477)	Learning Rate [0.00125]
3: TRAIN [0][2940/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00093)	Tok/s 55455 (53057)	Loss/tok 3.6009 (4.3471)	Learning Rate [0.00125]
2: TRAIN [0][2940/3416]	Time 0.066 (0.058)	Data 0.00100 (0.00100)	Tok/s 55384 (52962)	Loss/tok 3.3770 (4.3438)	Learning Rate [0.00125]
5: TRAIN [0][2940/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00095)	Tok/s 56016 (53223)	Loss/tok 3.4091 (4.3446)	Learning Rate [0.00125]
6: TRAIN [0][2940/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00093)	Tok/s 56282 (53294)	Loss/tok 3.4271 (4.3450)	Learning Rate [0.00125]
1: TRAIN [0][2940/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00095)	Tok/s 55300 (52865)	Loss/tok 3.5736 (4.3462)	Learning Rate [0.00125]
7: TRAIN [0][2940/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00096)	Tok/s 56186 (53374)	Loss/tok 3.6969 (4.3437)	Learning Rate [0.00125]
0: TRAIN [0][2940/3416]	Time 0.066 (0.058)	Data 0.00109 (0.00097)	Tok/s 55185 (52771)	Loss/tok 3.6814 (4.3523)	Learning Rate [0.00125]
8: TRAIN [0][2940/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00094)	Tok/s 56115 (53452)	Loss/tok 3.5159 (4.3406)	Learning Rate [0.00125]
15: TRAIN [0][2940/3416]	Time 0.066 (0.058)	Data 0.00087 (0.00092)	Tok/s 56058 (54062)	Loss/tok 3.8434 (4.3442)	Learning Rate [0.00125]
9: TRAIN [0][2940/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00093)	Tok/s 55997 (53510)	Loss/tok 3.5598 (4.3452)	Learning Rate [0.00125]
14: TRAIN [0][2940/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00095)	Tok/s 55971 (53956)	Loss/tok 3.4528 (4.3505)	Learning Rate [0.00125]
13: TRAIN [0][2940/3416]	Time 0.067 (0.058)	Data 0.00102 (0.00097)	Tok/s 55808 (53856)	Loss/tok 3.5705 (4.3435)	Learning Rate [0.00125]
12: TRAIN [0][2940/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00097)	Tok/s 55799 (53758)	Loss/tok 3.4030 (4.3480)	Learning Rate [0.00125]
10: TRAIN [0][2940/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00096)	Tok/s 55897 (53578)	Loss/tok 3.3088 (4.3472)	Learning Rate [0.00125]
11: TRAIN [0][2940/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00091)	Tok/s 55809 (53655)	Loss/tok 3.5531 (4.3500)	Learning Rate [0.00125]
3: TRAIN [0][2950/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00093)	Tok/s 51892 (53037)	Loss/tok 3.7329 (4.3445)	Learning Rate [0.00125]
1: TRAIN [0][2950/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00094)	Tok/s 52004 (52843)	Loss/tok 3.8439 (4.3440)	Learning Rate [0.00125]
4: TRAIN [0][2950/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00100)	Tok/s 51964 (53122)	Loss/tok 4.0219 (4.3456)	Learning Rate [0.00125]
14: TRAIN [0][2950/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00095)	Tok/s 52701 (53938)	Loss/tok 3.6806 (4.3479)	Learning Rate [0.00125]
5: TRAIN [0][2950/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00095)	Tok/s 51981 (53204)	Loss/tok 3.7077 (4.3421)	Learning Rate [0.00125]
6: TRAIN [0][2950/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00093)	Tok/s 51909 (53274)	Loss/tok 3.8391 (4.3428)	Learning Rate [0.00125]
9: TRAIN [0][2950/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00093)	Tok/s 52299 (53492)	Loss/tok 3.6592 (4.3426)	Learning Rate [0.00125]
10: TRAIN [0][2950/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00096)	Tok/s 52438 (53560)	Loss/tok 3.9726 (4.3447)	Learning Rate [0.00125]
11: TRAIN [0][2950/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00091)	Tok/s 52381 (53637)	Loss/tok 3.8361 (4.3475)	Learning Rate [0.00125]
13: TRAIN [0][2950/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00097)	Tok/s 52332 (53838)	Loss/tok 3.4207 (4.3408)	Learning Rate [0.00125]
8: TRAIN [0][2950/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00094)	Tok/s 52291 (53433)	Loss/tok 3.7876 (4.3382)	Learning Rate [0.00125]
7: TRAIN [0][2950/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00096)	Tok/s 52167 (53355)	Loss/tok 3.6471 (4.3413)	Learning Rate [0.00125]
15: TRAIN [0][2950/3416]	Time 0.066 (0.058)	Data 0.00080 (0.00092)	Tok/s 53117 (54044)	Loss/tok 3.6574 (4.3419)	Learning Rate [0.00125]
2: TRAIN [0][2950/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00100)	Tok/s 52022 (52941)	Loss/tok 3.7489 (4.3415)	Learning Rate [0.00125]
0: TRAIN [0][2950/3416]	Time 0.066 (0.058)	Data 0.00100 (0.00097)	Tok/s 52122 (52748)	Loss/tok 3.8383 (4.3498)	Learning Rate [0.00125]
12: TRAIN [0][2950/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00097)	Tok/s 52441 (53740)	Loss/tok 3.6238 (4.3457)	Learning Rate [0.00125]
9: Gradient norm: inf
8: Gradient norm: inf
10: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
12: Gradient norm: inf
5: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
3: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
9: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00093)	Tok/s 52893 (53504)	Loss/tok 3.3782 (4.3394)	Learning Rate [0.00125]
8: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00094)	Tok/s 52882 (53445)	Loss/tok 3.6194 (4.3349)	Learning Rate [0.00125]
6: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00093)	Tok/s 52812 (53287)	Loss/tok 3.5759 (4.3397)	Learning Rate [0.00125]
7: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00096)	Tok/s 52781 (53368)	Loss/tok 3.5136 (4.3383)	Learning Rate [0.00125]
11: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00091)	Tok/s 52905 (53649)	Loss/tok 3.5216 (4.3443)	Learning Rate [0.00125]
5: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00095)	Tok/s 52808 (53216)	Loss/tok 3.4580 (4.3390)	Learning Rate [0.00125]
10: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00096)	Tok/s 52892 (53572)	Loss/tok 3.5403 (4.3416)	Learning Rate [0.00125]
3: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00093)	Tok/s 52798 (53049)	Loss/tok 3.5224 (4.3413)	Learning Rate [0.00125]
4: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00100)	Tok/s 52774 (53135)	Loss/tok 3.6610 (4.3428)	Learning Rate [0.00125]
14: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00095)	Tok/s 52904 (53950)	Loss/tok 3.5229 (4.3446)	Learning Rate [0.00125]
12: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00097)	Tok/s 52880 (53753)	Loss/tok 3.1738 (4.3423)	Learning Rate [0.00125]
15: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00092)	Tok/s 52912 (54057)	Loss/tok 3.5025 (4.3388)	Learning Rate [0.00125]
2: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00100)	Tok/s 52764 (52954)	Loss/tok 3.5174 (4.3386)	Learning Rate [0.00125]
13: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00097)	Tok/s 52811 (53850)	Loss/tok 3.6966 (4.3377)	Learning Rate [0.00125]
1: TRAIN [0][2960/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00094)	Tok/s 52689 (52856)	Loss/tok 3.7225 (4.3411)	Learning Rate [0.00125]
0: TRAIN [0][2960/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00097)	Tok/s 52849 (52761)	Loss/tok 3.5319 (4.3468)	Learning Rate [0.00125]
11: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00091 (0.00091)	Tok/s 29735 (53653)	Loss/tok 2.9333 (4.3415)	Learning Rate [0.00125]
10: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00096)	Tok/s 29777 (53577)	Loss/tok 2.5712 (4.3387)	Learning Rate [0.00125]
9: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00084 (0.00093)	Tok/s 29795 (53508)	Loss/tok 2.7984 (4.3364)	Learning Rate [0.00125]
8: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00088 (0.00094)	Tok/s 29728 (53450)	Loss/tok 2.8524 (4.3320)	Learning Rate [0.00125]
6: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00084 (0.00093)	Tok/s 29799 (53291)	Loss/tok 2.7534 (4.3372)	Learning Rate [0.00125]
7: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00095 (0.00096)	Tok/s 29775 (53372)	Loss/tok 2.6669 (4.3355)	Learning Rate [0.00125]
12: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00093 (0.00097)	Tok/s 29558 (53757)	Loss/tok 2.8006 (4.3393)	Learning Rate [0.00125]
13: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00090 (0.00097)	Tok/s 30555 (53854)	Loss/tok 2.8099 (4.3349)	Learning Rate [0.00125]
14: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00095)	Tok/s 31195 (53954)	Loss/tok 2.9220 (4.3417)	Learning Rate [0.00125]
4: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00097 (0.00100)	Tok/s 28212 (53139)	Loss/tok 2.7706 (4.3401)	Learning Rate [0.00125]
5: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00102 (0.00095)	Tok/s 28838 (53221)	Loss/tok 2.5070 (4.3359)	Learning Rate [0.00125]
15: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00082 (0.00092)	Tok/s 31183 (54061)	Loss/tok 3.1171 (4.3358)	Learning Rate [0.00125]
1: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00094)	Tok/s 28088 (52860)	Loss/tok 2.7350 (4.3381)	Learning Rate [0.00125]
3: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00093 (0.00093)	Tok/s 28155 (53054)	Loss/tok 2.5435 (4.3385)	Learning Rate [0.00125]
2: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00103 (0.00100)	Tok/s 28112 (52958)	Loss/tok 2.6319 (4.3358)	Learning Rate [0.00125]
0: TRAIN [0][2970/3416]	Time 0.041 (0.058)	Data 0.00103 (0.00097)	Tok/s 28075 (52766)	Loss/tok 2.7125 (4.3441)	Learning Rate [0.00125]
7: TRAIN [0][2980/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00096)	Tok/s 48544 (53366)	Loss/tok 3.2153 (4.3332)	Learning Rate [0.00125]
6: TRAIN [0][2980/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00093)	Tok/s 47982 (53286)	Loss/tok 3.5022 (4.3345)	Learning Rate [0.00125]
8: TRAIN [0][2980/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00094)	Tok/s 48532 (53445)	Loss/tok 3.4467 (4.3296)	Learning Rate [0.00125]
10: TRAIN [0][2980/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00096)	Tok/s 48621 (53572)	Loss/tok 3.4419 (4.3362)	Learning Rate [0.00125]
9: TRAIN [0][2980/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00093)	Tok/s 48542 (53503)	Loss/tok 3.2457 (4.3338)	Learning Rate [0.00125]
5: TRAIN [0][2980/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00095)	Tok/s 47120 (53215)	Loss/tok 3.4887 (4.3335)	Learning Rate [0.00125]
4: TRAIN [0][2980/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00100)	Tok/s 47161 (53132)	Loss/tok 3.2782 (4.3375)	Learning Rate [0.00125]
12: TRAIN [0][2980/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00097)	Tok/s 48488 (53752)	Loss/tok 3.3953 (4.3364)	Learning Rate [0.00125]
3: TRAIN [0][2980/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00093)	Tok/s 47097 (53046)	Loss/tok 3.5660 (4.3360)	Learning Rate [0.00125]
2: TRAIN [0][2980/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00100)	Tok/s 47232 (52950)	Loss/tok 3.0984 (4.3333)	Learning Rate [0.00125]
11: TRAIN [0][2980/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00091)	Tok/s 48491 (53648)	Loss/tok 3.3831 (4.3387)	Learning Rate [0.00125]
1: TRAIN [0][2980/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00094)	Tok/s 47116 (52851)	Loss/tok 3.4971 (4.3355)	Learning Rate [0.00125]
15: TRAIN [0][2980/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00092)	Tok/s 48541 (54058)	Loss/tok 3.4276 (4.3335)	Learning Rate [0.00125]
0: TRAIN [0][2980/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00097)	Tok/s 47226 (52756)	Loss/tok 3.3757 (4.3415)	Learning Rate [0.00125]
13: TRAIN [0][2980/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00097)	Tok/s 48509 (53850)	Loss/tok 3.5544 (4.3328)	Learning Rate [0.00125]
14: TRAIN [0][2980/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00095)	Tok/s 48423 (53951)	Loss/tok 3.6599 (4.3389)	Learning Rate [0.00125]
9: TRAIN [0][2990/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 60675 (53517)	Loss/tok 3.4429 (4.3307)	Learning Rate [0.00125]
14: TRAIN [0][2990/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00095)	Tok/s 60680 (53964)	Loss/tok 3.4663 (4.3357)	Learning Rate [0.00125]
13: TRAIN [0][2990/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00097)	Tok/s 60749 (53864)	Loss/tok 3.6612 (4.3299)	Learning Rate [0.00125]
11: TRAIN [0][2990/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00091)	Tok/s 60742 (53661)	Loss/tok 3.6787 (4.3358)	Learning Rate [0.00125]
15: TRAIN [0][2990/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 61525 (54071)	Loss/tok 3.8028 (4.3304)	Learning Rate [0.00125]
10: TRAIN [0][2990/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00096)	Tok/s 60784 (53585)	Loss/tok 3.6539 (4.3334)	Learning Rate [0.00125]
8: TRAIN [0][2990/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00094)	Tok/s 60807 (53458)	Loss/tok 3.6537 (4.3266)	Learning Rate [0.00125]
12: TRAIN [0][2990/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00097)	Tok/s 60737 (53766)	Loss/tok 3.5619 (4.3332)	Learning Rate [0.00125]
0: TRAIN [0][2990/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00097)	Tok/s 60576 (52770)	Loss/tok 3.6932 (4.3384)	Learning Rate [0.00125]
7: TRAIN [0][2990/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 60576 (53380)	Loss/tok 3.5737 (4.3303)	Learning Rate [0.00125]
6: TRAIN [0][2990/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00093)	Tok/s 60414 (53299)	Loss/tok 3.7188 (4.3314)	Learning Rate [0.00125]
1: TRAIN [0][2990/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00094)	Tok/s 60417 (52865)	Loss/tok 3.7884 (4.3324)	Learning Rate [0.00125]
2: TRAIN [0][2990/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 60354 (52963)	Loss/tok 3.7245 (4.3305)	Learning Rate [0.00125]
5: TRAIN [0][2990/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00095)	Tok/s 60340 (53229)	Loss/tok 3.6298 (4.3305)	Learning Rate [0.00125]
4: TRAIN [0][2990/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 60272 (53146)	Loss/tok 3.7944 (4.3344)	Learning Rate [0.00125]
3: TRAIN [0][2990/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 60218 (53059)	Loss/tok 3.6418 (4.3329)	Learning Rate [0.00125]
1: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00094)	Tok/s 75333 (52891)	Loss/tok 3.6980 (4.3294)	Learning Rate [0.00125]
2: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00100)	Tok/s 75252 (52989)	Loss/tok 3.7025 (4.3272)	Learning Rate [0.00125]
0: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00097)	Tok/s 75377 (52795)	Loss/tok 3.5531 (4.3350)	Learning Rate [0.00125]
4: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00100)	Tok/s 75248 (53171)	Loss/tok 3.3659 (4.3311)	Learning Rate [0.00125]
3: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 75145 (53085)	Loss/tok 3.4047 (4.3295)	Learning Rate [0.00125]
15: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 76272 (54097)	Loss/tok 3.3902 (4.3273)	Learning Rate [0.00125]
14: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00095)	Tok/s 76264 (53989)	Loss/tok 3.6925 (4.3325)	Learning Rate [0.00125]
10: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00096)	Tok/s 76385 (53611)	Loss/tok 3.5408 (4.3303)	Learning Rate [0.00125]
6: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 75130 (53324)	Loss/tok 3.4603 (4.3283)	Learning Rate [0.00125]
5: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00095)	Tok/s 75141 (53254)	Loss/tok 3.3080 (4.3271)	Learning Rate [0.00125]
11: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00091)	Tok/s 76346 (53687)	Loss/tok 3.4149 (4.3326)	Learning Rate [0.00125]
7: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00096)	Tok/s 75171 (53405)	Loss/tok 3.3825 (4.3270)	Learning Rate [0.00125]
12: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 76272 (53791)	Loss/tok 3.4905 (4.3299)	Learning Rate [0.00125]
9: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 76098 (53543)	Loss/tok 3.3559 (4.3271)	Learning Rate [0.00125]
8: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00094)	Tok/s 76045 (53483)	Loss/tok 3.7058 (4.3235)	Learning Rate [0.00125]
13: TRAIN [0][3000/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 76239 (53890)	Loss/tok 3.3851 (4.3271)	Learning Rate [0.00125]
12: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00097)	Tok/s 49982 (53803)	Loss/tok 3.4431 (4.3269)	Learning Rate [0.00125]
11: TRAIN [0][3010/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00091)	Tok/s 50351 (53699)	Loss/tok 3.1629 (4.3296)	Learning Rate [0.00125]
13: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00097)	Tok/s 50022 (53901)	Loss/tok 3.6453 (4.3240)	Learning Rate [0.00125]
10: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00096)	Tok/s 49802 (53623)	Loss/tok 3.3996 (4.3274)	Learning Rate [0.00125]
14: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00118 (0.00095)	Tok/s 49984 (54000)	Loss/tok 3.3745 (4.3292)	Learning Rate [0.00125]
9: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00093)	Tok/s 49728 (53554)	Loss/tok 3.2958 (4.3241)	Learning Rate [0.00125]
15: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00092)	Tok/s 49928 (54107)	Loss/tok 3.5125 (4.3243)	Learning Rate [0.00125]
8: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00094)	Tok/s 49756 (53495)	Loss/tok 3.4095 (4.3205)	Learning Rate [0.00125]
0: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00097)	Tok/s 49835 (52807)	Loss/tok 3.2599 (4.3320)	Learning Rate [0.00125]
7: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00096)	Tok/s 49702 (53416)	Loss/tok 3.4555 (4.3239)	Learning Rate [0.00125]
1: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00094)	Tok/s 49756 (52903)	Loss/tok 3.1888 (4.3265)	Learning Rate [0.00125]
6: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00093)	Tok/s 49587 (53335)	Loss/tok 3.3292 (4.3251)	Learning Rate [0.00125]
5: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00095)	Tok/s 49442 (53264)	Loss/tok 3.4416 (4.3240)	Learning Rate [0.00125]
2: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00103 (0.00100)	Tok/s 49572 (53001)	Loss/tok 3.2584 (4.3240)	Learning Rate [0.00125]
3: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00093)	Tok/s 49479 (53096)	Loss/tok 3.1233 (4.3263)	Learning Rate [0.00125]
4: TRAIN [0][3010/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00100)	Tok/s 49409 (53182)	Loss/tok 3.4188 (4.3282)	Learning Rate [0.00125]
8: TRAIN [0][3020/3416]	Time 0.050 (0.058)	Data 0.00106 (0.00094)	Tok/s 36852 (53508)	Loss/tok 3.2288 (4.3176)	Learning Rate [0.00125]
9: TRAIN [0][3020/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00093)	Tok/s 36854 (53568)	Loss/tok 3.3382 (4.3212)	Learning Rate [0.00125]
7: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00096)	Tok/s 36723 (53430)	Loss/tok 3.3190 (4.3213)	Learning Rate [0.00125]
11: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00091)	Tok/s 36738 (53712)	Loss/tok 3.2292 (4.3268)	Learning Rate [0.00125]
6: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00112 (0.00093)	Tok/s 36565 (53349)	Loss/tok 3.3816 (4.3226)	Learning Rate [0.00125]
10: TRAIN [0][3020/3416]	Time 0.050 (0.058)	Data 0.00107 (0.00096)	Tok/s 36782 (53636)	Loss/tok 3.0807 (4.3245)	Learning Rate [0.00125]
12: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00097)	Tok/s 36739 (53816)	Loss/tok 3.3144 (4.3241)	Learning Rate [0.00125]
5: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00112 (0.00095)	Tok/s 36551 (53278)	Loss/tok 3.2706 (4.3211)	Learning Rate [0.00125]
4: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00100)	Tok/s 36519 (53196)	Loss/tok 3.4895 (4.3253)	Learning Rate [0.00125]
1: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00094)	Tok/s 36133 (52917)	Loss/tok 3.3261 (4.3239)	Learning Rate [0.00125]
3: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00093)	Tok/s 36502 (53110)	Loss/tok 3.3464 (4.3235)	Learning Rate [0.00125]
13: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00097)	Tok/s 36549 (53913)	Loss/tok 3.4445 (4.3212)	Learning Rate [0.00125]
2: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00100)	Tok/s 36392 (53014)	Loss/tok 3.3922 (4.3211)	Learning Rate [0.00125]
14: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00095)	Tok/s 36502 (54012)	Loss/tok 3.3578 (4.3264)	Learning Rate [0.00125]
0: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00112 (0.00097)	Tok/s 35142 (52820)	Loss/tok 3.1930 (4.3292)	Learning Rate [0.00125]
15: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00092)	Tok/s 36390 (54119)	Loss/tok 2.8182 (4.3215)	Learning Rate [0.00125]
6: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00112 (0.00093)	Tok/s 54996 (53356)	Loss/tok 3.4025 (4.3197)	Learning Rate [0.00125]
5: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00095)	Tok/s 54896 (53285)	Loss/tok 3.7225 (4.3183)	Learning Rate [0.00125]
7: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00095)	Tok/s 54978 (53437)	Loss/tok 3.4951 (4.3184)	Learning Rate [0.00125]
8: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00094)	Tok/s 55181 (53515)	Loss/tok 3.5698 (4.3149)	Learning Rate [0.00125]
4: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00100)	Tok/s 54769 (53202)	Loss/tok 3.5550 (4.3225)	Learning Rate [0.00125]
9: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00093)	Tok/s 56036 (53575)	Loss/tok 3.4699 (4.3185)	Learning Rate [0.00125]
3: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00093)	Tok/s 54704 (53116)	Loss/tok 3.6898 (4.3209)	Learning Rate [0.00125]
2: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00100)	Tok/s 54688 (53022)	Loss/tok 3.9218 (4.3185)	Learning Rate [0.00125]
10: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00096)	Tok/s 55932 (53644)	Loss/tok 3.4048 (4.3216)	Learning Rate [0.00125]
1: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00094)	Tok/s 54675 (52924)	Loss/tok 3.9188 (4.3211)	Learning Rate [0.00125]
11: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00078 (0.00091)	Tok/s 55877 (53720)	Loss/tok 3.5041 (4.3239)	Learning Rate [0.00125]
0: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00097)	Tok/s 54675 (52827)	Loss/tok 3.5274 (4.3263)	Learning Rate [0.00125]
15: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00084 (0.00092)	Tok/s 55714 (54127)	Loss/tok 3.7469 (4.3186)	Learning Rate [0.00125]
12: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00097)	Tok/s 55753 (53823)	Loss/tok 3.6138 (4.3212)	Learning Rate [0.00125]
14: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00095)	Tok/s 55675 (54020)	Loss/tok 3.4852 (4.3234)	Learning Rate [0.00125]
13: TRAIN [0][3030/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00097)	Tok/s 55653 (53921)	Loss/tok 3.4181 (4.3181)	Learning Rate [0.00125]
3: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 67870 (53112)	Loss/tok 3.6267 (4.3183)	Learning Rate [0.00125]
4: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 67693 (53198)	Loss/tok 3.6411 (4.3200)	Learning Rate [0.00125]
2: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00100)	Tok/s 67817 (53017)	Loss/tok 3.7368 (4.3161)	Learning Rate [0.00125]
1: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00094)	Tok/s 67836 (52918)	Loss/tok 3.6050 (4.3186)	Learning Rate [0.00125]
5: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00095)	Tok/s 67675 (53281)	Loss/tok 3.7067 (4.3158)	Learning Rate [0.00125]
0: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 67866 (52821)	Loss/tok 3.4861 (4.3240)	Learning Rate [0.00125]
6: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00093)	Tok/s 67999 (53353)	Loss/tok 3.5527 (4.3170)	Learning Rate [0.00125]
15: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 68624 (54125)	Loss/tok 3.8771 (4.3161)	Learning Rate [0.00125]
7: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00095)	Tok/s 68379 (53434)	Loss/tok 3.3930 (4.3159)	Learning Rate [0.00125]
14: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00095)	Tok/s 68531 (54018)	Loss/tok 3.6936 (4.3210)	Learning Rate [0.00125]
9: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 68194 (53573)	Loss/tok 3.7214 (4.3159)	Learning Rate [0.00125]
8: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00094)	Tok/s 68258 (53513)	Loss/tok 3.6017 (4.3124)	Learning Rate [0.00125]
13: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00097)	Tok/s 68430 (53919)	Loss/tok 3.6364 (4.3153)	Learning Rate [0.00125]
11: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00091)	Tok/s 68262 (53717)	Loss/tok 3.8257 (4.3213)	Learning Rate [0.00125]
12: TRAIN [0][3040/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 68219 (53821)	Loss/tok 3.5534 (4.3185)	Learning Rate [0.00125]
10: TRAIN [0][3040/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 68067 (53641)	Loss/tok 3.7313 (4.3193)	Learning Rate [0.00125]
6: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00093)	Tok/s 33448 (53344)	Loss/tok 2.9921 (4.3143)	Learning Rate [0.00125]
7: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00095)	Tok/s 33517 (53426)	Loss/tok 3.1795 (4.3131)	Learning Rate [0.00125]
8: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00094)	Tok/s 33448 (53505)	Loss/tok 3.4664 (4.3096)	Learning Rate [0.00125]
9: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00093)	Tok/s 33369 (53565)	Loss/tok 3.1368 (4.3133)	Learning Rate [0.00125]
5: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00095)	Tok/s 33416 (53272)	Loss/tok 3.1400 (4.3131)	Learning Rate [0.00125]
4: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00100)	Tok/s 33380 (53189)	Loss/tok 3.3223 (4.3174)	Learning Rate [0.00125]
10: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00096)	Tok/s 33307 (53634)	Loss/tok 3.2967 (4.3161)	Learning Rate [0.00125]
3: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00078 (0.00093)	Tok/s 33274 (53103)	Loss/tok 3.0048 (4.3153)	Learning Rate [0.00125]
11: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00091)	Tok/s 33219 (53710)	Loss/tok 3.0356 (4.3186)	Learning Rate [0.00125]
2: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00100)	Tok/s 33197 (53008)	Loss/tok 3.3224 (4.3133)	Learning Rate [0.00125]
12: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00097)	Tok/s 33216 (53813)	Loss/tok 3.1156 (4.3159)	Learning Rate [0.00125]
1: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00094)	Tok/s 33190 (52909)	Loss/tok 3.2612 (4.3156)	Learning Rate [0.00125]
0: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00097)	Tok/s 33198 (52812)	Loss/tok 3.2154 (4.3213)	Learning Rate [0.00125]
15: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 34461 (54118)	Loss/tok 3.2033 (4.3133)	Learning Rate [0.00125]
13: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00097)	Tok/s 33181 (53912)	Loss/tok 3.0585 (4.3125)	Learning Rate [0.00125]
14: TRAIN [0][3050/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00095)	Tok/s 34414 (54011)	Loss/tok 2.9277 (4.3179)	Learning Rate [0.00125]
2: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00110 (0.00100)	Tok/s 51234 (53029)	Loss/tok 3.7616 (4.3107)	Learning Rate [0.00125]
1: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00094)	Tok/s 51265 (52930)	Loss/tok 3.2013 (4.3128)	Learning Rate [0.00125]
3: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00093)	Tok/s 51258 (53124)	Loss/tok 3.7464 (4.3125)	Learning Rate [0.00125]
0: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00097)	Tok/s 51237 (52834)	Loss/tok 3.4696 (4.3183)	Learning Rate [0.00125]
4: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00100)	Tok/s 51194 (53210)	Loss/tok 3.4509 (4.3147)	Learning Rate [0.00125]
15: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00092)	Tok/s 52327 (54139)	Loss/tok 3.5492 (4.3103)	Learning Rate [0.00125]
6: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00083 (0.00093)	Tok/s 52340 (53366)	Loss/tok 3.5477 (4.3114)	Learning Rate [0.00125]
5: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00095)	Tok/s 51735 (53293)	Loss/tok 3.4478 (4.3102)	Learning Rate [0.00125]
14: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00095)	Tok/s 52329 (54032)	Loss/tok 3.5510 (4.3150)	Learning Rate [0.00125]
12: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00097)	Tok/s 52304 (53834)	Loss/tok 3.3892 (4.3128)	Learning Rate [0.00125]
7: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00105 (0.00095)	Tok/s 52327 (53447)	Loss/tok 3.6599 (4.3101)	Learning Rate [0.00125]
11: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00083 (0.00091)	Tok/s 52245 (53730)	Loss/tok 3.6846 (4.3158)	Learning Rate [0.00125]
8: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00094)	Tok/s 52192 (53526)	Loss/tok 3.5946 (4.3069)	Learning Rate [0.00125]
9: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00093)	Tok/s 52124 (53586)	Loss/tok 3.3829 (4.3106)	Learning Rate [0.00125]
10: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00096)	Tok/s 52283 (53654)	Loss/tok 3.4064 (4.3133)	Learning Rate [0.00125]
13: TRAIN [0][3060/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00097)	Tok/s 52253 (53932)	Loss/tok 3.6479 (4.3096)	Learning Rate [0.00125]
2: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00115 (0.00100)	Tok/s 48641 (53049)	Loss/tok 3.4481 (4.3078)	Learning Rate [0.00125]
3: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00093)	Tok/s 48596 (53143)	Loss/tok 3.3603 (4.3094)	Learning Rate [0.00125]
1: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00116 (0.00094)	Tok/s 48633 (52951)	Loss/tok 2.9730 (4.3097)	Learning Rate [0.00125]
4: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00099)	Tok/s 48531 (53230)	Loss/tok 3.3762 (4.3116)	Learning Rate [0.00125]
6: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00093)	Tok/s 49998 (53386)	Loss/tok 3.2767 (4.3081)	Learning Rate [0.00125]
0: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00097)	Tok/s 48632 (52854)	Loss/tok 3.4211 (4.3151)	Learning Rate [0.00125]
5: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00111 (0.00095)	Tok/s 48835 (53313)	Loss/tok 3.3118 (4.3070)	Learning Rate [0.00125]
15: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00092)	Tok/s 49954 (54159)	Loss/tok 3.6206 (4.3073)	Learning Rate [0.00125]
7: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00115 (0.00095)	Tok/s 49876 (53467)	Loss/tok 3.6005 (4.3070)	Learning Rate [0.00125]
8: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00094)	Tok/s 49962 (53546)	Loss/tok 3.5752 (4.3041)	Learning Rate [0.00125]
14: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00095)	Tok/s 49966 (54051)	Loss/tok 3.1819 (4.3119)	Learning Rate [0.00125]
13: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00097)	Tok/s 50032 (53952)	Loss/tok 3.5020 (4.3066)	Learning Rate [0.00125]
9: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00093)	Tok/s 49949 (53605)	Loss/tok 3.2116 (4.3076)	Learning Rate [0.00125]
11: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00091)	Tok/s 49960 (53750)	Loss/tok 3.4123 (4.3126)	Learning Rate [0.00125]
12: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00102 (0.00097)	Tok/s 49812 (53854)	Loss/tok 3.4101 (4.3096)	Learning Rate [0.00125]
10: TRAIN [0][3070/3416]	Time 0.046 (0.058)	Data 0.00102 (0.00096)	Tok/s 49966 (53674)	Loss/tok 3.4041 (4.3100)	Learning Rate [0.00125]
6: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 86400 (53388)	Loss/tok 3.3176 (4.3052)	Learning Rate [0.00125]
5: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00095)	Tok/s 86411 (53315)	Loss/tok 3.3884 (4.3042)	Learning Rate [0.00125]
9: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00093)	Tok/s 87393 (53607)	Loss/tok 3.3278 (4.3050)	Learning Rate [0.00125]
7: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00095)	Tok/s 87179 (53469)	Loss/tok 3.4391 (4.3044)	Learning Rate [0.00125]
4: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00099)	Tok/s 86414 (53232)	Loss/tok 3.2921 (4.3089)	Learning Rate [0.00125]
8: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00094)	Tok/s 87347 (53548)	Loss/tok 3.1955 (4.3012)	Learning Rate [0.00125]
10: TRAIN [0][3080/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 88480 (53677)	Loss/tok 3.4857 (4.3075)	Learning Rate [0.00125]
3: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 85863 (53146)	Loss/tok 3.3330 (4.3067)	Learning Rate [0.00125]
2: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00100)	Tok/s 85442 (53051)	Loss/tok 3.2824 (4.3051)	Learning Rate [0.00125]
1: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00094)	Tok/s 85475 (52953)	Loss/tok 3.1245 (4.3066)	Learning Rate [0.00125]
12: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 88906 (53856)	Loss/tok 3.6230 (4.3071)	Learning Rate [0.00125]
11: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 88372 (53753)	Loss/tok 3.4984 (4.3101)	Learning Rate [0.00125]
0: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 85603 (52857)	Loss/tok 3.2230 (4.3124)	Learning Rate [0.00125]
13: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00097)	Tok/s 89299 (53955)	Loss/tok 3.2850 (4.3038)	Learning Rate [0.00125]
15: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 90659 (54162)	Loss/tok 3.5376 (4.3045)	Learning Rate [0.00125]
14: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00095)	Tok/s 90084 (54054)	Loss/tok 3.5673 (4.3093)	Learning Rate [0.00125]
14: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
7: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00105 (0.00095)	Tok/s 55581 (53454)	Loss/tok 3.4550 (4.3020)	Learning Rate [0.00125]
8: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00094)	Tok/s 55590 (53533)	Loss/tok 3.5585 (4.2987)	Learning Rate [0.00125]
6: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00093)	Tok/s 55486 (53373)	Loss/tok 3.9906 (4.3030)	Learning Rate [0.00125]
9: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00093)	Tok/s 55517 (53592)	Loss/tok 3.6517 (4.3028)	Learning Rate [0.00125]
5: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00095)	Tok/s 56090 (53300)	Loss/tok 3.6577 (4.3018)	Learning Rate [0.00125]
4: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00099)	Tok/s 55415 (53216)	Loss/tok 3.8133 (4.3068)	Learning Rate [0.00125]
10: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00096)	Tok/s 55590 (53662)	Loss/tok 3.8213 (4.3056)	Learning Rate [0.00125]
3: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00093)	Tok/s 55320 (53130)	Loss/tok 3.5549 (4.3043)	Learning Rate [0.00125]
11: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00091)	Tok/s 55420 (53738)	Loss/tok 3.6674 (4.3077)	Learning Rate [0.00125]
2: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00107 (0.00100)	Tok/s 55395 (53035)	Loss/tok 3.6558 (4.3028)	Learning Rate [0.00125]
1: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00094)	Tok/s 55447 (52938)	Loss/tok 3.5673 (4.3042)	Learning Rate [0.00125]
12: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00097)	Tok/s 55495 (53841)	Loss/tok 3.4409 (4.3047)	Learning Rate [0.00125]
15: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00092)	Tok/s 56462 (54147)	Loss/tok 3.5889 (4.3021)	Learning Rate [0.00125]
0: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00097)	Tok/s 55398 (52842)	Loss/tok 3.7497 (4.3101)	Learning Rate [0.00125]
13: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00097)	Tok/s 56386 (53940)	Loss/tok 3.3994 (4.3015)	Learning Rate [0.00125]
14: TRAIN [0][3090/3416]	Time 0.062 (0.058)	Data 0.00123 (0.00095)	Tok/s 57191 (54039)	Loss/tok 3.6439 (4.3071)	Learning Rate [0.00125]
2: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
15: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
6: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
12: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 512.0
2: Skipped batch, new scale: 512.0
3: Skipped batch, new scale: 512.0
4: Gradient norm: inf
0: Skipped batch, new scale: 512.0
15: Gradient norm: inf
4: Skipped batch, new scale: 512.0
5: Gradient norm: inf
14: Gradient norm: inf
15: Skipped batch, new scale: 512.0
5: Skipped batch, new scale: 512.0
6: Gradient norm: inf
3: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 85558 (53170)	Loss/tok 3.4671 (4.3008)	Learning Rate [0.00125]
2: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00100)	Tok/s 85421 (53075)	Loss/tok 3.3848 (4.2998)	Learning Rate [0.00125]
1: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00094)	Tok/s 84796 (52978)	Loss/tok 3.3913 (4.3007)	Learning Rate [0.00125]
14: Skipped batch, new scale: 512.0
13: Gradient norm: inf
6: Skipped batch, new scale: 512.0
7: Gradient norm: inf
0: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 84322 (52882)	Loss/tok 3.5881 (4.3062)	Learning Rate [0.00125]
12: Gradient norm: inf
4: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00099)	Tok/s 85785 (53256)	Loss/tok 3.3028 (4.3032)	Learning Rate [0.00125]
13: Skipped batch, new scale: 512.0
8: Gradient norm: inf
7: Skipped batch, new scale: 512.0
11: Gradient norm: inf
12: Skipped batch, new scale: 512.0
15: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 91089 (54190)	Loss/tok 3.3737 (4.2988)	Learning Rate [0.00125]
5: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00095)	Tok/s 86491 (53340)	Loss/tok 3.4124 (4.2985)	Learning Rate [0.00125]
8: Skipped batch, new scale: 512.0
11: Skipped batch, new scale: 512.0
10: Gradient norm: inf
9: Gradient norm: inf
14: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00095)	Tok/s 89694 (54081)	Loss/tok 3.2926 (4.3033)	Learning Rate [0.00125]
9: Skipped batch, new scale: 512.0
6: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00093)	Tok/s 86356 (53413)	Loss/tok 3.3189 (4.2993)	Learning Rate [0.00125]
10: Skipped batch, new scale: 512.0
13: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00097)	Tok/s 88746 (53981)	Loss/tok 3.3888 (4.2979)	Learning Rate [0.00125]
7: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00096)	Tok/s 86402 (53494)	Loss/tok 3.3368 (4.2982)	Learning Rate [0.00125]
12: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 88572 (53882)	Loss/tok 3.3982 (4.3013)	Learning Rate [0.00125]
11: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 87768 (53779)	Loss/tok 3.2295 (4.3039)	Learning Rate [0.00125]
8: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00094)	Tok/s 87033 (53573)	Loss/tok 3.4622 (4.2953)	Learning Rate [0.00125]
10: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 87411 (53702)	Loss/tok 3.3978 (4.3020)	Learning Rate [0.00125]
9: TRAIN [0][3100/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 86901 (53633)	Loss/tok 3.2862 (4.2993)	Learning Rate [0.00125]
6: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 65151 (53405)	Loss/tok 3.8613 (4.2971)	Learning Rate [0.00125]
8: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00094)	Tok/s 65023 (53565)	Loss/tok 3.5484 (4.2929)	Learning Rate [0.00125]
7: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00096)	Tok/s 65037 (53486)	Loss/tok 3.7466 (4.2957)	Learning Rate [0.00125]
5: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00095)	Tok/s 65125 (53333)	Loss/tok 3.9450 (4.2962)	Learning Rate [0.00125]
4: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00099)	Tok/s 64974 (53249)	Loss/tok 3.7526 (4.3007)	Learning Rate [0.00125]
3: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 65131 (53163)	Loss/tok 3.8272 (4.2985)	Learning Rate [0.00125]
9: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 65020 (53625)	Loss/tok 3.4358 (4.2969)	Learning Rate [0.00125]
2: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00100)	Tok/s 65057 (53068)	Loss/tok 3.7262 (4.2977)	Learning Rate [0.00125]
1: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00094)	Tok/s 65133 (52971)	Loss/tok 3.3359 (4.2981)	Learning Rate [0.00125]
10: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 65587 (53695)	Loss/tok 3.5945 (4.2996)	Learning Rate [0.00125]
11: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00091)	Tok/s 65949 (53771)	Loss/tok 3.5686 (4.3015)	Learning Rate [0.00125]
0: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 65198 (52875)	Loss/tok 3.7165 (4.3040)	Learning Rate [0.00125]
12: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 65836 (53875)	Loss/tok 3.6282 (4.2990)	Learning Rate [0.00125]
15: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 66008 (54182)	Loss/tok 3.6884 (4.2965)	Learning Rate [0.00125]
14: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00095)	Tok/s 65997 (54073)	Loss/tok 3.6368 (4.3011)	Learning Rate [0.00125]
13: TRAIN [0][3110/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 65956 (53974)	Loss/tok 3.6742 (4.2958)	Learning Rate [0.00125]
2: TRAIN [0][3120/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 72678 (53080)	Loss/tok 3.4368 (4.2948)	Learning Rate [0.00125]
6: TRAIN [0][3120/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 72652 (53417)	Loss/tok 3.5114 (4.2942)	Learning Rate [0.00125]
3: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 72764 (53175)	Loss/tok 3.8504 (4.2955)	Learning Rate [0.00125]
1: TRAIN [0][3120/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00094)	Tok/s 72476 (52983)	Loss/tok 3.2958 (4.2952)	Learning Rate [0.00125]
4: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00099)	Tok/s 72776 (53261)	Loss/tok 3.7155 (4.2977)	Learning Rate [0.00125]
0: TRAIN [0][3120/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 71545 (52887)	Loss/tok 3.6441 (4.3013)	Learning Rate [0.00125]
10: TRAIN [0][3120/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 72221 (53707)	Loss/tok 3.3821 (4.2969)	Learning Rate [0.00125]
11: TRAIN [0][3120/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00091)	Tok/s 72122 (53783)	Loss/tok 3.7100 (4.2987)	Learning Rate [0.00125]
14: TRAIN [0][3120/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00095)	Tok/s 73239 (54085)	Loss/tok 3.3855 (4.2981)	Learning Rate [0.00125]
9: TRAIN [0][3120/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 72475 (53637)	Loss/tok 3.6412 (4.2942)	Learning Rate [0.00125]
13: TRAIN [0][3120/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 73106 (53986)	Loss/tok 3.5457 (4.2932)	Learning Rate [0.00125]
8: TRAIN [0][3120/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00094)	Tok/s 72441 (53577)	Loss/tok 3.5929 (4.2902)	Learning Rate [0.00125]
12: TRAIN [0][3120/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 72764 (53886)	Loss/tok 3.4308 (4.2959)	Learning Rate [0.00125]
7: TRAIN [0][3120/3416]	Time 0.070 (0.058)	Data 0.00114 (0.00096)	Tok/s 72689 (53498)	Loss/tok 3.6851 (4.2928)	Learning Rate [0.00125]
5: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00095)	Tok/s 72899 (53345)	Loss/tok 3.4085 (4.2930)	Learning Rate [0.00125]
15: TRAIN [0][3120/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 73298 (54194)	Loss/tok 3.5461 (4.2937)	Learning Rate [0.00125]
3: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00093)	Tok/s 51320 (53163)	Loss/tok 3.7395 (4.2930)	Learning Rate [0.00125]
4: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00099)	Tok/s 51252 (53250)	Loss/tok 3.4190 (4.2952)	Learning Rate [0.00125]
2: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00100)	Tok/s 51365 (53069)	Loss/tok 3.2532 (4.2921)	Learning Rate [0.00125]
1: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00102 (0.00094)	Tok/s 51356 (52971)	Loss/tok 3.4887 (4.2928)	Learning Rate [0.00125]
6: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00093)	Tok/s 52149 (53406)	Loss/tok 3.5998 (4.2918)	Learning Rate [0.00125]
0: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00097)	Tok/s 51335 (52875)	Loss/tok 3.4206 (4.2991)	Learning Rate [0.00125]
15: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00092)	Tok/s 52578 (54182)	Loss/tok 3.6880 (4.2915)	Learning Rate [0.00125]
5: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00095)	Tok/s 51108 (53333)	Loss/tok 3.4891 (4.2906)	Learning Rate [0.00125]
7: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00110 (0.00096)	Tok/s 52137 (53487)	Loss/tok 3.4001 (4.2906)	Learning Rate [0.00125]
14: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00101 (0.00095)	Tok/s 52545 (54073)	Loss/tok 3.3517 (4.2956)	Learning Rate [0.00125]
11: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00102 (0.00091)	Tok/s 52256 (53771)	Loss/tok 3.4889 (4.2963)	Learning Rate [0.00125]
8: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00094)	Tok/s 52080 (53565)	Loss/tok 3.5349 (4.2880)	Learning Rate [0.00125]
9: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00093)	Tok/s 52144 (53625)	Loss/tok 3.3571 (4.2915)	Learning Rate [0.00125]
13: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00097)	Tok/s 52428 (53974)	Loss/tok 3.5120 (4.2909)	Learning Rate [0.00125]
10: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00096)	Tok/s 52226 (53694)	Loss/tok 3.2617 (4.2945)	Learning Rate [0.00125]
12: TRAIN [0][3130/3416]	Time 0.049 (0.058)	Data 0.00103 (0.00097)	Tok/s 52262 (53875)	Loss/tok 3.5233 (4.2935)	Learning Rate [0.00125]
14: TRAIN [0][3140/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00095)	Tok/s 56069 (54070)	Loss/tok 3.7142 (4.2934)	Learning Rate [0.00125]
15: TRAIN [0][3140/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00092)	Tok/s 55972 (54179)	Loss/tok 3.7225 (4.2892)	Learning Rate [0.00125]
13: TRAIN [0][3140/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00097)	Tok/s 56049 (53971)	Loss/tok 3.6072 (4.2885)	Learning Rate [0.00125]
11: TRAIN [0][3140/3416]	Time 0.067 (0.058)	Data 0.00111 (0.00091)	Tok/s 56100 (53769)	Loss/tok 3.5776 (4.2938)	Learning Rate [0.00125]
0: TRAIN [0][3140/3416]	Time 0.068 (0.058)	Data 0.00123 (0.00097)	Tok/s 54877 (52873)	Loss/tok 3.6756 (4.2966)	Learning Rate [0.00125]
1: TRAIN [0][3140/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00094)	Tok/s 55766 (52968)	Loss/tok 3.5554 (4.2904)	Learning Rate [0.00125]
12: TRAIN [0][3140/3416]	Time 0.067 (0.058)	Data 0.00113 (0.00097)	Tok/s 56027 (53872)	Loss/tok 3.8825 (4.2911)	Learning Rate [0.00125]
2: TRAIN [0][3140/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00100)	Tok/s 55767 (53065)	Loss/tok 3.4581 (4.2899)	Learning Rate [0.00125]
8: TRAIN [0][3140/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00094)	Tok/s 56062 (53563)	Loss/tok 3.6505 (4.2859)	Learning Rate [0.00125]
10: TRAIN [0][3140/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00096)	Tok/s 56028 (53692)	Loss/tok 3.5373 (4.2923)	Learning Rate [0.00125]
9: TRAIN [0][3140/3416]	Time 0.067 (0.058)	Data 0.00102 (0.00093)	Tok/s 56068 (53622)	Loss/tok 3.4918 (4.2891)	Learning Rate [0.00125]
3: TRAIN [0][3140/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00093)	Tok/s 55772 (53160)	Loss/tok 3.5019 (4.2905)	Learning Rate [0.00125]
7: TRAIN [0][3140/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00096)	Tok/s 55877 (53484)	Loss/tok 3.2940 (4.2880)	Learning Rate [0.00125]
6: TRAIN [0][3140/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00093)	Tok/s 55712 (53402)	Loss/tok 3.5680 (4.2895)	Learning Rate [0.00125]
5: TRAIN [0][3140/3416]	Time 0.068 (0.058)	Data 0.00116 (0.00095)	Tok/s 55782 (53329)	Loss/tok 3.6807 (4.2883)	Learning Rate [0.00125]
4: TRAIN [0][3140/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00099)	Tok/s 55737 (53246)	Loss/tok 3.4409 (4.2929)	Learning Rate [0.00125]
13: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00097)	Tok/s 51958 (53979)	Loss/tok 3.5207 (4.2855)	Learning Rate [0.00125]
14: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00095)	Tok/s 52011 (54078)	Loss/tok 3.3459 (4.2904)	Learning Rate [0.00125]
12: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00097)	Tok/s 51978 (53880)	Loss/tok 3.3709 (4.2885)	Learning Rate [0.00125]
15: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00092)	Tok/s 52007 (54187)	Loss/tok 3.4675 (4.2864)	Learning Rate [0.00125]
9: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00093)	Tok/s 51896 (53630)	Loss/tok 3.3881 (4.2862)	Learning Rate [0.00125]
0: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00097)	Tok/s 50713 (52876)	Loss/tok 3.4868 (4.2937)	Learning Rate [0.00125]
10: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00096)	Tok/s 51870 (53699)	Loss/tok 3.4473 (4.2897)	Learning Rate [0.00125]
1: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00094)	Tok/s 50698 (52972)	Loss/tok 3.0291 (4.2875)	Learning Rate [0.00125]
8: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00094)	Tok/s 51306 (53570)	Loss/tok 3.4399 (4.2829)	Learning Rate [0.00125]
3: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00093)	Tok/s 50784 (53166)	Loss/tok 3.3819 (4.2879)	Learning Rate [0.00125]
7: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00095)	Tok/s 50628 (53491)	Loss/tok 3.5659 (4.2852)	Learning Rate [0.00125]
6: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00093)	Tok/s 50580 (53409)	Loss/tok 3.3638 (4.2868)	Learning Rate [0.00125]
5: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00095)	Tok/s 50700 (53336)	Loss/tok 3.7251 (4.2859)	Learning Rate [0.00125]
4: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00099)	Tok/s 50599 (53253)	Loss/tok 3.4415 (4.2902)	Learning Rate [0.00125]
11: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00091)	Tok/s 51959 (53776)	Loss/tok 3.5208 (4.2910)	Learning Rate [0.00125]
2: TRAIN [0][3150/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00100)	Tok/s 50675 (53071)	Loss/tok 3.4808 (4.2870)	Learning Rate [0.00125]
6: TRAIN [0][3160/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 61748 (53429)	Loss/tok 3.4668 (4.2841)	Learning Rate [0.00125]
5: TRAIN [0][3160/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00095)	Tok/s 61791 (53356)	Loss/tok 3.3048 (4.2828)	Learning Rate [0.00125]
4: TRAIN [0][3160/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 61788 (53273)	Loss/tok 3.6245 (4.2876)	Learning Rate [0.00125]
3: TRAIN [0][3160/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 61791 (53186)	Loss/tok 3.7067 (4.2852)	Learning Rate [0.00125]
9: TRAIN [0][3160/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 61557 (53649)	Loss/tok 3.8111 (4.2837)	Learning Rate [0.00125]
7: TRAIN [0][3160/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00095)	Tok/s 61575 (53511)	Loss/tok 3.6022 (4.2824)	Learning Rate [0.00125]
2: TRAIN [0][3160/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00100)	Tok/s 61789 (53091)	Loss/tok 3.6111 (4.2843)	Learning Rate [0.00125]
8: TRAIN [0][3160/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00094)	Tok/s 61456 (53589)	Loss/tok 3.4636 (4.2801)	Learning Rate [0.00125]
1: TRAIN [0][3160/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00094)	Tok/s 61684 (52992)	Loss/tok 3.9241 (4.2851)	Learning Rate [0.00125]
0: TRAIN [0][3160/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 60826 (52896)	Loss/tok 3.6084 (4.2909)	Learning Rate [0.00125]
15: TRAIN [0][3160/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 61692 (54206)	Loss/tok 3.7039 (4.2836)	Learning Rate [0.00125]
10: TRAIN [0][3160/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00096)	Tok/s 61409 (53718)	Loss/tok 3.7062 (4.2871)	Learning Rate [0.00125]
13: TRAIN [0][3160/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 61517 (53998)	Loss/tok 3.7691 (4.2827)	Learning Rate [0.00125]
12: TRAIN [0][3160/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 61543 (53899)	Loss/tok 3.7052 (4.2859)	Learning Rate [0.00125]
14: TRAIN [0][3160/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00095)	Tok/s 61606 (54097)	Loss/tok 3.6989 (4.2877)	Learning Rate [0.00125]
11: TRAIN [0][3160/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00091)	Tok/s 61564 (53795)	Loss/tok 3.7333 (4.2886)	Learning Rate [0.00125]
5: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00076 (0.00095)	Tok/s 52025 (53358)	Loss/tok 3.5005 (4.2801)	Learning Rate [0.00125]
6: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00089 (0.00093)	Tok/s 52004 (53431)	Loss/tok 3.3646 (4.2812)	Learning Rate [0.00125]
4: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00099)	Tok/s 51991 (53275)	Loss/tok 3.3929 (4.2849)	Learning Rate [0.00125]
3: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00083 (0.00093)	Tok/s 51951 (53188)	Loss/tok 3.5271 (4.2824)	Learning Rate [0.00125]
7: TRAIN [0][3170/3416]	Time 0.056 (0.058)	Data 0.00082 (0.00095)	Tok/s 52106 (53513)	Loss/tok 3.5124 (4.2799)	Learning Rate [0.00125]
2: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00100)	Tok/s 52026 (53093)	Loss/tok 3.6573 (4.2818)	Learning Rate [0.00125]
8: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00094)	Tok/s 52081 (53592)	Loss/tok 3.3384 (4.2774)	Learning Rate [0.00125]
1: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00094)	Tok/s 51987 (52995)	Loss/tok 3.6096 (4.2823)	Learning Rate [0.00125]
0: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00097)	Tok/s 51989 (52898)	Loss/tok 3.5906 (4.2882)	Learning Rate [0.00125]
9: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00081 (0.00093)	Tok/s 52056 (53651)	Loss/tok 3.4789 (4.2809)	Learning Rate [0.00125]
10: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00086 (0.00096)	Tok/s 52072 (53721)	Loss/tok 3.5284 (4.2843)	Learning Rate [0.00125]
14: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00085 (0.00095)	Tok/s 53081 (54100)	Loss/tok 3.6681 (4.2852)	Learning Rate [0.00125]
13: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00097)	Tok/s 52738 (54001)	Loss/tok 3.4624 (4.2798)	Learning Rate [0.00125]
12: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00100 (0.00097)	Tok/s 52028 (53902)	Loss/tok 3.5867 (4.2834)	Learning Rate [0.00125]
15: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00084 (0.00092)	Tok/s 52879 (54209)	Loss/tok 3.2849 (4.2808)	Learning Rate [0.00125]
11: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00091)	Tok/s 52072 (53798)	Loss/tok 3.5568 (4.2860)	Learning Rate [0.00125]
4: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00099)	Tok/s 55630 (53271)	Loss/tok 3.6017 (4.2823)	Learning Rate [0.00125]
6: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00093)	Tok/s 55677 (53427)	Loss/tok 3.7305 (4.2789)	Learning Rate [0.00125]
5: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00095)	Tok/s 55663 (53353)	Loss/tok 3.5110 (4.2776)	Learning Rate [0.00125]
3: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00093)	Tok/s 55500 (53183)	Loss/tok 3.8691 (4.2800)	Learning Rate [0.00125]
2: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00100)	Tok/s 55479 (53087)	Loss/tok 3.6229 (4.2793)	Learning Rate [0.00125]
7: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00095)	Tok/s 55770 (53509)	Loss/tok 3.3949 (4.2772)	Learning Rate [0.00125]
8: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00094)	Tok/s 56640 (53588)	Loss/tok 3.7614 (4.2748)	Learning Rate [0.00125]
1: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00094)	Tok/s 55474 (52988)	Loss/tok 3.7152 (4.2798)	Learning Rate [0.00125]
9: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00087 (0.00093)	Tok/s 56630 (53647)	Loss/tok 3.7247 (4.2782)	Learning Rate [0.00125]
0: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00087 (0.00097)	Tok/s 55460 (52891)	Loss/tok 3.9238 (4.2856)	Learning Rate [0.00125]
15: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00092)	Tok/s 56454 (54207)	Loss/tok 3.7183 (4.2781)	Learning Rate [0.00125]
10: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00096)	Tok/s 56591 (53718)	Loss/tok 3.8010 (4.2819)	Learning Rate [0.00125]
14: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00077 (0.00095)	Tok/s 56428 (54099)	Loss/tok 3.7900 (4.2825)	Learning Rate [0.00125]
13: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00097)	Tok/s 56449 (53999)	Loss/tok 3.7493 (4.2773)	Learning Rate [0.00125]
12: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00097)	Tok/s 56405 (53900)	Loss/tok 3.5858 (4.2811)	Learning Rate [0.00125]
11: TRAIN [0][3180/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00091)	Tok/s 56561 (53795)	Loss/tok 3.4456 (4.2835)	Learning Rate [0.00125]
5: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00095)	Tok/s 54527 (53358)	Loss/tok 3.6536 (4.2754)	Learning Rate [0.00125]
6: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00093)	Tok/s 54416 (53432)	Loss/tok 3.5248 (4.2762)	Learning Rate [0.00125]
4: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00105 (0.00100)	Tok/s 54489 (53276)	Loss/tok 3.5599 (4.2796)	Learning Rate [0.00125]
3: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00093)	Tok/s 54430 (53188)	Loss/tok 3.5954 (4.2775)	Learning Rate [0.00125]
2: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00112 (0.00100)	Tok/s 54366 (53093)	Loss/tok 3.6736 (4.2768)	Learning Rate [0.00125]
7: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00095)	Tok/s 54346 (53514)	Loss/tok 3.5748 (4.2746)	Learning Rate [0.00125]
1: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00094)	Tok/s 54380 (52993)	Loss/tok 3.5474 (4.2772)	Learning Rate [0.00125]
8: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00094)	Tok/s 55170 (53593)	Loss/tok 3.6498 (4.2723)	Learning Rate [0.00125]
9: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00087 (0.00093)	Tok/s 55087 (53652)	Loss/tok 3.6579 (4.2757)	Learning Rate [0.00125]
11: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00091)	Tok/s 54962 (53800)	Loss/tok 3.7144 (4.2811)	Learning Rate [0.00125]
0: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00107 (0.00097)	Tok/s 54172 (52896)	Loss/tok 3.4806 (4.2833)	Learning Rate [0.00125]
10: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00096)	Tok/s 54989 (53722)	Loss/tok 3.7894 (4.2795)	Learning Rate [0.00125]
15: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00092)	Tok/s 55030 (54212)	Loss/tok 3.5400 (4.2757)	Learning Rate [0.00125]
14: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00095)	Tok/s 54944 (54104)	Loss/tok 3.3815 (4.2798)	Learning Rate [0.00125]
13: TRAIN [0][3190/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00097)	Tok/s 54889 (54004)	Loss/tok 3.5969 (4.2750)	Learning Rate [0.00125]
12: TRAIN [0][3190/3416]	Time 0.067 (0.058)	Data 0.00107 (0.00097)	Tok/s 54783 (53904)	Loss/tok 3.6046 (4.2785)	Learning Rate [0.00125]
2: TRAIN [0][3200/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00100)	Tok/s 49771 (53095)	Loss/tok 3.4133 (4.2746)	Learning Rate [0.00125]
1: TRAIN [0][3200/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00094)	Tok/s 49683 (52996)	Loss/tok 3.5797 (4.2750)	Learning Rate [0.00125]
3: TRAIN [0][3200/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00093)	Tok/s 49733 (53190)	Loss/tok 3.4836 (4.2752)	Learning Rate [0.00125]
0: TRAIN [0][3200/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00097)	Tok/s 49595 (52899)	Loss/tok 3.4073 (4.2809)	Learning Rate [0.00125]
4: TRAIN [0][3200/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00100)	Tok/s 49575 (53277)	Loss/tok 3.3027 (4.2773)	Learning Rate [0.00125]
15: TRAIN [0][3200/3416]	Time 0.050 (0.058)	Data 0.00076 (0.00092)	Tok/s 50761 (54214)	Loss/tok 3.6295 (4.2732)	Learning Rate [0.00125]
5: TRAIN [0][3200/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00095)	Tok/s 50292 (53360)	Loss/tok 3.4727 (4.2730)	Learning Rate [0.00125]
6: TRAIN [0][3200/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00093)	Tok/s 50682 (53434)	Loss/tok 3.4973 (4.2737)	Learning Rate [0.00125]
14: TRAIN [0][3200/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00095)	Tok/s 50617 (54106)	Loss/tok 3.6859 (4.2777)	Learning Rate [0.00125]
13: TRAIN [0][3200/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00097)	Tok/s 50520 (54006)	Loss/tok 3.6469 (4.2727)	Learning Rate [0.00125]
7: TRAIN [0][3200/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00095)	Tok/s 50595 (53516)	Loss/tok 3.5048 (4.2723)	Learning Rate [0.00125]
8: TRAIN [0][3200/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00094)	Tok/s 50469 (53595)	Loss/tok 3.3874 (4.2700)	Learning Rate [0.00125]
11: TRAIN [0][3200/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00091)	Tok/s 50290 (53802)	Loss/tok 3.6752 (4.2792)	Learning Rate [0.00125]
9: TRAIN [0][3200/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00093)	Tok/s 50365 (53654)	Loss/tok 3.5193 (4.2734)	Learning Rate [0.00125]
12: TRAIN [0][3200/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00097)	Tok/s 50409 (53907)	Loss/tok 3.2768 (4.2763)	Learning Rate [0.00125]
10: TRAIN [0][3200/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00096)	Tok/s 50336 (53724)	Loss/tok 3.5038 (4.2772)	Learning Rate [0.00125]
11: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00091)	Tok/s 54439 (53785)	Loss/tok 3.3801 (4.2771)	Learning Rate [0.00125]
12: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00097)	Tok/s 54431 (53890)	Loss/tok 3.5585 (4.2740)	Learning Rate [0.00125]
14: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00095)	Tok/s 54464 (54089)	Loss/tok 3.5416 (4.2756)	Learning Rate [0.00125]
15: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00082 (0.00092)	Tok/s 54448 (54197)	Loss/tok 3.6072 (4.2709)	Learning Rate [0.00125]
0: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00097)	Tok/s 54015 (52883)	Loss/tok 3.3494 (4.2787)	Learning Rate [0.00125]
9: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00093)	Tok/s 54340 (53637)	Loss/tok 3.5351 (4.2713)	Learning Rate [0.00125]
2: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00100)	Tok/s 54494 (53079)	Loss/tok 3.4509 (4.2723)	Learning Rate [0.00125]
10: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00096)	Tok/s 54416 (53707)	Loss/tok 3.5492 (4.2751)	Learning Rate [0.00125]
1: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00094)	Tok/s 54471 (52980)	Loss/tok 3.4943 (4.2730)	Learning Rate [0.00125]
6: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00093)	Tok/s 54257 (53417)	Loss/tok 3.3803 (4.2715)	Learning Rate [0.00125]
7: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00095)	Tok/s 54297 (53499)	Loss/tok 3.6543 (4.2703)	Learning Rate [0.00125]
3: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00093)	Tok/s 54404 (53173)	Loss/tok 3.3772 (4.2730)	Learning Rate [0.00125]
4: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00118 (0.00100)	Tok/s 54355 (53260)	Loss/tok 3.5179 (4.2753)	Learning Rate [0.00125]
5: TRAIN [0][3210/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00095)	Tok/s 54285 (53343)	Loss/tok 3.5303 (4.2708)	Learning Rate [0.00125]
13: TRAIN [0][3210/3416]	Time 0.060 (0.058)	Data 0.00106 (0.00097)	Tok/s 53765 (53989)	Loss/tok 3.5110 (4.2706)	Learning Rate [0.00125]
8: TRAIN [0][3210/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00094)	Tok/s 53486 (53578)	Loss/tok 3.3893 (4.2680)	Learning Rate [0.00125]
0: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 84992 (52863)	Loss/tok 3.4428 (4.2764)	Learning Rate [0.00125]
1: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00094)	Tok/s 84815 (52961)	Loss/tok 3.4494 (4.2707)	Learning Rate [0.00125]
15: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 90031 (54188)	Loss/tok 3.3661 (4.2685)	Learning Rate [0.00125]
2: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00100)	Tok/s 84706 (53062)	Loss/tok 3.3801 (4.2700)	Learning Rate [0.00125]
14: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00095)	Tok/s 89350 (54080)	Loss/tok 3.4356 (4.2733)	Learning Rate [0.00125]
13: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 88644 (53979)	Loss/tok 3.3793 (4.2684)	Learning Rate [0.00125]
3: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 85208 (53157)	Loss/tok 3.3994 (4.2705)	Learning Rate [0.00125]
4: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00100)	Tok/s 85561 (53246)	Loss/tok 3.2896 (4.2728)	Learning Rate [0.00125]
11: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00091)	Tok/s 87711 (53774)	Loss/tok 3.4788 (4.2747)	Learning Rate [0.00125]
12: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 87920 (53879)	Loss/tok 3.3217 (4.2715)	Learning Rate [0.00125]
5: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00095)	Tok/s 85679 (53330)	Loss/tok 3.3675 (4.2685)	Learning Rate [0.00125]
10: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00096)	Tok/s 87191 (53696)	Loss/tok 3.2633 (4.2727)	Learning Rate [0.00125]
6: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 85647 (53404)	Loss/tok 3.4586 (4.2690)	Learning Rate [0.00125]
9: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 86726 (53626)	Loss/tok 3.2784 (4.2688)	Learning Rate [0.00125]
8: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00076 (0.00094)	Tok/s 86615 (53567)	Loss/tok 3.3394 (4.2655)	Learning Rate [0.00125]
7: TRAIN [0][3220/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00095)	Tok/s 86129 (53487)	Loss/tok 3.4288 (4.2679)	Learning Rate [0.00125]
9: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
11: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00091)	Tok/s 55127 (53769)	Loss/tok 3.5740 (4.2724)	Learning Rate [0.00125]
9: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00093)	Tok/s 55138 (53622)	Loss/tok 3.3778 (4.2666)	Learning Rate [0.00125]
10: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00116 (0.00096)	Tok/s 55128 (53691)	Loss/tok 3.7879 (4.2703)	Learning Rate [0.00125]
6: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00093)	Tok/s 55256 (53400)	Loss/tok 3.7336 (4.2668)	Learning Rate [0.00125]
8: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00094)	Tok/s 55176 (53563)	Loss/tok 3.6494 (4.2633)	Learning Rate [0.00125]
12: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00111 (0.00097)	Tok/s 55015 (53875)	Loss/tok 3.5523 (4.2693)	Learning Rate [0.00125]
4: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00108 (0.00100)	Tok/s 55288 (53241)	Loss/tok 3.7878 (4.2705)	Learning Rate [0.00125]
13: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00097)	Tok/s 54928 (53975)	Loss/tok 3.5977 (4.2660)	Learning Rate [0.00125]
5: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00095)	Tok/s 55287 (53325)	Loss/tok 3.4490 (4.2661)	Learning Rate [0.00125]
7: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00095)	Tok/s 55188 (53483)	Loss/tok 3.7218 (4.2655)	Learning Rate [0.00125]
14: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00095)	Tok/s 54937 (54076)	Loss/tok 3.8200 (4.2711)	Learning Rate [0.00125]
3: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00093)	Tok/s 55166 (53153)	Loss/tok 3.2071 (4.2681)	Learning Rate [0.00125]
2: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00112 (0.00101)	Tok/s 55104 (53057)	Loss/tok 3.5389 (4.2677)	Learning Rate [0.00125]
15: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00092)	Tok/s 54939 (54184)	Loss/tok 3.4733 (4.2665)	Learning Rate [0.00125]
1: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00094)	Tok/s 55001 (52957)	Loss/tok 3.5761 (4.2684)	Learning Rate [0.00125]
0: TRAIN [0][3230/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00097)	Tok/s 54945 (52858)	Loss/tok 3.4972 (4.2743)	Learning Rate [0.00125]
10: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 81381 (53726)	Loss/tok 3.4693 (4.2674)	Learning Rate [0.00125]
4: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00100)	Tok/s 80088 (53276)	Loss/tok 3.5403 (4.2677)	Learning Rate [0.00125]
3: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00093)	Tok/s 80190 (53189)	Loss/tok 3.6290 (4.2654)	Learning Rate [0.00125]
2: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00101)	Tok/s 80291 (53092)	Loss/tok 3.3466 (4.2644)	Learning Rate [0.00125]
11: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00091)	Tok/s 81192 (53804)	Loss/tok 3.5686 (4.2698)	Learning Rate [0.00125]
8: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00094)	Tok/s 81101 (53597)	Loss/tok 3.6439 (4.2604)	Learning Rate [0.00125]
9: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00093)	Tok/s 81057 (53656)	Loss/tok 3.3476 (4.2634)	Learning Rate [0.00125]
5: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00095)	Tok/s 80119 (53360)	Loss/tok 3.2612 (4.2633)	Learning Rate [0.00125]
1: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00094)	Tok/s 80230 (52992)	Loss/tok 3.3973 (4.2656)	Learning Rate [0.00125]
6: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00093)	Tok/s 80092 (53434)	Loss/tok 3.3724 (4.2635)	Learning Rate [0.00125]
7: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00095)	Tok/s 80401 (53517)	Loss/tok 3.3732 (4.2628)	Learning Rate [0.00125]
13: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 81313 (54009)	Loss/tok 3.3053 (4.2631)	Learning Rate [0.00125]
0: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 79714 (52894)	Loss/tok 3.5650 (4.2715)	Learning Rate [0.00125]
12: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00097)	Tok/s 81109 (53909)	Loss/tok 3.2534 (4.2663)	Learning Rate [0.00125]
14: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00095)	Tok/s 81638 (54110)	Loss/tok 3.3023 (4.2682)	Learning Rate [0.00125]
15: TRAIN [0][3240/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 81900 (54219)	Loss/tok 3.3089 (4.2635)	Learning Rate [0.00125]
6: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00092 (0.00093)	Tok/s 27092 (53404)	Loss/tok 2.6300 (4.2615)	Learning Rate [0.00125]
5: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00091 (0.00095)	Tok/s 27054 (53330)	Loss/tok 2.5645 (4.2614)	Learning Rate [0.00125]
7: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00092 (0.00095)	Tok/s 28044 (53488)	Loss/tok 2.5656 (4.2606)	Learning Rate [0.00125]
4: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00096 (0.00100)	Tok/s 26933 (53246)	Loss/tok 2.7324 (4.2657)	Learning Rate [0.00125]
8: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00089 (0.00094)	Tok/s 28678 (53568)	Loss/tok 2.6068 (4.2583)	Learning Rate [0.00125]
3: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00095 (0.00093)	Tok/s 26491 (53157)	Loss/tok 2.4601 (4.2637)	Learning Rate [0.00125]
2: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00104 (0.00101)	Tok/s 25200 (53060)	Loss/tok 2.4160 (4.2627)	Learning Rate [0.00125]
9: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00091 (0.00093)	Tok/s 28543 (53628)	Loss/tok 2.6292 (4.2614)	Learning Rate [0.00125]
1: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00096 (0.00094)	Tok/s 25146 (52959)	Loss/tok 2.2169 (4.2637)	Learning Rate [0.00125]
10: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00086 (0.00096)	Tok/s 28540 (53698)	Loss/tok 2.6272 (4.2653)	Learning Rate [0.00125]
11: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00088 (0.00091)	Tok/s 28491 (53775)	Loss/tok 2.5542 (4.2678)	Learning Rate [0.00125]
0: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00085 (0.00097)	Tok/s 25048 (52860)	Loss/tok 2.3718 (4.2695)	Learning Rate [0.00125]
15: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00081 (0.00092)	Tok/s 30018 (54192)	Loss/tok 2.6415 (4.2614)	Learning Rate [0.00125]
14: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00089 (0.00095)	Tok/s 30018 (54083)	Loss/tok 2.7031 (4.2663)	Learning Rate [0.00125]
13: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00090 (0.00096)	Tok/s 29802 (53982)	Loss/tok 2.5636 (4.2614)	Learning Rate [0.00125]
12: TRAIN [0][3250/3416]	Time 0.038 (0.058)	Data 0.00085 (0.00097)	Tok/s 28475 (53881)	Loss/tok 2.4437 (4.2644)	Learning Rate [0.00125]
7: TRAIN [0][3260/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00095)	Tok/s 32861 (53491)	Loss/tok 3.2727 (4.2583)	Learning Rate [0.00125]
8: TRAIN [0][3260/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00094)	Tok/s 32354 (53571)	Loss/tok 3.2244 (4.2560)	Learning Rate [0.00125]
6: TRAIN [0][3260/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00093)	Tok/s 32434 (53408)	Loss/tok 3.1184 (4.2594)	Learning Rate [0.00125]
9: TRAIN [0][3260/3416]	Time 0.048 (0.058)	Data 0.00110 (0.00093)	Tok/s 32293 (53631)	Loss/tok 2.7522 (4.2592)	Learning Rate [0.00125]
4: TRAIN [0][3260/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00100)	Tok/s 32477 (53249)	Loss/tok 3.1292 (4.2633)	Learning Rate [0.00125]
5: TRAIN [0][3260/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00095)	Tok/s 32450 (53334)	Loss/tok 3.1030 (4.2591)	Learning Rate [0.00125]
1: TRAIN [0][3260/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00094)	Tok/s 32506 (52963)	Loss/tok 2.9494 (4.2614)	Learning Rate [0.00125]
3: TRAIN [0][3260/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00093)	Tok/s 32463 (53161)	Loss/tok 2.9506 (4.2613)	Learning Rate [0.00125]
10: TRAIN [0][3260/3416]	Time 0.048 (0.058)	Data 0.00125 (0.00096)	Tok/s 32202 (53700)	Loss/tok 3.0584 (4.2629)	Learning Rate [0.00125]
11: TRAIN [0][3260/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00091)	Tok/s 32232 (53778)	Loss/tok 2.9167 (4.2653)	Learning Rate [0.00125]
0: TRAIN [0][3260/3416]	Time 0.047 (0.058)	Data 0.00122 (0.00097)	Tok/s 32423 (52864)	Loss/tok 3.2045 (4.2672)	Learning Rate [0.00125]
12: TRAIN [0][3260/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00097)	Tok/s 33345 (53884)	Loss/tok 3.1463 (4.2622)	Learning Rate [0.00125]
2: TRAIN [0][3260/3416]	Time 0.047 (0.058)	Data 0.00139 (0.00101)	Tok/s 32549 (53064)	Loss/tok 3.0166 (4.2603)	Learning Rate [0.00125]
15: TRAIN [0][3260/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00092)	Tok/s 33703 (54194)	Loss/tok 3.0245 (4.2590)	Learning Rate [0.00125]
13: TRAIN [0][3260/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00096)	Tok/s 33588 (53984)	Loss/tok 2.8503 (4.2591)	Learning Rate [0.00125]
14: TRAIN [0][3260/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00095)	Tok/s 33619 (54085)	Loss/tok 3.0808 (4.2643)	Learning Rate [0.00125]
2: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00106 (0.00101)	Tok/s 54602 (53077)	Loss/tok 3.5595 (4.2580)	Learning Rate [0.00125]
1: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00094)	Tok/s 54575 (52976)	Loss/tok 3.4327 (4.2589)	Learning Rate [0.00125]
3: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00093)	Tok/s 54595 (53173)	Loss/tok 3.6254 (4.2589)	Learning Rate [0.00125]
4: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00103 (0.00100)	Tok/s 54616 (53262)	Loss/tok 3.4962 (4.2609)	Learning Rate [0.00125]
9: TRAIN [0][3270/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00093)	Tok/s 55566 (53643)	Loss/tok 3.5737 (4.2566)	Learning Rate [0.00125]
0: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00097)	Tok/s 54593 (52877)	Loss/tok 3.5177 (4.2647)	Learning Rate [0.00125]
6: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00093)	Tok/s 54619 (53420)	Loss/tok 3.5652 (4.2569)	Learning Rate [0.00125]
5: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00095)	Tok/s 54556 (53346)	Loss/tok 3.7319 (4.2564)	Learning Rate [0.00125]
8: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00094)	Tok/s 54706 (53584)	Loss/tok 3.6291 (4.2534)	Learning Rate [0.00125]
15: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00092)	Tok/s 55525 (54206)	Loss/tok 3.7141 (4.2563)	Learning Rate [0.00125]
7: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00095)	Tok/s 54652 (53503)	Loss/tok 3.9058 (4.2562)	Learning Rate [0.00125]
10: TRAIN [0][3270/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00096)	Tok/s 55761 (53713)	Loss/tok 3.3250 (4.2599)	Learning Rate [0.00125]
11: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00091)	Tok/s 55665 (53790)	Loss/tok 3.3404 (4.2628)	Learning Rate [0.00125]
12: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00097)	Tok/s 55621 (53896)	Loss/tok 3.7059 (4.2594)	Learning Rate [0.00125]
14: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00095)	Tok/s 55525 (54097)	Loss/tok 3.6656 (4.2616)	Learning Rate [0.00125]
13: TRAIN [0][3270/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00096)	Tok/s 55506 (53996)	Loss/tok 3.4047 (4.2568)	Learning Rate [0.00125]
11: TRAIN [0][3280/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00091)	Tok/s 41263 (53792)	Loss/tok 3.1607 (4.2604)	Learning Rate [0.00125]
12: TRAIN [0][3280/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00097)	Tok/s 41266 (53898)	Loss/tok 3.0301 (4.2573)	Learning Rate [0.00125]
13: TRAIN [0][3280/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00096)	Tok/s 41162 (53998)	Loss/tok 3.4505 (4.2547)	Learning Rate [0.00125]
14: TRAIN [0][3280/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00095)	Tok/s 41048 (54099)	Loss/tok 3.3834 (4.2594)	Learning Rate [0.00125]
9: TRAIN [0][3280/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00093)	Tok/s 41184 (53645)	Loss/tok 3.4074 (4.2544)	Learning Rate [0.00125]
15: TRAIN [0][3280/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00092)	Tok/s 40966 (54207)	Loss/tok 3.2166 (4.2542)	Learning Rate [0.00125]
10: TRAIN [0][3280/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00096)	Tok/s 41211 (53715)	Loss/tok 3.2272 (4.2577)	Learning Rate [0.00125]
8: TRAIN [0][3280/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00094)	Tok/s 41079 (53586)	Loss/tok 3.3641 (4.2511)	Learning Rate [0.00125]
0: TRAIN [0][3280/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00097)	Tok/s 39539 (52880)	Loss/tok 3.3869 (4.2624)	Learning Rate [0.00125]
1: TRAIN [0][3280/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00094)	Tok/s 39438 (52979)	Loss/tok 2.9830 (4.2566)	Learning Rate [0.00125]
6: TRAIN [0][3280/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00093)	Tok/s 39592 (53422)	Loss/tok 3.1683 (4.2547)	Learning Rate [0.00125]
2: TRAIN [0][3280/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00101)	Tok/s 39387 (53080)	Loss/tok 3.2753 (4.2556)	Learning Rate [0.00125]
7: TRAIN [0][3280/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00095)	Tok/s 40333 (53505)	Loss/tok 3.2661 (4.2539)	Learning Rate [0.00125]
5: TRAIN [0][3280/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00095)	Tok/s 39470 (53348)	Loss/tok 3.2367 (4.2542)	Learning Rate [0.00125]
4: TRAIN [0][3280/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00100)	Tok/s 39386 (53264)	Loss/tok 3.2869 (4.2585)	Learning Rate [0.00125]
3: TRAIN [0][3280/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00093)	Tok/s 39318 (53176)	Loss/tok 3.4617 (4.2567)	Learning Rate [0.00125]
6: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00093)	Tok/s 63852 (53428)	Loss/tok 3.6834 (4.2522)	Learning Rate [0.00125]
4: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 63634 (53271)	Loss/tok 3.6128 (4.2562)	Learning Rate [0.00125]
8: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00094)	Tok/s 63858 (53592)	Loss/tok 3.7018 (4.2489)	Learning Rate [0.00125]
7: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00095)	Tok/s 63817 (53511)	Loss/tok 3.6537 (4.2517)	Learning Rate [0.00125]
5: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00095)	Tok/s 63709 (53355)	Loss/tok 3.6240 (4.2519)	Learning Rate [0.00125]
3: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 63574 (53182)	Loss/tok 3.6102 (4.2541)	Learning Rate [0.00125]
9: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00093)	Tok/s 63825 (53651)	Loss/tok 3.7747 (4.2521)	Learning Rate [0.00125]
2: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00101)	Tok/s 63579 (53087)	Loss/tok 3.7213 (4.2533)	Learning Rate [0.00125]
1: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00094)	Tok/s 63626 (52986)	Loss/tok 3.6355 (4.2543)	Learning Rate [0.00125]
10: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00096)	Tok/s 63815 (53721)	Loss/tok 3.5918 (4.2554)	Learning Rate [0.00125]
11: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 63824 (53798)	Loss/tok 3.6049 (4.2582)	Learning Rate [0.00125]
0: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00097)	Tok/s 63550 (52886)	Loss/tok 3.5984 (4.2597)	Learning Rate [0.00125]
12: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00097)	Tok/s 63774 (53904)	Loss/tok 3.5411 (4.2549)	Learning Rate [0.00125]
15: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 64544 (54214)	Loss/tok 3.7478 (4.2518)	Learning Rate [0.00125]
13: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00096)	Tok/s 63690 (54004)	Loss/tok 3.7688 (4.2525)	Learning Rate [0.00125]
14: TRAIN [0][3290/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00095)	Tok/s 63969 (54105)	Loss/tok 3.6487 (4.2569)	Learning Rate [0.00125]
13: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 71202 (54005)	Loss/tok 3.3400 (4.2501)	Learning Rate [0.00125]
14: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00095)	Tok/s 71122 (54106)	Loss/tok 3.3915 (4.2547)	Learning Rate [0.00125]
12: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 71232 (53905)	Loss/tok 3.3399 (4.2528)	Learning Rate [0.00125]
15: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 70989 (54214)	Loss/tok 3.3669 (4.2498)	Learning Rate [0.00125]
11: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00091)	Tok/s 71197 (53799)	Loss/tok 3.4455 (4.2561)	Learning Rate [0.00125]
0: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 70091 (52888)	Loss/tok 3.4831 (4.2575)	Learning Rate [0.00125]
1: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00094)	Tok/s 70087 (52987)	Loss/tok 3.5644 (4.2522)	Learning Rate [0.00125]
10: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 70940 (53721)	Loss/tok 3.7297 (4.2530)	Learning Rate [0.00125]
2: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00101)	Tok/s 70111 (53088)	Loss/tok 3.4399 (4.2512)	Learning Rate [0.00125]
9: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00093)	Tok/s 70231 (53652)	Loss/tok 3.6017 (4.2497)	Learning Rate [0.00125]
8: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00094)	Tok/s 70254 (53593)	Loss/tok 3.7012 (4.2466)	Learning Rate [0.00125]
3: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 70096 (53183)	Loss/tok 3.6051 (4.2522)	Learning Rate [0.00125]
6: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 70161 (53429)	Loss/tok 3.5079 (4.2503)	Learning Rate [0.00125]
7: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00095)	Tok/s 70218 (53512)	Loss/tok 3.5933 (4.2496)	Learning Rate [0.00125]
4: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00100)	Tok/s 70104 (53272)	Loss/tok 3.6447 (4.2540)	Learning Rate [0.00125]
5: TRAIN [0][3300/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00095)	Tok/s 70120 (53356)	Loss/tok 3.8313 (4.2496)	Learning Rate [0.00125]
1: TRAIN [0][3310/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00094)	Tok/s 65269 (52997)	Loss/tok 3.6170 (4.2498)	Learning Rate [0.00125]
2: TRAIN [0][3310/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00101)	Tok/s 65323 (53097)	Loss/tok 3.3217 (4.2486)	Learning Rate [0.00125]
3: TRAIN [0][3310/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 65320 (53193)	Loss/tok 3.7001 (4.2498)	Learning Rate [0.00125]
11: TRAIN [0][3310/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00091)	Tok/s 66389 (53810)	Loss/tok 3.8630 (4.2535)	Learning Rate [0.00125]
10: TRAIN [0][3310/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00096)	Tok/s 66443 (53732)	Loss/tok 3.6160 (4.2504)	Learning Rate [0.00125]
4: TRAIN [0][3310/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00100)	Tok/s 65296 (53282)	Loss/tok 3.6520 (4.2514)	Learning Rate [0.00125]
14: TRAIN [0][3310/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00095)	Tok/s 66195 (54117)	Loss/tok 3.6532 (4.2522)	Learning Rate [0.00125]
15: TRAIN [0][3310/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 66170 (54225)	Loss/tok 3.8330 (4.2474)	Learning Rate [0.00125]
9: TRAIN [0][3310/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 65669 (53662)	Loss/tok 3.5855 (4.2474)	Learning Rate [0.00125]
13: TRAIN [0][3310/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 66238 (54016)	Loss/tok 3.6000 (4.2475)	Learning Rate [0.00125]
0: TRAIN [0][3310/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 65270 (52898)	Loss/tok 3.6460 (4.2549)	Learning Rate [0.00125]
8: TRAIN [0][3310/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00094)	Tok/s 65457 (53603)	Loss/tok 3.6092 (4.2441)	Learning Rate [0.00125]
12: TRAIN [0][3310/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 66286 (53915)	Loss/tok 3.5852 (4.2504)	Learning Rate [0.00125]
5: TRAIN [0][3310/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00095)	Tok/s 65324 (53365)	Loss/tok 3.2462 (4.2469)	Learning Rate [0.00125]
6: TRAIN [0][3310/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00093)	Tok/s 65280 (53439)	Loss/tok 3.5362 (4.2477)	Learning Rate [0.00125]
7: TRAIN [0][3310/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00095)	Tok/s 65390 (53522)	Loss/tok 3.6985 (4.2473)	Learning Rate [0.00125]
8: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00094)	Tok/s 53926 (53595)	Loss/tok 3.7916 (4.2422)	Learning Rate [0.00125]
6: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00093)	Tok/s 53984 (53429)	Loss/tok 3.5464 (4.2456)	Learning Rate [0.00125]
7: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00095)	Tok/s 53915 (53513)	Loss/tok 3.5700 (4.2453)	Learning Rate [0.00125]
10: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00096)	Tok/s 54005 (53724)	Loss/tok 3.3668 (4.2483)	Learning Rate [0.00125]
4: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00100)	Tok/s 53928 (53273)	Loss/tok 3.5564 (4.2496)	Learning Rate [0.00125]
11: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00091)	Tok/s 53908 (53801)	Loss/tok 3.4966 (4.2515)	Learning Rate [0.00125]
12: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00097)	Tok/s 53954 (53907)	Loss/tok 3.4333 (4.2483)	Learning Rate [0.00125]
5: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00095)	Tok/s 53861 (53356)	Loss/tok 3.4390 (4.2450)	Learning Rate [0.00125]
13: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00081 (0.00096)	Tok/s 53935 (54007)	Loss/tok 3.6435 (4.2455)	Learning Rate [0.00125]
3: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00093)	Tok/s 53884 (53183)	Loss/tok 3.6252 (4.2478)	Learning Rate [0.00125]
1: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00094)	Tok/s 53912 (52988)	Loss/tok 3.6280 (4.2478)	Learning Rate [0.00125]
2: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00101)	Tok/s 53908 (53088)	Loss/tok 3.6468 (4.2465)	Learning Rate [0.00125]
0: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00097)	Tok/s 53912 (52889)	Loss/tok 3.6861 (4.2529)	Learning Rate [0.00125]
14: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00095)	Tok/s 53862 (54108)	Loss/tok 3.4925 (4.2501)	Learning Rate [0.00125]
15: TRAIN [0][3320/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00092)	Tok/s 53859 (54216)	Loss/tok 3.6544 (4.2454)	Learning Rate [0.00125]
9: TRAIN [0][3320/3416]	Time 0.060 (0.058)	Data 0.00083 (0.00093)	Tok/s 53385 (53653)	Loss/tok 3.5037 (4.2453)	Learning Rate [0.00125]
3: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00093)	Tok/s 52847 (53200)	Loss/tok 3.4279 (4.2454)	Learning Rate [0.00125]
2: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00103 (0.00101)	Tok/s 52864 (53105)	Loss/tok 3.3813 (4.2441)	Learning Rate [0.00125]
4: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00108 (0.00100)	Tok/s 52700 (53289)	Loss/tok 3.5519 (4.2473)	Learning Rate [0.00125]
1: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00094)	Tok/s 52841 (53004)	Loss/tok 3.3957 (4.2453)	Learning Rate [0.00125]
0: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00097)	Tok/s 52856 (52906)	Loss/tok 3.5392 (4.2506)	Learning Rate [0.00125]
5: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00095)	Tok/s 52628 (53372)	Loss/tok 3.4615 (4.2425)	Learning Rate [0.00125]
6: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00099 (0.00093)	Tok/s 52500 (53445)	Loss/tok 3.4437 (4.2432)	Learning Rate [0.00125]
7: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00095)	Tok/s 52454 (53529)	Loss/tok 3.5523 (4.2431)	Learning Rate [0.00125]
15: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00092)	Tok/s 52775 (54231)	Loss/tok 3.6333 (4.2430)	Learning Rate [0.00125]
8: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00094)	Tok/s 52440 (53610)	Loss/tok 3.5153 (4.2397)	Learning Rate [0.00125]
14: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00100 (0.00095)	Tok/s 52822 (54123)	Loss/tok 3.3277 (4.2480)	Learning Rate [0.00125]
9: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00093)	Tok/s 52397 (53669)	Loss/tok 3.5745 (4.2433)	Learning Rate [0.00125]
13: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00096)	Tok/s 52649 (54022)	Loss/tok 3.7421 (4.2430)	Learning Rate [0.00125]
12: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00097)	Tok/s 52573 (53922)	Loss/tok 3.5075 (4.2458)	Learning Rate [0.00125]
11: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00091)	Tok/s 52474 (53817)	Loss/tok 3.4196 (4.2490)	Learning Rate [0.00125]
10: TRAIN [0][3330/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00096)	Tok/s 52475 (53740)	Loss/tok 3.3886 (4.2459)	Learning Rate [0.00125]
1: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00094)	Tok/s 64672 (53022)	Loss/tok 3.6684 (4.2429)	Learning Rate [0.00125]
3: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00093)	Tok/s 64809 (53218)	Loss/tok 3.4121 (4.2428)	Learning Rate [0.00125]
0: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00097)	Tok/s 64552 (52923)	Loss/tok 3.6699 (4.2477)	Learning Rate [0.00125]
4: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00113 (0.00100)	Tok/s 64814 (53307)	Loss/tok 3.5490 (4.2448)	Learning Rate [0.00125]
15: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00092)	Tok/s 65458 (54248)	Loss/tok 3.6076 (4.2403)	Learning Rate [0.00125]
5: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00095)	Tok/s 64791 (53389)	Loss/tok 3.6069 (4.2401)	Learning Rate [0.00125]
6: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00093)	Tok/s 64761 (53462)	Loss/tok 3.5771 (4.2409)	Learning Rate [0.00125]
14: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00108 (0.00095)	Tok/s 65498 (54141)	Loss/tok 3.7562 (4.2455)	Learning Rate [0.00125]
2: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00131 (0.00101)	Tok/s 64718 (53122)	Loss/tok 3.2668 (4.2414)	Learning Rate [0.00125]
13: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00096)	Tok/s 64757 (54040)	Loss/tok 3.5891 (4.2406)	Learning Rate [0.00125]
7: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00095)	Tok/s 64794 (53546)	Loss/tok 3.6879 (4.2404)	Learning Rate [0.00125]
8: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00094)	Tok/s 64675 (53628)	Loss/tok 3.5536 (4.2370)	Learning Rate [0.00125]
11: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00091)	Tok/s 64601 (53834)	Loss/tok 3.4157 (4.2465)	Learning Rate [0.00125]
12: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00097)	Tok/s 64501 (53940)	Loss/tok 3.5930 (4.2430)	Learning Rate [0.00125]
10: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00096)	Tok/s 64519 (53757)	Loss/tok 3.6984 (4.2436)	Learning Rate [0.00125]
9: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00093)	Tok/s 64479 (53687)	Loss/tok 3.5950 (4.2407)	Learning Rate [0.00125]
2: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00101)	Tok/s 49789 (53139)	Loss/tok 3.4214 (4.2389)	Learning Rate [0.00125]
3: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 49762 (53235)	Loss/tok 3.3047 (4.2400)	Learning Rate [0.00125]
1: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00094)	Tok/s 49767 (53039)	Loss/tok 3.3268 (4.2403)	Learning Rate [0.00125]
4: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00100)	Tok/s 49640 (53324)	Loss/tok 3.2066 (4.2426)	Learning Rate [0.00125]
0: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00097)	Tok/s 49675 (52940)	Loss/tok 3.2766 (4.2452)	Learning Rate [0.00125]
5: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00095)	Tok/s 49545 (53407)	Loss/tok 3.3931 (4.2376)	Learning Rate [0.00125]
6: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00093)	Tok/s 49421 (53479)	Loss/tok 3.4924 (4.2382)	Learning Rate [0.00125]
15: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00092)	Tok/s 49539 (54264)	Loss/tok 3.4355 (4.2379)	Learning Rate [0.00125]
12: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00097)	Tok/s 49505 (53957)	Loss/tok 3.2920 (4.2404)	Learning Rate [0.00125]
13: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00096)	Tok/s 49508 (54056)	Loss/tok 3.2317 (4.2383)	Learning Rate [0.00125]
14: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00095)	Tok/s 49502 (54157)	Loss/tok 3.6008 (4.2431)	Learning Rate [0.00125]
11: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00091)	Tok/s 49364 (53851)	Loss/tok 3.2861 (4.2439)	Learning Rate [0.00125]
7: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00095)	Tok/s 49314 (53563)	Loss/tok 3.2117 (4.2381)	Learning Rate [0.00125]
10: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00096)	Tok/s 49280 (53774)	Loss/tok 3.2581 (4.2409)	Learning Rate [0.00125]
8: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00079 (0.00094)	Tok/s 49198 (53644)	Loss/tok 3.5337 (4.2347)	Learning Rate [0.00125]
9: TRAIN [0][3350/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00093)	Tok/s 49051 (53704)	Loss/tok 3.4787 (4.2383)	Learning Rate [0.00125]
11: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
15: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 62612 (54263)	Loss/tok 3.4996 (4.2355)	Learning Rate [0.00125]
0: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 62142 (52940)	Loss/tok 3.7010 (4.2430)	Learning Rate [0.00125]
14: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00095)	Tok/s 62281 (54156)	Loss/tok 3.6875 (4.2411)	Learning Rate [0.00125]
1: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00094)	Tok/s 62025 (53038)	Loss/tok 3.4553 (4.2383)	Learning Rate [0.00125]
13: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00096)	Tok/s 62223 (54055)	Loss/tok 3.6554 (4.2361)	Learning Rate [0.00125]
2: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00101)	Tok/s 61914 (53139)	Loss/tok 3.6313 (4.2370)	Learning Rate [0.00125]
12: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 62199 (53956)	Loss/tok 3.7384 (4.2383)	Learning Rate [0.00125]
11: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00091)	Tok/s 62083 (53851)	Loss/tok 3.6487 (4.2419)	Learning Rate [0.00125]
3: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00093)	Tok/s 61823 (53234)	Loss/tok 3.4820 (4.2380)	Learning Rate [0.00125]
4: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00100)	Tok/s 61750 (53324)	Loss/tok 3.9816 (4.2406)	Learning Rate [0.00125]
9: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 61893 (53704)	Loss/tok 3.6224 (4.2362)	Learning Rate [0.00125]
10: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00096)	Tok/s 61833 (53774)	Loss/tok 3.4487 (4.2384)	Learning Rate [0.00125]
8: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00094)	Tok/s 61779 (53644)	Loss/tok 3.7584 (4.2325)	Learning Rate [0.00125]
6: TRAIN [0][3360/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00093)	Tok/s 61658 (53479)	Loss/tok 3.6128 (4.2358)	Learning Rate [0.00125]
5: TRAIN [0][3360/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00095)	Tok/s 61611 (53407)	Loss/tok 3.6702 (4.2354)	Learning Rate [0.00125]
7: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00095)	Tok/s 61700 (53563)	Loss/tok 3.8348 (4.2362)	Learning Rate [0.00125]
9: Gradient norm: inf
8: Gradient norm: inf
10: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
3: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
0: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
6: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00093)	Tok/s 64131 (53475)	Loss/tok 3.5578 (4.2335)	Learning Rate [0.00125]
5: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00095)	Tok/s 64050 (53403)	Loss/tok 3.5715 (4.2334)	Learning Rate [0.00125]
9: TRAIN [0][3370/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00093)	Tok/s 64759 (53700)	Loss/tok 3.3439 (4.2337)	Learning Rate [0.00125]
4: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 64069 (53320)	Loss/tok 3.6146 (4.2384)	Learning Rate [0.00125]
8: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 64055 (53640)	Loss/tok 3.5355 (4.2303)	Learning Rate [0.00125]
7: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00095)	Tok/s 64017 (53558)	Loss/tok 3.4992 (4.2341)	Learning Rate [0.00125]
10: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00096)	Tok/s 64162 (53770)	Loss/tok 3.5031 (4.2361)	Learning Rate [0.00125]
2: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00101)	Tok/s 64063 (53136)	Loss/tok 3.5961 (4.2347)	Learning Rate [0.00125]
1: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00094)	Tok/s 63888 (53035)	Loss/tok 3.4387 (4.2360)	Learning Rate [0.00125]
0: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 63149 (52937)	Loss/tok 3.4712 (4.2406)	Learning Rate [0.00125]
11: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00091)	Tok/s 63972 (53847)	Loss/tok 3.4350 (4.2395)	Learning Rate [0.00125]
3: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 64053 (53231)	Loss/tok 3.6288 (4.2358)	Learning Rate [0.00125]
15: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 64096 (54260)	Loss/tok 3.7635 (4.2336)	Learning Rate [0.00125]
13: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 64005 (54052)	Loss/tok 3.9448 (4.2340)	Learning Rate [0.00125]
14: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00095)	Tok/s 64107 (54153)	Loss/tok 3.5769 (4.2389)	Learning Rate [0.00125]
12: TRAIN [0][3370/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 64063 (53953)	Loss/tok 3.5519 (4.2359)	Learning Rate [0.00125]
14: TRAIN [0][3380/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00095)	Tok/s 58482 (54150)	Loss/tok 3.6327 (4.2371)	Learning Rate [0.00125]
15: TRAIN [0][3380/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 58340 (54257)	Loss/tok 3.4714 (4.2314)	Learning Rate [0.00125]
13: TRAIN [0][3380/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00096)	Tok/s 58385 (54049)	Loss/tok 3.7228 (4.2320)	Learning Rate [0.00125]
0: TRAIN [0][3380/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 57299 (52929)	Loss/tok 3.6332 (4.2386)	Learning Rate [0.00125]
1: TRAIN [0][3380/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00094)	Tok/s 57209 (53028)	Loss/tok 3.6812 (4.2340)	Learning Rate [0.00125]
11: TRAIN [0][3380/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00091)	Tok/s 58184 (53844)	Loss/tok 3.4461 (4.2374)	Learning Rate [0.00125]
12: TRAIN [0][3380/3416]	Time 0.067 (0.058)	Data 0.00122 (0.00097)	Tok/s 58940 (53949)	Loss/tok 3.5159 (4.2337)	Learning Rate [0.00125]
2: TRAIN [0][3380/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00101)	Tok/s 57528 (53130)	Loss/tok 3.5612 (4.2323)	Learning Rate [0.00125]
10: TRAIN [0][3380/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00096)	Tok/s 58105 (53766)	Loss/tok 3.7178 (4.2340)	Learning Rate [0.00125]
9: TRAIN [0][3380/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00092)	Tok/s 57961 (53696)	Loss/tok 3.5083 (4.2314)	Learning Rate [0.00125]
3: TRAIN [0][3380/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00093)	Tok/s 57961 (53226)	Loss/tok 3.5962 (4.2337)	Learning Rate [0.00125]
8: TRAIN [0][3380/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00094)	Tok/s 57897 (53636)	Loss/tok 3.4301 (4.2278)	Learning Rate [0.00125]
4: TRAIN [0][3380/3416]	Time 0.068 (0.058)	Data 0.00122 (0.00100)	Tok/s 58547 (53315)	Loss/tok 3.6201 (4.2363)	Learning Rate [0.00125]
6: TRAIN [0][3380/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 57752 (53471)	Loss/tok 3.7273 (4.2314)	Learning Rate [0.00125]
5: TRAIN [0][3380/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00095)	Tok/s 57766 (53399)	Loss/tok 3.5890 (4.2312)	Learning Rate [0.00125]
7: TRAIN [0][3380/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00095)	Tok/s 57802 (53555)	Loss/tok 3.4391 (4.2320)	Learning Rate [0.00125]
2: TRAIN [0][3390/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00101)	Tok/s 55555 (53131)	Loss/tok 3.3652 (4.2301)	Learning Rate [0.00125]
1: TRAIN [0][3390/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00094)	Tok/s 55573 (53029)	Loss/tok 3.5070 (4.2319)	Learning Rate [0.00125]
3: TRAIN [0][3390/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00093)	Tok/s 56535 (53228)	Loss/tok 3.6379 (4.2314)	Learning Rate [0.00125]
4: TRAIN [0][3390/3416]	Time 0.063 (0.058)	Data 0.00105 (0.00100)	Tok/s 56678 (53318)	Loss/tok 3.5941 (4.2342)	Learning Rate [0.00125]
0: TRAIN [0][3390/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00097)	Tok/s 55487 (52929)	Loss/tok 3.5984 (4.2365)	Learning Rate [0.00125]
15: TRAIN [0][3390/3416]	Time 0.064 (0.058)	Data 0.00083 (0.00092)	Tok/s 56406 (54261)	Loss/tok 3.4381 (4.2290)	Learning Rate [0.00125]
6: TRAIN [0][3390/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00093)	Tok/s 56419 (53475)	Loss/tok 3.4865 (4.2291)	Learning Rate [0.00125]
5: TRAIN [0][3390/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00095)	Tok/s 56540 (53402)	Loss/tok 3.8849 (4.2289)	Learning Rate [0.00125]
14: TRAIN [0][3390/3416]	Time 0.064 (0.058)	Data 0.00100 (0.00095)	Tok/s 56305 (54154)	Loss/tok 3.7491 (4.2348)	Learning Rate [0.00125]
13: TRAIN [0][3390/3416]	Time 0.064 (0.058)	Data 0.00082 (0.00096)	Tok/s 56254 (54052)	Loss/tok 3.7110 (4.2298)	Learning Rate [0.00125]
11: TRAIN [0][3390/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00091)	Tok/s 56081 (53848)	Loss/tok 3.7009 (4.2353)	Learning Rate [0.00125]
12: TRAIN [0][3390/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00097)	Tok/s 56212 (53954)	Loss/tok 3.9933 (4.2313)	Learning Rate [0.00125]
7: TRAIN [0][3390/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00095)	Tok/s 56380 (53558)	Loss/tok 3.6119 (4.2295)	Learning Rate [0.00125]
9: TRAIN [0][3390/3416]	Time 0.064 (0.058)	Data 0.00084 (0.00092)	Tok/s 56109 (53700)	Loss/tok 3.5174 (4.2292)	Learning Rate [0.00125]
8: TRAIN [0][3390/3416]	Time 0.064 (0.058)	Data 0.00084 (0.00094)	Tok/s 56300 (53640)	Loss/tok 3.5711 (4.2254)	Learning Rate [0.00125]
10: TRAIN [0][3390/3416]	Time 0.064 (0.058)	Data 0.00107 (0.00096)	Tok/s 56105 (53770)	Loss/tok 3.5308 (4.2317)	Learning Rate [0.00125]
4: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00100)	Tok/s 33341 (53327)	Loss/tok 3.2937 (4.2319)	Learning Rate [0.00125]
6: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00093)	Tok/s 33160 (53484)	Loss/tok 2.9946 (4.2266)	Learning Rate [0.00125]
5: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00094)	Tok/s 33249 (53411)	Loss/tok 2.8808 (4.2264)	Learning Rate [0.00125]
3: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00093)	Tok/s 33291 (53237)	Loss/tok 3.2093 (4.2290)	Learning Rate [0.00125]
2: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00101)	Tok/s 33341 (53140)	Loss/tok 3.2294 (4.2278)	Learning Rate [0.00125]
7: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00095)	Tok/s 33210 (53567)	Loss/tok 3.3141 (4.2271)	Learning Rate [0.00125]
1: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00108 (0.00094)	Tok/s 33250 (53038)	Loss/tok 3.3463 (4.2295)	Learning Rate [0.00125]
8: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00094)	Tok/s 33570 (53649)	Loss/tok 3.0964 (4.2229)	Learning Rate [0.00125]
13: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00096)	Tok/s 34620 (54062)	Loss/tok 3.1382 (4.2274)	Learning Rate [0.00125]
0: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 33330 (52938)	Loss/tok 3.0819 (4.2343)	Learning Rate [0.00125]
12: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00097)	Tok/s 34602 (53963)	Loss/tok 2.8643 (4.2288)	Learning Rate [0.00125]
11: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00091)	Tok/s 34519 (53857)	Loss/tok 3.0839 (4.2330)	Learning Rate [0.00125]
9: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00092)	Tok/s 34395 (53709)	Loss/tok 3.0510 (4.2267)	Learning Rate [0.00125]
14: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00095)	Tok/s 34584 (54163)	Loss/tok 3.1988 (4.2324)	Learning Rate [0.00125]
15: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00092)	Tok/s 34554 (54271)	Loss/tok 2.9230 (4.2266)	Learning Rate [0.00125]
10: TRAIN [0][3400/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00096)	Tok/s 34510 (53779)	Loss/tok 3.2028 (4.2290)	Learning Rate [0.00125]
12: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 58387 (53950)	Loss/tok 3.5558 (4.2269)	Learning Rate [0.00125]
13: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 58340 (54050)	Loss/tok 3.9193 (4.2256)	Learning Rate [0.00125]
11: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00091)	Tok/s 57970 (53844)	Loss/tok 3.7017 (4.2310)	Learning Rate [0.00125]
8: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00094)	Tok/s 57454 (53636)	Loss/tok 3.6175 (4.2210)	Learning Rate [0.00125]
10: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 57403 (53766)	Loss/tok 3.6967 (4.2269)	Learning Rate [0.00125]
9: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 57407 (53696)	Loss/tok 3.6657 (4.2249)	Learning Rate [0.00125]
15: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00079 (0.00092)	Tok/s 58325 (54258)	Loss/tok 3.7763 (4.2246)	Learning Rate [0.00125]
14: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00095)	Tok/s 58278 (54150)	Loss/tok 3.5277 (4.2304)	Learning Rate [0.00125]
0: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00097)	Tok/s 57434 (52926)	Loss/tok 3.5120 (4.2324)	Learning Rate [0.00125]
1: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 57444 (53026)	Loss/tok 3.8017 (4.2277)	Learning Rate [0.00125]
7: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00095)	Tok/s 57445 (53555)	Loss/tok 3.2441 (4.2249)	Learning Rate [0.00125]
2: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00101)	Tok/s 57412 (53128)	Loss/tok 3.7867 (4.2257)	Learning Rate [0.00125]
4: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00100)	Tok/s 57428 (53315)	Loss/tok 3.7080 (4.2301)	Learning Rate [0.00125]
3: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 57414 (53225)	Loss/tok 3.7662 (4.2270)	Learning Rate [0.00125]
5: TRAIN [0][3410/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 57396 (53398)	Loss/tok 3.7390 (4.2244)	Learning Rate [0.00125]
6: TRAIN [0][3410/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 57048 (53471)	Loss/tok 3.7337 (4.2247)	Learning Rate [0.00125]
15: Running validation on dev set
3: Running validation on dev set
2: Running validation on dev set
0: Running validation on dev set
1: Running validation on dev set
11: Running validation on dev set
7: Running validation on dev set
5: Running validation on dev set
8: Running validation on dev set
10: Running validation on dev set
9: Running validation on dev set
6: Running validation on dev set
14: Running validation on dev set
13: Running validation on dev set
4: Running validation on dev set
12: Running validation on dev set
15: VALIDATION [0][0/5]	Time 0.023 (0.000)	Data 0.00229 (0.00000)	Tok/s 225651 (0)	Loss/tok 3.3836 (0.0000)	Learning Rate [0.00125]
3: VALIDATION [0][0/5]	Time 0.032 (0.000)	Data 0.00211 (0.00000)	Tok/s 229773 (0)	Loss/tok 3.4790 (0.0000)	Learning Rate [0.00125]
2: VALIDATION [0][0/5]	Time 0.034 (0.000)	Data 0.00216 (0.00000)	Tok/s 225621 (0)	Loss/tok 3.5884 (0.0000)	Learning Rate [0.00125]
1: VALIDATION [0][0/5]	Time 0.037 (0.000)	Data 0.00214 (0.00000)	Tok/s 226476 (0)	Loss/tok 3.6024 (0.0000)	Learning Rate [0.00125]
0: VALIDATION [0][0/5]	Time 0.061 (0.000)	Data 0.00213 (0.00000)	Tok/s 165530 (0)	Loss/tok 3.7310 (0.0000)	Learning Rate [0.00125]
11: VALIDATION [0][0/5]	Time 0.024 (0.000)	Data 0.00213 (0.00000)	Tok/s 230690 (0)	Loss/tok 3.4522 (0.0000)	Learning Rate [0.00125]
7: VALIDATION [0][0/5]	Time 0.027 (0.000)	Data 0.00213 (0.00000)	Tok/s 228755 (0)	Loss/tok 3.5616 (0.0000)	Learning Rate [0.00125]
8: VALIDATION [0][0/5]	Time 0.027 (0.000)	Data 0.00237 (0.00000)	Tok/s 226214 (0)	Loss/tok 3.5564 (0.0000)	Learning Rate [0.00125]
5: VALIDATION [0][0/5]	Time 0.029 (0.000)	Data 0.00215 (0.00000)	Tok/s 232278 (0)	Loss/tok 3.4348 (0.0000)	Learning Rate [0.00125]
10: VALIDATION [0][0/5]	Time 0.027 (0.000)	Data 0.00341 (0.00000)	Tok/s 208382 (0)	Loss/tok 3.3570 (0.0000)	Learning Rate [0.00125]
9: VALIDATION [0][0/5]	Time 0.026 (0.000)	Data 0.00212 (0.00000)	Tok/s 224484 (0)	Loss/tok 3.5521 (0.0000)	Learning Rate [0.00125]
14: VALIDATION [0][0/5]	Time 0.025 (0.000)	Data 0.00313 (0.00000)	Tok/s 206016 (0)	Loss/tok 3.5385 (0.0000)	Learning Rate [0.00125]
13: VALIDATION [0][0/5]	Time 0.025 (0.000)	Data 0.00227 (0.00000)	Tok/s 207519 (0)	Loss/tok 3.5357 (0.0000)	Learning Rate [0.00125]
12: VALIDATION [0][0/5]	Time 0.025 (0.000)	Data 0.00368 (0.00000)	Tok/s 216377 (0)	Loss/tok 3.4165 (0.0000)	Learning Rate [0.00125]
6: VALIDATION [0][0/5]	Time 0.028 (0.000)	Data 0.00220 (0.00000)	Tok/s 225725 (0)	Loss/tok 3.4242 (0.0000)	Learning Rate [0.00125]
4: VALIDATION [0][0/5]	Time 0.032 (0.000)	Data 0.00223 (0.00000)	Tok/s 214330 (0)	Loss/tok 3.4456 (0.0000)	Learning Rate [0.00125]
14: Running evaluation on test set
4: Running evaluation on test set
9: Running evaluation on test set
11: Running evaluation on test set
7: Running evaluation on test set
1: Running evaluation on test set
8: Running evaluation on test set
3: Running evaluation on test set
13: Running evaluation on test set
5: Running evaluation on test set
2: Running evaluation on test set
10: Running evaluation on test set
15: Running evaluation on test set
6: Running evaluation on test set
12: Running evaluation on test set
:::MLPv0.5.0 gnmt 1541784288.657964230 (train.py:459) eval_start: 0
0: Running evaluation on test set
5: TEST [0][0/2]	Time 1.068 (1.068)	Decoder iters 59.0 (59.0)	Tok/s 6170 (6170)
9: TEST [0][0/2]	Time 1.069 (1.069)	Decoder iters 59.0 (59.0)	Tok/s 6226 (6226)
14: TEST [0][0/2]	Time 1.069 (1.069)	Decoder iters 149.0 (149.0)	Tok/s 7495 (7495)
3: TEST [0][0/2]	Time 1.069 (1.069)	Decoder iters 84.0 (84.0)	Tok/s 7050 (7050)
7: TEST [0][0/2]	Time 1.069 (1.069)	Decoder iters 67.0 (67.0)	Tok/s 6707 (6707)
12: TEST [0][0/2]	Time 1.068 (1.068)	Decoder iters 63.0 (63.0)	Tok/s 5930 (5930)
13: TEST [0][0/2]	Time 1.069 (1.069)	Decoder iters 66.0 (66.0)	Tok/s 6502 (6502)
11: TEST [0][0/2]	Time 1.069 (1.069)	Decoder iters 66.0 (66.0)	Tok/s 5932 (5932)
1: TEST [0][0/2]	Time 1.070 (1.070)	Decoder iters 149.0 (149.0)	Tok/s 7067 (7067)
8: TEST [0][0/2]	Time 1.070 (1.070)	Decoder iters 149.0 (149.0)	Tok/s 6981 (6981)
0: TEST [0][0/2]	Time 1.070 (1.070)	Decoder iters 62.0 (62.0)	Tok/s 6479 (6479)
2: TEST [0][0/2]	Time 1.071 (1.071)	Decoder iters 133.0 (133.0)	Tok/s 6769 (6769)
4: TEST [0][0/2]	Time 1.071 (1.071)	Decoder iters 77.0 (77.0)	Tok/s 7319 (7319)
15: TEST [0][0/2]	Time 1.071 (1.071)	Decoder iters 149.0 (149.0)	Tok/s 7474 (7474)
10: TEST [0][0/2]	Time 1.073 (1.073)	Decoder iters 63.0 (63.0)	Tok/s 6112 (6112)
6: TEST [0][0/2]	Time 1.074 (1.074)	Decoder iters 71.0 (71.0)	Tok/s 7187 (7187)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
7: Finished evaluation on test set
13: Finished evaluation on test set
9: Finished evaluation on test set
3: Finished evaluation on test set
15: Finished evaluation on test set
2: Finished evaluation on test set
10: Finished evaluation on test set
14: Finished evaluation on test set
8: Finished evaluation on test set
1: Finished evaluation on test set
4: Finished evaluation on test set
6: Finished evaluation on test set
12: Finished evaluation on test set
11: Finished evaluation on test set
5: Finished evaluation on test set
0: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1541784295.595239878 (train.py:464) eval_accuracy: {"epoch": 0, "value": 19.040000915527344}
:::MLPv0.5.0 gnmt 1541784295.595674992 (train.py:466) eval_target: 21.8
5: Summary: Epoch: 0	Training Loss 4.2258
11: Summary: Epoch: 0	Training Loss 4.2258
14: Summary: Epoch: 0	Training Loss 4.2258
2: Summary: Epoch: 0	Training Loss 4.2258
3: Summary: Epoch: 0	Training Loss 4.2258
12: Summary: Epoch: 0	Training Loss 4.2258
9: Summary: Epoch: 0	Training Loss 4.2258
13: Summary: Epoch: 0	Training Loss 4.2258
7: Summary: Epoch: 0	Training Loss 4.2258
1: Summary: Epoch: 0	Training Loss 4.2258
6: Summary: Epoch: 0	Training Loss 4.2258
10: Summary: Epoch: 0	Training Loss 4.2258
8: Summary: Epoch: 0	Training Loss 4.2258
4: Summary: Epoch: 0	Training Loss 4.2258
15: Summary: Epoch: 0	Training Loss 4.2258
11: Performance: Epoch: 0	Training: 857145 Tok/s
5: Performance: Epoch: 0	Training: 857145 Tok/s
14: Performance: Epoch: 0	Training: 857145 Tok/s
2: Performance: Epoch: 0	Training: 857145 Tok/s
3: Performance: Epoch: 0	Training: 857145 Tok/s
13: Performance: Epoch: 0	Training: 857145 Tok/s
9: Performance: Epoch: 0	Training: 857145 Tok/s
7: Performance: Epoch: 0	Training: 857145 Tok/s
1: Performance: Epoch: 0	Training: 857145 Tok/s
10: Performance: Epoch: 0	Training: 857145 Tok/s
6: Performance: Epoch: 0	Training: 857145 Tok/s
15: Performance: Epoch: 0	Training: 857145 Tok/s
12: Performance: Epoch: 0	Training: 857145 Tok/s
8: Performance: Epoch: 0	Training: 857145 Tok/s
4: Performance: Epoch: 0	Training: 857145 Tok/s
11: Finished epoch 0
5: Finished epoch 0
3: Finished epoch 0
14: Finished epoch 0
2: Finished epoch 0
13: Finished epoch 0
9: Finished epoch 0
7: Finished epoch 0
1: Finished epoch 0
10: Finished epoch 0
6: Finished epoch 0
3: Starting epoch 1
2: Starting epoch 1
13: Starting epoch 1
15: Finished epoch 0
4: Finished epoch 0
8: Finished epoch 0
9: Starting epoch 1
7: Starting epoch 1
11: Starting epoch 1
1: Starting epoch 1
5: Starting epoch 1
14: Starting epoch 1
10: Starting epoch 1
6: Starting epoch 1
12: Finished epoch 0
15: Starting epoch 1
:::MLPv0.5.0 gnmt 1541784295.596045494 (train.py:467) eval_stop
4: Starting epoch 1
8: Starting epoch 1
12: Starting epoch 1
0: Summary: Epoch: 0	Training Loss: 4.2258	Validation Loss: 3.2846	Test BLEU: 19.04
0: Performance: Epoch: 0	Training: 857145 Tok/s	Validation: 2806329 Tok/s
0: Finished epoch 0
0: Starting epoch 1
:::MLPv0.5.0 gnmt 1541784295.596649647 (train.py:443) train_epoch: 1
11: Sampler for epoch 1 uses seed 873282904
2: Sampler for epoch 1 uses seed 873282904
13: Sampler for epoch 1 uses seed 873282904
3: Sampler for epoch 1 uses seed 873282904
9: Sampler for epoch 1 uses seed 873282904
5: Sampler for epoch 1 uses seed 873282904
15: Sampler for epoch 1 uses seed 873282904
8: Sampler for epoch 1 uses seed 873282904
12: Sampler for epoch 1 uses seed 873282904
14: Sampler for epoch 1 uses seed 873282904
10: Sampler for epoch 1 uses seed 873282904
1: Sampler for epoch 1 uses seed 873282904
7: Sampler for epoch 1 uses seed 873282904
6: Sampler for epoch 1 uses seed 873282904
4: Sampler for epoch 1 uses seed 873282904
:::MLPv0.5.0 gnmt 1541784295.952568054 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 1 uses seed 873282904
:::MLPv0.5.0 gnmt 1541784296.118328094 (seq2seq/data/sampler.py:66) input_shard: 81920
2: TRAIN [1][0/3416]	Time 3.677 (0.000)	Data 1.80303 (0.00000)	Tok/s 818 (0)	Loss/tok 3.4077 (0.0000)	Learning Rate [0.00125]
3: TRAIN [1][0/3416]	Time 3.677 (0.000)	Data 3.13084 (0.00000)	Tok/s 818 (0)	Loss/tok 3.6626 (0.0000)	Learning Rate [0.00125]
7: TRAIN [1][0/3416]	Time 3.677 (0.000)	Data 2.51156 (0.00000)	Tok/s 818 (0)	Loss/tok 3.2877 (0.0000)	Learning Rate [0.00125]
8: TRAIN [1][0/3416]	Time 3.677 (0.000)	Data 3.36506 (0.00000)	Tok/s 818 (0)	Loss/tok 3.3422 (0.0000)	Learning Rate [0.00125]
5: TRAIN [1][0/3416]	Time 3.677 (0.000)	Data 3.41924 (0.00000)	Tok/s 818 (0)	Loss/tok 3.6770 (0.0000)	Learning Rate [0.00125]
11: TRAIN [1][0/3416]	Time 3.678 (0.000)	Data 2.99743 (0.00000)	Tok/s 818 (0)	Loss/tok 3.1476 (0.0000)	Learning Rate [0.00125]
4: TRAIN [1][0/3416]	Time 3.677 (0.000)	Data 3.45552 (0.00000)	Tok/s 818 (0)	Loss/tok 3.4124 (0.0000)	Learning Rate [0.00125]
14: TRAIN [1][0/3416]	Time 3.678 (0.000)	Data 2.50900 (0.00000)	Tok/s 818 (0)	Loss/tok 3.4762 (0.0000)	Learning Rate [0.00125]
6: TRAIN [1][0/3416]	Time 3.677 (0.000)	Data 3.13565 (0.00000)	Tok/s 818 (0)	Loss/tok 3.4023 (0.0000)	Learning Rate [0.00125]
1: TRAIN [1][0/3416]	Time 3.677 (0.000)	Data 3.50870 (0.00000)	Tok/s 818 (0)	Loss/tok 3.3945 (0.0000)	Learning Rate [0.00125]
0: TRAIN [1][0/3416]	Time 3.678 (0.000)	Data 2.62018 (0.00000)	Tok/s 818 (0)	Loss/tok 3.3870 (0.0000)	Learning Rate [0.00125]
12: TRAIN [1][0/3416]	Time 3.678 (0.000)	Data 3.61843 (0.00000)	Tok/s 818 (0)	Loss/tok 3.3308 (0.0000)	Learning Rate [0.00125]
15: TRAIN [1][0/3416]	Time 3.678 (0.000)	Data 2.45553 (0.00000)	Tok/s 818 (0)	Loss/tok 3.1642 (0.0000)	Learning Rate [0.00125]
9: TRAIN [1][0/3416]	Time 3.678 (0.000)	Data 3.44758 (0.00000)	Tok/s 818 (0)	Loss/tok 3.6625 (0.0000)	Learning Rate [0.00125]
10: TRAIN [1][0/3416]	Time 3.678 (0.000)	Data 3.39676 (0.00000)	Tok/s 818 (0)	Loss/tok 3.4952 (0.0000)	Learning Rate [0.00125]
13: TRAIN [1][0/3416]	Time 3.679 (0.000)	Data 3.21403 (0.00000)	Tok/s 818 (0)	Loss/tok 3.2424 (0.0000)	Learning Rate [0.00125]
15: TRAIN [1][10/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00079)	Tok/s 57299 (50432)	Loss/tok 3.4957 (3.4447)	Learning Rate [0.00125]
0: TRAIN [1][10/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00101)	Tok/s 56350 (49682)	Loss/tok 3.3645 (3.3234)	Learning Rate [0.00125]
14: TRAIN [1][10/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00110)	Tok/s 57230 (50300)	Loss/tok 3.6216 (3.4645)	Learning Rate [0.00125]
1: TRAIN [1][10/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00102)	Tok/s 56252 (49818)	Loss/tok 3.5997 (3.4474)	Learning Rate [0.00125]
12: TRAIN [1][10/3416]	Time 0.071 (0.058)	Data 0.00111 (0.00086)	Tok/s 56140 (50185)	Loss/tok 3.6282 (3.3964)	Learning Rate [0.00125]
13: TRAIN [1][10/3416]	Time 0.071 (0.058)	Data 0.00104 (0.00120)	Tok/s 56329 (50314)	Loss/tok 3.5154 (3.3758)	Learning Rate [0.00125]
2: TRAIN [1][10/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00083)	Tok/s 56323 (49809)	Loss/tok 3.5320 (3.4501)	Learning Rate [0.00125]
11: TRAIN [1][10/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00147)	Tok/s 55926 (50072)	Loss/tok 3.3565 (3.3477)	Learning Rate [0.00125]
3: TRAIN [1][10/3416]	Time 0.071 (0.058)	Data 0.00110 (0.00089)	Tok/s 56277 (49921)	Loss/tok 3.4504 (3.3428)	Learning Rate [0.00125]
9: TRAIN [1][10/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00098)	Tok/s 56031 (50139)	Loss/tok 3.3827 (3.3712)	Learning Rate [0.00125]
4: TRAIN [1][10/3416]	Time 0.071 (0.058)	Data 0.00105 (0.00107)	Tok/s 56198 (49941)	Loss/tok 3.4765 (3.4422)	Learning Rate [0.00125]
8: TRAIN [1][10/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00104)	Tok/s 55985 (50045)	Loss/tok 3.1340 (3.3451)	Learning Rate [0.00125]
10: TRAIN [1][10/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00090)	Tok/s 55813 (50155)	Loss/tok 3.5452 (3.4052)	Learning Rate [0.00125]
5: TRAIN [1][10/3416]	Time 0.071 (0.058)	Data 0.00102 (0.00100)	Tok/s 56114 (49923)	Loss/tok 3.3984 (3.3970)	Learning Rate [0.00125]
7: TRAIN [1][10/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00104)	Tok/s 55961 (50035)	Loss/tok 3.4323 (3.3276)	Learning Rate [0.00125]
6: TRAIN [1][10/3416]	Time 0.071 (0.058)	Data 0.00102 (0.00098)	Tok/s 55943 (50003)	Loss/tok 3.6360 (3.4264)	Learning Rate [0.00125]
6: TRAIN [1][20/3416]	Time 0.070 (0.055)	Data 0.00085 (0.00099)	Tok/s 54264 (48012)	Loss/tok 3.5224 (3.3326)	Learning Rate [0.00125]
7: TRAIN [1][20/3416]	Time 0.069 (0.055)	Data 0.00099 (0.00100)	Tok/s 54413 (48019)	Loss/tok 3.5676 (3.3067)	Learning Rate [0.00125]
8: TRAIN [1][20/3416]	Time 0.069 (0.055)	Data 0.00103 (0.00109)	Tok/s 54372 (48046)	Loss/tok 3.6481 (3.3297)	Learning Rate [0.00125]
5: TRAIN [1][20/3416]	Time 0.070 (0.055)	Data 0.00087 (0.00097)	Tok/s 54206 (47961)	Loss/tok 3.2587 (3.3506)	Learning Rate [0.00125]
9: TRAIN [1][20/3416]	Time 0.070 (0.055)	Data 0.00092 (0.00096)	Tok/s 54320 (48120)	Loss/tok 3.5593 (3.3487)	Learning Rate [0.00125]
4: TRAIN [1][20/3416]	Time 0.070 (0.055)	Data 0.00113 (0.00107)	Tok/s 54158 (47967)	Loss/tok 3.4586 (3.3650)	Learning Rate [0.00125]
10: TRAIN [1][20/3416]	Time 0.069 (0.055)	Data 0.00094 (0.00095)	Tok/s 54407 (48222)	Loss/tok 3.3737 (3.3516)	Learning Rate [0.00125]
11: TRAIN [1][20/3416]	Time 0.069 (0.055)	Data 0.00090 (0.00123)	Tok/s 54437 (48256)	Loss/tok 3.6034 (3.2913)	Learning Rate [0.00125]
3: TRAIN [1][20/3416]	Time 0.070 (0.055)	Data 0.00093 (0.00094)	Tok/s 54060 (47945)	Loss/tok 3.4276 (3.3064)	Learning Rate [0.00125]
2: TRAIN [1][20/3416]	Time 0.070 (0.055)	Data 0.00095 (0.00091)	Tok/s 53245 (47838)	Loss/tok 3.3406 (3.3470)	Learning Rate [0.00125]
1: TRAIN [1][20/3416]	Time 0.070 (0.055)	Data 0.00100 (0.00099)	Tok/s 53238 (47771)	Loss/tok 3.2384 (3.3639)	Learning Rate [0.00125]
12: TRAIN [1][20/3416]	Time 0.070 (0.055)	Data 0.00104 (0.00094)	Tok/s 54266 (48309)	Loss/tok 3.3003 (3.3499)	Learning Rate [0.00125]
15: TRAIN [1][20/3416]	Time 0.070 (0.055)	Data 0.00088 (0.00085)	Tok/s 54113 (48615)	Loss/tok 3.5683 (3.3645)	Learning Rate [0.00125]
0: TRAIN [1][20/3416]	Time 0.070 (0.055)	Data 0.00101 (0.00104)	Tok/s 53204 (47683)	Loss/tok 3.5128 (3.3119)	Learning Rate [0.00125]
13: TRAIN [1][20/3416]	Time 0.070 (0.055)	Data 0.00115 (0.00115)	Tok/s 54271 (48375)	Loss/tok 3.4933 (3.3392)	Learning Rate [0.00125]
14: TRAIN [1][20/3416]	Time 0.070 (0.055)	Data 0.00118 (0.00106)	Tok/s 54225 (48489)	Loss/tok 3.4886 (3.3817)	Learning Rate [0.00125]
4: TRAIN [1][30/3416]	Time 0.061 (0.055)	Data 0.00110 (0.00106)	Tok/s 52160 (48052)	Loss/tok 3.5687 (3.3828)	Learning Rate [0.00125]
2: TRAIN [1][30/3416]	Time 0.061 (0.055)	Data 0.00094 (0.00092)	Tok/s 52081 (47914)	Loss/tok 3.8234 (3.3910)	Learning Rate [0.00125]
1: TRAIN [1][30/3416]	Time 0.061 (0.055)	Data 0.00094 (0.00099)	Tok/s 52053 (47812)	Loss/tok 3.5348 (3.4036)	Learning Rate [0.00125]
15: TRAIN [1][30/3416]	Time 0.062 (0.055)	Data 0.00092 (0.00087)	Tok/s 53054 (48666)	Loss/tok 3.3872 (3.3819)	Learning Rate [0.00125]
13: TRAIN [1][30/3416]	Time 0.062 (0.055)	Data 0.00095 (0.00113)	Tok/s 53063 (48420)	Loss/tok 3.2580 (3.3408)	Learning Rate [0.00125]
5: TRAIN [1][30/3416]	Time 0.062 (0.055)	Data 0.00093 (0.00098)	Tok/s 51970 (48027)	Loss/tok 3.4377 (3.3777)	Learning Rate [0.00125]
6: TRAIN [1][30/3416]	Time 0.062 (0.055)	Data 0.00095 (0.00098)	Tok/s 51888 (48063)	Loss/tok 3.3610 (3.3384)	Learning Rate [0.00125]
12: TRAIN [1][30/3416]	Time 0.062 (0.055)	Data 0.00094 (0.00095)	Tok/s 52983 (48362)	Loss/tok 3.3659 (3.3212)	Learning Rate [0.00125]
7: TRAIN [1][30/3416]	Time 0.062 (0.055)	Data 0.00105 (0.00099)	Tok/s 51801 (48095)	Loss/tok 3.4055 (3.3030)	Learning Rate [0.00125]
9: TRAIN [1][30/3416]	Time 0.062 (0.055)	Data 0.00106 (0.00095)	Tok/s 51942 (48163)	Loss/tok 3.5015 (3.3518)	Learning Rate [0.00125]
8: TRAIN [1][30/3416]	Time 0.062 (0.055)	Data 0.00108 (0.00107)	Tok/s 51746 (48109)	Loss/tok 3.3636 (3.3423)	Learning Rate [0.00125]
3: TRAIN [1][30/3416]	Time 0.061 (0.055)	Data 0.00110 (0.00097)	Tok/s 52258 (47999)	Loss/tok 3.2660 (3.3104)	Learning Rate [0.00125]
11: TRAIN [1][30/3416]	Time 0.062 (0.055)	Data 0.00103 (0.00114)	Tok/s 52911 (48316)	Loss/tok 3.2911 (3.2971)	Learning Rate [0.00125]
14: TRAIN [1][30/3416]	Time 0.062 (0.055)	Data 0.00095 (0.00104)	Tok/s 53014 (48560)	Loss/tok 3.5458 (3.3566)	Learning Rate [0.00125]
10: TRAIN [1][30/3416]	Time 0.062 (0.055)	Data 0.00119 (0.00095)	Tok/s 52846 (48261)	Loss/tok 3.6080 (3.3559)	Learning Rate [0.00125]
0: TRAIN [1][30/3416]	Time 0.062 (0.056)	Data 0.00097 (0.00104)	Tok/s 51416 (47674)	Loss/tok 3.4497 (3.3420)	Learning Rate [0.00125]
6: TRAIN [1][40/3416]	Time 0.051 (0.055)	Data 0.00083 (0.00097)	Tok/s 33701 (47550)	Loss/tok 3.0103 (3.2948)	Learning Rate [0.00125]
5: TRAIN [1][40/3416]	Time 0.051 (0.055)	Data 0.00086 (0.00095)	Tok/s 33635 (47523)	Loss/tok 3.0918 (3.3802)	Learning Rate [0.00125]
7: TRAIN [1][40/3416]	Time 0.051 (0.055)	Data 0.00088 (0.00097)	Tok/s 33682 (47611)	Loss/tok 2.8946 (3.2899)	Learning Rate [0.00125]
4: TRAIN [1][40/3416]	Time 0.051 (0.055)	Data 0.00102 (0.00105)	Tok/s 33559 (47537)	Loss/tok 3.2444 (3.3612)	Learning Rate [0.00125]
8: TRAIN [1][40/3416]	Time 0.051 (0.055)	Data 0.00092 (0.00105)	Tok/s 33633 (47664)	Loss/tok 3.1345 (3.3444)	Learning Rate [0.00125]
9: TRAIN [1][40/3416]	Time 0.051 (0.055)	Data 0.00089 (0.00095)	Tok/s 33672 (47761)	Loss/tok 2.8963 (3.3348)	Learning Rate [0.00125]
2: TRAIN [1][40/3416]	Time 0.052 (0.055)	Data 0.00094 (0.00093)	Tok/s 33510 (47363)	Loss/tok 3.0975 (3.3730)	Learning Rate [0.00125]
11: TRAIN [1][40/3416]	Time 0.051 (0.055)	Data 0.00083 (0.00108)	Tok/s 34279 (47908)	Loss/tok 3.3675 (3.3148)	Learning Rate [0.00125]
10: TRAIN [1][40/3416]	Time 0.051 (0.055)	Data 0.00091 (0.00095)	Tok/s 33667 (47841)	Loss/tok 3.0674 (3.3289)	Learning Rate [0.00125]
1: TRAIN [1][40/3416]	Time 0.052 (0.055)	Data 0.00094 (0.00099)	Tok/s 33517 (47290)	Loss/tok 2.9232 (3.3609)	Learning Rate [0.00125]
0: TRAIN [1][40/3416]	Time 0.052 (0.055)	Data 0.00091 (0.00103)	Tok/s 33504 (47197)	Loss/tok 3.0378 (3.3299)	Learning Rate [0.00125]
15: TRAIN [1][40/3416]	Time 0.052 (0.055)	Data 0.00086 (0.00087)	Tok/s 34696 (48291)	Loss/tok 3.3111 (3.3762)	Learning Rate [0.00125]
14: TRAIN [1][40/3416]	Time 0.052 (0.055)	Data 0.00089 (0.00100)	Tok/s 34637 (48216)	Loss/tok 3.2250 (3.3501)	Learning Rate [0.00125]
3: TRAIN [1][40/3416]	Time 0.052 (0.055)	Data 0.00095 (0.00097)	Tok/s 33522 (47486)	Loss/tok 3.2709 (3.3131)	Learning Rate [0.00125]
12: TRAIN [1][40/3416]	Time 0.052 (0.055)	Data 0.00092 (0.00097)	Tok/s 34773 (48010)	Loss/tok 3.1804 (3.3170)	Learning Rate [0.00125]
13: TRAIN [1][40/3416]	Time 0.053 (0.055)	Data 0.00083 (0.00109)	Tok/s 34000 (48073)	Loss/tok 3.0007 (3.3436)	Learning Rate [0.00125]
4: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00099 (0.00104)	Tok/s 53358 (48616)	Loss/tok 3.3230 (3.3595)	Learning Rate [0.00125]
2: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00101 (0.00094)	Tok/s 53443 (48451)	Loss/tok 3.2870 (3.3843)	Learning Rate [0.00125]
6: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00089 (0.00097)	Tok/s 53174 (48639)	Loss/tok 3.1087 (3.3076)	Learning Rate [0.00125]
5: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00096 (0.00095)	Tok/s 53258 (48613)	Loss/tok 3.6691 (3.3862)	Learning Rate [0.00125]
9: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00098 (0.00094)	Tok/s 53378 (48842)	Loss/tok 3.5990 (3.3554)	Learning Rate [0.00125]
8: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00095 (0.00104)	Tok/s 53323 (48745)	Loss/tok 3.4867 (3.3726)	Learning Rate [0.00125]
1: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00094 (0.00098)	Tok/s 53359 (48375)	Loss/tok 3.4850 (3.3589)	Learning Rate [0.00125]
10: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00096 (0.00095)	Tok/s 53459 (48952)	Loss/tok 3.2820 (3.3251)	Learning Rate [0.00125]
7: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00091 (0.00095)	Tok/s 53262 (48688)	Loss/tok 3.5059 (3.2992)	Learning Rate [0.00125]
11: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00093 (0.00106)	Tok/s 53425 (49010)	Loss/tok 3.3883 (3.3347)	Learning Rate [0.00125]
15: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00090 (0.00087)	Tok/s 53443 (49356)	Loss/tok 3.0386 (3.3806)	Learning Rate [0.00125]
12: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00095 (0.00097)	Tok/s 53448 (49110)	Loss/tok 3.4102 (3.3415)	Learning Rate [0.00125]
14: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00102 (0.00100)	Tok/s 53441 (49285)	Loss/tok 3.7743 (3.3605)	Learning Rate [0.00125]
13: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00094 (0.00108)	Tok/s 53443 (49179)	Loss/tok 3.5160 (3.3446)	Learning Rate [0.00125]
0: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00100 (0.00104)	Tok/s 53468 (48265)	Loss/tok 3.5353 (3.3479)	Learning Rate [0.00125]
3: TRAIN [1][50/3416]	Time 0.054 (0.055)	Data 0.00099 (0.00097)	Tok/s 53487 (48570)	Loss/tok 3.2719 (3.3188)	Learning Rate [0.00125]
9: TRAIN [1][60/3416]	Time 0.071 (0.056)	Data 0.00089 (0.00093)	Tok/s 85602 (50762)	Loss/tok 3.3239 (3.3646)	Learning Rate [0.00125]
8: TRAIN [1][60/3416]	Time 0.071 (0.056)	Data 0.00093 (0.00103)	Tok/s 85322 (50668)	Loss/tok 3.2441 (3.3708)	Learning Rate [0.00125]
7: TRAIN [1][60/3416]	Time 0.071 (0.056)	Data 0.00088 (0.00095)	Tok/s 85199 (50612)	Loss/tok 3.3676 (3.3272)	Learning Rate [0.00125]
10: TRAIN [1][60/3416]	Time 0.071 (0.056)	Data 0.00094 (0.00094)	Tok/s 86267 (50865)	Loss/tok 3.0956 (3.3514)	Learning Rate [0.00125]
6: TRAIN [1][60/3416]	Time 0.071 (0.056)	Data 0.00088 (0.00096)	Tok/s 84476 (50545)	Loss/tok 3.2352 (3.3348)	Learning Rate [0.00125]
11: TRAIN [1][60/3416]	Time 0.071 (0.056)	Data 0.00083 (0.00103)	Tok/s 86180 (50913)	Loss/tok 3.0564 (3.3418)	Learning Rate [0.00125]
5: TRAIN [1][60/3416]	Time 0.072 (0.056)	Data 0.00086 (0.00094)	Tok/s 84092 (50518)	Loss/tok 3.2825 (3.3873)	Learning Rate [0.00125]
4: TRAIN [1][60/3416]	Time 0.072 (0.056)	Data 0.00101 (0.00103)	Tok/s 83902 (50509)	Loss/tok 3.0988 (3.3832)	Learning Rate [0.00125]
12: TRAIN [1][60/3416]	Time 0.071 (0.056)	Data 0.00092 (0.00096)	Tok/s 86645 (51005)	Loss/tok 3.2291 (3.3371)	Learning Rate [0.00125]
14: TRAIN [1][60/3416]	Time 0.072 (0.056)	Data 0.00092 (0.00098)	Tok/s 87437 (51189)	Loss/tok 3.0507 (3.3527)	Learning Rate [0.00125]
15: TRAIN [1][60/3416]	Time 0.072 (0.056)	Data 0.00076 (0.00087)	Tok/s 88017 (51260)	Loss/tok 3.1005 (3.3779)	Learning Rate [0.00125]
0: TRAIN [1][60/3416]	Time 0.072 (0.056)	Data 0.00096 (0.00104)	Tok/s 82954 (50152)	Loss/tok 3.2756 (3.3685)	Learning Rate [0.00125]
1: TRAIN [1][60/3416]	Time 0.072 (0.056)	Data 0.00092 (0.00097)	Tok/s 82816 (50256)	Loss/tok 3.4326 (3.3789)	Learning Rate [0.00125]
2: TRAIN [1][60/3416]	Time 0.072 (0.056)	Data 0.00092 (0.00095)	Tok/s 82842 (50333)	Loss/tok 3.1309 (3.3801)	Learning Rate [0.00125]
3: TRAIN [1][60/3416]	Time 0.072 (0.056)	Data 0.00100 (0.00096)	Tok/s 83710 (50460)	Loss/tok 3.3647 (3.3477)	Learning Rate [0.00125]
13: TRAIN [1][60/3416]	Time 0.073 (0.056)	Data 0.00086 (0.00106)	Tok/s 84863 (51045)	Loss/tok 3.1498 (3.3422)	Learning Rate [0.00125]
6: TRAIN [1][70/3416]	Time 0.052 (0.056)	Data 0.00089 (0.00096)	Tok/s 51674 (51053)	Loss/tok 3.3964 (3.3577)	Learning Rate [0.00125]
4: TRAIN [1][70/3416]	Time 0.052 (0.056)	Data 0.00101 (0.00102)	Tok/s 51750 (51019)	Loss/tok 3.3177 (3.3856)	Learning Rate [0.00125]
5: TRAIN [1][70/3416]	Time 0.052 (0.056)	Data 0.00088 (0.00093)	Tok/s 51730 (51025)	Loss/tok 3.2551 (3.3965)	Learning Rate [0.00125]
7: TRAIN [1][70/3416]	Time 0.052 (0.056)	Data 0.00081 (0.00095)	Tok/s 51698 (51138)	Loss/tok 3.3195 (3.3531)	Learning Rate [0.00125]
8: TRAIN [1][70/3416]	Time 0.052 (0.056)	Data 0.00091 (0.00103)	Tok/s 51538 (51205)	Loss/tok 3.3929 (3.3861)	Learning Rate [0.00125]
9: TRAIN [1][70/3416]	Time 0.052 (0.056)	Data 0.00101 (0.00094)	Tok/s 51405 (51286)	Loss/tok 3.3399 (3.3705)	Learning Rate [0.00125]
2: TRAIN [1][70/3416]	Time 0.052 (0.056)	Data 0.00091 (0.00097)	Tok/s 50372 (50827)	Loss/tok 3.3416 (3.3914)	Learning Rate [0.00125]
1: TRAIN [1][70/3416]	Time 0.052 (0.056)	Data 0.00089 (0.00097)	Tok/s 50289 (50754)	Loss/tok 3.6766 (3.3860)	Learning Rate [0.00125]
10: TRAIN [1][70/3416]	Time 0.052 (0.056)	Data 0.00100 (0.00094)	Tok/s 51317 (51374)	Loss/tok 3.2074 (3.3599)	Learning Rate [0.00125]
11: TRAIN [1][70/3416]	Time 0.053 (0.056)	Data 0.00087 (0.00101)	Tok/s 51178 (51415)	Loss/tok 3.3203 (3.3422)	Learning Rate [0.00125]
0: TRAIN [1][70/3416]	Time 0.052 (0.056)	Data 0.00092 (0.00104)	Tok/s 50162 (50653)	Loss/tok 3.2933 (3.3683)	Learning Rate [0.00125]
15: TRAIN [1][70/3416]	Time 0.052 (0.056)	Data 0.00080 (0.00088)	Tok/s 51257 (51764)	Loss/tok 3.4827 (3.3855)	Learning Rate [0.00125]
12: TRAIN [1][70/3416]	Time 0.053 (0.056)	Data 0.00087 (0.00096)	Tok/s 51086 (51493)	Loss/tok 3.3208 (3.3501)	Learning Rate [0.00125]
14: TRAIN [1][70/3416]	Time 0.052 (0.056)	Data 0.00094 (0.00097)	Tok/s 51637 (51682)	Loss/tok 3.3234 (3.3567)	Learning Rate [0.00125]
13: TRAIN [1][70/3416]	Time 0.053 (0.056)	Data 0.00086 (0.00106)	Tok/s 51167 (51559)	Loss/tok 3.2382 (3.3476)	Learning Rate [0.00125]
3: TRAIN [1][70/3416]	Time 0.052 (0.056)	Data 0.00092 (0.00096)	Tok/s 51490 (50957)	Loss/tok 3.4521 (3.3486)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
4: TRAIN [1][80/3416]	Time 0.051 (0.057)	Data 0.00105 (0.00102)	Tok/s 32533 (51266)	Loss/tok 3.1731 (3.3760)	Learning Rate [0.00125]
2: TRAIN [1][80/3416]	Time 0.051 (0.057)	Data 0.00095 (0.00097)	Tok/s 32498 (51093)	Loss/tok 3.0115 (3.3868)	Learning Rate [0.00125]
1: TRAIN [1][80/3416]	Time 0.051 (0.057)	Data 0.00087 (0.00096)	Tok/s 32479 (51034)	Loss/tok 3.2918 (3.3875)	Learning Rate [0.00125]
5: TRAIN [1][80/3416]	Time 0.051 (0.057)	Data 0.00089 (0.00092)	Tok/s 32474 (51278)	Loss/tok 2.9599 (3.3920)	Learning Rate [0.00125]
6: TRAIN [1][80/3416]	Time 0.051 (0.057)	Data 0.00084 (0.00096)	Tok/s 32385 (51311)	Loss/tok 3.1212 (3.3698)	Learning Rate [0.00125]
7: TRAIN [1][80/3416]	Time 0.051 (0.057)	Data 0.00089 (0.00095)	Tok/s 32366 (51397)	Loss/tok 3.0448 (3.3577)	Learning Rate [0.00125]
0: TRAIN [1][80/3416]	Time 0.051 (0.057)	Data 0.00086 (0.00103)	Tok/s 32384 (50943)	Loss/tok 3.1018 (3.3689)	Learning Rate [0.00125]
8: TRAIN [1][80/3416]	Time 0.052 (0.057)	Data 0.00099 (0.00102)	Tok/s 32296 (51484)	Loss/tok 2.9682 (3.3769)	Learning Rate [0.00125]
15: TRAIN [1][80/3416]	Time 0.051 (0.057)	Data 0.00076 (0.00088)	Tok/s 33568 (52069)	Loss/tok 3.2188 (3.3783)	Learning Rate [0.00125]
9: TRAIN [1][80/3416]	Time 0.052 (0.057)	Data 0.00100 (0.00094)	Tok/s 32986 (51573)	Loss/tok 2.8794 (3.3711)	Learning Rate [0.00125]
14: TRAIN [1][80/3416]	Time 0.052 (0.057)	Data 0.00087 (0.00096)	Tok/s 33538 (51991)	Loss/tok 3.2881 (3.3666)	Learning Rate [0.00125]
11: TRAIN [1][80/3416]	Time 0.052 (0.057)	Data 0.00086 (0.00100)	Tok/s 33414 (51715)	Loss/tok 3.1272 (3.3334)	Learning Rate [0.00125]
3: TRAIN [1][80/3416]	Time 0.051 (0.057)	Data 0.00091 (0.00096)	Tok/s 32736 (51205)	Loss/tok 3.1226 (3.3536)	Learning Rate [0.00125]
12: TRAIN [1][80/3416]	Time 0.052 (0.057)	Data 0.00091 (0.00096)	Tok/s 33469 (51816)	Loss/tok 2.9466 (3.3533)	Learning Rate [0.00125]
10: TRAIN [1][80/3416]	Time 0.052 (0.057)	Data 0.00096 (0.00094)	Tok/s 33358 (51670)	Loss/tok 2.9108 (3.3624)	Learning Rate [0.00125]
13: TRAIN [1][80/3416]	Time 0.052 (0.057)	Data 0.00093 (0.00106)	Tok/s 33450 (51883)	Loss/tok 3.1682 (3.3348)	Learning Rate [0.00125]
0: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00093 (0.00104)	Tok/s 51187 (50511)	Loss/tok 3.1022 (3.3615)	Learning Rate [0.00125]
1: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00105 (0.00096)	Tok/s 51088 (50590)	Loss/tok 3.2942 (3.3902)	Learning Rate [0.00125]
6: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00081 (0.00096)	Tok/s 50816 (50878)	Loss/tok 3.0521 (3.3594)	Learning Rate [0.00125]
15: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00086 (0.00087)	Tok/s 51137 (51628)	Loss/tok 3.3671 (3.3741)	Learning Rate [0.00125]
2: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00100 (0.00098)	Tok/s 50975 (50651)	Loss/tok 3.5348 (3.3912)	Learning Rate [0.00125]
7: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00096 (0.00095)	Tok/s 50950 (50955)	Loss/tok 3.2927 (3.3595)	Learning Rate [0.00125]
9: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00106 (0.00095)	Tok/s 51010 (51114)	Loss/tok 3.2345 (3.3617)	Learning Rate [0.00125]
8: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00108 (0.00102)	Tok/s 50976 (51034)	Loss/tok 3.3289 (3.3738)	Learning Rate [0.00125]
4: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00114 (0.00102)	Tok/s 50870 (50834)	Loss/tok 3.1061 (3.3795)	Learning Rate [0.00125]
10: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00098 (0.00094)	Tok/s 51104 (51201)	Loss/tok 3.4174 (3.3601)	Learning Rate [0.00125]
14: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00084 (0.00096)	Tok/s 51114 (51558)	Loss/tok 3.0879 (3.3582)	Learning Rate [0.00125]
5: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00080 (0.00092)	Tok/s 50588 (50847)	Loss/tok 3.1984 (3.3857)	Learning Rate [0.00125]
11: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00091 (0.00099)	Tok/s 51023 (51253)	Loss/tok 3.1174 (3.3297)	Learning Rate [0.00125]
13: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00092 (0.00106)	Tok/s 51147 (51464)	Loss/tok 3.1975 (3.3350)	Learning Rate [0.00125]
12: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00096 (0.00096)	Tok/s 51111 (51377)	Loss/tok 3.1710 (3.3580)	Learning Rate [0.00125]
3: TRAIN [1][90/3416]	Time 0.044 (0.056)	Data 0.00098 (0.00096)	Tok/s 50912 (50748)	Loss/tok 3.4444 (3.3514)	Learning Rate [0.00125]
12: Gradient norm: inf
13: Gradient norm: inf
11: Gradient norm: inf
14: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
8: Gradient norm: inf
6: Gradient norm: inf
0: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
4: Gradient norm: inf
3: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
4: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00099 (0.00102)	Tok/s 61211 (51713)	Loss/tok 3.4556 (3.3898)	Learning Rate [0.00125]
2: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00105 (0.00098)	Tok/s 61091 (51540)	Loss/tok 3.5614 (3.4040)	Learning Rate [0.00125]
6: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00093 (0.00096)	Tok/s 61346 (51782)	Loss/tok 3.5635 (3.3657)	Learning Rate [0.00125]
5: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00101 (0.00092)	Tok/s 61156 (51730)	Loss/tok 3.6441 (3.3963)	Learning Rate [0.00125]
1: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00092 (0.00096)	Tok/s 61070 (51485)	Loss/tok 3.3407 (3.3867)	Learning Rate [0.00125]
10: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00104 (0.00094)	Tok/s 61410 (52110)	Loss/tok 3.6680 (3.3721)	Learning Rate [0.00125]
9: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00106 (0.00095)	Tok/s 61391 (52020)	Loss/tok 3.4812 (3.3599)	Learning Rate [0.00125]
8: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00113 (0.00102)	Tok/s 61261 (51938)	Loss/tok 3.6539 (3.3816)	Learning Rate [0.00125]
7: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00094 (0.00095)	Tok/s 61247 (51862)	Loss/tok 3.5308 (3.3602)	Learning Rate [0.00125]
15: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00089 (0.00087)	Tok/s 61105 (52506)	Loss/tok 3.4705 (3.3789)	Learning Rate [0.00125]
12: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00113 (0.00096)	Tok/s 61196 (52270)	Loss/tok 3.3878 (3.3635)	Learning Rate [0.00125]
14: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00093 (0.00095)	Tok/s 61144 (52437)	Loss/tok 3.5863 (3.3643)	Learning Rate [0.00125]
11: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00088 (0.00099)	Tok/s 61358 (52159)	Loss/tok 3.5393 (3.3388)	Learning Rate [0.00125]
13: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00094 (0.00105)	Tok/s 61181 (52348)	Loss/tok 3.4665 (3.3319)	Learning Rate [0.00125]
0: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00094 (0.00103)	Tok/s 60268 (51405)	Loss/tok 3.6742 (3.3692)	Learning Rate [0.00125]
3: TRAIN [1][100/3416]	Time 0.069 (0.057)	Data 0.00101 (0.00097)	Tok/s 61181 (51630)	Loss/tok 3.7930 (3.3686)	Learning Rate [0.00125]
11: TRAIN [1][110/3416]	Time 0.069 (0.057)	Data 0.00085 (0.00098)	Tok/s 79695 (52555)	Loss/tok 3.5123 (3.3397)	Learning Rate [0.00125]
9: TRAIN [1][110/3416]	Time 0.070 (0.057)	Data 0.00093 (0.00095)	Tok/s 79099 (52415)	Loss/tok 3.1751 (3.3500)	Learning Rate [0.00125]
10: TRAIN [1][110/3416]	Time 0.069 (0.057)	Data 0.00096 (0.00094)	Tok/s 79246 (52497)	Loss/tok 3.4822 (3.3640)	Learning Rate [0.00125]
1: TRAIN [1][110/3416]	Time 0.070 (0.057)	Data 0.00093 (0.00096)	Tok/s 77897 (51882)	Loss/tok 3.3921 (3.3801)	Learning Rate [0.00125]
12: TRAIN [1][110/3416]	Time 0.070 (0.057)	Data 0.00089 (0.00095)	Tok/s 80109 (52664)	Loss/tok 3.3152 (3.3526)	Learning Rate [0.00125]
0: TRAIN [1][110/3416]	Time 0.070 (0.057)	Data 0.00091 (0.00102)	Tok/s 77975 (51803)	Loss/tok 3.3908 (3.3614)	Learning Rate [0.00125]
8: TRAIN [1][110/3416]	Time 0.070 (0.057)	Data 0.00093 (0.00102)	Tok/s 79033 (52333)	Loss/tok 3.3666 (3.3742)	Learning Rate [0.00125]
13: TRAIN [1][110/3416]	Time 0.070 (0.057)	Data 0.00093 (0.00104)	Tok/s 79977 (52734)	Loss/tok 3.5682 (3.3312)	Learning Rate [0.00125]
2: TRAIN [1][110/3416]	Time 0.070 (0.057)	Data 0.00091 (0.00098)	Tok/s 77842 (51939)	Loss/tok 3.3076 (3.4006)	Learning Rate [0.00125]
15: TRAIN [1][110/3416]	Time 0.070 (0.057)	Data 0.00084 (0.00087)	Tok/s 79786 (52909)	Loss/tok 3.2226 (3.3761)	Learning Rate [0.00125]
14: TRAIN [1][110/3416]	Time 0.070 (0.057)	Data 0.00080 (0.00094)	Tok/s 79874 (52825)	Loss/tok 3.4752 (3.3649)	Learning Rate [0.00125]
7: TRAIN [1][110/3416]	Time 0.070 (0.057)	Data 0.00090 (0.00095)	Tok/s 78926 (52254)	Loss/tok 3.4655 (3.3579)	Learning Rate [0.00125]
6: TRAIN [1][110/3416]	Time 0.070 (0.057)	Data 0.00079 (0.00095)	Tok/s 78767 (52179)	Loss/tok 3.4438 (3.3642)	Learning Rate [0.00125]
4: TRAIN [1][110/3416]	Time 0.070 (0.057)	Data 0.00086 (0.00102)	Tok/s 78669 (52106)	Loss/tok 3.4061 (3.3903)	Learning Rate [0.00125]
3: TRAIN [1][110/3416]	Time 0.070 (0.057)	Data 0.00090 (0.00097)	Tok/s 77774 (52021)	Loss/tok 3.5933 (3.3725)	Learning Rate [0.00125]
5: TRAIN [1][110/3416]	Time 0.071 (0.057)	Data 0.00088 (0.00092)	Tok/s 77508 (52121)	Loss/tok 3.6196 (3.3953)	Learning Rate [0.00125]
2: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00090 (0.00098)	Tok/s 53345 (52078)	Loss/tok 3.4954 (3.3989)	Learning Rate [0.00125]
1: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00087 (0.00096)	Tok/s 53372 (52018)	Loss/tok 3.4791 (3.3747)	Learning Rate [0.00125]
0: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00090 (0.00102)	Tok/s 53363 (51946)	Loss/tok 3.3461 (3.3641)	Learning Rate [0.00125]
4: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00096 (0.00101)	Tok/s 53116 (52256)	Loss/tok 3.6162 (3.3889)	Learning Rate [0.00125]
15: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00084 (0.00088)	Tok/s 54375 (53091)	Loss/tok 3.5296 (3.3688)	Learning Rate [0.00125]
5: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00093 (0.00093)	Tok/s 53043 (52290)	Loss/tok 3.5450 (3.3928)	Learning Rate [0.00125]
6: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00093 (0.00095)	Tok/s 52985 (52338)	Loss/tok 3.4213 (3.3603)	Learning Rate [0.00125]
7: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00093 (0.00095)	Tok/s 52932 (52409)	Loss/tok 3.4353 (3.3516)	Learning Rate [0.00125]
12: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00086 (0.00095)	Tok/s 54142 (52814)	Loss/tok 3.5213 (3.3521)	Learning Rate [0.00125]
11: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00083 (0.00097)	Tok/s 54006 (52702)	Loss/tok 3.5197 (3.3424)	Learning Rate [0.00125]
8: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00101 (0.00102)	Tok/s 53843 (52489)	Loss/tok 3.1024 (3.3666)	Learning Rate [0.00125]
9: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00103 (0.00095)	Tok/s 53823 (52564)	Loss/tok 3.4388 (3.3528)	Learning Rate [0.00125]
3: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00087 (0.00097)	Tok/s 53364 (52161)	Loss/tok 3.6683 (3.3729)	Learning Rate [0.00125]
10: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00097 (0.00095)	Tok/s 53909 (52646)	Loss/tok 3.5469 (3.3627)	Learning Rate [0.00125]
13: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00092 (0.00104)	Tok/s 53886 (52898)	Loss/tok 3.4126 (3.3308)	Learning Rate [0.00125]
14: TRAIN [1][120/3416]	Time 0.064 (0.057)	Data 0.00090 (0.00094)	Tok/s 54330 (53001)	Loss/tok 3.5005 (3.3692)	Learning Rate [0.00125]
11: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00087 (0.00096)	Tok/s 53086 (52802)	Loss/tok 3.3757 (3.3498)	Learning Rate [0.00125]
10: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00093 (0.00095)	Tok/s 53022 (52747)	Loss/tok 3.3874 (3.3716)	Learning Rate [0.00125]
12: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00090 (0.00095)	Tok/s 53118 (52906)	Loss/tok 3.3190 (3.3577)	Learning Rate [0.00125]
9: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00092 (0.00094)	Tok/s 52902 (52667)	Loss/tok 3.5678 (3.3681)	Learning Rate [0.00125]
13: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00097 (0.00103)	Tok/s 53044 (52985)	Loss/tok 3.2718 (3.3405)	Learning Rate [0.00125]
8: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00094 (0.00101)	Tok/s 52670 (52596)	Loss/tok 3.3127 (3.3735)	Learning Rate [0.00125]
14: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00091 (0.00094)	Tok/s 53081 (53099)	Loss/tok 3.3176 (3.3703)	Learning Rate [0.00125]
7: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00085 (0.00095)	Tok/s 51737 (52514)	Loss/tok 3.4244 (3.3568)	Learning Rate [0.00125]
15: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00087 (0.00088)	Tok/s 53078 (53174)	Loss/tok 3.7492 (3.3816)	Learning Rate [0.00125]
6: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00086 (0.00095)	Tok/s 51700 (52443)	Loss/tok 3.1155 (3.3629)	Learning Rate [0.00125]
0: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00096 (0.00101)	Tok/s 51899 (52061)	Loss/tok 3.1195 (3.3705)	Learning Rate [0.00125]
4: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00096 (0.00101)	Tok/s 51727 (52353)	Loss/tok 3.3521 (3.3966)	Learning Rate [0.00125]
1: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00088 (0.00096)	Tok/s 51842 (52126)	Loss/tok 3.2097 (3.3801)	Learning Rate [0.00125]
5: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00097 (0.00093)	Tok/s 51736 (52387)	Loss/tok 3.2895 (3.3979)	Learning Rate [0.00125]
2: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00090 (0.00099)	Tok/s 51767 (52187)	Loss/tok 3.2609 (3.3999)	Learning Rate [0.00125]
3: TRAIN [1][130/3416]	Time 0.057 (0.057)	Data 0.00092 (0.00097)	Tok/s 51991 (52266)	Loss/tok 3.4286 (3.3759)	Learning Rate [0.00125]
6: TRAIN [1][140/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00095)	Tok/s 60771 (52706)	Loss/tok 3.7223 (3.3625)	Learning Rate [0.00125]
7: TRAIN [1][140/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00095)	Tok/s 60698 (52776)	Loss/tok 3.4556 (3.3644)	Learning Rate [0.00125]
5: TRAIN [1][140/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00093)	Tok/s 60808 (52650)	Loss/tok 3.3431 (3.4042)	Learning Rate [0.00125]
4: TRAIN [1][140/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00101)	Tok/s 60823 (52616)	Loss/tok 3.5079 (3.4062)	Learning Rate [0.00125]
8: TRAIN [1][140/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00101)	Tok/s 60645 (52855)	Loss/tok 3.5731 (3.3798)	Learning Rate [0.00125]
9: TRAIN [1][140/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00094)	Tok/s 60534 (52919)	Loss/tok 3.6871 (3.3734)	Learning Rate [0.00125]
2: TRAIN [1][140/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00099)	Tok/s 60773 (52453)	Loss/tok 3.6185 (3.4037)	Learning Rate [0.00125]
1: TRAIN [1][140/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00096)	Tok/s 60707 (52396)	Loss/tok 3.4302 (3.3819)	Learning Rate [0.00125]
10: TRAIN [1][140/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00095)	Tok/s 60437 (52997)	Loss/tok 3.3565 (3.3755)	Learning Rate [0.00125]
11: TRAIN [1][140/3416]	Time 0.068 (0.058)	Data 0.00080 (0.00096)	Tok/s 60325 (53050)	Loss/tok 3.3643 (3.3530)	Learning Rate [0.00125]
0: TRAIN [1][140/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00101)	Tok/s 60562 (52330)	Loss/tok 3.2992 (3.3704)	Learning Rate [0.00125]
15: TRAIN [1][140/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00088)	Tok/s 60489 (53396)	Loss/tok 3.4326 (3.3822)	Learning Rate [0.00125]
12: TRAIN [1][140/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00095)	Tok/s 60351 (53145)	Loss/tok 3.7217 (3.3686)	Learning Rate [0.00125]
13: TRAIN [1][140/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00103)	Tok/s 60337 (53219)	Loss/tok 3.5341 (3.3486)	Learning Rate [0.00125]
3: TRAIN [1][140/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00096)	Tok/s 61048 (52527)	Loss/tok 3.5985 (3.3857)	Learning Rate [0.00125]
14: TRAIN [1][140/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00095)	Tok/s 58858 (53315)	Loss/tok 3.4768 (3.3766)	Learning Rate [0.00125]
15: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00087 (0.00088)	Tok/s 56564 (53914)	Loss/tok 3.4179 (3.3897)	Learning Rate [0.00125]
1: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00096)	Tok/s 56608 (52900)	Loss/tok 3.3221 (3.3813)	Learning Rate [0.00125]
0: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00101)	Tok/s 56557 (52834)	Loss/tok 3.2926 (3.3726)	Learning Rate [0.00125]
14: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00094)	Tok/s 56479 (53836)	Loss/tok 3.5778 (3.3803)	Learning Rate [0.00125]
13: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00102)	Tok/s 56316 (53730)	Loss/tok 3.3659 (3.3539)	Learning Rate [0.00125]
2: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00100 (0.00099)	Tok/s 56558 (52956)	Loss/tok 3.6903 (3.4052)	Learning Rate [0.00125]
12: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00095)	Tok/s 56287 (53657)	Loss/tok 3.5451 (3.3756)	Learning Rate [0.00125]
11: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00095)	Tok/s 56185 (53564)	Loss/tok 3.4029 (3.3623)	Learning Rate [0.00125]
4: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00101)	Tok/s 56435 (53119)	Loss/tok 3.4529 (3.4065)	Learning Rate [0.00125]
10: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00103 (0.00095)	Tok/s 56185 (53513)	Loss/tok 3.5636 (3.3820)	Learning Rate [0.00125]
9: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00094)	Tok/s 56173 (53431)	Loss/tok 3.4157 (3.3765)	Learning Rate [0.00125]
8: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00101)	Tok/s 56190 (53357)	Loss/tok 3.4809 (3.3886)	Learning Rate [0.00125]
6: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00087 (0.00095)	Tok/s 56278 (53207)	Loss/tok 3.3477 (3.3730)	Learning Rate [0.00125]
5: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00093)	Tok/s 56354 (53153)	Loss/tok 3.8380 (3.4102)	Learning Rate [0.00125]
7: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00095)	Tok/s 56230 (53283)	Loss/tok 3.4893 (3.3663)	Learning Rate [0.00125]
3: TRAIN [1][150/3416]	Time 0.066 (0.058)	Data 0.00112 (0.00097)	Tok/s 56670 (53032)	Loss/tok 3.5567 (3.3892)	Learning Rate [0.00125]
6: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00095)	Tok/s 55185 (52850)	Loss/tok 3.6550 (3.3754)	Learning Rate [0.00125]
5: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 54985 (52792)	Loss/tok 3.6465 (3.4063)	Learning Rate [0.00125]
4: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00101)	Tok/s 54960 (52756)	Loss/tok 3.5937 (3.3997)	Learning Rate [0.00125]
2: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00098)	Tok/s 54707 (52602)	Loss/tok 3.5347 (3.4001)	Learning Rate [0.00125]
7: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00095)	Tok/s 55914 (52925)	Loss/tok 3.4739 (3.3656)	Learning Rate [0.00125]
8: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00120 (0.00101)	Tok/s 55887 (52995)	Loss/tok 3.5088 (3.3854)	Learning Rate [0.00125]
1: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 54686 (52547)	Loss/tok 3.3767 (3.3809)	Learning Rate [0.00125]
9: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00094)	Tok/s 55884 (53069)	Loss/tok 3.3889 (3.3741)	Learning Rate [0.00125]
0: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00101)	Tok/s 54662 (52486)	Loss/tok 3.4327 (3.3709)	Learning Rate [0.00125]
10: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00095)	Tok/s 55766 (53145)	Loss/tok 3.5115 (3.3798)	Learning Rate [0.00125]
15: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00088)	Tok/s 55602 (53560)	Loss/tok 3.6499 (3.3869)	Learning Rate [0.00125]
14: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00094)	Tok/s 55598 (53484)	Loss/tok 3.5478 (3.3766)	Learning Rate [0.00125]
13: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00102)	Tok/s 55635 (53373)	Loss/tok 3.5099 (3.3546)	Learning Rate [0.00125]
11: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00095)	Tok/s 55620 (53198)	Loss/tok 3.6670 (3.3611)	Learning Rate [0.00125]
3: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 54844 (52674)	Loss/tok 3.4929 (3.3892)	Learning Rate [0.00125]
12: TRAIN [1][160/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00095)	Tok/s 55569 (53296)	Loss/tok 3.5015 (3.3726)	Learning Rate [0.00125]
14: TRAIN [1][170/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00094)	Tok/s 51259 (53496)	Loss/tok 3.4610 (3.3796)	Learning Rate [0.00125]
15: TRAIN [1][170/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00089)	Tok/s 51219 (53572)	Loss/tok 3.2166 (3.3830)	Learning Rate [0.00125]
13: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00102)	Tok/s 51154 (53385)	Loss/tok 3.0974 (3.3494)	Learning Rate [0.00125]
0: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00101)	Tok/s 49743 (52485)	Loss/tok 3.1373 (3.3734)	Learning Rate [0.00125]
11: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00081 (0.00095)	Tok/s 50941 (53203)	Loss/tok 3.4098 (3.3609)	Learning Rate [0.00125]
12: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00095)	Tok/s 51019 (53311)	Loss/tok 3.4058 (3.3718)	Learning Rate [0.00125]
1: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00096)	Tok/s 49604 (52552)	Loss/tok 3.2663 (3.3770)	Learning Rate [0.00125]
10: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00095)	Tok/s 50714 (53151)	Loss/tok 3.4413 (3.3762)	Learning Rate [0.00125]
2: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00098)	Tok/s 49433 (52603)	Loss/tok 3.2117 (3.3950)	Learning Rate [0.00125]
9: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00094)	Tok/s 50609 (53079)	Loss/tok 3.3309 (3.3718)	Learning Rate [0.00125]
8: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00101)	Tok/s 50436 (53007)	Loss/tok 3.3427 (3.3860)	Learning Rate [0.00125]
4: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00101)	Tok/s 50250 (52761)	Loss/tok 3.0634 (3.3961)	Learning Rate [0.00125]
7: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00095)	Tok/s 50301 (52930)	Loss/tok 2.9391 (3.3620)	Learning Rate [0.00125]
6: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00095)	Tok/s 50331 (52854)	Loss/tok 3.2818 (3.3792)	Learning Rate [0.00125]
5: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00093)	Tok/s 50452 (52796)	Loss/tok 3.0731 (3.4016)	Learning Rate [0.00125]
3: TRAIN [1][170/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00096)	Tok/s 49489 (52676)	Loss/tok 3.2469 (3.3891)	Learning Rate [0.00125]
0: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00099 (0.00100)	Tok/s 24740 (52756)	Loss/tok 2.3255 (3.3715)	Learning Rate [0.00125]
15: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00086 (0.00089)	Tok/s 29603 (53862)	Loss/tok 2.5818 (3.3821)	Learning Rate [0.00125]
2: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00100 (0.00098)	Tok/s 24706 (52876)	Loss/tok 2.3965 (3.3984)	Learning Rate [0.00125]
1: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00100 (0.00096)	Tok/s 24739 (52825)	Loss/tok 2.3599 (3.3743)	Learning Rate [0.00125]
14: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00094 (0.00094)	Tok/s 29501 (53790)	Loss/tok 2.9101 (3.3791)	Learning Rate [0.00125]
13: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00098 (0.00102)	Tok/s 27830 (53677)	Loss/tok 2.6270 (3.3532)	Learning Rate [0.00125]
12: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00090 (0.00095)	Tok/s 27740 (53607)	Loss/tok 2.5928 (3.3719)	Learning Rate [0.00125]
4: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00094 (0.00100)	Tok/s 26240 (53048)	Loss/tok 2.5938 (3.4003)	Learning Rate [0.00125]
11: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00086 (0.00094)	Tok/s 27625 (53500)	Loss/tok 2.4537 (3.3601)	Learning Rate [0.00125]
6: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00086 (0.00094)	Tok/s 26121 (53141)	Loss/tok 2.4216 (3.3785)	Learning Rate [0.00125]
5: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00098 (0.00093)	Tok/s 26184 (53081)	Loss/tok 2.5482 (3.4067)	Learning Rate [0.00125]
10: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00095 (0.00095)	Tok/s 27588 (53444)	Loss/tok 2.4495 (3.3772)	Learning Rate [0.00125]
7: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00084 (0.00095)	Tok/s 26271 (53218)	Loss/tok 2.9124 (3.3652)	Learning Rate [0.00125]
8: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00092 (0.00100)	Tok/s 27652 (53299)	Loss/tok 2.3561 (3.3848)	Learning Rate [0.00125]
9: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00088 (0.00094)	Tok/s 27621 (53368)	Loss/tok 2.5113 (3.3726)	Learning Rate [0.00125]
3: TRAIN [1][180/3416]	Time 0.039 (0.058)	Data 0.00090 (0.00096)	Tok/s 25504 (52960)	Loss/tok 2.4646 (3.3894)	Learning Rate [0.00125]
0: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 56655 (52641)	Loss/tok 3.7523 (3.3755)	Learning Rate [0.00125]
1: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 56571 (52710)	Loss/tok 3.4572 (3.3778)	Learning Rate [0.00125]
15: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00088)	Tok/s 57556 (53745)	Loss/tok 3.2926 (3.3795)	Learning Rate [0.00125]
14: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00094)	Tok/s 57577 (53675)	Loss/tok 3.6155 (3.3820)	Learning Rate [0.00125]
2: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00098)	Tok/s 56582 (52764)	Loss/tok 3.5056 (3.3943)	Learning Rate [0.00125]
4: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00100)	Tok/s 56573 (52933)	Loss/tok 3.5503 (3.4014)	Learning Rate [0.00125]
13: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00102)	Tok/s 57544 (53559)	Loss/tok 3.7401 (3.3585)	Learning Rate [0.00125]
12: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00095)	Tok/s 57442 (53488)	Loss/tok 3.4544 (3.3745)	Learning Rate [0.00125]
11: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 57349 (53380)	Loss/tok 3.7934 (3.3630)	Learning Rate [0.00125]
5: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 56458 (52964)	Loss/tok 3.4956 (3.4039)	Learning Rate [0.00125]
6: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 56368 (53021)	Loss/tok 3.8041 (3.3827)	Learning Rate [0.00125]
10: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00095)	Tok/s 57236 (53322)	Loss/tok 3.7996 (3.3801)	Learning Rate [0.00125]
8: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00115 (0.00100)	Tok/s 57901 (53175)	Loss/tok 3.6585 (3.3883)	Learning Rate [0.00125]
7: TRAIN [1][190/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00095)	Tok/s 57135 (53093)	Loss/tok 3.7444 (3.3713)	Learning Rate [0.00125]
9: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00094)	Tok/s 57153 (53241)	Loss/tok 3.4655 (3.3751)	Learning Rate [0.00125]
3: TRAIN [1][190/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00096)	Tok/s 56749 (52850)	Loss/tok 3.3211 (3.3862)	Learning Rate [0.00125]
9: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00093)	Tok/s 59705 (53250)	Loss/tok 3.6279 (3.3732)	Learning Rate [0.00125]
10: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00095)	Tok/s 59941 (53327)	Loss/tok 3.5364 (3.3795)	Learning Rate [0.00125]
7: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00095)	Tok/s 59750 (53108)	Loss/tok 3.4033 (3.3731)	Learning Rate [0.00125]
5: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 59839 (52984)	Loss/tok 3.3936 (3.4011)	Learning Rate [0.00125]
11: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00094)	Tok/s 60419 (53386)	Loss/tok 3.5207 (3.3678)	Learning Rate [0.00125]
8: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00100)	Tok/s 59710 (53186)	Loss/tok 3.5831 (3.3915)	Learning Rate [0.00125]
12: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00095)	Tok/s 60459 (53499)	Loss/tok 3.6267 (3.3788)	Learning Rate [0.00125]
6: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00094)	Tok/s 59768 (53039)	Loss/tok 3.4117 (3.3841)	Learning Rate [0.00125]
4: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00099)	Tok/s 59725 (52949)	Loss/tok 3.5776 (3.4052)	Learning Rate [0.00125]
13: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00101)	Tok/s 60466 (53567)	Loss/tok 3.7289 (3.3633)	Learning Rate [0.00125]
2: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 59698 (52775)	Loss/tok 3.4823 (3.3917)	Learning Rate [0.00125]
14: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00094)	Tok/s 60456 (53676)	Loss/tok 3.5747 (3.3819)	Learning Rate [0.00125]
1: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 59634 (52723)	Loss/tok 3.5809 (3.3805)	Learning Rate [0.00125]
15: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00088)	Tok/s 60487 (53747)	Loss/tok 3.3325 (3.3855)	Learning Rate [0.00125]
0: TRAIN [1][200/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00100)	Tok/s 59604 (52658)	Loss/tok 3.7801 (3.3774)	Learning Rate [0.00125]
3: TRAIN [1][200/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00096)	Tok/s 59974 (52858)	Loss/tok 3.6286 (3.3845)	Learning Rate [0.00125]
9: TRAIN [1][210/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00093)	Tok/s 39565 (53162)	Loss/tok 3.0265 (3.3709)	Learning Rate [0.00125]
8: TRAIN [1][210/3416]	Time 0.050 (0.058)	Data 0.00108 (0.00100)	Tok/s 39593 (53102)	Loss/tok 3.0214 (3.3896)	Learning Rate [0.00125]
7: TRAIN [1][210/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00095)	Tok/s 39529 (53028)	Loss/tok 3.0557 (3.3716)	Learning Rate [0.00125]
10: TRAIN [1][210/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00095)	Tok/s 39511 (53241)	Loss/tok 3.2996 (3.3757)	Learning Rate [0.00125]
11: TRAIN [1][210/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00094)	Tok/s 39412 (53302)	Loss/tok 3.1931 (3.3657)	Learning Rate [0.00125]
6: TRAIN [1][210/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00094)	Tok/s 39346 (52962)	Loss/tok 3.0956 (3.3812)	Learning Rate [0.00125]
12: TRAIN [1][210/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00095)	Tok/s 40182 (53424)	Loss/tok 3.2065 (3.3804)	Learning Rate [0.00125]
5: TRAIN [1][210/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 39274 (52908)	Loss/tok 3.1859 (3.3961)	Learning Rate [0.00125]
13: TRAIN [1][210/3416]	Time 0.051 (0.058)	Data 0.00107 (0.00102)	Tok/s 40523 (53497)	Loss/tok 3.3609 (3.3628)	Learning Rate [0.00125]
4: TRAIN [1][210/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00099)	Tok/s 39210 (52876)	Loss/tok 3.1146 (3.4022)	Learning Rate [0.00125]
14: TRAIN [1][210/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00094)	Tok/s 40425 (53609)	Loss/tok 3.2840 (3.3781)	Learning Rate [0.00125]
3: TRAIN [1][210/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00095)	Tok/s 39139 (52785)	Loss/tok 2.8897 (3.3817)	Learning Rate [0.00125]
2: TRAIN [1][210/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00098)	Tok/s 39062 (52696)	Loss/tok 2.9763 (3.3877)	Learning Rate [0.00125]
15: TRAIN [1][210/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00089)	Tok/s 40309 (53683)	Loss/tok 3.1466 (3.3807)	Learning Rate [0.00125]
1: TRAIN [1][210/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00096)	Tok/s 38995 (52645)	Loss/tok 3.2431 (3.3787)	Learning Rate [0.00125]
0: TRAIN [1][210/3416]	Time 0.051 (0.058)	Data 0.00127 (0.00100)	Tok/s 39044 (52581)	Loss/tok 3.1773 (3.3773)	Learning Rate [0.00125]
11: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00094)	Tok/s 36705 (53319)	Loss/tok 3.2066 (3.3658)	Learning Rate [0.00125]
12: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00095)	Tok/s 36637 (53437)	Loss/tok 2.9513 (3.3778)	Learning Rate [0.00125]
8: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00100)	Tok/s 36746 (53107)	Loss/tok 3.0180 (3.3878)	Learning Rate [0.00125]
10: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00095)	Tok/s 36689 (53248)	Loss/tok 2.9980 (3.3766)	Learning Rate [0.00125]
4: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00099)	Tok/s 36705 (52888)	Loss/tok 3.1624 (3.3962)	Learning Rate [0.00125]
13: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00102)	Tok/s 36577 (53509)	Loss/tok 3.4570 (3.3637)	Learning Rate [0.00125]
9: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00093)	Tok/s 36723 (53169)	Loss/tok 3.2056 (3.3702)	Learning Rate [0.00125]
6: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00093)	Tok/s 36698 (52967)	Loss/tok 3.0610 (3.3818)	Learning Rate [0.00125]
7: TRAIN [1][220/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00095)	Tok/s 36791 (53030)	Loss/tok 3.1173 (3.3674)	Learning Rate [0.00125]
3: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00095)	Tok/s 36641 (52787)	Loss/tok 3.1383 (3.3770)	Learning Rate [0.00125]
5: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00093)	Tok/s 36734 (52916)	Loss/tok 3.1300 (3.3940)	Learning Rate [0.00125]
2: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00098)	Tok/s 36560 (52701)	Loss/tok 2.9136 (3.3875)	Learning Rate [0.00125]
15: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00089)	Tok/s 36458 (53707)	Loss/tok 3.0753 (3.3789)	Learning Rate [0.00125]
1: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00117 (0.00096)	Tok/s 36458 (52650)	Loss/tok 3.1329 (3.3788)	Learning Rate [0.00125]
0: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00101)	Tok/s 36438 (52583)	Loss/tok 3.0794 (3.3735)	Learning Rate [0.00125]
14: TRAIN [1][220/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00094)	Tok/s 36502 (53618)	Loss/tok 3.2497 (3.3761)	Learning Rate [0.00125]
6: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
6: TRAIN [1][230/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00093)	Tok/s 51240 (53017)	Loss/tok 3.3173 (3.3819)	Learning Rate [0.00125]
7: TRAIN [1][230/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00096)	Tok/s 51274 (53078)	Loss/tok 3.1794 (3.3725)	Learning Rate [0.00125]
8: TRAIN [1][230/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00100)	Tok/s 51283 (53150)	Loss/tok 3.0236 (3.3889)	Learning Rate [0.00125]
9: TRAIN [1][230/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00093)	Tok/s 51141 (53211)	Loss/tok 3.3883 (3.3712)	Learning Rate [0.00125]
5: TRAIN [1][230/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00093)	Tok/s 51095 (52968)	Loss/tok 3.5221 (3.3956)	Learning Rate [0.00125]
4: TRAIN [1][230/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00099)	Tok/s 50979 (52941)	Loss/tok 3.5473 (3.3979)	Learning Rate [0.00125]
10: TRAIN [1][230/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00095)	Tok/s 51023 (53290)	Loss/tok 3.2648 (3.3777)	Learning Rate [0.00125]
3: TRAIN [1][230/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00095)	Tok/s 50876 (52841)	Loss/tok 3.4412 (3.3815)	Learning Rate [0.00125]
11: TRAIN [1][230/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00094)	Tok/s 51782 (53364)	Loss/tok 3.4102 (3.3687)	Learning Rate [0.00125]
2: TRAIN [1][230/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00098)	Tok/s 50752 (52757)	Loss/tok 3.1120 (3.3856)	Learning Rate [0.00125]
13: TRAIN [1][230/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00101)	Tok/s 52005 (53549)	Loss/tok 3.4240 (3.3666)	Learning Rate [0.00125]
1: TRAIN [1][230/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00097)	Tok/s 50668 (52706)	Loss/tok 3.0321 (3.3820)	Learning Rate [0.00125]
12: TRAIN [1][230/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00095)	Tok/s 52089 (53478)	Loss/tok 3.3557 (3.3811)	Learning Rate [0.00125]
0: TRAIN [1][230/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00101)	Tok/s 50644 (52638)	Loss/tok 3.1627 (3.3755)	Learning Rate [0.00125]
15: TRAIN [1][230/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00089)	Tok/s 51914 (53741)	Loss/tok 3.4779 (3.3822)	Learning Rate [0.00125]
14: TRAIN [1][230/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00094)	Tok/s 51921 (53656)	Loss/tok 3.3028 (3.3800)	Learning Rate [0.00125]
15: Gradient norm: inf
14: Gradient norm: inf
0: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
10: Gradient norm: inf
13: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
11: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
3: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
5: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
9: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00080 (0.00093)	Tok/s 49126 (53369)	Loss/tok 3.0598 (3.3729)	Learning Rate [0.00125]
8: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00087 (0.00100)	Tok/s 49059 (53308)	Loss/tok 3.2847 (3.3898)	Learning Rate [0.00125]
6: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00084 (0.00093)	Tok/s 49090 (53172)	Loss/tok 3.2760 (3.3838)	Learning Rate [0.00125]
7: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00106 (0.00096)	Tok/s 49063 (53233)	Loss/tok 3.0083 (3.3723)	Learning Rate [0.00125]
10: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00088 (0.00095)	Tok/s 49619 (53450)	Loss/tok 3.1794 (3.3815)	Learning Rate [0.00125]
11: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00080 (0.00094)	Tok/s 50597 (53528)	Loss/tok 3.5553 (3.3709)	Learning Rate [0.00125]
5: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00071 (0.00092)	Tok/s 49093 (53125)	Loss/tok 3.2817 (3.3987)	Learning Rate [0.00125]
4: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00099)	Tok/s 49117 (53099)	Loss/tok 3.3275 (3.3984)	Learning Rate [0.00125]
3: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00086 (0.00095)	Tok/s 49097 (53004)	Loss/tok 3.1468 (3.3840)	Learning Rate [0.00125]
12: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00104 (0.00095)	Tok/s 50590 (53646)	Loss/tok 3.3543 (3.3833)	Learning Rate [0.00125]
2: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00101 (0.00098)	Tok/s 49117 (52923)	Loss/tok 3.1678 (3.3909)	Learning Rate [0.00125]
14: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00096 (0.00094)	Tok/s 50604 (53827)	Loss/tok 3.2478 (3.3820)	Learning Rate [0.00125]
15: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00090 (0.00089)	Tok/s 50622 (53911)	Loss/tok 3.1905 (3.3834)	Learning Rate [0.00125]
1: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00096)	Tok/s 49059 (52872)	Loss/tok 3.2234 (3.3847)	Learning Rate [0.00125]
0: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00103 (0.00101)	Tok/s 49099 (52801)	Loss/tok 3.2352 (3.3769)	Learning Rate [0.00125]
13: TRAIN [1][240/3416]	Time 0.043 (0.058)	Data 0.00096 (0.00101)	Tok/s 50703 (53722)	Loss/tok 3.2077 (3.3675)	Learning Rate [0.00125]
0: TRAIN [1][250/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00101)	Tok/s 50093 (52433)	Loss/tok 3.3966 (3.3747)	Learning Rate [0.00125]
1: TRAIN [1][250/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00096)	Tok/s 50000 (52507)	Loss/tok 3.3187 (3.3822)	Learning Rate [0.00125]
14: TRAIN [1][250/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00094)	Tok/s 51322 (53453)	Loss/tok 3.2002 (3.3768)	Learning Rate [0.00125]
2: TRAIN [1][250/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00098)	Tok/s 49855 (52557)	Loss/tok 3.2553 (3.3858)	Learning Rate [0.00125]
13: TRAIN [1][250/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00101)	Tok/s 51322 (53344)	Loss/tok 3.2872 (3.3618)	Learning Rate [0.00125]
15: TRAIN [1][250/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00090)	Tok/s 51328 (53544)	Loss/tok 3.1634 (3.3815)	Learning Rate [0.00125]
3: TRAIN [1][250/3416]	Time 0.053 (0.058)	Data 0.00075 (0.00094)	Tok/s 49797 (52635)	Loss/tok 3.4341 (3.3848)	Learning Rate [0.00125]
4: TRAIN [1][250/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00099)	Tok/s 49784 (52726)	Loss/tok 3.7332 (3.3973)	Learning Rate [0.00125]
12: TRAIN [1][250/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00096)	Tok/s 51402 (53268)	Loss/tok 3.2956 (3.3821)	Learning Rate [0.00125]
11: TRAIN [1][250/3416]	Time 0.052 (0.058)	Data 0.00082 (0.00093)	Tok/s 51239 (53153)	Loss/tok 3.1781 (3.3693)	Learning Rate [0.00125]
5: TRAIN [1][250/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00092)	Tok/s 49798 (52750)	Loss/tok 3.4105 (3.3953)	Learning Rate [0.00125]
6: TRAIN [1][250/3416]	Time 0.053 (0.058)	Data 0.00080 (0.00093)	Tok/s 49808 (52798)	Loss/tok 3.3071 (3.3818)	Learning Rate [0.00125]
9: TRAIN [1][250/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00093)	Tok/s 51155 (52993)	Loss/tok 3.5274 (3.3702)	Learning Rate [0.00125]
10: TRAIN [1][250/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00095)	Tok/s 51233 (53074)	Loss/tok 3.1806 (3.3775)	Learning Rate [0.00125]
7: TRAIN [1][250/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00096)	Tok/s 50909 (52861)	Loss/tok 3.4493 (3.3720)	Learning Rate [0.00125]
8: TRAIN [1][250/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00100)	Tok/s 51024 (52933)	Loss/tok 3.2169 (3.3840)	Learning Rate [0.00125]
6: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00081 (0.00093)	Tok/s 32608 (52352)	Loss/tok 2.9615 (3.3756)	Learning Rate [0.00125]
5: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00082 (0.00092)	Tok/s 32598 (52305)	Loss/tok 2.9942 (3.3903)	Learning Rate [0.00125]
7: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00096)	Tok/s 32650 (52412)	Loss/tok 2.9343 (3.3673)	Learning Rate [0.00125]
4: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00099)	Tok/s 32539 (52280)	Loss/tok 3.0488 (3.3922)	Learning Rate [0.00125]
8: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00100)	Tok/s 32594 (52481)	Loss/tok 3.1546 (3.3795)	Learning Rate [0.00125]
3: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00082 (0.00094)	Tok/s 32540 (52191)	Loss/tok 3.3386 (3.3822)	Learning Rate [0.00125]
9: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00082 (0.00093)	Tok/s 32590 (52538)	Loss/tok 3.1092 (3.3664)	Learning Rate [0.00125]
2: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00098)	Tok/s 32549 (52110)	Loss/tok 2.9751 (3.3827)	Learning Rate [0.00125]
1: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00096)	Tok/s 32567 (52055)	Loss/tok 3.1011 (3.3807)	Learning Rate [0.00125]
11: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00093)	Tok/s 33451 (52708)	Loss/tok 3.0135 (3.3657)	Learning Rate [0.00125]
0: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00101)	Tok/s 32564 (51982)	Loss/tok 3.1755 (3.3706)	Learning Rate [0.00125]
10: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00095)	Tok/s 32549 (52621)	Loss/tok 3.0407 (3.3716)	Learning Rate [0.00125]
15: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00090)	Tok/s 33870 (53098)	Loss/tok 3.1985 (3.3771)	Learning Rate [0.00125]
14: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00094)	Tok/s 33899 (53006)	Loss/tok 3.1069 (3.3721)	Learning Rate [0.00125]
13: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00101)	Tok/s 33981 (52896)	Loss/tok 2.9222 (3.3577)	Learning Rate [0.00125]
12: TRAIN [1][260/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00096)	Tok/s 33774 (52819)	Loss/tok 3.4591 (3.3792)	Learning Rate [0.00125]
0: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00099 (0.00101)	Tok/s 50737 (52153)	Loss/tok 3.5246 (3.3756)	Learning Rate [0.00125]
1: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00096)	Tok/s 50695 (52224)	Loss/tok 3.4690 (3.3847)	Learning Rate [0.00125]
15: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00090)	Tok/s 51773 (53263)	Loss/tok 3.4082 (3.3801)	Learning Rate [0.00125]
2: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00087 (0.00098)	Tok/s 50793 (52280)	Loss/tok 3.4102 (3.3854)	Learning Rate [0.00125]
14: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00094)	Tok/s 51660 (53175)	Loss/tok 3.2740 (3.3732)	Learning Rate [0.00125]
13: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00101)	Tok/s 51667 (53069)	Loss/tok 3.7384 (3.3604)	Learning Rate [0.00125]
3: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00081 (0.00094)	Tok/s 50806 (52362)	Loss/tok 3.3945 (3.3848)	Learning Rate [0.00125]
6: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00089 (0.00092)	Tok/s 51973 (52522)	Loss/tok 3.2423 (3.3811)	Learning Rate [0.00125]
10: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00087 (0.00095)	Tok/s 51806 (52791)	Loss/tok 3.2347 (3.3750)	Learning Rate [0.00125]
12: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00098 (0.00096)	Tok/s 51708 (52986)	Loss/tok 3.4187 (3.3816)	Learning Rate [0.00125]
9: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00093)	Tok/s 51782 (52706)	Loss/tok 3.3466 (3.3721)	Learning Rate [0.00125]
11: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00080 (0.00093)	Tok/s 51649 (52876)	Loss/tok 3.3365 (3.3713)	Learning Rate [0.00125]
5: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00092)	Tok/s 52100 (52477)	Loss/tok 3.3300 (3.3916)	Learning Rate [0.00125]
4: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00099)	Tok/s 51759 (52454)	Loss/tok 3.3255 (3.3922)	Learning Rate [0.00125]
7: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00098 (0.00096)	Tok/s 51789 (52580)	Loss/tok 3.3882 (3.3683)	Learning Rate [0.00125]
8: TRAIN [1][270/3416]	Time 0.057 (0.058)	Data 0.00098 (0.00100)	Tok/s 51779 (52648)	Loss/tok 3.4008 (3.3861)	Learning Rate [0.00125]
3: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00089 (0.00094)	Tok/s 52388 (52241)	Loss/tok 3.3197 (3.3814)	Learning Rate [0.00125]
5: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00083 (0.00092)	Tok/s 53429 (52362)	Loss/tok 3.6070 (3.3895)	Learning Rate [0.00125]
6: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00092 (0.00092)	Tok/s 53359 (52408)	Loss/tok 3.3532 (3.3798)	Learning Rate [0.00125]
4: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00084 (0.00098)	Tok/s 53308 (52338)	Loss/tok 3.7003 (3.3940)	Learning Rate [0.00125]
2: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00082 (0.00098)	Tok/s 52055 (52160)	Loss/tok 3.3385 (3.3822)	Learning Rate [0.00125]
1: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00093 (0.00097)	Tok/s 51990 (52105)	Loss/tok 3.1686 (3.3823)	Learning Rate [0.00125]
15: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00088 (0.00090)	Tok/s 52975 (53138)	Loss/tok 3.1987 (3.3803)	Learning Rate [0.00125]
0: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00093 (0.00101)	Tok/s 51850 (52037)	Loss/tok 3.6078 (3.3762)	Learning Rate [0.00125]
14: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00090 (0.00094)	Tok/s 52833 (53053)	Loss/tok 3.1030 (3.3726)	Learning Rate [0.00125]
9: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00086 (0.00093)	Tok/s 53060 (52596)	Loss/tok 3.3696 (3.3685)	Learning Rate [0.00125]
7: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00097 (0.00097)	Tok/s 53217 (52471)	Loss/tok 3.5198 (3.3673)	Learning Rate [0.00125]
8: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00096 (0.00100)	Tok/s 53125 (52538)	Loss/tok 3.2055 (3.3833)	Learning Rate [0.00125]
11: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00083 (0.00093)	Tok/s 52896 (52761)	Loss/tok 3.4499 (3.3702)	Learning Rate [0.00125]
13: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00094 (0.00101)	Tok/s 52785 (52951)	Loss/tok 3.5380 (3.3609)	Learning Rate [0.00125]
12: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00091 (0.00096)	Tok/s 52759 (52869)	Loss/tok 3.3620 (3.3817)	Learning Rate [0.00125]
10: TRAIN [1][280/3416]	Time 0.053 (0.057)	Data 0.00087 (0.00095)	Tok/s 52853 (52678)	Loss/tok 3.6931 (3.3764)	Learning Rate [0.00125]
10: TRAIN [1][290/3416]	Time 0.066 (0.058)	Data 0.00104 (0.00095)	Tok/s 57056 (52771)	Loss/tok 3.4868 (3.3785)	Learning Rate [0.00125]
9: TRAIN [1][290/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00092)	Tok/s 56842 (52689)	Loss/tok 3.5777 (3.3704)	Learning Rate [0.00125]
11: TRAIN [1][290/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00093)	Tok/s 57036 (52850)	Loss/tok 3.4636 (3.3762)	Learning Rate [0.00125]
8: TRAIN [1][290/3416]	Time 0.066 (0.058)	Data 0.00104 (0.00100)	Tok/s 56902 (52628)	Loss/tok 3.4719 (3.3856)	Learning Rate [0.00125]
12: TRAIN [1][290/3416]	Time 0.066 (0.058)	Data 0.00107 (0.00096)	Tok/s 57026 (52955)	Loss/tok 3.4957 (3.3835)	Learning Rate [0.00125]
6: TRAIN [1][290/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00092)	Tok/s 56649 (52502)	Loss/tok 3.7416 (3.3844)	Learning Rate [0.00125]
14: TRAIN [1][290/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00094)	Tok/s 56991 (53140)	Loss/tok 3.4849 (3.3763)	Learning Rate [0.00125]
5: TRAIN [1][290/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00092)	Tok/s 56606 (52457)	Loss/tok 3.5689 (3.3913)	Learning Rate [0.00125]
15: TRAIN [1][290/3416]	Time 0.066 (0.058)	Data 0.00108 (0.00090)	Tok/s 56909 (53222)	Loss/tok 3.6253 (3.3840)	Learning Rate [0.00125]
4: TRAIN [1][290/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00098)	Tok/s 56703 (52432)	Loss/tok 3.5894 (3.3948)	Learning Rate [0.00125]
0: TRAIN [1][290/3416]	Time 0.066 (0.058)	Data 0.00105 (0.00101)	Tok/s 55864 (52128)	Loss/tok 3.2843 (3.3780)	Learning Rate [0.00125]
2: TRAIN [1][290/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00098)	Tok/s 55947 (52255)	Loss/tok 3.4143 (3.3828)	Learning Rate [0.00125]
1: TRAIN [1][290/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00097)	Tok/s 55807 (52199)	Loss/tok 3.5512 (3.3839)	Learning Rate [0.00125]
3: TRAIN [1][290/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00094)	Tok/s 56718 (52335)	Loss/tok 3.6623 (3.3823)	Learning Rate [0.00125]
7: TRAIN [1][290/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00097)	Tok/s 56013 (52561)	Loss/tok 4.0286 (3.3715)	Learning Rate [0.00125]
13: TRAIN [1][290/3416]	Time 0.067 (0.058)	Data 0.00107 (0.00101)	Tok/s 56325 (53038)	Loss/tok 3.4814 (3.3633)	Learning Rate [0.00125]
8: TRAIN [1][300/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00101)	Tok/s 37764 (52529)	Loss/tok 3.0338 (3.3877)	Learning Rate [0.00125]
9: TRAIN [1][300/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00092)	Tok/s 37746 (52589)	Loss/tok 3.3361 (3.3705)	Learning Rate [0.00125]
6: TRAIN [1][300/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00092)	Tok/s 37582 (52406)	Loss/tok 3.3655 (3.3842)	Learning Rate [0.00125]
7: TRAIN [1][300/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00097)	Tok/s 37655 (52466)	Loss/tok 3.1315 (3.3699)	Learning Rate [0.00125]
11: TRAIN [1][300/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00093)	Tok/s 37656 (52747)	Loss/tok 3.1708 (3.3747)	Learning Rate [0.00125]
10: TRAIN [1][300/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00095)	Tok/s 37699 (52668)	Loss/tok 3.3632 (3.3799)	Learning Rate [0.00125]
5: TRAIN [1][300/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00092)	Tok/s 37333 (52362)	Loss/tok 3.2774 (3.3888)	Learning Rate [0.00125]
3: TRAIN [1][300/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00094)	Tok/s 36080 (52240)	Loss/tok 3.1152 (3.3836)	Learning Rate [0.00125]
4: TRAIN [1][300/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00099)	Tok/s 36122 (52338)	Loss/tok 3.2794 (3.3971)	Learning Rate [0.00125]
2: TRAIN [1][300/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00098)	Tok/s 36009 (52159)	Loss/tok 2.9596 (3.3834)	Learning Rate [0.00125]
1: TRAIN [1][300/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00097)	Tok/s 36032 (52101)	Loss/tok 3.0249 (3.3833)	Learning Rate [0.00125]
14: TRAIN [1][300/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00094)	Tok/s 37374 (53040)	Loss/tok 3.0619 (3.3753)	Learning Rate [0.00125]
13: TRAIN [1][300/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00101)	Tok/s 37429 (52940)	Loss/tok 3.1417 (3.3648)	Learning Rate [0.00125]
15: TRAIN [1][300/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00090)	Tok/s 37282 (53122)	Loss/tok 3.2094 (3.3839)	Learning Rate [0.00125]
0: TRAIN [1][300/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00101)	Tok/s 36019 (52027)	Loss/tok 3.1878 (3.3765)	Learning Rate [0.00125]
12: TRAIN [1][300/3416]	Time 0.052 (0.058)	Data 0.00109 (0.00096)	Tok/s 37266 (52850)	Loss/tok 3.2462 (3.3814)	Learning Rate [0.00125]
2: TRAIN [1][310/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00098)	Tok/s 51962 (52128)	Loss/tok 3.3276 (3.3853)	Learning Rate [0.00125]
0: TRAIN [1][310/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00101)	Tok/s 52022 (51995)	Loss/tok 3.4539 (3.3792)	Learning Rate [0.00125]
3: TRAIN [1][310/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00095)	Tok/s 51918 (52206)	Loss/tok 3.4568 (3.3874)	Learning Rate [0.00125]
15: TRAIN [1][310/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00091)	Tok/s 53167 (53089)	Loss/tok 3.2705 (3.3848)	Learning Rate [0.00125]
4: TRAIN [1][310/3416]	Time 0.055 (0.058)	Data 0.00116 (0.00099)	Tok/s 51968 (52301)	Loss/tok 3.3716 (3.3978)	Learning Rate [0.00125]
14: TRAIN [1][310/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00094)	Tok/s 53129 (53008)	Loss/tok 3.3863 (3.3770)	Learning Rate [0.00125]
5: TRAIN [1][310/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00092)	Tok/s 51915 (52324)	Loss/tok 3.1108 (3.3888)	Learning Rate [0.00125]
6: TRAIN [1][310/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00092)	Tok/s 52403 (52370)	Loss/tok 3.2519 (3.3840)	Learning Rate [0.00125]
1: TRAIN [1][310/3416]	Time 0.056 (0.058)	Data 0.00106 (0.00097)	Tok/s 51768 (52069)	Loss/tok 3.6267 (3.3878)	Learning Rate [0.00125]
13: TRAIN [1][310/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00101)	Tok/s 53038 (52910)	Loss/tok 3.2379 (3.3664)	Learning Rate [0.00125]
12: TRAIN [1][310/3416]	Time 0.056 (0.058)	Data 0.00101 (0.00096)	Tok/s 53021 (52824)	Loss/tok 3.2757 (3.3814)	Learning Rate [0.00125]
9: TRAIN [1][310/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00093)	Tok/s 53068 (52555)	Loss/tok 3.5525 (3.3744)	Learning Rate [0.00125]
7: TRAIN [1][310/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00097)	Tok/s 53070 (52433)	Loss/tok 3.4240 (3.3726)	Learning Rate [0.00125]
8: TRAIN [1][310/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00101)	Tok/s 53217 (52496)	Loss/tok 3.5268 (3.3892)	Learning Rate [0.00125]
10: TRAIN [1][310/3416]	Time 0.055 (0.058)	Data 0.00118 (0.00095)	Tok/s 53065 (52633)	Loss/tok 3.1093 (3.3842)	Learning Rate [0.00125]
11: TRAIN [1][310/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00093)	Tok/s 53202 (52713)	Loss/tok 3.4865 (3.3761)	Learning Rate [0.00125]
6: TRAIN [1][320/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00092)	Tok/s 32264 (52297)	Loss/tok 2.9635 (3.3826)	Learning Rate [0.00125]
5: TRAIN [1][320/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00092)	Tok/s 32335 (52253)	Loss/tok 2.8571 (3.3878)	Learning Rate [0.00125]
7: TRAIN [1][320/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00097)	Tok/s 32257 (52358)	Loss/tok 2.9622 (3.3725)	Learning Rate [0.00125]
4: TRAIN [1][320/3416]	Time 0.048 (0.058)	Data 0.00106 (0.00099)	Tok/s 32318 (52230)	Loss/tok 3.1505 (3.3984)	Learning Rate [0.00125]
3: TRAIN [1][320/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00094)	Tok/s 32356 (52136)	Loss/tok 2.9953 (3.3888)	Learning Rate [0.00125]
9: TRAIN [1][320/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00093)	Tok/s 32226 (52478)	Loss/tok 3.0450 (3.3730)	Learning Rate [0.00125]
2: TRAIN [1][320/3416]	Time 0.048 (0.058)	Data 0.00106 (0.00098)	Tok/s 32327 (52060)	Loss/tok 3.0151 (3.3815)	Learning Rate [0.00125]
1: TRAIN [1][320/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00097)	Tok/s 32363 (52003)	Loss/tok 2.8639 (3.3888)	Learning Rate [0.00125]
15: TRAIN [1][320/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00091)	Tok/s 33693 (53022)	Loss/tok 3.3337 (3.3871)	Learning Rate [0.00125]
0: TRAIN [1][320/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00101)	Tok/s 32345 (51929)	Loss/tok 2.8137 (3.3793)	Learning Rate [0.00125]
10: TRAIN [1][320/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00095)	Tok/s 33160 (52561)	Loss/tok 2.7943 (3.3820)	Learning Rate [0.00125]
14: TRAIN [1][320/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00094)	Tok/s 33675 (52942)	Loss/tok 3.1685 (3.3782)	Learning Rate [0.00125]
13: TRAIN [1][320/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00101)	Tok/s 33573 (52842)	Loss/tok 2.8205 (3.3653)	Learning Rate [0.00125]
12: TRAIN [1][320/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00096)	Tok/s 33508 (52757)	Loss/tok 2.9908 (3.3825)	Learning Rate [0.00125]
11: TRAIN [1][320/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00093)	Tok/s 33695 (52642)	Loss/tok 3.0432 (3.3738)	Learning Rate [0.00125]
8: TRAIN [1][320/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00101)	Tok/s 31745 (52418)	Loss/tok 2.9745 (3.3898)	Learning Rate [0.00125]
8: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00101)	Tok/s 81441 (52830)	Loss/tok 3.3227 (3.3914)	Learning Rate [0.00125]
0: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00101)	Tok/s 79565 (52340)	Loss/tok 3.4327 (3.3831)	Learning Rate [0.00125]
7: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 80669 (52766)	Loss/tok 3.2508 (3.3764)	Learning Rate [0.00125]
10: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00096)	Tok/s 81396 (52969)	Loss/tok 3.4126 (3.3846)	Learning Rate [0.00125]
1: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00098)	Tok/s 80401 (52416)	Loss/tok 3.4894 (3.3910)	Learning Rate [0.00125]
12: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 81242 (53164)	Loss/tok 3.2256 (3.3835)	Learning Rate [0.00125]
6: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 80624 (52707)	Loss/tok 3.5271 (3.3842)	Learning Rate [0.00125]
15: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00091)	Tok/s 82105 (53431)	Loss/tok 3.0918 (3.3871)	Learning Rate [0.00125]
9: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00093)	Tok/s 81482 (52885)	Loss/tok 3.4914 (3.3744)	Learning Rate [0.00125]
14: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00094)	Tok/s 81660 (53348)	Loss/tok 3.3801 (3.3785)	Learning Rate [0.00125]
13: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00101)	Tok/s 81104 (53249)	Loss/tok 3.2517 (3.3663)	Learning Rate [0.00125]
5: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00092)	Tok/s 80606 (52663)	Loss/tok 3.4168 (3.3913)	Learning Rate [0.00125]
2: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00099)	Tok/s 80395 (52471)	Loss/tok 3.3599 (3.3836)	Learning Rate [0.00125]
3: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00095)	Tok/s 80415 (52546)	Loss/tok 3.3053 (3.3883)	Learning Rate [0.00125]
11: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00093)	Tok/s 81610 (53051)	Loss/tok 3.3050 (3.3782)	Learning Rate [0.00125]
4: TRAIN [1][330/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00099)	Tok/s 80504 (52638)	Loss/tok 3.3406 (3.4020)	Learning Rate [0.00125]
10: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00096)	Tok/s 75845 (53375)	Loss/tok 3.4139 (3.3799)	Learning Rate [0.00125]
9: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00093)	Tok/s 75898 (53288)	Loss/tok 3.4426 (3.3713)	Learning Rate [0.00125]
8: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00101)	Tok/s 75643 (53232)	Loss/tok 3.2304 (3.3896)	Learning Rate [0.00125]
6: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00093)	Tok/s 75733 (53110)	Loss/tok 3.4814 (3.3816)	Learning Rate [0.00125]
7: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00100 (0.00097)	Tok/s 75775 (53169)	Loss/tok 3.4159 (3.3727)	Learning Rate [0.00125]
13: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00101)	Tok/s 76949 (53661)	Loss/tok 3.4253 (3.3639)	Learning Rate [0.00125]
5: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00092)	Tok/s 75870 (53066)	Loss/tok 3.2604 (3.3886)	Learning Rate [0.00125]
14: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00103 (0.00094)	Tok/s 76886 (53760)	Loss/tok 3.3425 (3.3771)	Learning Rate [0.00125]
4: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00100 (0.00099)	Tok/s 75846 (53039)	Loss/tok 3.4753 (3.4016)	Learning Rate [0.00125]
15: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00108 (0.00091)	Tok/s 76892 (53849)	Loss/tok 3.2501 (3.3844)	Learning Rate [0.00125]
1: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00102 (0.00098)	Tok/s 74971 (52806)	Loss/tok 3.3093 (3.3917)	Learning Rate [0.00125]
3: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00095)	Tok/s 75751 (52945)	Loss/tok 3.3563 (3.3867)	Learning Rate [0.00125]
0: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00099 (0.00101)	Tok/s 75009 (52732)	Loss/tok 3.5996 (3.3843)	Learning Rate [0.00125]
11: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00100 (0.00093)	Tok/s 76926 (53458)	Loss/tok 3.5146 (3.3769)	Learning Rate [0.00125]
2: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00099)	Tok/s 74957 (52864)	Loss/tok 3.3166 (3.3839)	Learning Rate [0.00125]
12: TRAIN [1][340/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00096)	Tok/s 76686 (53574)	Loss/tok 3.3396 (3.3807)	Learning Rate [0.00125]
6: TRAIN [1][350/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 68283 (53178)	Loss/tok 3.3039 (3.3819)	Learning Rate [0.00125]
10: TRAIN [1][350/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00096)	Tok/s 68595 (53438)	Loss/tok 3.3954 (3.3815)	Learning Rate [0.00125]
9: TRAIN [1][350/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 68435 (53351)	Loss/tok 3.3411 (3.3695)	Learning Rate [0.00125]
8: TRAIN [1][350/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00101)	Tok/s 68341 (53296)	Loss/tok 3.5810 (3.3918)	Learning Rate [0.00125]
12: TRAIN [1][350/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 68531 (53637)	Loss/tok 3.4777 (3.3823)	Learning Rate [0.00125]
5: TRAIN [1][350/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 67283 (53129)	Loss/tok 3.5762 (3.3898)	Learning Rate [0.00125]
13: TRAIN [1][350/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00101)	Tok/s 68441 (53723)	Loss/tok 3.5827 (3.3671)	Learning Rate [0.00125]
4: TRAIN [1][350/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00100)	Tok/s 67128 (53103)	Loss/tok 3.5043 (3.4030)	Learning Rate [0.00125]
14: TRAIN [1][350/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00094)	Tok/s 68378 (53823)	Loss/tok 3.4818 (3.3813)	Learning Rate [0.00125]
3: TRAIN [1][350/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00095)	Tok/s 67144 (53012)	Loss/tok 3.3894 (3.3867)	Learning Rate [0.00125]
15: TRAIN [1][350/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 68234 (53915)	Loss/tok 3.5535 (3.3856)	Learning Rate [0.00125]
2: TRAIN [1][350/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00099)	Tok/s 67119 (52934)	Loss/tok 3.4597 (3.3870)	Learning Rate [0.00125]
7: TRAIN [1][350/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 68288 (53235)	Loss/tok 3.6073 (3.3728)	Learning Rate [0.00125]
1: TRAIN [1][350/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 67131 (52876)	Loss/tok 3.6168 (3.3923)	Learning Rate [0.00125]
0: TRAIN [1][350/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00101)	Tok/s 67198 (52801)	Loss/tok 3.4720 (3.3867)	Learning Rate [0.00125]
11: TRAIN [1][350/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00094)	Tok/s 68776 (53523)	Loss/tok 3.4863 (3.3777)	Learning Rate [0.00125]
6: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
6: TRAIN [1][360/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00093)	Tok/s 55075 (53093)	Loss/tok 3.2327 (3.3805)	Learning Rate [0.00125]
9: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
5: TRAIN [1][360/3416]	Time 0.059 (0.058)	Data 0.00080 (0.00092)	Tok/s 55159 (53042)	Loss/tok 3.2904 (3.3891)	Learning Rate [0.00125]
8: TRAIN [1][360/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00101)	Tok/s 55533 (53215)	Loss/tok 3.4239 (3.3913)	Learning Rate [0.00125]
1: Upscaling, new scale: 2048.0
4: TRAIN [1][360/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00100)	Tok/s 55038 (53011)	Loss/tok 3.3756 (3.4034)	Learning Rate [0.00125]
7: TRAIN [1][360/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00097)	Tok/s 55086 (53151)	Loss/tok 3.5168 (3.3710)	Learning Rate [0.00125]
10: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
9: TRAIN [1][360/3416]	Time 0.059 (0.058)	Data 0.00078 (0.00093)	Tok/s 55936 (53269)	Loss/tok 3.3522 (3.3692)	Learning Rate [0.00125]
3: TRAIN [1][360/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00094)	Tok/s 54976 (52914)	Loss/tok 3.2498 (3.3867)	Learning Rate [0.00125]
2: TRAIN [1][360/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00099)	Tok/s 54907 (52833)	Loss/tok 3.5031 (3.3878)	Learning Rate [0.00125]
15: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
1: TRAIN [1][360/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00098)	Tok/s 54724 (52768)	Loss/tok 3.3585 (3.3895)	Learning Rate [0.00125]
10: TRAIN [1][360/3416]	Time 0.060 (0.058)	Data 0.00100 (0.00096)	Tok/s 55747 (53355)	Loss/tok 3.4154 (3.3799)	Learning Rate [0.00125]
13: Upscaling, new scale: 2048.0
11: TRAIN [1][360/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00094)	Tok/s 55686 (53442)	Loss/tok 3.4322 (3.3779)	Learning Rate [0.00125]
0: TRAIN [1][360/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00101)	Tok/s 54731 (52682)	Loss/tok 3.6280 (3.3868)	Learning Rate [0.00125]
15: TRAIN [1][360/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00092)	Tok/s 55662 (53840)	Loss/tok 3.5587 (3.3869)	Learning Rate [0.00125]
14: Upscaling, new scale: 2048.0
12: TRAIN [1][360/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00097)	Tok/s 55571 (53561)	Loss/tok 3.2776 (3.3811)	Learning Rate [0.00125]
13: TRAIN [1][360/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00100)	Tok/s 55485 (53644)	Loss/tok 3.4382 (3.3660)	Learning Rate [0.00125]
14: TRAIN [1][360/3416]	Time 0.060 (0.058)	Data 0.00080 (0.00095)	Tok/s 55451 (53747)	Loss/tok 3.4726 (3.3817)	Learning Rate [0.00125]
6: TRAIN [1][370/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 63113 (53163)	Loss/tok 3.2281 (3.3831)	Learning Rate [0.00125]
7: TRAIN [1][370/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 63084 (53220)	Loss/tok 3.5206 (3.3752)	Learning Rate [0.00125]
5: TRAIN [1][370/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00091)	Tok/s 63160 (53114)	Loss/tok 3.4862 (3.3903)	Learning Rate [0.00125]
8: TRAIN [1][370/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00101)	Tok/s 62957 (53283)	Loss/tok 3.5867 (3.3921)	Learning Rate [0.00125]
4: TRAIN [1][370/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00100)	Tok/s 63116 (53083)	Loss/tok 3.3951 (3.4040)	Learning Rate [0.00125]
9: TRAIN [1][370/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 62861 (53337)	Loss/tok 3.8769 (3.3730)	Learning Rate [0.00125]
3: TRAIN [1][370/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00094)	Tok/s 63085 (52986)	Loss/tok 3.4173 (3.3892)	Learning Rate [0.00125]
2: TRAIN [1][370/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00099)	Tok/s 63010 (52903)	Loss/tok 3.3944 (3.3902)	Learning Rate [0.00125]
11: TRAIN [1][370/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00094)	Tok/s 63592 (53508)	Loss/tok 3.6300 (3.3818)	Learning Rate [0.00125]
10: TRAIN [1][370/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00097)	Tok/s 63132 (53422)	Loss/tok 3.6166 (3.3820)	Learning Rate [0.00125]
1: TRAIN [1][370/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 62856 (52838)	Loss/tok 3.4290 (3.3922)	Learning Rate [0.00125]
0: TRAIN [1][370/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00101)	Tok/s 62809 (52754)	Loss/tok 3.5048 (3.3871)	Learning Rate [0.00125]
15: TRAIN [1][370/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 63629 (53899)	Loss/tok 3.1971 (3.3876)	Learning Rate [0.00125]
12: TRAIN [1][370/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 63494 (53623)	Loss/tok 3.6750 (3.3844)	Learning Rate [0.00125]
14: TRAIN [1][370/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00095)	Tok/s 63527 (53807)	Loss/tok 3.6818 (3.3831)	Learning Rate [0.00125]
13: TRAIN [1][370/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00100)	Tok/s 63458 (53704)	Loss/tok 3.3828 (3.3685)	Learning Rate [0.00125]
0: TRAIN [1][380/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00101)	Tok/s 73751 (52874)	Loss/tok 3.3030 (3.3893)	Learning Rate [0.00125]
7: TRAIN [1][380/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 74428 (53339)	Loss/tok 3.3711 (3.3752)	Learning Rate [0.00125]
1: TRAIN [1][380/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 73751 (52958)	Loss/tok 3.5620 (3.3941)	Learning Rate [0.00125]
6: TRAIN [1][380/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 73767 (53282)	Loss/tok 3.4331 (3.3863)	Learning Rate [0.00125]
15: TRAIN [1][380/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 74566 (54020)	Loss/tok 3.7154 (3.3893)	Learning Rate [0.00125]
8: TRAIN [1][380/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00101)	Tok/s 74526 (53400)	Loss/tok 3.5021 (3.3942)	Learning Rate [0.00125]
14: TRAIN [1][380/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00094)	Tok/s 74461 (53923)	Loss/tok 3.5515 (3.3843)	Learning Rate [0.00125]
2: TRAIN [1][380/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00099)	Tok/s 73760 (53022)	Loss/tok 3.2898 (3.3901)	Learning Rate [0.00125]
5: TRAIN [1][380/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 73746 (53230)	Loss/tok 3.3081 (3.3898)	Learning Rate [0.00125]
9: TRAIN [1][380/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 74424 (53453)	Loss/tok 3.4534 (3.3744)	Learning Rate [0.00125]
4: TRAIN [1][380/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 73716 (53201)	Loss/tok 3.5355 (3.4051)	Learning Rate [0.00125]
13: TRAIN [1][380/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 74324 (53817)	Loss/tok 3.3108 (3.3691)	Learning Rate [0.00125]
3: TRAIN [1][380/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00094)	Tok/s 73730 (53106)	Loss/tok 3.5412 (3.3899)	Learning Rate [0.00125]
11: TRAIN [1][380/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00094)	Tok/s 74251 (53623)	Loss/tok 3.5527 (3.3850)	Learning Rate [0.00125]
10: TRAIN [1][380/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 74311 (53536)	Loss/tok 3.4171 (3.3836)	Learning Rate [0.00125]
12: TRAIN [1][380/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 74142 (53737)	Loss/tok 3.3606 (3.3832)	Learning Rate [0.00125]
9: TRAIN [1][390/3416]	Time 0.064 (0.058)	Data 0.00097 (0.00093)	Tok/s 53628 (53458)	Loss/tok 3.3412 (3.3735)	Learning Rate [0.00125]
8: TRAIN [1][390/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00101)	Tok/s 53702 (53402)	Loss/tok 3.4872 (3.3955)	Learning Rate [0.00125]
10: TRAIN [1][390/3416]	Time 0.064 (0.058)	Data 0.00103 (0.00097)	Tok/s 53601 (53538)	Loss/tok 3.5930 (3.3840)	Learning Rate [0.00125]
7: TRAIN [1][390/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00097)	Tok/s 53650 (53339)	Loss/tok 3.3155 (3.3776)	Learning Rate [0.00125]
11: TRAIN [1][390/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00094)	Tok/s 53482 (53624)	Loss/tok 3.7714 (3.3872)	Learning Rate [0.00125]
6: TRAIN [1][390/3416]	Time 0.064 (0.058)	Data 0.00101 (0.00093)	Tok/s 53657 (53283)	Loss/tok 3.5114 (3.3878)	Learning Rate [0.00125]
12: TRAIN [1][390/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00097)	Tok/s 53415 (53737)	Loss/tok 3.4749 (3.3837)	Learning Rate [0.00125]
5: TRAIN [1][390/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00091)	Tok/s 53596 (53233)	Loss/tok 3.6233 (3.3900)	Learning Rate [0.00125]
13: TRAIN [1][390/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00100)	Tok/s 53296 (53818)	Loss/tok 3.6422 (3.3706)	Learning Rate [0.00125]
4: TRAIN [1][390/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00100)	Tok/s 53526 (53204)	Loss/tok 3.5865 (3.4060)	Learning Rate [0.00125]
3: TRAIN [1][390/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00094)	Tok/s 53476 (53108)	Loss/tok 3.3713 (3.3903)	Learning Rate [0.00125]
14: TRAIN [1][390/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00094)	Tok/s 53284 (53923)	Loss/tok 3.4480 (3.3834)	Learning Rate [0.00125]
15: TRAIN [1][390/3416]	Time 0.065 (0.058)	Data 0.00114 (0.00092)	Tok/s 53287 (54018)	Loss/tok 3.4223 (3.3920)	Learning Rate [0.00125]
2: TRAIN [1][390/3416]	Time 0.065 (0.058)	Data 0.00099 (0.00099)	Tok/s 53419 (53024)	Loss/tok 3.2914 (3.3883)	Learning Rate [0.00125]
0: TRAIN [1][390/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00101)	Tok/s 53318 (52879)	Loss/tok 3.5308 (3.3895)	Learning Rate [0.00125]
1: TRAIN [1][390/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00099)	Tok/s 53357 (52962)	Loss/tok 3.6127 (3.3960)	Learning Rate [0.00125]
2: TRAIN [1][400/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 65464 (53189)	Loss/tok 3.5349 (3.3896)	Learning Rate [0.00125]
4: TRAIN [1][400/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00100)	Tok/s 65360 (53368)	Loss/tok 3.5143 (3.4050)	Learning Rate [0.00125]
3: TRAIN [1][400/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00094)	Tok/s 65407 (53272)	Loss/tok 3.4948 (3.3926)	Learning Rate [0.00125]
1: TRAIN [1][400/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00099)	Tok/s 65444 (53129)	Loss/tok 3.3810 (3.3969)	Learning Rate [0.00125]
6: TRAIN [1][400/3416]	Time 0.070 (0.058)	Data 0.00075 (0.00093)	Tok/s 65140 (53446)	Loss/tok 3.2309 (3.3889)	Learning Rate [0.00125]
0: TRAIN [1][400/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00101)	Tok/s 65440 (53048)	Loss/tok 3.5357 (3.3898)	Learning Rate [0.00125]
5: TRAIN [1][400/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00091)	Tok/s 65181 (53397)	Loss/tok 3.4501 (3.3927)	Learning Rate [0.00125]
15: TRAIN [1][400/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 66282 (54183)	Loss/tok 3.4100 (3.3946)	Learning Rate [0.00125]
7: TRAIN [1][400/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 65000 (53505)	Loss/tok 3.6132 (3.3817)	Learning Rate [0.00125]
8: TRAIN [1][400/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00101)	Tok/s 65011 (53568)	Loss/tok 3.4972 (3.4006)	Learning Rate [0.00125]
9: TRAIN [1][400/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 65562 (53624)	Loss/tok 3.5468 (3.3742)	Learning Rate [0.00125]
13: TRAIN [1][400/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00100)	Tok/s 66173 (53983)	Loss/tok 3.7248 (3.3741)	Learning Rate [0.00125]
11: TRAIN [1][400/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00094)	Tok/s 65954 (53791)	Loss/tok 3.7710 (3.3879)	Learning Rate [0.00125]
12: TRAIN [1][400/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 66069 (53902)	Loss/tok 3.6646 (3.3850)	Learning Rate [0.00125]
10: TRAIN [1][400/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 65890 (53704)	Loss/tok 3.5339 (3.3840)	Learning Rate [0.00125]
14: TRAIN [1][400/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00094)	Tok/s 65128 (54083)	Loss/tok 3.6723 (3.3857)	Learning Rate [0.00125]
1: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00099)	Tok/s 53343 (52962)	Loss/tok 3.2760 (3.3955)	Learning Rate [0.00125]
4: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00100)	Tok/s 53640 (53224)	Loss/tok 3.3491 (3.4035)	Learning Rate [0.00125]
11: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00082 (0.00094)	Tok/s 54073 (53672)	Loss/tok 3.4296 (3.3858)	Learning Rate [0.00125]
12: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00097)	Tok/s 54133 (53784)	Loss/tok 3.1371 (3.3820)	Learning Rate [0.00125]
0: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00101)	Tok/s 53227 (52871)	Loss/tok 3.0317 (3.3888)	Learning Rate [0.00125]
13: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00100)	Tok/s 54150 (53866)	Loss/tok 3.1119 (3.3719)	Learning Rate [0.00125]
15: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00104 (0.00092)	Tok/s 54239 (54073)	Loss/tok 3.6303 (3.3934)	Learning Rate [0.00125]
5: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00091)	Tok/s 54304 (53268)	Loss/tok 3.5419 (3.3918)	Learning Rate [0.00125]
2: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00099)	Tok/s 53389 (53036)	Loss/tok 3.2093 (3.3880)	Learning Rate [0.00125]
10: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00097)	Tok/s 54041 (53588)	Loss/tok 3.3403 (3.3816)	Learning Rate [0.00125]
6: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00093)	Tok/s 54170 (53320)	Loss/tok 3.5036 (3.3881)	Learning Rate [0.00125]
14: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00083 (0.00094)	Tok/s 54173 (53970)	Loss/tok 3.5812 (3.3836)	Learning Rate [0.00125]
9: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00093)	Tok/s 54028 (53506)	Loss/tok 3.7505 (3.3747)	Learning Rate [0.00125]
8: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00101)	Tok/s 54062 (53449)	Loss/tok 3.5290 (3.3987)	Learning Rate [0.00125]
7: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00104 (0.00097)	Tok/s 54088 (53382)	Loss/tok 3.3765 (3.3802)	Learning Rate [0.00125]
3: TRAIN [1][410/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00094)	Tok/s 53591 (53122)	Loss/tok 3.3017 (3.3900)	Learning Rate [0.00125]
4: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00085 (0.00099)	Tok/s 29576 (53082)	Loss/tok 2.9326 (3.4045)	Learning Rate [0.00125]
2: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00099)	Tok/s 29607 (52894)	Loss/tok 2.6734 (3.3871)	Learning Rate [0.00125]
5: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00091)	Tok/s 30776 (53129)	Loss/tok 2.7703 (3.3914)	Learning Rate [0.00125]
1: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00099)	Tok/s 29597 (52820)	Loss/tok 2.9521 (3.3944)	Learning Rate [0.00125]
7: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00101 (0.00097)	Tok/s 30926 (53240)	Loss/tok 2.7943 (3.3792)	Learning Rate [0.00125]
8: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00100 (0.00100)	Tok/s 30924 (53306)	Loss/tok 2.6861 (3.3969)	Learning Rate [0.00125]
0: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00101)	Tok/s 29580 (52730)	Loss/tok 3.0132 (3.3883)	Learning Rate [0.00125]
9: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00090 (0.00093)	Tok/s 30924 (53361)	Loss/tok 2.7172 (3.3753)	Learning Rate [0.00125]
15: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00092)	Tok/s 31165 (53927)	Loss/tok 2.8709 (3.3934)	Learning Rate [0.00125]
11: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00084 (0.00093)	Tok/s 31020 (53526)	Loss/tok 2.7040 (3.3845)	Learning Rate [0.00125]
12: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00085 (0.00097)	Tok/s 31057 (53637)	Loss/tok 2.6895 (3.3799)	Learning Rate [0.00125]
3: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00085 (0.00094)	Tok/s 29732 (52980)	Loss/tok 2.7461 (3.3892)	Learning Rate [0.00125]
10: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00088 (0.00097)	Tok/s 30934 (53442)	Loss/tok 2.6982 (3.3815)	Learning Rate [0.00125]
13: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00100)	Tok/s 31039 (53720)	Loss/tok 2.8197 (3.3720)	Learning Rate [0.00125]
14: TRAIN [1][420/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00094)	Tok/s 30985 (53825)	Loss/tok 2.8125 (3.3845)	Learning Rate [0.00125]
6: TRAIN [1][420/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00093)	Tok/s 30419 (53178)	Loss/tok 2.8237 (3.3861)	Learning Rate [0.00125]
11: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00093)	Tok/s 58590 (53537)	Loss/tok 3.4197 (3.3829)	Learning Rate [0.00125]
9: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00093)	Tok/s 57770 (53369)	Loss/tok 3.2768 (3.3748)	Learning Rate [0.00125]
10: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00097)	Tok/s 57774 (53449)	Loss/tok 3.3605 (3.3821)	Learning Rate [0.00125]
8: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00101)	Tok/s 57765 (53316)	Loss/tok 3.4565 (3.3983)	Learning Rate [0.00125]
13: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00100)	Tok/s 58506 (53729)	Loss/tok 3.5327 (3.3733)	Learning Rate [0.00125]
6: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00093)	Tok/s 57775 (53192)	Loss/tok 3.4125 (3.3867)	Learning Rate [0.00125]
14: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00094)	Tok/s 58514 (53832)	Loss/tok 3.5218 (3.3844)	Learning Rate [0.00125]
7: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00097)	Tok/s 57779 (53251)	Loss/tok 3.2533 (3.3795)	Learning Rate [0.00125]
15: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00092)	Tok/s 58456 (53931)	Loss/tok 3.6962 (3.3946)	Learning Rate [0.00125]
12: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00097)	Tok/s 58485 (53648)	Loss/tok 3.3490 (3.3804)	Learning Rate [0.00125]
0: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00101)	Tok/s 57604 (52740)	Loss/tok 3.4374 (3.3872)	Learning Rate [0.00125]
5: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00091)	Tok/s 57827 (53142)	Loss/tok 3.3978 (3.3897)	Learning Rate [0.00125]
1: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00099)	Tok/s 57594 (52831)	Loss/tok 3.5437 (3.3950)	Learning Rate [0.00125]
4: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00100)	Tok/s 57701 (53096)	Loss/tok 3.5165 (3.4036)	Learning Rate [0.00125]
2: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00099)	Tok/s 57560 (52905)	Loss/tok 3.6181 (3.3892)	Learning Rate [0.00125]
3: TRAIN [1][430/3416]	Time 0.068 (0.058)	Data 0.00113 (0.00094)	Tok/s 57718 (52993)	Loss/tok 3.6615 (3.3899)	Learning Rate [0.00125]
15: TRAIN [1][440/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00092)	Tok/s 54011 (53836)	Loss/tok 3.4817 (3.3947)	Learning Rate [0.00125]
0: TRAIN [1][440/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00101)	Tok/s 53041 (52609)	Loss/tok 3.4663 (3.3871)	Learning Rate [0.00125]
1: TRAIN [1][440/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00099)	Tok/s 53071 (52705)	Loss/tok 3.6339 (3.3944)	Learning Rate [0.00125]
13: TRAIN [1][440/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00100)	Tok/s 53843 (53631)	Loss/tok 3.3960 (3.3730)	Learning Rate [0.00125]
2: TRAIN [1][440/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00099)	Tok/s 53071 (52785)	Loss/tok 3.4123 (3.3891)	Learning Rate [0.00125]
12: TRAIN [1][440/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00096)	Tok/s 53768 (53549)	Loss/tok 3.3241 (3.3790)	Learning Rate [0.00125]
4: TRAIN [1][440/3416]	Time 0.066 (0.058)	Data 0.00116 (0.00100)	Tok/s 53048 (52983)	Loss/tok 3.3437 (3.4031)	Learning Rate [0.00125]
3: TRAIN [1][440/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00094)	Tok/s 53051 (52876)	Loss/tok 3.4394 (3.3901)	Learning Rate [0.00125]
10: TRAIN [1][440/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00097)	Tok/s 53741 (53343)	Loss/tok 3.5148 (3.3835)	Learning Rate [0.00125]
8: TRAIN [1][440/3416]	Time 0.067 (0.058)	Data 0.00104 (0.00101)	Tok/s 53791 (53213)	Loss/tok 3.3738 (3.3982)	Learning Rate [0.00125]
7: TRAIN [1][440/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00097)	Tok/s 53647 (53147)	Loss/tok 3.7755 (3.3806)	Learning Rate [0.00125]
6: TRAIN [1][440/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00092)	Tok/s 52835 (53085)	Loss/tok 3.3788 (3.3865)	Learning Rate [0.00125]
14: TRAIN [1][440/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00094)	Tok/s 53930 (53734)	Loss/tok 3.4291 (3.3854)	Learning Rate [0.00125]
11: TRAIN [1][440/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00093)	Tok/s 53736 (53430)	Loss/tok 3.4334 (3.3813)	Learning Rate [0.00125]
5: TRAIN [1][440/3416]	Time 0.067 (0.058)	Data 0.00115 (0.00092)	Tok/s 52931 (53031)	Loss/tok 3.6959 (3.3903)	Learning Rate [0.00125]
9: TRAIN [1][440/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00093)	Tok/s 52836 (53263)	Loss/tok 3.4672 (3.3750)	Learning Rate [0.00125]
11: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00093)	Tok/s 39991 (53441)	Loss/tok 3.1740 (3.3801)	Learning Rate [0.00125]
10: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00097)	Tok/s 40001 (53351)	Loss/tok 3.1467 (3.3839)	Learning Rate [0.00125]
9: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00093)	Tok/s 39751 (53274)	Loss/tok 3.1591 (3.3755)	Learning Rate [0.00125]
8: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00101)	Tok/s 38525 (53218)	Loss/tok 3.3313 (3.3992)	Learning Rate [0.00125]
12: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00096)	Tok/s 39850 (53557)	Loss/tok 3.0234 (3.3794)	Learning Rate [0.00125]
6: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00092)	Tok/s 38384 (53094)	Loss/tok 3.3724 (3.3896)	Learning Rate [0.00125]
7: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00097)	Tok/s 38495 (53155)	Loss/tok 3.1395 (3.3823)	Learning Rate [0.00125]
13: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00100)	Tok/s 39785 (53636)	Loss/tok 3.0563 (3.3734)	Learning Rate [0.00125]
5: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 38280 (53040)	Loss/tok 3.4167 (3.3925)	Learning Rate [0.00125]
15: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00092)	Tok/s 39609 (53839)	Loss/tok 3.3740 (3.3972)	Learning Rate [0.00125]
0: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00101)	Tok/s 38234 (52621)	Loss/tok 3.1363 (3.3866)	Learning Rate [0.00125]
3: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00094)	Tok/s 38098 (52884)	Loss/tok 3.2818 (3.3932)	Learning Rate [0.00125]
4: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00100)	Tok/s 38108 (52991)	Loss/tok 3.1826 (3.4042)	Learning Rate [0.00125]
1: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00099)	Tok/s 38135 (52716)	Loss/tok 3.0812 (3.3961)	Learning Rate [0.00125]
2: TRAIN [1][450/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00099)	Tok/s 38016 (52795)	Loss/tok 2.9991 (3.3894)	Learning Rate [0.00125]
14: TRAIN [1][450/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00094)	Tok/s 39662 (53739)	Loss/tok 3.0416 (3.3860)	Learning Rate [0.00125]
13: Gradient norm: inf
12: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
15: Gradient norm: inf
14: Gradient norm: inf
10: Gradient norm: inf
0: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
6: Gradient norm: inf
7: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
5: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
13: TRAIN [1][460/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 67459 (53767)	Loss/tok 3.4785 (3.3745)	Learning Rate [0.00125]
11: TRAIN [1][460/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 67248 (53571)	Loss/tok 3.4155 (3.3805)	Learning Rate [0.00125]
15: TRAIN [1][460/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00092)	Tok/s 67516 (53971)	Loss/tok 3.4812 (3.3971)	Learning Rate [0.00125]
0: TRAIN [1][460/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00101)	Tok/s 66584 (52754)	Loss/tok 3.4453 (3.3881)	Learning Rate [0.00125]
12: TRAIN [1][460/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 67362 (53688)	Loss/tok 3.4710 (3.3786)	Learning Rate [0.00125]
10: TRAIN [1][460/3416]	Time 0.069 (0.058)	Data 0.00228 (0.00097)	Tok/s 67225 (53481)	Loss/tok 3.6825 (3.3841)	Learning Rate [0.00125]
14: TRAIN [1][460/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00094)	Tok/s 67457 (53869)	Loss/tok 3.5054 (3.3875)	Learning Rate [0.00125]
9: TRAIN [1][460/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00093)	Tok/s 67067 (53405)	Loss/tok 3.5680 (3.3774)	Learning Rate [0.00125]
1: TRAIN [1][460/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00099)	Tok/s 69070 (52848)	Loss/tok 3.5028 (3.3987)	Learning Rate [0.00125]
8: TRAIN [1][460/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00101)	Tok/s 67064 (53350)	Loss/tok 3.4032 (3.3988)	Learning Rate [0.00125]
2: TRAIN [1][460/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00099)	Tok/s 66446 (52928)	Loss/tok 3.3383 (3.3901)	Learning Rate [0.00125]
4: TRAIN [1][460/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00100)	Tok/s 66246 (53122)	Loss/tok 3.5721 (3.4021)	Learning Rate [0.00125]
7: TRAIN [1][460/3416]	Time 0.070 (0.058)	Data 0.00113 (0.00097)	Tok/s 66637 (53286)	Loss/tok 3.4401 (3.3837)	Learning Rate [0.00125]
6: TRAIN [1][460/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 66090 (53223)	Loss/tok 3.6074 (3.3912)	Learning Rate [0.00125]
3: TRAIN [1][460/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00094)	Tok/s 66329 (53016)	Loss/tok 3.5090 (3.3955)	Learning Rate [0.00125]
5: TRAIN [1][460/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 66223 (53171)	Loss/tok 3.5751 (3.3942)	Learning Rate [0.00125]
14: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00094)	Tok/s 56214 (53898)	Loss/tok 3.3712 (3.3887)	Learning Rate [0.00125]
13: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00097 (0.00100)	Tok/s 56260 (53798)	Loss/tok 3.5348 (3.3771)	Learning Rate [0.00125]
15: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00100 (0.00092)	Tok/s 56118 (53997)	Loss/tok 3.5232 (3.3986)	Learning Rate [0.00125]
11: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00093)	Tok/s 56305 (53604)	Loss/tok 3.3092 (3.3824)	Learning Rate [0.00125]
1: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00099)	Tok/s 55059 (52886)	Loss/tok 3.6337 (3.3995)	Learning Rate [0.00125]
12: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00096)	Tok/s 56173 (53720)	Loss/tok 3.5475 (3.3797)	Learning Rate [0.00125]
2: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00099)	Tok/s 55938 (52966)	Loss/tok 3.7774 (3.3919)	Learning Rate [0.00125]
0: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00101)	Tok/s 54917 (52791)	Loss/tok 3.2603 (3.3893)	Learning Rate [0.00125]
10: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00097)	Tok/s 56205 (53516)	Loss/tok 3.2764 (3.3837)	Learning Rate [0.00125]
9: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00093)	Tok/s 56213 (53442)	Loss/tok 3.2366 (3.3777)	Learning Rate [0.00125]
3: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00093)	Tok/s 55941 (53054)	Loss/tok 3.6899 (3.3981)	Learning Rate [0.00125]
4: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00100)	Tok/s 55972 (53160)	Loss/tok 3.6463 (3.4046)	Learning Rate [0.00125]
8: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00103 (0.00101)	Tok/s 56144 (53387)	Loss/tok 3.4311 (3.3992)	Learning Rate [0.00125]
5: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00092)	Tok/s 55975 (53209)	Loss/tok 3.4236 (3.3967)	Learning Rate [0.00125]
6: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00092)	Tok/s 55959 (53262)	Loss/tok 3.1936 (3.3896)	Learning Rate [0.00125]
7: TRAIN [1][470/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00097)	Tok/s 56100 (53325)	Loss/tok 3.7085 (3.3845)	Learning Rate [0.00125]
13: Gradient norm: inf
12: Gradient norm: inf
13: Skipped batch, new scale: 512.0
14: Gradient norm: inf
12: Skipped batch, new scale: 512.0
11: Gradient norm: inf
15: Gradient norm: inf
14: Skipped batch, new scale: 512.0
11: Skipped batch, new scale: 512.0
10: Gradient norm: inf
15: Skipped batch, new scale: 512.0
0: Gradient norm: inf
9: Gradient norm: inf
10: Skipped batch, new scale: 512.0
0: Skipped batch, new scale: 512.0
1: Gradient norm: inf
9: Skipped batch, new scale: 512.0
8: Gradient norm: inf
8: Skipped batch, new scale: 512.0
2: Gradient norm: inf
1: Skipped batch, new scale: 512.0
7: Gradient norm: inf
3: Gradient norm: inf
2: Skipped batch, new scale: 512.0
7: Skipped batch, new scale: 512.0
3: Skipped batch, new scale: 512.0
4: Gradient norm: inf
6: Gradient norm: inf
5: Gradient norm: inf
4: Skipped batch, new scale: 512.0
6: Skipped batch, new scale: 512.0
5: Skipped batch, new scale: 512.0
2: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 56807 (53085)	Loss/tok 3.6829 (3.3946)	Learning Rate [0.00125]
3: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 56773 (53174)	Loss/tok 3.5701 (3.3997)	Learning Rate [0.00125]
4: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 56788 (53278)	Loss/tok 3.4262 (3.4037)	Learning Rate [0.00125]
1: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00099)	Tok/s 56797 (53003)	Loss/tok 3.5445 (3.4012)	Learning Rate [0.00125]
5: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 56775 (53326)	Loss/tok 3.6540 (3.3981)	Learning Rate [0.00125]
6: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 56781 (53379)	Loss/tok 3.4147 (3.3902)	Learning Rate [0.00125]
15: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00092)	Tok/s 57713 (54119)	Loss/tok 3.5550 (3.4002)	Learning Rate [0.00125]
0: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00101)	Tok/s 56793 (52909)	Loss/tok 3.3502 (3.3921)	Learning Rate [0.00125]
7: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00097)	Tok/s 56804 (53443)	Loss/tok 3.4851 (3.3849)	Learning Rate [0.00125]
14: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00094)	Tok/s 57708 (54017)	Loss/tok 3.4721 (3.3907)	Learning Rate [0.00125]
8: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00101)	Tok/s 56802 (53504)	Loss/tok 3.4493 (3.4008)	Learning Rate [0.00125]
9: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 57710 (53561)	Loss/tok 3.5761 (3.3810)	Learning Rate [0.00125]
13: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00100)	Tok/s 57705 (53916)	Loss/tok 3.6014 (3.3806)	Learning Rate [0.00125]
12: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00096)	Tok/s 57726 (53839)	Loss/tok 3.5630 (3.3831)	Learning Rate [0.00125]
11: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 57706 (53724)	Loss/tok 3.7401 (3.3835)	Learning Rate [0.00125]
10: TRAIN [1][480/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 57721 (53636)	Loss/tok 3.5712 (3.3845)	Learning Rate [0.00125]
11: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00093)	Tok/s 30581 (53780)	Loss/tok 2.8214 (3.3854)	Learning Rate [0.00125]
12: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00096)	Tok/s 30590 (53898)	Loss/tok 2.5978 (3.3835)	Learning Rate [0.00125]
13: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00100)	Tok/s 30527 (53975)	Loss/tok 2.6398 (3.3817)	Learning Rate [0.00125]
10: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00103 (0.00097)	Tok/s 30682 (53693)	Loss/tok 2.8089 (3.3842)	Learning Rate [0.00125]
0: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00101)	Tok/s 29050 (52966)	Loss/tok 2.7802 (3.3926)	Learning Rate [0.00125]
14: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00107 (0.00094)	Tok/s 30492 (54077)	Loss/tok 2.8216 (3.3917)	Learning Rate [0.00125]
15: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00103 (0.00092)	Tok/s 30499 (54178)	Loss/tok 2.7619 (3.3998)	Learning Rate [0.00125]
5: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00092)	Tok/s 29094 (53379)	Loss/tok 2.6827 (3.3967)	Learning Rate [0.00125]
3: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00093)	Tok/s 29048 (53228)	Loss/tok 2.8625 (3.3988)	Learning Rate [0.00125]
1: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00099)	Tok/s 29027 (53059)	Loss/tok 2.7430 (3.4021)	Learning Rate [0.00125]
8: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00101)	Tok/s 30630 (53560)	Loss/tok 2.5789 (3.4004)	Learning Rate [0.00125]
6: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00092)	Tok/s 29322 (53431)	Loss/tok 2.6867 (3.3901)	Learning Rate [0.00125]
7: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00113 (0.00097)	Tok/s 30576 (53499)	Loss/tok 2.7380 (3.3849)	Learning Rate [0.00125]
4: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00100)	Tok/s 29048 (53332)	Loss/tok 2.8325 (3.4020)	Learning Rate [0.00125]
2: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00099)	Tok/s 29032 (53139)	Loss/tok 2.6607 (3.3939)	Learning Rate [0.00125]
9: TRAIN [1][490/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00093)	Tok/s 30622 (53616)	Loss/tok 2.6746 (3.3805)	Learning Rate [0.00125]
11: TRAIN [1][500/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00093)	Tok/s 35021 (53787)	Loss/tok 3.0238 (3.3845)	Learning Rate [0.00125]
12: TRAIN [1][500/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00096)	Tok/s 34982 (53903)	Loss/tok 3.0228 (3.3843)	Learning Rate [0.00125]
6: TRAIN [1][500/3416]	Time 0.051 (0.058)	Data 0.00080 (0.00092)	Tok/s 34999 (53438)	Loss/tok 2.9791 (3.3931)	Learning Rate [0.00125]
8: TRAIN [1][500/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00100)	Tok/s 34967 (53568)	Loss/tok 2.9492 (3.4011)	Learning Rate [0.00125]
10: TRAIN [1][500/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00097)	Tok/s 34968 (53699)	Loss/tok 2.9825 (3.3847)	Learning Rate [0.00125]
7: TRAIN [1][500/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00097)	Tok/s 35004 (53505)	Loss/tok 2.9684 (3.3850)	Learning Rate [0.00125]
9: TRAIN [1][500/3416]	Time 0.051 (0.058)	Data 0.00080 (0.00093)	Tok/s 34950 (53623)	Loss/tok 3.0222 (3.3826)	Learning Rate [0.00125]
14: TRAIN [1][500/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00094)	Tok/s 34919 (54080)	Loss/tok 3.2445 (3.3934)	Learning Rate [0.00125]
13: TRAIN [1][500/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00100)	Tok/s 34989 (53979)	Loss/tok 2.8774 (3.3826)	Learning Rate [0.00125]
5: TRAIN [1][500/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00092)	Tok/s 34860 (53387)	Loss/tok 3.2228 (3.3959)	Learning Rate [0.00125]
15: TRAIN [1][500/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 34847 (54180)	Loss/tok 2.9669 (3.4005)	Learning Rate [0.00125]
4: TRAIN [1][500/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00100)	Tok/s 34726 (53339)	Loss/tok 3.4076 (3.4019)	Learning Rate [0.00125]
0: TRAIN [1][500/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00101)	Tok/s 34749 (52977)	Loss/tok 3.2761 (3.3930)	Learning Rate [0.00125]
3: TRAIN [1][500/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00093)	Tok/s 34732 (53236)	Loss/tok 2.9938 (3.4005)	Learning Rate [0.00125]
1: TRAIN [1][500/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00099)	Tok/s 34679 (53068)	Loss/tok 3.0540 (3.4017)	Learning Rate [0.00125]
2: TRAIN [1][500/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00098)	Tok/s 34621 (53147)	Loss/tok 3.1477 (3.3931)	Learning Rate [0.00125]
8: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00100)	Tok/s 53973 (53565)	Loss/tok 3.5767 (3.4022)	Learning Rate [0.00125]
9: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00079 (0.00093)	Tok/s 53947 (53619)	Loss/tok 3.4078 (3.3832)	Learning Rate [0.00125]
7: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00114 (0.00097)	Tok/s 54105 (53503)	Loss/tok 3.4965 (3.3864)	Learning Rate [0.00125]
10: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00097)	Tok/s 53852 (53694)	Loss/tok 3.6517 (3.3850)	Learning Rate [0.00125]
11: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00093)	Tok/s 54312 (53782)	Loss/tok 3.5510 (3.3846)	Learning Rate [0.00125]
4: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00100)	Tok/s 53782 (53336)	Loss/tok 3.4303 (3.4030)	Learning Rate [0.00125]
3: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00093)	Tok/s 53812 (53235)	Loss/tok 3.5282 (3.4010)	Learning Rate [0.00125]
12: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00115 (0.00096)	Tok/s 54638 (53896)	Loss/tok 3.3690 (3.3852)	Learning Rate [0.00125]
2: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00098)	Tok/s 53785 (53148)	Loss/tok 3.6702 (3.3941)	Learning Rate [0.00125]
13: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00100)	Tok/s 54663 (53971)	Loss/tok 3.3859 (3.3821)	Learning Rate [0.00125]
14: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00094)	Tok/s 54651 (54070)	Loss/tok 3.5421 (3.3935)	Learning Rate [0.00125]
1: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00098)	Tok/s 53747 (53070)	Loss/tok 3.4295 (3.4010)	Learning Rate [0.00125]
0: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00103 (0.00101)	Tok/s 53677 (52979)	Loss/tok 3.4913 (3.3929)	Learning Rate [0.00125]
15: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00092)	Tok/s 54660 (54171)	Loss/tok 3.4085 (3.3998)	Learning Rate [0.00125]
6: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00111 (0.00092)	Tok/s 53881 (53435)	Loss/tok 3.4651 (3.3926)	Learning Rate [0.00125]
5: TRAIN [1][510/3416]	Time 0.063 (0.058)	Data 0.00111 (0.00092)	Tok/s 53846 (53383)	Loss/tok 3.4776 (3.3972)	Learning Rate [0.00125]
0: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00101)	Tok/s 83057 (53021)	Loss/tok 3.1856 (3.3911)	Learning Rate [0.00125]
1: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 82779 (53110)	Loss/tok 3.4018 (3.4014)	Learning Rate [0.00125]
6: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00078 (0.00092)	Tok/s 83296 (53474)	Loss/tok 3.3706 (3.3917)	Learning Rate [0.00125]
15: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 85604 (54209)	Loss/tok 3.3817 (3.3992)	Learning Rate [0.00125]
7: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00098)	Tok/s 83260 (53543)	Loss/tok 3.2391 (3.3861)	Learning Rate [0.00125]
8: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00100)	Tok/s 83129 (53606)	Loss/tok 3.3010 (3.4015)	Learning Rate [0.00125]
14: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00094)	Tok/s 84507 (54108)	Loss/tok 3.1719 (3.3935)	Learning Rate [0.00125]
2: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00098)	Tok/s 82659 (53186)	Loss/tok 3.3646 (3.3939)	Learning Rate [0.00125]
5: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 83315 (53421)	Loss/tok 3.4122 (3.3982)	Learning Rate [0.00125]
4: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00100)	Tok/s 82877 (53373)	Loss/tok 3.3743 (3.4030)	Learning Rate [0.00125]
9: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00093)	Tok/s 83419 (53661)	Loss/tok 3.3214 (3.3841)	Learning Rate [0.00125]
3: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00077 (0.00093)	Tok/s 82447 (53273)	Loss/tok 3.2657 (3.4023)	Learning Rate [0.00125]
12: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00096)	Tok/s 84216 (53937)	Loss/tok 3.3258 (3.3854)	Learning Rate [0.00125]
13: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00100)	Tok/s 84421 (54011)	Loss/tok 3.1689 (3.3819)	Learning Rate [0.00125]
10: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 84006 (53735)	Loss/tok 3.2983 (3.3851)	Learning Rate [0.00125]
11: TRAIN [1][520/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 84096 (53823)	Loss/tok 3.1903 (3.3833)	Learning Rate [0.00125]
4: TRAIN [1][530/3416]	Time 0.069 (0.059)	Data 0.00122 (0.00100)	Tok/s 87005 (53477)	Loss/tok 3.3862 (3.4026)	Learning Rate [0.00125]
3: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00083 (0.00093)	Tok/s 85795 (53377)	Loss/tok 3.2456 (3.4034)	Learning Rate [0.00125]
2: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00100 (0.00098)	Tok/s 84856 (53289)	Loss/tok 3.4517 (3.3917)	Learning Rate [0.00125]
1: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00096 (0.00098)	Tok/s 84840 (53214)	Loss/tok 3.3675 (3.4018)	Learning Rate [0.00125]
0: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00097 (0.00101)	Tok/s 84850 (53124)	Loss/tok 3.2894 (3.3905)	Learning Rate [0.00125]
6: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00097 (0.00092)	Tok/s 86171 (53577)	Loss/tok 3.3290 (3.3907)	Learning Rate [0.00125]
5: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00098 (0.00092)	Tok/s 85886 (53525)	Loss/tok 3.2542 (3.3973)	Learning Rate [0.00125]
15: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00097 (0.00093)	Tok/s 89963 (54318)	Loss/tok 3.2927 (3.3968)	Learning Rate [0.00125]
7: TRAIN [1][530/3416]	Time 0.069 (0.059)	Data 0.00094 (0.00098)	Tok/s 87868 (53647)	Loss/tok 3.1422 (3.3848)	Learning Rate [0.00125]
14: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00093 (0.00093)	Tok/s 89372 (54217)	Loss/tok 3.4196 (3.3935)	Learning Rate [0.00125]
8: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00093 (0.00100)	Tok/s 86790 (53709)	Loss/tok 3.0897 (3.4002)	Learning Rate [0.00125]
9: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00090 (0.00093)	Tok/s 87031 (53764)	Loss/tok 3.2890 (3.3825)	Learning Rate [0.00125]
13: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00096 (0.00100)	Tok/s 88451 (54120)	Loss/tok 3.1142 (3.3811)	Learning Rate [0.00125]
12: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00092 (0.00096)	Tok/s 88242 (54044)	Loss/tok 3.4123 (3.3854)	Learning Rate [0.00125]
10: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00092 (0.00097)	Tok/s 87624 (53842)	Loss/tok 3.2654 (3.3861)	Learning Rate [0.00125]
11: TRAIN [1][530/3416]	Time 0.070 (0.059)	Data 0.00100 (0.00093)	Tok/s 87487 (53930)	Loss/tok 3.0894 (3.3826)	Learning Rate [0.00125]
1: TRAIN [1][540/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00098)	Tok/s 51783 (53188)	Loss/tok 3.3765 (3.4005)	Learning Rate [0.00125]
2: TRAIN [1][540/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00098)	Tok/s 51690 (53262)	Loss/tok 3.1431 (3.3892)	Learning Rate [0.00125]
0: TRAIN [1][540/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00101)	Tok/s 51809 (53099)	Loss/tok 2.9883 (3.3890)	Learning Rate [0.00125]
4: TRAIN [1][540/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00100)	Tok/s 51594 (53448)	Loss/tok 3.4526 (3.4002)	Learning Rate [0.00125]
15: TRAIN [1][540/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00092)	Tok/s 53091 (54296)	Loss/tok 3.2171 (3.3952)	Learning Rate [0.00125]
3: TRAIN [1][540/3416]	Time 0.050 (0.058)	Data 0.00079 (0.00093)	Tok/s 51451 (53350)	Loss/tok 3.3266 (3.4021)	Learning Rate [0.00125]
14: TRAIN [1][540/3416]	Time 0.049 (0.058)	Data 0.00078 (0.00093)	Tok/s 53103 (54196)	Loss/tok 3.1625 (3.3919)	Learning Rate [0.00125]
13: TRAIN [1][540/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00100)	Tok/s 53008 (54099)	Loss/tok 3.1148 (3.3794)	Learning Rate [0.00125]
6: TRAIN [1][540/3416]	Time 0.050 (0.058)	Data 0.00078 (0.00092)	Tok/s 51527 (53547)	Loss/tok 3.2599 (3.3888)	Learning Rate [0.00125]
5: TRAIN [1][540/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 51509 (53495)	Loss/tok 3.2741 (3.3950)	Learning Rate [0.00125]
12: TRAIN [1][540/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00096)	Tok/s 51908 (54022)	Loss/tok 3.2465 (3.3846)	Learning Rate [0.00125]
9: TRAIN [1][540/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00093)	Tok/s 51507 (53742)	Loss/tok 3.2279 (3.3804)	Learning Rate [0.00125]
8: TRAIN [1][540/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00100)	Tok/s 51604 (53686)	Loss/tok 3.2365 (3.3985)	Learning Rate [0.00125]
7: TRAIN [1][540/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00098)	Tok/s 51448 (53622)	Loss/tok 3.3506 (3.3829)	Learning Rate [0.00125]
10: TRAIN [1][540/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00097)	Tok/s 51589 (53822)	Loss/tok 3.1422 (3.3850)	Learning Rate [0.00125]
11: TRAIN [1][540/3416]	Time 0.049 (0.058)	Data 0.00102 (0.00093)	Tok/s 51768 (53909)	Loss/tok 3.2838 (3.3824)	Learning Rate [0.00125]
6: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00081 (0.00092)	Tok/s 52007 (53615)	Loss/tok 3.5030 (3.3888)	Learning Rate [0.00125]
5: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 52026 (53563)	Loss/tok 3.3617 (3.3961)	Learning Rate [0.00125]
3: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00093)	Tok/s 51968 (53419)	Loss/tok 3.1548 (3.4036)	Learning Rate [0.00125]
7: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00098)	Tok/s 52103 (53691)	Loss/tok 3.5267 (3.3847)	Learning Rate [0.00125]
4: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00100)	Tok/s 51761 (53516)	Loss/tok 3.2113 (3.4015)	Learning Rate [0.00125]
2: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00098)	Tok/s 51857 (53333)	Loss/tok 3.4169 (3.3902)	Learning Rate [0.00125]
15: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00092)	Tok/s 52602 (54360)	Loss/tok 3.3091 (3.3955)	Learning Rate [0.00125]
1: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00098)	Tok/s 51862 (53260)	Loss/tok 3.2036 (3.3998)	Learning Rate [0.00125]
10: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00096)	Tok/s 52003 (53889)	Loss/tok 3.3846 (3.3870)	Learning Rate [0.00125]
9: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 51950 (53811)	Loss/tok 3.4836 (3.3819)	Learning Rate [0.00125]
8: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00100)	Tok/s 51942 (53755)	Loss/tok 3.4431 (3.4000)	Learning Rate [0.00125]
0: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00101)	Tok/s 51824 (53169)	Loss/tok 3.4943 (3.3890)	Learning Rate [0.00125]
14: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00093)	Tok/s 51850 (54259)	Loss/tok 3.1129 (3.3930)	Learning Rate [0.00125]
13: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00100)	Tok/s 51882 (54160)	Loss/tok 3.3669 (3.3799)	Learning Rate [0.00125]
12: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00096)	Tok/s 51772 (54085)	Loss/tok 3.4910 (3.3859)	Learning Rate [0.00125]
11: TRAIN [1][550/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00093)	Tok/s 51995 (53974)	Loss/tok 3.1833 (3.3827)	Learning Rate [0.00125]
7: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00103 (0.00098)	Tok/s 32262 (53719)	Loss/tok 2.9149 (3.3836)	Learning Rate [0.00125]
6: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00092)	Tok/s 32297 (53644)	Loss/tok 2.6381 (3.3899)	Learning Rate [0.00125]
8: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00100)	Tok/s 32169 (53783)	Loss/tok 2.7860 (3.4009)	Learning Rate [0.00125]
9: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00093)	Tok/s 32118 (53837)	Loss/tok 2.7729 (3.3838)	Learning Rate [0.00125]
4: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00109 (0.00100)	Tok/s 32270 (53545)	Loss/tok 2.8470 (3.4018)	Learning Rate [0.00125]
3: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00093)	Tok/s 32293 (53448)	Loss/tok 2.8087 (3.4050)	Learning Rate [0.00125]
5: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00092)	Tok/s 32314 (53592)	Loss/tok 2.6264 (3.3957)	Learning Rate [0.00125]
10: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00102 (0.00096)	Tok/s 32116 (53915)	Loss/tok 2.9794 (3.3862)	Learning Rate [0.00125]
2: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00098)	Tok/s 32295 (53362)	Loss/tok 2.8667 (3.3903)	Learning Rate [0.00125]
12: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00096)	Tok/s 32122 (54108)	Loss/tok 2.9208 (3.3852)	Learning Rate [0.00125]
1: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00098)	Tok/s 31698 (53288)	Loss/tok 2.8691 (3.4010)	Learning Rate [0.00125]
0: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00101)	Tok/s 30778 (53194)	Loss/tok 2.6490 (3.3896)	Learning Rate [0.00125]
13: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00100)	Tok/s 32136 (54183)	Loss/tok 2.7514 (3.3804)	Learning Rate [0.00125]
14: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00093)	Tok/s 33437 (54285)	Loss/tok 3.0372 (3.3941)	Learning Rate [0.00125]
15: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00092)	Tok/s 33651 (54387)	Loss/tok 2.8698 (3.3961)	Learning Rate [0.00125]
11: TRAIN [1][560/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00093)	Tok/s 32122 (53999)	Loss/tok 3.1246 (3.3830)	Learning Rate [0.00125]
1: TRAIN [1][570/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00098)	Tok/s 47837 (53175)	Loss/tok 3.1367 (3.3993)	Learning Rate [0.00125]
2: TRAIN [1][570/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00098)	Tok/s 48171 (53255)	Loss/tok 2.9237 (3.3904)	Learning Rate [0.00125]
0: TRAIN [1][570/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00101)	Tok/s 47789 (53076)	Loss/tok 3.2947 (3.3878)	Learning Rate [0.00125]
15: TRAIN [1][570/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00092)	Tok/s 49249 (54309)	Loss/tok 3.0741 (3.3936)	Learning Rate [0.00125]
3: TRAIN [1][570/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00093)	Tok/s 48996 (53346)	Loss/tok 3.1945 (3.4032)	Learning Rate [0.00125]
14: TRAIN [1][570/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00093)	Tok/s 49268 (54207)	Loss/tok 3.3054 (3.3919)	Learning Rate [0.00125]
4: TRAIN [1][570/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00100)	Tok/s 48843 (53448)	Loss/tok 3.2166 (3.4003)	Learning Rate [0.00125]
13: TRAIN [1][570/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00099)	Tok/s 49187 (54105)	Loss/tok 3.2087 (3.3792)	Learning Rate [0.00125]
5: TRAIN [1][570/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00092)	Tok/s 48754 (53496)	Loss/tok 3.0088 (3.3948)	Learning Rate [0.00125]
6: TRAIN [1][570/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00092)	Tok/s 48734 (53551)	Loss/tok 3.0702 (3.3888)	Learning Rate [0.00125]
12: TRAIN [1][570/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00096)	Tok/s 49092 (54026)	Loss/tok 3.4087 (3.3850)	Learning Rate [0.00125]
10: TRAIN [1][570/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00096)	Tok/s 48946 (53830)	Loss/tok 3.3493 (3.3839)	Learning Rate [0.00125]
7: TRAIN [1][570/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00098)	Tok/s 48715 (53628)	Loss/tok 3.3290 (3.3822)	Learning Rate [0.00125]
9: TRAIN [1][570/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00093)	Tok/s 48786 (53749)	Loss/tok 3.3164 (3.3815)	Learning Rate [0.00125]
8: TRAIN [1][570/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00100)	Tok/s 48628 (53694)	Loss/tok 3.5016 (3.3994)	Learning Rate [0.00125]
11: TRAIN [1][570/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00093)	Tok/s 49050 (53914)	Loss/tok 3.2958 (3.3821)	Learning Rate [0.00125]
10: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00096)	Tok/s 58728 (53863)	Loss/tok 3.3939 (3.3833)	Learning Rate [0.00125]
9: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00093)	Tok/s 58642 (53781)	Loss/tok 3.5214 (3.3808)	Learning Rate [0.00125]
13: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00099)	Tok/s 58647 (54138)	Loss/tok 3.4267 (3.3777)	Learning Rate [0.00125]
8: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00100)	Tok/s 57650 (53721)	Loss/tok 3.3770 (3.3984)	Learning Rate [0.00125]
14: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 58566 (54239)	Loss/tok 3.3955 (3.3916)	Learning Rate [0.00125]
7: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 57556 (53655)	Loss/tok 3.5132 (3.3813)	Learning Rate [0.00125]
6: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00092)	Tok/s 57675 (53578)	Loss/tok 3.4943 (3.3892)	Learning Rate [0.00125]
15: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 58462 (54342)	Loss/tok 3.5549 (3.3928)	Learning Rate [0.00125]
0: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00101)	Tok/s 57425 (53108)	Loss/tok 3.7259 (3.3876)	Learning Rate [0.00125]
12: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00096)	Tok/s 58588 (54060)	Loss/tok 3.4833 (3.3836)	Learning Rate [0.00125]
1: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00114 (0.00098)	Tok/s 57342 (53206)	Loss/tok 3.4423 (3.3986)	Learning Rate [0.00125]
5: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 57369 (53524)	Loss/tok 3.6377 (3.3950)	Learning Rate [0.00125]
4: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00100)	Tok/s 57255 (53477)	Loss/tok 3.3382 (3.3988)	Learning Rate [0.00125]
3: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00093)	Tok/s 57211 (53377)	Loss/tok 3.4645 (3.4040)	Learning Rate [0.00125]
2: TRAIN [1][580/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00098)	Tok/s 57264 (53289)	Loss/tok 3.5431 (3.3902)	Learning Rate [0.00125]
11: TRAIN [1][580/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00094)	Tok/s 58799 (53946)	Loss/tok 3.3310 (3.3806)	Learning Rate [0.00125]
3: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00093)	Tok/s 65517 (53410)	Loss/tok 3.5353 (3.4042)	Learning Rate [0.00125]
4: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00100)	Tok/s 65516 (53511)	Loss/tok 3.3614 (3.3982)	Learning Rate [0.00125]
2: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00098)	Tok/s 65421 (53323)	Loss/tok 3.5081 (3.3912)	Learning Rate [0.00125]
1: TRAIN [1][590/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00098)	Tok/s 65343 (53241)	Loss/tok 3.6691 (3.3995)	Learning Rate [0.00125]
5: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00092)	Tok/s 65457 (53560)	Loss/tok 3.6960 (3.3952)	Learning Rate [0.00125]
0: TRAIN [1][590/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00101)	Tok/s 65229 (53145)	Loss/tok 3.5086 (3.3880)	Learning Rate [0.00125]
6: TRAIN [1][590/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 65355 (53614)	Loss/tok 3.6141 (3.3915)	Learning Rate [0.00125]
15: TRAIN [1][590/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 66053 (54376)	Loss/tok 3.5979 (3.3937)	Learning Rate [0.00125]
9: TRAIN [1][590/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 65164 (53816)	Loss/tok 3.8878 (3.3839)	Learning Rate [0.00125]
7: TRAIN [1][590/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 65305 (53692)	Loss/tok 3.3604 (3.3811)	Learning Rate [0.00125]
14: TRAIN [1][590/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00093)	Tok/s 65933 (54275)	Loss/tok 3.4414 (3.3931)	Learning Rate [0.00125]
8: TRAIN [1][590/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 65221 (53757)	Loss/tok 3.4444 (3.3993)	Learning Rate [0.00125]
13: TRAIN [1][590/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00099)	Tok/s 65866 (54175)	Loss/tok 3.3930 (3.3781)	Learning Rate [0.00125]
12: TRAIN [1][590/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 65315 (54097)	Loss/tok 3.6551 (3.3850)	Learning Rate [0.00125]
10: TRAIN [1][590/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 65114 (53900)	Loss/tok 3.2739 (3.3837)	Learning Rate [0.00125]
11: TRAIN [1][590/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00093)	Tok/s 65059 (53983)	Loss/tok 3.4206 (3.3822)	Learning Rate [0.00125]
7: TRAIN [1][600/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00097)	Tok/s 51365 (53754)	Loss/tok 3.3930 (3.3815)	Learning Rate [0.00125]
8: TRAIN [1][600/3416]	Time 0.057 (0.058)	Data 0.00099 (0.00099)	Tok/s 51348 (53821)	Loss/tok 3.0670 (3.3984)	Learning Rate [0.00125]
6: TRAIN [1][600/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00092)	Tok/s 51174 (53674)	Loss/tok 3.3480 (3.3932)	Learning Rate [0.00125]
5: TRAIN [1][600/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00092)	Tok/s 51139 (53621)	Loss/tok 3.3381 (3.3960)	Learning Rate [0.00125]
4: TRAIN [1][600/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00100)	Tok/s 51031 (53572)	Loss/tok 3.3906 (3.3985)	Learning Rate [0.00125]
10: TRAIN [1][600/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00096)	Tok/s 51382 (53962)	Loss/tok 3.1659 (3.3838)	Learning Rate [0.00125]
3: TRAIN [1][600/3416]	Time 0.058 (0.058)	Data 0.00102 (0.00093)	Tok/s 50951 (53473)	Loss/tok 3.4016 (3.4052)	Learning Rate [0.00125]
9: TRAIN [1][600/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00093)	Tok/s 51273 (53880)	Loss/tok 3.2469 (3.3836)	Learning Rate [0.00125]
2: TRAIN [1][600/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00098)	Tok/s 50907 (53387)	Loss/tok 3.5207 (3.3923)	Learning Rate [0.00125]
12: TRAIN [1][600/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00096)	Tok/s 51244 (54156)	Loss/tok 3.2489 (3.3841)	Learning Rate [0.00125]
1: TRAIN [1][600/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00098)	Tok/s 50918 (53306)	Loss/tok 3.2603 (3.3996)	Learning Rate [0.00125]
0: TRAIN [1][600/3416]	Time 0.058 (0.058)	Data 0.00104 (0.00101)	Tok/s 50949 (53211)	Loss/tok 3.2986 (3.3899)	Learning Rate [0.00125]
15: TRAIN [1][600/3416]	Time 0.058 (0.058)	Data 0.00083 (0.00092)	Tok/s 51928 (54438)	Loss/tok 3.5284 (3.3952)	Learning Rate [0.00125]
13: TRAIN [1][600/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00099)	Tok/s 51142 (54233)	Loss/tok 3.3751 (3.3793)	Learning Rate [0.00125]
11: TRAIN [1][600/3416]	Time 0.057 (0.058)	Data 0.00111 (0.00094)	Tok/s 51237 (54043)	Loss/tok 3.1226 (3.3823)	Learning Rate [0.00125]
14: TRAIN [1][600/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00093)	Tok/s 50777 (54335)	Loss/tok 3.3599 (3.3940)	Learning Rate [0.00125]
0: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
9: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
4: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00100)	Tok/s 57297 (53556)	Loss/tok 3.5818 (3.3986)	Learning Rate [0.00125]
3: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00093)	Tok/s 57222 (53455)	Loss/tok 3.5195 (3.4054)	Learning Rate [0.00125]
2: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 57134 (53365)	Loss/tok 3.6316 (3.3926)	Learning Rate [0.00125]
1: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00098)	Tok/s 57047 (53279)	Loss/tok 3.8520 (3.3999)	Learning Rate [0.00125]
0: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00101)	Tok/s 56940 (53181)	Loss/tok 3.5247 (3.3897)	Learning Rate [0.00125]
6: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00092)	Tok/s 57215 (53663)	Loss/tok 3.2431 (3.3931)	Learning Rate [0.00125]
5: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00092)	Tok/s 57166 (53608)	Loss/tok 3.4524 (3.3958)	Learning Rate [0.00125]
15: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 57767 (54434)	Loss/tok 3.3243 (3.3953)	Learning Rate [0.00125]
7: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00097)	Tok/s 57162 (53742)	Loss/tok 3.4425 (3.3828)	Learning Rate [0.00125]
8: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00099)	Tok/s 57079 (53814)	Loss/tok 3.5508 (3.3981)	Learning Rate [0.00125]
14: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00093)	Tok/s 57717 (54331)	Loss/tok 3.4549 (3.3946)	Learning Rate [0.00125]
13: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00099)	Tok/s 57766 (54229)	Loss/tok 3.6199 (3.3807)	Learning Rate [0.00125]
9: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 56949 (53874)	Loss/tok 3.3688 (3.3833)	Learning Rate [0.00125]
10: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00096)	Tok/s 56966 (53955)	Loss/tok 3.7107 (3.3843)	Learning Rate [0.00125]
12: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 57721 (54151)	Loss/tok 3.7020 (3.3832)	Learning Rate [0.00125]
11: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00114 (0.00094)	Tok/s 57819 (54037)	Loss/tok 3.3742 (3.3824)	Learning Rate [0.00125]
12: TRAIN [1][620/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00096)	Tok/s 50128 (54197)	Loss/tok 3.2345 (3.3866)	Learning Rate [0.00125]
13: TRAIN [1][620/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00099)	Tok/s 50120 (54273)	Loss/tok 3.3219 (3.3824)	Learning Rate [0.00125]
10: TRAIN [1][620/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00096)	Tok/s 50222 (54002)	Loss/tok 3.0589 (3.3867)	Learning Rate [0.00125]
9: TRAIN [1][620/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00093)	Tok/s 50165 (53922)	Loss/tok 3.4559 (3.3841)	Learning Rate [0.00125]
0: TRAIN [1][620/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00101)	Tok/s 49730 (53230)	Loss/tok 3.2665 (3.3907)	Learning Rate [0.00125]
8: TRAIN [1][620/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00099)	Tok/s 50158 (53862)	Loss/tok 3.2584 (3.3993)	Learning Rate [0.00125]
14: TRAIN [1][620/3416]	Time 0.047 (0.058)	Data 0.00079 (0.00093)	Tok/s 49888 (54373)	Loss/tok 3.2494 (3.3958)	Learning Rate [0.00125]
1: TRAIN [1][620/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00098)	Tok/s 49656 (53326)	Loss/tok 3.5597 (3.4011)	Learning Rate [0.00125]
15: TRAIN [1][620/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00092)	Tok/s 49780 (54476)	Loss/tok 3.2598 (3.3953)	Learning Rate [0.00125]
6: TRAIN [1][620/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00092)	Tok/s 49998 (53713)	Loss/tok 3.1638 (3.3934)	Learning Rate [0.00125]
7: TRAIN [1][620/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00097)	Tok/s 50040 (53792)	Loss/tok 3.2312 (3.3833)	Learning Rate [0.00125]
2: TRAIN [1][620/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00098)	Tok/s 49621 (53412)	Loss/tok 3.3197 (3.3931)	Learning Rate [0.00125]
5: TRAIN [1][620/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 49838 (53657)	Loss/tok 3.1809 (3.3959)	Learning Rate [0.00125]
4: TRAIN [1][620/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00100)	Tok/s 49800 (53604)	Loss/tok 3.2788 (3.3983)	Learning Rate [0.00125]
3: TRAIN [1][620/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00093)	Tok/s 49664 (53502)	Loss/tok 3.2210 (3.4065)	Learning Rate [0.00125]
11: TRAIN [1][620/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00094)	Tok/s 50175 (54084)	Loss/tok 3.0276 (3.3822)	Learning Rate [0.00125]
4: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00100)	Tok/s 64497 (53533)	Loss/tok 3.4803 (3.3972)	Learning Rate [0.00125]
6: TRAIN [1][630/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00092)	Tok/s 64436 (53644)	Loss/tok 3.6100 (3.3933)	Learning Rate [0.00125]
3: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00093)	Tok/s 64497 (53432)	Loss/tok 3.3731 (3.4063)	Learning Rate [0.00125]
5: TRAIN [1][630/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 64431 (53586)	Loss/tok 3.6111 (3.3967)	Learning Rate [0.00125]
2: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00098)	Tok/s 64504 (53343)	Loss/tok 3.5238 (3.3925)	Learning Rate [0.00125]
7: TRAIN [1][630/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 64426 (53724)	Loss/tok 3.6068 (3.3832)	Learning Rate [0.00125]
1: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00098)	Tok/s 64484 (53256)	Loss/tok 3.6094 (3.4007)	Learning Rate [0.00125]
8: TRAIN [1][630/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00099)	Tok/s 64411 (53793)	Loss/tok 3.4488 (3.3993)	Learning Rate [0.00125]
0: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00101)	Tok/s 64488 (53159)	Loss/tok 3.5630 (3.3907)	Learning Rate [0.00125]
9: TRAIN [1][630/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 64436 (53851)	Loss/tok 3.3831 (3.3841)	Learning Rate [0.00125]
15: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00092)	Tok/s 65161 (54405)	Loss/tok 3.4856 (3.3941)	Learning Rate [0.00125]
14: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00093)	Tok/s 64534 (54302)	Loss/tok 3.4735 (3.3967)	Learning Rate [0.00125]
12: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00096)	Tok/s 64559 (54125)	Loss/tok 3.3500 (3.3863)	Learning Rate [0.00125]
13: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00106 (0.00099)	Tok/s 64552 (54203)	Loss/tok 3.5320 (3.3827)	Learning Rate [0.00125]
10: TRAIN [1][630/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 64431 (53930)	Loss/tok 3.6043 (3.3874)	Learning Rate [0.00125]
11: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00094)	Tok/s 64522 (54011)	Loss/tok 3.5532 (3.3841)	Learning Rate [0.00125]
4: TRAIN [1][640/3416]	Time 0.041 (0.058)	Data 0.00098 (0.00100)	Tok/s 28712 (53573)	Loss/tok 2.7117 (3.3970)	Learning Rate [0.00125]
2: TRAIN [1][640/3416]	Time 0.041 (0.058)	Data 0.00080 (0.00098)	Tok/s 27937 (53383)	Loss/tok 2.4733 (3.3926)	Learning Rate [0.00125]
1: TRAIN [1][640/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00098)	Tok/s 27918 (53293)	Loss/tok 2.7171 (3.4007)	Learning Rate [0.00125]
6: TRAIN [1][640/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00092)	Tok/s 29271 (53684)	Loss/tok 2.6852 (3.3938)	Learning Rate [0.00125]
5: TRAIN [1][640/3416]	Time 0.041 (0.058)	Data 0.00084 (0.00092)	Tok/s 29315 (53627)	Loss/tok 2.5429 (3.3968)	Learning Rate [0.00125]
3: TRAIN [1][640/3416]	Time 0.041 (0.058)	Data 0.00093 (0.00093)	Tok/s 27909 (53471)	Loss/tok 2.6927 (3.4069)	Learning Rate [0.00125]
7: TRAIN [1][640/3416]	Time 0.042 (0.058)	Data 0.00092 (0.00097)	Tok/s 29208 (53763)	Loss/tok 2.6299 (3.3837)	Learning Rate [0.00125]
0: TRAIN [1][640/3416]	Time 0.041 (0.058)	Data 0.00099 (0.00101)	Tok/s 27902 (53197)	Loss/tok 2.5386 (3.3906)	Learning Rate [0.00125]
15: TRAIN [1][640/3416]	Time 0.041 (0.058)	Data 0.00078 (0.00092)	Tok/s 30922 (54442)	Loss/tok 2.7152 (3.3949)	Learning Rate [0.00125]
14: TRAIN [1][640/3416]	Time 0.042 (0.058)	Data 0.00088 (0.00093)	Tok/s 30825 (54340)	Loss/tok 2.7275 (3.3980)	Learning Rate [0.00125]
9: TRAIN [1][640/3416]	Time 0.042 (0.058)	Data 0.00088 (0.00092)	Tok/s 29012 (53888)	Loss/tok 2.8856 (3.3843)	Learning Rate [0.00125]
8: TRAIN [1][640/3416]	Time 0.042 (0.058)	Data 0.00103 (0.00100)	Tok/s 29068 (53831)	Loss/tok 2.7106 (3.3997)	Learning Rate [0.00125]
12: TRAIN [1][640/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00096)	Tok/s 29179 (54162)	Loss/tok 2.6854 (3.3863)	Learning Rate [0.00125]
13: TRAIN [1][640/3416]	Time 0.042 (0.058)	Data 0.00099 (0.00099)	Tok/s 30462 (54240)	Loss/tok 2.7160 (3.3831)	Learning Rate [0.00125]
10: TRAIN [1][640/3416]	Time 0.042 (0.058)	Data 0.00099 (0.00096)	Tok/s 29033 (53966)	Loss/tok 2.6768 (3.3873)	Learning Rate [0.00125]
11: TRAIN [1][640/3416]	Time 0.042 (0.058)	Data 0.00084 (0.00094)	Tok/s 29088 (54048)	Loss/tok 2.7813 (3.3851)	Learning Rate [0.00125]
6: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00084 (0.00092)	Tok/s 30666 (53554)	Loss/tok 2.6817 (3.3931)	Learning Rate [0.00125]
7: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00088 (0.00097)	Tok/s 30615 (53634)	Loss/tok 2.6990 (3.3820)	Learning Rate [0.00125]
8: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00083 (0.00100)	Tok/s 30675 (53703)	Loss/tok 2.8028 (3.3990)	Learning Rate [0.00125]
5: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00083 (0.00092)	Tok/s 30514 (53497)	Loss/tok 2.5539 (3.3971)	Learning Rate [0.00125]
9: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00080 (0.00092)	Tok/s 30634 (53761)	Loss/tok 2.8244 (3.3836)	Learning Rate [0.00125]
4: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00109 (0.00100)	Tok/s 29659 (53436)	Loss/tok 2.5874 (3.3969)	Learning Rate [0.00125]
10: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00085 (0.00096)	Tok/s 30616 (53839)	Loss/tok 2.5812 (3.3861)	Learning Rate [0.00125]
3: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00086 (0.00093)	Tok/s 28746 (53328)	Loss/tok 2.7317 (3.4059)	Learning Rate [0.00125]
2: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00092 (0.00098)	Tok/s 28651 (53239)	Loss/tok 2.4891 (3.3915)	Learning Rate [0.00125]
1: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00089 (0.00098)	Tok/s 28638 (53145)	Loss/tok 2.5218 (3.3993)	Learning Rate [0.00125]
12: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00084 (0.00096)	Tok/s 30661 (54035)	Loss/tok 2.7186 (3.3859)	Learning Rate [0.00125]
0: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00097 (0.00101)	Tok/s 28576 (53045)	Loss/tok 2.7135 (3.3903)	Learning Rate [0.00125]
13: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00093 (0.00099)	Tok/s 31923 (54114)	Loss/tok 2.7893 (3.3815)	Learning Rate [0.00125]
15: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00074 (0.00092)	Tok/s 31783 (54314)	Loss/tok 2.8822 (3.3944)	Learning Rate [0.00125]
14: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00077 (0.00093)	Tok/s 31811 (54212)	Loss/tok 2.9819 (3.3978)	Learning Rate [0.00125]
11: TRAIN [1][650/3416]	Time 0.040 (0.058)	Data 0.00087 (0.00094)	Tok/s 30462 (53920)	Loss/tok 2.9969 (3.3847)	Learning Rate [0.00125]
13: TRAIN [1][660/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00099)	Tok/s 50799 (54095)	Loss/tok 3.3320 (3.3806)	Learning Rate [0.00125]
12: TRAIN [1][660/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00096)	Tok/s 50677 (54016)	Loss/tok 3.3178 (3.3859)	Learning Rate [0.00125]
14: TRAIN [1][660/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00093)	Tok/s 50787 (54191)	Loss/tok 3.4465 (3.3962)	Learning Rate [0.00125]
11: TRAIN [1][660/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00094)	Tok/s 50578 (53902)	Loss/tok 3.3108 (3.3846)	Learning Rate [0.00125]
15: TRAIN [1][660/3416]	Time 0.048 (0.058)	Data 0.00076 (0.00092)	Tok/s 50718 (54294)	Loss/tok 3.3324 (3.3943)	Learning Rate [0.00125]
10: TRAIN [1][660/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00096)	Tok/s 50444 (53820)	Loss/tok 3.2105 (3.3851)	Learning Rate [0.00125]
0: TRAIN [1][660/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00101)	Tok/s 50611 (53029)	Loss/tok 3.2456 (3.3901)	Learning Rate [0.00125]
9: TRAIN [1][660/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 50280 (53741)	Loss/tok 3.2385 (3.3833)	Learning Rate [0.00125]
1: TRAIN [1][660/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00098)	Tok/s 50546 (53131)	Loss/tok 3.1531 (3.3989)	Learning Rate [0.00125]
8: TRAIN [1][660/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00099)	Tok/s 50218 (53684)	Loss/tok 3.1015 (3.3986)	Learning Rate [0.00125]
2: TRAIN [1][660/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00098)	Tok/s 50391 (53225)	Loss/tok 3.6262 (3.3917)	Learning Rate [0.00125]
6: TRAIN [1][660/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00092)	Tok/s 50063 (53537)	Loss/tok 3.3350 (3.3929)	Learning Rate [0.00125]
7: TRAIN [1][660/3416]	Time 0.049 (0.058)	Data 0.00108 (0.00097)	Tok/s 50131 (53615)	Loss/tok 3.3891 (3.3821)	Learning Rate [0.00125]
3: TRAIN [1][660/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00093)	Tok/s 50222 (53312)	Loss/tok 3.0233 (3.4065)	Learning Rate [0.00125]
5: TRAIN [1][660/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00092)	Tok/s 50085 (53479)	Loss/tok 3.3356 (3.3978)	Learning Rate [0.00125]
4: TRAIN [1][660/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00100)	Tok/s 50147 (53419)	Loss/tok 3.3986 (3.3956)	Learning Rate [0.00125]
1: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00098)	Tok/s 81909 (53200)	Loss/tok 3.3290 (3.3979)	Learning Rate [0.00125]
0: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00101)	Tok/s 81050 (53098)	Loss/tok 3.4313 (3.3890)	Learning Rate [0.00125]
2: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00098)	Tok/s 81778 (53293)	Loss/tok 3.2418 (3.3911)	Learning Rate [0.00125]
15: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00092)	Tok/s 84131 (54369)	Loss/tok 3.3192 (3.3933)	Learning Rate [0.00125]
3: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 81715 (53381)	Loss/tok 3.4032 (3.4049)	Learning Rate [0.00125]
4: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00100)	Tok/s 81768 (53491)	Loss/tok 3.2211 (3.3949)	Learning Rate [0.00125]
5: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 81778 (53552)	Loss/tok 3.1407 (3.3977)	Learning Rate [0.00125]
6: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 82573 (53612)	Loss/tok 3.3395 (3.3931)	Learning Rate [0.00125]
13: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00099)	Tok/s 83771 (54171)	Loss/tok 3.4005 (3.3804)	Learning Rate [0.00125]
12: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00096)	Tok/s 83585 (54091)	Loss/tok 3.3018 (3.3866)	Learning Rate [0.00125]
9: TRAIN [1][670/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00092)	Tok/s 82587 (53812)	Loss/tok 3.3018 (3.3825)	Learning Rate [0.00125]
7: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 82684 (53689)	Loss/tok 3.1900 (3.3821)	Learning Rate [0.00125]
10: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 82721 (53891)	Loss/tok 3.4216 (3.3845)	Learning Rate [0.00125]
8: TRAIN [1][670/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00099)	Tok/s 82561 (53756)	Loss/tok 3.1815 (3.3978)	Learning Rate [0.00125]
14: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00117 (0.00093)	Tok/s 83674 (54265)	Loss/tok 3.2480 (3.3957)	Learning Rate [0.00125]
11: TRAIN [1][670/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00094)	Tok/s 83437 (53973)	Loss/tok 3.3412 (3.3843)	Learning Rate [0.00125]
3: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00093)	Tok/s 56223 (53357)	Loss/tok 3.4138 (3.4044)	Learning Rate [0.00125]
2: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00098)	Tok/s 56252 (53269)	Loss/tok 3.5902 (3.3906)	Learning Rate [0.00125]
4: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00100)	Tok/s 56144 (53466)	Loss/tok 3.5686 (3.3954)	Learning Rate [0.00125]
6: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00092)	Tok/s 57009 (53589)	Loss/tok 3.5787 (3.3930)	Learning Rate [0.00125]
1: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00098)	Tok/s 56221 (53177)	Loss/tok 3.2682 (3.3971)	Learning Rate [0.00125]
5: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00103 (0.00092)	Tok/s 56611 (53528)	Loss/tok 3.4628 (3.3971)	Learning Rate [0.00125]
0: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00101)	Tok/s 56197 (53076)	Loss/tok 3.5562 (3.3893)	Learning Rate [0.00125]
15: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00092)	Tok/s 57207 (54346)	Loss/tok 3.5374 (3.3938)	Learning Rate [0.00125]
7: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00119 (0.00097)	Tok/s 56913 (53667)	Loss/tok 3.5324 (3.3818)	Learning Rate [0.00125]
13: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00120 (0.00099)	Tok/s 57211 (54147)	Loss/tok 3.6163 (3.3801)	Learning Rate [0.00125]
14: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00093)	Tok/s 57238 (54242)	Loss/tok 3.5777 (3.3958)	Learning Rate [0.00125]
11: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00094)	Tok/s 56994 (53952)	Loss/tok 3.4879 (3.3844)	Learning Rate [0.00125]
8: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00100)	Tok/s 56870 (53734)	Loss/tok 3.7605 (3.3979)	Learning Rate [0.00125]
9: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00092)	Tok/s 56934 (53790)	Loss/tok 3.3740 (3.3815)	Learning Rate [0.00125]
12: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00105 (0.00096)	Tok/s 57025 (54068)	Loss/tok 3.6362 (3.3862)	Learning Rate [0.00125]
10: TRAIN [1][680/3416]	Time 0.063 (0.058)	Data 0.00103 (0.00096)	Tok/s 56893 (53869)	Loss/tok 3.6078 (3.3836)	Learning Rate [0.00125]
0: TRAIN [1][690/3416]	Time 0.042 (0.058)	Data 0.00094 (0.00101)	Tok/s 48242 (53041)	Loss/tok 3.3052 (3.3892)	Learning Rate [0.00125]
4: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00102 (0.00100)	Tok/s 48678 (53430)	Loss/tok 3.1662 (3.3959)	Learning Rate [0.00125]
1: TRAIN [1][690/3416]	Time 0.042 (0.058)	Data 0.00096 (0.00098)	Tok/s 48213 (53140)	Loss/tok 3.2437 (3.3974)	Learning Rate [0.00125]
15: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00089 (0.00092)	Tok/s 49660 (54311)	Loss/tok 3.1143 (3.3944)	Learning Rate [0.00125]
3: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00093)	Tok/s 48061 (53320)	Loss/tok 3.1735 (3.4032)	Learning Rate [0.00125]
2: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00097)	Tok/s 48119 (53232)	Loss/tok 3.4489 (3.3908)	Learning Rate [0.00125]
13: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00107 (0.00099)	Tok/s 49467 (54108)	Loss/tok 3.0889 (3.3811)	Learning Rate [0.00125]
6: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00099 (0.00092)	Tok/s 49270 (53553)	Loss/tok 3.1810 (3.3935)	Learning Rate [0.00125]
5: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00092)	Tok/s 49385 (53492)	Loss/tok 3.0367 (3.3958)	Learning Rate [0.00125]
12: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00100 (0.00096)	Tok/s 49317 (54030)	Loss/tok 3.1727 (3.3866)	Learning Rate [0.00125]
7: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00109 (0.00097)	Tok/s 49172 (53631)	Loss/tok 3.3117 (3.3824)	Learning Rate [0.00125]
11: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00098 (0.00094)	Tok/s 49158 (53916)	Loss/tok 3.1118 (3.3833)	Learning Rate [0.00125]
14: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00093)	Tok/s 49370 (54204)	Loss/tok 3.5142 (3.3973)	Learning Rate [0.00125]
9: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00091 (0.00092)	Tok/s 48965 (53756)	Loss/tok 3.4774 (3.3829)	Learning Rate [0.00125]
8: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00100)	Tok/s 49014 (53699)	Loss/tok 3.1602 (3.3970)	Learning Rate [0.00125]
10: TRAIN [1][690/3416]	Time 0.043 (0.058)	Data 0.00099 (0.00096)	Tok/s 49038 (53834)	Loss/tok 2.9578 (3.3831)	Learning Rate [0.00125]
4: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00099)	Tok/s 52622 (53445)	Loss/tok 3.4085 (3.3957)	Learning Rate [0.00125]
6: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00101 (0.00092)	Tok/s 53797 (53569)	Loss/tok 3.1998 (3.3930)	Learning Rate [0.00125]
5: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00092)	Tok/s 52853 (53508)	Loss/tok 3.4565 (3.3958)	Learning Rate [0.00125]
3: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00093)	Tok/s 52526 (53337)	Loss/tok 3.3250 (3.4035)	Learning Rate [0.00125]
8: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00107 (0.00100)	Tok/s 53739 (53718)	Loss/tok 3.6025 (3.3974)	Learning Rate [0.00125]
7: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00101 (0.00097)	Tok/s 53720 (53646)	Loss/tok 3.4248 (3.3825)	Learning Rate [0.00125]
2: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00097)	Tok/s 52372 (53249)	Loss/tok 3.5286 (3.3908)	Learning Rate [0.00125]
9: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00092)	Tok/s 53725 (53776)	Loss/tok 3.3942 (3.3829)	Learning Rate [0.00125]
1: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00101 (0.00098)	Tok/s 52335 (53158)	Loss/tok 3.4340 (3.3981)	Learning Rate [0.00125]
15: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00092)	Tok/s 53484 (54328)	Loss/tok 3.6185 (3.3941)	Learning Rate [0.00125]
0: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00101)	Tok/s 52343 (53059)	Loss/tok 3.4488 (3.3897)	Learning Rate [0.00125]
11: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00094)	Tok/s 53600 (53934)	Loss/tok 3.5902 (3.3834)	Learning Rate [0.00125]
10: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00096)	Tok/s 53657 (53854)	Loss/tok 3.3991 (3.3833)	Learning Rate [0.00125]
12: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00096)	Tok/s 53528 (54046)	Loss/tok 3.2535 (3.3860)	Learning Rate [0.00125]
13: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00099)	Tok/s 53422 (54124)	Loss/tok 3.4387 (3.3818)	Learning Rate [0.00125]
14: TRAIN [1][700/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00093)	Tok/s 53382 (54221)	Loss/tok 3.4712 (3.3971)	Learning Rate [0.00125]
6: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00092)	Tok/s 52097 (53568)	Loss/tok 3.5472 (3.3925)	Learning Rate [0.00125]
5: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00092)	Tok/s 52099 (53505)	Loss/tok 3.3461 (3.3962)	Learning Rate [0.00125]
4: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00099)	Tok/s 52143 (53441)	Loss/tok 3.4788 (3.3959)	Learning Rate [0.00125]
3: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00093)	Tok/s 52108 (53333)	Loss/tok 3.4209 (3.4036)	Learning Rate [0.00125]
7: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00110 (0.00097)	Tok/s 52105 (53645)	Loss/tok 3.5339 (3.3828)	Learning Rate [0.00125]
2: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00097)	Tok/s 52116 (53245)	Loss/tok 3.3220 (3.3913)	Learning Rate [0.00125]
8: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00100)	Tok/s 52118 (53716)	Loss/tok 3.2562 (3.3957)	Learning Rate [0.00125]
9: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00092)	Tok/s 52126 (53773)	Loss/tok 3.3325 (3.3817)	Learning Rate [0.00125]
0: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00101)	Tok/s 52108 (53054)	Loss/tok 3.2579 (3.3893)	Learning Rate [0.00125]
15: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00092)	Tok/s 53216 (54324)	Loss/tok 3.4549 (3.3937)	Learning Rate [0.00125]
10: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00096)	Tok/s 52063 (53850)	Loss/tok 3.4960 (3.3836)	Learning Rate [0.00125]
13: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00099)	Tok/s 53199 (54121)	Loss/tok 3.5669 (3.3815)	Learning Rate [0.00125]
11: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00094)	Tok/s 52115 (53932)	Loss/tok 3.5867 (3.3844)	Learning Rate [0.00125]
12: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00096)	Tok/s 52969 (54044)	Loss/tok 3.5843 (3.3868)	Learning Rate [0.00125]
14: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00093)	Tok/s 53179 (54218)	Loss/tok 3.2952 (3.3966)	Learning Rate [0.00125]
1: TRAIN [1][710/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00098)	Tok/s 51880 (53153)	Loss/tok 3.2722 (3.3978)	Learning Rate [0.00125]
3: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00081 (0.00093)	Tok/s 54922 (53326)	Loss/tok 3.3558 (3.4038)	Learning Rate [0.00125]
2: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00097)	Tok/s 55068 (53238)	Loss/tok 3.3688 (3.3900)	Learning Rate [0.00125]
1: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00098)	Tok/s 54954 (53148)	Loss/tok 3.5849 (3.3975)	Learning Rate [0.00125]
4: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00099)	Tok/s 54770 (53435)	Loss/tok 3.5685 (3.3944)	Learning Rate [0.00125]
6: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00092)	Tok/s 55545 (53561)	Loss/tok 3.4143 (3.3914)	Learning Rate [0.00125]
0: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00101)	Tok/s 54930 (53050)	Loss/tok 3.4146 (3.3888)	Learning Rate [0.00125]
5: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00092)	Tok/s 54725 (53497)	Loss/tok 3.4286 (3.3958)	Learning Rate [0.00125]
15: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00080 (0.00092)	Tok/s 55945 (54322)	Loss/tok 3.8128 (3.3948)	Learning Rate [0.00125]
7: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00097)	Tok/s 55744 (53640)	Loss/tok 3.5055 (3.3819)	Learning Rate [0.00125]
14: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00093)	Tok/s 55915 (54216)	Loss/tok 3.4321 (3.3973)	Learning Rate [0.00125]
8: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00100)	Tok/s 55743 (53710)	Loss/tok 3.4158 (3.3945)	Learning Rate [0.00125]
13: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00099)	Tok/s 55834 (54120)	Loss/tok 3.4181 (3.3812)	Learning Rate [0.00125]
10: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00096)	Tok/s 55741 (53845)	Loss/tok 3.3388 (3.3827)	Learning Rate [0.00125]
9: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00092)	Tok/s 55737 (53768)	Loss/tok 3.2859 (3.3816)	Learning Rate [0.00125]
12: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00080 (0.00096)	Tok/s 55786 (54041)	Loss/tok 3.5009 (3.3866)	Learning Rate [0.00125]
11: TRAIN [1][720/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00094)	Tok/s 55782 (53930)	Loss/tok 3.6908 (3.3846)	Learning Rate [0.00125]
9: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
8: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00100)	Tok/s 54473 (53626)	Loss/tok 3.6585 (3.3936)	Learning Rate [0.00125]
9: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00092)	Tok/s 54508 (53683)	Loss/tok 3.6177 (3.3803)	Learning Rate [0.00125]
5: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
6: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00092)	Tok/s 54264 (53478)	Loss/tok 3.2447 (3.3901)	Learning Rate [0.00125]
7: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00097)	Tok/s 54395 (53557)	Loss/tok 3.7031 (3.3810)	Learning Rate [0.00125]
10: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00096)	Tok/s 54484 (53759)	Loss/tok 3.4042 (3.3823)	Learning Rate [0.00125]
14: Upscaling, new scale: 2048.0
11: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00094)	Tok/s 54375 (53842)	Loss/tok 3.2617 (3.3837)	Learning Rate [0.00125]
3: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
12: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00096)	Tok/s 54279 (53955)	Loss/tok 3.6467 (3.3869)	Learning Rate [0.00125]
4: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00099)	Tok/s 54084 (53350)	Loss/tok 3.4512 (3.3933)	Learning Rate [0.00125]
0: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
13: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00098)	Tok/s 54172 (54033)	Loss/tok 3.3896 (3.3812)	Learning Rate [0.00125]
5: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00092)	Tok/s 54148 (53414)	Loss/tok 3.3516 (3.3947)	Learning Rate [0.00125]
2: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00097)	Tok/s 53915 (53154)	Loss/tok 3.2450 (3.3899)	Learning Rate [0.00125]
3: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00093)	Tok/s 53939 (53241)	Loss/tok 3.6150 (3.4040)	Learning Rate [0.00125]
0: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00100)	Tok/s 53950 (52963)	Loss/tok 3.4478 (3.3875)	Learning Rate [0.00125]
14: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00093)	Tok/s 54068 (54128)	Loss/tok 3.3374 (3.3960)	Learning Rate [0.00125]
1: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00097)	Tok/s 53887 (53063)	Loss/tok 3.6666 (3.3972)	Learning Rate [0.00125]
15: TRAIN [1][730/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00092)	Tok/s 53959 (54233)	Loss/tok 3.3260 (3.3938)	Learning Rate [0.00125]
7: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00097)	Tok/s 51487 (53555)	Loss/tok 3.1279 (3.3817)	Learning Rate [0.00125]
6: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00081 (0.00092)	Tok/s 51382 (53478)	Loss/tok 3.3593 (3.3908)	Learning Rate [0.00125]
8: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00100)	Tok/s 51514 (53625)	Loss/tok 3.0557 (3.3930)	Learning Rate [0.00125]
9: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00092)	Tok/s 51482 (53681)	Loss/tok 3.1557 (3.3809)	Learning Rate [0.00125]
5: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00092)	Tok/s 51229 (53414)	Loss/tok 3.2601 (3.3936)	Learning Rate [0.00125]
4: TRAIN [1][740/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00099)	Tok/s 51137 (53351)	Loss/tok 3.6550 (3.3928)	Learning Rate [0.00125]
10: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00096)	Tok/s 51460 (53758)	Loss/tok 3.2975 (3.3819)	Learning Rate [0.00125]
3: TRAIN [1][740/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00093)	Tok/s 51175 (53244)	Loss/tok 2.9678 (3.4031)	Learning Rate [0.00125]
11: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00094)	Tok/s 51442 (53841)	Loss/tok 3.1527 (3.3833)	Learning Rate [0.00125]
2: TRAIN [1][740/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00097)	Tok/s 51180 (53155)	Loss/tok 3.1683 (3.3894)	Learning Rate [0.00125]
1: TRAIN [1][740/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00097)	Tok/s 51179 (53062)	Loss/tok 3.1107 (3.3960)	Learning Rate [0.00125]
12: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00096)	Tok/s 51379 (53952)	Loss/tok 3.3713 (3.3866)	Learning Rate [0.00125]
0: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00100)	Tok/s 51203 (52961)	Loss/tok 3.0179 (3.3884)	Learning Rate [0.00125]
13: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00098)	Tok/s 51362 (54030)	Loss/tok 3.4983 (3.3808)	Learning Rate [0.00125]
15: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00092)	Tok/s 52007 (54230)	Loss/tok 3.2511 (3.3937)	Learning Rate [0.00125]
14: TRAIN [1][740/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00093)	Tok/s 51161 (54124)	Loss/tok 3.3449 (3.3960)	Learning Rate [0.00125]
5: TRAIN [1][750/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00092)	Tok/s 52850 (53381)	Loss/tok 3.4799 (3.3939)	Learning Rate [0.00125]
6: TRAIN [1][750/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00092)	Tok/s 52833 (53445)	Loss/tok 3.1396 (3.3906)	Learning Rate [0.00125]
4: TRAIN [1][750/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00099)	Tok/s 52695 (53319)	Loss/tok 3.6145 (3.3926)	Learning Rate [0.00125]
3: TRAIN [1][750/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00093)	Tok/s 52639 (53211)	Loss/tok 3.3524 (3.4029)	Learning Rate [0.00125]
7: TRAIN [1][750/3416]	Time 0.058 (0.058)	Data 0.00105 (0.00097)	Tok/s 53679 (53526)	Loss/tok 3.3821 (3.3819)	Learning Rate [0.00125]
2: TRAIN [1][750/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00097)	Tok/s 52542 (53122)	Loss/tok 3.3730 (3.3897)	Learning Rate [0.00125]
1: TRAIN [1][750/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00097)	Tok/s 52473 (53028)	Loss/tok 3.3265 (3.3954)	Learning Rate [0.00125]
8: TRAIN [1][750/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00100)	Tok/s 53995 (53597)	Loss/tok 3.2488 (3.3923)	Learning Rate [0.00125]
9: TRAIN [1][750/3416]	Time 0.058 (0.058)	Data 0.00117 (0.00092)	Tok/s 53850 (53652)	Loss/tok 3.4175 (3.3802)	Learning Rate [0.00125]
0: TRAIN [1][750/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00100)	Tok/s 52430 (52928)	Loss/tok 3.5308 (3.3881)	Learning Rate [0.00125]
10: TRAIN [1][750/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00096)	Tok/s 53783 (53728)	Loss/tok 3.4923 (3.3821)	Learning Rate [0.00125]
15: TRAIN [1][750/3416]	Time 0.059 (0.058)	Data 0.00109 (0.00092)	Tok/s 53519 (54197)	Loss/tok 3.3803 (3.3935)	Learning Rate [0.00125]
11: TRAIN [1][750/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00094)	Tok/s 53661 (53810)	Loss/tok 3.2600 (3.3842)	Learning Rate [0.00125]
13: TRAIN [1][750/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00098)	Tok/s 53470 (54000)	Loss/tok 3.5995 (3.3809)	Learning Rate [0.00125]
12: TRAIN [1][750/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00096)	Tok/s 53507 (53922)	Loss/tok 3.6735 (3.3855)	Learning Rate [0.00125]
14: TRAIN [1][750/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00093)	Tok/s 53493 (54093)	Loss/tok 3.4964 (3.3957)	Learning Rate [0.00125]
4: Gradient norm: inf
5: Gradient norm: inf
3: Gradient norm: inf
6: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
7: Gradient norm: inf
1: Gradient norm: inf
0: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
4: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00099)	Tok/s 87113 (53396)	Loss/tok 3.2768 (3.3921)	Learning Rate [0.00125]
14: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
6: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 87236 (53522)	Loss/tok 3.4836 (3.3901)	Learning Rate [0.00125]
13: Skipped batch, new scale: 1024.0
3: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00093)	Tok/s 86727 (53289)	Loss/tok 3.1256 (3.4023)	Learning Rate [0.00125]
5: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 87198 (53458)	Loss/tok 3.2935 (3.3938)	Learning Rate [0.00125]
12: Gradient norm: inf
11: Gradient norm: inf
10: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
2: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 86112 (53199)	Loss/tok 3.3941 (3.3889)	Learning Rate [0.00125]
12: Skipped batch, new scale: 1024.0
1: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 86125 (53106)	Loss/tok 3.2312 (3.3953)	Learning Rate [0.00125]
7: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 88143 (53602)	Loss/tok 3.4307 (3.3820)	Learning Rate [0.00125]
0: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 86184 (53008)	Loss/tok 3.2570 (3.3877)	Learning Rate [0.00125]
11: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
15: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 91465 (54274)	Loss/tok 3.3703 (3.3937)	Learning Rate [0.00125]
14: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00093)	Tok/s 90749 (54169)	Loss/tok 3.1920 (3.3956)	Learning Rate [0.00125]
8: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 88102 (53673)	Loss/tok 3.3741 (3.3920)	Learning Rate [0.00125]
13: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 90040 (54075)	Loss/tok 3.1715 (3.3812)	Learning Rate [0.00125]
9: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 88140 (53727)	Loss/tok 3.0424 (3.3781)	Learning Rate [0.00125]
11: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00094)	Tok/s 89100 (53885)	Loss/tok 3.3511 (3.3845)	Learning Rate [0.00125]
12: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00096)	Tok/s 89695 (53997)	Loss/tok 3.1961 (3.3858)	Learning Rate [0.00125]
10: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 88958 (53804)	Loss/tok 3.2706 (3.3818)	Learning Rate [0.00125]
6: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00092)	Tok/s 57701 (53560)	Loss/tok 3.7870 (3.3902)	Learning Rate [0.00125]
7: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00102 (0.00097)	Tok/s 57679 (53642)	Loss/tok 3.6101 (3.3820)	Learning Rate [0.00125]
8: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00100)	Tok/s 57659 (53712)	Loss/tok 3.5978 (3.3929)	Learning Rate [0.00125]
5: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00092)	Tok/s 57622 (53496)	Loss/tok 3.5027 (3.3939)	Learning Rate [0.00125]
4: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00099)	Tok/s 57597 (53433)	Loss/tok 3.4840 (3.3930)	Learning Rate [0.00125]
10: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00096)	Tok/s 57687 (53844)	Loss/tok 3.5530 (3.3823)	Learning Rate [0.00125]
3: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00093)	Tok/s 57015 (53326)	Loss/tok 3.5149 (3.4029)	Learning Rate [0.00125]
11: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00094)	Tok/s 57666 (53925)	Loss/tok 3.5674 (3.3853)	Learning Rate [0.00125]
2: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00112 (0.00097)	Tok/s 56631 (53234)	Loss/tok 3.3050 (3.3883)	Learning Rate [0.00125]
9: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00092)	Tok/s 57594 (53767)	Loss/tok 3.5020 (3.3782)	Learning Rate [0.00125]
1: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00097)	Tok/s 56642 (53142)	Loss/tok 3.4644 (3.3965)	Learning Rate [0.00125]
12: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00096)	Tok/s 57605 (54035)	Loss/tok 3.3416 (3.3861)	Learning Rate [0.00125]
0: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00100)	Tok/s 56625 (53045)	Loss/tok 3.6166 (3.3883)	Learning Rate [0.00125]
13: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00098)	Tok/s 57520 (54114)	Loss/tok 3.6444 (3.3833)	Learning Rate [0.00125]
15: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00092)	Tok/s 57570 (54310)	Loss/tok 3.6734 (3.3940)	Learning Rate [0.00125]
14: TRAIN [1][770/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00093)	Tok/s 57465 (54206)	Loss/tok 3.3179 (3.3957)	Learning Rate [0.00125]
2: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00097)	Tok/s 80074 (53296)	Loss/tok 3.2044 (3.3882)	Learning Rate [0.00125]
1: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00097)	Tok/s 79696 (53203)	Loss/tok 3.3514 (3.3965)	Learning Rate [0.00125]
0: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 79585 (53106)	Loss/tok 3.4763 (3.3883)	Learning Rate [0.00125]
3: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 80738 (53389)	Loss/tok 3.3520 (3.4026)	Learning Rate [0.00125]
13: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 81480 (54175)	Loss/tok 3.1682 (3.3833)	Learning Rate [0.00125]
4: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00099)	Tok/s 80764 (53496)	Loss/tok 3.1727 (3.3919)	Learning Rate [0.00125]
8: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00100)	Tok/s 80836 (53773)	Loss/tok 3.5403 (3.3931)	Learning Rate [0.00125]
7: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00097)	Tok/s 80867 (53704)	Loss/tok 3.0672 (3.3817)	Learning Rate [0.00125]
6: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 80842 (53623)	Loss/tok 3.3278 (3.3893)	Learning Rate [0.00125]
15: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 81552 (54372)	Loss/tok 3.4341 (3.3939)	Learning Rate [0.00125]
11: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00094)	Tok/s 81536 (53987)	Loss/tok 3.4146 (3.3858)	Learning Rate [0.00125]
12: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 81530 (54097)	Loss/tok 3.3266 (3.3864)	Learning Rate [0.00125]
14: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 81391 (54266)	Loss/tok 3.4119 (3.3954)	Learning Rate [0.00125]
10: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 81650 (53907)	Loss/tok 3.3500 (3.3824)	Learning Rate [0.00125]
5: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 80760 (53558)	Loss/tok 3.3005 (3.3941)	Learning Rate [0.00125]
9: TRAIN [1][780/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00092)	Tok/s 81058 (53830)	Loss/tok 3.3250 (3.3772)	Learning Rate [0.00125]
12: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00096)	Tok/s 50129 (54172)	Loss/tok 3.5610 (3.3858)	Learning Rate [0.00125]
13: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00098)	Tok/s 50151 (54249)	Loss/tok 3.5374 (3.3836)	Learning Rate [0.00125]
14: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00093)	Tok/s 50182 (54341)	Loss/tok 3.2107 (3.3950)	Learning Rate [0.00125]
11: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00094)	Tok/s 49983 (54062)	Loss/tok 3.2834 (3.3858)	Learning Rate [0.00125]
15: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00092)	Tok/s 50185 (54448)	Loss/tok 3.3356 (3.3927)	Learning Rate [0.00125]
9: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00092)	Tok/s 49804 (53905)	Loss/tok 3.5949 (3.3772)	Learning Rate [0.00125]
0: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00100)	Tok/s 50150 (53182)	Loss/tok 3.4324 (3.3891)	Learning Rate [0.00125]
10: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00096)	Tok/s 49854 (53982)	Loss/tok 3.4400 (3.3827)	Learning Rate [0.00125]
1: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00097)	Tok/s 50089 (53278)	Loss/tok 3.3020 (3.3963)	Learning Rate [0.00125]
8: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00100)	Tok/s 49720 (53848)	Loss/tok 3.5529 (3.3939)	Learning Rate [0.00125]
6: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00092)	Tok/s 49763 (53695)	Loss/tok 3.3236 (3.3887)	Learning Rate [0.00125]
2: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00098)	Tok/s 50014 (53370)	Loss/tok 3.3479 (3.3881)	Learning Rate [0.00125]
3: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00093)	Tok/s 49946 (53463)	Loss/tok 3.3348 (3.4025)	Learning Rate [0.00125]
4: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00099)	Tok/s 49863 (53568)	Loss/tok 3.4938 (3.3921)	Learning Rate [0.00125]
7: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00097)	Tok/s 49745 (53778)	Loss/tok 3.3902 (3.3809)	Learning Rate [0.00125]
5: TRAIN [1][790/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 49790 (53630)	Loss/tok 3.3641 (3.3936)	Learning Rate [0.00125]
1: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00097)	Tok/s 36703 (53250)	Loss/tok 3.2595 (3.3968)	Learning Rate [0.00125]
0: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00100)	Tok/s 35654 (53150)	Loss/tok 2.9937 (3.3894)	Learning Rate [0.00125]
2: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00119 (0.00098)	Tok/s 36696 (53347)	Loss/tok 3.0876 (3.3883)	Learning Rate [0.00125]
3: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 36647 (53441)	Loss/tok 3.1398 (3.4020)	Learning Rate [0.00125]
15: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00092)	Tok/s 36560 (54438)	Loss/tok 2.9977 (3.3921)	Learning Rate [0.00125]
4: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00099)	Tok/s 36518 (53547)	Loss/tok 2.8398 (3.3920)	Learning Rate [0.00125]
14: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00093)	Tok/s 36493 (54329)	Loss/tok 3.0214 (3.3940)	Learning Rate [0.00125]
6: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00092)	Tok/s 36466 (53678)	Loss/tok 3.2934 (3.3883)	Learning Rate [0.00125]
12: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00096)	Tok/s 36500 (54159)	Loss/tok 3.1129 (3.3855)	Learning Rate [0.00125]
13: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00098)	Tok/s 36488 (54236)	Loss/tok 3.4348 (3.3843)	Learning Rate [0.00125]
5: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00092)	Tok/s 36498 (53612)	Loss/tok 3.0925 (3.3933)	Learning Rate [0.00125]
11: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00093)	Tok/s 36468 (54048)	Loss/tok 3.3293 (3.3861)	Learning Rate [0.00125]
7: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00097)	Tok/s 36395 (53762)	Loss/tok 2.9438 (3.3812)	Learning Rate [0.00125]
10: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00096)	Tok/s 36453 (53967)	Loss/tok 3.3749 (3.3835)	Learning Rate [0.00125]
9: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00092)	Tok/s 36413 (53890)	Loss/tok 3.0644 (3.3769)	Learning Rate [0.00125]
8: TRAIN [1][800/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00100)	Tok/s 36383 (53834)	Loss/tok 3.3808 (3.3937)	Learning Rate [0.00125]
3: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00080 (0.00093)	Tok/s 32737 (53478)	Loss/tok 2.7891 (3.4017)	Learning Rate [0.00125]
6: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00081 (0.00092)	Tok/s 32567 (53715)	Loss/tok 2.9291 (3.3879)	Learning Rate [0.00125]
2: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00098)	Tok/s 32036 (53384)	Loss/tok 2.6265 (3.3873)	Learning Rate [0.00125]
4: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00099 (0.00099)	Tok/s 32600 (53583)	Loss/tok 2.8472 (3.3916)	Learning Rate [0.00125]
5: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00091 (0.00092)	Tok/s 32630 (53648)	Loss/tok 2.8382 (3.3922)	Learning Rate [0.00125]
1: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00084 (0.00097)	Tok/s 31172 (53287)	Loss/tok 2.6839 (3.3966)	Learning Rate [0.00125]
7: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00083 (0.00097)	Tok/s 32572 (53798)	Loss/tok 2.9186 (3.3811)	Learning Rate [0.00125]
0: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00085 (0.00100)	Tok/s 31014 (53187)	Loss/tok 2.8100 (3.3895)	Learning Rate [0.00125]
8: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00100)	Tok/s 32506 (53869)	Loss/tok 2.6791 (3.3937)	Learning Rate [0.00125]
9: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00096 (0.00092)	Tok/s 32491 (53927)	Loss/tok 2.8426 (3.3762)	Learning Rate [0.00125]
15: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00081 (0.00092)	Tok/s 33930 (54476)	Loss/tok 2.9025 (3.3916)	Learning Rate [0.00125]
14: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00087 (0.00093)	Tok/s 32453 (54364)	Loss/tok 3.0733 (3.3936)	Learning Rate [0.00125]
10: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00085 (0.00096)	Tok/s 32454 (54004)	Loss/tok 2.6825 (3.3831)	Learning Rate [0.00125]
13: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00078 (0.00098)	Tok/s 32388 (54272)	Loss/tok 2.8360 (3.3834)	Learning Rate [0.00125]
11: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00086 (0.00093)	Tok/s 32379 (54084)	Loss/tok 2.9406 (3.3856)	Learning Rate [0.00125]
12: TRAIN [1][810/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00096)	Tok/s 32463 (54195)	Loss/tok 2.7521 (3.3843)	Learning Rate [0.00125]
12: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00108 (0.00096)	Tok/s 40702 (54130)	Loss/tok 3.2209 (3.3838)	Learning Rate [0.00125]
11: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00093)	Tok/s 40717 (54020)	Loss/tok 3.1778 (3.3852)	Learning Rate [0.00125]
13: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00098)	Tok/s 40622 (54208)	Loss/tok 2.9664 (3.3825)	Learning Rate [0.00125]
10: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00096)	Tok/s 40709 (53939)	Loss/tok 3.1197 (3.3833)	Learning Rate [0.00125]
9: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00092)	Tok/s 40394 (53861)	Loss/tok 3.1354 (3.3757)	Learning Rate [0.00125]
14: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00093)	Tok/s 40620 (54299)	Loss/tok 3.0834 (3.3932)	Learning Rate [0.00125]
8: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00100)	Tok/s 39498 (53802)	Loss/tok 3.1736 (3.3943)	Learning Rate [0.00125]
0: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00100)	Tok/s 39365 (53125)	Loss/tok 3.2839 (3.3892)	Learning Rate [0.00125]
7: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00097)	Tok/s 39492 (53730)	Loss/tok 3.2799 (3.3812)	Learning Rate [0.00125]
1: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00097)	Tok/s 39368 (53224)	Loss/tok 3.2475 (3.3964)	Learning Rate [0.00125]
6: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00092)	Tok/s 39505 (53649)	Loss/tok 3.1604 (3.3884)	Learning Rate [0.00125]
15: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00092)	Tok/s 40626 (54409)	Loss/tok 3.1947 (3.3911)	Learning Rate [0.00125]
3: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00093)	Tok/s 39425 (53414)	Loss/tok 3.0592 (3.4011)	Learning Rate [0.00125]
5: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00092)	Tok/s 39457 (53583)	Loss/tok 3.2451 (3.3924)	Learning Rate [0.00125]
4: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00125 (0.00099)	Tok/s 39514 (53518)	Loss/tok 3.0640 (3.3914)	Learning Rate [0.00125]
2: TRAIN [1][820/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00098)	Tok/s 39479 (53320)	Loss/tok 3.2620 (3.3865)	Learning Rate [0.00125]
1: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00097)	Tok/s 34743 (53353)	Loss/tok 3.2822 (3.3962)	Learning Rate [0.00125]
0: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00100)	Tok/s 34690 (53254)	Loss/tok 2.9373 (3.3885)	Learning Rate [0.00125]
2: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00098)	Tok/s 34728 (53450)	Loss/tok 3.1494 (3.3853)	Learning Rate [0.00125]
15: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00092)	Tok/s 34607 (54540)	Loss/tok 3.1431 (3.3895)	Learning Rate [0.00125]
3: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00093)	Tok/s 34716 (53542)	Loss/tok 3.1166 (3.4007)	Learning Rate [0.00125]
14: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00093)	Tok/s 34525 (54429)	Loss/tok 3.1779 (3.3928)	Learning Rate [0.00125]
13: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00098)	Tok/s 34458 (54338)	Loss/tok 3.3631 (3.3833)	Learning Rate [0.00125]
4: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00111 (0.00100)	Tok/s 34723 (53649)	Loss/tok 3.1847 (3.3904)	Learning Rate [0.00125]
6: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00092)	Tok/s 34646 (53778)	Loss/tok 3.1176 (3.3874)	Learning Rate [0.00125]
5: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00092)	Tok/s 34743 (53713)	Loss/tok 2.9116 (3.3915)	Learning Rate [0.00125]
12: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00096)	Tok/s 34439 (54260)	Loss/tok 3.0393 (3.3842)	Learning Rate [0.00125]
11: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00093)	Tok/s 34453 (54149)	Loss/tok 3.0701 (3.3852)	Learning Rate [0.00125]
7: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00111 (0.00097)	Tok/s 34570 (53859)	Loss/tok 3.0804 (3.3810)	Learning Rate [0.00125]
8: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00117 (0.00100)	Tok/s 34512 (53930)	Loss/tok 3.2229 (3.3938)	Learning Rate [0.00125]
10: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00096)	Tok/s 34416 (54069)	Loss/tok 2.8157 (3.3823)	Learning Rate [0.00125]
9: TRAIN [1][830/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00092)	Tok/s 34455 (53990)	Loss/tok 3.1504 (3.3748)	Learning Rate [0.00125]
0: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00100)	Tok/s 73621 (53235)	Loss/tok 3.3406 (3.3881)	Learning Rate [0.00125]
1: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00097)	Tok/s 73856 (53335)	Loss/tok 3.4915 (3.3960)	Learning Rate [0.00125]
15: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00085 (0.00092)	Tok/s 74803 (54520)	Loss/tok 3.4545 (3.3889)	Learning Rate [0.00125]
14: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00087 (0.00093)	Tok/s 74832 (54410)	Loss/tok 3.4421 (3.3925)	Learning Rate [0.00125]
2: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00098)	Tok/s 73802 (53432)	Loss/tok 3.5995 (3.3860)	Learning Rate [0.00125]
12: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00099 (0.00096)	Tok/s 74933 (54239)	Loss/tok 3.2997 (3.3835)	Learning Rate [0.00125]
3: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00093)	Tok/s 73790 (53523)	Loss/tok 3.5168 (3.4014)	Learning Rate [0.00125]
13: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00086 (0.00098)	Tok/s 74726 (54318)	Loss/tok 3.2810 (3.3828)	Learning Rate [0.00125]
11: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00093)	Tok/s 74795 (54128)	Loss/tok 3.5468 (3.3852)	Learning Rate [0.00125]
4: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00107 (0.00100)	Tok/s 73742 (53629)	Loss/tok 3.5795 (3.3907)	Learning Rate [0.00125]
5: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00092)	Tok/s 73755 (53691)	Loss/tok 3.4147 (3.3912)	Learning Rate [0.00125]
6: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00088 (0.00092)	Tok/s 73795 (53756)	Loss/tok 3.2661 (3.3858)	Learning Rate [0.00125]
9: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00083 (0.00092)	Tok/s 74126 (53970)	Loss/tok 3.4447 (3.3752)	Learning Rate [0.00125]
10: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00096)	Tok/s 74819 (54049)	Loss/tok 3.5230 (3.3827)	Learning Rate [0.00125]
7: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00097)	Tok/s 73828 (53838)	Loss/tok 3.5065 (3.3811)	Learning Rate [0.00125]
8: TRAIN [1][840/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00100)	Tok/s 73828 (53909)	Loss/tok 3.2854 (3.3934)	Learning Rate [0.00125]
8: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00100)	Tok/s 59171 (53940)	Loss/tok 3.5088 (3.3939)	Learning Rate [0.00125]
6: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00092)	Tok/s 59236 (53785)	Loss/tok 3.5615 (3.3859)	Learning Rate [0.00125]
9: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00092)	Tok/s 59020 (54000)	Loss/tok 3.3778 (3.3756)	Learning Rate [0.00125]
7: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00106 (0.00097)	Tok/s 59120 (53868)	Loss/tok 3.7751 (3.3813)	Learning Rate [0.00125]
4: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00111 (0.00100)	Tok/s 59257 (53658)	Loss/tok 3.6070 (3.3914)	Learning Rate [0.00125]
5: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00092)	Tok/s 59187 (53720)	Loss/tok 3.4377 (3.3903)	Learning Rate [0.00125]
10: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00095)	Tok/s 58991 (54079)	Loss/tok 3.5515 (3.3824)	Learning Rate [0.00125]
11: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00093)	Tok/s 59095 (54158)	Loss/tok 3.5589 (3.3849)	Learning Rate [0.00125]
3: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00093)	Tok/s 59114 (53553)	Loss/tok 3.6089 (3.4011)	Learning Rate [0.00125]
2: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00098)	Tok/s 59086 (53461)	Loss/tok 3.5373 (3.3864)	Learning Rate [0.00125]
13: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00098)	Tok/s 59117 (54348)	Loss/tok 3.3196 (3.3827)	Learning Rate [0.00125]
12: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00096)	Tok/s 59105 (54269)	Loss/tok 3.4323 (3.3830)	Learning Rate [0.00125]
1: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00097)	Tok/s 59155 (53363)	Loss/tok 3.2433 (3.3951)	Learning Rate [0.00125]
14: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00093)	Tok/s 59092 (54440)	Loss/tok 3.5590 (3.3926)	Learning Rate [0.00125]
0: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00100)	Tok/s 59136 (53265)	Loss/tok 3.5289 (3.3881)	Learning Rate [0.00125]
15: TRAIN [1][850/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00092)	Tok/s 59351 (54549)	Loss/tok 3.3855 (3.3894)	Learning Rate [0.00125]
6: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00092)	Tok/s 30747 (53828)	Loss/tok 2.8264 (3.3852)	Learning Rate [0.00125]
7: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00097)	Tok/s 30834 (53911)	Loss/tok 2.6079 (3.3820)	Learning Rate [0.00125]
5: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00106 (0.00093)	Tok/s 30704 (53764)	Loss/tok 2.9377 (3.3904)	Learning Rate [0.00125]
9: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00092)	Tok/s 30796 (54046)	Loss/tok 2.8789 (3.3754)	Learning Rate [0.00125]
10: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00095)	Tok/s 30729 (54126)	Loss/tok 2.9945 (3.3828)	Learning Rate [0.00125]
4: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00108 (0.00100)	Tok/s 30574 (53701)	Loss/tok 2.9058 (3.3902)	Learning Rate [0.00125]
8: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00100)	Tok/s 30724 (53983)	Loss/tok 2.8619 (3.3937)	Learning Rate [0.00125]
2: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00098)	Tok/s 30446 (53506)	Loss/tok 2.7371 (3.3864)	Learning Rate [0.00125]
11: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00093)	Tok/s 30673 (54205)	Loss/tok 2.7188 (3.3847)	Learning Rate [0.00125]
12: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00096)	Tok/s 30686 (54315)	Loss/tok 2.8114 (3.3830)	Learning Rate [0.00125]
1: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00097)	Tok/s 30353 (53408)	Loss/tok 3.0708 (3.3953)	Learning Rate [0.00125]
0: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00099)	Tok/s 29084 (53309)	Loss/tok 2.8215 (3.3873)	Learning Rate [0.00125]
3: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00093)	Tok/s 30514 (53597)	Loss/tok 2.8610 (3.4002)	Learning Rate [0.00125]
13: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00098)	Tok/s 30592 (54392)	Loss/tok 2.5668 (3.3824)	Learning Rate [0.00125]
15: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00092)	Tok/s 31862 (54595)	Loss/tok 2.9391 (3.3893)	Learning Rate [0.00125]
14: TRAIN [1][860/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00093)	Tok/s 31401 (54485)	Loss/tok 2.7659 (3.3921)	Learning Rate [0.00125]
9: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 56398 (54064)	Loss/tok 3.6015 (3.3754)	Learning Rate [0.00125]
10: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00095)	Tok/s 56375 (54143)	Loss/tok 3.3760 (3.3825)	Learning Rate [0.00125]
11: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00093)	Tok/s 56275 (54221)	Loss/tok 3.5621 (3.3850)	Learning Rate [0.00125]
8: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00100)	Tok/s 56399 (54002)	Loss/tok 3.6067 (3.3945)	Learning Rate [0.00125]
12: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00096)	Tok/s 56199 (54333)	Loss/tok 3.3248 (3.3830)	Learning Rate [0.00125]
7: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00107 (0.00097)	Tok/s 56351 (53929)	Loss/tok 3.7416 (3.3828)	Learning Rate [0.00125]
6: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 56383 (53846)	Loss/tok 3.3077 (3.3853)	Learning Rate [0.00125]
13: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00098)	Tok/s 56113 (54410)	Loss/tok 3.5629 (3.3837)	Learning Rate [0.00125]
4: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00108 (0.00100)	Tok/s 56314 (53720)	Loss/tok 3.4660 (3.3906)	Learning Rate [0.00125]
5: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00093)	Tok/s 56412 (53782)	Loss/tok 3.7693 (3.3917)	Learning Rate [0.00125]
0: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00099)	Tok/s 55172 (53330)	Loss/tok 3.4986 (3.3880)	Learning Rate [0.00125]
15: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 56091 (54611)	Loss/tok 3.6089 (3.3903)	Learning Rate [0.00125]
3: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00093)	Tok/s 56230 (53617)	Loss/tok 3.6780 (3.4004)	Learning Rate [0.00125]
2: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00098)	Tok/s 55806 (53527)	Loss/tok 3.7101 (3.3878)	Learning Rate [0.00125]
14: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00108 (0.00093)	Tok/s 56117 (54503)	Loss/tok 3.3452 (3.3918)	Learning Rate [0.00125]
1: TRAIN [1][870/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00097)	Tok/s 55176 (53429)	Loss/tok 3.4985 (3.3961)	Learning Rate [0.00125]
1: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 80012 (53483)	Loss/tok 3.2602 (3.3959)	Learning Rate [0.00125]
2: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 79969 (53584)	Loss/tok 3.3160 (3.3882)	Learning Rate [0.00125]
0: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00099)	Tok/s 79993 (53380)	Loss/tok 3.2463 (3.3871)	Learning Rate [0.00125]
3: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 80590 (53677)	Loss/tok 3.3647 (3.4009)	Learning Rate [0.00125]
5: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00093)	Tok/s 80669 (53845)	Loss/tok 3.5446 (3.3920)	Learning Rate [0.00125]
7: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 80722 (53994)	Loss/tok 3.4592 (3.3830)	Learning Rate [0.00125]
9: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 80767 (54131)	Loss/tok 3.2798 (3.3749)	Learning Rate [0.00125]
4: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00100)	Tok/s 80682 (53783)	Loss/tok 3.3672 (3.3898)	Learning Rate [0.00125]
6: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 80663 (53910)	Loss/tok 3.4486 (3.3856)	Learning Rate [0.00125]
8: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00100)	Tok/s 80705 (54069)	Loss/tok 3.3394 (3.3937)	Learning Rate [0.00125]
15: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 81867 (54681)	Loss/tok 3.3425 (3.3899)	Learning Rate [0.00125]
10: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00095)	Tok/s 81599 (54212)	Loss/tok 3.4554 (3.3830)	Learning Rate [0.00125]
11: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 81721 (54291)	Loss/tok 3.2862 (3.3850)	Learning Rate [0.00125]
14: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00093)	Tok/s 81826 (54573)	Loss/tok 3.2253 (3.3916)	Learning Rate [0.00125]
13: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 81751 (54480)	Loss/tok 3.4633 (3.3833)	Learning Rate [0.00125]
12: TRAIN [1][880/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 81700 (54403)	Loss/tok 3.2480 (3.3822)	Learning Rate [0.00125]
0: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
14: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00093)	Tok/s 50620 (54593)	Loss/tok 3.2466 (3.3906)	Learning Rate [0.00125]
13: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00098)	Tok/s 50627 (54499)	Loss/tok 3.2168 (3.3823)	Learning Rate [0.00125]
15: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00092)	Tok/s 50567 (54701)	Loss/tok 3.1076 (3.3895)	Learning Rate [0.00125]
0: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00099)	Tok/s 50518 (53401)	Loss/tok 3.2326 (3.3875)	Learning Rate [0.00125]
12: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00096)	Tok/s 50633 (54422)	Loss/tok 3.2724 (3.3817)	Learning Rate [0.00125]
1: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00097)	Tok/s 50519 (53503)	Loss/tok 3.4802 (3.3955)	Learning Rate [0.00125]
11: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00093)	Tok/s 50663 (54309)	Loss/tok 3.3254 (3.3846)	Learning Rate [0.00125]
10: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00095)	Tok/s 50620 (54229)	Loss/tok 3.0345 (3.3826)	Learning Rate [0.00125]
2: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00098)	Tok/s 50579 (53604)	Loss/tok 3.3275 (3.3880)	Learning Rate [0.00125]
3: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 50549 (53697)	Loss/tok 3.1793 (3.3987)	Learning Rate [0.00125]
9: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 50608 (54147)	Loss/tok 3.3193 (3.3749)	Learning Rate [0.00125]
8: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00100)	Tok/s 50549 (54085)	Loss/tok 2.9530 (3.3934)	Learning Rate [0.00125]
4: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00100)	Tok/s 50504 (53802)	Loss/tok 3.1099 (3.3883)	Learning Rate [0.00125]
6: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00092)	Tok/s 50516 (53928)	Loss/tok 3.3389 (3.3855)	Learning Rate [0.00125]
7: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00097)	Tok/s 50616 (54011)	Loss/tok 3.2965 (3.3820)	Learning Rate [0.00125]
5: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00093)	Tok/s 50506 (53864)	Loss/tok 3.4540 (3.3916)	Learning Rate [0.00125]
9: Gradient norm: inf
10: Gradient norm: inf
1: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
11: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
6: Gradient norm: inf
7: Gradient norm: inf
5: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
3: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
15: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
6: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 47456 (53939)	Loss/tok 3.5252 (3.3849)	Learning Rate [0.00125]
5: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00093)	Tok/s 47461 (53876)	Loss/tok 3.4504 (3.3912)	Learning Rate [0.00125]
8: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00099)	Tok/s 48619 (54099)	Loss/tok 2.9015 (3.3928)	Learning Rate [0.00125]
4: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00100)	Tok/s 47464 (53814)	Loss/tok 3.5769 (3.3877)	Learning Rate [0.00125]
3: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00092)	Tok/s 47459 (53709)	Loss/tok 2.8792 (3.3972)	Learning Rate [0.00125]
7: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 48568 (54025)	Loss/tok 3.2280 (3.3815)	Learning Rate [0.00125]
2: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00098)	Tok/s 47465 (53616)	Loss/tok 3.1239 (3.3876)	Learning Rate [0.00125]
1: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00097)	Tok/s 47461 (53515)	Loss/tok 3.1822 (3.3962)	Learning Rate [0.00125]
9: TRAIN [1][900/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00092)	Tok/s 48432 (54161)	Loss/tok 3.1138 (3.3750)	Learning Rate [0.00125]
0: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00099)	Tok/s 47466 (53412)	Loss/tok 3.2704 (3.3866)	Learning Rate [0.00125]
12: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00096)	Tok/s 48631 (54437)	Loss/tok 3.1701 (3.3809)	Learning Rate [0.00125]
15: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00092)	Tok/s 48769 (54716)	Loss/tok 3.2827 (3.3890)	Learning Rate [0.00125]
10: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00095)	Tok/s 48515 (54244)	Loss/tok 3.1538 (3.3820)	Learning Rate [0.00125]
11: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00093)	Tok/s 48526 (54324)	Loss/tok 3.3950 (3.3845)	Learning Rate [0.00125]
14: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00093)	Tok/s 48656 (54607)	Loss/tok 3.5062 (3.3901)	Learning Rate [0.00125]
13: TRAIN [1][900/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00098)	Tok/s 48591 (54513)	Loss/tok 3.3683 (3.3823)	Learning Rate [0.00125]
7: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00098 (0.00097)	Tok/s 53196 (54015)	Loss/tok 3.2501 (3.3805)	Learning Rate [0.00125]
6: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00092)	Tok/s 53040 (53929)	Loss/tok 3.4236 (3.3849)	Learning Rate [0.00125]
8: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00099 (0.00099)	Tok/s 53095 (54089)	Loss/tok 3.3213 (3.3919)	Learning Rate [0.00125]
4: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00109 (0.00100)	Tok/s 52876 (53805)	Loss/tok 3.2809 (3.3876)	Learning Rate [0.00125]
5: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00093)	Tok/s 52921 (53866)	Loss/tok 3.5966 (3.3915)	Learning Rate [0.00125]
9: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00099 (0.00092)	Tok/s 53051 (54152)	Loss/tok 3.1320 (3.3747)	Learning Rate [0.00125]
10: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00095)	Tok/s 53026 (54234)	Loss/tok 3.5195 (3.3816)	Learning Rate [0.00125]
11: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00093)	Tok/s 53023 (54315)	Loss/tok 3.1703 (3.3841)	Learning Rate [0.00125]
2: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00099 (0.00098)	Tok/s 52709 (53609)	Loss/tok 3.3394 (3.3873)	Learning Rate [0.00125]
12: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00098 (0.00096)	Tok/s 52996 (54428)	Loss/tok 3.1659 (3.3811)	Learning Rate [0.00125]
1: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00100 (0.00097)	Tok/s 52729 (53508)	Loss/tok 3.5984 (3.3963)	Learning Rate [0.00125]
13: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00098)	Tok/s 52899 (54504)	Loss/tok 3.2286 (3.3825)	Learning Rate [0.00125]
0: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00098 (0.00099)	Tok/s 52727 (53407)	Loss/tok 3.8713 (3.3870)	Learning Rate [0.00125]
15: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00092)	Tok/s 52747 (54707)	Loss/tok 3.5850 (3.3892)	Learning Rate [0.00125]
14: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00093)	Tok/s 52791 (54599)	Loss/tok 3.3914 (3.3899)	Learning Rate [0.00125]
3: TRAIN [1][910/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00093)	Tok/s 52751 (53701)	Loss/tok 3.3657 (3.3974)	Learning Rate [0.00125]
2: TRAIN [1][920/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00098)	Tok/s 65770 (53576)	Loss/tok 3.4110 (3.3868)	Learning Rate [0.00125]
4: TRAIN [1][920/3416]	Time 0.069 (0.058)	Data 0.00114 (0.00100)	Tok/s 65686 (53772)	Loss/tok 3.5920 (3.3881)	Learning Rate [0.00125]
6: TRAIN [1][920/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 65515 (53896)	Loss/tok 3.6485 (3.3855)	Learning Rate [0.00125]
7: TRAIN [1][920/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 65563 (53983)	Loss/tok 3.4525 (3.3798)	Learning Rate [0.00125]
5: TRAIN [1][920/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00093)	Tok/s 65645 (53833)	Loss/tok 3.5974 (3.3923)	Learning Rate [0.00125]
1: TRAIN [1][920/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 65725 (53477)	Loss/tok 3.3402 (3.3954)	Learning Rate [0.00125]
0: TRAIN [1][920/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00099)	Tok/s 65604 (53376)	Loss/tok 3.5047 (3.3872)	Learning Rate [0.00125]
11: TRAIN [1][920/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 65433 (54283)	Loss/tok 3.5958 (3.3841)	Learning Rate [0.00125]
9: TRAIN [1][920/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 65223 (54120)	Loss/tok 3.4765 (3.3753)	Learning Rate [0.00125]
15: TRAIN [1][920/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 66510 (54672)	Loss/tok 3.4421 (3.3895)	Learning Rate [0.00125]
10: TRAIN [1][920/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00095)	Tok/s 65361 (54202)	Loss/tok 3.5002 (3.3815)	Learning Rate [0.00125]
14: TRAIN [1][920/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 65608 (54564)	Loss/tok 3.5136 (3.3897)	Learning Rate [0.00125]
8: TRAIN [1][920/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00099)	Tok/s 65377 (54058)	Loss/tok 3.4005 (3.3915)	Learning Rate [0.00125]
13: TRAIN [1][920/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00098)	Tok/s 65495 (54471)	Loss/tok 3.5763 (3.3831)	Learning Rate [0.00125]
3: TRAIN [1][920/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 65845 (53667)	Loss/tok 3.3716 (3.3974)	Learning Rate [0.00125]
12: TRAIN [1][920/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00096)	Tok/s 65191 (54395)	Loss/tok 3.6970 (3.3812)	Learning Rate [0.00125]
11: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00081 (0.00093)	Tok/s 61013 (54204)	Loss/tok 3.4341 (3.3844)	Learning Rate [0.00125]
9: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00092)	Tok/s 60859 (54041)	Loss/tok 3.5356 (3.3753)	Learning Rate [0.00125]
13: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00097)	Tok/s 60827 (54391)	Loss/tok 3.4231 (3.3835)	Learning Rate [0.00125]
12: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00096)	Tok/s 60918 (54315)	Loss/tok 3.4247 (3.3804)	Learning Rate [0.00125]
14: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00093)	Tok/s 60823 (54484)	Loss/tok 3.3969 (3.3897)	Learning Rate [0.00125]
10: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00095)	Tok/s 60936 (54122)	Loss/tok 3.4526 (3.3812)	Learning Rate [0.00125]
15: TRAIN [1][930/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00092)	Tok/s 61079 (54591)	Loss/tok 3.5342 (3.3889)	Learning Rate [0.00125]
8: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00099)	Tok/s 60819 (53980)	Loss/tok 3.4730 (3.3913)	Learning Rate [0.00125]
6: TRAIN [1][930/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 60594 (53819)	Loss/tok 3.5507 (3.3855)	Learning Rate [0.00125]
7: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00097)	Tok/s 60710 (53905)	Loss/tok 3.4811 (3.3796)	Learning Rate [0.00125]
4: TRAIN [1][930/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00100)	Tok/s 60563 (53693)	Loss/tok 3.5919 (3.3876)	Learning Rate [0.00125]
5: TRAIN [1][930/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00093)	Tok/s 60558 (53756)	Loss/tok 3.6115 (3.3916)	Learning Rate [0.00125]
0: TRAIN [1][930/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00099)	Tok/s 60497 (53298)	Loss/tok 3.4549 (3.3870)	Learning Rate [0.00125]
1: TRAIN [1][930/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00097)	Tok/s 60401 (53398)	Loss/tok 3.7674 (3.3955)	Learning Rate [0.00125]
2: TRAIN [1][930/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00098)	Tok/s 60328 (53497)	Loss/tok 3.5599 (3.3871)	Learning Rate [0.00125]
3: TRAIN [1][930/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00093)	Tok/s 60325 (53588)	Loss/tok 3.7477 (3.3973)	Learning Rate [0.00125]
7: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00097)	Tok/s 71719 (53837)	Loss/tok 3.4617 (3.3789)	Learning Rate [0.00125]
6: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 71624 (53750)	Loss/tok 3.5769 (3.3847)	Learning Rate [0.00125]
8: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00099)	Tok/s 71728 (53911)	Loss/tok 3.5149 (3.3902)	Learning Rate [0.00125]
9: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 71651 (53972)	Loss/tok 3.6877 (3.3753)	Learning Rate [0.00125]
5: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00093)	Tok/s 71328 (53687)	Loss/tok 3.2897 (3.3904)	Learning Rate [0.00125]
4: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00101)	Tok/s 70465 (53624)	Loss/tok 3.3959 (3.3876)	Learning Rate [0.00125]
11: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 71704 (54134)	Loss/tok 3.4925 (3.3836)	Learning Rate [0.00125]
10: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 71755 (54053)	Loss/tok 3.3323 (3.3806)	Learning Rate [0.00125]
2: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 70426 (53428)	Loss/tok 3.5670 (3.3868)	Learning Rate [0.00125]
12: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 71678 (54245)	Loss/tok 3.7559 (3.3802)	Learning Rate [0.00125]
1: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 70427 (53330)	Loss/tok 3.2564 (3.3945)	Learning Rate [0.00125]
15: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 71383 (54523)	Loss/tok 3.3857 (3.3879)	Learning Rate [0.00125]
14: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 71432 (54415)	Loss/tok 3.3629 (3.3889)	Learning Rate [0.00125]
13: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00097)	Tok/s 71487 (54322)	Loss/tok 3.4586 (3.3827)	Learning Rate [0.00125]
0: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00099)	Tok/s 70404 (53229)	Loss/tok 3.5021 (3.3872)	Learning Rate [0.00125]
3: TRAIN [1][940/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00093)	Tok/s 70324 (53518)	Loss/tok 3.6522 (3.3976)	Learning Rate [0.00125]
15: TRAIN [1][950/3416]	Time 0.051 (0.058)	Data 0.00080 (0.00092)	Tok/s 37326 (54414)	Loss/tok 2.9184 (3.3865)	Learning Rate [0.00125]
14: TRAIN [1][950/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00093)	Tok/s 37364 (54307)	Loss/tok 3.4760 (3.3881)	Learning Rate [0.00125]
0: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00099)	Tok/s 36008 (53106)	Loss/tok 3.1078 (3.3865)	Learning Rate [0.00125]
1: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00097)	Tok/s 35926 (53210)	Loss/tok 3.0642 (3.3939)	Learning Rate [0.00125]
13: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00097)	Tok/s 37210 (54213)	Loss/tok 3.0183 (3.3814)	Learning Rate [0.00125]
2: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00110 (0.00098)	Tok/s 35839 (53310)	Loss/tok 3.2955 (3.3860)	Learning Rate [0.00125]
12: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00096)	Tok/s 37102 (54133)	Loss/tok 3.0914 (3.3787)	Learning Rate [0.00125]
11: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00093)	Tok/s 37046 (54021)	Loss/tok 2.9085 (3.3827)	Learning Rate [0.00125]
10: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00096)	Tok/s 36970 (53940)	Loss/tok 3.3251 (3.3803)	Learning Rate [0.00125]
4: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00101)	Tok/s 35933 (53506)	Loss/tok 3.1684 (3.3870)	Learning Rate [0.00125]
9: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00092)	Tok/s 36904 (53859)	Loss/tok 3.1973 (3.3742)	Learning Rate [0.00125]
6: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00092)	Tok/s 36749 (53637)	Loss/tok 3.2338 (3.3843)	Learning Rate [0.00125]
5: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00093)	Tok/s 36852 (53572)	Loss/tok 3.1466 (3.3899)	Learning Rate [0.00125]
8: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00099)	Tok/s 36800 (53798)	Loss/tok 3.3100 (3.3898)	Learning Rate [0.00125]
7: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00082 (0.00097)	Tok/s 36702 (53723)	Loss/tok 3.0673 (3.3790)	Learning Rate [0.00125]
3: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00093)	Tok/s 35785 (53400)	Loss/tok 3.1184 (3.3970)	Learning Rate [0.00125]
11: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00093)	Tok/s 41630 (53976)	Loss/tok 3.2872 (3.3822)	Learning Rate [0.00125]
10: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00095)	Tok/s 41550 (53895)	Loss/tok 3.0057 (3.3805)	Learning Rate [0.00125]
9: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00092)	Tok/s 40234 (53812)	Loss/tok 3.1528 (3.3745)	Learning Rate [0.00125]
12: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00096)	Tok/s 41498 (54088)	Loss/tok 3.1119 (3.3786)	Learning Rate [0.00125]
13: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00097)	Tok/s 41386 (54168)	Loss/tok 3.1758 (3.3812)	Learning Rate [0.00125]
14: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00093)	Tok/s 41280 (54262)	Loss/tok 3.2427 (3.3885)	Learning Rate [0.00125]
7: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00097)	Tok/s 40130 (53675)	Loss/tok 3.0654 (3.3786)	Learning Rate [0.00125]
6: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00082 (0.00092)	Tok/s 39998 (53587)	Loss/tok 3.0873 (3.3842)	Learning Rate [0.00125]
5: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00093)	Tok/s 39902 (53523)	Loss/tok 3.0777 (3.3889)	Learning Rate [0.00125]
1: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00097)	Tok/s 39806 (53163)	Loss/tok 3.3918 (3.3932)	Learning Rate [0.00125]
0: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00099)	Tok/s 39787 (53061)	Loss/tok 3.0779 (3.3860)	Learning Rate [0.00125]
4: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00101)	Tok/s 39821 (53458)	Loss/tok 3.0666 (3.3876)	Learning Rate [0.00125]
2: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00098)	Tok/s 39741 (53262)	Loss/tok 2.9636 (3.3859)	Learning Rate [0.00125]
8: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00099)	Tok/s 39916 (53750)	Loss/tok 3.4936 (3.3911)	Learning Rate [0.00125]
15: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00092)	Tok/s 40935 (54368)	Loss/tok 3.2902 (3.3868)	Learning Rate [0.00125]
3: TRAIN [1][960/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00093)	Tok/s 39671 (53352)	Loss/tok 3.0910 (3.3961)	Learning Rate [0.00125]
1: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00106 (0.00097)	Tok/s 49833 (53179)	Loss/tok 3.2487 (3.3937)	Learning Rate [0.00125]
2: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00098)	Tok/s 49757 (53277)	Loss/tok 3.2879 (3.3856)	Learning Rate [0.00125]
4: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00100)	Tok/s 49618 (53472)	Loss/tok 3.1653 (3.3873)	Learning Rate [0.00125]
6: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00092)	Tok/s 49579 (53603)	Loss/tok 3.3432 (3.3856)	Learning Rate [0.00125]
5: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00093)	Tok/s 49530 (53538)	Loss/tok 3.4199 (3.3888)	Learning Rate [0.00125]
15: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00092)	Tok/s 49731 (54382)	Loss/tok 3.3518 (3.3875)	Learning Rate [0.00125]
0: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00099)	Tok/s 48659 (53076)	Loss/tok 3.1909 (3.3856)	Learning Rate [0.00125]
14: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00093)	Tok/s 49665 (54277)	Loss/tok 3.3828 (3.3884)	Learning Rate [0.00125]
7: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00109 (0.00097)	Tok/s 49552 (53690)	Loss/tok 3.2077 (3.3785)	Learning Rate [0.00125]
8: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00099)	Tok/s 49534 (53765)	Loss/tok 3.2103 (3.3918)	Learning Rate [0.00125]
9: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00092)	Tok/s 49546 (53826)	Loss/tok 3.2741 (3.3749)	Learning Rate [0.00125]
11: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00093)	Tok/s 49552 (53991)	Loss/tok 3.1210 (3.3820)	Learning Rate [0.00125]
13: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00097)	Tok/s 49696 (54183)	Loss/tok 3.1595 (3.3814)	Learning Rate [0.00125]
3: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00093)	Tok/s 49789 (53367)	Loss/tok 3.4036 (3.3968)	Learning Rate [0.00125]
10: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00095)	Tok/s 49540 (53910)	Loss/tok 3.0819 (3.3806)	Learning Rate [0.00125]
12: TRAIN [1][970/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00096)	Tok/s 49682 (54101)	Loss/tok 3.0615 (3.3787)	Learning Rate [0.00125]
4: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00100)	Tok/s 47860 (53436)	Loss/tok 3.1761 (3.3862)	Learning Rate [0.00125]
5: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00112 (0.00093)	Tok/s 47746 (53500)	Loss/tok 3.1389 (3.3886)	Learning Rate [0.00125]
2: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00098)	Tok/s 47835 (53242)	Loss/tok 3.1852 (3.3865)	Learning Rate [0.00125]
6: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00083 (0.00092)	Tok/s 47743 (53565)	Loss/tok 3.2629 (3.3862)	Learning Rate [0.00125]
1: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00097)	Tok/s 47848 (53144)	Loss/tok 3.2140 (3.3933)	Learning Rate [0.00125]
8: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00107 (0.00099)	Tok/s 47791 (53727)	Loss/tok 3.2808 (3.3925)	Learning Rate [0.00125]
0: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00103 (0.00099)	Tok/s 47810 (53040)	Loss/tok 3.2679 (3.3861)	Learning Rate [0.00125]
9: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00083 (0.00092)	Tok/s 47653 (53789)	Loss/tok 3.2351 (3.3757)	Learning Rate [0.00125]
3: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00127 (0.00093)	Tok/s 47856 (53331)	Loss/tok 3.2003 (3.3963)	Learning Rate [0.00125]
7: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00133 (0.00097)	Tok/s 47867 (53653)	Loss/tok 3.1965 (3.3793)	Learning Rate [0.00125]
11: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00093)	Tok/s 47664 (53953)	Loss/tok 3.1666 (3.3823)	Learning Rate [0.00125]
10: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00095)	Tok/s 47763 (53872)	Loss/tok 3.0280 (3.3809)	Learning Rate [0.00125]
12: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00096)	Tok/s 49130 (54064)	Loss/tok 3.2325 (3.3793)	Learning Rate [0.00125]
13: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00097)	Tok/s 49075 (54146)	Loss/tok 3.1259 (3.3816)	Learning Rate [0.00125]
15: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00111 (0.00092)	Tok/s 48978 (54343)	Loss/tok 3.3890 (3.3872)	Learning Rate [0.00125]
14: TRAIN [1][980/3416]	Time 0.044 (0.058)	Data 0.00108 (0.00093)	Tok/s 48993 (54238)	Loss/tok 3.5102 (3.3886)	Learning Rate [0.00125]
6: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00092)	Tok/s 50747 (53554)	Loss/tok 3.2078 (3.3857)	Learning Rate [0.00125]
11: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00093)	Tok/s 50558 (53939)	Loss/tok 3.0422 (3.3824)	Learning Rate [0.00125]
9: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00092)	Tok/s 50665 (53776)	Loss/tok 3.1104 (3.3754)	Learning Rate [0.00125]
10: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00095)	Tok/s 50588 (53860)	Loss/tok 3.3510 (3.3799)	Learning Rate [0.00125]
8: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00099)	Tok/s 50660 (53714)	Loss/tok 3.4296 (3.3925)	Learning Rate [0.00125]
7: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00097)	Tok/s 50774 (53642)	Loss/tok 2.9088 (3.3796)	Learning Rate [0.00125]
5: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00093)	Tok/s 50769 (53490)	Loss/tok 3.3840 (3.3883)	Learning Rate [0.00125]
4: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00100)	Tok/s 50655 (53425)	Loss/tok 3.1242 (3.3857)	Learning Rate [0.00125]
12: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00096)	Tok/s 50528 (54049)	Loss/tok 3.3615 (3.3788)	Learning Rate [0.00125]
2: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00098)	Tok/s 50567 (53233)	Loss/tok 3.3431 (3.3863)	Learning Rate [0.00125]
13: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00097)	Tok/s 50840 (54131)	Loss/tok 3.4039 (3.3814)	Learning Rate [0.00125]
1: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00097)	Tok/s 50544 (53136)	Loss/tok 3.4116 (3.3928)	Learning Rate [0.00125]
14: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00093)	Tok/s 50602 (54224)	Loss/tok 3.1808 (3.3879)	Learning Rate [0.00125]
0: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00099)	Tok/s 50578 (53027)	Loss/tok 3.3185 (3.3858)	Learning Rate [0.00125]
15: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00092)	Tok/s 50603 (54328)	Loss/tok 3.3011 (3.3877)	Learning Rate [0.00125]
3: TRAIN [1][990/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00093)	Tok/s 50466 (53322)	Loss/tok 3.1368 (3.3965)	Learning Rate [0.00125]
4: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00100)	Tok/s 76898 (53458)	Loss/tok 3.4579 (3.3867)	Learning Rate [0.00125]
6: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00092)	Tok/s 77137 (53588)	Loss/tok 3.2569 (3.3855)	Learning Rate [0.00125]
5: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 77083 (53524)	Loss/tok 3.5095 (3.3880)	Learning Rate [0.00125]
3: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 77055 (53352)	Loss/tok 3.3745 (3.3953)	Learning Rate [0.00125]
2: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 76541 (53262)	Loss/tok 3.4016 (3.3863)	Learning Rate [0.00125]
7: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 77120 (53676)	Loss/tok 3.4685 (3.3793)	Learning Rate [0.00125]
1: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00097)	Tok/s 76014 (53163)	Loss/tok 3.4390 (3.3925)	Learning Rate [0.00125]
8: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00099)	Tok/s 76983 (53750)	Loss/tok 3.2015 (3.3916)	Learning Rate [0.00125]
11: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 78179 (53978)	Loss/tok 3.2193 (3.3817)	Learning Rate [0.00125]
9: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 77135 (53812)	Loss/tok 3.5943 (3.3755)	Learning Rate [0.00125]
10: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00095)	Tok/s 77378 (53897)	Loss/tok 3.4045 (3.3795)	Learning Rate [0.00125]
15: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 77954 (54369)	Loss/tok 3.4857 (3.3874)	Learning Rate [0.00125]
12: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00096)	Tok/s 78117 (54088)	Loss/tok 3.4812 (3.3790)	Learning Rate [0.00125]
14: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 78008 (54263)	Loss/tok 3.5245 (3.3868)	Learning Rate [0.00125]
0: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00099)	Tok/s 76127 (53051)	Loss/tok 3.5057 (3.3859)	Learning Rate [0.00125]
13: TRAIN [1][1000/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 78072 (54169)	Loss/tok 3.1935 (3.3810)	Learning Rate [0.00125]
14: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 81572 (54301)	Loss/tok 3.2260 (3.3868)	Learning Rate [0.00125]
15: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 81821 (54407)	Loss/tok 3.2578 (3.3867)	Learning Rate [0.00125]
12: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 81353 (54124)	Loss/tok 3.4417 (3.3786)	Learning Rate [0.00125]
9: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 81479 (53850)	Loss/tok 3.2189 (3.3750)	Learning Rate [0.00125]
10: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00095)	Tok/s 81398 (53934)	Loss/tok 3.3587 (3.3797)	Learning Rate [0.00125]
0: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00099)	Tok/s 79716 (53089)	Loss/tok 3.1163 (3.3859)	Learning Rate [0.00125]
1: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00097)	Tok/s 79868 (53201)	Loss/tok 3.5390 (3.3921)	Learning Rate [0.00125]
8: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00099)	Tok/s 80664 (53788)	Loss/tok 3.2835 (3.3911)	Learning Rate [0.00125]
2: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 80455 (53300)	Loss/tok 3.2351 (3.3854)	Learning Rate [0.00125]
6: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 80606 (53627)	Loss/tok 3.2869 (3.3858)	Learning Rate [0.00125]
13: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 81291 (54206)	Loss/tok 3.5311 (3.3814)	Learning Rate [0.00125]
3: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00093)	Tok/s 80695 (53390)	Loss/tok 3.2652 (3.3952)	Learning Rate [0.00125]
7: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 80602 (53714)	Loss/tok 3.3153 (3.3787)	Learning Rate [0.00125]
5: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00093)	Tok/s 80604 (53563)	Loss/tok 3.4119 (3.3882)	Learning Rate [0.00125]
4: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00100)	Tok/s 80551 (53496)	Loss/tok 3.5229 (3.3864)	Learning Rate [0.00125]
11: TRAIN [1][1010/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 81318 (54015)	Loss/tok 3.4423 (3.3821)	Learning Rate [0.00125]
10: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00095)	Tok/s 61560 (54014)	Loss/tok 3.4488 (3.3803)	Learning Rate [0.00125]
12: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00096)	Tok/s 61585 (54203)	Loss/tok 3.3740 (3.3791)	Learning Rate [0.00125]
9: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 61598 (53930)	Loss/tok 3.8222 (3.3753)	Learning Rate [0.00125]
14: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 61619 (54381)	Loss/tok 3.3319 (3.3868)	Learning Rate [0.00125]
13: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 61571 (54286)	Loss/tok 3.4239 (3.3818)	Learning Rate [0.00125]
15: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 61590 (54488)	Loss/tok 3.4301 (3.3868)	Learning Rate [0.00125]
8: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00099)	Tok/s 61618 (53869)	Loss/tok 3.6197 (3.3917)	Learning Rate [0.00125]
6: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00091)	Tok/s 61587 (53707)	Loss/tok 3.7023 (3.3864)	Learning Rate [0.00125]
7: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 61622 (53795)	Loss/tok 3.4340 (3.3792)	Learning Rate [0.00125]
0: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 60921 (53168)	Loss/tok 3.4663 (3.3861)	Learning Rate [0.00125]
1: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00097)	Tok/s 61635 (53281)	Loss/tok 3.6938 (3.3926)	Learning Rate [0.00125]
5: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 61622 (53643)	Loss/tok 3.6526 (3.3892)	Learning Rate [0.00125]
3: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 61623 (53469)	Loss/tok 3.4617 (3.3959)	Learning Rate [0.00125]
4: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00100)	Tok/s 61513 (53575)	Loss/tok 3.5757 (3.3873)	Learning Rate [0.00125]
11: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 61559 (54094)	Loss/tok 3.5039 (3.3836)	Learning Rate [0.00125]
2: TRAIN [1][1020/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00098)	Tok/s 61629 (53379)	Loss/tok 3.5202 (3.3859)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
8: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00099)	Tok/s 70817 (53922)	Loss/tok 3.6535 (3.3915)	Learning Rate [0.00125]
10: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00095)	Tok/s 71638 (54068)	Loss/tok 3.1411 (3.3806)	Learning Rate [0.00125]
7: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 70798 (53848)	Loss/tok 3.4829 (3.3796)	Learning Rate [0.00125]
6: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00091)	Tok/s 70634 (53760)	Loss/tok 3.6456 (3.3866)	Learning Rate [0.00125]
9: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 71575 (53983)	Loss/tok 3.3996 (3.3750)	Learning Rate [0.00125]
12: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 71592 (54259)	Loss/tok 3.2812 (3.3795)	Learning Rate [0.00125]
5: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 70644 (53696)	Loss/tok 3.6130 (3.3896)	Learning Rate [0.00125]
13: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 71427 (54342)	Loss/tok 3.3444 (3.3820)	Learning Rate [0.00125]
4: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00100)	Tok/s 70787 (53629)	Loss/tok 3.6911 (3.3878)	Learning Rate [0.00125]
3: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 70760 (53524)	Loss/tok 3.4126 (3.3948)	Learning Rate [0.00125]
14: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00093)	Tok/s 71577 (54437)	Loss/tok 3.4105 (3.3871)	Learning Rate [0.00125]
2: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00098)	Tok/s 70866 (53434)	Loss/tok 3.4368 (3.3863)	Learning Rate [0.00125]
15: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 71559 (54544)	Loss/tok 3.6567 (3.3864)	Learning Rate [0.00125]
1: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 70718 (53335)	Loss/tok 3.2763 (3.3939)	Learning Rate [0.00125]
0: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00099)	Tok/s 70649 (53223)	Loss/tok 3.5465 (3.3867)	Learning Rate [0.00125]
11: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 71479 (54149)	Loss/tok 3.6152 (3.3837)	Learning Rate [0.00125]
2: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
4: Gradient norm: inf
5: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
14: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
12: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
4: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00109 (0.00100)	Tok/s 52568 (53682)	Loss/tok 3.4030 (3.3881)	Learning Rate [0.00125]
2: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00109 (0.00098)	Tok/s 52607 (53489)	Loss/tok 3.3269 (3.3867)	Learning Rate [0.00125]
6: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00091)	Tok/s 52362 (53813)	Loss/tok 3.4651 (3.3871)	Learning Rate [0.00125]
5: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00093)	Tok/s 52445 (53749)	Loss/tok 3.3181 (3.3904)	Learning Rate [0.00125]
15: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00113 (0.00092)	Tok/s 53552 (54598)	Loss/tok 3.5125 (3.3863)	Learning Rate [0.00125]
1: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00097)	Tok/s 52535 (53391)	Loss/tok 3.5391 (3.3943)	Learning Rate [0.00125]
3: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00111 (0.00093)	Tok/s 52655 (53578)	Loss/tok 3.3262 (3.3951)	Learning Rate [0.00125]
9: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00092)	Tok/s 52330 (54036)	Loss/tok 3.1078 (3.3749)	Learning Rate [0.00125]
0: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00099)	Tok/s 52516 (53279)	Loss/tok 3.2430 (3.3865)	Learning Rate [0.00125]
7: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00097)	Tok/s 52276 (53900)	Loss/tok 3.4343 (3.3799)	Learning Rate [0.00125]
8: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00108 (0.00099)	Tok/s 52270 (53973)	Loss/tok 3.5127 (3.3917)	Learning Rate [0.00125]
11: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00093)	Tok/s 52948 (54203)	Loss/tok 3.3263 (3.3835)	Learning Rate [0.00125]
14: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00093)	Tok/s 53358 (54490)	Loss/tok 3.3794 (3.3866)	Learning Rate [0.00125]
13: TRAIN [1][1040/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00097)	Tok/s 53267 (54395)	Loss/tok 3.3442 (3.3822)	Learning Rate [0.00125]
10: TRAIN [1][1040/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00095)	Tok/s 52119 (54121)	Loss/tok 3.2490 (3.3808)	Learning Rate [0.00125]
12: TRAIN [1][1040/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00096)	Tok/s 53151 (54313)	Loss/tok 3.3959 (3.3798)	Learning Rate [0.00125]
7: TRAIN [1][1050/3416]	Time 0.064 (0.058)	Data 0.00099 (0.00097)	Tok/s 53858 (53890)	Loss/tok 3.5746 (3.3801)	Learning Rate [0.00125]
6: TRAIN [1][1050/3416]	Time 0.064 (0.058)	Data 0.00104 (0.00091)	Tok/s 53930 (53802)	Loss/tok 3.4517 (3.3865)	Learning Rate [0.00125]
8: TRAIN [1][1050/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00099)	Tok/s 53966 (53963)	Loss/tok 3.4234 (3.3913)	Learning Rate [0.00125]
5: TRAIN [1][1050/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00093)	Tok/s 53626 (53738)	Loss/tok 3.3048 (3.3900)	Learning Rate [0.00125]
9: TRAIN [1][1050/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00092)	Tok/s 53900 (54026)	Loss/tok 3.4500 (3.3751)	Learning Rate [0.00125]
4: TRAIN [1][1050/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00100)	Tok/s 52698 (53671)	Loss/tok 3.5666 (3.3880)	Learning Rate [0.00125]
3: TRAIN [1][1050/3416]	Time 0.064 (0.058)	Data 0.00084 (0.00093)	Tok/s 52632 (53567)	Loss/tok 3.6267 (3.3950)	Learning Rate [0.00125]
10: TRAIN [1][1050/3416]	Time 0.064 (0.058)	Data 0.00099 (0.00095)	Tok/s 53637 (54113)	Loss/tok 3.2984 (3.3811)	Learning Rate [0.00125]
11: TRAIN [1][1050/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00093)	Tok/s 53491 (54194)	Loss/tok 3.5060 (3.3835)	Learning Rate [0.00125]
2: TRAIN [1][1050/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00098)	Tok/s 52505 (53478)	Loss/tok 3.6405 (3.3865)	Learning Rate [0.00125]
1: TRAIN [1][1050/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00097)	Tok/s 52436 (53380)	Loss/tok 3.4818 (3.3939)	Learning Rate [0.00125]
13: TRAIN [1][1050/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00097)	Tok/s 53408 (54385)	Loss/tok 3.7141 (3.3829)	Learning Rate [0.00125]
12: TRAIN [1][1050/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00096)	Tok/s 53393 (54303)	Loss/tok 3.3636 (3.3797)	Learning Rate [0.00125]
0: TRAIN [1][1050/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00099)	Tok/s 52320 (53270)	Loss/tok 3.7260 (3.3872)	Learning Rate [0.00125]
14: TRAIN [1][1050/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00093)	Tok/s 53306 (54479)	Loss/tok 3.2732 (3.3864)	Learning Rate [0.00125]
15: TRAIN [1][1050/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00092)	Tok/s 53237 (54586)	Loss/tok 3.6913 (3.3860)	Learning Rate [0.00125]
14: TRAIN [1][1060/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00093)	Tok/s 53598 (54446)	Loss/tok 3.3728 (3.3863)	Learning Rate [0.00125]
15: TRAIN [1][1060/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00092)	Tok/s 53468 (54556)	Loss/tok 3.3352 (3.3854)	Learning Rate [0.00125]
0: TRAIN [1][1060/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00099)	Tok/s 53385 (53239)	Loss/tok 3.4868 (3.3875)	Learning Rate [0.00125]
13: TRAIN [1][1060/3416]	Time 0.061 (0.058)	Data 0.00106 (0.00097)	Tok/s 53546 (54352)	Loss/tok 3.6667 (3.3826)	Learning Rate [0.00125]
11: TRAIN [1][1060/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00093)	Tok/s 53455 (54161)	Loss/tok 3.4469 (3.3832)	Learning Rate [0.00125]
12: TRAIN [1][1060/3416]	Time 0.061 (0.058)	Data 0.00102 (0.00096)	Tok/s 53529 (54270)	Loss/tok 3.2859 (3.3788)	Learning Rate [0.00125]
1: TRAIN [1][1060/3416]	Time 0.061 (0.058)	Data 0.00101 (0.00097)	Tok/s 53261 (53349)	Loss/tok 3.5809 (3.3943)	Learning Rate [0.00125]
9: TRAIN [1][1060/3416]	Time 0.061 (0.058)	Data 0.00104 (0.00092)	Tok/s 53232 (53993)	Loss/tok 3.1440 (3.3749)	Learning Rate [0.00125]
10: TRAIN [1][1060/3416]	Time 0.061 (0.058)	Data 0.00101 (0.00095)	Tok/s 53349 (54080)	Loss/tok 3.5020 (3.3808)	Learning Rate [0.00125]
3: TRAIN [1][1060/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00093)	Tok/s 53074 (53534)	Loss/tok 3.0012 (3.3941)	Learning Rate [0.00125]
2: TRAIN [1][1060/3416]	Time 0.061 (0.058)	Data 0.00108 (0.00098)	Tok/s 53127 (53445)	Loss/tok 3.5435 (3.3863)	Learning Rate [0.00125]
8: TRAIN [1][1060/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00099)	Tok/s 53084 (53929)	Loss/tok 3.7150 (3.3911)	Learning Rate [0.00125]
6: TRAIN [1][1060/3416]	Time 0.062 (0.058)	Data 0.00084 (0.00091)	Tok/s 52918 (53768)	Loss/tok 3.1974 (3.3869)	Learning Rate [0.00125]
4: TRAIN [1][1060/3416]	Time 0.062 (0.058)	Data 0.00115 (0.00100)	Tok/s 52948 (53638)	Loss/tok 3.5130 (3.3876)	Learning Rate [0.00125]
5: TRAIN [1][1060/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00093)	Tok/s 52900 (53705)	Loss/tok 3.2330 (3.3889)	Learning Rate [0.00125]
7: TRAIN [1][1060/3416]	Time 0.062 (0.058)	Data 0.00107 (0.00097)	Tok/s 52996 (53855)	Loss/tok 3.1808 (3.3797)	Learning Rate [0.00125]
2: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00098)	Tok/s 71433 (53442)	Loss/tok 3.4625 (3.3859)	Learning Rate [0.00125]
1: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00097)	Tok/s 71458 (53346)	Loss/tok 3.7879 (3.3945)	Learning Rate [0.00125]
3: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 71363 (53530)	Loss/tok 3.4192 (3.3934)	Learning Rate [0.00125]
4: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00100)	Tok/s 71756 (53635)	Loss/tok 3.4724 (3.3869)	Learning Rate [0.00125]
15: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 72973 (54550)	Loss/tok 3.4550 (3.3851)	Learning Rate [0.00125]
0: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00099)	Tok/s 71435 (53237)	Loss/tok 3.2787 (3.3865)	Learning Rate [0.00125]
6: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 72200 (53766)	Loss/tok 3.3791 (3.3866)	Learning Rate [0.00125]
5: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 72228 (53703)	Loss/tok 3.5301 (3.3891)	Learning Rate [0.00125]
14: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 72427 (54438)	Loss/tok 3.4813 (3.3865)	Learning Rate [0.00125]
7: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 72220 (53852)	Loss/tok 3.6196 (3.3795)	Learning Rate [0.00125]
13: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 72398 (54344)	Loss/tok 3.4376 (3.3822)	Learning Rate [0.00125]
12: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 72412 (54263)	Loss/tok 3.6874 (3.3790)	Learning Rate [0.00125]
11: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 72487 (54155)	Loss/tok 3.6292 (3.3831)	Learning Rate [0.00125]
8: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00099)	Tok/s 72155 (53925)	Loss/tok 3.3135 (3.3907)	Learning Rate [0.00125]
10: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00095)	Tok/s 72200 (54074)	Loss/tok 3.7172 (3.3813)	Learning Rate [0.00125]
9: TRAIN [1][1070/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 71779 (53988)	Loss/tok 3.4091 (3.3745)	Learning Rate [0.00125]
5: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00093)	Tok/s 32541 (53740)	Loss/tok 2.9827 (3.3894)	Learning Rate [0.00125]
6: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00081 (0.00091)	Tok/s 32516 (53803)	Loss/tok 3.0599 (3.3870)	Learning Rate [0.00125]
4: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00100)	Tok/s 32453 (53672)	Loss/tok 2.9252 (3.3866)	Learning Rate [0.00125]
3: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00093)	Tok/s 32396 (53567)	Loss/tok 3.1748 (3.3937)	Learning Rate [0.00125]
7: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00097)	Tok/s 32482 (53889)	Loss/tok 2.9998 (3.3805)	Learning Rate [0.00125]
2: TRAIN [1][1080/3416]	Time 0.050 (0.058)	Data 0.00107 (0.00098)	Tok/s 32299 (53480)	Loss/tok 2.8543 (3.3863)	Learning Rate [0.00125]
1: TRAIN [1][1080/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00097)	Tok/s 32212 (53384)	Loss/tok 3.3180 (3.3949)	Learning Rate [0.00125]
9: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00092)	Tok/s 32425 (54025)	Loss/tok 2.9677 (3.3753)	Learning Rate [0.00125]
0: TRAIN [1][1080/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00099)	Tok/s 32159 (53276)	Loss/tok 3.1420 (3.3879)	Learning Rate [0.00125]
8: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00099)	Tok/s 32459 (53961)	Loss/tok 3.1236 (3.3917)	Learning Rate [0.00125]
15: TRAIN [1][1080/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 33372 (54586)	Loss/tok 3.1114 (3.3857)	Learning Rate [0.00125]
10: TRAIN [1][1080/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00095)	Tok/s 32259 (54110)	Loss/tok 3.1907 (3.3818)	Learning Rate [0.00125]
11: TRAIN [1][1080/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00093)	Tok/s 33077 (54193)	Loss/tok 2.8716 (3.3834)	Learning Rate [0.00125]
14: TRAIN [1][1080/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00093)	Tok/s 33363 (54475)	Loss/tok 2.8834 (3.3874)	Learning Rate [0.00125]
13: TRAIN [1][1080/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00097)	Tok/s 33376 (54382)	Loss/tok 3.0767 (3.3826)	Learning Rate [0.00125]
12: TRAIN [1][1080/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00096)	Tok/s 33368 (54300)	Loss/tok 2.7149 (3.3785)	Learning Rate [0.00125]
0: TRAIN [1][1090/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00099)	Tok/s 51135 (53302)	Loss/tok 3.1344 (3.3878)	Learning Rate [0.00125]
1: TRAIN [1][1090/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00097)	Tok/s 51876 (53411)	Loss/tok 3.3740 (3.3951)	Learning Rate [0.00125]
2: TRAIN [1][1090/3416]	Time 0.055 (0.058)	Data 0.00113 (0.00098)	Tok/s 52096 (53507)	Loss/tok 3.2397 (3.3867)	Learning Rate [0.00125]
15: TRAIN [1][1090/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00092)	Tok/s 52237 (54607)	Loss/tok 3.0959 (3.3863)	Learning Rate [0.00125]
14: TRAIN [1][1090/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00093)	Tok/s 52193 (54497)	Loss/tok 3.5061 (3.3883)	Learning Rate [0.00125]
3: TRAIN [1][1090/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00093)	Tok/s 51963 (53593)	Loss/tok 3.0790 (3.3934)	Learning Rate [0.00125]
13: TRAIN [1][1090/3416]	Time 0.055 (0.058)	Data 0.00116 (0.00097)	Tok/s 52146 (54405)	Loss/tok 3.4933 (3.3836)	Learning Rate [0.00125]
6: TRAIN [1][1090/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00091)	Tok/s 51758 (53827)	Loss/tok 3.3019 (3.3878)	Learning Rate [0.00125]
12: TRAIN [1][1090/3416]	Time 0.055 (0.058)	Data 0.00102 (0.00096)	Tok/s 52060 (54323)	Loss/tok 3.5361 (3.3785)	Learning Rate [0.00125]
11: TRAIN [1][1090/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00093)	Tok/s 51882 (54217)	Loss/tok 3.4022 (3.3842)	Learning Rate [0.00125]
4: TRAIN [1][1090/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00100)	Tok/s 51842 (53697)	Loss/tok 3.3869 (3.3866)	Learning Rate [0.00125]
5: TRAIN [1][1090/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00093)	Tok/s 51806 (53764)	Loss/tok 3.4719 (3.3898)	Learning Rate [0.00125]
8: TRAIN [1][1090/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00099)	Tok/s 51715 (53985)	Loss/tok 3.2606 (3.3915)	Learning Rate [0.00125]
9: TRAIN [1][1090/3416]	Time 0.056 (0.058)	Data 0.00103 (0.00092)	Tok/s 51718 (54048)	Loss/tok 3.0698 (3.3757)	Learning Rate [0.00125]
10: TRAIN [1][1090/3416]	Time 0.056 (0.058)	Data 0.00099 (0.00095)	Tok/s 51858 (54134)	Loss/tok 3.2157 (3.3820)	Learning Rate [0.00125]
7: TRAIN [1][1090/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00097)	Tok/s 51623 (53913)	Loss/tok 3.3247 (3.3813)	Learning Rate [0.00125]
1: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00097)	Tok/s 37844 (53437)	Loss/tok 2.9920 (3.3955)	Learning Rate [0.00125]
0: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00099)	Tok/s 37816 (53328)	Loss/tok 3.1124 (3.3880)	Learning Rate [0.00125]
15: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00092)	Tok/s 39010 (54629)	Loss/tok 3.1543 (3.3859)	Learning Rate [0.00125]
14: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 38941 (54519)	Loss/tok 3.2716 (3.3879)	Learning Rate [0.00125]
13: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00097)	Tok/s 38886 (54427)	Loss/tok 3.2691 (3.3841)	Learning Rate [0.00125]
2: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00098)	Tok/s 37743 (53531)	Loss/tok 3.2239 (3.3868)	Learning Rate [0.00125]
3: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00093)	Tok/s 37688 (53617)	Loss/tok 3.1543 (3.3929)	Learning Rate [0.00125]
4: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00100)	Tok/s 37570 (53719)	Loss/tok 3.2165 (3.3868)	Learning Rate [0.00125]
11: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00122 (0.00093)	Tok/s 38814 (54240)	Loss/tok 2.9602 (3.3850)	Learning Rate [0.00125]
9: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00092)	Tok/s 38812 (54071)	Loss/tok 2.9614 (3.3759)	Learning Rate [0.00125]
12: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00096)	Tok/s 38778 (54346)	Loss/tok 3.4447 (3.3787)	Learning Rate [0.00125]
6: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00077 (0.00091)	Tok/s 37525 (53849)	Loss/tok 3.3161 (3.3876)	Learning Rate [0.00125]
5: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00093)	Tok/s 37514 (53787)	Loss/tok 3.3398 (3.3900)	Learning Rate [0.00125]
10: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00095)	Tok/s 38742 (54157)	Loss/tok 3.4500 (3.3824)	Learning Rate [0.00125]
7: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00097)	Tok/s 37542 (53934)	Loss/tok 2.9182 (3.3815)	Learning Rate [0.00125]
8: TRAIN [1][1100/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00099)	Tok/s 38706 (54007)	Loss/tok 2.8764 (3.3911)	Learning Rate [0.00125]
9: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00092)	Tok/s 47220 (54069)	Loss/tok 3.1808 (3.3754)	Learning Rate [0.00125]
8: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00099)	Tok/s 47087 (54006)	Loss/tok 3.2682 (3.3906)	Learning Rate [0.00125]
7: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00097)	Tok/s 47012 (53933)	Loss/tok 3.1858 (3.3812)	Learning Rate [0.00125]
6: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00091)	Tok/s 46986 (53848)	Loss/tok 3.1822 (3.3878)	Learning Rate [0.00125]
10: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00095)	Tok/s 47113 (54155)	Loss/tok 2.9126 (3.3821)	Learning Rate [0.00125]
11: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00093)	Tok/s 47180 (54238)	Loss/tok 3.3901 (3.3851)	Learning Rate [0.00125]
12: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00096)	Tok/s 47127 (54343)	Loss/tok 3.1211 (3.3788)	Learning Rate [0.00125]
4: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00100)	Tok/s 46296 (53715)	Loss/tok 3.2579 (3.3870)	Learning Rate [0.00125]
5: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00093)	Tok/s 46939 (53785)	Loss/tok 3.4183 (3.3897)	Learning Rate [0.00125]
13: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00108 (0.00097)	Tok/s 47141 (54424)	Loss/tok 3.3811 (3.3833)	Learning Rate [0.00125]
14: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00093)	Tok/s 47139 (54515)	Loss/tok 3.0017 (3.3876)	Learning Rate [0.00125]
3: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00093)	Tok/s 45512 (53613)	Loss/tok 3.3718 (3.3924)	Learning Rate [0.00125]
15: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00092)	Tok/s 47058 (54624)	Loss/tok 3.2593 (3.3850)	Learning Rate [0.00125]
2: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00105 (0.00098)	Tok/s 45505 (53528)	Loss/tok 3.2128 (3.3864)	Learning Rate [0.00125]
1: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00097)	Tok/s 45535 (53433)	Loss/tok 3.4222 (3.3953)	Learning Rate [0.00125]
0: TRAIN [1][1110/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00099)	Tok/s 45575 (53325)	Loss/tok 3.0370 (3.3879)	Learning Rate [0.00125]
2: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 70130 (53556)	Loss/tok 3.4322 (3.3867)	Learning Rate [0.00125]
1: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00097)	Tok/s 70137 (53461)	Loss/tok 3.3952 (3.3952)	Learning Rate [0.00125]
3: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 70039 (53640)	Loss/tok 3.4829 (3.3928)	Learning Rate [0.00125]
4: TRAIN [1][1120/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00100)	Tok/s 69967 (53742)	Loss/tok 3.5525 (3.3870)	Learning Rate [0.00125]
0: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00099)	Tok/s 70122 (53354)	Loss/tok 3.4429 (3.3876)	Learning Rate [0.00125]
15: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00078 (0.00092)	Tok/s 71065 (54649)	Loss/tok 3.3911 (3.3853)	Learning Rate [0.00125]
5: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 70038 (53812)	Loss/tok 3.3250 (3.3904)	Learning Rate [0.00125]
6: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00077 (0.00091)	Tok/s 70082 (53876)	Loss/tok 3.4406 (3.3876)	Learning Rate [0.00125]
14: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00077 (0.00093)	Tok/s 71079 (54540)	Loss/tok 3.3642 (3.3876)	Learning Rate [0.00125]
13: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00097)	Tok/s 71071 (54450)	Loss/tok 3.4006 (3.3835)	Learning Rate [0.00125]
7: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 70040 (53961)	Loss/tok 3.4952 (3.3815)	Learning Rate [0.00125]
8: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00099)	Tok/s 70765 (54033)	Loss/tok 3.7896 (3.3910)	Learning Rate [0.00125]
11: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 71002 (54265)	Loss/tok 3.4552 (3.3848)	Learning Rate [0.00125]
12: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 71038 (54370)	Loss/tok 3.4125 (3.3790)	Learning Rate [0.00125]
9: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 71079 (54096)	Loss/tok 3.5105 (3.3767)	Learning Rate [0.00125]
10: TRAIN [1][1120/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00095)	Tok/s 71001 (54182)	Loss/tok 3.4554 (3.3822)	Learning Rate [0.00125]
6: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00091)	Tok/s 58233 (53895)	Loss/tok 3.3878 (3.3878)	Learning Rate [0.00125]
3: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00093)	Tok/s 57563 (53659)	Loss/tok 3.8410 (3.3937)	Learning Rate [0.00125]
2: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00098)	Tok/s 57421 (53575)	Loss/tok 3.4935 (3.3869)	Learning Rate [0.00125]
8: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00099)	Tok/s 58047 (54053)	Loss/tok 3.5741 (3.3911)	Learning Rate [0.00125]
4: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00100)	Tok/s 58214 (53761)	Loss/tok 3.4955 (3.3875)	Learning Rate [0.00125]
7: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00097)	Tok/s 58120 (53980)	Loss/tok 3.4014 (3.3816)	Learning Rate [0.00125]
1: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00097)	Tok/s 57381 (53481)	Loss/tok 3.3886 (3.3954)	Learning Rate [0.00125]
9: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00092)	Tok/s 57957 (54117)	Loss/tok 3.7690 (3.3774)	Learning Rate [0.00125]
5: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00093)	Tok/s 58208 (53831)	Loss/tok 3.5241 (3.3905)	Learning Rate [0.00125]
0: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00099)	Tok/s 57330 (53375)	Loss/tok 3.7138 (3.3884)	Learning Rate [0.00125]
15: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 58200 (54667)	Loss/tok 3.8286 (3.3860)	Learning Rate [0.00125]
11: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00093)	Tok/s 57979 (54285)	Loss/tok 3.4148 (3.3852)	Learning Rate [0.00125]
10: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00095)	Tok/s 57958 (54203)	Loss/tok 3.8268 (3.3828)	Learning Rate [0.00125]
14: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00081 (0.00093)	Tok/s 58120 (54560)	Loss/tok 3.6510 (3.3875)	Learning Rate [0.00125]
13: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 57986 (54470)	Loss/tok 3.7788 (3.3852)	Learning Rate [0.00125]
12: TRAIN [1][1130/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00096)	Tok/s 57964 (54390)	Loss/tok 3.4233 (3.3787)	Learning Rate [0.00125]
6: TRAIN [1][1140/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00091)	Tok/s 32363 (53891)	Loss/tok 2.9216 (3.3877)	Learning Rate [0.00125]
4: TRAIN [1][1140/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00100)	Tok/s 32453 (53759)	Loss/tok 2.9179 (3.3870)	Learning Rate [0.00125]
5: TRAIN [1][1140/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00093)	Tok/s 32387 (53828)	Loss/tok 2.8616 (3.3902)	Learning Rate [0.00125]
7: TRAIN [1][1140/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00097)	Tok/s 32265 (53976)	Loss/tok 3.1770 (3.3818)	Learning Rate [0.00125]
9: TRAIN [1][1140/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00092)	Tok/s 32159 (54112)	Loss/tok 2.7393 (3.3776)	Learning Rate [0.00125]
8: TRAIN [1][1140/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00099)	Tok/s 32256 (54049)	Loss/tok 3.0274 (3.3910)	Learning Rate [0.00125]
3: TRAIN [1][1140/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00093)	Tok/s 32385 (53657)	Loss/tok 2.6791 (3.3928)	Learning Rate [0.00125]
2: TRAIN [1][1140/3416]	Time 0.045 (0.058)	Data 0.00105 (0.00098)	Tok/s 32400 (53573)	Loss/tok 2.9368 (3.3870)	Learning Rate [0.00125]
1: TRAIN [1][1140/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00097)	Tok/s 32305 (53480)	Loss/tok 2.8037 (3.3953)	Learning Rate [0.00125]
11: TRAIN [1][1140/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00093)	Tok/s 32090 (54281)	Loss/tok 2.9495 (3.3855)	Learning Rate [0.00125]
10: TRAIN [1][1140/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00095)	Tok/s 32081 (54198)	Loss/tok 3.1306 (3.3832)	Learning Rate [0.00125]
0: TRAIN [1][1140/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00099)	Tok/s 32260 (53375)	Loss/tok 2.7725 (3.3883)	Learning Rate [0.00125]
15: TRAIN [1][1140/3416]	Time 0.046 (0.058)	Data 0.00082 (0.00092)	Tok/s 33605 (54662)	Loss/tok 3.1021 (3.3861)	Learning Rate [0.00125]
14: TRAIN [1][1140/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00093)	Tok/s 33543 (54556)	Loss/tok 3.0583 (3.3872)	Learning Rate [0.00125]
12: TRAIN [1][1140/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00096)	Tok/s 32106 (54386)	Loss/tok 3.0550 (3.3782)	Learning Rate [0.00125]
13: TRAIN [1][1140/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00097)	Tok/s 32903 (54466)	Loss/tok 2.8815 (3.3855)	Learning Rate [0.00125]
9: TRAIN [1][1150/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 64044 (54111)	Loss/tok 3.3904 (3.3772)	Learning Rate [0.00125]
8: TRAIN [1][1150/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 63994 (54046)	Loss/tok 3.4941 (3.3907)	Learning Rate [0.00125]
11: TRAIN [1][1150/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 64861 (54280)	Loss/tok 3.6002 (3.3860)	Learning Rate [0.00125]
10: TRAIN [1][1150/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00095)	Tok/s 64879 (54197)	Loss/tok 3.5648 (3.3829)	Learning Rate [0.00125]
6: TRAIN [1][1150/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00091)	Tok/s 63666 (53890)	Loss/tok 3.3089 (3.3880)	Learning Rate [0.00125]
7: TRAIN [1][1150/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 63786 (53974)	Loss/tok 3.3536 (3.3813)	Learning Rate [0.00125]
5: TRAIN [1][1150/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 63597 (53827)	Loss/tok 3.5359 (3.3903)	Learning Rate [0.00125]
12: TRAIN [1][1150/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 64667 (54384)	Loss/tok 3.6681 (3.3778)	Learning Rate [0.00125]
14: TRAIN [1][1150/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 64472 (54554)	Loss/tok 3.5664 (3.3866)	Learning Rate [0.00125]
13: TRAIN [1][1150/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 64549 (54465)	Loss/tok 3.4783 (3.3854)	Learning Rate [0.00125]
3: TRAIN [1][1150/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 63368 (53657)	Loss/tok 3.4573 (3.3919)	Learning Rate [0.00125]
4: TRAIN [1][1150/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00100)	Tok/s 63417 (53758)	Loss/tok 3.3852 (3.3864)	Learning Rate [0.00125]
15: TRAIN [1][1150/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 64366 (54659)	Loss/tok 3.5002 (3.3862)	Learning Rate [0.00125]
0: TRAIN [1][1150/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00099)	Tok/s 63318 (53376)	Loss/tok 3.4692 (3.3883)	Learning Rate [0.00125]
1: TRAIN [1][1150/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00097)	Tok/s 63199 (53480)	Loss/tok 3.3393 (3.3948)	Learning Rate [0.00125]
2: TRAIN [1][1150/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 63224 (53573)	Loss/tok 3.7753 (3.3870)	Learning Rate [0.00125]
9: TRAIN [1][1160/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00092)	Tok/s 71852 (54157)	Loss/tok 3.3016 (3.3779)	Learning Rate [0.00125]
12: TRAIN [1][1160/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 71672 (54429)	Loss/tok 3.4387 (3.3780)	Learning Rate [0.00125]
10: TRAIN [1][1160/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00095)	Tok/s 71743 (54244)	Loss/tok 3.5141 (3.3841)	Learning Rate [0.00125]
13: TRAIN [1][1160/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 71561 (54509)	Loss/tok 3.5187 (3.3860)	Learning Rate [0.00125]
8: TRAIN [1][1160/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 71797 (54092)	Loss/tok 3.6308 (3.3925)	Learning Rate [0.00125]
15: TRAIN [1][1160/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 71613 (54701)	Loss/tok 3.4576 (3.3863)	Learning Rate [0.00125]
6: TRAIN [1][1160/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 71853 (53936)	Loss/tok 3.5911 (3.3886)	Learning Rate [0.00125]
7: TRAIN [1][1160/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00097)	Tok/s 71802 (54020)	Loss/tok 3.2508 (3.3810)	Learning Rate [0.00125]
0: TRAIN [1][1160/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 70688 (53422)	Loss/tok 3.6185 (3.3884)	Learning Rate [0.00125]
5: TRAIN [1][1160/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 71874 (53874)	Loss/tok 3.4688 (3.3910)	Learning Rate [0.00125]
1: TRAIN [1][1160/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 70704 (53526)	Loss/tok 3.4290 (3.3958)	Learning Rate [0.00125]
3: TRAIN [1][1160/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 70855 (53704)	Loss/tok 3.2631 (3.3917)	Learning Rate [0.00125]
4: TRAIN [1][1160/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 70952 (53805)	Loss/tok 3.3455 (3.3870)	Learning Rate [0.00125]
2: TRAIN [1][1160/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 70743 (53620)	Loss/tok 3.4661 (3.3872)	Learning Rate [0.00125]
11: TRAIN [1][1160/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00093)	Tok/s 71947 (54325)	Loss/tok 3.2918 (3.3860)	Learning Rate [0.00125]
14: TRAIN [1][1160/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00093)	Tok/s 71752 (54596)	Loss/tok 3.1612 (3.3874)	Learning Rate [0.00125]
6: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
0: TRAIN [1][1170/3416]	Time 0.048 (0.058)	Data 0.00108 (0.00099)	Tok/s 48900 (53364)	Loss/tok 3.3097 (3.3880)	Learning Rate [0.00125]
1: TRAIN [1][1170/3416]	Time 0.049 (0.058)	Data 0.00101 (0.00097)	Tok/s 48809 (53468)	Loss/tok 3.3800 (3.3955)	Learning Rate [0.00125]
15: TRAIN [1][1170/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00092)	Tok/s 50257 (54644)	Loss/tok 3.4524 (3.3855)	Learning Rate [0.00125]
2: TRAIN [1][1170/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00098)	Tok/s 48702 (53561)	Loss/tok 3.3713 (3.3866)	Learning Rate [0.00125]
14: TRAIN [1][1170/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00093)	Tok/s 50257 (54540)	Loss/tok 3.1284 (3.3870)	Learning Rate [0.00125]
13: TRAIN [1][1170/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00097)	Tok/s 50266 (54452)	Loss/tok 3.1677 (3.3853)	Learning Rate [0.00125]
3: TRAIN [1][1170/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00093)	Tok/s 48734 (53645)	Loss/tok 3.2148 (3.3909)	Learning Rate [0.00125]
4: TRAIN [1][1170/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00100)	Tok/s 49114 (53746)	Loss/tok 3.2091 (3.3866)	Learning Rate [0.00125]
12: TRAIN [1][1170/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00096)	Tok/s 50267 (54371)	Loss/tok 3.2305 (3.3783)	Learning Rate [0.00125]
11: TRAIN [1][1170/3416]	Time 0.048 (0.058)	Data 0.00082 (0.00093)	Tok/s 50242 (54268)	Loss/tok 3.4051 (3.3859)	Learning Rate [0.00125]
5: TRAIN [1][1170/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00093)	Tok/s 50021 (53817)	Loss/tok 3.3212 (3.3909)	Learning Rate [0.00125]
6: TRAIN [1][1170/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00091)	Tok/s 50005 (53879)	Loss/tok 3.0011 (3.3884)	Learning Rate [0.00125]
9: TRAIN [1][1170/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00092)	Tok/s 50126 (54100)	Loss/tok 3.1398 (3.3768)	Learning Rate [0.00125]
8: TRAIN [1][1170/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00098)	Tok/s 50128 (54035)	Loss/tok 3.2615 (3.3920)	Learning Rate [0.00125]
7: TRAIN [1][1170/3416]	Time 0.049 (0.058)	Data 0.00106 (0.00097)	Tok/s 50067 (53964)	Loss/tok 3.2307 (3.3803)	Learning Rate [0.00125]
10: TRAIN [1][1170/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00096)	Tok/s 50184 (54186)	Loss/tok 3.2348 (3.3833)	Learning Rate [0.00125]
13: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00097)	Tok/s 50835 (54455)	Loss/tok 3.4452 (3.3852)	Learning Rate [0.00125]
12: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00096)	Tok/s 50759 (54375)	Loss/tok 3.3840 (3.3776)	Learning Rate [0.00125]
11: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00078 (0.00093)	Tok/s 50608 (54273)	Loss/tok 3.1651 (3.3857)	Learning Rate [0.00125]
14: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00093)	Tok/s 50838 (54543)	Loss/tok 3.3863 (3.3864)	Learning Rate [0.00125]
15: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 50829 (54647)	Loss/tok 3.2582 (3.3856)	Learning Rate [0.00125]
0: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00106 (0.00099)	Tok/s 49423 (53371)	Loss/tok 3.3183 (3.3882)	Learning Rate [0.00125]
10: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00096)	Tok/s 50487 (54191)	Loss/tok 3.1358 (3.3835)	Learning Rate [0.00125]
9: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 50363 (54106)	Loss/tok 3.1972 (3.3765)	Learning Rate [0.00125]
1: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00097)	Tok/s 49357 (53474)	Loss/tok 3.1193 (3.3952)	Learning Rate [0.00125]
8: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00098)	Tok/s 50263 (54041)	Loss/tok 3.3552 (3.3918)	Learning Rate [0.00125]
2: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00082 (0.00098)	Tok/s 49228 (53567)	Loss/tok 3.0193 (3.3867)	Learning Rate [0.00125]
6: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00091)	Tok/s 50225 (53886)	Loss/tok 3.3817 (3.3888)	Learning Rate [0.00125]
3: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00093)	Tok/s 49120 (53651)	Loss/tok 3.1002 (3.3909)	Learning Rate [0.00125]
7: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00097)	Tok/s 50279 (53970)	Loss/tok 3.4154 (3.3802)	Learning Rate [0.00125]
5: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00093)	Tok/s 50298 (53823)	Loss/tok 3.2624 (3.3902)	Learning Rate [0.00125]
4: TRAIN [1][1180/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00100)	Tok/s 50338 (53753)	Loss/tok 3.3179 (3.3863)	Learning Rate [0.00125]
4: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00108 (0.00100)	Tok/s 49172 (53761)	Loss/tok 3.2401 (3.3859)	Learning Rate [0.00125]
6: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00091)	Tok/s 49119 (53893)	Loss/tok 3.0843 (3.3889)	Learning Rate [0.00125]
3: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00093)	Tok/s 48997 (53659)	Loss/tok 3.1825 (3.3909)	Learning Rate [0.00125]
5: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00093)	Tok/s 49111 (53831)	Loss/tok 3.4095 (3.3900)	Learning Rate [0.00125]
2: TRAIN [1][1190/3416]	Time 0.045 (0.058)	Data 0.00109 (0.00098)	Tok/s 48868 (53575)	Loss/tok 3.5132 (3.3866)	Learning Rate [0.00125]
1: TRAIN [1][1190/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00097)	Tok/s 48706 (53482)	Loss/tok 3.1515 (3.3948)	Learning Rate [0.00125]
7: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00108 (0.00097)	Tok/s 49014 (53978)	Loss/tok 3.2693 (3.3807)	Learning Rate [0.00125]
0: TRAIN [1][1190/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00099)	Tok/s 48585 (53380)	Loss/tok 3.2782 (3.3883)	Learning Rate [0.00125]
8: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00098)	Tok/s 48930 (54049)	Loss/tok 3.5124 (3.3915)	Learning Rate [0.00125]
9: TRAIN [1][1190/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00092)	Tok/s 48785 (54113)	Loss/tok 3.4211 (3.3772)	Learning Rate [0.00125]
15: TRAIN [1][1190/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00092)	Tok/s 49852 (54654)	Loss/tok 3.1961 (3.3850)	Learning Rate [0.00125]
11: TRAIN [1][1190/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00093)	Tok/s 48547 (54279)	Loss/tok 3.2725 (3.3861)	Learning Rate [0.00125]
13: TRAIN [1][1190/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00097)	Tok/s 49779 (54463)	Loss/tok 3.1139 (3.3845)	Learning Rate [0.00125]
14: TRAIN [1][1190/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00093)	Tok/s 49834 (54551)	Loss/tok 3.1926 (3.3864)	Learning Rate [0.00125]
10: TRAIN [1][1190/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00096)	Tok/s 48567 (54198)	Loss/tok 3.1820 (3.3831)	Learning Rate [0.00125]
12: TRAIN [1][1190/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00096)	Tok/s 48454 (54381)	Loss/tok 3.3417 (3.3780)	Learning Rate [0.00125]
7: Gradient norm: inf
8: Gradient norm: inf
6: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
13: Gradient norm: inf
11: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
2: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
1: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00097)	Tok/s 52601 (53529)	Loss/tok 3.1841 (3.3945)	Learning Rate [0.00125]
2: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00108 (0.00098)	Tok/s 52693 (53620)	Loss/tok 3.2231 (3.3856)	Learning Rate [0.00125]
4: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00113 (0.00100)	Tok/s 52617 (53805)	Loss/tok 3.4235 (3.3860)	Learning Rate [0.00125]
3: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00093)	Tok/s 52613 (53704)	Loss/tok 3.5956 (3.3909)	Learning Rate [0.00125]
0: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00099)	Tok/s 52458 (53427)	Loss/tok 3.4832 (3.3884)	Learning Rate [0.00125]
6: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00091)	Tok/s 52582 (53939)	Loss/tok 3.4650 (3.3898)	Learning Rate [0.00125]
15: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00092)	Tok/s 53349 (54700)	Loss/tok 3.4918 (3.3857)	Learning Rate [0.00125]
5: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00093)	Tok/s 52577 (53876)	Loss/tok 3.4897 (3.3913)	Learning Rate [0.00125]
14: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00085 (0.00093)	Tok/s 53347 (54598)	Loss/tok 3.3090 (3.3864)	Learning Rate [0.00125]
13: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00097)	Tok/s 53334 (54511)	Loss/tok 3.2892 (3.3846)	Learning Rate [0.00125]
7: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00103 (0.00097)	Tok/s 52477 (54024)	Loss/tok 3.5584 (3.3809)	Learning Rate [0.00125]
8: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00098)	Tok/s 52465 (54094)	Loss/tok 3.7355 (3.3920)	Learning Rate [0.00125]
9: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00092)	Tok/s 52382 (54157)	Loss/tok 3.3285 (3.3773)	Learning Rate [0.00125]
11: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00093)	Tok/s 52301 (54325)	Loss/tok 3.3165 (3.3864)	Learning Rate [0.00125]
12: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00096)	Tok/s 52316 (54428)	Loss/tok 3.5321 (3.3779)	Learning Rate [0.00125]
10: TRAIN [1][1200/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00096)	Tok/s 52359 (54243)	Loss/tok 3.1565 (3.3838)	Learning Rate [0.00125]
9: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00092)	Tok/s 44191 (54129)	Loss/tok 3.0212 (3.3769)	Learning Rate [0.00125]
11: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00093)	Tok/s 44083 (54296)	Loss/tok 3.2809 (3.3857)	Learning Rate [0.00125]
6: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00091)	Tok/s 44186 (53912)	Loss/tok 3.0205 (3.3891)	Learning Rate [0.00125]
10: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00096)	Tok/s 44067 (54215)	Loss/tok 3.1286 (3.3831)	Learning Rate [0.00125]
8: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00098)	Tok/s 44163 (54066)	Loss/tok 3.1864 (3.3915)	Learning Rate [0.00125]
12: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00095)	Tok/s 45107 (54399)	Loss/tok 3.2287 (3.3773)	Learning Rate [0.00125]
7: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00097)	Tok/s 44169 (53996)	Loss/tok 3.1379 (3.3805)	Learning Rate [0.00125]
13: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00106 (0.00097)	Tok/s 45205 (54482)	Loss/tok 3.1707 (3.3837)	Learning Rate [0.00125]
14: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00093)	Tok/s 45083 (54568)	Loss/tok 3.1656 (3.3855)	Learning Rate [0.00125]
3: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00093)	Tok/s 43939 (53677)	Loss/tok 3.3586 (3.3897)	Learning Rate [0.00125]
4: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00116 (0.00100)	Tok/s 43988 (53778)	Loss/tok 3.0399 (3.3852)	Learning Rate [0.00125]
15: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00092)	Tok/s 45129 (54670)	Loss/tok 3.0009 (3.3855)	Learning Rate [0.00125]
0: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00099)	Tok/s 43715 (53401)	Loss/tok 3.0211 (3.3877)	Learning Rate [0.00125]
5: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00093)	Tok/s 44044 (53848)	Loss/tok 3.0801 (3.3905)	Learning Rate [0.00125]
2: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00109 (0.00098)	Tok/s 43799 (53594)	Loss/tok 3.2041 (3.3849)	Learning Rate [0.00125]
1: TRAIN [1][1210/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 43681 (53503)	Loss/tok 2.9391 (3.3935)	Learning Rate [0.00125]
2: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00098)	Tok/s 49252 (53561)	Loss/tok 3.3755 (3.3841)	Learning Rate [0.00125]
1: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00097)	Tok/s 49282 (53470)	Loss/tok 3.0969 (3.3930)	Learning Rate [0.00125]
0: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00107 (0.00099)	Tok/s 49276 (53369)	Loss/tok 3.4866 (3.3873)	Learning Rate [0.00125]
4: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00100)	Tok/s 49283 (53744)	Loss/tok 3.3541 (3.3852)	Learning Rate [0.00125]
6: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00091)	Tok/s 50561 (53879)	Loss/tok 3.2845 (3.3882)	Learning Rate [0.00125]
15: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 50529 (54638)	Loss/tok 3.3083 (3.3856)	Learning Rate [0.00125]
5: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00093)	Tok/s 49407 (53815)	Loss/tok 3.1842 (3.3899)	Learning Rate [0.00125]
7: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 50619 (53963)	Loss/tok 3.0854 (3.3799)	Learning Rate [0.00125]
13: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00097)	Tok/s 50575 (54450)	Loss/tok 3.1508 (3.3834)	Learning Rate [0.00125]
8: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00098)	Tok/s 50643 (54034)	Loss/tok 3.3586 (3.3915)	Learning Rate [0.00125]
11: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00093)	Tok/s 50566 (54263)	Loss/tok 3.3343 (3.3855)	Learning Rate [0.00125]
12: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00113 (0.00095)	Tok/s 50595 (54366)	Loss/tok 3.0599 (3.3770)	Learning Rate [0.00125]
9: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00092)	Tok/s 50538 (54097)	Loss/tok 3.3438 (3.3762)	Learning Rate [0.00125]
10: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00096)	Tok/s 50577 (54182)	Loss/tok 3.4648 (3.3828)	Learning Rate [0.00125]
3: TRAIN [1][1220/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00093)	Tok/s 48466 (53644)	Loss/tok 3.2223 (3.3891)	Learning Rate [0.00125]
14: TRAIN [1][1220/3416]	Time 0.051 (0.058)	Data 0.00112 (0.00093)	Tok/s 49729 (54535)	Loss/tok 3.6303 (3.3851)	Learning Rate [0.00125]
4: TRAIN [1][1230/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00100)	Tok/s 66494 (53782)	Loss/tok 3.3899 (3.3858)	Learning Rate [0.00125]
8: TRAIN [1][1230/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 67077 (54072)	Loss/tok 3.4428 (3.3917)	Learning Rate [0.00125]
7: TRAIN [1][1230/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 66573 (54001)	Loss/tok 3.5628 (3.3805)	Learning Rate [0.00125]
6: TRAIN [1][1230/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00091)	Tok/s 66172 (53916)	Loss/tok 3.4103 (3.3887)	Learning Rate [0.00125]
5: TRAIN [1][1230/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00093)	Tok/s 66396 (53852)	Loss/tok 3.5525 (3.3897)	Learning Rate [0.00125]
9: TRAIN [1][1230/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 67048 (54134)	Loss/tok 3.3642 (3.3762)	Learning Rate [0.00125]
3: TRAIN [1][1230/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00093)	Tok/s 66245 (53683)	Loss/tok 3.3724 (3.3893)	Learning Rate [0.00125]
2: TRAIN [1][1230/3416]	Time 0.068 (0.058)	Data 0.00115 (0.00098)	Tok/s 67053 (53599)	Loss/tok 3.4399 (3.3840)	Learning Rate [0.00125]
10: TRAIN [1][1230/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 66868 (54220)	Loss/tok 3.6323 (3.3830)	Learning Rate [0.00125]
11: TRAIN [1][1230/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 66902 (54300)	Loss/tok 3.4285 (3.3851)	Learning Rate [0.00125]
1: TRAIN [1][1230/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 66059 (53509)	Loss/tok 3.4868 (3.3927)	Learning Rate [0.00125]
12: TRAIN [1][1230/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00095)	Tok/s 66954 (54402)	Loss/tok 3.6728 (3.3775)	Learning Rate [0.00125]
13: TRAIN [1][1230/3416]	Time 0.068 (0.058)	Data 0.00111 (0.00097)	Tok/s 67823 (54486)	Loss/tok 3.6543 (3.3836)	Learning Rate [0.00125]
15: TRAIN [1][1230/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00091)	Tok/s 66867 (54674)	Loss/tok 3.4320 (3.3855)	Learning Rate [0.00125]
14: TRAIN [1][1230/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 66891 (54572)	Loss/tok 3.3866 (3.3858)	Learning Rate [0.00125]
0: TRAIN [1][1230/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00099)	Tok/s 65882 (53407)	Loss/tok 3.6112 (3.3880)	Learning Rate [0.00125]
13: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00097)	Tok/s 39191 (54521)	Loss/tok 3.0364 (3.3839)	Learning Rate [0.00125]
14: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00093)	Tok/s 39111 (54608)	Loss/tok 2.9606 (3.3860)	Learning Rate [0.00125]
11: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 39123 (54336)	Loss/tok 3.3020 (3.3852)	Learning Rate [0.00125]
15: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00091)	Tok/s 39011 (54710)	Loss/tok 2.9699 (3.3856)	Learning Rate [0.00125]
12: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00096)	Tok/s 39107 (54438)	Loss/tok 2.9760 (3.3778)	Learning Rate [0.00125]
9: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 38064 (54170)	Loss/tok 3.2521 (3.3767)	Learning Rate [0.00125]
10: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00096)	Tok/s 39033 (54256)	Loss/tok 3.3859 (3.3833)	Learning Rate [0.00125]
6: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00091)	Tok/s 37475 (53952)	Loss/tok 3.0417 (3.3886)	Learning Rate [0.00125]
0: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00099)	Tok/s 37571 (53445)	Loss/tok 3.2049 (3.3880)	Learning Rate [0.00125]
3: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00093)	Tok/s 37425 (53720)	Loss/tok 3.2819 (3.3898)	Learning Rate [0.00125]
1: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00097)	Tok/s 37506 (53546)	Loss/tok 3.2337 (3.3929)	Learning Rate [0.00125]
8: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00098)	Tok/s 37560 (54107)	Loss/tok 3.0630 (3.3926)	Learning Rate [0.00125]
7: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00097)	Tok/s 37482 (54037)	Loss/tok 3.2688 (3.3811)	Learning Rate [0.00125]
5: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00093)	Tok/s 37399 (53888)	Loss/tok 3.2301 (3.3898)	Learning Rate [0.00125]
2: TRAIN [1][1240/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00098)	Tok/s 37389 (53636)	Loss/tok 3.0656 (3.3848)	Learning Rate [0.00125]
4: TRAIN [1][1240/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00100)	Tok/s 37276 (53818)	Loss/tok 3.1184 (3.3864)	Learning Rate [0.00125]
6: TRAIN [1][1250/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00091)	Tok/s 55782 (53951)	Loss/tok 3.3322 (3.3892)	Learning Rate [0.00125]
7: TRAIN [1][1250/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00097)	Tok/s 55725 (54036)	Loss/tok 3.7401 (3.3825)	Learning Rate [0.00125]
8: TRAIN [1][1250/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00098)	Tok/s 55610 (54106)	Loss/tok 3.5041 (3.3928)	Learning Rate [0.00125]
9: TRAIN [1][1250/3416]	Time 0.064 (0.058)	Data 0.00082 (0.00092)	Tok/s 56453 (54169)	Loss/tok 3.4137 (3.3774)	Learning Rate [0.00125]
4: TRAIN [1][1250/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00100)	Tok/s 55766 (53818)	Loss/tok 3.2804 (3.3866)	Learning Rate [0.00125]
5: TRAIN [1][1250/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00093)	Tok/s 55753 (53887)	Loss/tok 3.3875 (3.3897)	Learning Rate [0.00125]
10: TRAIN [1][1250/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00096)	Tok/s 56478 (54255)	Loss/tok 3.6815 (3.3845)	Learning Rate [0.00125]
2: TRAIN [1][1250/3416]	Time 0.064 (0.058)	Data 0.00104 (0.00098)	Tok/s 55754 (53636)	Loss/tok 3.6587 (3.3856)	Learning Rate [0.00125]
11: TRAIN [1][1250/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00093)	Tok/s 56476 (54334)	Loss/tok 3.2579 (3.3847)	Learning Rate [0.00125]
1: TRAIN [1][1250/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00097)	Tok/s 55708 (53546)	Loss/tok 3.4234 (3.3937)	Learning Rate [0.00125]
12: TRAIN [1][1250/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00096)	Tok/s 56497 (54435)	Loss/tok 3.4404 (3.3789)	Learning Rate [0.00125]
3: TRAIN [1][1250/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00093)	Tok/s 55739 (53720)	Loss/tok 3.5977 (3.3902)	Learning Rate [0.00125]
13: TRAIN [1][1250/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00097)	Tok/s 56532 (54520)	Loss/tok 3.4289 (3.3841)	Learning Rate [0.00125]
14: TRAIN [1][1250/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00093)	Tok/s 56507 (54607)	Loss/tok 3.6100 (3.3868)	Learning Rate [0.00125]
15: TRAIN [1][1250/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00091)	Tok/s 56544 (54708)	Loss/tok 3.4390 (3.3856)	Learning Rate [0.00125]
0: TRAIN [1][1250/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00099)	Tok/s 55594 (53446)	Loss/tok 3.6800 (3.3889)	Learning Rate [0.00125]
3: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00093)	Tok/s 53531 (53743)	Loss/tok 3.3575 (3.3898)	Learning Rate [0.00125]
4: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00100)	Tok/s 53415 (53840)	Loss/tok 3.4198 (3.3857)	Learning Rate [0.00125]
2: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00098)	Tok/s 52381 (53658)	Loss/tok 3.4907 (3.3852)	Learning Rate [0.00125]
1: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00097)	Tok/s 52370 (53569)	Loss/tok 3.4559 (3.3935)	Learning Rate [0.00125]
5: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00093)	Tok/s 53356 (53910)	Loss/tok 3.5604 (3.3897)	Learning Rate [0.00125]
6: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00103 (0.00091)	Tok/s 53278 (53974)	Loss/tok 3.5498 (3.3893)	Learning Rate [0.00125]
0: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00099)	Tok/s 52381 (53469)	Loss/tok 3.4241 (3.3882)	Learning Rate [0.00125]
15: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00084 (0.00091)	Tok/s 53464 (54733)	Loss/tok 3.3515 (3.3854)	Learning Rate [0.00125]
7: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00107 (0.00097)	Tok/s 53277 (54059)	Loss/tok 3.2910 (3.3824)	Learning Rate [0.00125]
14: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00093)	Tok/s 53459 (54632)	Loss/tok 3.4774 (3.3866)	Learning Rate [0.00125]
8: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00098)	Tok/s 53206 (54129)	Loss/tok 3.7260 (3.3921)	Learning Rate [0.00125]
9: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00092)	Tok/s 53235 (54191)	Loss/tok 3.4776 (3.3775)	Learning Rate [0.00125]
13: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00098 (0.00097)	Tok/s 53375 (54545)	Loss/tok 3.6113 (3.3837)	Learning Rate [0.00125]
11: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00093)	Tok/s 53293 (54357)	Loss/tok 3.2121 (3.3840)	Learning Rate [0.00125]
12: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00117 (0.00096)	Tok/s 53343 (54459)	Loss/tok 3.4765 (3.3780)	Learning Rate [0.00125]
10: TRAIN [1][1260/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00096)	Tok/s 53232 (54277)	Loss/tok 3.3812 (3.3840)	Learning Rate [0.00125]
6: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00091)	Tok/s 52551 (54009)	Loss/tok 3.4485 (3.3892)	Learning Rate [0.00125]
7: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00107 (0.00097)	Tok/s 52621 (54093)	Loss/tok 3.0791 (3.3827)	Learning Rate [0.00125]
8: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00098)	Tok/s 52675 (54163)	Loss/tok 3.2339 (3.3925)	Learning Rate [0.00125]
5: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00093)	Tok/s 52428 (53943)	Loss/tok 3.3507 (3.3891)	Learning Rate [0.00125]
9: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00092)	Tok/s 52616 (54225)	Loss/tok 3.2579 (3.3775)	Learning Rate [0.00125]
4: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00100)	Tok/s 52259 (53873)	Loss/tok 3.3087 (3.3854)	Learning Rate [0.00125]
3: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00093)	Tok/s 52267 (53776)	Loss/tok 3.1625 (3.3895)	Learning Rate [0.00125]
11: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00083 (0.00092)	Tok/s 52578 (54390)	Loss/tok 3.3033 (3.3837)	Learning Rate [0.00125]
10: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00096)	Tok/s 52603 (54310)	Loss/tok 3.3839 (3.3833)	Learning Rate [0.00125]
2: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00098)	Tok/s 52272 (53692)	Loss/tok 3.3460 (3.3852)	Learning Rate [0.00125]
1: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00108 (0.00097)	Tok/s 52245 (53603)	Loss/tok 3.2670 (3.3929)	Learning Rate [0.00125]
12: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00107 (0.00096)	Tok/s 52441 (54492)	Loss/tok 3.3036 (3.3774)	Learning Rate [0.00125]
15: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00091)	Tok/s 53328 (54768)	Loss/tok 3.4621 (3.3856)	Learning Rate [0.00125]
13: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00097)	Tok/s 52400 (54578)	Loss/tok 3.4148 (3.3839)	Learning Rate [0.00125]
14: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00093)	Tok/s 52723 (54666)	Loss/tok 3.1925 (3.3860)	Learning Rate [0.00125]
0: TRAIN [1][1270/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00098)	Tok/s 52176 (53502)	Loss/tok 3.2397 (3.3882)	Learning Rate [0.00125]
2: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 78290 (53708)	Loss/tok 3.3841 (3.3858)	Learning Rate [0.00125]
3: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 78959 (53793)	Loss/tok 3.3114 (3.3890)	Learning Rate [0.00125]
8: TRAIN [1][1280/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00098)	Tok/s 79215 (54178)	Loss/tok 3.2213 (3.3929)	Learning Rate [0.00125]
1: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 77902 (53619)	Loss/tok 3.3499 (3.3932)	Learning Rate [0.00125]
6: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00091)	Tok/s 78993 (54025)	Loss/tok 3.4193 (3.3897)	Learning Rate [0.00125]
4: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00100)	Tok/s 78921 (53889)	Loss/tok 3.3596 (3.3856)	Learning Rate [0.00125]
5: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 78942 (53959)	Loss/tok 3.4225 (3.3892)	Learning Rate [0.00125]
11: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 80042 (54404)	Loss/tok 3.3501 (3.3840)	Learning Rate [0.00125]
7: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00097)	Tok/s 79081 (54108)	Loss/tok 3.2106 (3.3827)	Learning Rate [0.00125]
9: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 79144 (54239)	Loss/tok 3.4923 (3.3780)	Learning Rate [0.00125]
0: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 77907 (53520)	Loss/tok 3.4741 (3.3886)	Learning Rate [0.00125]
10: TRAIN [1][1280/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 79905 (54325)	Loss/tok 3.4232 (3.3832)	Learning Rate [0.00125]
15: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00091)	Tok/s 79764 (54780)	Loss/tok 3.5062 (3.3862)	Learning Rate [0.00125]
12: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00096)	Tok/s 80017 (54506)	Loss/tok 3.2945 (3.3777)	Learning Rate [0.00125]
14: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 79780 (54680)	Loss/tok 3.3211 (3.3857)	Learning Rate [0.00125]
13: TRAIN [1][1280/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 79866 (54592)	Loss/tok 3.2643 (3.3837)	Learning Rate [0.00125]
12: TRAIN [1][1290/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00096)	Tok/s 51460 (54499)	Loss/tok 3.2767 (3.3779)	Learning Rate [0.00125]
11: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00076 (0.00092)	Tok/s 51400 (54397)	Loss/tok 3.4151 (3.3843)	Learning Rate [0.00125]
13: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00097)	Tok/s 51361 (54584)	Loss/tok 3.2790 (3.3829)	Learning Rate [0.00125]
9: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00092)	Tok/s 51315 (54231)	Loss/tok 3.4211 (3.3786)	Learning Rate [0.00125]
10: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00096)	Tok/s 51310 (54317)	Loss/tok 3.5460 (3.3829)	Learning Rate [0.00125]
14: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00078 (0.00093)	Tok/s 51251 (54671)	Loss/tok 3.5311 (3.3860)	Learning Rate [0.00125]
8: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00098)	Tok/s 51249 (54169)	Loss/tok 3.3949 (3.3925)	Learning Rate [0.00125]
15: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00091)	Tok/s 51110 (54771)	Loss/tok 3.4542 (3.3862)	Learning Rate [0.00125]
1: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00097)	Tok/s 50968 (53613)	Loss/tok 3.8037 (3.3934)	Learning Rate [0.00125]
7: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00097)	Tok/s 51204 (54100)	Loss/tok 3.3265 (3.3830)	Learning Rate [0.00125]
0: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00081 (0.00098)	Tok/s 51032 (53515)	Loss/tok 3.3167 (3.3887)	Learning Rate [0.00125]
6: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00091)	Tok/s 51075 (54016)	Loss/tok 3.4525 (3.3900)	Learning Rate [0.00125]
2: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00098)	Tok/s 50863 (53701)	Loss/tok 3.6217 (3.3868)	Learning Rate [0.00125]
3: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00093)	Tok/s 50915 (53785)	Loss/tok 3.4137 (3.3883)	Learning Rate [0.00125]
5: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00082 (0.00093)	Tok/s 51022 (53950)	Loss/tok 3.3205 (3.3891)	Learning Rate [0.00125]
4: TRAIN [1][1290/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00100)	Tok/s 50955 (53881)	Loss/tok 3.5167 (3.3856)	Learning Rate [0.00125]
6: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 67084 (53985)	Loss/tok 3.3040 (3.3896)	Learning Rate [0.00125]
7: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 67161 (54068)	Loss/tok 3.4341 (3.3827)	Learning Rate [0.00125]
8: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00098)	Tok/s 67140 (54138)	Loss/tok 3.5194 (3.3914)	Learning Rate [0.00125]
5: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 66955 (53918)	Loss/tok 3.5602 (3.3897)	Learning Rate [0.00125]
9: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 67144 (54200)	Loss/tok 3.3481 (3.3782)	Learning Rate [0.00125]
4: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00100)	Tok/s 66900 (53848)	Loss/tok 3.4610 (3.3852)	Learning Rate [0.00125]
10: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 67119 (54286)	Loss/tok 3.7358 (3.3831)	Learning Rate [0.00125]
3: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 66713 (53750)	Loss/tok 3.4932 (3.3877)	Learning Rate [0.00125]
2: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 66667 (53665)	Loss/tok 3.7599 (3.3870)	Learning Rate [0.00125]
11: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 66981 (54366)	Loss/tok 3.6118 (3.3840)	Learning Rate [0.00125]
1: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00097)	Tok/s 66663 (53575)	Loss/tok 3.6969 (3.3934)	Learning Rate [0.00125]
15: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00091)	Tok/s 67594 (54741)	Loss/tok 3.7242 (3.3861)	Learning Rate [0.00125]
12: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00096)	Tok/s 67387 (54468)	Loss/tok 3.4489 (3.3774)	Learning Rate [0.00125]
14: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 67631 (54641)	Loss/tok 3.6808 (3.3862)	Learning Rate [0.00125]
13: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 67747 (54553)	Loss/tok 3.5601 (3.3826)	Learning Rate [0.00125]
0: TRAIN [1][1300/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00098)	Tok/s 66624 (53475)	Loss/tok 3.4466 (3.3883)	Learning Rate [0.00125]
10: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00096)	Tok/s 55523 (54305)	Loss/tok 3.2011 (3.3824)	Learning Rate [0.00125]
11: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00092)	Tok/s 55688 (54385)	Loss/tok 3.5929 (3.3842)	Learning Rate [0.00125]
9: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00092)	Tok/s 54488 (54219)	Loss/tok 3.5291 (3.3781)	Learning Rate [0.00125]
8: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00098)	Tok/s 54407 (54158)	Loss/tok 3.8327 (3.3914)	Learning Rate [0.00125]
12: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00096)	Tok/s 55610 (54487)	Loss/tok 3.4796 (3.3782)	Learning Rate [0.00125]
6: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00091)	Tok/s 54390 (54004)	Loss/tok 3.4298 (3.3901)	Learning Rate [0.00125]
7: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00097)	Tok/s 54439 (54088)	Loss/tok 3.4225 (3.3826)	Learning Rate [0.00125]
13: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00097)	Tok/s 55478 (54573)	Loss/tok 3.4242 (3.3831)	Learning Rate [0.00125]
14: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00093)	Tok/s 55326 (54661)	Loss/tok 3.2517 (3.3861)	Learning Rate [0.00125]
5: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00093)	Tok/s 54350 (53938)	Loss/tok 3.5023 (3.3899)	Learning Rate [0.00125]
4: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00100)	Tok/s 54323 (53868)	Loss/tok 3.5050 (3.3854)	Learning Rate [0.00125]
15: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00091)	Tok/s 55221 (54760)	Loss/tok 3.3955 (3.3866)	Learning Rate [0.00125]
2: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00098)	Tok/s 54107 (53685)	Loss/tok 3.7488 (3.3874)	Learning Rate [0.00125]
3: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00093)	Tok/s 54155 (53770)	Loss/tok 3.3430 (3.3877)	Learning Rate [0.00125]
1: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00097)	Tok/s 54056 (53595)	Loss/tok 3.2801 (3.3940)	Learning Rate [0.00125]
0: TRAIN [1][1310/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00098)	Tok/s 54032 (53495)	Loss/tok 3.4624 (3.3886)	Learning Rate [0.00125]
0: TRAIN [1][1320/3416]	Time 0.064 (0.058)	Data 0.00079 (0.00098)	Tok/s 53411 (53506)	Loss/tok 3.3225 (3.3885)	Learning Rate [0.00125]
15: TRAIN [1][1320/3416]	Time 0.063 (0.058)	Data 0.00084 (0.00091)	Tok/s 54482 (54770)	Loss/tok 3.2730 (3.3870)	Learning Rate [0.00125]
14: TRAIN [1][1320/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00093)	Tok/s 54448 (54671)	Loss/tok 3.4053 (3.3863)	Learning Rate [0.00125]
2: TRAIN [1][1320/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00098)	Tok/s 53294 (53696)	Loss/tok 3.3652 (3.3875)	Learning Rate [0.00125]
13: TRAIN [1][1320/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00097)	Tok/s 54453 (54583)	Loss/tok 3.4011 (3.3840)	Learning Rate [0.00125]
3: TRAIN [1][1320/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00093)	Tok/s 53338 (53781)	Loss/tok 3.6270 (3.3880)	Learning Rate [0.00125]
4: TRAIN [1][1320/3416]	Time 0.064 (0.058)	Data 0.00100 (0.00100)	Tok/s 53367 (53878)	Loss/tok 3.2677 (3.3854)	Learning Rate [0.00125]
12: TRAIN [1][1320/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00096)	Tok/s 54452 (54497)	Loss/tok 3.4972 (3.3785)	Learning Rate [0.00125]
11: TRAIN [1][1320/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00092)	Tok/s 54458 (54395)	Loss/tok 3.3238 (3.3845)	Learning Rate [0.00125]
6: TRAIN [1][1320/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00091)	Tok/s 53362 (54013)	Loss/tok 3.4355 (3.3905)	Learning Rate [0.00125]
5: TRAIN [1][1320/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00093)	Tok/s 53349 (53948)	Loss/tok 3.5110 (3.3904)	Learning Rate [0.00125]
9: TRAIN [1][1320/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00092)	Tok/s 53442 (54229)	Loss/tok 3.4752 (3.3785)	Learning Rate [0.00125]
10: TRAIN [1][1320/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00096)	Tok/s 53814 (54315)	Loss/tok 3.5451 (3.3834)	Learning Rate [0.00125]
8: TRAIN [1][1320/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00098)	Tok/s 53431 (54168)	Loss/tok 3.3242 (3.3913)	Learning Rate [0.00125]
7: TRAIN [1][1320/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00097)	Tok/s 53340 (54096)	Loss/tok 3.3104 (3.3824)	Learning Rate [0.00125]
1: TRAIN [1][1320/3416]	Time 0.064 (0.058)	Data 0.00111 (0.00097)	Tok/s 53298 (53606)	Loss/tok 3.4356 (3.3946)	Learning Rate [0.00125]
8: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
8: Gradient norm: inf
9: Gradient norm: inf
7: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
12: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
14: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
6: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00091)	Tok/s 63671 (54013)	Loss/tok 3.4746 (3.3899)	Learning Rate [0.00125]
5: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 63716 (53948)	Loss/tok 3.4753 (3.3899)	Learning Rate [0.00125]
7: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 63562 (54096)	Loss/tok 3.8212 (3.3827)	Learning Rate [0.00125]
8: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00098)	Tok/s 63568 (54168)	Loss/tok 3.5254 (3.3905)	Learning Rate [0.00125]
4: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00100)	Tok/s 63674 (53878)	Loss/tok 3.6677 (3.3856)	Learning Rate [0.00125]
9: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 63616 (54228)	Loss/tok 3.4447 (3.3789)	Learning Rate [0.00125]
3: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00093)	Tok/s 63705 (53782)	Loss/tok 3.4984 (3.3876)	Learning Rate [0.00125]
11: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 63719 (54395)	Loss/tok 3.5329 (3.3846)	Learning Rate [0.00125]
2: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 63724 (53697)	Loss/tok 3.7442 (3.3878)	Learning Rate [0.00125]
1: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 63737 (53607)	Loss/tok 3.5130 (3.3940)	Learning Rate [0.00125]
10: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 63630 (54314)	Loss/tok 3.4550 (3.3839)	Learning Rate [0.00125]
12: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00096)	Tok/s 64318 (54498)	Loss/tok 3.5473 (3.3784)	Learning Rate [0.00125]
0: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00116 (0.00098)	Tok/s 63761 (53508)	Loss/tok 3.5785 (3.3883)	Learning Rate [0.00125]
15: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 64677 (54770)	Loss/tok 3.5433 (3.3873)	Learning Rate [0.00125]
13: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 64654 (54583)	Loss/tok 3.4738 (3.3833)	Learning Rate [0.00125]
14: TRAIN [1][1330/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 64759 (54671)	Loss/tok 3.6546 (3.3866)	Learning Rate [0.00125]
6: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 73455 (53973)	Loss/tok 3.2624 (3.3897)	Learning Rate [0.00125]
4: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00100)	Tok/s 73273 (53838)	Loss/tok 3.5026 (3.3851)	Learning Rate [0.00125]
5: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 73277 (53908)	Loss/tok 3.2103 (3.3893)	Learning Rate [0.00125]
0: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00098)	Tok/s 73443 (53471)	Loss/tok 3.3167 (3.3879)	Learning Rate [0.00125]
7: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00097)	Tok/s 73605 (54055)	Loss/tok 3.7584 (3.3830)	Learning Rate [0.00125]
15: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00077 (0.00091)	Tok/s 74431 (54731)	Loss/tok 3.3153 (3.3871)	Learning Rate [0.00125]
9: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 74408 (54186)	Loss/tok 3.4327 (3.3781)	Learning Rate [0.00125]
1: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 73300 (53570)	Loss/tok 3.4652 (3.3937)	Learning Rate [0.00125]
8: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 74293 (54127)	Loss/tok 3.4257 (3.3898)	Learning Rate [0.00125]
14: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 74427 (54631)	Loss/tok 3.5582 (3.3863)	Learning Rate [0.00125]
3: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 73183 (53743)	Loss/tok 3.4038 (3.3873)	Learning Rate [0.00125]
2: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00098)	Tok/s 73222 (53659)	Loss/tok 3.5430 (3.3877)	Learning Rate [0.00125]
12: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00096)	Tok/s 74440 (54456)	Loss/tok 3.5065 (3.3783)	Learning Rate [0.00125]
11: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00078 (0.00092)	Tok/s 74344 (54354)	Loss/tok 3.3919 (3.3846)	Learning Rate [0.00125]
10: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 74339 (54273)	Loss/tok 3.3527 (3.3834)	Learning Rate [0.00125]
13: TRAIN [1][1340/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 73940 (54542)	Loss/tok 3.4846 (3.3828)	Learning Rate [0.00125]
1: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00097)	Tok/s 47947 (53523)	Loss/tok 3.5798 (3.3940)	Learning Rate [0.00125]
0: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00098)	Tok/s 47923 (53425)	Loss/tok 3.3319 (3.3880)	Learning Rate [0.00125]
2: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00098)	Tok/s 47855 (53611)	Loss/tok 3.2365 (3.3872)	Learning Rate [0.00125]
3: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00093)	Tok/s 47740 (53695)	Loss/tok 3.2843 (3.3867)	Learning Rate [0.00125]
15: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00091)	Tok/s 49229 (54688)	Loss/tok 3.2542 (3.3867)	Learning Rate [0.00125]
4: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00100)	Tok/s 47795 (53791)	Loss/tok 3.0965 (3.3847)	Learning Rate [0.00125]
14: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00093)	Tok/s 49132 (54588)	Loss/tok 3.2987 (3.3861)	Learning Rate [0.00125]
13: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00097)	Tok/s 49001 (54498)	Loss/tok 3.3111 (3.3825)	Learning Rate [0.00125]
5: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00093)	Tok/s 48540 (53862)	Loss/tok 3.3206 (3.3890)	Learning Rate [0.00125]
6: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00091)	Tok/s 49087 (53928)	Loss/tok 3.1838 (3.3892)	Learning Rate [0.00125]
11: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00083 (0.00092)	Tok/s 48955 (54310)	Loss/tok 3.2723 (3.3846)	Learning Rate [0.00125]
12: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00096)	Tok/s 48917 (54412)	Loss/tok 3.2679 (3.3779)	Learning Rate [0.00125]
9: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00092)	Tok/s 48987 (54142)	Loss/tok 3.4443 (3.3780)	Learning Rate [0.00125]
7: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00097)	Tok/s 49095 (54010)	Loss/tok 3.3118 (3.3828)	Learning Rate [0.00125]
10: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00096)	Tok/s 48951 (54230)	Loss/tok 3.2091 (3.3827)	Learning Rate [0.00125]
8: TRAIN [1][1350/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00098)	Tok/s 48931 (54082)	Loss/tok 3.3821 (3.3901)	Learning Rate [0.00125]
3: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00090 (0.00093)	Tok/s 16975 (53705)	Loss/tok 1.6742 (3.3861)	Learning Rate [0.00125]
4: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00094 (0.00100)	Tok/s 18161 (53801)	Loss/tok 2.0482 (3.3850)	Learning Rate [0.00125]
1: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00095 (0.00097)	Tok/s 12063 (53530)	Loss/tok 1.7829 (3.3943)	Learning Rate [0.00125]
2: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00091 (0.00098)	Tok/s 15231 (53620)	Loss/tok 1.8849 (3.3868)	Learning Rate [0.00125]
5: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00083 (0.00093)	Tok/s 20588 (53873)	Loss/tok 2.1549 (3.3893)	Learning Rate [0.00125]
6: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00091 (0.00091)	Tok/s 22175 (53941)	Loss/tok 2.1458 (3.3891)	Learning Rate [0.00125]
0: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00103 (0.00098)	Tok/s 9445 (53431)	Loss/tok 1.5246 (3.3881)	Learning Rate [0.00125]
15: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00092 (0.00091)	Tok/s 28298 (54704)	Loss/tok 2.4462 (3.3869)	Learning Rate [0.00125]
7: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00107 (0.00097)	Tok/s 22874 (54023)	Loss/tok 2.2799 (3.3824)	Learning Rate [0.00125]
14: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00098 (0.00093)	Tok/s 27033 (54605)	Loss/tok 2.4319 (3.3865)	Learning Rate [0.00125]
8: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00084 (0.00098)	Tok/s 24406 (54097)	Loss/tok 2.1308 (3.3902)	Learning Rate [0.00125]
13: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00100 (0.00097)	Tok/s 26438 (54515)	Loss/tok 2.3906 (3.3826)	Learning Rate [0.00125]
11: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00082 (0.00092)	Tok/s 24535 (54325)	Loss/tok 2.0973 (3.3842)	Learning Rate [0.00125]
9: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00091 (0.00092)	Tok/s 24393 (54158)	Loss/tok 2.0998 (3.3774)	Learning Rate [0.00125]
12: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00106 (0.00096)	Tok/s 26385 (54429)	Loss/tok 2.3469 (3.3778)	Learning Rate [0.00125]
10: TRAIN [1][1360/3416]	Time 0.034 (0.058)	Data 0.00104 (0.00096)	Tok/s 24408 (54245)	Loss/tok 2.0436 (3.3827)	Learning Rate [0.00125]
9: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00092)	Tok/s 51737 (54119)	Loss/tok 3.2954 (3.3772)	Learning Rate [0.00125]
12: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00096)	Tok/s 51799 (54389)	Loss/tok 3.3387 (3.3776)	Learning Rate [0.00125]
13: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00097)	Tok/s 51769 (54475)	Loss/tok 3.3742 (3.3822)	Learning Rate [0.00125]
1: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00097)	Tok/s 50751 (53492)	Loss/tok 3.4029 (3.3941)	Learning Rate [0.00125]
4: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00100)	Tok/s 51844 (53763)	Loss/tok 3.3781 (3.3849)	Learning Rate [0.00125]
8: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00098)	Tok/s 51737 (54059)	Loss/tok 3.2524 (3.3897)	Learning Rate [0.00125]
2: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00089 (0.00098)	Tok/s 50728 (53583)	Loss/tok 3.2913 (3.3866)	Learning Rate [0.00125]
7: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00097)	Tok/s 51761 (53985)	Loss/tok 3.5223 (3.3821)	Learning Rate [0.00125]
0: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00098)	Tok/s 50737 (53393)	Loss/tok 3.2364 (3.3872)	Learning Rate [0.00125]
14: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00093)	Tok/s 51865 (54565)	Loss/tok 3.4916 (3.3860)	Learning Rate [0.00125]
15: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00089 (0.00091)	Tok/s 51804 (54664)	Loss/tok 3.4396 (3.3867)	Learning Rate [0.00125]
10: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00096)	Tok/s 51745 (54206)	Loss/tok 3.1187 (3.3821)	Learning Rate [0.00125]
3: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00087 (0.00093)	Tok/s 50738 (53667)	Loss/tok 3.4290 (3.3859)	Learning Rate [0.00125]
11: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00082 (0.00092)	Tok/s 51734 (54286)	Loss/tok 3.2923 (3.3836)	Learning Rate [0.00125]
6: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00091)	Tok/s 51849 (53903)	Loss/tok 3.3070 (3.3882)	Learning Rate [0.00125]
5: TRAIN [1][1370/3416]	Time 0.057 (0.058)	Data 0.00085 (0.00093)	Tok/s 51858 (53836)	Loss/tok 3.4909 (3.3889)	Learning Rate [0.00125]
4: TRAIN [1][1380/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00099)	Tok/s 51139 (53722)	Loss/tok 3.4871 (3.3843)	Learning Rate [0.00125]
5: TRAIN [1][1380/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00093)	Tok/s 51097 (53795)	Loss/tok 3.1955 (3.3882)	Learning Rate [0.00125]
6: TRAIN [1][1380/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00091)	Tok/s 51147 (53863)	Loss/tok 3.1679 (3.3876)	Learning Rate [0.00125]
3: TRAIN [1][1380/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 50983 (53624)	Loss/tok 3.4787 (3.3853)	Learning Rate [0.00125]
7: TRAIN [1][1380/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00097)	Tok/s 51279 (53946)	Loss/tok 3.3530 (3.3815)	Learning Rate [0.00125]
9: TRAIN [1][1380/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00092)	Tok/s 52505 (54083)	Loss/tok 3.4218 (3.3765)	Learning Rate [0.00125]
1: TRAIN [1][1380/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00097)	Tok/s 50897 (53445)	Loss/tok 2.9203 (3.3933)	Learning Rate [0.00125]
8: TRAIN [1][1380/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00098)	Tok/s 51304 (54021)	Loss/tok 3.4289 (3.3891)	Learning Rate [0.00125]
10: TRAIN [1][1380/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00096)	Tok/s 52562 (54170)	Loss/tok 3.4341 (3.3817)	Learning Rate [0.00125]
11: TRAIN [1][1380/3416]	Time 0.051 (0.058)	Data 0.00078 (0.00092)	Tok/s 52403 (54250)	Loss/tok 3.3627 (3.3827)	Learning Rate [0.00125]
0: TRAIN [1][1380/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00098)	Tok/s 50895 (53344)	Loss/tok 3.4410 (3.3868)	Learning Rate [0.00125]
12: TRAIN [1][1380/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00096)	Tok/s 52319 (54353)	Loss/tok 3.2629 (3.3776)	Learning Rate [0.00125]
2: TRAIN [1][1380/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00098)	Tok/s 50858 (53538)	Loss/tok 3.3379 (3.3860)	Learning Rate [0.00125]
15: TRAIN [1][1380/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00091)	Tok/s 52125 (54631)	Loss/tok 3.3297 (3.3857)	Learning Rate [0.00125]
13: TRAIN [1][1380/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00097)	Tok/s 52215 (54440)	Loss/tok 3.3797 (3.3816)	Learning Rate [0.00125]
14: TRAIN [1][1380/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00093)	Tok/s 52151 (54530)	Loss/tok 3.3842 (3.3856)	Learning Rate [0.00125]
13: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 67334 (54442)	Loss/tok 3.1259 (3.3816)	Learning Rate [0.00125]
6: TRAIN [1][1390/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00091)	Tok/s 66103 (53865)	Loss/tok 3.5671 (3.3873)	Learning Rate [0.00125]
14: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00093)	Tok/s 67299 (54531)	Loss/tok 3.3898 (3.3851)	Learning Rate [0.00125]
5: TRAIN [1][1390/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 66077 (53797)	Loss/tok 3.6745 (3.3884)	Learning Rate [0.00125]
4: TRAIN [1][1390/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 66061 (53724)	Loss/tok 3.5575 (3.3850)	Learning Rate [0.00125]
7: TRAIN [1][1390/3416]	Time 0.070 (0.058)	Data 0.00122 (0.00097)	Tok/s 66130 (53948)	Loss/tok 3.5744 (3.3818)	Learning Rate [0.00125]
0: TRAIN [1][1390/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00098)	Tok/s 66211 (53347)	Loss/tok 3.6599 (3.3875)	Learning Rate [0.00125]
15: TRAIN [1][1390/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00092)	Tok/s 67219 (54633)	Loss/tok 3.4005 (3.3857)	Learning Rate [0.00125]
8: TRAIN [1][1390/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 66129 (54022)	Loss/tok 3.4291 (3.3890)	Learning Rate [0.00125]
3: TRAIN [1][1390/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 66026 (53626)	Loss/tok 3.4621 (3.3858)	Learning Rate [0.00125]
12: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 67248 (54354)	Loss/tok 3.3803 (3.3774)	Learning Rate [0.00125]
2: TRAIN [1][1390/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 66050 (53541)	Loss/tok 3.6520 (3.3866)	Learning Rate [0.00125]
11: TRAIN [1][1390/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 67179 (54251)	Loss/tok 3.5459 (3.3829)	Learning Rate [0.00125]
1: TRAIN [1][1390/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00097)	Tok/s 66085 (53448)	Loss/tok 3.4174 (3.3934)	Learning Rate [0.00125]
9: TRAIN [1][1390/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 66082 (54085)	Loss/tok 3.7891 (3.3771)	Learning Rate [0.00125]
10: TRAIN [1][1390/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00096)	Tok/s 67042 (54172)	Loss/tok 3.4373 (3.3819)	Learning Rate [0.00125]
4: TRAIN [1][1400/3416]	Time 0.040 (0.058)	Data 0.00107 (0.00099)	Tok/s 29611 (53732)	Loss/tok 2.7015 (3.3849)	Learning Rate [0.00125]
2: TRAIN [1][1400/3416]	Time 0.041 (0.058)	Data 0.00094 (0.00098)	Tok/s 28442 (53549)	Loss/tok 2.3888 (3.3863)	Learning Rate [0.00125]
3: TRAIN [1][1400/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00093)	Tok/s 28490 (53634)	Loss/tok 2.5105 (3.3854)	Learning Rate [0.00125]
6: TRAIN [1][1400/3416]	Time 0.040 (0.058)	Data 0.00102 (0.00091)	Tok/s 30128 (53872)	Loss/tok 2.7023 (3.3867)	Learning Rate [0.00125]
7: TRAIN [1][1400/3416]	Time 0.040 (0.058)	Data 0.00111 (0.00097)	Tok/s 30181 (53955)	Loss/tok 2.4555 (3.3811)	Learning Rate [0.00125]
5: TRAIN [1][1400/3416]	Time 0.040 (0.058)	Data 0.00105 (0.00093)	Tok/s 30094 (53805)	Loss/tok 2.6927 (3.3881)	Learning Rate [0.00125]
9: TRAIN [1][1400/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00092)	Tok/s 30168 (54091)	Loss/tok 2.6370 (3.3771)	Learning Rate [0.00125]
8: TRAIN [1][1400/3416]	Time 0.040 (0.058)	Data 0.00103 (0.00098)	Tok/s 30108 (54029)	Loss/tok 2.6342 (3.3891)	Learning Rate [0.00125]
1: TRAIN [1][1400/3416]	Time 0.041 (0.058)	Data 0.00101 (0.00097)	Tok/s 28296 (53457)	Loss/tok 2.5649 (3.3927)	Learning Rate [0.00125]
0: TRAIN [1][1400/3416]	Time 0.041 (0.058)	Data 0.00101 (0.00098)	Tok/s 28310 (53356)	Loss/tok 2.5019 (3.3871)	Learning Rate [0.00125]
15: TRAIN [1][1400/3416]	Time 0.041 (0.058)	Data 0.00107 (0.00092)	Tok/s 31497 (54640)	Loss/tok 2.6443 (3.3852)	Learning Rate [0.00125]
11: TRAIN [1][1400/3416]	Time 0.041 (0.058)	Data 0.00100 (0.00092)	Tok/s 30024 (54257)	Loss/tok 2.6628 (3.3824)	Learning Rate [0.00125]
10: TRAIN [1][1400/3416]	Time 0.041 (0.058)	Data 0.00103 (0.00096)	Tok/s 29981 (54178)	Loss/tok 2.7466 (3.3822)	Learning Rate [0.00125]
13: TRAIN [1][1400/3416]	Time 0.041 (0.058)	Data 0.00108 (0.00097)	Tok/s 31229 (54448)	Loss/tok 2.7713 (3.3813)	Learning Rate [0.00125]
12: TRAIN [1][1400/3416]	Time 0.041 (0.058)	Data 0.00106 (0.00096)	Tok/s 29945 (54359)	Loss/tok 2.4740 (3.3775)	Learning Rate [0.00125]
14: TRAIN [1][1400/3416]	Time 0.041 (0.058)	Data 0.00102 (0.00093)	Tok/s 31483 (54538)	Loss/tok 2.8094 (3.3852)	Learning Rate [0.00125]
13: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00097)	Tok/s 39101 (54456)	Loss/tok 3.0829 (3.3807)	Learning Rate [0.00125]
14: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00093)	Tok/s 39077 (54545)	Loss/tok 3.1971 (3.3849)	Learning Rate [0.00125]
11: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00092)	Tok/s 38968 (54265)	Loss/tok 3.1608 (3.3822)	Learning Rate [0.00125]
15: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 39057 (54647)	Loss/tok 3.2327 (3.3849)	Learning Rate [0.00125]
12: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00096)	Tok/s 39036 (54368)	Loss/tok 2.9635 (3.3771)	Learning Rate [0.00125]
9: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 38389 (54099)	Loss/tok 3.0334 (3.3763)	Learning Rate [0.00125]
0: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00098)	Tok/s 37821 (53362)	Loss/tok 3.2596 (3.3869)	Learning Rate [0.00125]
10: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00096)	Tok/s 38915 (54186)	Loss/tok 3.0794 (3.3820)	Learning Rate [0.00125]
1: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00097)	Tok/s 37770 (53463)	Loss/tok 3.0970 (3.3919)	Learning Rate [0.00125]
6: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00091)	Tok/s 37479 (53879)	Loss/tok 3.0933 (3.3864)	Learning Rate [0.00125]
3: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00093)	Tok/s 37627 (53640)	Loss/tok 3.1544 (3.3855)	Learning Rate [0.00125]
5: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00093)	Tok/s 37535 (53812)	Loss/tok 3.2220 (3.3879)	Learning Rate [0.00125]
2: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00112 (0.00098)	Tok/s 37701 (53555)	Loss/tok 3.2198 (3.3864)	Learning Rate [0.00125]
7: TRAIN [1][1410/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00097)	Tok/s 37516 (53963)	Loss/tok 3.2435 (3.3816)	Learning Rate [0.00125]
8: TRAIN [1][1410/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00098)	Tok/s 36843 (54036)	Loss/tok 3.5146 (3.3889)	Learning Rate [0.00125]
4: TRAIN [1][1410/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00100)	Tok/s 36920 (53738)	Loss/tok 3.2524 (3.3838)	Learning Rate [0.00125]
1: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00097)	Tok/s 32669 (53492)	Loss/tok 2.9270 (3.3914)	Learning Rate [0.00125]
2: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00098)	Tok/s 32629 (53583)	Loss/tok 2.8554 (3.3862)	Learning Rate [0.00125]
0: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00098)	Tok/s 32685 (53391)	Loss/tok 2.6765 (3.3864)	Learning Rate [0.00125]
15: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00092)	Tok/s 34088 (54675)	Loss/tok 2.9878 (3.3844)	Learning Rate [0.00125]
3: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00093)	Tok/s 32527 (53669)	Loss/tok 2.8007 (3.3855)	Learning Rate [0.00125]
14: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00093)	Tok/s 34072 (54573)	Loss/tok 2.9814 (3.3845)	Learning Rate [0.00125]
4: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00100)	Tok/s 32494 (53767)	Loss/tok 3.0544 (3.3836)	Learning Rate [0.00125]
13: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00097)	Tok/s 34101 (54484)	Loss/tok 2.9449 (3.3812)	Learning Rate [0.00125]
9: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00092)	Tok/s 32750 (54126)	Loss/tok 2.9067 (3.3757)	Learning Rate [0.00125]
11: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 32755 (54292)	Loss/tok 3.1095 (3.3817)	Learning Rate [0.00125]
10: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00096)	Tok/s 32805 (54213)	Loss/tok 3.0020 (3.3822)	Learning Rate [0.00125]
8: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00098)	Tok/s 32640 (54064)	Loss/tok 3.2227 (3.3891)	Learning Rate [0.00125]
5: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00093)	Tok/s 32511 (53841)	Loss/tok 3.0044 (3.3870)	Learning Rate [0.00125]
6: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00091)	Tok/s 32517 (53907)	Loss/tok 2.7566 (3.3868)	Learning Rate [0.00125]
7: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00097)	Tok/s 32575 (53991)	Loss/tok 3.2221 (3.3810)	Learning Rate [0.00125]
12: TRAIN [1][1420/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00096)	Tok/s 33568 (54395)	Loss/tok 3.1474 (3.3770)	Learning Rate [0.00125]
0: TRAIN [1][1430/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00099)	Tok/s 52011 (53411)	Loss/tok 3.0937 (3.3866)	Learning Rate [0.00125]
15: TRAIN [1][1430/3416]	Time 0.054 (0.058)	Data 0.00094 (0.00092)	Tok/s 53150 (54695)	Loss/tok 3.4962 (3.3841)	Learning Rate [0.00125]
1: TRAIN [1][1430/3416]	Time 0.054 (0.058)	Data 0.00107 (0.00097)	Tok/s 51917 (53511)	Loss/tok 3.2007 (3.3910)	Learning Rate [0.00125]
9: TRAIN [1][1430/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00092)	Tok/s 51618 (54144)	Loss/tok 3.3696 (3.3761)	Learning Rate [0.00125]
14: TRAIN [1][1430/3416]	Time 0.054 (0.058)	Data 0.00106 (0.00093)	Tok/s 53062 (54593)	Loss/tok 3.5420 (3.3843)	Learning Rate [0.00125]
2: TRAIN [1][1430/3416]	Time 0.054 (0.058)	Data 0.00116 (0.00098)	Tok/s 51798 (53602)	Loss/tok 3.4456 (3.3854)	Learning Rate [0.00125]
8: TRAIN [1][1430/3416]	Time 0.055 (0.058)	Data 0.00111 (0.00098)	Tok/s 51512 (54082)	Loss/tok 3.6125 (3.3888)	Learning Rate [0.00125]
7: TRAIN [1][1430/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00097)	Tok/s 51516 (54008)	Loss/tok 3.3352 (3.3810)	Learning Rate [0.00125]
10: TRAIN [1][1430/3416]	Time 0.054 (0.058)	Data 0.00101 (0.00096)	Tok/s 51691 (54233)	Loss/tok 3.3688 (3.3818)	Learning Rate [0.00125]
11: TRAIN [1][1430/3416]	Time 0.055 (0.058)	Data 0.00080 (0.00092)	Tok/s 52739 (54313)	Loss/tok 3.3647 (3.3811)	Learning Rate [0.00125]
3: TRAIN [1][1430/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00093)	Tok/s 51608 (53688)	Loss/tok 3.2077 (3.3853)	Learning Rate [0.00125]
6: TRAIN [1][1430/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00091)	Tok/s 51435 (53925)	Loss/tok 3.4047 (3.3866)	Learning Rate [0.00125]
13: TRAIN [1][1430/3416]	Time 0.054 (0.058)	Data 0.00102 (0.00097)	Tok/s 53016 (54503)	Loss/tok 3.3375 (3.3809)	Learning Rate [0.00125]
5: TRAIN [1][1430/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00093)	Tok/s 51465 (53859)	Loss/tok 3.5312 (3.3865)	Learning Rate [0.00125]
12: TRAIN [1][1430/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00096)	Tok/s 52828 (54415)	Loss/tok 3.3407 (3.3767)	Learning Rate [0.00125]
4: TRAIN [1][1430/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00100)	Tok/s 51428 (53785)	Loss/tok 3.1269 (3.3831)	Learning Rate [0.00125]
7: TRAIN [1][1440/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00097)	Tok/s 52972 (53940)	Loss/tok 3.3865 (3.3800)	Learning Rate [0.00125]
8: TRAIN [1][1440/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00098)	Tok/s 53016 (54014)	Loss/tok 3.3455 (3.3883)	Learning Rate [0.00125]
6: TRAIN [1][1440/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00091)	Tok/s 52836 (53856)	Loss/tok 3.2741 (3.3861)	Learning Rate [0.00125]
4: TRAIN [1][1440/3416]	Time 0.061 (0.058)	Data 0.00105 (0.00100)	Tok/s 52829 (53716)	Loss/tok 3.5355 (3.3828)	Learning Rate [0.00125]
10: TRAIN [1][1440/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00096)	Tok/s 53004 (54163)	Loss/tok 3.6502 (3.3814)	Learning Rate [0.00125]
9: TRAIN [1][1440/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00092)	Tok/s 52980 (54075)	Loss/tok 3.4590 (3.3761)	Learning Rate [0.00125]
5: TRAIN [1][1440/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00093)	Tok/s 52705 (53789)	Loss/tok 3.3290 (3.3862)	Learning Rate [0.00125]
3: TRAIN [1][1440/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00093)	Tok/s 52747 (53619)	Loss/tok 3.0742 (3.3841)	Learning Rate [0.00125]
1: TRAIN [1][1440/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00097)	Tok/s 52878 (53442)	Loss/tok 3.5470 (3.3905)	Learning Rate [0.00125]
2: TRAIN [1][1440/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00098)	Tok/s 52862 (53532)	Loss/tok 3.3318 (3.3851)	Learning Rate [0.00125]
11: TRAIN [1][1440/3416]	Time 0.060 (0.058)	Data 0.00084 (0.00092)	Tok/s 52950 (54243)	Loss/tok 3.4309 (3.3807)	Learning Rate [0.00125]
0: TRAIN [1][1440/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00099)	Tok/s 52862 (53340)	Loss/tok 3.3469 (3.3857)	Learning Rate [0.00125]
15: TRAIN [1][1440/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00092)	Tok/s 53930 (54627)	Loss/tok 3.4600 (3.3833)	Learning Rate [0.00125]
12: TRAIN [1][1440/3416]	Time 0.060 (0.058)	Data 0.00100 (0.00096)	Tok/s 53377 (54346)	Loss/tok 3.4933 (3.3760)	Learning Rate [0.00125]
14: TRAIN [1][1440/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00093)	Tok/s 53940 (54524)	Loss/tok 3.4857 (3.3839)	Learning Rate [0.00125]
13: TRAIN [1][1440/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00097)	Tok/s 54006 (54434)	Loss/tok 3.3459 (3.3801)	Learning Rate [0.00125]
3: TRAIN [1][1450/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00093)	Tok/s 54462 (53624)	Loss/tok 3.5581 (3.3842)	Learning Rate [0.00125]
2: TRAIN [1][1450/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00098)	Tok/s 54476 (53538)	Loss/tok 3.5815 (3.3861)	Learning Rate [0.00125]
1: TRAIN [1][1450/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00097)	Tok/s 54493 (53448)	Loss/tok 3.2177 (3.3905)	Learning Rate [0.00125]
0: TRAIN [1][1450/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00099)	Tok/s 54536 (53347)	Loss/tok 3.5050 (3.3858)	Learning Rate [0.00125]
4: TRAIN [1][1450/3416]	Time 0.064 (0.058)	Data 0.00112 (0.00100)	Tok/s 54331 (53722)	Loss/tok 3.5695 (3.3833)	Learning Rate [0.00125]
15: TRAIN [1][1450/3416]	Time 0.063 (0.058)	Data 0.00107 (0.00092)	Tok/s 55312 (54630)	Loss/tok 3.5075 (3.3836)	Learning Rate [0.00125]
6: TRAIN [1][1450/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00091)	Tok/s 54184 (53861)	Loss/tok 3.4159 (3.3867)	Learning Rate [0.00125]
5: TRAIN [1][1450/3416]	Time 0.064 (0.058)	Data 0.00102 (0.00093)	Tok/s 54283 (53794)	Loss/tok 3.4115 (3.3868)	Learning Rate [0.00125]
14: TRAIN [1][1450/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00093)	Tok/s 54518 (54526)	Loss/tok 3.5403 (3.3842)	Learning Rate [0.00125]
13: TRAIN [1][1450/3416]	Time 0.063 (0.058)	Data 0.00108 (0.00097)	Tok/s 54429 (54437)	Loss/tok 3.8761 (3.3810)	Learning Rate [0.00125]
7: TRAIN [1][1450/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00097)	Tok/s 54099 (53944)	Loss/tok 3.6609 (3.3804)	Learning Rate [0.00125]
8: TRAIN [1][1450/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00098)	Tok/s 54112 (54017)	Loss/tok 3.3369 (3.3882)	Learning Rate [0.00125]
11: TRAIN [1][1450/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00092)	Tok/s 54243 (54246)	Loss/tok 3.3685 (3.3811)	Learning Rate [0.00125]
9: TRAIN [1][1450/3416]	Time 0.064 (0.058)	Data 0.00101 (0.00092)	Tok/s 54109 (54079)	Loss/tok 3.4219 (3.3766)	Learning Rate [0.00125]
12: TRAIN [1][1450/3416]	Time 0.064 (0.058)	Data 0.00100 (0.00096)	Tok/s 54340 (54349)	Loss/tok 3.3513 (3.3767)	Learning Rate [0.00125]
10: TRAIN [1][1450/3416]	Time 0.064 (0.058)	Data 0.00100 (0.00096)	Tok/s 54002 (54166)	Loss/tok 3.4170 (3.3814)	Learning Rate [0.00125]
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
4: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00100)	Tok/s 50792 (53712)	Loss/tok 3.3551 (3.3822)	Learning Rate [0.00125]
2: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00098)	Tok/s 50749 (53528)	Loss/tok 3.3298 (3.3852)	Learning Rate [0.00125]
6: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00091)	Tok/s 50846 (53851)	Loss/tok 3.2345 (3.3862)	Learning Rate [0.00125]
3: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00093)	Tok/s 50642 (53613)	Loss/tok 3.5405 (3.3837)	Learning Rate [0.00125]
5: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00093)	Tok/s 50724 (53785)	Loss/tok 3.2033 (3.3867)	Learning Rate [0.00125]
1: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00097)	Tok/s 50683 (53438)	Loss/tok 3.2806 (3.3900)	Learning Rate [0.00125]
7: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00097)	Tok/s 50814 (53934)	Loss/tok 3.4008 (3.3794)	Learning Rate [0.00125]
0: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00099)	Tok/s 50692 (53336)	Loss/tok 3.1315 (3.3843)	Learning Rate [0.00125]
8: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00098)	Tok/s 50803 (54008)	Loss/tok 3.3041 (3.3880)	Learning Rate [0.00125]
9: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00092)	Tok/s 50862 (54070)	Loss/tok 3.7480 (3.3761)	Learning Rate [0.00125]
15: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00092)	Tok/s 50684 (54623)	Loss/tok 3.0783 (3.3831)	Learning Rate [0.00125]
14: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00093)	Tok/s 50691 (54519)	Loss/tok 3.3976 (3.3833)	Learning Rate [0.00125]
11: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00083 (0.00092)	Tok/s 50675 (54237)	Loss/tok 3.3402 (3.3807)	Learning Rate [0.00125]
13: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00106 (0.00097)	Tok/s 50715 (54427)	Loss/tok 3.2781 (3.3809)	Learning Rate [0.00125]
10: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00096)	Tok/s 50783 (54157)	Loss/tok 3.3130 (3.3807)	Learning Rate [0.00125]
12: TRAIN [1][1460/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00096)	Tok/s 50706 (54339)	Loss/tok 3.1107 (3.3763)	Learning Rate [0.00125]
0: TRAIN [1][1470/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00099)	Tok/s 59885 (53308)	Loss/tok 3.4544 (3.3839)	Learning Rate [0.00125]
1: TRAIN [1][1470/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00097)	Tok/s 59814 (53409)	Loss/tok 3.4117 (3.3894)	Learning Rate [0.00125]
2: TRAIN [1][1470/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00098)	Tok/s 59771 (53498)	Loss/tok 3.6145 (3.3850)	Learning Rate [0.00125]
13: TRAIN [1][1470/3416]	Time 0.068 (0.058)	Data 0.00115 (0.00097)	Tok/s 60248 (54397)	Loss/tok 3.4706 (3.3810)	Learning Rate [0.00125]
14: TRAIN [1][1470/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00093)	Tok/s 60771 (54489)	Loss/tok 3.3179 (3.3830)	Learning Rate [0.00125]
12: TRAIN [1][1470/3416]	Time 0.068 (0.058)	Data 0.00110 (0.00096)	Tok/s 59974 (54309)	Loss/tok 3.3141 (3.3764)	Learning Rate [0.00125]
4: TRAIN [1][1470/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00100)	Tok/s 59778 (53682)	Loss/tok 3.4899 (3.3821)	Learning Rate [0.00125]
5: TRAIN [1][1470/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00093)	Tok/s 59860 (53755)	Loss/tok 3.7166 (3.3865)	Learning Rate [0.00125]
3: TRAIN [1][1470/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 59725 (53583)	Loss/tok 3.3639 (3.3835)	Learning Rate [0.00125]
15: TRAIN [1][1470/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00092)	Tok/s 60769 (54593)	Loss/tok 3.4815 (3.3830)	Learning Rate [0.00125]
11: TRAIN [1][1470/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 59748 (54206)	Loss/tok 3.4885 (3.3806)	Learning Rate [0.00125]
10: TRAIN [1][1470/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00096)	Tok/s 59902 (54126)	Loss/tok 3.6343 (3.3808)	Learning Rate [0.00125]
6: TRAIN [1][1470/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00091)	Tok/s 59750 (53821)	Loss/tok 3.6105 (3.3861)	Learning Rate [0.00125]
9: TRAIN [1][1470/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00092)	Tok/s 59783 (54039)	Loss/tok 3.3990 (3.3760)	Learning Rate [0.00125]
7: TRAIN [1][1470/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00097)	Tok/s 59816 (53904)	Loss/tok 3.6575 (3.3796)	Learning Rate [0.00125]
8: TRAIN [1][1470/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00098)	Tok/s 59848 (53978)	Loss/tok 3.6228 (3.3875)	Learning Rate [0.00125]
15: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00082 (0.00092)	Tok/s 51924 (54570)	Loss/tok 3.2215 (3.3826)	Learning Rate [0.00125]
0: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00101 (0.00099)	Tok/s 51819 (53271)	Loss/tok 3.2968 (3.3837)	Learning Rate [0.00125]
14: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00080 (0.00093)	Tok/s 51892 (54465)	Loss/tok 3.3972 (3.3827)	Learning Rate [0.00125]
1: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00097)	Tok/s 51791 (53373)	Loss/tok 3.2969 (3.3887)	Learning Rate [0.00125]
12: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00096)	Tok/s 51919 (54283)	Loss/tok 3.4406 (3.3762)	Learning Rate [0.00125]
2: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00098)	Tok/s 51805 (53464)	Loss/tok 3.1177 (3.3847)	Learning Rate [0.00125]
11: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00080 (0.00092)	Tok/s 51880 (54180)	Loss/tok 3.1756 (3.3803)	Learning Rate [0.00125]
3: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00080 (0.00093)	Tok/s 51761 (53552)	Loss/tok 3.3997 (3.3834)	Learning Rate [0.00125]
9: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00092)	Tok/s 51928 (54013)	Loss/tok 3.2734 (3.3756)	Learning Rate [0.00125]
4: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00107 (0.00100)	Tok/s 51914 (53650)	Loss/tok 3.4265 (3.3813)	Learning Rate [0.00125]
5: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00093)	Tok/s 51797 (53724)	Loss/tok 3.1195 (3.3852)	Learning Rate [0.00125]
10: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00096)	Tok/s 51961 (54099)	Loss/tok 3.5589 (3.3802)	Learning Rate [0.00125]
6: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00081 (0.00091)	Tok/s 51785 (53791)	Loss/tok 3.3963 (3.3858)	Learning Rate [0.00125]
8: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00098)	Tok/s 51893 (53951)	Loss/tok 3.6585 (3.3875)	Learning Rate [0.00125]
13: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00119 (0.00097)	Tok/s 51925 (54373)	Loss/tok 3.4646 (3.3809)	Learning Rate [0.00125]
7: TRAIN [1][1480/3416]	Time 0.053 (0.058)	Data 0.00109 (0.00097)	Tok/s 51851 (53875)	Loss/tok 3.5239 (3.3798)	Learning Rate [0.00125]
3: TRAIN [1][1490/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00093)	Tok/s 52728 (53523)	Loss/tok 3.3521 (3.3833)	Learning Rate [0.00125]
5: TRAIN [1][1490/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00093)	Tok/s 52749 (53696)	Loss/tok 3.1825 (3.3849)	Learning Rate [0.00125]
2: TRAIN [1][1490/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00098)	Tok/s 51661 (53435)	Loss/tok 3.6871 (3.3845)	Learning Rate [0.00125]
6: TRAIN [1][1490/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00091)	Tok/s 52680 (53763)	Loss/tok 3.3574 (3.3854)	Learning Rate [0.00125]
4: TRAIN [1][1490/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00100)	Tok/s 52629 (53621)	Loss/tok 3.4449 (3.3811)	Learning Rate [0.00125]
1: TRAIN [1][1490/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00097)	Tok/s 51474 (53344)	Loss/tok 3.4273 (3.3886)	Learning Rate [0.00125]
15: TRAIN [1][1490/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00092)	Tok/s 52362 (54538)	Loss/tok 3.4182 (3.3821)	Learning Rate [0.00125]
0: TRAIN [1][1490/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00099)	Tok/s 51416 (53242)	Loss/tok 3.2052 (3.3831)	Learning Rate [0.00125]
14: TRAIN [1][1490/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00093)	Tok/s 52354 (54434)	Loss/tok 3.3486 (3.3825)	Learning Rate [0.00125]
9: TRAIN [1][1490/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00092)	Tok/s 52508 (53984)	Loss/tok 3.2170 (3.3753)	Learning Rate [0.00125]
11: TRAIN [1][1490/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00092)	Tok/s 52386 (54150)	Loss/tok 3.7362 (3.3808)	Learning Rate [0.00125]
7: TRAIN [1][1490/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00097)	Tok/s 52602 (53848)	Loss/tok 3.4645 (3.3797)	Learning Rate [0.00125]
8: TRAIN [1][1490/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00098)	Tok/s 52538 (53922)	Loss/tok 3.2097 (3.3867)	Learning Rate [0.00125]
10: TRAIN [1][1490/3416]	Time 0.063 (0.058)	Data 0.00103 (0.00096)	Tok/s 52436 (54070)	Loss/tok 3.3380 (3.3800)	Learning Rate [0.00125]
13: TRAIN [1][1490/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00097)	Tok/s 52299 (54342)	Loss/tok 3.2130 (3.3805)	Learning Rate [0.00125]
12: TRAIN [1][1490/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00096)	Tok/s 52294 (54252)	Loss/tok 3.4521 (3.3762)	Learning Rate [0.00125]
4: Gradient norm: inf
3: Gradient norm: inf
5: Gradient norm: inf
2: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
15: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
13: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
12: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
15: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00092)	Tok/s 48897 (54568)	Loss/tok 3.3511 (3.3821)	Learning Rate [0.00125]
14: TRAIN [1][1500/3416]	Time 0.044 (0.058)	Data 0.00083 (0.00093)	Tok/s 48907 (54463)	Loss/tok 3.1033 (3.3824)	Learning Rate [0.00125]
0: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00099)	Tok/s 48766 (53272)	Loss/tok 3.1771 (3.3834)	Learning Rate [0.00125]
1: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00097)	Tok/s 48677 (53374)	Loss/tok 3.1563 (3.3890)	Learning Rate [0.00125]
13: TRAIN [1][1500/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00097)	Tok/s 49062 (54371)	Loss/tok 3.4021 (3.3808)	Learning Rate [0.00125]
2: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00098)	Tok/s 48525 (53464)	Loss/tok 3.1763 (3.3841)	Learning Rate [0.00125]
12: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00096)	Tok/s 48843 (54282)	Loss/tok 3.2240 (3.3762)	Learning Rate [0.00125]
11: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00092)	Tok/s 48705 (54179)	Loss/tok 3.1741 (3.3806)	Learning Rate [0.00125]
3: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00093)	Tok/s 48419 (53552)	Loss/tok 3.2009 (3.3832)	Learning Rate [0.00125]
10: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00096)	Tok/s 48646 (54099)	Loss/tok 3.2983 (3.3800)	Learning Rate [0.00125]
9: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00092)	Tok/s 48491 (54012)	Loss/tok 3.2822 (3.3754)	Learning Rate [0.00125]
4: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00100)	Tok/s 48314 (53650)	Loss/tok 3.3182 (3.3812)	Learning Rate [0.00125]
6: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00091)	Tok/s 48189 (53791)	Loss/tok 3.1918 (3.3860)	Learning Rate [0.00125]
5: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00093)	Tok/s 48206 (53724)	Loss/tok 3.2216 (3.3851)	Learning Rate [0.00125]
8: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00098)	Tok/s 48348 (53952)	Loss/tok 2.9571 (3.3863)	Learning Rate [0.00125]
7: TRAIN [1][1500/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00097)	Tok/s 48257 (53876)	Loss/tok 3.2971 (3.3796)	Learning Rate [0.00125]
9: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 62811 (53996)	Loss/tok 3.2423 (3.3747)	Learning Rate [0.00125]
11: TRAIN [1][1510/3416]	Time 0.070 (0.058)	Data 0.00075 (0.00092)	Tok/s 62576 (54163)	Loss/tok 3.6397 (3.3804)	Learning Rate [0.00125]
10: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 62722 (54082)	Loss/tok 3.6041 (3.3800)	Learning Rate [0.00125]
8: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00098)	Tok/s 62738 (53936)	Loss/tok 3.3064 (3.3864)	Learning Rate [0.00125]
7: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00097)	Tok/s 62769 (53860)	Loss/tok 3.3561 (3.3788)	Learning Rate [0.00125]
6: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00091)	Tok/s 62714 (53774)	Loss/tok 3.3609 (3.3858)	Learning Rate [0.00125]
12: TRAIN [1][1510/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 62602 (54267)	Loss/tok 3.6155 (3.3760)	Learning Rate [0.00125]
5: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00093)	Tok/s 62812 (53707)	Loss/tok 3.4028 (3.3848)	Learning Rate [0.00125]
13: TRAIN [1][1510/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 62548 (54357)	Loss/tok 3.4685 (3.3807)	Learning Rate [0.00125]
0: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00099)	Tok/s 62641 (53248)	Loss/tok 3.4963 (3.3835)	Learning Rate [0.00125]
14: TRAIN [1][1510/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 62669 (54449)	Loss/tok 3.2411 (3.3821)	Learning Rate [0.00125]
4: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 62743 (53631)	Loss/tok 3.5846 (3.3810)	Learning Rate [0.00125]
15: TRAIN [1][1510/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 63419 (54554)	Loss/tok 3.5682 (3.3821)	Learning Rate [0.00125]
3: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00093)	Tok/s 62682 (53532)	Loss/tok 3.3819 (3.3831)	Learning Rate [0.00125]
2: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 62627 (53444)	Loss/tok 3.7017 (3.3842)	Learning Rate [0.00125]
1: TRAIN [1][1510/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 62158 (53351)	Loss/tok 3.5455 (3.3892)	Learning Rate [0.00125]
4: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00100)	Tok/s 36886 (53654)	Loss/tok 3.1422 (3.3811)	Learning Rate [0.00125]
5: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00093)	Tok/s 37224 (53731)	Loss/tok 3.0965 (3.3853)	Learning Rate [0.00125]
2: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00098)	Tok/s 36954 (53467)	Loss/tok 3.2870 (3.3846)	Learning Rate [0.00125]
6: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00091)	Tok/s 38032 (53799)	Loss/tok 3.0702 (3.3859)	Learning Rate [0.00125]
1: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00097)	Tok/s 36958 (53375)	Loss/tok 3.1286 (3.3889)	Learning Rate [0.00125]
3: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00093)	Tok/s 36933 (53555)	Loss/tok 3.0437 (3.3832)	Learning Rate [0.00125]
0: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00099)	Tok/s 36965 (53273)	Loss/tok 3.2798 (3.3835)	Learning Rate [0.00125]
7: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00118 (0.00097)	Tok/s 38037 (53884)	Loss/tok 3.2444 (3.3793)	Learning Rate [0.00125]
8: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00098)	Tok/s 38081 (53959)	Loss/tok 3.1914 (3.3866)	Learning Rate [0.00125]
15: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00092)	Tok/s 38239 (54576)	Loss/tok 3.2457 (3.3828)	Learning Rate [0.00125]
9: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00092)	Tok/s 38043 (54020)	Loss/tok 2.9997 (3.3751)	Learning Rate [0.00125]
14: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00093)	Tok/s 38214 (54471)	Loss/tok 3.1325 (3.3822)	Learning Rate [0.00125]
10: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00096)	Tok/s 38102 (54105)	Loss/tok 3.1107 (3.3804)	Learning Rate [0.00125]
11: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00092)	Tok/s 38057 (54187)	Loss/tok 3.1656 (3.3810)	Learning Rate [0.00125]
13: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00097)	Tok/s 38199 (54379)	Loss/tok 3.2713 (3.3809)	Learning Rate [0.00125]
12: TRAIN [1][1520/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00096)	Tok/s 38065 (54290)	Loss/tok 2.9637 (3.3762)	Learning Rate [0.00125]
8: TRAIN [1][1530/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00098)	Tok/s 38352 (53956)	Loss/tok 3.1400 (3.3866)	Learning Rate [0.00125]
9: TRAIN [1][1530/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00092)	Tok/s 38431 (54016)	Loss/tok 3.2054 (3.3750)	Learning Rate [0.00125]
6: TRAIN [1][1530/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00091)	Tok/s 38203 (53795)	Loss/tok 3.1237 (3.3860)	Learning Rate [0.00125]
10: TRAIN [1][1530/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00096)	Tok/s 38361 (54101)	Loss/tok 3.1260 (3.3800)	Learning Rate [0.00125]
11: TRAIN [1][1530/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 38306 (54183)	Loss/tok 2.8800 (3.3811)	Learning Rate [0.00125]
5: TRAIN [1][1530/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00093)	Tok/s 38089 (53726)	Loss/tok 3.3213 (3.3856)	Learning Rate [0.00125]
4: TRAIN [1][1530/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00100)	Tok/s 37502 (53650)	Loss/tok 3.2904 (3.3814)	Learning Rate [0.00125]
12: TRAIN [1][1530/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00096)	Tok/s 38323 (54286)	Loss/tok 3.0888 (3.3762)	Learning Rate [0.00125]
3: TRAIN [1][1530/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00093)	Tok/s 36790 (53551)	Loss/tok 2.8959 (3.3834)	Learning Rate [0.00125]
2: TRAIN [1][1530/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00098)	Tok/s 36759 (53464)	Loss/tok 3.2053 (3.3851)	Learning Rate [0.00125]
13: TRAIN [1][1530/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00097)	Tok/s 38235 (54375)	Loss/tok 3.0354 (3.3808)	Learning Rate [0.00125]
14: TRAIN [1][1530/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00093)	Tok/s 38165 (54466)	Loss/tok 3.2718 (3.3824)	Learning Rate [0.00125]
1: TRAIN [1][1530/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00097)	Tok/s 36734 (53372)	Loss/tok 3.1500 (3.3892)	Learning Rate [0.00125]
15: TRAIN [1][1530/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00092)	Tok/s 38062 (54572)	Loss/tok 3.2571 (3.3827)	Learning Rate [0.00125]
7: TRAIN [1][1530/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00097)	Tok/s 37622 (53880)	Loss/tok 2.9201 (3.3799)	Learning Rate [0.00125]
0: TRAIN [1][1530/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00099)	Tok/s 36125 (53270)	Loss/tok 3.0676 (3.3839)	Learning Rate [0.00125]
11: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00092)	Tok/s 51329 (54177)	Loss/tok 3.4633 (3.3809)	Learning Rate [0.00125]
12: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00096)	Tok/s 51360 (54281)	Loss/tok 3.3710 (3.3756)	Learning Rate [0.00125]
9: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00092)	Tok/s 51118 (54010)	Loss/tok 3.3764 (3.3748)	Learning Rate [0.00125]
10: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00102 (0.00096)	Tok/s 51229 (54095)	Loss/tok 3.3660 (3.3799)	Learning Rate [0.00125]
13: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00097)	Tok/s 51327 (54369)	Loss/tok 3.3472 (3.3808)	Learning Rate [0.00125]
8: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00102 (0.00098)	Tok/s 51102 (53949)	Loss/tok 3.5167 (3.3868)	Learning Rate [0.00125]
14: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00093)	Tok/s 51272 (54461)	Loss/tok 3.3069 (3.3823)	Learning Rate [0.00125]
6: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00091)	Tok/s 51154 (53787)	Loss/tok 3.6971 (3.3857)	Learning Rate [0.00125]
7: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00097)	Tok/s 51120 (53873)	Loss/tok 3.1887 (3.3803)	Learning Rate [0.00125]
15: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00092)	Tok/s 51225 (54566)	Loss/tok 3.2455 (3.3830)	Learning Rate [0.00125]
0: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00099)	Tok/s 50014 (53264)	Loss/tok 3.0522 (3.3837)	Learning Rate [0.00125]
5: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00093)	Tok/s 51099 (53719)	Loss/tok 3.3602 (3.3858)	Learning Rate [0.00125]
1: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00097)	Tok/s 50045 (53365)	Loss/tok 3.2078 (3.3892)	Learning Rate [0.00125]
4: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00117 (0.00100)	Tok/s 49954 (53642)	Loss/tok 3.4245 (3.3815)	Learning Rate [0.00125]
3: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00093)	Tok/s 49980 (53543)	Loss/tok 3.4179 (3.3838)	Learning Rate [0.00125]
2: TRAIN [1][1540/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00098)	Tok/s 50136 (53456)	Loss/tok 3.5466 (3.3852)	Learning Rate [0.00125]
11: TRAIN [1][1550/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 65560 (54157)	Loss/tok 3.6395 (3.3810)	Learning Rate [0.00125]
9: TRAIN [1][1550/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 65516 (53989)	Loss/tok 3.3276 (3.3749)	Learning Rate [0.00125]
13: TRAIN [1][1550/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 65386 (54349)	Loss/tok 3.7317 (3.3809)	Learning Rate [0.00125]
10: TRAIN [1][1550/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 65495 (54073)	Loss/tok 3.2702 (3.3798)	Learning Rate [0.00125]
12: TRAIN [1][1550/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 65410 (54260)	Loss/tok 3.5373 (3.3758)	Learning Rate [0.00125]
8: TRAIN [1][1550/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 65552 (53929)	Loss/tok 3.8287 (3.3871)	Learning Rate [0.00125]
14: TRAIN [1][1550/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 65352 (54440)	Loss/tok 3.3356 (3.3821)	Learning Rate [0.00125]
6: TRAIN [1][1550/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00091)	Tok/s 65612 (53767)	Loss/tok 3.5363 (3.3852)	Learning Rate [0.00125]
15: TRAIN [1][1550/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 66164 (54544)	Loss/tok 3.4547 (3.3827)	Learning Rate [0.00125]
7: TRAIN [1][1550/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 65518 (53853)	Loss/tok 3.2969 (3.3799)	Learning Rate [0.00125]
5: TRAIN [1][1550/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 65579 (53699)	Loss/tok 3.5620 (3.3855)	Learning Rate [0.00125]
0: TRAIN [1][1550/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00099)	Tok/s 64281 (53243)	Loss/tok 3.8164 (3.3837)	Learning Rate [0.00125]
3: TRAIN [1][1550/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 65329 (53522)	Loss/tok 3.5245 (3.3839)	Learning Rate [0.00125]
1: TRAIN [1][1550/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 65084 (53345)	Loss/tok 3.5567 (3.3891)	Learning Rate [0.00125]
4: TRAIN [1][1550/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00100)	Tok/s 65352 (53621)	Loss/tok 3.4137 (3.3814)	Learning Rate [0.00125]
2: TRAIN [1][1550/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00098)	Tok/s 65234 (53435)	Loss/tok 3.2965 (3.3852)	Learning Rate [0.00125]
6: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00091)	Tok/s 53450 (53736)	Loss/tok 3.1028 (3.3845)	Learning Rate [0.00125]
5: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00093)	Tok/s 53525 (53669)	Loss/tok 3.3510 (3.3851)	Learning Rate [0.00125]
4: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00108 (0.00100)	Tok/s 53532 (53592)	Loss/tok 3.7968 (3.3813)	Learning Rate [0.00125]
3: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00083 (0.00093)	Tok/s 53558 (53494)	Loss/tok 3.4768 (3.3843)	Learning Rate [0.00125]
7: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00097)	Tok/s 53450 (53822)	Loss/tok 3.3994 (3.3795)	Learning Rate [0.00125]
2: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00084 (0.00098)	Tok/s 53562 (53407)	Loss/tok 3.4538 (3.3847)	Learning Rate [0.00125]
8: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00098)	Tok/s 53434 (53898)	Loss/tok 3.3638 (3.3871)	Learning Rate [0.00125]
1: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00084 (0.00097)	Tok/s 53565 (53317)	Loss/tok 3.4599 (3.3890)	Learning Rate [0.00125]
9: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00092)	Tok/s 53452 (53957)	Loss/tok 3.3115 (3.3744)	Learning Rate [0.00125]
0: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00099)	Tok/s 53581 (53217)	Loss/tok 3.3784 (3.3834)	Learning Rate [0.00125]
10: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00096)	Tok/s 53538 (54041)	Loss/tok 3.6136 (3.3799)	Learning Rate [0.00125]
15: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00082 (0.00092)	Tok/s 54580 (54512)	Loss/tok 3.2773 (3.3829)	Learning Rate [0.00125]
11: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00080 (0.00092)	Tok/s 54106 (54126)	Loss/tok 3.3156 (3.3804)	Learning Rate [0.00125]
14: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00093)	Tok/s 54564 (54409)	Loss/tok 3.4579 (3.3819)	Learning Rate [0.00125]
12: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00096)	Tok/s 54470 (54230)	Loss/tok 3.4889 (3.3762)	Learning Rate [0.00125]
13: TRAIN [1][1560/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00097)	Tok/s 54560 (54318)	Loss/tok 3.4611 (3.3811)	Learning Rate [0.00125]
9: TRAIN [1][1570/3416]	Time 0.053 (0.058)	Data 0.00081 (0.00092)	Tok/s 52018 (53923)	Loss/tok 3.2560 (3.3740)	Learning Rate [0.00125]
10: TRAIN [1][1570/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00096)	Tok/s 51922 (54007)	Loss/tok 3.2968 (3.3796)	Learning Rate [0.00125]
8: TRAIN [1][1570/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00098)	Tok/s 51914 (53864)	Loss/tok 3.4114 (3.3873)	Learning Rate [0.00125]
11: TRAIN [1][1570/3416]	Time 0.053 (0.058)	Data 0.00082 (0.00092)	Tok/s 51836 (54092)	Loss/tok 3.4036 (3.3804)	Learning Rate [0.00125]
6: TRAIN [1][1570/3416]	Time 0.053 (0.058)	Data 0.00080 (0.00091)	Tok/s 51693 (53704)	Loss/tok 3.2617 (3.3839)	Learning Rate [0.00125]
7: TRAIN [1][1570/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00097)	Tok/s 51823 (53788)	Loss/tok 3.3593 (3.3790)	Learning Rate [0.00125]
12: TRAIN [1][1570/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00096)	Tok/s 51702 (54195)	Loss/tok 3.5082 (3.3760)	Learning Rate [0.00125]
4: TRAIN [1][1570/3416]	Time 0.053 (0.058)	Data 0.00102 (0.00100)	Tok/s 51547 (53559)	Loss/tok 3.4368 (3.3811)	Learning Rate [0.00125]
13: TRAIN [1][1570/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00097)	Tok/s 51614 (54286)	Loss/tok 3.3524 (3.3808)	Learning Rate [0.00125]
14: TRAIN [1][1570/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00093)	Tok/s 51518 (54376)	Loss/tok 3.0643 (3.3816)	Learning Rate [0.00125]
5: TRAIN [1][1570/3416]	Time 0.053 (0.058)	Data 0.00079 (0.00093)	Tok/s 51639 (53636)	Loss/tok 3.4275 (3.3848)	Learning Rate [0.00125]
15: TRAIN [1][1570/3416]	Time 0.054 (0.058)	Data 0.00085 (0.00092)	Tok/s 51404 (54479)	Loss/tok 3.4308 (3.3826)	Learning Rate [0.00125]
2: TRAIN [1][1570/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00098)	Tok/s 51268 (53374)	Loss/tok 3.5073 (3.3844)	Learning Rate [0.00125]
1: TRAIN [1][1570/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00097)	Tok/s 51194 (53284)	Loss/tok 3.2183 (3.3884)	Learning Rate [0.00125]
0: TRAIN [1][1570/3416]	Time 0.054 (0.058)	Data 0.00100 (0.00099)	Tok/s 51351 (53185)	Loss/tok 3.5580 (3.3832)	Learning Rate [0.00125]
3: TRAIN [1][1570/3416]	Time 0.054 (0.058)	Data 0.00081 (0.00093)	Tok/s 51352 (53461)	Loss/tok 3.5341 (3.3839)	Learning Rate [0.00125]
6: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00091)	Tok/s 50294 (53649)	Loss/tok 3.0022 (3.3836)	Learning Rate [0.00125]
7: TRAIN [1][1580/3416]	Time 0.044 (0.058)	Data 0.00105 (0.00097)	Tok/s 50346 (53735)	Loss/tok 3.1660 (3.3787)	Learning Rate [0.00125]
8: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00098)	Tok/s 50171 (53812)	Loss/tok 3.1992 (3.3868)	Learning Rate [0.00125]
5: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00081 (0.00093)	Tok/s 50073 (53581)	Loss/tok 3.3147 (3.3848)	Learning Rate [0.00125]
9: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00092)	Tok/s 50046 (53871)	Loss/tok 3.1655 (3.3740)	Learning Rate [0.00125]
4: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00100)	Tok/s 50028 (53502)	Loss/tok 3.1141 (3.3809)	Learning Rate [0.00125]
3: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00093)	Tok/s 49945 (53401)	Loss/tok 3.1500 (3.3834)	Learning Rate [0.00125]
10: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00096)	Tok/s 49970 (53954)	Loss/tok 3.1892 (3.3795)	Learning Rate [0.00125]
2: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00098)	Tok/s 49798 (53311)	Loss/tok 3.4862 (3.3843)	Learning Rate [0.00125]
11: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00092)	Tok/s 49785 (54039)	Loss/tok 3.2980 (3.3795)	Learning Rate [0.00125]
12: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00096)	Tok/s 49771 (54145)	Loss/tok 3.2325 (3.3760)	Learning Rate [0.00125]
1: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00097)	Tok/s 48886 (53217)	Loss/tok 3.2896 (3.3881)	Learning Rate [0.00125]
0: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00099)	Tok/s 48151 (53115)	Loss/tok 3.2131 (3.3829)	Learning Rate [0.00125]
15: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00092)	Tok/s 49419 (54431)	Loss/tok 3.5239 (3.3821)	Learning Rate [0.00125]
13: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00097)	Tok/s 49580 (54236)	Loss/tok 3.3176 (3.3805)	Learning Rate [0.00125]
14: TRAIN [1][1580/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00093)	Tok/s 49459 (54328)	Loss/tok 3.2687 (3.3812)	Learning Rate [0.00125]
7: TRAIN [1][1590/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00097)	Tok/s 32423 (53705)	Loss/tok 2.8809 (3.3785)	Learning Rate [0.00125]
6: TRAIN [1][1590/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00091)	Tok/s 32328 (53620)	Loss/tok 3.1611 (3.3833)	Learning Rate [0.00125]
8: TRAIN [1][1590/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00098)	Tok/s 32391 (53781)	Loss/tok 2.9824 (3.3863)	Learning Rate [0.00125]
9: TRAIN [1][1590/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 33279 (53841)	Loss/tok 2.8416 (3.3737)	Learning Rate [0.00125]
5: TRAIN [1][1590/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 32308 (53552)	Loss/tok 2.9840 (3.3847)	Learning Rate [0.00125]
4: TRAIN [1][1590/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00100)	Tok/s 32316 (53473)	Loss/tok 2.7730 (3.3806)	Learning Rate [0.00125]
3: TRAIN [1][1590/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00093)	Tok/s 32316 (53372)	Loss/tok 2.7908 (3.3826)	Learning Rate [0.00125]
11: TRAIN [1][1590/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00092)	Tok/s 33658 (54008)	Loss/tok 3.2381 (3.3789)	Learning Rate [0.00125]
2: TRAIN [1][1590/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00098)	Tok/s 32310 (53282)	Loss/tok 3.0878 (3.3842)	Learning Rate [0.00125]
1: TRAIN [1][1590/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00097)	Tok/s 32293 (53188)	Loss/tok 3.2080 (3.3878)	Learning Rate [0.00125]
12: TRAIN [1][1590/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00096)	Tok/s 33639 (54114)	Loss/tok 2.9554 (3.3755)	Learning Rate [0.00125]
14: TRAIN [1][1590/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00093)	Tok/s 33670 (54296)	Loss/tok 3.1041 (3.3808)	Learning Rate [0.00125]
15: TRAIN [1][1590/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00092)	Tok/s 33743 (54400)	Loss/tok 2.7538 (3.3814)	Learning Rate [0.00125]
13: TRAIN [1][1590/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00097)	Tok/s 33628 (54205)	Loss/tok 3.0629 (3.3798)	Learning Rate [0.00125]
10: TRAIN [1][1590/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00096)	Tok/s 33649 (53924)	Loss/tok 3.0062 (3.3794)	Learning Rate [0.00125]
0: TRAIN [1][1590/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00099)	Tok/s 32258 (53086)	Loss/tok 3.0386 (3.3828)	Learning Rate [0.00125]
15: TRAIN [1][1600/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 84437 (54449)	Loss/tok 3.2537 (3.3809)	Learning Rate [0.00125]
14: TRAIN [1][1600/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00093)	Tok/s 83749 (54345)	Loss/tok 3.1908 (3.3808)	Learning Rate [0.00125]
0: TRAIN [1][1600/3416]	Time 0.071 (0.058)	Data 0.00106 (0.00099)	Tok/s 81660 (53129)	Loss/tok 3.2420 (3.3824)	Learning Rate [0.00125]
1: TRAIN [1][1600/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00097)	Tok/s 81698 (53231)	Loss/tok 3.1093 (3.3872)	Learning Rate [0.00125]
13: TRAIN [1][1600/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 83553 (54252)	Loss/tok 3.3405 (3.3793)	Learning Rate [0.00125]
12: TRAIN [1][1600/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 83604 (54160)	Loss/tok 3.2155 (3.3756)	Learning Rate [0.00125]
2: TRAIN [1][1600/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 81737 (53325)	Loss/tok 3.2068 (3.3838)	Learning Rate [0.00125]
11: TRAIN [1][1600/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 83587 (54054)	Loss/tok 3.4033 (3.3792)	Learning Rate [0.00125]
6: TRAIN [1][1600/3416]	Time 0.071 (0.058)	Data 0.00084 (0.00091)	Tok/s 82537 (53664)	Loss/tok 3.2303 (3.3833)	Learning Rate [0.00125]
3: TRAIN [1][1600/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 81711 (53415)	Loss/tok 3.1692 (3.3828)	Learning Rate [0.00125]
7: TRAIN [1][1600/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 82674 (53749)	Loss/tok 3.2120 (3.3782)	Learning Rate [0.00125]
8: TRAIN [1][1600/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 82680 (53826)	Loss/tok 3.1847 (3.3856)	Learning Rate [0.00125]
4: TRAIN [1][1600/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00100)	Tok/s 81747 (53517)	Loss/tok 3.2740 (3.3802)	Learning Rate [0.00125]
10: TRAIN [1][1600/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00096)	Tok/s 83354 (53969)	Loss/tok 3.2191 (3.3796)	Learning Rate [0.00125]
9: TRAIN [1][1600/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 82731 (53885)	Loss/tok 3.1036 (3.3732)	Learning Rate [0.00125]
5: TRAIN [1][1600/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00093)	Tok/s 82628 (53596)	Loss/tok 3.0654 (3.3837)	Learning Rate [0.00125]
6: TRAIN [1][1610/3416]	Time 0.032 (0.058)	Data 0.00087 (0.00091)	Tok/s 22296 (53675)	Loss/tok 2.2360 (3.3825)	Learning Rate [0.00125]
4: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00095 (0.00100)	Tok/s 18923 (53526)	Loss/tok 1.9954 (3.3800)	Learning Rate [0.00125]
7: TRAIN [1][1610/3416]	Time 0.032 (0.058)	Data 0.00089 (0.00097)	Tok/s 23685 (53761)	Loss/tok 2.0987 (3.3784)	Learning Rate [0.00125]
5: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00100 (0.00093)	Tok/s 21658 (53607)	Loss/tok 2.0178 (3.3836)	Learning Rate [0.00125]
8: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00086 (0.00097)	Tok/s 25010 (53839)	Loss/tok 2.0061 (3.3854)	Learning Rate [0.00125]
9: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00092 (0.00092)	Tok/s 25533 (53899)	Loss/tok 2.1611 (3.3735)	Learning Rate [0.00125]
3: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00086 (0.00093)	Tok/s 17583 (53424)	Loss/tok 1.6897 (3.3824)	Learning Rate [0.00125]
1: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00088 (0.00097)	Tok/s 12767 (53237)	Loss/tok 1.7281 (3.3872)	Learning Rate [0.00125]
10: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00081 (0.00096)	Tok/s 25319 (53983)	Loss/tok 1.9378 (3.3802)	Learning Rate [0.00125]
0: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00089 (0.00099)	Tok/s 9732 (53133)	Loss/tok 1.7236 (3.3828)	Learning Rate [0.00125]
2: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00093 (0.00098)	Tok/s 15969 (53334)	Loss/tok 1.8602 (3.3839)	Learning Rate [0.00125]
11: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00086 (0.00092)	Tok/s 25284 (54067)	Loss/tok 1.9273 (3.3791)	Learning Rate [0.00125]
13: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00092 (0.00097)	Tok/s 27278 (54267)	Loss/tok 2.3291 (3.3797)	Learning Rate [0.00125]
15: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00097 (0.00092)	Tok/s 27976 (54464)	Loss/tok 2.3875 (3.3808)	Learning Rate [0.00125]
14: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00095 (0.00093)	Tok/s 27282 (54359)	Loss/tok 2.4313 (3.3808)	Learning Rate [0.00125]
12: TRAIN [1][1610/3416]	Time 0.033 (0.058)	Data 0.00093 (0.00096)	Tok/s 26012 (54173)	Loss/tok 2.1422 (3.3754)	Learning Rate [0.00125]
12: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 84206 (54215)	Loss/tok 3.3287 (3.3758)	Learning Rate [0.00125]
11: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 84066 (54109)	Loss/tok 3.1108 (3.3790)	Learning Rate [0.00125]
13: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 84194 (54308)	Loss/tok 3.3728 (3.3807)	Learning Rate [0.00125]
14: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00093)	Tok/s 84706 (54400)	Loss/tok 3.1653 (3.3812)	Learning Rate [0.00125]
9: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 83424 (53940)	Loss/tok 3.2499 (3.3740)	Learning Rate [0.00125]
15: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 85175 (54505)	Loss/tok 3.2146 (3.3809)	Learning Rate [0.00125]
10: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 84079 (54024)	Loss/tok 2.9170 (3.3798)	Learning Rate [0.00125]
8: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 83145 (53880)	Loss/tok 3.2345 (3.3857)	Learning Rate [0.00125]
0: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00099)	Tok/s 82403 (53175)	Loss/tok 3.3549 (3.3831)	Learning Rate [0.00125]
6: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00091)	Tok/s 83151 (53717)	Loss/tok 3.1880 (3.3829)	Learning Rate [0.00125]
1: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 82423 (53279)	Loss/tok 3.3370 (3.3867)	Learning Rate [0.00125]
7: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00097)	Tok/s 83140 (53802)	Loss/tok 3.2902 (3.3781)	Learning Rate [0.00125]
2: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 82402 (53375)	Loss/tok 3.2544 (3.3840)	Learning Rate [0.00125]
4: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 83165 (53568)	Loss/tok 3.3335 (3.3811)	Learning Rate [0.00125]
5: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 83217 (53649)	Loss/tok 3.0934 (3.3838)	Learning Rate [0.00125]
3: TRAIN [1][1620/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00093)	Tok/s 82358 (53465)	Loss/tok 3.6041 (3.3831)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
3: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00093)	Tok/s 37386 (53414)	Loss/tok 3.0068 (3.3826)	Learning Rate [0.00125]
4: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00100)	Tok/s 37298 (53516)	Loss/tok 3.1826 (3.3803)	Learning Rate [0.00125]
2: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00098)	Tok/s 37374 (53324)	Loss/tok 3.1206 (3.3834)	Learning Rate [0.00125]
1: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00097)	Tok/s 37389 (53228)	Loss/tok 3.0565 (3.3860)	Learning Rate [0.00125]
0: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00099)	Tok/s 37394 (53124)	Loss/tok 3.0885 (3.3825)	Learning Rate [0.00125]
5: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00093)	Tok/s 37181 (53597)	Loss/tok 3.3193 (3.3834)	Learning Rate [0.00125]
6: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00091)	Tok/s 38281 (53665)	Loss/tok 3.2000 (3.3821)	Learning Rate [0.00125]
15: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00092)	Tok/s 38734 (54451)	Loss/tok 2.9990 (3.3803)	Learning Rate [0.00125]
7: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00097)	Tok/s 38303 (53750)	Loss/tok 3.2502 (3.3779)	Learning Rate [0.00125]
8: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00097)	Tok/s 38290 (53827)	Loss/tok 3.1565 (3.3852)	Learning Rate [0.00125]
14: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00093)	Tok/s 38613 (54346)	Loss/tok 3.0942 (3.3808)	Learning Rate [0.00125]
9: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00092)	Tok/s 38320 (53887)	Loss/tok 3.2407 (3.3737)	Learning Rate [0.00125]
13: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00097)	Tok/s 38539 (54254)	Loss/tok 2.9574 (3.3797)	Learning Rate [0.00125]
11: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 38396 (54055)	Loss/tok 3.1072 (3.3783)	Learning Rate [0.00125]
12: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00096)	Tok/s 38401 (54161)	Loss/tok 3.3445 (3.3755)	Learning Rate [0.00125]
10: TRAIN [1][1630/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00096)	Tok/s 38347 (53971)	Loss/tok 2.9504 (3.3789)	Learning Rate [0.00125]
0: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00099)	Tok/s 53205 (53107)	Loss/tok 3.1620 (3.3821)	Learning Rate [0.00125]
1: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00097)	Tok/s 53115 (53211)	Loss/tok 3.5792 (3.3855)	Learning Rate [0.00125]
15: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00092)	Tok/s 54049 (54443)	Loss/tok 3.4183 (3.3802)	Learning Rate [0.00125]
3: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00077 (0.00093)	Tok/s 53270 (53400)	Loss/tok 3.4026 (3.3825)	Learning Rate [0.00125]
14: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00076 (0.00093)	Tok/s 53950 (54338)	Loss/tok 3.5428 (3.3810)	Learning Rate [0.00125]
2: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00119 (0.00098)	Tok/s 53211 (53308)	Loss/tok 3.2418 (3.3830)	Learning Rate [0.00125]
4: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00100)	Tok/s 54204 (53503)	Loss/tok 3.5546 (3.3799)	Learning Rate [0.00125]
6: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00081 (0.00091)	Tok/s 54123 (53654)	Loss/tok 3.3359 (3.3819)	Learning Rate [0.00125]
13: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00097)	Tok/s 53815 (54246)	Loss/tok 3.2783 (3.3789)	Learning Rate [0.00125]
5: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00093)	Tok/s 54176 (53585)	Loss/tok 3.5381 (3.3832)	Learning Rate [0.00125]
12: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00096)	Tok/s 53805 (54152)	Loss/tok 3.5292 (3.3746)	Learning Rate [0.00125]
11: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00078 (0.00092)	Tok/s 53819 (54046)	Loss/tok 3.4307 (3.3778)	Learning Rate [0.00125]
7: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00097)	Tok/s 53986 (53740)	Loss/tok 3.3897 (3.3776)	Learning Rate [0.00125]
9: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00092)	Tok/s 53890 (53878)	Loss/tok 3.3034 (3.3730)	Learning Rate [0.00125]
8: TRAIN [1][1640/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00097)	Tok/s 53885 (53818)	Loss/tok 3.4869 (3.3850)	Learning Rate [0.00125]
10: TRAIN [1][1640/3416]	Time 0.060 (0.058)	Data 0.00084 (0.00096)	Tok/s 53769 (53962)	Loss/tok 3.5016 (3.3792)	Learning Rate [0.00125]
12: TRAIN [1][1650/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00096)	Tok/s 69047 (54204)	Loss/tok 3.3809 (3.3752)	Learning Rate [0.00125]
13: TRAIN [1][1650/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 68963 (54297)	Loss/tok 3.4829 (3.3793)	Learning Rate [0.00125]
10: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 69139 (54014)	Loss/tok 3.5333 (3.3794)	Learning Rate [0.00125]
9: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 69096 (53931)	Loss/tok 3.4370 (3.3738)	Learning Rate [0.00125]
8: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 69079 (53871)	Loss/tok 3.4068 (3.3854)	Learning Rate [0.00125]
14: TRAIN [1][1650/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 68949 (54389)	Loss/tok 3.1703 (3.3811)	Learning Rate [0.00125]
15: TRAIN [1][1650/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00092)	Tok/s 68953 (54495)	Loss/tok 3.4352 (3.3805)	Learning Rate [0.00125]
0: TRAIN [1][1650/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00099)	Tok/s 68048 (53160)	Loss/tok 3.3581 (3.3825)	Learning Rate [0.00125]
7: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00097)	Tok/s 69106 (53792)	Loss/tok 3.5208 (3.3784)	Learning Rate [0.00125]
1: TRAIN [1][1650/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 68070 (53264)	Loss/tok 3.4010 (3.3857)	Learning Rate [0.00125]
6: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 69114 (53706)	Loss/tok 3.3896 (3.3819)	Learning Rate [0.00125]
11: TRAIN [1][1650/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 68883 (54098)	Loss/tok 3.5157 (3.3782)	Learning Rate [0.00125]
2: TRAIN [1][1650/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 68074 (53361)	Loss/tok 3.5820 (3.3838)	Learning Rate [0.00125]
3: TRAIN [1][1650/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00093)	Tok/s 68088 (53452)	Loss/tok 3.1525 (3.3826)	Learning Rate [0.00125]
5: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00093)	Tok/s 69084 (53637)	Loss/tok 3.6308 (3.3835)	Learning Rate [0.00125]
4: TRAIN [1][1650/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 68570 (53555)	Loss/tok 3.5428 (3.3805)	Learning Rate [0.00125]
9: TRAIN [1][1660/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00092)	Tok/s 55874 (53952)	Loss/tok 3.5948 (3.3735)	Learning Rate [0.00125]
8: TRAIN [1][1660/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00097)	Tok/s 55856 (53892)	Loss/tok 3.3844 (3.3853)	Learning Rate [0.00125]
7: TRAIN [1][1660/3416]	Time 0.066 (0.058)	Data 0.00103 (0.00097)	Tok/s 55897 (53815)	Loss/tok 3.7130 (3.3788)	Learning Rate [0.00125]
3: TRAIN [1][1660/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00093)	Tok/s 56036 (53476)	Loss/tok 3.7412 (3.3829)	Learning Rate [0.00125]
6: TRAIN [1][1660/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00091)	Tok/s 55892 (53729)	Loss/tok 3.4384 (3.3818)	Learning Rate [0.00125]
4: TRAIN [1][1660/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00100)	Tok/s 55969 (53578)	Loss/tok 3.3541 (3.3802)	Learning Rate [0.00125]
11: TRAIN [1][1660/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00092)	Tok/s 55716 (54120)	Loss/tok 3.4909 (3.3780)	Learning Rate [0.00125]
10: TRAIN [1][1660/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00096)	Tok/s 55804 (54035)	Loss/tok 3.4320 (3.3796)	Learning Rate [0.00125]
2: TRAIN [1][1660/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00098)	Tok/s 56041 (53385)	Loss/tok 3.2437 (3.3839)	Learning Rate [0.00125]
5: TRAIN [1][1660/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00093)	Tok/s 55842 (53660)	Loss/tok 3.5934 (3.3835)	Learning Rate [0.00125]
1: TRAIN [1][1660/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00097)	Tok/s 55994 (53288)	Loss/tok 3.6815 (3.3856)	Learning Rate [0.00125]
12: TRAIN [1][1660/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00096)	Tok/s 55717 (54225)	Loss/tok 3.7319 (3.3755)	Learning Rate [0.00125]
0: TRAIN [1][1660/3416]	Time 0.066 (0.058)	Data 0.00104 (0.00099)	Tok/s 55921 (53185)	Loss/tok 3.3182 (3.3823)	Learning Rate [0.00125]
13: TRAIN [1][1660/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00097)	Tok/s 55802 (54318)	Loss/tok 3.5504 (3.3790)	Learning Rate [0.00125]
15: TRAIN [1][1660/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00092)	Tok/s 56804 (54515)	Loss/tok 3.5630 (3.3808)	Learning Rate [0.00125]
14: TRAIN [1][1660/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00093)	Tok/s 56591 (54411)	Loss/tok 3.6758 (3.3816)	Learning Rate [0.00125]
0: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00099)	Tok/s 51312 (53203)	Loss/tok 3.2305 (3.3824)	Learning Rate [0.00125]
1: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00097)	Tok/s 51181 (53306)	Loss/tok 3.2857 (3.3859)	Learning Rate [0.00125]
15: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00082 (0.00092)	Tok/s 52701 (54531)	Loss/tok 3.1776 (3.3804)	Learning Rate [0.00125]
14: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00093)	Tok/s 52681 (54427)	Loss/tok 3.3680 (3.3815)	Learning Rate [0.00125]
2: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00098)	Tok/s 51031 (53402)	Loss/tok 3.5299 (3.3842)	Learning Rate [0.00125]
3: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00093)	Tok/s 51030 (53493)	Loss/tok 3.6063 (3.3828)	Learning Rate [0.00125]
13: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00097)	Tok/s 52689 (54334)	Loss/tok 3.2156 (3.3789)	Learning Rate [0.00125]
4: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00100)	Tok/s 51040 (53595)	Loss/tok 3.1377 (3.3802)	Learning Rate [0.00125]
12: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00096)	Tok/s 52678 (54241)	Loss/tok 3.0787 (3.3757)	Learning Rate [0.00125]
11: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00092)	Tok/s 52669 (54136)	Loss/tok 3.3099 (3.3780)	Learning Rate [0.00125]
5: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00093)	Tok/s 51055 (53677)	Loss/tok 3.1624 (3.3833)	Learning Rate [0.00125]
6: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00091)	Tok/s 51048 (53745)	Loss/tok 3.3749 (3.3815)	Learning Rate [0.00125]
9: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00092)	Tok/s 52600 (53968)	Loss/tok 3.2235 (3.3733)	Learning Rate [0.00125]
10: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00108 (0.00096)	Tok/s 52716 (54051)	Loss/tok 3.0403 (3.3794)	Learning Rate [0.00125]
8: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00097)	Tok/s 52195 (53908)	Loss/tok 3.2808 (3.3855)	Learning Rate [0.00125]
7: TRAIN [1][1670/3416]	Time 0.046 (0.058)	Data 0.00109 (0.00097)	Tok/s 51067 (53830)	Loss/tok 3.2027 (3.3787)	Learning Rate [0.00125]
4: TRAIN [1][1680/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00100)	Tok/s 50250 (53601)	Loss/tok 2.9270 (3.3799)	Learning Rate [0.00125]
6: TRAIN [1][1680/3416]	Time 0.056 (0.058)	Data 0.00106 (0.00091)	Tok/s 50129 (53751)	Loss/tok 3.0707 (3.3817)	Learning Rate [0.00125]
5: TRAIN [1][1680/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00093)	Tok/s 50155 (53683)	Loss/tok 3.3516 (3.3837)	Learning Rate [0.00125]
3: TRAIN [1][1680/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00093)	Tok/s 50162 (53498)	Loss/tok 3.2806 (3.3830)	Learning Rate [0.00125]
7: TRAIN [1][1680/3416]	Time 0.056 (0.058)	Data 0.00103 (0.00097)	Tok/s 49977 (53836)	Loss/tok 3.1588 (3.3777)	Learning Rate [0.00125]
1: TRAIN [1][1680/3416]	Time 0.056 (0.058)	Data 0.00105 (0.00097)	Tok/s 50192 (53311)	Loss/tok 3.2484 (3.3855)	Learning Rate [0.00125]
8: TRAIN [1][1680/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00097)	Tok/s 49859 (53915)	Loss/tok 3.3799 (3.3852)	Learning Rate [0.00125]
9: TRAIN [1][1680/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00092)	Tok/s 49828 (53975)	Loss/tok 3.2570 (3.3729)	Learning Rate [0.00125]
10: TRAIN [1][1680/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00096)	Tok/s 49898 (54058)	Loss/tok 3.3751 (3.3789)	Learning Rate [0.00125]
2: TRAIN [1][1680/3416]	Time 0.056 (0.058)	Data 0.00100 (0.00098)	Tok/s 50125 (53407)	Loss/tok 3.5676 (3.3841)	Learning Rate [0.00125]
0: TRAIN [1][1680/3416]	Time 0.056 (0.058)	Data 0.00099 (0.00099)	Tok/s 50075 (53209)	Loss/tok 3.3886 (3.3822)	Learning Rate [0.00125]
11: TRAIN [1][1680/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00092)	Tok/s 49772 (54143)	Loss/tok 3.4204 (3.3781)	Learning Rate [0.00125]
14: TRAIN [1][1680/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00093)	Tok/s 51066 (54434)	Loss/tok 3.3825 (3.3816)	Learning Rate [0.00125]
13: TRAIN [1][1680/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00097)	Tok/s 51002 (54342)	Loss/tok 3.5004 (3.3789)	Learning Rate [0.00125]
12: TRAIN [1][1680/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00096)	Tok/s 50892 (54248)	Loss/tok 3.3156 (3.3753)	Learning Rate [0.00125]
15: TRAIN [1][1680/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00092)	Tok/s 51146 (54538)	Loss/tok 3.1909 (3.3796)	Learning Rate [0.00125]
12: TRAIN [1][1690/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00096)	Tok/s 30448 (54234)	Loss/tok 2.9957 (3.3756)	Learning Rate [0.00125]
11: TRAIN [1][1690/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00092)	Tok/s 30399 (54129)	Loss/tok 2.8993 (3.3781)	Learning Rate [0.00125]
13: TRAIN [1][1690/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00097)	Tok/s 30334 (54327)	Loss/tok 2.9095 (3.3789)	Learning Rate [0.00125]
10: TRAIN [1][1690/3416]	Time 0.046 (0.058)	Data 0.00102 (0.00096)	Tok/s 30402 (54044)	Loss/tok 2.7384 (3.3790)	Learning Rate [0.00125]
9: TRAIN [1][1690/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00092)	Tok/s 30436 (53962)	Loss/tok 2.7794 (3.3735)	Learning Rate [0.00125]
14: TRAIN [1][1690/3416]	Time 0.047 (0.058)	Data 0.00081 (0.00093)	Tok/s 30256 (54419)	Loss/tok 2.9254 (3.3815)	Learning Rate [0.00125]
8: TRAIN [1][1690/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00097)	Tok/s 30441 (53901)	Loss/tok 2.9736 (3.3857)	Learning Rate [0.00125]
15: TRAIN [1][1690/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00092)	Tok/s 30814 (54523)	Loss/tok 2.8651 (3.3795)	Learning Rate [0.00125]
0: TRAIN [1][1690/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00099)	Tok/s 28828 (53197)	Loss/tok 2.8855 (3.3824)	Learning Rate [0.00125]
6: TRAIN [1][1690/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00091)	Tok/s 30374 (53737)	Loss/tok 3.2012 (3.3824)	Learning Rate [0.00125]
1: TRAIN [1][1690/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00097)	Tok/s 28831 (53299)	Loss/tok 2.4169 (3.3856)	Learning Rate [0.00125]
7: TRAIN [1][1690/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00097)	Tok/s 30410 (53822)	Loss/tok 2.7171 (3.3775)	Learning Rate [0.00125]
4: TRAIN [1][1690/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00100)	Tok/s 30297 (53589)	Loss/tok 2.7205 (3.3800)	Learning Rate [0.00125]
2: TRAIN [1][1690/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00098)	Tok/s 28844 (53394)	Loss/tok 2.6468 (3.3842)	Learning Rate [0.00125]
3: TRAIN [1][1690/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00093)	Tok/s 30024 (53486)	Loss/tok 2.7592 (3.3826)	Learning Rate [0.00125]
5: TRAIN [1][1690/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00093)	Tok/s 30281 (53669)	Loss/tok 2.7211 (3.3834)	Learning Rate [0.00125]
14: Gradient norm: inf
13: Gradient norm: inf
12: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
0: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
7: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
4: TRAIN [1][1700/3416]	Time 0.068 (0.058)	Data 0.00106 (0.00100)	Tok/s 56476 (53605)	Loss/tok 3.4829 (3.3798)	Learning Rate [0.00125]
3: TRAIN [1][1700/3416]	Time 0.068 (0.058)	Data 0.00115 (0.00093)	Tok/s 56532 (53501)	Loss/tok 3.6792 (3.3822)	Learning Rate [0.00125]
6: TRAIN [1][1700/3416]	Time 0.068 (0.058)	Data 0.00111 (0.00091)	Tok/s 56213 (53756)	Loss/tok 3.4444 (3.3821)	Learning Rate [0.00125]
5: TRAIN [1][1700/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00093)	Tok/s 56274 (53687)	Loss/tok 3.5535 (3.3830)	Learning Rate [0.00125]
2: TRAIN [1][1700/3416]	Time 0.068 (0.058)	Data 0.00116 (0.00098)	Tok/s 56433 (53408)	Loss/tok 3.5842 (3.3845)	Learning Rate [0.00125]
1: TRAIN [1][1700/3416]	Time 0.068 (0.058)	Data 0.00111 (0.00097)	Tok/s 56314 (53311)	Loss/tok 3.4022 (3.3855)	Learning Rate [0.00125]
9: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 55987 (53981)	Loss/tok 3.5711 (3.3733)	Learning Rate [0.00125]
7: TRAIN [1][1700/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00097)	Tok/s 56093 (53841)	Loss/tok 3.2457 (3.3766)	Learning Rate [0.00125]
8: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00097)	Tok/s 55964 (53920)	Loss/tok 3.7482 (3.3858)	Learning Rate [0.00125]
0: TRAIN [1][1700/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00099)	Tok/s 56221 (53207)	Loss/tok 3.4037 (3.3823)	Learning Rate [0.00125]
11: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 56856 (54149)	Loss/tok 3.9714 (3.3780)	Learning Rate [0.00125]
15: TRAIN [1][1700/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 57058 (54546)	Loss/tok 3.7526 (3.3788)	Learning Rate [0.00125]
13: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 56983 (54348)	Loss/tok 3.5251 (3.3785)	Learning Rate [0.00125]
14: TRAIN [1][1700/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00093)	Tok/s 56993 (54440)	Loss/tok 3.4890 (3.3815)	Learning Rate [0.00125]
10: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 56638 (54064)	Loss/tok 3.3843 (3.3789)	Learning Rate [0.00125]
12: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 56771 (54254)	Loss/tok 3.3536 (3.3751)	Learning Rate [0.00125]
1: TRAIN [1][1710/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00097)	Tok/s 34907 (53314)	Loss/tok 3.0211 (3.3853)	Learning Rate [0.00125]
2: TRAIN [1][1710/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00098)	Tok/s 34856 (53411)	Loss/tok 3.2325 (3.3845)	Learning Rate [0.00125]
4: TRAIN [1][1710/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00100)	Tok/s 34791 (53608)	Loss/tok 3.0602 (3.3797)	Learning Rate [0.00125]
0: TRAIN [1][1710/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00099)	Tok/s 34892 (53210)	Loss/tok 3.0028 (3.3821)	Learning Rate [0.00125]
3: TRAIN [1][1710/3416]	Time 0.051 (0.058)	Data 0.00114 (0.00093)	Tok/s 34821 (53504)	Loss/tok 3.0172 (3.3823)	Learning Rate [0.00125]
15: TRAIN [1][1710/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00092)	Tok/s 36150 (54549)	Loss/tok 3.0737 (3.3784)	Learning Rate [0.00125]
5: TRAIN [1][1710/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00093)	Tok/s 34804 (53690)	Loss/tok 3.1201 (3.3831)	Learning Rate [0.00125]
14: TRAIN [1][1710/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00093)	Tok/s 34918 (54443)	Loss/tok 2.8911 (3.3811)	Learning Rate [0.00125]
6: TRAIN [1][1710/3416]	Time 0.052 (0.058)	Data 0.00121 (0.00091)	Tok/s 34772 (53758)	Loss/tok 3.1073 (3.3817)	Learning Rate [0.00125]
13: TRAIN [1][1710/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00097)	Tok/s 34843 (54351)	Loss/tok 2.8491 (3.3779)	Learning Rate [0.00125]
8: TRAIN [1][1710/3416]	Time 0.051 (0.058)	Data 0.00114 (0.00097)	Tok/s 34808 (53924)	Loss/tok 3.0366 (3.3856)	Learning Rate [0.00125]
7: TRAIN [1][1710/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00097)	Tok/s 34791 (53844)	Loss/tok 2.9166 (3.3771)	Learning Rate [0.00125]
12: TRAIN [1][1710/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00096)	Tok/s 34794 (54258)	Loss/tok 3.1094 (3.3748)	Learning Rate [0.00125]
11: TRAIN [1][1710/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00092)	Tok/s 34807 (54153)	Loss/tok 3.0822 (3.3777)	Learning Rate [0.00125]
9: TRAIN [1][1710/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00092)	Tok/s 34792 (53984)	Loss/tok 3.1593 (3.3726)	Learning Rate [0.00125]
10: TRAIN [1][1710/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00096)	Tok/s 34836 (54067)	Loss/tok 3.0450 (3.3792)	Learning Rate [0.00125]
4: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00100)	Tok/s 34201 (53548)	Loss/tok 3.0055 (3.3794)	Learning Rate [0.00125]
3: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00093)	Tok/s 34208 (53444)	Loss/tok 2.9416 (3.3815)	Learning Rate [0.00125]
5: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00081 (0.00093)	Tok/s 34268 (53629)	Loss/tok 2.9233 (3.3826)	Learning Rate [0.00125]
0: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00098)	Tok/s 34315 (53152)	Loss/tok 3.0035 (3.3814)	Learning Rate [0.00125]
6: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00091)	Tok/s 34256 (53698)	Loss/tok 2.8079 (3.3815)	Learning Rate [0.00125]
1: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00097)	Tok/s 34266 (53255)	Loss/tok 3.1021 (3.3845)	Learning Rate [0.00125]
8: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00081 (0.00097)	Tok/s 34290 (53864)	Loss/tok 3.2149 (3.3854)	Learning Rate [0.00125]
7: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00097)	Tok/s 34299 (53784)	Loss/tok 3.0353 (3.3767)	Learning Rate [0.00125]
2: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00110 (0.00098)	Tok/s 34235 (53352)	Loss/tok 3.3368 (3.3838)	Learning Rate [0.00125]
9: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00079 (0.00092)	Tok/s 34353 (53924)	Loss/tok 3.0907 (3.3723)	Learning Rate [0.00125]
10: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00096)	Tok/s 34350 (54008)	Loss/tok 3.1751 (3.3784)	Learning Rate [0.00125]
11: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00092)	Tok/s 34334 (54093)	Loss/tok 2.8982 (3.3775)	Learning Rate [0.00125]
15: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00081 (0.00092)	Tok/s 34270 (54489)	Loss/tok 3.1212 (3.3781)	Learning Rate [0.00125]
14: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00079 (0.00093)	Tok/s 34273 (54383)	Loss/tok 2.8929 (3.3812)	Learning Rate [0.00125]
13: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00097)	Tok/s 34273 (54292)	Loss/tok 3.1421 (3.3776)	Learning Rate [0.00125]
12: TRAIN [1][1720/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00096)	Tok/s 34264 (54198)	Loss/tok 3.0582 (3.3745)	Learning Rate [0.00125]
6: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00091)	Tok/s 63267 (53727)	Loss/tok 3.4920 (3.3815)	Learning Rate [0.00125]
5: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 63302 (53658)	Loss/tok 3.5128 (3.3832)	Learning Rate [0.00125]
7: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 63204 (53813)	Loss/tok 3.6004 (3.3775)	Learning Rate [0.00125]
4: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 63255 (53577)	Loss/tok 3.5310 (3.3806)	Learning Rate [0.00125]
8: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00097)	Tok/s 63019 (53892)	Loss/tok 3.6349 (3.3860)	Learning Rate [0.00125]
3: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00093)	Tok/s 63273 (53473)	Loss/tok 3.4612 (3.3816)	Learning Rate [0.00125]
9: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00079 (0.00092)	Tok/s 63024 (53952)	Loss/tok 3.4132 (3.3725)	Learning Rate [0.00125]
2: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 63271 (53381)	Loss/tok 3.5896 (3.3840)	Learning Rate [0.00125]
1: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00117 (0.00097)	Tok/s 63238 (53285)	Loss/tok 3.6446 (3.3850)	Learning Rate [0.00125]
10: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 63010 (54035)	Loss/tok 3.4648 (3.3791)	Learning Rate [0.00125]
11: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 62983 (54120)	Loss/tok 3.2458 (3.3780)	Learning Rate [0.00125]
0: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00098)	Tok/s 63211 (53182)	Loss/tok 3.4699 (3.3815)	Learning Rate [0.00125]
15: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 63969 (54517)	Loss/tok 3.2875 (3.3783)	Learning Rate [0.00125]
14: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00093)	Tok/s 63026 (54410)	Loss/tok 3.4448 (3.3820)	Learning Rate [0.00125]
12: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 62951 (54226)	Loss/tok 3.6543 (3.3752)	Learning Rate [0.00125]
13: TRAIN [1][1730/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 63001 (54319)	Loss/tok 3.5004 (3.3780)	Learning Rate [0.00125]
3: TRAIN [1][1740/3416]	Time 0.044 (0.058)	Data 0.00109 (0.00093)	Tok/s 49609 (53481)	Loss/tok 3.3401 (3.3816)	Learning Rate [0.00125]
2: TRAIN [1][1740/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00098)	Tok/s 49478 (53390)	Loss/tok 3.2024 (3.3842)	Learning Rate [0.00125]
4: TRAIN [1][1740/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00100)	Tok/s 49523 (53584)	Loss/tok 3.2860 (3.3807)	Learning Rate [0.00125]
1: TRAIN [1][1740/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00097)	Tok/s 49259 (53294)	Loss/tok 2.9929 (3.3849)	Learning Rate [0.00125]
6: TRAIN [1][1740/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00091)	Tok/s 49148 (53734)	Loss/tok 3.2929 (3.3818)	Learning Rate [0.00125]
5: TRAIN [1][1740/3416]	Time 0.044 (0.058)	Data 0.00085 (0.00093)	Tok/s 49366 (53665)	Loss/tok 2.9273 (3.3832)	Learning Rate [0.00125]
0: TRAIN [1][1740/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00098)	Tok/s 49107 (53192)	Loss/tok 3.3135 (3.3820)	Learning Rate [0.00125]
15: TRAIN [1][1740/3416]	Time 0.044 (0.058)	Data 0.00084 (0.00092)	Tok/s 50479 (54524)	Loss/tok 3.0934 (3.3781)	Learning Rate [0.00125]
14: TRAIN [1][1740/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00093)	Tok/s 50365 (54418)	Loss/tok 3.1778 (3.3822)	Learning Rate [0.00125]
7: TRAIN [1][1740/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00097)	Tok/s 49055 (53819)	Loss/tok 3.1475 (3.3775)	Learning Rate [0.00125]
9: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00092)	Tok/s 48892 (53958)	Loss/tok 3.4060 (3.3727)	Learning Rate [0.00125]
8: TRAIN [1][1740/3416]	Time 0.044 (0.058)	Data 0.00084 (0.00097)	Tok/s 48930 (53898)	Loss/tok 3.2434 (3.3860)	Learning Rate [0.00125]
11: TRAIN [1][1740/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00092)	Tok/s 48946 (54126)	Loss/tok 3.2996 (3.3782)	Learning Rate [0.00125]
10: TRAIN [1][1740/3416]	Time 0.044 (0.058)	Data 0.00083 (0.00096)	Tok/s 48930 (54041)	Loss/tok 3.2611 (3.3789)	Learning Rate [0.00125]
12: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00096)	Tok/s 48835 (54232)	Loss/tok 3.3310 (3.3749)	Learning Rate [0.00125]
13: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00097)	Tok/s 49001 (54326)	Loss/tok 3.2382 (3.3778)	Learning Rate [0.00125]
6: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00091)	Tok/s 40517 (53706)	Loss/tok 3.1131 (3.3816)	Learning Rate [0.00125]
7: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00111 (0.00097)	Tok/s 40524 (53791)	Loss/tok 3.0265 (3.3770)	Learning Rate [0.00125]
8: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00097)	Tok/s 40462 (53870)	Loss/tok 3.0185 (3.3853)	Learning Rate [0.00125]
5: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00093)	Tok/s 40515 (53638)	Loss/tok 2.8470 (3.3828)	Learning Rate [0.00125]
4: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00100)	Tok/s 40508 (53558)	Loss/tok 3.2050 (3.3807)	Learning Rate [0.00125]
9: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00092)	Tok/s 40380 (53930)	Loss/tok 3.2863 (3.3726)	Learning Rate [0.00125]
3: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00093)	Tok/s 40556 (53455)	Loss/tok 3.3126 (3.3814)	Learning Rate [0.00125]
11: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00092)	Tok/s 40402 (54098)	Loss/tok 3.2984 (3.3780)	Learning Rate [0.00125]
10: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00096)	Tok/s 40439 (54013)	Loss/tok 3.2573 (3.3790)	Learning Rate [0.00125]
2: TRAIN [1][1750/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00098)	Tok/s 42873 (53364)	Loss/tok 3.0664 (3.3840)	Learning Rate [0.00125]
1: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00097)	Tok/s 40536 (53269)	Loss/tok 3.1895 (3.3843)	Learning Rate [0.00125]
12: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00096)	Tok/s 40483 (54203)	Loss/tok 3.1159 (3.3744)	Learning Rate [0.00125]
0: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00098)	Tok/s 40524 (53166)	Loss/tok 3.0439 (3.3818)	Learning Rate [0.00125]
13: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00097)	Tok/s 40511 (54297)	Loss/tok 3.3414 (3.3777)	Learning Rate [0.00125]
15: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00092)	Tok/s 40457 (54495)	Loss/tok 3.2592 (3.3779)	Learning Rate [0.00125]
14: TRAIN [1][1750/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00093)	Tok/s 40426 (54389)	Loss/tok 3.2297 (3.3821)	Learning Rate [0.00125]
0: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00089 (0.00098)	Tok/s 25406 (53133)	Loss/tok 2.3529 (3.3814)	Learning Rate [0.00125]
1: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00086 (0.00097)	Tok/s 25331 (53237)	Loss/tok 2.3035 (3.3839)	Learning Rate [0.00125]
15: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00081 (0.00092)	Tok/s 30450 (54476)	Loss/tok 2.7497 (3.3776)	Learning Rate [0.00125]
2: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00093 (0.00098)	Tok/s 25243 (53333)	Loss/tok 2.4040 (3.3840)	Learning Rate [0.00125]
14: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00081 (0.00093)	Tok/s 30450 (54369)	Loss/tok 2.5175 (3.3816)	Learning Rate [0.00125]
13: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00092 (0.00097)	Tok/s 29095 (54276)	Loss/tok 2.6543 (3.3773)	Learning Rate [0.00125]
3: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00096 (0.00093)	Tok/s 26094 (53426)	Loss/tok 2.6008 (3.3815)	Learning Rate [0.00125]
4: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00098 (0.00100)	Tok/s 26847 (53530)	Loss/tok 2.8075 (3.3800)	Learning Rate [0.00125]
12: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00094 (0.00096)	Tok/s 28722 (54182)	Loss/tok 2.5166 (3.3741)	Learning Rate [0.00125]
11: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00085 (0.00092)	Tok/s 28712 (54076)	Loss/tok 2.4596 (3.3773)	Learning Rate [0.00125]
5: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00082 (0.00093)	Tok/s 26822 (53612)	Loss/tok 2.4467 (3.3825)	Learning Rate [0.00125]
6: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00099 (0.00091)	Tok/s 26820 (53682)	Loss/tok 2.5053 (3.3811)	Learning Rate [0.00125]
9: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00086 (0.00092)	Tok/s 28610 (53908)	Loss/tok 2.5549 (3.3725)	Learning Rate [0.00125]
10: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00096 (0.00096)	Tok/s 28640 (53991)	Loss/tok 2.5413 (3.3782)	Learning Rate [0.00125]
8: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00091 (0.00097)	Tok/s 28567 (53848)	Loss/tok 2.3565 (3.3849)	Learning Rate [0.00125]
7: TRAIN [1][1760/3416]	Time 0.038 (0.058)	Data 0.00101 (0.00097)	Tok/s 27693 (53768)	Loss/tok 2.4858 (3.3767)	Learning Rate [0.00125]
7: TRAIN [1][1770/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00097)	Tok/s 47694 (53721)	Loss/tok 3.1809 (3.3759)	Learning Rate [0.00125]
8: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00097)	Tok/s 47821 (53801)	Loss/tok 3.3821 (3.3842)	Learning Rate [0.00125]
10: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00096)	Tok/s 47757 (53943)	Loss/tok 3.3460 (3.3774)	Learning Rate [0.00125]
5: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00093)	Tok/s 46337 (53563)	Loss/tok 3.0311 (3.3819)	Learning Rate [0.00125]
4: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00100)	Tok/s 46156 (53480)	Loss/tok 3.1991 (3.3792)	Learning Rate [0.00125]
6: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00109 (0.00091)	Tok/s 46417 (53634)	Loss/tok 3.0137 (3.3804)	Learning Rate [0.00125]
9: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00092)	Tok/s 47707 (53860)	Loss/tok 3.3295 (3.3718)	Learning Rate [0.00125]
3: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00093)	Tok/s 46108 (53377)	Loss/tok 3.1619 (3.3811)	Learning Rate [0.00125]
11: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00092)	Tok/s 47551 (54028)	Loss/tok 3.3126 (3.3768)	Learning Rate [0.00125]
1: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00097)	Tok/s 45891 (53187)	Loss/tok 3.1286 (3.3835)	Learning Rate [0.00125]
2: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00098)	Tok/s 45969 (53284)	Loss/tok 2.9347 (3.3835)	Learning Rate [0.00125]
12: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00096)	Tok/s 47462 (54135)	Loss/tok 3.2308 (3.3739)	Learning Rate [0.00125]
13: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00097)	Tok/s 47350 (54228)	Loss/tok 3.1085 (3.3767)	Learning Rate [0.00125]
0: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00098)	Tok/s 45783 (53084)	Loss/tok 3.3848 (3.3805)	Learning Rate [0.00125]
15: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00092)	Tok/s 47353 (54427)	Loss/tok 3.0101 (3.3767)	Learning Rate [0.00125]
14: TRAIN [1][1770/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00093)	Tok/s 47266 (54321)	Loss/tok 3.2364 (3.3810)	Learning Rate [0.00125]
11: TRAIN [1][1780/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00092)	Tok/s 51721 (54059)	Loss/tok 3.2353 (3.3765)	Learning Rate [0.00125]
10: TRAIN [1][1780/3416]	Time 0.054 (0.058)	Data 0.00109 (0.00096)	Tok/s 51771 (53972)	Loss/tok 3.3833 (3.3773)	Learning Rate [0.00125]
12: TRAIN [1][1780/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00096)	Tok/s 51638 (54166)	Loss/tok 3.2099 (3.3739)	Learning Rate [0.00125]
9: TRAIN [1][1780/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00092)	Tok/s 51698 (53890)	Loss/tok 3.3935 (3.3719)	Learning Rate [0.00125]
13: TRAIN [1][1780/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00097)	Tok/s 51595 (54259)	Loss/tok 3.1292 (3.3767)	Learning Rate [0.00125]
8: TRAIN [1][1780/3416]	Time 0.054 (0.058)	Data 0.00106 (0.00097)	Tok/s 51709 (53830)	Loss/tok 3.2279 (3.3842)	Learning Rate [0.00125]
14: TRAIN [1][1780/3416]	Time 0.055 (0.058)	Data 0.00112 (0.00093)	Tok/s 52290 (54352)	Loss/tok 3.1902 (3.3806)	Learning Rate [0.00125]
7: TRAIN [1][1780/3416]	Time 0.054 (0.058)	Data 0.00108 (0.00097)	Tok/s 51716 (53750)	Loss/tok 3.3260 (3.3757)	Learning Rate [0.00125]
6: TRAIN [1][1780/3416]	Time 0.054 (0.058)	Data 0.00108 (0.00092)	Tok/s 51829 (53663)	Loss/tok 3.3199 (3.3806)	Learning Rate [0.00125]
15: TRAIN [1][1780/3416]	Time 0.055 (0.058)	Data 0.00106 (0.00092)	Tok/s 52744 (54459)	Loss/tok 3.3554 (3.3768)	Learning Rate [0.00125]
0: TRAIN [1][1780/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00098)	Tok/s 51573 (53114)	Loss/tok 3.4605 (3.3810)	Learning Rate [0.00125]
4: TRAIN [1][1780/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00100)	Tok/s 51589 (53510)	Loss/tok 3.2908 (3.3789)	Learning Rate [0.00125]
5: TRAIN [1][1780/3416]	Time 0.054 (0.058)	Data 0.00103 (0.00093)	Tok/s 51672 (53592)	Loss/tok 3.3881 (3.3817)	Learning Rate [0.00125]
1: TRAIN [1][1780/3416]	Time 0.055 (0.058)	Data 0.00105 (0.00097)	Tok/s 51502 (53218)	Loss/tok 3.4744 (3.3835)	Learning Rate [0.00125]
3: TRAIN [1][1780/3416]	Time 0.055 (0.058)	Data 0.00112 (0.00093)	Tok/s 51491 (53407)	Loss/tok 3.3907 (3.3809)	Learning Rate [0.00125]
2: TRAIN [1][1780/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00098)	Tok/s 51420 (53315)	Loss/tok 3.3155 (3.3832)	Learning Rate [0.00125]
8: TRAIN [1][1790/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00097)	Tok/s 51649 (53857)	Loss/tok 3.2370 (3.3845)	Learning Rate [0.00125]
7: TRAIN [1][1790/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00097)	Tok/s 51531 (53777)	Loss/tok 3.3357 (3.3760)	Learning Rate [0.00125]
9: TRAIN [1][1790/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 51625 (53916)	Loss/tok 3.3463 (3.3724)	Learning Rate [0.00125]
6: TRAIN [1][1790/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00092)	Tok/s 51451 (53691)	Loss/tok 3.3571 (3.3805)	Learning Rate [0.00125]
5: TRAIN [1][1790/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00093)	Tok/s 51448 (53619)	Loss/tok 3.4565 (3.3820)	Learning Rate [0.00125]
11: TRAIN [1][1790/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 51452 (54087)	Loss/tok 3.3808 (3.3766)	Learning Rate [0.00125]
4: TRAIN [1][1790/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00100)	Tok/s 51428 (53537)	Loss/tok 3.0302 (3.3787)	Learning Rate [0.00125]
3: TRAIN [1][1790/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00093)	Tok/s 51439 (53434)	Loss/tok 3.3582 (3.3807)	Learning Rate [0.00125]
10: TRAIN [1][1790/3416]	Time 0.052 (0.058)	Data 0.00139 (0.00096)	Tok/s 51616 (54000)	Loss/tok 3.2379 (3.3775)	Learning Rate [0.00125]
12: TRAIN [1][1790/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00096)	Tok/s 51327 (54193)	Loss/tok 3.3239 (3.3739)	Learning Rate [0.00125]
13: TRAIN [1][1790/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 51217 (54287)	Loss/tok 3.0507 (3.3767)	Learning Rate [0.00125]
14: TRAIN [1][1790/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00093)	Tok/s 51769 (54379)	Loss/tok 3.4009 (3.3810)	Learning Rate [0.00125]
2: TRAIN [1][1790/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00098)	Tok/s 51347 (53343)	Loss/tok 3.3016 (3.3834)	Learning Rate [0.00125]
1: TRAIN [1][1790/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00097)	Tok/s 51240 (53246)	Loss/tok 3.3322 (3.3835)	Learning Rate [0.00125]
15: TRAIN [1][1790/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00092)	Tok/s 52336 (54486)	Loss/tok 3.4606 (3.3768)	Learning Rate [0.00125]
0: TRAIN [1][1790/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00098)	Tok/s 51148 (53143)	Loss/tok 3.4911 (3.3813)	Learning Rate [0.00125]
13: TRAIN [1][1800/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00097)	Tok/s 55646 (54325)	Loss/tok 3.6235 (3.3769)	Learning Rate [0.00125]
14: TRAIN [1][1800/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00093)	Tok/s 55579 (54417)	Loss/tok 3.2483 (3.3809)	Learning Rate [0.00125]
12: TRAIN [1][1800/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00096)	Tok/s 55632 (54232)	Loss/tok 3.4995 (3.3738)	Learning Rate [0.00125]
11: TRAIN [1][1800/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00092)	Tok/s 55626 (54126)	Loss/tok 3.5904 (3.3767)	Learning Rate [0.00125]
15: TRAIN [1][1800/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00092)	Tok/s 55453 (54524)	Loss/tok 3.4150 (3.3769)	Learning Rate [0.00125]
0: TRAIN [1][1800/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00098)	Tok/s 54288 (53183)	Loss/tok 3.7856 (3.3819)	Learning Rate [0.00125]
10: TRAIN [1][1800/3416]	Time 0.061 (0.058)	Data 0.00116 (0.00096)	Tok/s 55571 (54039)	Loss/tok 3.4456 (3.3779)	Learning Rate [0.00125]
9: TRAIN [1][1800/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00092)	Tok/s 55492 (53956)	Loss/tok 3.2596 (3.3719)	Learning Rate [0.00125]
1: TRAIN [1][1800/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00097)	Tok/s 54179 (53287)	Loss/tok 3.3745 (3.3834)	Learning Rate [0.00125]
8: TRAIN [1][1800/3416]	Time 0.061 (0.058)	Data 0.00102 (0.00097)	Tok/s 55401 (53897)	Loss/tok 3.5374 (3.3852)	Learning Rate [0.00125]
6: TRAIN [1][1800/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00092)	Tok/s 55187 (53731)	Loss/tok 3.1789 (3.3811)	Learning Rate [0.00125]
7: TRAIN [1][1800/3416]	Time 0.061 (0.058)	Data 0.00113 (0.00097)	Tok/s 55266 (53817)	Loss/tok 3.4170 (3.3764)	Learning Rate [0.00125]
2: TRAIN [1][1800/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00098)	Tok/s 54077 (53384)	Loss/tok 3.5587 (3.3845)	Learning Rate [0.00125]
3: TRAIN [1][1800/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00093)	Tok/s 53994 (53475)	Loss/tok 3.5067 (3.3814)	Learning Rate [0.00125]
4: TRAIN [1][1800/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00100)	Tok/s 54055 (53577)	Loss/tok 3.6917 (3.3789)	Learning Rate [0.00125]
5: TRAIN [1][1800/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00093)	Tok/s 54596 (53660)	Loss/tok 3.6750 (3.3825)	Learning Rate [0.00125]
12: TRAIN [1][1810/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00096)	Tok/s 33639 (54220)	Loss/tok 3.1796 (3.3734)	Learning Rate [0.00125]
10: TRAIN [1][1810/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00096)	Tok/s 33658 (54026)	Loss/tok 2.9889 (3.3774)	Learning Rate [0.00125]
13: TRAIN [1][1810/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00097)	Tok/s 33555 (54313)	Loss/tok 3.1834 (3.3769)	Learning Rate [0.00125]
9: TRAIN [1][1810/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00092)	Tok/s 32958 (53943)	Loss/tok 2.8346 (3.3717)	Learning Rate [0.00125]
11: TRAIN [1][1810/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00092)	Tok/s 33590 (54114)	Loss/tok 3.0886 (3.3765)	Learning Rate [0.00125]
8: TRAIN [1][1810/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00097)	Tok/s 32488 (53884)	Loss/tok 2.9614 (3.3848)	Learning Rate [0.00125]
0: TRAIN [1][1810/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00098)	Tok/s 32126 (53171)	Loss/tok 3.1029 (3.3816)	Learning Rate [0.00125]
14: TRAIN [1][1810/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00092)	Tok/s 33434 (54405)	Loss/tok 3.1242 (3.3809)	Learning Rate [0.00125]
6: TRAIN [1][1810/3416]	Time 0.049 (0.058)	Data 0.00102 (0.00092)	Tok/s 32406 (53718)	Loss/tok 2.9926 (3.3811)	Learning Rate [0.00125]
15: TRAIN [1][1810/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00092)	Tok/s 33369 (54511)	Loss/tok 3.0227 (3.3767)	Learning Rate [0.00125]
1: TRAIN [1][1810/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00097)	Tok/s 32106 (53275)	Loss/tok 2.8224 (3.3830)	Learning Rate [0.00125]
7: TRAIN [1][1810/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00097)	Tok/s 32358 (53804)	Loss/tok 2.9499 (3.3762)	Learning Rate [0.00125]
5: TRAIN [1][1810/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00093)	Tok/s 32216 (53647)	Loss/tok 3.0630 (3.3823)	Learning Rate [0.00125]
3: TRAIN [1][1810/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00093)	Tok/s 32085 (53462)	Loss/tok 2.8491 (3.3810)	Learning Rate [0.00125]
4: TRAIN [1][1810/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00100)	Tok/s 32183 (53564)	Loss/tok 3.1033 (3.3789)	Learning Rate [0.00125]
2: TRAIN [1][1810/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00098)	Tok/s 31713 (53371)	Loss/tok 3.0578 (3.3844)	Learning Rate [0.00125]
9: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 51813 (53934)	Loss/tok 3.4494 (3.3718)	Learning Rate [0.00125]
5: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00093)	Tok/s 51581 (53637)	Loss/tok 3.1839 (3.3821)	Learning Rate [0.00125]
12: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00096)	Tok/s 52023 (54211)	Loss/tok 3.4927 (3.3732)	Learning Rate [0.00125]
10: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00112 (0.00096)	Tok/s 51917 (54017)	Loss/tok 3.3091 (3.3770)	Learning Rate [0.00125]
8: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00097)	Tok/s 51723 (53874)	Loss/tok 3.6050 (3.3847)	Learning Rate [0.00125]
11: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00092)	Tok/s 51878 (54104)	Loss/tok 3.5475 (3.3762)	Learning Rate [0.00125]
6: TRAIN [1][1820/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00092)	Tok/s 51418 (53709)	Loss/tok 3.3908 (3.3813)	Learning Rate [0.00125]
7: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00109 (0.00097)	Tok/s 51671 (53795)	Loss/tok 3.1384 (3.3763)	Learning Rate [0.00125]
4: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00100)	Tok/s 51503 (53555)	Loss/tok 3.1661 (3.3788)	Learning Rate [0.00125]
14: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00092)	Tok/s 51774 (54396)	Loss/tok 3.4777 (3.3810)	Learning Rate [0.00125]
3: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00093)	Tok/s 51504 (53454)	Loss/tok 3.2240 (3.3810)	Learning Rate [0.00125]
0: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00098)	Tok/s 51594 (53163)	Loss/tok 3.2686 (3.3819)	Learning Rate [0.00125]
15: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00081 (0.00092)	Tok/s 51674 (54501)	Loss/tok 3.2018 (3.3764)	Learning Rate [0.00125]
1: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00097)	Tok/s 51527 (53266)	Loss/tok 3.6424 (3.3828)	Learning Rate [0.00125]
13: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00134 (0.00097)	Tok/s 51926 (54303)	Loss/tok 3.3556 (3.3770)	Learning Rate [0.00125]
2: TRAIN [1][1820/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00098)	Tok/s 51526 (53363)	Loss/tok 3.3059 (3.3842)	Learning Rate [0.00125]
6: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
14: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 67405 (54393)	Loss/tok 3.5875 (3.3812)	Learning Rate [0.00125]
15: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 67437 (54499)	Loss/tok 3.7264 (3.3766)	Learning Rate [0.00125]
13: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 67318 (54301)	Loss/tok 3.3910 (3.3768)	Learning Rate [0.00125]
0: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 66514 (53162)	Loss/tok 3.2414 (3.3817)	Learning Rate [0.00125]
11: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 67294 (54101)	Loss/tok 3.3386 (3.3763)	Learning Rate [0.00125]
12: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 67350 (54208)	Loss/tok 3.4743 (3.3728)	Learning Rate [0.00125]
1: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 66489 (53265)	Loss/tok 3.7990 (3.3832)	Learning Rate [0.00125]
2: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 66520 (53362)	Loss/tok 3.5863 (3.3847)	Learning Rate [0.00125]
9: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 67287 (53931)	Loss/tok 3.5184 (3.3719)	Learning Rate [0.00125]
10: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00096)	Tok/s 67334 (54014)	Loss/tok 3.3705 (3.3769)	Learning Rate [0.00125]
3: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 66488 (53452)	Loss/tok 3.2728 (3.3811)	Learning Rate [0.00125]
6: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 66318 (53706)	Loss/tok 3.5168 (3.3814)	Learning Rate [0.00125]
5: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 66337 (53634)	Loss/tok 3.3063 (3.3818)	Learning Rate [0.00125]
8: TRAIN [1][1830/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 66309 (53871)	Loss/tok 3.4237 (3.3845)	Learning Rate [0.00125]
7: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00097)	Tok/s 66335 (53792)	Loss/tok 3.4042 (3.3766)	Learning Rate [0.00125]
4: TRAIN [1][1830/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 66389 (53553)	Loss/tok 3.7796 (3.3789)	Learning Rate [0.00125]
0: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00101 (0.00098)	Tok/s 32973 (53148)	Loss/tok 3.0360 (3.3808)	Learning Rate [0.00125]
1: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00097)	Tok/s 32897 (53252)	Loss/tok 2.7687 (3.3825)	Learning Rate [0.00125]
15: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00092)	Tok/s 34274 (54487)	Loss/tok 3.2563 (3.3759)	Learning Rate [0.00125]
2: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00098)	Tok/s 32894 (53348)	Loss/tok 3.2372 (3.3840)	Learning Rate [0.00125]
14: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00078 (0.00092)	Tok/s 34238 (54380)	Loss/tok 3.0714 (3.3807)	Learning Rate [0.00125]
3: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00093)	Tok/s 32885 (53438)	Loss/tok 2.9507 (3.3809)	Learning Rate [0.00125]
13: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00097)	Tok/s 33958 (54288)	Loss/tok 2.9255 (3.3759)	Learning Rate [0.00125]
12: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00096)	Tok/s 32790 (54194)	Loss/tok 3.0775 (3.3725)	Learning Rate [0.00125]
4: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00100)	Tok/s 32807 (53538)	Loss/tok 2.9893 (3.3782)	Learning Rate [0.00125]
11: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00092)	Tok/s 32708 (54086)	Loss/tok 2.6875 (3.3756)	Learning Rate [0.00125]
6: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00092)	Tok/s 32752 (53691)	Loss/tok 3.0643 (3.3805)	Learning Rate [0.00125]
5: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00093)	Tok/s 32770 (53620)	Loss/tok 2.8635 (3.3815)	Learning Rate [0.00125]
9: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00092)	Tok/s 32603 (53916)	Loss/tok 2.9542 (3.3712)	Learning Rate [0.00125]
10: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00096)	Tok/s 32601 (53999)	Loss/tok 3.0515 (3.3760)	Learning Rate [0.00125]
7: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00097)	Tok/s 32666 (53777)	Loss/tok 2.8396 (3.3757)	Learning Rate [0.00125]
8: TRAIN [1][1840/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00097)	Tok/s 32540 (53856)	Loss/tok 3.0725 (3.3837)	Learning Rate [0.00125]
14: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00092)	Tok/s 45961 (54329)	Loss/tok 3.1569 (3.3799)	Learning Rate [0.00125]
15: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00092)	Tok/s 45865 (54435)	Loss/tok 3.4837 (3.3755)	Learning Rate [0.00125]
13: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00104 (0.00097)	Tok/s 45934 (54235)	Loss/tok 3.2090 (3.3756)	Learning Rate [0.00125]
0: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00111 (0.00098)	Tok/s 44288 (53086)	Loss/tok 2.9723 (3.3805)	Learning Rate [0.00125]
1: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00097)	Tok/s 44172 (53190)	Loss/tok 3.0379 (3.3820)	Learning Rate [0.00125]
12: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00096)	Tok/s 45280 (54141)	Loss/tok 3.0287 (3.3722)	Learning Rate [0.00125]
9: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00092)	Tok/s 44328 (53862)	Loss/tok 3.1134 (3.3706)	Learning Rate [0.00125]
2: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00098)	Tok/s 44027 (53288)	Loss/tok 3.1042 (3.3833)	Learning Rate [0.00125]
10: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00117 (0.00096)	Tok/s 44457 (53946)	Loss/tok 3.0736 (3.3756)	Learning Rate [0.00125]
4: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00100)	Tok/s 44007 (53481)	Loss/tok 3.1775 (3.3778)	Learning Rate [0.00125]
11: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00092)	Tok/s 44481 (54032)	Loss/tok 3.1806 (3.3754)	Learning Rate [0.00125]
8: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00106 (0.00097)	Tok/s 44175 (53802)	Loss/tok 3.3716 (3.3829)	Learning Rate [0.00125]
7: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00115 (0.00097)	Tok/s 44079 (53723)	Loss/tok 3.2096 (3.3757)	Learning Rate [0.00125]
6: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00092)	Tok/s 44020 (53636)	Loss/tok 3.2536 (3.3799)	Learning Rate [0.00125]
5: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00093)	Tok/s 43928 (53563)	Loss/tok 3.4809 (3.3812)	Learning Rate [0.00125]
3: TRAIN [1][1850/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00093)	Tok/s 43938 (53379)	Loss/tok 3.3994 (3.3803)	Learning Rate [0.00125]
9: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 60650 (53898)	Loss/tok 3.2159 (3.3709)	Learning Rate [0.00125]
11: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 60606 (54068)	Loss/tok 3.6200 (3.3757)	Learning Rate [0.00125]
10: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 60649 (53981)	Loss/tok 3.5385 (3.3759)	Learning Rate [0.00125]
8: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 60633 (53838)	Loss/tok 3.5272 (3.3831)	Learning Rate [0.00125]
7: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 60462 (53759)	Loss/tok 3.6761 (3.3765)	Learning Rate [0.00125]
6: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 60382 (53672)	Loss/tok 3.4065 (3.3803)	Learning Rate [0.00125]
14: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 60323 (54363)	Loss/tok 3.1346 (3.3802)	Learning Rate [0.00125]
4: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00100)	Tok/s 60205 (53518)	Loss/tok 3.5740 (3.3788)	Learning Rate [0.00125]
5: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 60265 (53600)	Loss/tok 3.3404 (3.3817)	Learning Rate [0.00125]
0: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00098)	Tok/s 60131 (53123)	Loss/tok 3.5519 (3.3811)	Learning Rate [0.00125]
1: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 60045 (53228)	Loss/tok 3.3616 (3.3819)	Learning Rate [0.00125]
3: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 60043 (53416)	Loss/tok 3.5432 (3.3802)	Learning Rate [0.00125]
15: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 60809 (54469)	Loss/tok 3.3724 (3.3760)	Learning Rate [0.00125]
2: TRAIN [1][1860/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 60022 (53325)	Loss/tok 3.7737 (3.3841)	Learning Rate [0.00125]
12: TRAIN [1][1860/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 59689 (54175)	Loss/tok 3.8612 (3.3730)	Learning Rate [0.00125]
13: TRAIN [1][1860/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00097)	Tok/s 59609 (54269)	Loss/tok 3.3818 (3.3766)	Learning Rate [0.00125]
12: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00096)	Tok/s 40843 (54147)	Loss/tok 2.9650 (3.3727)	Learning Rate [0.00125]
13: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00097)	Tok/s 40743 (54241)	Loss/tok 3.1837 (3.3763)	Learning Rate [0.00125]
11: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 40004 (54039)	Loss/tok 3.3801 (3.3754)	Learning Rate [0.00125]
14: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00092)	Tok/s 40666 (54335)	Loss/tok 3.3093 (3.3797)	Learning Rate [0.00125]
10: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00096)	Tok/s 39523 (53952)	Loss/tok 3.1682 (3.3757)	Learning Rate [0.00125]
9: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 39492 (53869)	Loss/tok 3.1117 (3.3707)	Learning Rate [0.00125]
15: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 40568 (54441)	Loss/tok 3.0664 (3.3755)	Learning Rate [0.00125]
8: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00097)	Tok/s 39495 (53809)	Loss/tok 2.9795 (3.3828)	Learning Rate [0.00125]
1: TRAIN [1][1870/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00097)	Tok/s 39140 (53200)	Loss/tok 3.0500 (3.3815)	Learning Rate [0.00125]
7: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 39333 (53730)	Loss/tok 3.0706 (3.3765)	Learning Rate [0.00125]
0: TRAIN [1][1870/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00098)	Tok/s 39160 (53096)	Loss/tok 3.2985 (3.3809)	Learning Rate [0.00125]
6: TRAIN [1][1870/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00092)	Tok/s 39195 (53643)	Loss/tok 3.0423 (3.3799)	Learning Rate [0.00125]
5: TRAIN [1][1870/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00093)	Tok/s 39165 (53571)	Loss/tok 3.3096 (3.3819)	Learning Rate [0.00125]
4: TRAIN [1][1870/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00100)	Tok/s 39025 (53489)	Loss/tok 3.1213 (3.3788)	Learning Rate [0.00125]
3: TRAIN [1][1870/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00093)	Tok/s 39046 (53387)	Loss/tok 3.1813 (3.3800)	Learning Rate [0.00125]
2: TRAIN [1][1870/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00098)	Tok/s 38996 (53297)	Loss/tok 3.0716 (3.3841)	Learning Rate [0.00125]
4: TRAIN [1][1880/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00100)	Tok/s 53927 (53495)	Loss/tok 3.3918 (3.3788)	Learning Rate [0.00125]
3: TRAIN [1][1880/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00093)	Tok/s 53907 (53394)	Loss/tok 3.1205 (3.3794)	Learning Rate [0.00125]
2: TRAIN [1][1880/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00098)	Tok/s 53821 (53304)	Loss/tok 3.5005 (3.3849)	Learning Rate [0.00125]
1: TRAIN [1][1880/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 53712 (53208)	Loss/tok 3.4046 (3.3816)	Learning Rate [0.00125]
5: TRAIN [1][1880/3416]	Time 0.052 (0.058)	Data 0.00074 (0.00093)	Tok/s 53976 (53576)	Loss/tok 3.3623 (3.3816)	Learning Rate [0.00125]
6: TRAIN [1][1880/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 53921 (53648)	Loss/tok 3.2814 (3.3802)	Learning Rate [0.00125]
0: TRAIN [1][1880/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00098)	Tok/s 53588 (53104)	Loss/tok 3.3756 (3.3809)	Learning Rate [0.00125]
15: TRAIN [1][1880/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00092)	Tok/s 54679 (54444)	Loss/tok 3.2056 (3.3753)	Learning Rate [0.00125]
7: TRAIN [1][1880/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00097)	Tok/s 53848 (53735)	Loss/tok 3.3764 (3.3765)	Learning Rate [0.00125]
8: TRAIN [1][1880/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00097)	Tok/s 53806 (53813)	Loss/tok 3.3650 (3.3834)	Learning Rate [0.00125]
14: TRAIN [1][1880/3416]	Time 0.053 (0.058)	Data 0.00081 (0.00092)	Tok/s 54695 (54339)	Loss/tok 3.4830 (3.3797)	Learning Rate [0.00125]
9: TRAIN [1][1880/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 53687 (53873)	Loss/tok 3.1677 (3.3708)	Learning Rate [0.00125]
13: TRAIN [1][1880/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00097)	Tok/s 54702 (54245)	Loss/tok 3.4450 (3.3764)	Learning Rate [0.00125]
10: TRAIN [1][1880/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00096)	Tok/s 54160 (53956)	Loss/tok 3.3840 (3.3755)	Learning Rate [0.00125]
11: TRAIN [1][1880/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00092)	Tok/s 54737 (54043)	Loss/tok 3.4188 (3.3759)	Learning Rate [0.00125]
12: TRAIN [1][1880/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00096)	Tok/s 54688 (54151)	Loss/tok 3.5767 (3.3731)	Learning Rate [0.00125]
4: TRAIN [1][1890/3416]	Time 0.061 (0.058)	Data 0.00101 (0.00100)	Tok/s 55359 (53496)	Loss/tok 3.4162 (3.3792)	Learning Rate [0.00125]
6: TRAIN [1][1890/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00092)	Tok/s 55760 (53649)	Loss/tok 3.4628 (3.3797)	Learning Rate [0.00125]
3: TRAIN [1][1890/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00093)	Tok/s 55337 (53394)	Loss/tok 3.3502 (3.3796)	Learning Rate [0.00125]
5: TRAIN [1][1890/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00093)	Tok/s 55228 (53576)	Loss/tok 3.3073 (3.3810)	Learning Rate [0.00125]
2: TRAIN [1][1890/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00098)	Tok/s 55360 (53305)	Loss/tok 3.6406 (3.3851)	Learning Rate [0.00125]
8: TRAIN [1][1890/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00097)	Tok/s 56051 (53814)	Loss/tok 3.4416 (3.3834)	Learning Rate [0.00125]
1: TRAIN [1][1890/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00097)	Tok/s 55363 (53209)	Loss/tok 3.3523 (3.3815)	Learning Rate [0.00125]
7: TRAIN [1][1890/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00097)	Tok/s 56016 (53736)	Loss/tok 3.4137 (3.3764)	Learning Rate [0.00125]
15: TRAIN [1][1890/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00092)	Tok/s 56294 (54444)	Loss/tok 3.3458 (3.3752)	Learning Rate [0.00125]
12: TRAIN [1][1890/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00096)	Tok/s 56130 (54151)	Loss/tok 3.4871 (3.3734)	Learning Rate [0.00125]
9: TRAIN [1][1890/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00092)	Tok/s 55921 (53873)	Loss/tok 3.4586 (3.3711)	Learning Rate [0.00125]
0: TRAIN [1][1890/3416]	Time 0.061 (0.058)	Data 0.00101 (0.00098)	Tok/s 55325 (53106)	Loss/tok 3.5124 (3.3814)	Learning Rate [0.00125]
14: TRAIN [1][1890/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00092)	Tok/s 56183 (54339)	Loss/tok 3.7289 (3.3799)	Learning Rate [0.00125]
11: TRAIN [1][1890/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00092)	Tok/s 55972 (54043)	Loss/tok 3.3463 (3.3759)	Learning Rate [0.00125]
10: TRAIN [1][1890/3416]	Time 0.062 (0.058)	Data 0.00110 (0.00096)	Tok/s 55945 (53957)	Loss/tok 3.5298 (3.3755)	Learning Rate [0.00125]
13: TRAIN [1][1890/3416]	Time 0.062 (0.058)	Data 0.00104 (0.00097)	Tok/s 56098 (54246)	Loss/tok 3.3687 (3.3761)	Learning Rate [0.00125]
1: Gradient norm: inf
2: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
3: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
14: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
12: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
10: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
4: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00100)	Tok/s 62538 (53547)	Loss/tok 3.6458 (3.3792)	Learning Rate [0.00125]
3: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 62518 (53446)	Loss/tok 3.6024 (3.3797)	Learning Rate [0.00125]
5: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 62369 (53627)	Loss/tok 3.4571 (3.3807)	Learning Rate [0.00125]
2: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 62491 (53357)	Loss/tok 3.5054 (3.3850)	Learning Rate [0.00125]
7: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 62291 (53787)	Loss/tok 3.4651 (3.3764)	Learning Rate [0.00125]
6: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 62287 (53699)	Loss/tok 3.4212 (3.3800)	Learning Rate [0.00125]
1: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 61718 (53261)	Loss/tok 3.5244 (3.3817)	Learning Rate [0.00125]
8: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 62264 (53865)	Loss/tok 3.4645 (3.3831)	Learning Rate [0.00125]
0: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00098)	Tok/s 61560 (53157)	Loss/tok 3.3329 (3.3812)	Learning Rate [0.00125]
15: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00092)	Tok/s 62453 (54495)	Loss/tok 3.3753 (3.3750)	Learning Rate [0.00125]
9: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 62173 (53924)	Loss/tok 3.6257 (3.3706)	Learning Rate [0.00125]
12: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 62332 (54202)	Loss/tok 3.4375 (3.3733)	Learning Rate [0.00125]
14: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 62388 (54390)	Loss/tok 3.5672 (3.3801)	Learning Rate [0.00125]
10: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00096)	Tok/s 62131 (54008)	Loss/tok 3.5678 (3.3751)	Learning Rate [0.00125]
13: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00097)	Tok/s 62288 (54296)	Loss/tok 3.4026 (3.3761)	Learning Rate [0.00125]
11: TRAIN [1][1900/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 62164 (54094)	Loss/tok 3.7130 (3.3763)	Learning Rate [0.00125]
5: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 43101 (53593)	Loss/tok 3.0915 (3.3802)	Learning Rate [0.00125]
6: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00080 (0.00091)	Tok/s 42994 (53665)	Loss/tok 3.2084 (3.3797)	Learning Rate [0.00125]
4: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00100)	Tok/s 43074 (53513)	Loss/tok 3.0329 (3.3790)	Learning Rate [0.00125]
3: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00093)	Tok/s 43091 (53412)	Loss/tok 3.3005 (3.3795)	Learning Rate [0.00125]
2: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00098)	Tok/s 43076 (53323)	Loss/tok 2.8851 (3.3846)	Learning Rate [0.00125]
7: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00097)	Tok/s 42846 (53752)	Loss/tok 3.0342 (3.3761)	Learning Rate [0.00125]
8: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00097)	Tok/s 42859 (53830)	Loss/tok 3.2426 (3.3829)	Learning Rate [0.00125]
9: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 42901 (53889)	Loss/tok 3.3414 (3.3703)	Learning Rate [0.00125]
1: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00097)	Tok/s 43086 (53228)	Loss/tok 3.3309 (3.3813)	Learning Rate [0.00125]
0: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00098)	Tok/s 43072 (53125)	Loss/tok 3.2165 (3.3810)	Learning Rate [0.00125]
15: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00092)	Tok/s 43051 (54459)	Loss/tok 3.1331 (3.3746)	Learning Rate [0.00125]
11: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00092)	Tok/s 42841 (54058)	Loss/tok 3.0817 (3.3758)	Learning Rate [0.00125]
10: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00108 (0.00096)	Tok/s 42920 (53973)	Loss/tok 3.1622 (3.3750)	Learning Rate [0.00125]
14: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00092)	Tok/s 43024 (54354)	Loss/tok 3.2377 (3.3798)	Learning Rate [0.00125]
12: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00096)	Tok/s 42938 (54166)	Loss/tok 3.1673 (3.3728)	Learning Rate [0.00125]
13: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00097)	Tok/s 42942 (54260)	Loss/tok 3.4184 (3.3758)	Learning Rate [0.00125]
4: TRAIN [1][1920/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00099)	Tok/s 33279 (53504)	Loss/tok 2.9025 (3.3792)	Learning Rate [0.00125]
3: TRAIN [1][1920/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00093)	Tok/s 33325 (53404)	Loss/tok 2.8087 (3.3788)	Learning Rate [0.00125]
5: TRAIN [1][1920/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00093)	Tok/s 33242 (53585)	Loss/tok 3.0191 (3.3806)	Learning Rate [0.00125]
6: TRAIN [1][1920/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00091)	Tok/s 33155 (53658)	Loss/tok 2.7282 (3.3795)	Learning Rate [0.00125]
2: TRAIN [1][1920/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00098)	Tok/s 33279 (53315)	Loss/tok 2.8346 (3.3848)	Learning Rate [0.00125]
1: TRAIN [1][1920/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00097)	Tok/s 33240 (53217)	Loss/tok 2.9249 (3.3814)	Learning Rate [0.00125]
7: TRAIN [1][1920/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00097)	Tok/s 33088 (53747)	Loss/tok 2.8244 (3.3765)	Learning Rate [0.00125]
0: TRAIN [1][1920/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00098)	Tok/s 33178 (53113)	Loss/tok 3.0617 (3.3809)	Learning Rate [0.00125]
8: TRAIN [1][1920/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00097)	Tok/s 33194 (53825)	Loss/tok 3.0037 (3.3827)	Learning Rate [0.00125]
9: TRAIN [1][1920/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00092)	Tok/s 34289 (53885)	Loss/tok 3.0579 (3.3701)	Learning Rate [0.00125]
15: TRAIN [1][1920/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00092)	Tok/s 34523 (54455)	Loss/tok 3.0100 (3.3747)	Learning Rate [0.00125]
14: TRAIN [1][1920/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00092)	Tok/s 34414 (54350)	Loss/tok 3.0904 (3.3795)	Learning Rate [0.00125]
11: TRAIN [1][1920/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00092)	Tok/s 34259 (54053)	Loss/tok 2.7773 (3.3759)	Learning Rate [0.00125]
13: TRAIN [1][1920/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00097)	Tok/s 34322 (54256)	Loss/tok 3.2671 (3.3764)	Learning Rate [0.00125]
10: TRAIN [1][1920/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00096)	Tok/s 34204 (53968)	Loss/tok 3.2315 (3.3753)	Learning Rate [0.00125]
12: TRAIN [1][1920/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00096)	Tok/s 34259 (54161)	Loss/tok 3.0680 (3.3731)	Learning Rate [0.00125]
6: TRAIN [1][1930/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00091)	Tok/s 38050 (53648)	Loss/tok 3.0414 (3.3785)	Learning Rate [0.00125]
7: TRAIN [1][1930/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00097)	Tok/s 38128 (53737)	Loss/tok 3.0960 (3.3764)	Learning Rate [0.00125]
9: TRAIN [1][1930/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00092)	Tok/s 39430 (53875)	Loss/tok 3.1048 (3.3696)	Learning Rate [0.00125]
5: TRAIN [1][1930/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 37998 (53575)	Loss/tok 3.2496 (3.3807)	Learning Rate [0.00125]
4: TRAIN [1][1930/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00100)	Tok/s 37942 (53494)	Loss/tok 3.0429 (3.3784)	Learning Rate [0.00125]
8: TRAIN [1][1930/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00097)	Tok/s 38122 (53816)	Loss/tok 3.0748 (3.3828)	Learning Rate [0.00125]
3: TRAIN [1][1930/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 37814 (53393)	Loss/tok 3.2443 (3.3787)	Learning Rate [0.00125]
11: TRAIN [1][1930/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00092)	Tok/s 39428 (54043)	Loss/tok 3.0450 (3.3760)	Learning Rate [0.00125]
10: TRAIN [1][1930/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00096)	Tok/s 39363 (53958)	Loss/tok 3.1278 (3.3751)	Learning Rate [0.00125]
2: TRAIN [1][1930/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00098)	Tok/s 37806 (53305)	Loss/tok 3.1030 (3.3843)	Learning Rate [0.00125]
12: TRAIN [1][1930/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00096)	Tok/s 39339 (54152)	Loss/tok 3.2468 (3.3729)	Learning Rate [0.00125]
1: TRAIN [1][1930/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 37746 (53208)	Loss/tok 3.0989 (3.3816)	Learning Rate [0.00125]
15: TRAIN [1][1930/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00092)	Tok/s 39103 (54445)	Loss/tok 3.0558 (3.3748)	Learning Rate [0.00125]
0: TRAIN [1][1930/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00098)	Tok/s 37786 (53103)	Loss/tok 3.0644 (3.3806)	Learning Rate [0.00125]
13: TRAIN [1][1930/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00097)	Tok/s 39211 (54246)	Loss/tok 3.2697 (3.3763)	Learning Rate [0.00125]
14: TRAIN [1][1930/3416]	Time 0.051 (0.058)	Data 0.00081 (0.00092)	Tok/s 39136 (54340)	Loss/tok 2.8394 (3.3793)	Learning Rate [0.00125]
7: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00097)	Tok/s 31446 (53710)	Loss/tok 2.6922 (3.3760)	Learning Rate [0.00125]
8: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00097)	Tok/s 31444 (53789)	Loss/tok 2.9696 (3.3820)	Learning Rate [0.00125]
4: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00100)	Tok/s 31255 (53466)	Loss/tok 3.1160 (3.3780)	Learning Rate [0.00125]
5: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00093)	Tok/s 31286 (53548)	Loss/tok 3.0676 (3.3801)	Learning Rate [0.00125]
9: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 31446 (53850)	Loss/tok 3.1977 (3.3693)	Learning Rate [0.00125]
11: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00092)	Tok/s 32335 (54018)	Loss/tok 2.8032 (3.3759)	Learning Rate [0.00125]
3: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00093)	Tok/s 31200 (53365)	Loss/tok 2.8568 (3.3783)	Learning Rate [0.00125]
10: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00096)	Tok/s 31444 (53933)	Loss/tok 2.9963 (3.3746)	Learning Rate [0.00125]
2: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00098)	Tok/s 31206 (53276)	Loss/tok 2.8378 (3.3841)	Learning Rate [0.00125]
1: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 31198 (53177)	Loss/tok 2.9199 (3.3814)	Learning Rate [0.00125]
12: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00096)	Tok/s 32737 (54127)	Loss/tok 2.9657 (3.3725)	Learning Rate [0.00125]
6: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00091)	Tok/s 31481 (53621)	Loss/tok 2.9494 (3.3785)	Learning Rate [0.00125]
15: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00092)	Tok/s 32600 (54423)	Loss/tok 3.0849 (3.3746)	Learning Rate [0.00125]
13: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00097)	Tok/s 32672 (54222)	Loss/tok 2.8041 (3.3758)	Learning Rate [0.00125]
14: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00092)	Tok/s 32628 (54316)	Loss/tok 2.8298 (3.3789)	Learning Rate [0.00125]
0: TRAIN [1][1940/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00098)	Tok/s 31191 (53071)	Loss/tok 2.9324 (3.3805)	Learning Rate [0.00125]
10: Gradient norm: inf
11: Gradient norm: inf
9: Gradient norm: inf
10: Skipped batch, new scale: 512.0
11: Skipped batch, new scale: 512.0
9: Skipped batch, new scale: 512.0
12: Gradient norm: inf
8: Gradient norm: inf
12: Skipped batch, new scale: 512.0
8: Skipped batch, new scale: 512.0
13: Gradient norm: inf
7: Gradient norm: inf
6: Gradient norm: inf
13: Skipped batch, new scale: 512.0
14: Gradient norm: inf
7: Skipped batch, new scale: 512.0
5: Gradient norm: inf
6: Skipped batch, new scale: 512.0
15: Gradient norm: inf
14: Skipped batch, new scale: 512.0
4: Gradient norm: inf
5: Skipped batch, new scale: 512.0
15: Skipped batch, new scale: 512.0
0: Gradient norm: inf
3: Gradient norm: inf
4: Skipped batch, new scale: 512.0
1: Gradient norm: inf
0: Skipped batch, new scale: 512.0
3: Skipped batch, new scale: 512.0
1: Skipped batch, new scale: 512.0
2: Gradient norm: inf
2: Skipped batch, new scale: 512.0
8: TRAIN [1][1950/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00097)	Tok/s 58618 (53792)	Loss/tok 3.4326 (3.3815)	Learning Rate [0.00125]
9: TRAIN [1][1950/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00092)	Tok/s 58785 (53853)	Loss/tok 3.5123 (3.3691)	Learning Rate [0.00125]
14: TRAIN [1][1950/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00092)	Tok/s 58552 (54319)	Loss/tok 3.5094 (3.3787)	Learning Rate [0.00125]
15: TRAIN [1][1950/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00092)	Tok/s 58452 (54427)	Loss/tok 3.4585 (3.3744)	Learning Rate [0.00125]
7: TRAIN [1][1950/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00097)	Tok/s 57865 (53712)	Loss/tok 3.4757 (3.3760)	Learning Rate [0.00125]
0: TRAIN [1][1950/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00098)	Tok/s 57414 (53075)	Loss/tok 3.5357 (3.3806)	Learning Rate [0.00125]
13: TRAIN [1][1950/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00097)	Tok/s 58537 (54225)	Loss/tok 3.4844 (3.3754)	Learning Rate [0.00125]
11: TRAIN [1][1950/3416]	Time 0.068 (0.058)	Data 0.00077 (0.00092)	Tok/s 58586 (54021)	Loss/tok 3.5006 (3.3753)	Learning Rate [0.00125]
5: TRAIN [1][1950/3416]	Time 0.068 (0.058)	Data 0.00078 (0.00093)	Tok/s 57658 (53550)	Loss/tok 3.7253 (3.3802)	Learning Rate [0.00125]
12: TRAIN [1][1950/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00096)	Tok/s 58563 (54130)	Loss/tok 3.5938 (3.3725)	Learning Rate [0.00125]
1: TRAIN [1][1950/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00097)	Tok/s 57421 (53180)	Loss/tok 3.6482 (3.3814)	Learning Rate [0.00125]
4: TRAIN [1][1950/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00100)	Tok/s 57613 (53468)	Loss/tok 3.6612 (3.3779)	Learning Rate [0.00125]
10: TRAIN [1][1950/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00096)	Tok/s 58747 (53936)	Loss/tok 3.6461 (3.3748)	Learning Rate [0.00125]
3: TRAIN [1][1950/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00093)	Tok/s 57430 (53367)	Loss/tok 3.5627 (3.3778)	Learning Rate [0.00125]
2: TRAIN [1][1950/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00098)	Tok/s 57418 (53278)	Loss/tok 3.4911 (3.3843)	Learning Rate [0.00125]
6: TRAIN [1][1950/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00092)	Tok/s 57931 (53623)	Loss/tok 3.5597 (3.3782)	Learning Rate [0.00125]
1: TRAIN [1][1960/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 57539 (53212)	Loss/tok 3.5165 (3.3814)	Learning Rate [0.00125]
2: TRAIN [1][1960/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 57914 (53311)	Loss/tok 3.4112 (3.3845)	Learning Rate [0.00125]
3: TRAIN [1][1960/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00093)	Tok/s 58505 (53399)	Loss/tok 3.5569 (3.3778)	Learning Rate [0.00125]
0: TRAIN [1][1960/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 57339 (53108)	Loss/tok 3.5316 (3.3808)	Learning Rate [0.00125]
4: TRAIN [1][1960/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00100)	Tok/s 58392 (53499)	Loss/tok 3.5338 (3.3784)	Learning Rate [0.00125]
15: TRAIN [1][1960/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 59087 (54461)	Loss/tok 3.5174 (3.3744)	Learning Rate [0.00125]
5: TRAIN [1][1960/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 58328 (53582)	Loss/tok 3.5453 (3.3802)	Learning Rate [0.00125]
14: TRAIN [1][1960/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00092)	Tok/s 58574 (54353)	Loss/tok 3.4589 (3.3788)	Learning Rate [0.00125]
7: TRAIN [1][1960/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00097)	Tok/s 58093 (53744)	Loss/tok 3.3756 (3.3760)	Learning Rate [0.00125]
13: TRAIN [1][1960/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00097)	Tok/s 57961 (54258)	Loss/tok 3.5664 (3.3759)	Learning Rate [0.00125]
11: TRAIN [1][1960/3416]	Time 0.071 (0.058)	Data 0.00083 (0.00092)	Tok/s 57890 (54054)	Loss/tok 3.4445 (3.3756)	Learning Rate [0.00125]
9: TRAIN [1][1960/3416]	Time 0.071 (0.058)	Data 0.00086 (0.00092)	Tok/s 57966 (53885)	Loss/tok 3.4625 (3.3689)	Learning Rate [0.00125]
12: TRAIN [1][1960/3416]	Time 0.071 (0.058)	Data 0.00085 (0.00096)	Tok/s 57865 (54163)	Loss/tok 3.3968 (3.3730)	Learning Rate [0.00125]
8: TRAIN [1][1960/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00097)	Tok/s 58009 (53824)	Loss/tok 3.2428 (3.3812)	Learning Rate [0.00125]
6: TRAIN [1][1960/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 58278 (53655)	Loss/tok 3.5130 (3.3784)	Learning Rate [0.00125]
10: TRAIN [1][1960/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00096)	Tok/s 57783 (53969)	Loss/tok 3.5887 (3.3750)	Learning Rate [0.00125]
3: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00121 (0.00093)	Tok/s 73496 (53421)	Loss/tok 3.5788 (3.3778)	Learning Rate [0.00125]
15: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00115 (0.00092)	Tok/s 74226 (54483)	Loss/tok 3.2676 (3.3740)	Learning Rate [0.00125]
0: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 73335 (53130)	Loss/tok 3.6449 (3.3808)	Learning Rate [0.00125]
1: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 73363 (53235)	Loss/tok 3.3597 (3.3814)	Learning Rate [0.00125]
5: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00093)	Tok/s 73580 (53603)	Loss/tok 3.2112 (3.3804)	Learning Rate [0.00125]
14: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00092)	Tok/s 74239 (54375)	Loss/tok 3.3947 (3.3786)	Learning Rate [0.00125]
2: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00098)	Tok/s 73403 (53332)	Loss/tok 3.3653 (3.3844)	Learning Rate [0.00125]
4: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00100)	Tok/s 73539 (53521)	Loss/tok 3.6527 (3.3782)	Learning Rate [0.00125]
12: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 74374 (54185)	Loss/tok 3.1954 (3.3725)	Learning Rate [0.00125]
7: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 73979 (53767)	Loss/tok 3.3652 (3.3760)	Learning Rate [0.00125]
13: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 74145 (54280)	Loss/tok 3.4861 (3.3757)	Learning Rate [0.00125]
11: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 74230 (54076)	Loss/tok 3.4160 (3.3754)	Learning Rate [0.00125]
9: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00092)	Tok/s 74264 (53908)	Loss/tok 3.5272 (3.3689)	Learning Rate [0.00125]
8: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00097)	Tok/s 74209 (53847)	Loss/tok 3.1894 (3.3811)	Learning Rate [0.00125]
10: TRAIN [1][1970/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00096)	Tok/s 74232 (53991)	Loss/tok 3.3581 (3.3749)	Learning Rate [0.00125]
6: TRAIN [1][1970/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00092)	Tok/s 73720 (53677)	Loss/tok 3.3819 (3.3782)	Learning Rate [0.00125]
0: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00105 (0.00098)	Tok/s 51065 (53126)	Loss/tok 3.1209 (3.3811)	Learning Rate [0.00125]
15: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00106 (0.00092)	Tok/s 52267 (54476)	Loss/tok 3.2317 (3.3741)	Learning Rate [0.00125]
1: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00097)	Tok/s 51151 (53231)	Loss/tok 3.1543 (3.3813)	Learning Rate [0.00125]
2: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00098)	Tok/s 52139 (53329)	Loss/tok 3.4841 (3.3845)	Learning Rate [0.00125]
14: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00092)	Tok/s 52239 (54368)	Loss/tok 3.1088 (3.3787)	Learning Rate [0.00125]
13: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00097)	Tok/s 52247 (54273)	Loss/tok 3.3431 (3.3759)	Learning Rate [0.00125]
3: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00108 (0.00093)	Tok/s 52286 (53417)	Loss/tok 3.0957 (3.3776)	Learning Rate [0.00125]
12: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00096)	Tok/s 52291 (54178)	Loss/tok 3.3041 (3.3724)	Learning Rate [0.00125]
4: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00104 (0.00100)	Tok/s 52328 (53516)	Loss/tok 3.3326 (3.3782)	Learning Rate [0.00125]
11: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00092)	Tok/s 52235 (54070)	Loss/tok 3.2225 (3.3756)	Learning Rate [0.00125]
5: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00093)	Tok/s 52275 (53598)	Loss/tok 3.3925 (3.3801)	Learning Rate [0.00125]
9: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00092)	Tok/s 52222 (53902)	Loss/tok 2.8128 (3.3687)	Learning Rate [0.00125]
10: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00096)	Tok/s 52217 (53985)	Loss/tok 3.4337 (3.3750)	Learning Rate [0.00125]
8: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00097)	Tok/s 52270 (53842)	Loss/tok 3.3651 (3.3814)	Learning Rate [0.00125]
7: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00097)	Tok/s 52183 (53761)	Loss/tok 3.0783 (3.3760)	Learning Rate [0.00125]
6: TRAIN [1][1980/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00092)	Tok/s 52284 (53671)	Loss/tok 3.4219 (3.3784)	Learning Rate [0.00125]
0: TRAIN [1][1990/3416]	Time 0.043 (0.058)	Data 0.00106 (0.00098)	Tok/s 29456 (53114)	Loss/tok 2.6418 (3.3805)	Learning Rate [0.00125]
1: TRAIN [1][1990/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00097)	Tok/s 29423 (53218)	Loss/tok 2.7871 (3.3813)	Learning Rate [0.00125]
15: TRAIN [1][1990/3416]	Time 0.043 (0.058)	Data 0.00100 (0.00092)	Tok/s 30953 (54461)	Loss/tok 2.6159 (3.3740)	Learning Rate [0.00125]
2: TRAIN [1][1990/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00098)	Tok/s 29336 (53316)	Loss/tok 2.7723 (3.3843)	Learning Rate [0.00125]
14: TRAIN [1][1990/3416]	Time 0.043 (0.058)	Data 0.00090 (0.00092)	Tok/s 30942 (54353)	Loss/tok 2.8501 (3.3786)	Learning Rate [0.00125]
3: TRAIN [1][1990/3416]	Time 0.044 (0.058)	Data 0.00106 (0.00093)	Tok/s 29343 (53404)	Loss/tok 2.8219 (3.3774)	Learning Rate [0.00125]
13: TRAIN [1][1990/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00097)	Tok/s 30969 (54259)	Loss/tok 2.7992 (3.3758)	Learning Rate [0.00125]
4: TRAIN [1][1990/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00100)	Tok/s 29314 (53503)	Loss/tok 2.7934 (3.3785)	Learning Rate [0.00125]
12: TRAIN [1][1990/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00096)	Tok/s 30976 (54165)	Loss/tok 2.9555 (3.3723)	Learning Rate [0.00125]
11: TRAIN [1][1990/3416]	Time 0.043 (0.058)	Data 0.00078 (0.00092)	Tok/s 30958 (54057)	Loss/tok 2.7260 (3.3756)	Learning Rate [0.00125]
5: TRAIN [1][1990/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00093)	Tok/s 29607 (53585)	Loss/tok 2.7007 (3.3801)	Learning Rate [0.00125]
9: TRAIN [1][1990/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00092)	Tok/s 30926 (53890)	Loss/tok 3.0021 (3.3684)	Learning Rate [0.00125]
10: TRAIN [1][1990/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00096)	Tok/s 30995 (53972)	Loss/tok 2.8599 (3.3747)	Learning Rate [0.00125]
8: TRAIN [1][1990/3416]	Time 0.044 (0.058)	Data 0.00084 (0.00097)	Tok/s 30862 (53829)	Loss/tok 2.7310 (3.3814)	Learning Rate [0.00125]
7: TRAIN [1][1990/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00097)	Tok/s 30871 (53748)	Loss/tok 2.5081 (3.3760)	Learning Rate [0.00125]
6: TRAIN [1][1990/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00092)	Tok/s 30916 (53658)	Loss/tok 2.5255 (3.3778)	Learning Rate [0.00125]
7: TRAIN [1][2000/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00097)	Tok/s 52887 (53741)	Loss/tok 3.5669 (3.3760)	Learning Rate [0.00125]
8: TRAIN [1][2000/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00097)	Tok/s 52724 (53822)	Loss/tok 3.4090 (3.3810)	Learning Rate [0.00125]
5: TRAIN [1][2000/3416]	Time 0.058 (0.058)	Data 0.00081 (0.00093)	Tok/s 51844 (53578)	Loss/tok 3.4013 (3.3794)	Learning Rate [0.00125]
9: TRAIN [1][2000/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00092)	Tok/s 52654 (53883)	Loss/tok 3.4755 (3.3678)	Learning Rate [0.00125]
10: TRAIN [1][2000/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00096)	Tok/s 52699 (53966)	Loss/tok 3.1745 (3.3742)	Learning Rate [0.00125]
4: TRAIN [1][2000/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00100)	Tok/s 51343 (53496)	Loss/tok 3.2894 (3.3779)	Learning Rate [0.00125]
3: TRAIN [1][2000/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00093)	Tok/s 51252 (53398)	Loss/tok 3.5258 (3.3766)	Learning Rate [0.00125]
11: TRAIN [1][2000/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00092)	Tok/s 52483 (54050)	Loss/tok 3.1858 (3.3751)	Learning Rate [0.00125]
2: TRAIN [1][2000/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00098)	Tok/s 51138 (53310)	Loss/tok 3.0933 (3.3839)	Learning Rate [0.00125]
1: TRAIN [1][2000/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00097)	Tok/s 51064 (53212)	Loss/tok 3.5348 (3.3809)	Learning Rate [0.00125]
6: TRAIN [1][2000/3416]	Time 0.058 (0.058)	Data 0.00103 (0.00092)	Tok/s 52879 (53652)	Loss/tok 3.4384 (3.3776)	Learning Rate [0.00125]
12: TRAIN [1][2000/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00096)	Tok/s 52381 (54158)	Loss/tok 3.6019 (3.3721)	Learning Rate [0.00125]
0: TRAIN [1][2000/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00098)	Tok/s 51073 (53108)	Loss/tok 3.4428 (3.3800)	Learning Rate [0.00125]
13: TRAIN [1][2000/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00097)	Tok/s 52295 (54252)	Loss/tok 3.3496 (3.3757)	Learning Rate [0.00125]
15: TRAIN [1][2000/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00092)	Tok/s 52158 (54454)	Loss/tok 3.4283 (3.3736)	Learning Rate [0.00125]
14: TRAIN [1][2000/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00092)	Tok/s 52176 (54346)	Loss/tok 3.4001 (3.3784)	Learning Rate [0.00125]
7: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00100 (0.00097)	Tok/s 29444 (53739)	Loss/tok 2.6825 (3.3756)	Learning Rate [0.00125]
5: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00084 (0.00093)	Tok/s 29373 (53577)	Loss/tok 2.5689 (3.3790)	Learning Rate [0.00125]
4: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00093 (0.00100)	Tok/s 29382 (53496)	Loss/tok 2.8172 (3.3775)	Learning Rate [0.00125]
8: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00083 (0.00097)	Tok/s 29450 (53820)	Loss/tok 2.6235 (3.3805)	Learning Rate [0.00125]
9: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00088 (0.00092)	Tok/s 29449 (53881)	Loss/tok 2.6885 (3.3673)	Learning Rate [0.00125]
3: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00106 (0.00093)	Tok/s 28592 (53397)	Loss/tok 2.6249 (3.3764)	Learning Rate [0.00125]
1: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00098 (0.00097)	Tok/s 27846 (53211)	Loss/tok 2.5576 (3.3807)	Learning Rate [0.00125]
2: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00093 (0.00098)	Tok/s 27797 (53308)	Loss/tok 2.6072 (3.3836)	Learning Rate [0.00125]
11: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00085 (0.00092)	Tok/s 30775 (54048)	Loss/tok 3.0636 (3.3748)	Learning Rate [0.00125]
12: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00095 (0.00096)	Tok/s 31042 (54157)	Loss/tok 3.0896 (3.3716)	Learning Rate [0.00125]
13: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00100 (0.00097)	Tok/s 31030 (54250)	Loss/tok 2.7432 (3.3752)	Learning Rate [0.00125]
10: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00084 (0.00096)	Tok/s 29438 (53964)	Loss/tok 2.7219 (3.3743)	Learning Rate [0.00125]
0: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00093 (0.00098)	Tok/s 27793 (53107)	Loss/tok 2.4751 (3.3799)	Learning Rate [0.00125]
6: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00099 (0.00092)	Tok/s 29486 (53650)	Loss/tok 2.7058 (3.3777)	Learning Rate [0.00125]
15: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00097 (0.00092)	Tok/s 30905 (54452)	Loss/tok 2.6672 (3.3729)	Learning Rate [0.00125]
14: TRAIN [1][2010/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00092)	Tok/s 30925 (54344)	Loss/tok 2.8327 (3.3783)	Learning Rate [0.00125]
9: TRAIN [1][2020/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00092)	Tok/s 64526 (53911)	Loss/tok 3.6384 (3.3678)	Learning Rate [0.00125]
6: TRAIN [1][2020/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00092)	Tok/s 64621 (53680)	Loss/tok 3.5091 (3.3781)	Learning Rate [0.00125]
8: TRAIN [1][2020/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 64503 (53850)	Loss/tok 3.3581 (3.3806)	Learning Rate [0.00125]
12: TRAIN [1][2020/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 64306 (54186)	Loss/tok 3.3473 (3.3720)	Learning Rate [0.00125]
7: TRAIN [1][2020/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00097)	Tok/s 64510 (53768)	Loss/tok 3.5070 (3.3763)	Learning Rate [0.00125]
11: TRAIN [1][2020/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 64274 (54077)	Loss/tok 3.7255 (3.3756)	Learning Rate [0.00125]
10: TRAIN [1][2020/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00096)	Tok/s 64396 (53993)	Loss/tok 3.5714 (3.3754)	Learning Rate [0.00125]
5: TRAIN [1][2020/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 64542 (53607)	Loss/tok 3.5251 (3.3802)	Learning Rate [0.00125]
13: TRAIN [1][2020/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 64754 (54279)	Loss/tok 3.6690 (3.3757)	Learning Rate [0.00125]
4: TRAIN [1][2020/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00099)	Tok/s 64462 (53526)	Loss/tok 3.4399 (3.3777)	Learning Rate [0.00125]
3: TRAIN [1][2020/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00093)	Tok/s 64456 (53428)	Loss/tok 3.5342 (3.3765)	Learning Rate [0.00125]
14: TRAIN [1][2020/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 65101 (54373)	Loss/tok 3.3145 (3.3786)	Learning Rate [0.00125]
15: TRAIN [1][2020/3416]	Time 0.070 (0.058)	Data 0.00114 (0.00092)	Tok/s 65123 (54481)	Loss/tok 3.4928 (3.3733)	Learning Rate [0.00125]
2: TRAIN [1][2020/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 64317 (53340)	Loss/tok 3.4639 (3.3839)	Learning Rate [0.00125]
0: TRAIN [1][2020/3416]	Time 0.069 (0.058)	Data 0.00127 (0.00098)	Tok/s 64954 (53139)	Loss/tok 3.4813 (3.3799)	Learning Rate [0.00125]
1: TRAIN [1][2020/3416]	Time 0.069 (0.058)	Data 0.00117 (0.00097)	Tok/s 64950 (53242)	Loss/tok 3.3272 (3.3806)	Learning Rate [0.00125]
2: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00098)	Tok/s 38256 (53314)	Loss/tok 2.9805 (3.3836)	Learning Rate [0.00125]
1: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00097)	Tok/s 38255 (53217)	Loss/tok 2.9824 (3.3803)	Learning Rate [0.00125]
0: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00098)	Tok/s 38248 (53114)	Loss/tok 3.4497 (3.3797)	Learning Rate [0.00125]
3: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00093)	Tok/s 38122 (53402)	Loss/tok 3.0867 (3.3760)	Learning Rate [0.00125]
5: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00093)	Tok/s 38071 (53581)	Loss/tok 3.0158 (3.3795)	Learning Rate [0.00125]
15: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00092)	Tok/s 39497 (54455)	Loss/tok 3.2919 (3.3729)	Learning Rate [0.00125]
4: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00099)	Tok/s 38041 (53500)	Loss/tok 3.3246 (3.3774)	Learning Rate [0.00125]
6: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00081 (0.00092)	Tok/s 38071 (53654)	Loss/tok 3.1767 (3.3781)	Learning Rate [0.00125]
14: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00076 (0.00092)	Tok/s 39489 (54348)	Loss/tok 3.1909 (3.3781)	Learning Rate [0.00125]
8: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00097)	Tok/s 38108 (53825)	Loss/tok 3.2313 (3.3803)	Learning Rate [0.00125]
12: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00095)	Tok/s 39524 (54161)	Loss/tok 3.0591 (3.3718)	Learning Rate [0.00125]
11: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00092)	Tok/s 39453 (54053)	Loss/tok 3.4520 (3.3752)	Learning Rate [0.00125]
13: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 39457 (54254)	Loss/tok 3.0677 (3.3755)	Learning Rate [0.00125]
7: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00097)	Tok/s 38049 (53744)	Loss/tok 3.0528 (3.3761)	Learning Rate [0.00125]
9: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 38073 (53886)	Loss/tok 3.1052 (3.3674)	Learning Rate [0.00125]
10: TRAIN [1][2030/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00096)	Tok/s 39187 (53969)	Loss/tok 3.0069 (3.3751)	Learning Rate [0.00125]
6: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 39212 (53669)	Loss/tok 3.0421 (3.3778)	Learning Rate [0.00125]
7: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00097)	Tok/s 39251 (53759)	Loss/tok 3.1692 (3.3757)	Learning Rate [0.00125]
8: TRAIN [1][2040/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00097)	Tok/s 39289 (53840)	Loss/tok 3.2399 (3.3802)	Learning Rate [0.00125]
5: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 39218 (53595)	Loss/tok 3.0735 (3.3791)	Learning Rate [0.00125]
9: TRAIN [1][2040/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00092)	Tok/s 39294 (53902)	Loss/tok 3.1508 (3.3668)	Learning Rate [0.00125]
4: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00107 (0.00099)	Tok/s 39072 (53513)	Loss/tok 3.1900 (3.3771)	Learning Rate [0.00125]
3: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00093)	Tok/s 39136 (53414)	Loss/tok 3.1438 (3.3757)	Learning Rate [0.00125]
2: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00098)	Tok/s 39069 (53326)	Loss/tok 3.3329 (3.3830)	Learning Rate [0.00125]
11: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 39091 (54069)	Loss/tok 3.2302 (3.3746)	Learning Rate [0.00125]
1: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00097)	Tok/s 39051 (53227)	Loss/tok 3.0609 (3.3798)	Learning Rate [0.00125]
0: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00098)	Tok/s 39021 (53123)	Loss/tok 3.1010 (3.3792)	Learning Rate [0.00125]
12: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00095)	Tok/s 39072 (54177)	Loss/tok 3.3925 (3.3716)	Learning Rate [0.00125]
10: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00096)	Tok/s 39188 (53984)	Loss/tok 3.2200 (3.3749)	Learning Rate [0.00125]
13: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00107 (0.00097)	Tok/s 39085 (54270)	Loss/tok 3.2037 (3.3748)	Learning Rate [0.00125]
14: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 39208 (54364)	Loss/tok 3.3356 (3.3777)	Learning Rate [0.00125]
15: TRAIN [1][2040/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00092)	Tok/s 40245 (54472)	Loss/tok 2.8896 (3.3723)	Learning Rate [0.00125]
8: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00081 (0.00097)	Tok/s 50239 (53851)	Loss/tok 3.5932 (3.3803)	Learning Rate [0.00125]
9: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00092)	Tok/s 50166 (53912)	Loss/tok 3.4084 (3.3672)	Learning Rate [0.00125]
6: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00092)	Tok/s 50281 (53679)	Loss/tok 3.3955 (3.3782)	Learning Rate [0.00125]
7: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00110 (0.00097)	Tok/s 50246 (53769)	Loss/tok 3.3916 (3.3756)	Learning Rate [0.00125]
10: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00096)	Tok/s 50087 (53994)	Loss/tok 3.4592 (3.3748)	Learning Rate [0.00125]
5: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00093)	Tok/s 50237 (53606)	Loss/tok 3.1727 (3.3791)	Learning Rate [0.00125]
11: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00082 (0.00092)	Tok/s 49959 (54078)	Loss/tok 3.2450 (3.3749)	Learning Rate [0.00125]
4: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00104 (0.00099)	Tok/s 50270 (53524)	Loss/tok 3.3485 (3.3773)	Learning Rate [0.00125]
3: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00093)	Tok/s 50239 (53426)	Loss/tok 3.4108 (3.3755)	Learning Rate [0.00125]
12: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00095)	Tok/s 49960 (54186)	Loss/tok 3.0453 (3.3716)	Learning Rate [0.00125]
13: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00110 (0.00097)	Tok/s 50533 (54280)	Loss/tok 3.2436 (3.3752)	Learning Rate [0.00125]
2: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00098)	Tok/s 50176 (53338)	Loss/tok 3.5105 (3.3831)	Learning Rate [0.00125]
1: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00100 (0.00097)	Tok/s 50057 (53238)	Loss/tok 3.1626 (3.3797)	Learning Rate [0.00125]
14: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00086 (0.00092)	Tok/s 51080 (54374)	Loss/tok 3.3567 (3.3776)	Learning Rate [0.00125]
0: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00098)	Tok/s 50017 (53135)	Loss/tok 3.3314 (3.3791)	Learning Rate [0.00125]
15: TRAIN [1][2050/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00092)	Tok/s 51109 (54482)	Loss/tok 3.4643 (3.3723)	Learning Rate [0.00125]
3: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00106 (0.00093)	Tok/s 54369 (53424)	Loss/tok 3.2306 (3.3755)	Learning Rate [0.00125]
4: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00103 (0.00099)	Tok/s 54272 (53522)	Loss/tok 3.4058 (3.3774)	Learning Rate [0.00125]
2: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00098)	Tok/s 54323 (53336)	Loss/tok 3.2797 (3.3826)	Learning Rate [0.00125]
5: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00093)	Tok/s 54187 (53604)	Loss/tok 3.4989 (3.3791)	Learning Rate [0.00125]
1: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00104 (0.00097)	Tok/s 54334 (53237)	Loss/tok 3.5716 (3.3794)	Learning Rate [0.00125]
6: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00092)	Tok/s 53989 (53676)	Loss/tok 3.2515 (3.3779)	Learning Rate [0.00125]
0: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00098)	Tok/s 54322 (53134)	Loss/tok 3.4824 (3.3787)	Learning Rate [0.00125]
15: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00092)	Tok/s 55559 (54479)	Loss/tok 3.4213 (3.3723)	Learning Rate [0.00125]
7: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00097)	Tok/s 53882 (53767)	Loss/tok 3.3199 (3.3753)	Learning Rate [0.00125]
8: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00097)	Tok/s 53902 (53848)	Loss/tok 3.2574 (3.3802)	Learning Rate [0.00125]
14: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00092)	Tok/s 54613 (54371)	Loss/tok 3.4597 (3.3774)	Learning Rate [0.00125]
9: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00092)	Tok/s 53936 (53908)	Loss/tok 3.3251 (3.3671)	Learning Rate [0.00125]
13: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00105 (0.00098)	Tok/s 54194 (54276)	Loss/tok 3.2412 (3.3751)	Learning Rate [0.00125]
12: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00095)	Tok/s 54126 (54182)	Loss/tok 3.5261 (3.3716)	Learning Rate [0.00125]
11: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00092)	Tok/s 53992 (54074)	Loss/tok 3.4406 (3.3745)	Learning Rate [0.00125]
10: TRAIN [1][2060/3416]	Time 0.058 (0.058)	Data 0.00107 (0.00096)	Tok/s 53932 (53990)	Loss/tok 3.1485 (3.3745)	Learning Rate [0.00125]
9: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
9: TRAIN [1][2070/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00092)	Tok/s 54714 (53909)	Loss/tok 3.6683 (3.3672)	Learning Rate [0.00125]
5: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
8: TRAIN [1][2070/3416]	Time 0.059 (0.058)	Data 0.00080 (0.00097)	Tok/s 54630 (53849)	Loss/tok 3.5356 (3.3806)	Learning Rate [0.00125]
10: TRAIN [1][2070/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00096)	Tok/s 54744 (53991)	Loss/tok 3.3754 (3.3743)	Learning Rate [0.00125]
13: Upscaling, new scale: 1024.0
7: TRAIN [1][2070/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00097)	Tok/s 54577 (53768)	Loss/tok 3.4734 (3.3751)	Learning Rate [0.00125]
11: TRAIN [1][2070/3416]	Time 0.058 (0.058)	Data 0.00081 (0.00092)	Tok/s 54730 (54075)	Loss/tok 3.4482 (3.3745)	Learning Rate [0.00125]
6: TRAIN [1][2070/3416]	Time 0.059 (0.058)	Data 0.00076 (0.00092)	Tok/s 54556 (53678)	Loss/tok 3.3971 (3.3776)	Learning Rate [0.00125]
3: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
12: TRAIN [1][2070/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00095)	Tok/s 54783 (54184)	Loss/tok 3.2997 (3.3711)	Learning Rate [0.00125]
15: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
5: TRAIN [1][2070/3416]	Time 0.059 (0.058)	Data 0.00080 (0.00092)	Tok/s 54556 (53605)	Loss/tok 3.3158 (3.3790)	Learning Rate [0.00125]
0: Upscaling, new scale: 1024.0
13: TRAIN [1][2070/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00098)	Tok/s 54682 (54278)	Loss/tok 3.2627 (3.3750)	Learning Rate [0.00125]
14: TRAIN [1][2070/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00092)	Tok/s 54566 (54372)	Loss/tok 3.4056 (3.3773)	Learning Rate [0.00125]
4: TRAIN [1][2070/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00099)	Tok/s 54534 (53524)	Loss/tok 3.3532 (3.3773)	Learning Rate [0.00125]
3: TRAIN [1][2070/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00093)	Tok/s 54560 (53426)	Loss/tok 3.2630 (3.3753)	Learning Rate [0.00125]
15: TRAIN [1][2070/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00092)	Tok/s 54575 (54481)	Loss/tok 3.3199 (3.3725)	Learning Rate [0.00125]
1: TRAIN [1][2070/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00097)	Tok/s 54579 (53240)	Loss/tok 3.3725 (3.3802)	Learning Rate [0.00125]
0: TRAIN [1][2070/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00098)	Tok/s 53933 (53138)	Loss/tok 3.3480 (3.3787)	Learning Rate [0.00125]
2: TRAIN [1][2070/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00098)	Tok/s 54593 (53338)	Loss/tok 3.1240 (3.3828)	Learning Rate [0.00125]
0: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00098)	Tok/s 36489 (53107)	Loss/tok 3.3254 (3.3784)	Learning Rate [0.00125]
1: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00097)	Tok/s 36490 (53211)	Loss/tok 3.1468 (3.3799)	Learning Rate [0.00125]
15: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00092)	Tok/s 37665 (54457)	Loss/tok 3.1164 (3.3723)	Learning Rate [0.00125]
2: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00098)	Tok/s 37138 (53311)	Loss/tok 3.1363 (3.3829)	Learning Rate [0.00125]
14: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00092)	Tok/s 37593 (54348)	Loss/tok 3.4042 (3.3771)	Learning Rate [0.00125]
3: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00093)	Tok/s 37830 (53399)	Loss/tok 3.1802 (3.3753)	Learning Rate [0.00125]
13: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00107 (0.00098)	Tok/s 37485 (54253)	Loss/tok 3.3639 (3.3751)	Learning Rate [0.00125]
4: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00113 (0.00099)	Tok/s 37736 (53497)	Loss/tok 3.0509 (3.3775)	Learning Rate [0.00125]
12: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00095)	Tok/s 37417 (54159)	Loss/tok 3.2408 (3.3712)	Learning Rate [0.00125]
11: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 37424 (54051)	Loss/tok 3.1564 (3.3747)	Learning Rate [0.00125]
5: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 37645 (53579)	Loss/tok 3.0038 (3.3792)	Learning Rate [0.00125]
10: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00096)	Tok/s 37463 (53966)	Loss/tok 3.1211 (3.3743)	Learning Rate [0.00125]
6: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 37571 (53653)	Loss/tok 3.3338 (3.3772)	Learning Rate [0.00125]
9: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00092)	Tok/s 37470 (53885)	Loss/tok 3.0779 (3.3672)	Learning Rate [0.00125]
8: TRAIN [1][2080/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00097)	Tok/s 37441 (53825)	Loss/tok 3.0888 (3.3804)	Learning Rate [0.00125]
7: TRAIN [1][2080/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00097)	Tok/s 37213 (53743)	Loss/tok 3.0198 (3.3752)	Learning Rate [0.00125]
12: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00095)	Tok/s 54406 (54170)	Loss/tok 3.3964 (3.3714)	Learning Rate [0.00125]
11: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00092)	Tok/s 54474 (54062)	Loss/tok 3.4816 (3.3745)	Learning Rate [0.00125]
13: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00098)	Tok/s 54351 (54265)	Loss/tok 3.3869 (3.3760)	Learning Rate [0.00125]
14: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00092)	Tok/s 54240 (54359)	Loss/tok 3.3814 (3.3775)	Learning Rate [0.00125]
10: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00096)	Tok/s 54473 (53978)	Loss/tok 3.4057 (3.3745)	Learning Rate [0.00125]
9: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00112 (0.00092)	Tok/s 54432 (53897)	Loss/tok 3.4449 (3.3673)	Learning Rate [0.00125]
8: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00097)	Tok/s 54491 (53837)	Loss/tok 3.3242 (3.3805)	Learning Rate [0.00125]
0: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00098)	Tok/s 53170 (53120)	Loss/tok 3.3599 (3.3785)	Learning Rate [0.00125]
6: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00092)	Tok/s 54379 (53666)	Loss/tok 3.4578 (3.3776)	Learning Rate [0.00125]
1: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00097)	Tok/s 53541 (53224)	Loss/tok 3.4648 (3.3801)	Learning Rate [0.00125]
15: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00129 (0.00092)	Tok/s 54339 (54468)	Loss/tok 3.5589 (3.3725)	Learning Rate [0.00125]
5: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00092)	Tok/s 54457 (53592)	Loss/tok 3.3650 (3.3793)	Learning Rate [0.00125]
4: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00114 (0.00099)	Tok/s 54388 (53510)	Loss/tok 3.5833 (3.3774)	Learning Rate [0.00125]
3: TRAIN [1][2090/3416]	Time 0.059 (0.058)	Data 0.00112 (0.00093)	Tok/s 54361 (53412)	Loss/tok 3.2341 (3.3754)	Learning Rate [0.00125]
7: TRAIN [1][2090/3416]	Time 0.060 (0.058)	Data 0.00106 (0.00097)	Tok/s 53641 (53756)	Loss/tok 3.1329 (3.3752)	Learning Rate [0.00125]
2: TRAIN [1][2090/3416]	Time 0.060 (0.058)	Data 0.00104 (0.00098)	Tok/s 53468 (53323)	Loss/tok 3.2144 (3.3829)	Learning Rate [0.00125]
4: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00101 (0.00099)	Tok/s 26984 (53511)	Loss/tok 2.5721 (3.3776)	Learning Rate [0.00125]
6: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00087 (0.00092)	Tok/s 27036 (53667)	Loss/tok 2.5335 (3.3775)	Learning Rate [0.00125]
5: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00088 (0.00092)	Tok/s 27045 (53593)	Loss/tok 2.4516 (3.3791)	Learning Rate [0.00125]
3: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00095 (0.00093)	Tok/s 26332 (53412)	Loss/tok 2.3969 (3.3755)	Learning Rate [0.00125]
2: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00096 (0.00098)	Tok/s 25199 (53324)	Loss/tok 2.5613 (3.3826)	Learning Rate [0.00125]
7: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00105 (0.00097)	Tok/s 27038 (53757)	Loss/tok 2.4364 (3.3752)	Learning Rate [0.00125]
1: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00097 (0.00097)	Tok/s 25122 (53225)	Loss/tok 2.3589 (3.3800)	Learning Rate [0.00125]
8: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00097 (0.00097)	Tok/s 28637 (53839)	Loss/tok 2.4185 (3.3802)	Learning Rate [0.00125]
9: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00090 (0.00092)	Tok/s 28513 (53898)	Loss/tok 2.5811 (3.3672)	Learning Rate [0.00125]
15: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00091 (0.00092)	Tok/s 29966 (54470)	Loss/tok 2.5402 (3.3726)	Learning Rate [0.00125]
14: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00087 (0.00092)	Tok/s 29973 (54360)	Loss/tok 2.6061 (3.3775)	Learning Rate [0.00125]
0: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00097 (0.00098)	Tok/s 25003 (53121)	Loss/tok 2.3310 (3.3781)	Learning Rate [0.00125]
11: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00088 (0.00092)	Tok/s 28372 (54064)	Loss/tok 2.4469 (3.3745)	Learning Rate [0.00125]
13: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00115 (0.00098)	Tok/s 28609 (54265)	Loss/tok 2.5251 (3.3758)	Learning Rate [0.00125]
10: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00102 (0.00096)	Tok/s 28373 (53979)	Loss/tok 2.5837 (3.3746)	Learning Rate [0.00125]
12: TRAIN [1][2100/3416]	Time 0.038 (0.058)	Data 0.00107 (0.00095)	Tok/s 28650 (54171)	Loss/tok 2.5822 (3.3719)	Learning Rate [0.00125]
11: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00092)	Tok/s 57303 (54042)	Loss/tok 3.8537 (3.3745)	Learning Rate [0.00125]
9: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00092)	Tok/s 57361 (53878)	Loss/tok 3.3976 (3.3672)	Learning Rate [0.00125]
10: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00096)	Tok/s 57405 (53959)	Loss/tok 3.2280 (3.3744)	Learning Rate [0.00125]
6: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00092)	Tok/s 57364 (53647)	Loss/tok 3.5471 (3.3774)	Learning Rate [0.00125]
8: TRAIN [1][2110/3416]	Time 0.065 (0.058)	Data 0.00122 (0.00097)	Tok/s 57781 (53818)	Loss/tok 3.5392 (3.3803)	Learning Rate [0.00125]
12: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00095)	Tok/s 57190 (54150)	Loss/tok 3.2146 (3.3719)	Learning Rate [0.00125]
13: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00116 (0.00098)	Tok/s 57083 (54246)	Loss/tok 3.2438 (3.3755)	Learning Rate [0.00125]
7: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00104 (0.00097)	Tok/s 57329 (53737)	Loss/tok 3.4430 (3.3751)	Learning Rate [0.00125]
14: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00092)	Tok/s 56991 (54341)	Loss/tok 3.5241 (3.3774)	Learning Rate [0.00125]
5: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00092)	Tok/s 57242 (53574)	Loss/tok 3.4005 (3.3789)	Learning Rate [0.00125]
15: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00092)	Tok/s 56921 (54450)	Loss/tok 3.3450 (3.3732)	Learning Rate [0.00125]
0: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00103 (0.00098)	Tok/s 56922 (53103)	Loss/tok 3.4479 (3.3778)	Learning Rate [0.00125]
3: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00087 (0.00093)	Tok/s 57088 (53393)	Loss/tok 3.4471 (3.3754)	Learning Rate [0.00125]
4: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00107 (0.00100)	Tok/s 57185 (53492)	Loss/tok 3.3300 (3.3775)	Learning Rate [0.00125]
1: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00097)	Tok/s 56935 (53206)	Loss/tok 3.3806 (3.3798)	Learning Rate [0.00125]
2: TRAIN [1][2110/3416]	Time 0.066 (0.058)	Data 0.00103 (0.00098)	Tok/s 56991 (53305)	Loss/tok 3.6044 (3.3824)	Learning Rate [0.00125]
7: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00097)	Tok/s 51058 (53691)	Loss/tok 3.4342 (3.3744)	Learning Rate [0.00125]
6: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00092)	Tok/s 51065 (53600)	Loss/tok 3.2017 (3.3766)	Learning Rate [0.00125]
8: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00097)	Tok/s 51040 (53773)	Loss/tok 3.2850 (3.3802)	Learning Rate [0.00125]
5: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00092)	Tok/s 51061 (53526)	Loss/tok 3.3312 (3.3783)	Learning Rate [0.00125]
9: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00092)	Tok/s 51071 (53832)	Loss/tok 3.2928 (3.3670)	Learning Rate [0.00125]
4: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00116 (0.00100)	Tok/s 51085 (53443)	Loss/tok 3.1903 (3.3769)	Learning Rate [0.00125]
3: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00093)	Tok/s 51088 (53344)	Loss/tok 3.3760 (3.3750)	Learning Rate [0.00125]
10: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00096)	Tok/s 51972 (53912)	Loss/tok 3.1721 (3.3740)	Learning Rate [0.00125]
11: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00092)	Tok/s 52261 (53996)	Loss/tok 3.2825 (3.3743)	Learning Rate [0.00125]
2: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00106 (0.00098)	Tok/s 51075 (53255)	Loss/tok 3.2073 (3.3818)	Learning Rate [0.00125]
1: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00097)	Tok/s 51042 (53155)	Loss/tok 3.0643 (3.3794)	Learning Rate [0.00125]
12: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00095)	Tok/s 52241 (54105)	Loss/tok 3.3027 (3.3715)	Learning Rate [0.00125]
13: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00098)	Tok/s 52360 (54201)	Loss/tok 3.3955 (3.3748)	Learning Rate [0.00125]
0: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00098)	Tok/s 51059 (53051)	Loss/tok 3.2610 (3.3773)	Learning Rate [0.00125]
15: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00092)	Tok/s 52412 (54407)	Loss/tok 3.1739 (3.3728)	Learning Rate [0.00125]
14: TRAIN [1][2120/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00092)	Tok/s 52294 (54296)	Loss/tok 3.4366 (3.3773)	Learning Rate [0.00125]
11: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00082 (0.00092)	Tok/s 42084 (53979)	Loss/tok 3.0775 (3.3740)	Learning Rate [0.00125]
10: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00096)	Tok/s 41993 (53895)	Loss/tok 3.1082 (3.3736)	Learning Rate [0.00125]
9: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 41893 (53813)	Loss/tok 3.1605 (3.3663)	Learning Rate [0.00125]
12: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00095)	Tok/s 42096 (54087)	Loss/tok 3.0338 (3.3711)	Learning Rate [0.00125]
8: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00097)	Tok/s 41830 (53755)	Loss/tok 3.1083 (3.3795)	Learning Rate [0.00125]
13: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00098)	Tok/s 42094 (54183)	Loss/tok 3.0660 (3.3745)	Learning Rate [0.00125]
14: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00092)	Tok/s 42095 (54278)	Loss/tok 2.9624 (3.3769)	Learning Rate [0.00125]
7: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00097)	Tok/s 41830 (53673)	Loss/tok 3.2803 (3.3744)	Learning Rate [0.00125]
6: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00081 (0.00092)	Tok/s 41808 (53582)	Loss/tok 3.1259 (3.3762)	Learning Rate [0.00125]
15: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00092)	Tok/s 42786 (54389)	Loss/tok 3.1077 (3.3724)	Learning Rate [0.00125]
0: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00098)	Tok/s 42040 (53035)	Loss/tok 3.4247 (3.3770)	Learning Rate [0.00125]
5: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00092)	Tok/s 41824 (53509)	Loss/tok 3.0548 (3.3776)	Learning Rate [0.00125]
1: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00097)	Tok/s 41990 (53139)	Loss/tok 3.2707 (3.3791)	Learning Rate [0.00125]
4: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00100)	Tok/s 41834 (53426)	Loss/tok 3.0412 (3.3763)	Learning Rate [0.00125]
2: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00098)	Tok/s 41915 (53238)	Loss/tok 3.0588 (3.3813)	Learning Rate [0.00125]
3: TRAIN [1][2130/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00093)	Tok/s 41852 (53327)	Loss/tok 3.1808 (3.3744)	Learning Rate [0.00125]
1: TRAIN [1][2140/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 73632 (53137)	Loss/tok 3.4324 (3.3788)	Learning Rate [0.00125]
0: TRAIN [1][2140/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 73618 (53034)	Loss/tok 3.3965 (3.3765)	Learning Rate [0.00125]
15: TRAIN [1][2140/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00092)	Tok/s 75034 (54388)	Loss/tok 3.3075 (3.3718)	Learning Rate [0.00125]
13: TRAIN [1][2140/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00098)	Tok/s 74797 (54181)	Loss/tok 3.3420 (3.3740)	Learning Rate [0.00125]
14: TRAIN [1][2140/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 74649 (54276)	Loss/tok 3.3171 (3.3764)	Learning Rate [0.00125]
2: TRAIN [1][2140/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00098)	Tok/s 73490 (53236)	Loss/tok 3.3873 (3.3806)	Learning Rate [0.00125]
12: TRAIN [1][2140/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00095)	Tok/s 74761 (54086)	Loss/tok 3.5662 (3.3710)	Learning Rate [0.00125]
3: TRAIN [1][2140/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 73290 (53324)	Loss/tok 3.3436 (3.3740)	Learning Rate [0.00125]
11: TRAIN [1][2140/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 74720 (53978)	Loss/tok 3.4858 (3.3736)	Learning Rate [0.00125]
4: TRAIN [1][2140/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00100)	Tok/s 73367 (53423)	Loss/tok 3.3569 (3.3757)	Learning Rate [0.00125]
9: TRAIN [1][2140/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 74547 (53810)	Loss/tok 3.4868 (3.3660)	Learning Rate [0.00125]
10: TRAIN [1][2140/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 74694 (53893)	Loss/tok 3.5874 (3.3734)	Learning Rate [0.00125]
6: TRAIN [1][2140/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00092)	Tok/s 74311 (53580)	Loss/tok 3.3012 (3.3755)	Learning Rate [0.00125]
8: TRAIN [1][2140/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 74442 (53752)	Loss/tok 3.4930 (3.3793)	Learning Rate [0.00125]
5: TRAIN [1][2140/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 74020 (53506)	Loss/tok 3.4186 (3.3774)	Learning Rate [0.00125]
7: TRAIN [1][2140/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 74355 (53671)	Loss/tok 3.3376 (3.3740)	Learning Rate [0.00125]
1: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 36231 (53141)	Loss/tok 3.3997 (3.3785)	Learning Rate [0.00125]
0: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00098)	Tok/s 36176 (53038)	Loss/tok 3.2311 (3.3765)	Learning Rate [0.00125]
8: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00097)	Tok/s 37474 (53756)	Loss/tok 3.0333 (3.3787)	Learning Rate [0.00125]
14: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00092)	Tok/s 37486 (54279)	Loss/tok 2.9683 (3.3767)	Learning Rate [0.00125]
3: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00093)	Tok/s 36217 (53328)	Loss/tok 3.2315 (3.3739)	Learning Rate [0.00125]
15: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00107 (0.00092)	Tok/s 37484 (54390)	Loss/tok 3.2085 (3.3718)	Learning Rate [0.00125]
4: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00100)	Tok/s 37472 (53427)	Loss/tok 3.1348 (3.3755)	Learning Rate [0.00125]
13: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00109 (0.00098)	Tok/s 37450 (54184)	Loss/tok 3.0181 (3.3742)	Learning Rate [0.00125]
10: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00096)	Tok/s 37397 (53897)	Loss/tok 3.2419 (3.3737)	Learning Rate [0.00125]
11: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00092)	Tok/s 37343 (53982)	Loss/tok 3.3952 (3.3740)	Learning Rate [0.00125]
5: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00092)	Tok/s 37501 (53510)	Loss/tok 3.1757 (3.3777)	Learning Rate [0.00125]
7: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00097)	Tok/s 37450 (53674)	Loss/tok 2.9518 (3.3744)	Learning Rate [0.00125]
6: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00092)	Tok/s 37464 (53583)	Loss/tok 3.0870 (3.3758)	Learning Rate [0.00125]
12: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00095)	Tok/s 37401 (54089)	Loss/tok 3.2299 (3.3716)	Learning Rate [0.00125]
2: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00098)	Tok/s 36165 (53240)	Loss/tok 3.0147 (3.3804)	Learning Rate [0.00125]
9: TRAIN [1][2150/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00092)	Tok/s 37400 (53814)	Loss/tok 3.3798 (3.3658)	Learning Rate [0.00125]
6: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 69228 (53598)	Loss/tok 3.4727 (3.3757)	Learning Rate [0.00125]
5: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 69216 (53525)	Loss/tok 3.4254 (3.3775)	Learning Rate [0.00125]
7: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 69291 (53688)	Loss/tok 3.3713 (3.3744)	Learning Rate [0.00125]
4: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00122 (0.00100)	Tok/s 69134 (53442)	Loss/tok 3.5043 (3.3753)	Learning Rate [0.00125]
8: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 69323 (53769)	Loss/tok 3.5616 (3.3789)	Learning Rate [0.00125]
3: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 69132 (53343)	Loss/tok 3.4455 (3.3737)	Learning Rate [0.00125]
2: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00098)	Tok/s 68883 (53255)	Loss/tok 3.5086 (3.3804)	Learning Rate [0.00125]
11: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 69310 (53995)	Loss/tok 3.5962 (3.3740)	Learning Rate [0.00125]
0: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 68190 (53053)	Loss/tok 3.6165 (3.3766)	Learning Rate [0.00125]
10: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 69323 (53911)	Loss/tok 3.2397 (3.3737)	Learning Rate [0.00125]
15: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00092)	Tok/s 70032 (54403)	Loss/tok 3.4950 (3.3718)	Learning Rate [0.00125]
1: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00097)	Tok/s 68198 (53156)	Loss/tok 3.4274 (3.3784)	Learning Rate [0.00125]
12: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00095)	Tok/s 69130 (54103)	Loss/tok 3.2983 (3.3716)	Learning Rate [0.00125]
14: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 69533 (54293)	Loss/tok 3.2155 (3.3766)	Learning Rate [0.00125]
13: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00098)	Tok/s 69274 (54198)	Loss/tok 3.5792 (3.3748)	Learning Rate [0.00125]
9: TRAIN [1][2160/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00092)	Tok/s 69255 (53828)	Loss/tok 3.5623 (3.3663)	Learning Rate [0.00125]
5: TRAIN [1][2170/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00092)	Tok/s 54177 (53501)	Loss/tok 3.5794 (3.3777)	Learning Rate [0.00125]
3: TRAIN [1][2170/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00093)	Tok/s 54066 (53320)	Loss/tok 3.4275 (3.3735)	Learning Rate [0.00125]
4: TRAIN [1][2170/3416]	Time 0.060 (0.058)	Data 0.00110 (0.00100)	Tok/s 54189 (53418)	Loss/tok 3.6063 (3.3749)	Learning Rate [0.00125]
6: TRAIN [1][2170/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00092)	Tok/s 54084 (53574)	Loss/tok 3.3304 (3.3753)	Learning Rate [0.00125]
1: TRAIN [1][2170/3416]	Time 0.061 (0.058)	Data 0.00086 (0.00097)	Tok/s 53939 (53133)	Loss/tok 3.5341 (3.3783)	Learning Rate [0.00125]
2: TRAIN [1][2170/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00098)	Tok/s 53947 (53232)	Loss/tok 3.4589 (3.3803)	Learning Rate [0.00125]
7: TRAIN [1][2170/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00097)	Tok/s 54032 (53664)	Loss/tok 3.3756 (3.3738)	Learning Rate [0.00125]
8: TRAIN [1][2170/3416]	Time 0.061 (0.058)	Data 0.00086 (0.00096)	Tok/s 53921 (53745)	Loss/tok 3.3055 (3.3785)	Learning Rate [0.00125]
15: TRAIN [1][2170/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00092)	Tok/s 53707 (54378)	Loss/tok 3.3603 (3.3719)	Learning Rate [0.00125]
0: TRAIN [1][2170/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00099)	Tok/s 53742 (53030)	Loss/tok 3.8490 (3.3767)	Learning Rate [0.00125]
14: TRAIN [1][2170/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00092)	Tok/s 53582 (54268)	Loss/tok 3.3653 (3.3761)	Learning Rate [0.00125]
11: TRAIN [1][2170/3416]	Time 0.061 (0.058)	Data 0.00083 (0.00092)	Tok/s 53627 (53970)	Loss/tok 3.4285 (3.3738)	Learning Rate [0.00125]
13: TRAIN [1][2170/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00098)	Tok/s 53572 (54172)	Loss/tok 3.4782 (3.3743)	Learning Rate [0.00125]
12: TRAIN [1][2170/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00095)	Tok/s 53557 (54077)	Loss/tok 3.7300 (3.3714)	Learning Rate [0.00125]
10: TRAIN [1][2170/3416]	Time 0.061 (0.058)	Data 0.00081 (0.00096)	Tok/s 53566 (53886)	Loss/tok 3.4022 (3.3733)	Learning Rate [0.00125]
9: TRAIN [1][2170/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00092)	Tok/s 53801 (53803)	Loss/tok 3.5151 (3.3661)	Learning Rate [0.00125]
12: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00095)	Tok/s 53387 (54124)	Loss/tok 3.4707 (3.3716)	Learning Rate [0.00125]
11: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00081 (0.00092)	Tok/s 53354 (54016)	Loss/tok 3.4811 (3.3742)	Learning Rate [0.00125]
13: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00103 (0.00098)	Tok/s 53226 (54219)	Loss/tok 3.3042 (3.3746)	Learning Rate [0.00125]
14: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00092)	Tok/s 53167 (54314)	Loss/tok 3.4181 (3.3765)	Learning Rate [0.00125]
15: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00092)	Tok/s 53081 (54424)	Loss/tok 3.4200 (3.3722)	Learning Rate [0.00125]
8: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00096)	Tok/s 53337 (53792)	Loss/tok 3.6133 (3.3790)	Learning Rate [0.00125]
10: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00096)	Tok/s 53395 (53932)	Loss/tok 3.5630 (3.3738)	Learning Rate [0.00125]
0: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00099)	Tok/s 53028 (53078)	Loss/tok 3.3557 (3.3765)	Learning Rate [0.00125]
6: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00092)	Tok/s 53319 (53621)	Loss/tok 3.2643 (3.3757)	Learning Rate [0.00125]
7: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00097)	Tok/s 53319 (53710)	Loss/tok 3.5564 (3.3743)	Learning Rate [0.00125]
1: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00097)	Tok/s 53012 (53180)	Loss/tok 3.7993 (3.3791)	Learning Rate [0.00125]
5: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00092)	Tok/s 53182 (53547)	Loss/tok 3.4523 (3.3781)	Learning Rate [0.00125]
3: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00093)	Tok/s 53082 (53367)	Loss/tok 3.2399 (3.3736)	Learning Rate [0.00125]
2: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00098)	Tok/s 53036 (53279)	Loss/tok 3.4938 (3.3809)	Learning Rate [0.00125]
4: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00106 (0.00100)	Tok/s 53098 (53465)	Loss/tok 3.4675 (3.3756)	Learning Rate [0.00125]
9: TRAIN [1][2180/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00092)	Tok/s 53369 (53850)	Loss/tok 3.1710 (3.3669)	Learning Rate [0.00125]
1: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00097)	Tok/s 45602 (53150)	Loss/tok 3.3751 (3.3790)	Learning Rate [0.00125]
0: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00099)	Tok/s 45346 (53048)	Loss/tok 3.1298 (3.3760)	Learning Rate [0.00125]
2: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00098)	Tok/s 45628 (53249)	Loss/tok 2.9754 (3.3806)	Learning Rate [0.00125]
15: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00083 (0.00092)	Tok/s 45379 (54393)	Loss/tok 3.1744 (3.3717)	Learning Rate [0.00125]
3: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00093)	Tok/s 45642 (53336)	Loss/tok 3.1768 (3.3728)	Learning Rate [0.00125]
14: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00092)	Tok/s 45389 (54283)	Loss/tok 3.2147 (3.3760)	Learning Rate [0.00125]
4: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00110 (0.00100)	Tok/s 45665 (53436)	Loss/tok 3.1966 (3.3755)	Learning Rate [0.00125]
13: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00108 (0.00098)	Tok/s 45373 (54188)	Loss/tok 3.1963 (3.3744)	Learning Rate [0.00125]
11: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00079 (0.00092)	Tok/s 45481 (53985)	Loss/tok 3.1995 (3.3739)	Learning Rate [0.00125]
5: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00092)	Tok/s 45651 (53517)	Loss/tok 3.3147 (3.3780)	Learning Rate [0.00125]
12: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00095)	Tok/s 45448 (54092)	Loss/tok 3.3637 (3.3712)	Learning Rate [0.00125]
6: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00092)	Tok/s 45640 (53590)	Loss/tok 3.1223 (3.3755)	Learning Rate [0.00125]
7: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 45560 (53680)	Loss/tok 3.3110 (3.3740)	Learning Rate [0.00125]
8: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00096)	Tok/s 45405 (53761)	Loss/tok 3.1192 (3.3787)	Learning Rate [0.00125]
10: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00083 (0.00096)	Tok/s 45191 (53901)	Loss/tok 3.0450 (3.3734)	Learning Rate [0.00125]
9: TRAIN [1][2190/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00092)	Tok/s 45401 (53820)	Loss/tok 3.2213 (3.3666)	Learning Rate [0.00125]
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
8: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00096)	Tok/s 51541 (53739)	Loss/tok 3.1566 (3.3785)	Learning Rate [0.00125]
7: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00097)	Tok/s 51499 (53658)	Loss/tok 3.3595 (3.3739)	Learning Rate [0.00125]
9: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00092)	Tok/s 51489 (53798)	Loss/tok 3.0599 (3.3659)	Learning Rate [0.00125]
6: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00092)	Tok/s 51512 (53568)	Loss/tok 3.3359 (3.3753)	Learning Rate [0.00125]
0: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00099)	Tok/s 51275 (53021)	Loss/tok 3.2745 (3.3755)	Learning Rate [0.00125]
5: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00092)	Tok/s 51514 (53494)	Loss/tok 3.5007 (3.3781)	Learning Rate [0.00125]
1: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00097)	Tok/s 51290 (53124)	Loss/tok 3.0553 (3.3786)	Learning Rate [0.00125]
15: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00092)	Tok/s 51531 (54371)	Loss/tok 3.5806 (3.3719)	Learning Rate [0.00125]
11: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00092)	Tok/s 51443 (53963)	Loss/tok 3.3023 (3.3736)	Learning Rate [0.00125]
4: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00119 (0.00100)	Tok/s 51443 (53412)	Loss/tok 3.2114 (3.3755)	Learning Rate [0.00125]
10: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00096)	Tok/s 51435 (53879)	Loss/tok 3.2209 (3.3731)	Learning Rate [0.00125]
12: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00095)	Tok/s 51341 (54071)	Loss/tok 3.5514 (3.3710)	Learning Rate [0.00125]
3: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00093)	Tok/s 51355 (53312)	Loss/tok 3.4082 (3.3727)	Learning Rate [0.00125]
14: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00092)	Tok/s 51278 (54261)	Loss/tok 3.1847 (3.3758)	Learning Rate [0.00125]
2: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00098)	Tok/s 51298 (53224)	Loss/tok 3.4586 (3.3806)	Learning Rate [0.00125]
13: TRAIN [1][2200/3416]	Time 0.047 (0.058)	Data 0.00114 (0.00098)	Tok/s 51292 (54166)	Loss/tok 3.3543 (3.3742)	Learning Rate [0.00125]
15: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00092)	Tok/s 68996 (54397)	Loss/tok 3.4873 (3.3718)	Learning Rate [0.00125]
0: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00099)	Tok/s 68104 (53049)	Loss/tok 3.2937 (3.3750)	Learning Rate [0.00125]
14: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 68931 (54287)	Loss/tok 3.2960 (3.3757)	Learning Rate [0.00125]
1: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 68089 (53151)	Loss/tok 3.4119 (3.3785)	Learning Rate [0.00125]
13: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 68947 (54192)	Loss/tok 3.3035 (3.3738)	Learning Rate [0.00125]
12: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00095)	Tok/s 68953 (54097)	Loss/tok 3.3636 (3.3706)	Learning Rate [0.00125]
2: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 68096 (53250)	Loss/tok 3.5609 (3.3803)	Learning Rate [0.00125]
11: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00118 (0.00092)	Tok/s 68903 (53989)	Loss/tok 3.3952 (3.3736)	Learning Rate [0.00125]
3: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 68505 (53339)	Loss/tok 3.4042 (3.3726)	Learning Rate [0.00125]
4: TRAIN [1][2210/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00100)	Tok/s 69105 (53438)	Loss/tok 3.3223 (3.3750)	Learning Rate [0.00125]
9: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 68783 (53824)	Loss/tok 3.4797 (3.3660)	Learning Rate [0.00125]
8: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 68819 (53766)	Loss/tok 3.7320 (3.3786)	Learning Rate [0.00125]
10: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 68848 (53905)	Loss/tok 3.4011 (3.3728)	Learning Rate [0.00125]
5: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 68963 (53521)	Loss/tok 3.5933 (3.3780)	Learning Rate [0.00125]
6: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 68877 (53594)	Loss/tok 3.2568 (3.3751)	Learning Rate [0.00125]
7: TRAIN [1][2210/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 68838 (53685)	Loss/tok 3.4876 (3.3738)	Learning Rate [0.00125]
8: Gradient norm: inf
7: Gradient norm: inf
6: Gradient norm: inf
9: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
10: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
14: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
4: TRAIN [1][2220/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00100)	Tok/s 54015 (53432)	Loss/tok 3.4399 (3.3750)	Learning Rate [0.00125]
3: TRAIN [1][2220/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00093)	Tok/s 53987 (53333)	Loss/tok 3.2888 (3.3724)	Learning Rate [0.00125]
5: TRAIN [1][2220/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00092)	Tok/s 53896 (53514)	Loss/tok 3.3047 (3.3778)	Learning Rate [0.00125]
2: TRAIN [1][2220/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00098)	Tok/s 54016 (53244)	Loss/tok 3.2504 (3.3800)	Learning Rate [0.00125]
6: TRAIN [1][2220/3416]	Time 0.054 (0.058)	Data 0.00084 (0.00092)	Tok/s 53815 (53588)	Loss/tok 3.3516 (3.3753)	Learning Rate [0.00125]
1: TRAIN [1][2220/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00097)	Tok/s 54039 (53144)	Loss/tok 3.4108 (3.3783)	Learning Rate [0.00125]
7: TRAIN [1][2220/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00097)	Tok/s 53712 (53678)	Loss/tok 3.4248 (3.3736)	Learning Rate [0.00125]
0: TRAIN [1][2220/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00099)	Tok/s 54020 (53042)	Loss/tok 3.2715 (3.3748)	Learning Rate [0.00125]
8: TRAIN [1][2220/3416]	Time 0.054 (0.058)	Data 0.00084 (0.00096)	Tok/s 54036 (53760)	Loss/tok 3.4425 (3.3780)	Learning Rate [0.00125]
15: TRAIN [1][2220/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00092)	Tok/s 55164 (54391)	Loss/tok 3.0381 (3.3716)	Learning Rate [0.00125]
9: TRAIN [1][2220/3416]	Time 0.054 (0.058)	Data 0.00103 (0.00092)	Tok/s 54851 (53818)	Loss/tok 3.3171 (3.3658)	Learning Rate [0.00125]
14: TRAIN [1][2220/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00092)	Tok/s 55109 (54281)	Loss/tok 3.5341 (3.3755)	Learning Rate [0.00125]
11: TRAIN [1][2220/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00092)	Tok/s 54839 (53983)	Loss/tok 3.1910 (3.3732)	Learning Rate [0.00125]
13: TRAIN [1][2220/3416]	Time 0.054 (0.058)	Data 0.00106 (0.00098)	Tok/s 55002 (54186)	Loss/tok 3.3583 (3.3732)	Learning Rate [0.00125]
10: TRAIN [1][2220/3416]	Time 0.054 (0.058)	Data 0.00084 (0.00096)	Tok/s 54751 (53899)	Loss/tok 3.1176 (3.3725)	Learning Rate [0.00125]
12: TRAIN [1][2220/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00095)	Tok/s 54810 (54090)	Loss/tok 3.2999 (3.3702)	Learning Rate [0.00125]
7: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00097)	Tok/s 52041 (53640)	Loss/tok 3.2140 (3.3735)	Learning Rate [0.00125]
6: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00092)	Tok/s 52077 (53550)	Loss/tok 3.4692 (3.3751)	Learning Rate [0.00125]
8: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00096)	Tok/s 51894 (53722)	Loss/tok 3.3737 (3.3774)	Learning Rate [0.00125]
5: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00092)	Tok/s 52053 (53476)	Loss/tok 3.2380 (3.3772)	Learning Rate [0.00125]
9: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00092)	Tok/s 51901 (53780)	Loss/tok 3.7601 (3.3657)	Learning Rate [0.00125]
3: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00105 (0.00093)	Tok/s 52086 (53295)	Loss/tok 3.5613 (3.3720)	Learning Rate [0.00125]
11: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00092)	Tok/s 53049 (53944)	Loss/tok 3.4074 (3.3730)	Learning Rate [0.00125]
2: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00098)	Tok/s 52084 (53206)	Loss/tok 3.5466 (3.3797)	Learning Rate [0.00125]
10: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00096)	Tok/s 51914 (53860)	Loss/tok 3.1177 (3.3722)	Learning Rate [0.00125]
12: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00095)	Tok/s 53269 (54052)	Loss/tok 3.2254 (3.3699)	Learning Rate [0.00125]
4: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00111 (0.00100)	Tok/s 52081 (53394)	Loss/tok 3.3077 (3.3747)	Learning Rate [0.00125]
1: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00104 (0.00097)	Tok/s 52237 (53106)	Loss/tok 3.3898 (3.3782)	Learning Rate [0.00125]
13: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00117 (0.00098)	Tok/s 53203 (54147)	Loss/tok 3.0385 (3.3728)	Learning Rate [0.00125]
15: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00092)	Tok/s 53268 (54352)	Loss/tok 3.2582 (3.3712)	Learning Rate [0.00125]
14: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00092)	Tok/s 53243 (54242)	Loss/tok 3.3637 (3.3750)	Learning Rate [0.00125]
0: TRAIN [1][2230/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00099)	Tok/s 52089 (53004)	Loss/tok 3.3902 (3.3744)	Learning Rate [0.00125]
3: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 66633 (53315)	Loss/tok 3.5191 (3.3720)	Learning Rate [0.00125]
4: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00100)	Tok/s 66578 (53413)	Loss/tok 3.5060 (3.3747)	Learning Rate [0.00125]
2: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 66692 (53226)	Loss/tok 3.5242 (3.3798)	Learning Rate [0.00125]
1: TRAIN [1][2240/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 67357 (53126)	Loss/tok 3.9614 (3.3789)	Learning Rate [0.00125]
6: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 66558 (53570)	Loss/tok 3.4111 (3.3754)	Learning Rate [0.00125]
5: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 66524 (53495)	Loss/tok 3.6511 (3.3772)	Learning Rate [0.00125]
0: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00099)	Tok/s 66704 (53024)	Loss/tok 3.6845 (3.3748)	Learning Rate [0.00125]
15: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 67633 (54372)	Loss/tok 3.3150 (3.3711)	Learning Rate [0.00125]
14: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 67577 (54262)	Loss/tok 3.2932 (3.3748)	Learning Rate [0.00125]
7: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 66677 (53660)	Loss/tok 3.3355 (3.3733)	Learning Rate [0.00125]
8: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00096)	Tok/s 67499 (53742)	Loss/tok 3.5211 (3.3774)	Learning Rate [0.00125]
9: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 67441 (53800)	Loss/tok 3.2488 (3.3654)	Learning Rate [0.00125]
13: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00098)	Tok/s 67647 (54167)	Loss/tok 3.3898 (3.3729)	Learning Rate [0.00125]
11: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 67520 (53964)	Loss/tok 3.5339 (3.3731)	Learning Rate [0.00125]
12: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00095)	Tok/s 67573 (54071)	Loss/tok 3.5725 (3.3703)	Learning Rate [0.00125]
10: TRAIN [1][2240/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00096)	Tok/s 67449 (53881)	Loss/tok 3.5471 (3.3724)	Learning Rate [0.00125]
1: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00105 (0.00097)	Tok/s 54213 (53127)	Loss/tok 3.2449 (3.3789)	Learning Rate [0.00125]
0: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00127 (0.00099)	Tok/s 54190 (53025)	Loss/tok 3.3417 (3.3745)	Learning Rate [0.00125]
2: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00098)	Tok/s 54266 (53227)	Loss/tok 3.4381 (3.3797)	Learning Rate [0.00125]
15: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00092)	Tok/s 55211 (54373)	Loss/tok 3.1772 (3.3712)	Learning Rate [0.00125]
4: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00103 (0.00100)	Tok/s 54254 (53414)	Loss/tok 3.3658 (3.3747)	Learning Rate [0.00125]
14: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00092)	Tok/s 55245 (54263)	Loss/tok 3.6523 (3.3749)	Learning Rate [0.00125]
13: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00106 (0.00098)	Tok/s 55245 (54168)	Loss/tok 3.3317 (3.3728)	Learning Rate [0.00125]
3: TRAIN [1][2250/3416]	Time 0.062 (0.058)	Data 0.00104 (0.00093)	Tok/s 54283 (53316)	Loss/tok 3.0745 (3.3719)	Learning Rate [0.00125]
5: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00092)	Tok/s 54268 (53496)	Loss/tok 3.3388 (3.3772)	Learning Rate [0.00125]
6: TRAIN [1][2250/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00092)	Tok/s 54275 (53571)	Loss/tok 3.3496 (3.3751)	Learning Rate [0.00125]
12: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00095)	Tok/s 55238 (54073)	Loss/tok 3.5240 (3.3703)	Learning Rate [0.00125]
11: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00092)	Tok/s 55187 (53966)	Loss/tok 3.3144 (3.3732)	Learning Rate [0.00125]
7: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00097)	Tok/s 54263 (53661)	Loss/tok 3.4168 (3.3736)	Learning Rate [0.00125]
8: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00096)	Tok/s 55248 (53743)	Loss/tok 3.3421 (3.3775)	Learning Rate [0.00125]
9: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00092)	Tok/s 55220 (53801)	Loss/tok 3.3691 (3.3653)	Learning Rate [0.00125]
10: TRAIN [1][2250/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00096)	Tok/s 55114 (53882)	Loss/tok 3.4717 (3.3726)	Learning Rate [0.00125]
9: TRAIN [1][2260/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00092)	Tok/s 56129 (53802)	Loss/tok 3.2488 (3.3653)	Learning Rate [0.00125]
8: TRAIN [1][2260/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00096)	Tok/s 56160 (53744)	Loss/tok 3.2868 (3.3771)	Learning Rate [0.00125]
7: TRAIN [1][2260/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00097)	Tok/s 56169 (53663)	Loss/tok 3.2210 (3.3734)	Learning Rate [0.00125]
6: TRAIN [1][2260/3416]	Time 0.067 (0.058)	Data 0.00077 (0.00092)	Tok/s 56096 (53573)	Loss/tok 3.4846 (3.3750)	Learning Rate [0.00125]
10: TRAIN [1][2260/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00096)	Tok/s 56027 (53883)	Loss/tok 3.2190 (3.3725)	Learning Rate [0.00125]
11: TRAIN [1][2260/3416]	Time 0.068 (0.058)	Data 0.00079 (0.00092)	Tok/s 55912 (53967)	Loss/tok 3.2958 (3.3733)	Learning Rate [0.00125]
12: TRAIN [1][2260/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00095)	Tok/s 55854 (54073)	Loss/tok 3.6738 (3.3702)	Learning Rate [0.00125]
5: TRAIN [1][2260/3416]	Time 0.067 (0.058)	Data 0.00081 (0.00092)	Tok/s 56061 (53498)	Loss/tok 3.3977 (3.3769)	Learning Rate [0.00125]
4: TRAIN [1][2260/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00100)	Tok/s 56111 (53415)	Loss/tok 3.2083 (3.3743)	Learning Rate [0.00125]
13: TRAIN [1][2260/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00098)	Tok/s 55735 (54168)	Loss/tok 3.2360 (3.3723)	Learning Rate [0.00125]
14: TRAIN [1][2260/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00092)	Tok/s 55649 (54264)	Loss/tok 3.4819 (3.3745)	Learning Rate [0.00125]
3: TRAIN [1][2260/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00093)	Tok/s 55916 (53318)	Loss/tok 3.6184 (3.3717)	Learning Rate [0.00125]
2: TRAIN [1][2260/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00098)	Tok/s 55794 (53229)	Loss/tok 3.4358 (3.3797)	Learning Rate [0.00125]
15: TRAIN [1][2260/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 55656 (54373)	Loss/tok 3.3958 (3.3705)	Learning Rate [0.00125]
1: TRAIN [1][2260/3416]	Time 0.068 (0.058)	Data 0.00108 (0.00097)	Tok/s 55687 (53130)	Loss/tok 3.3913 (3.3788)	Learning Rate [0.00125]
0: TRAIN [1][2260/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00099)	Tok/s 55642 (53028)	Loss/tok 3.1898 (3.3743)	Learning Rate [0.00125]
1: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00105 (0.00097)	Tok/s 51387 (53114)	Loss/tok 3.1081 (3.3787)	Learning Rate [0.00125]
0: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00099)	Tok/s 51318 (53011)	Loss/tok 3.5856 (3.3741)	Learning Rate [0.00125]
2: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00098)	Tok/s 51362 (53214)	Loss/tok 3.1984 (3.3795)	Learning Rate [0.00125]
15: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00092)	Tok/s 52421 (54363)	Loss/tok 3.4594 (3.3704)	Learning Rate [0.00125]
3: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00093)	Tok/s 51675 (53303)	Loss/tok 3.4551 (3.3714)	Learning Rate [0.00125]
4: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00104 (0.00100)	Tok/s 52485 (53402)	Loss/tok 3.4488 (3.3739)	Learning Rate [0.00125]
14: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00092)	Tok/s 52421 (54253)	Loss/tok 3.3823 (3.3746)	Learning Rate [0.00125]
13: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00098)	Tok/s 52444 (54157)	Loss/tok 3.4374 (3.3723)	Learning Rate [0.00125]
5: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00084 (0.00092)	Tok/s 52462 (53485)	Loss/tok 3.2306 (3.3765)	Learning Rate [0.00125]
6: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00092)	Tok/s 52443 (53560)	Loss/tok 3.2977 (3.3748)	Learning Rate [0.00125]
9: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00092)	Tok/s 52495 (53791)	Loss/tok 3.1897 (3.3652)	Learning Rate [0.00125]
11: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00091)	Tok/s 52389 (53955)	Loss/tok 3.3788 (3.3730)	Learning Rate [0.00125]
12: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00095)	Tok/s 52343 (54062)	Loss/tok 3.0917 (3.3699)	Learning Rate [0.00125]
8: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00096)	Tok/s 52462 (53733)	Loss/tok 3.2191 (3.3764)	Learning Rate [0.00125]
7: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00084 (0.00097)	Tok/s 52468 (53651)	Loss/tok 3.2915 (3.3732)	Learning Rate [0.00125]
10: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00083 (0.00096)	Tok/s 52336 (53871)	Loss/tok 3.4386 (3.3722)	Learning Rate [0.00125]
6: TRAIN [1][2280/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00092)	Tok/s 31639 (53547)	Loss/tok 2.9307 (3.3747)	Learning Rate [0.00125]
5: TRAIN [1][2280/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 31612 (53472)	Loss/tok 3.0236 (3.3765)	Learning Rate [0.00125]
8: TRAIN [1][2280/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00096)	Tok/s 31716 (53720)	Loss/tok 3.1061 (3.3765)	Learning Rate [0.00125]
9: TRAIN [1][2280/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 31923 (53777)	Loss/tok 3.0670 (3.3651)	Learning Rate [0.00125]
7: TRAIN [1][2280/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00097)	Tok/s 31683 (53638)	Loss/tok 3.0406 (3.3729)	Learning Rate [0.00125]
4: TRAIN [1][2280/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00100)	Tok/s 31562 (53389)	Loss/tok 3.0786 (3.3740)	Learning Rate [0.00125]
11: TRAIN [1][2280/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00091)	Tok/s 32939 (53942)	Loss/tok 3.2602 (3.3730)	Learning Rate [0.00125]
3: TRAIN [1][2280/3416]	Time 0.051 (0.058)	Data 0.00117 (0.00093)	Tok/s 31594 (53291)	Loss/tok 3.0891 (3.3718)	Learning Rate [0.00125]
2: TRAIN [1][2280/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00098)	Tok/s 31624 (53202)	Loss/tok 2.9230 (3.3799)	Learning Rate [0.00125]
12: TRAIN [1][2280/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00095)	Tok/s 32902 (54049)	Loss/tok 3.0202 (3.3701)	Learning Rate [0.00125]
13: TRAIN [1][2280/3416]	Time 0.050 (0.058)	Data 0.00117 (0.00098)	Tok/s 32955 (54144)	Loss/tok 2.9635 (3.3722)	Learning Rate [0.00125]
0: TRAIN [1][2280/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00099)	Tok/s 31610 (52999)	Loss/tok 3.1532 (3.3741)	Learning Rate [0.00125]
15: TRAIN [1][2280/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 32867 (54349)	Loss/tok 3.0643 (3.3703)	Learning Rate [0.00125]
14: TRAIN [1][2280/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00092)	Tok/s 32889 (54240)	Loss/tok 2.9135 (3.3746)	Learning Rate [0.00125]
10: TRAIN [1][2280/3416]	Time 0.051 (0.058)	Data 0.00122 (0.00096)	Tok/s 32926 (53857)	Loss/tok 3.0699 (3.3718)	Learning Rate [0.00125]
1: TRAIN [1][2280/3416]	Time 0.051 (0.058)	Data 0.00125 (0.00097)	Tok/s 31624 (53102)	Loss/tok 2.9882 (3.3787)	Learning Rate [0.00125]
4: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00100)	Tok/s 29205 (53349)	Loss/tok 2.8175 (3.3737)	Learning Rate [0.00125]
5: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00092)	Tok/s 29182 (53432)	Loss/tok 2.6868 (3.3761)	Learning Rate [0.00125]
6: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00092)	Tok/s 29102 (53507)	Loss/tok 2.7086 (3.3743)	Learning Rate [0.00125]
3: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00094)	Tok/s 29196 (53251)	Loss/tok 2.6408 (3.3714)	Learning Rate [0.00125]
1: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00105 (0.00097)	Tok/s 29250 (53062)	Loss/tok 2.6624 (3.3783)	Learning Rate [0.00125]
8: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00096)	Tok/s 29860 (53679)	Loss/tok 2.6617 (3.3761)	Learning Rate [0.00125]
9: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00092)	Tok/s 30596 (53737)	Loss/tok 2.6362 (3.3647)	Learning Rate [0.00125]
2: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00098)	Tok/s 29197 (53162)	Loss/tok 2.8332 (3.3793)	Learning Rate [0.00125]
7: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00097)	Tok/s 29006 (53597)	Loss/tok 2.8102 (3.3727)	Learning Rate [0.00125]
10: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00096)	Tok/s 30666 (53817)	Loss/tok 2.7812 (3.3715)	Learning Rate [0.00125]
0: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00084 (0.00099)	Tok/s 29218 (52959)	Loss/tok 2.9981 (3.3739)	Learning Rate [0.00125]
11: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00091)	Tok/s 30565 (53901)	Loss/tok 2.5884 (3.3727)	Learning Rate [0.00125]
15: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00092)	Tok/s 30631 (54309)	Loss/tok 2.7445 (3.3702)	Learning Rate [0.00125]
12: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00095)	Tok/s 30562 (54008)	Loss/tok 2.6692 (3.3697)	Learning Rate [0.00125]
14: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00081 (0.00092)	Tok/s 30630 (54199)	Loss/tok 2.6252 (3.3743)	Learning Rate [0.00125]
13: TRAIN [1][2290/3416]	Time 0.044 (0.058)	Data 0.00085 (0.00098)	Tok/s 30609 (54103)	Loss/tok 2.4890 (3.3721)	Learning Rate [0.00125]
13: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00098)	Tok/s 56664 (54122)	Loss/tok 3.4477 (3.3722)	Learning Rate [0.00125]
12: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00095)	Tok/s 56702 (54027)	Loss/tok 3.4382 (3.3698)	Learning Rate [0.00125]
14: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 56572 (54218)	Loss/tok 3.5436 (3.3742)	Learning Rate [0.00125]
10: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00096)	Tok/s 56665 (53837)	Loss/tok 3.3295 (3.3714)	Learning Rate [0.00125]
0: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00099)	Tok/s 55466 (52980)	Loss/tok 3.6286 (3.3741)	Learning Rate [0.00125]
11: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00091)	Tok/s 56634 (53921)	Loss/tok 3.4592 (3.3726)	Learning Rate [0.00125]
1: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00097)	Tok/s 55409 (53082)	Loss/tok 3.2881 (3.3784)	Learning Rate [0.00125]
8: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00096)	Tok/s 56489 (53699)	Loss/tok 3.1871 (3.3762)	Learning Rate [0.00125]
9: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00092)	Tok/s 56565 (53757)	Loss/tok 3.2862 (3.3646)	Learning Rate [0.00125]
2: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00098)	Tok/s 55403 (53182)	Loss/tok 3.5342 (3.3793)	Learning Rate [0.00125]
7: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00097)	Tok/s 56413 (53617)	Loss/tok 3.4595 (3.3725)	Learning Rate [0.00125]
15: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00092)	Tok/s 56480 (54327)	Loss/tok 3.4738 (3.3706)	Learning Rate [0.00125]
6: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 56257 (53527)	Loss/tok 3.5054 (3.3741)	Learning Rate [0.00125]
3: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00094)	Tok/s 55389 (53271)	Loss/tok 3.3257 (3.3714)	Learning Rate [0.00125]
4: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00100)	Tok/s 56084 (53369)	Loss/tok 3.6416 (3.3744)	Learning Rate [0.00125]
5: TRAIN [1][2300/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00092)	Tok/s 56309 (53451)	Loss/tok 3.4960 (3.3759)	Learning Rate [0.00125]
6: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 77396 (53528)	Loss/tok 3.5739 (3.3742)	Learning Rate [0.00125]
5: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00092)	Tok/s 77298 (53453)	Loss/tok 3.4073 (3.3758)	Learning Rate [0.00125]
1: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 76914 (53085)	Loss/tok 3.3374 (3.3784)	Learning Rate [0.00125]
4: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 77189 (53371)	Loss/tok 3.4978 (3.3745)	Learning Rate [0.00125]
7: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 77332 (53618)	Loss/tok 3.3118 (3.3726)	Learning Rate [0.00125]
0: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00099)	Tok/s 76161 (52982)	Loss/tok 3.2755 (3.3738)	Learning Rate [0.00125]
12: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00095)	Tok/s 78310 (54028)	Loss/tok 3.5521 (3.3695)	Learning Rate [0.00125]
8: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 77326 (53700)	Loss/tok 3.2898 (3.3760)	Learning Rate [0.00125]
13: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00098)	Tok/s 78137 (54123)	Loss/tok 3.4265 (3.3721)	Learning Rate [0.00125]
11: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00091)	Tok/s 78245 (53921)	Loss/tok 3.4579 (3.3722)	Learning Rate [0.00125]
10: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 78200 (53838)	Loss/tok 3.2022 (3.3713)	Learning Rate [0.00125]
3: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00094)	Tok/s 77033 (53273)	Loss/tok 3.2613 (3.3711)	Learning Rate [0.00125]
15: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 77968 (54329)	Loss/tok 3.3585 (3.3704)	Learning Rate [0.00125]
14: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00092)	Tok/s 78014 (54220)	Loss/tok 3.3475 (3.3741)	Learning Rate [0.00125]
2: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00098)	Tok/s 76957 (53185)	Loss/tok 3.4420 (3.3792)	Learning Rate [0.00125]
9: TRAIN [1][2310/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 77273 (53758)	Loss/tok 3.2179 (3.3645)	Learning Rate [0.00125]
12: TRAIN [1][2320/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00095)	Tok/s 48640 (54025)	Loss/tok 3.1324 (3.3697)	Learning Rate [0.00125]
13: TRAIN [1][2320/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00098)	Tok/s 48650 (54120)	Loss/tok 3.5061 (3.3721)	Learning Rate [0.00125]
11: TRAIN [1][2320/3416]	Time 0.048 (0.058)	Data 0.00077 (0.00091)	Tok/s 48480 (53919)	Loss/tok 3.2785 (3.3726)	Learning Rate [0.00125]
10: TRAIN [1][2320/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00096)	Tok/s 48469 (53836)	Loss/tok 3.1489 (3.3713)	Learning Rate [0.00125]
14: TRAIN [1][2320/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00092)	Tok/s 48587 (54217)	Loss/tok 3.3181 (3.3740)	Learning Rate [0.00125]
9: TRAIN [1][2320/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00092)	Tok/s 48476 (53756)	Loss/tok 3.2700 (3.3647)	Learning Rate [0.00125]
15: TRAIN [1][2320/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00092)	Tok/s 48576 (54325)	Loss/tok 3.4549 (3.3705)	Learning Rate [0.00125]
8: TRAIN [1][2320/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00096)	Tok/s 48444 (53698)	Loss/tok 3.4132 (3.3765)	Learning Rate [0.00125]
7: TRAIN [1][2320/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00097)	Tok/s 48527 (53616)	Loss/tok 3.3008 (3.3725)	Learning Rate [0.00125]
0: TRAIN [1][2320/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00099)	Tok/s 47232 (52980)	Loss/tok 3.2497 (3.3737)	Learning Rate [0.00125]
1: TRAIN [1][2320/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 48651 (53083)	Loss/tok 3.3147 (3.3786)	Learning Rate [0.00125]
6: TRAIN [1][2320/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00092)	Tok/s 48443 (53526)	Loss/tok 3.1817 (3.3739)	Learning Rate [0.00125]
2: TRAIN [1][2320/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00098)	Tok/s 48545 (53183)	Loss/tok 3.3355 (3.3790)	Learning Rate [0.00125]
4: TRAIN [1][2320/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00100)	Tok/s 48479 (53369)	Loss/tok 3.1522 (3.3743)	Learning Rate [0.00125]
5: TRAIN [1][2320/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00092)	Tok/s 48455 (53450)	Loss/tok 3.4546 (3.3757)	Learning Rate [0.00125]
3: TRAIN [1][2320/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00094)	Tok/s 48498 (53271)	Loss/tok 3.1031 (3.3712)	Learning Rate [0.00125]
1: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00114 (0.00097)	Tok/s 33662 (53110)	Loss/tok 3.0186 (3.3784)	Learning Rate [0.00125]
2: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00098)	Tok/s 33701 (53210)	Loss/tok 2.9915 (3.3790)	Learning Rate [0.00125]
0: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00099)	Tok/s 33589 (53008)	Loss/tok 3.1909 (3.3735)	Learning Rate [0.00125]
3: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00094)	Tok/s 33719 (53298)	Loss/tok 3.1037 (3.3711)	Learning Rate [0.00125]
4: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00100)	Tok/s 33748 (53396)	Loss/tok 2.9097 (3.3738)	Learning Rate [0.00125]
15: TRAIN [1][2330/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 34791 (54354)	Loss/tok 3.0918 (3.3701)	Learning Rate [0.00125]
11: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00091)	Tok/s 33649 (53947)	Loss/tok 3.1560 (3.3719)	Learning Rate [0.00125]
12: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00095)	Tok/s 33639 (54053)	Loss/tok 3.1883 (3.3697)	Learning Rate [0.00125]
13: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00098)	Tok/s 34005 (54149)	Loss/tok 2.9541 (3.3714)	Learning Rate [0.00125]
14: TRAIN [1][2330/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 34781 (54246)	Loss/tok 2.9330 (3.3741)	Learning Rate [0.00125]
10: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00096)	Tok/s 33655 (53864)	Loss/tok 3.0014 (3.3706)	Learning Rate [0.00125]
5: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00092)	Tok/s 33695 (53477)	Loss/tok 3.2380 (3.3754)	Learning Rate [0.00125]
6: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00092)	Tok/s 33679 (53552)	Loss/tok 3.0389 (3.3734)	Learning Rate [0.00125]
9: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00092)	Tok/s 33656 (53783)	Loss/tok 3.0431 (3.3645)	Learning Rate [0.00125]
8: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00096)	Tok/s 33652 (53724)	Loss/tok 3.2466 (3.3764)	Learning Rate [0.00125]
7: TRAIN [1][2330/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00097)	Tok/s 33671 (53642)	Loss/tok 3.1769 (3.3719)	Learning Rate [0.00125]
15: TRAIN [1][2340/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 61962 (54385)	Loss/tok 3.3816 (3.3702)	Learning Rate [0.00125]
14: TRAIN [1][2340/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 61119 (54277)	Loss/tok 3.2580 (3.3739)	Learning Rate [0.00125]
0: TRAIN [1][2340/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00099)	Tok/s 61041 (53038)	Loss/tok 3.3939 (3.3738)	Learning Rate [0.00125]
13: TRAIN [1][2340/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00098)	Tok/s 60906 (54179)	Loss/tok 3.6615 (3.3709)	Learning Rate [0.00125]
1: TRAIN [1][2340/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00097)	Tok/s 60968 (53140)	Loss/tok 3.3969 (3.3781)	Learning Rate [0.00125]
11: TRAIN [1][2340/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00091)	Tok/s 60884 (53978)	Loss/tok 3.7204 (3.3720)	Learning Rate [0.00125]
2: TRAIN [1][2340/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00098)	Tok/s 60872 (53240)	Loss/tok 3.5312 (3.3786)	Learning Rate [0.00125]
12: TRAIN [1][2340/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00095)	Tok/s 60887 (54084)	Loss/tok 3.5805 (3.3693)	Learning Rate [0.00125]
3: TRAIN [1][2340/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00094)	Tok/s 60861 (53328)	Loss/tok 3.3435 (3.3710)	Learning Rate [0.00125]
4: TRAIN [1][2340/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00100)	Tok/s 60771 (53427)	Loss/tok 3.5387 (3.3737)	Learning Rate [0.00125]
10: TRAIN [1][2340/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 60721 (53895)	Loss/tok 3.4438 (3.3711)	Learning Rate [0.00125]
9: TRAIN [1][2340/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 60688 (53814)	Loss/tok 3.3582 (3.3643)	Learning Rate [0.00125]
5: TRAIN [1][2340/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 60685 (53508)	Loss/tok 3.4056 (3.3752)	Learning Rate [0.00125]
6: TRAIN [1][2340/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 60507 (53583)	Loss/tok 3.4853 (3.3730)	Learning Rate [0.00125]
8: TRAIN [1][2340/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 60539 (53755)	Loss/tok 3.4288 (3.3762)	Learning Rate [0.00125]
7: TRAIN [1][2340/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00097)	Tok/s 60485 (53673)	Loss/tok 3.6847 (3.3720)	Learning Rate [0.00125]
6: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
0: TRAIN [1][2350/3416]	Time 0.069 (0.058)	Data 0.00117 (0.00099)	Tok/s 58325 (53021)	Loss/tok 3.3949 (3.3733)	Learning Rate [0.00125]
1: TRAIN [1][2350/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00097)	Tok/s 58311 (53124)	Loss/tok 3.7539 (3.3778)	Learning Rate [0.00125]
2: TRAIN [1][2350/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00098)	Tok/s 58314 (53223)	Loss/tok 3.9311 (3.3787)	Learning Rate [0.00125]
15: TRAIN [1][2350/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 59131 (54369)	Loss/tok 3.7809 (3.3705)	Learning Rate [0.00125]
14: TRAIN [1][2350/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 59064 (54260)	Loss/tok 3.4904 (3.3736)	Learning Rate [0.00125]
13: TRAIN [1][2350/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00098)	Tok/s 58339 (54163)	Loss/tok 3.7139 (3.3707)	Learning Rate [0.00125]
3: TRAIN [1][2350/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00094)	Tok/s 58308 (53312)	Loss/tok 3.6957 (3.3708)	Learning Rate [0.00125]
4: TRAIN [1][2350/3416]	Time 0.069 (0.058)	Data 0.00128 (0.00100)	Tok/s 58285 (53410)	Loss/tok 3.4677 (3.3738)	Learning Rate [0.00125]
6: TRAIN [1][2350/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 58183 (53565)	Loss/tok 3.5486 (3.3725)	Learning Rate [0.00125]
12: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00095)	Tok/s 57926 (54066)	Loss/tok 3.6897 (3.3690)	Learning Rate [0.00125]
11: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00091)	Tok/s 57883 (53960)	Loss/tok 3.4207 (3.3718)	Learning Rate [0.00125]
5: TRAIN [1][2350/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 58190 (53490)	Loss/tok 3.2699 (3.3746)	Learning Rate [0.00125]
10: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00096)	Tok/s 57931 (53877)	Loss/tok 3.6520 (3.3708)	Learning Rate [0.00125]
8: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00096)	Tok/s 57988 (53738)	Loss/tok 3.7977 (3.3761)	Learning Rate [0.00125]
9: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 57947 (53796)	Loss/tok 3.5607 (3.3642)	Learning Rate [0.00125]
7: TRAIN [1][2350/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 58032 (53655)	Loss/tok 3.4952 (3.3718)	Learning Rate [0.00125]
8: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00096)	Tok/s 50470 (53740)	Loss/tok 3.1888 (3.3762)	Learning Rate [0.00125]
9: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00092)	Tok/s 50500 (53798)	Loss/tok 2.8668 (3.3641)	Learning Rate [0.00125]
7: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00097)	Tok/s 50336 (53657)	Loss/tok 2.9717 (3.3716)	Learning Rate [0.00125]
6: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00092)	Tok/s 50252 (53567)	Loss/tok 3.3171 (3.3725)	Learning Rate [0.00125]
10: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00096)	Tok/s 50423 (53879)	Loss/tok 3.2705 (3.3706)	Learning Rate [0.00125]
5: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00092)	Tok/s 50067 (53492)	Loss/tok 3.1572 (3.3744)	Learning Rate [0.00125]
11: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00091)	Tok/s 50280 (53962)	Loss/tok 3.1327 (3.3716)	Learning Rate [0.00125]
4: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00100)	Tok/s 49936 (53412)	Loss/tok 3.3258 (3.3739)	Learning Rate [0.00125]
12: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00096)	Tok/s 50213 (54068)	Loss/tok 3.1114 (3.3688)	Learning Rate [0.00125]
3: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00094)	Tok/s 49866 (53314)	Loss/tok 3.1082 (3.3709)	Learning Rate [0.00125]
13: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00098)	Tok/s 50063 (54163)	Loss/tok 3.1627 (3.3707)	Learning Rate [0.00125]
2: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00098)	Tok/s 49737 (53226)	Loss/tok 3.1825 (3.3788)	Learning Rate [0.00125]
14: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00092)	Tok/s 49902 (54261)	Loss/tok 3.1333 (3.3732)	Learning Rate [0.00125]
0: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00111 (0.00099)	Tok/s 49749 (53024)	Loss/tok 3.5045 (3.3734)	Learning Rate [0.00125]
1: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00097)	Tok/s 49684 (53127)	Loss/tok 3.2213 (3.3780)	Learning Rate [0.00125]
15: TRAIN [1][2360/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00092)	Tok/s 49784 (54370)	Loss/tok 3.0347 (3.3705)	Learning Rate [0.00125]
4: Gradient norm: inf
5: Gradient norm: inf
3: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
1: Gradient norm: inf
8: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
9: Gradient norm: inf
10: Gradient norm: inf
14: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
6: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00081 (0.00092)	Tok/s 50540 (53565)	Loss/tok 3.3915 (3.3720)	Learning Rate [0.00125]
5: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00083 (0.00092)	Tok/s 50446 (53490)	Loss/tok 3.3136 (3.3739)	Learning Rate [0.00125]
7: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00097)	Tok/s 50582 (53656)	Loss/tok 3.4155 (3.3711)	Learning Rate [0.00125]
4: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00100)	Tok/s 50417 (53409)	Loss/tok 3.3353 (3.3735)	Learning Rate [0.00125]
8: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00081 (0.00096)	Tok/s 50576 (53738)	Loss/tok 3.2237 (3.3756)	Learning Rate [0.00125]
9: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00079 (0.00092)	Tok/s 50634 (53797)	Loss/tok 3.3665 (3.3636)	Learning Rate [0.00125]
3: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00080 (0.00094)	Tok/s 50428 (53311)	Loss/tok 3.4623 (3.3708)	Learning Rate [0.00125]
2: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00098)	Tok/s 50447 (53221)	Loss/tok 3.4029 (3.3784)	Learning Rate [0.00125]
1: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00097)	Tok/s 50509 (53122)	Loss/tok 3.2643 (3.3779)	Learning Rate [0.00125]
10: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00096)	Tok/s 50570 (53879)	Loss/tok 3.3095 (3.3701)	Learning Rate [0.00125]
0: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00110 (0.00099)	Tok/s 50458 (53018)	Loss/tok 3.3284 (3.3728)	Learning Rate [0.00125]
12: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00096)	Tok/s 51465 (54068)	Loss/tok 3.2903 (3.3684)	Learning Rate [0.00125]
11: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00078 (0.00091)	Tok/s 50494 (53961)	Loss/tok 3.2521 (3.3711)	Learning Rate [0.00125]
15: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00081 (0.00092)	Tok/s 51594 (54371)	Loss/tok 3.1474 (3.3702)	Learning Rate [0.00125]
13: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00082 (0.00098)	Tok/s 51650 (54164)	Loss/tok 3.4055 (3.3704)	Learning Rate [0.00125]
14: TRAIN [1][2370/3416]	Time 0.056 (0.058)	Data 0.00081 (0.00092)	Tok/s 51621 (54262)	Loss/tok 3.4732 (3.3729)	Learning Rate [0.00125]
6: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00078 (0.00092)	Tok/s 52399 (53584)	Loss/tok 3.3402 (3.3720)	Learning Rate [0.00125]
5: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 52421 (53509)	Loss/tok 3.3792 (3.3741)	Learning Rate [0.00125]
4: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00100)	Tok/s 52428 (53428)	Loss/tok 3.2773 (3.3732)	Learning Rate [0.00125]
7: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00097)	Tok/s 52243 (53674)	Loss/tok 3.1533 (3.3712)	Learning Rate [0.00125]
8: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00096)	Tok/s 52265 (53757)	Loss/tok 3.6888 (3.3760)	Learning Rate [0.00125]
3: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00094)	Tok/s 51521 (53329)	Loss/tok 3.1129 (3.3706)	Learning Rate [0.00125]
9: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 52310 (53816)	Loss/tok 3.4403 (3.3636)	Learning Rate [0.00125]
2: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00098)	Tok/s 51170 (53240)	Loss/tok 3.2361 (3.3785)	Learning Rate [0.00125]
1: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00097)	Tok/s 51126 (53141)	Loss/tok 3.3174 (3.3780)	Learning Rate [0.00125]
10: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00096)	Tok/s 52239 (53897)	Loss/tok 3.1055 (3.3700)	Learning Rate [0.00125]
11: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00091)	Tok/s 52275 (53979)	Loss/tok 3.3853 (3.3708)	Learning Rate [0.00125]
0: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00099)	Tok/s 51165 (53037)	Loss/tok 3.2188 (3.3731)	Learning Rate [0.00125]
12: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00096)	Tok/s 52341 (54086)	Loss/tok 3.3324 (3.3683)	Learning Rate [0.00125]
13: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00098)	Tok/s 52340 (54182)	Loss/tok 3.4048 (3.3703)	Learning Rate [0.00125]
15: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00081 (0.00092)	Tok/s 52343 (54389)	Loss/tok 3.2264 (3.3707)	Learning Rate [0.00125]
14: TRAIN [1][2380/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00092)	Tok/s 52342 (54279)	Loss/tok 3.1890 (3.3728)	Learning Rate [0.00125]
1: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 59334 (53131)	Loss/tok 3.5771 (3.3779)	Learning Rate [0.00125]
0: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00099)	Tok/s 59376 (53026)	Loss/tok 3.4829 (3.3729)	Learning Rate [0.00125]
2: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00098)	Tok/s 59256 (53230)	Loss/tok 3.5263 (3.3783)	Learning Rate [0.00125]
15: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 59354 (54376)	Loss/tok 3.2829 (3.3703)	Learning Rate [0.00125]
4: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 59255 (53416)	Loss/tok 3.4431 (3.3729)	Learning Rate [0.00125]
3: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00094)	Tok/s 59213 (53318)	Loss/tok 3.3544 (3.3702)	Learning Rate [0.00125]
14: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 59357 (54267)	Loss/tok 3.4001 (3.3725)	Learning Rate [0.00125]
9: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 59452 (53804)	Loss/tok 3.3647 (3.3637)	Learning Rate [0.00125]
13: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 59352 (54170)	Loss/tok 3.2242 (3.3701)	Learning Rate [0.00125]
8: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 59390 (53745)	Loss/tok 3.4136 (3.3758)	Learning Rate [0.00125]
6: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 59244 (53572)	Loss/tok 3.5948 (3.3718)	Learning Rate [0.00125]
10: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00096)	Tok/s 59424 (53885)	Loss/tok 3.6392 (3.3700)	Learning Rate [0.00125]
5: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 59227 (53497)	Loss/tok 3.3527 (3.3741)	Learning Rate [0.00125]
12: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 59330 (54074)	Loss/tok 3.5479 (3.3682)	Learning Rate [0.00125]
11: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 59341 (53967)	Loss/tok 3.4567 (3.3705)	Learning Rate [0.00125]
7: TRAIN [1][2390/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00097)	Tok/s 59273 (53662)	Loss/tok 3.3338 (3.3709)	Learning Rate [0.00125]
1: TRAIN [1][2400/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00097)	Tok/s 41950 (53117)	Loss/tok 3.0586 (3.3775)	Learning Rate [0.00125]
0: TRAIN [1][2400/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00099)	Tok/s 42033 (53013)	Loss/tok 3.2404 (3.3727)	Learning Rate [0.00125]
2: TRAIN [1][2400/3416]	Time 0.047 (0.058)	Data 0.00082 (0.00098)	Tok/s 41904 (53216)	Loss/tok 2.9892 (3.3782)	Learning Rate [0.00125]
15: TRAIN [1][2400/3416]	Time 0.047 (0.058)	Data 0.00077 (0.00091)	Tok/s 42619 (54363)	Loss/tok 3.5412 (3.3698)	Learning Rate [0.00125]
8: TRAIN [1][2400/3416]	Time 0.047 (0.058)	Data 0.00080 (0.00096)	Tok/s 41850 (53732)	Loss/tok 2.9961 (3.3753)	Learning Rate [0.00125]
4: TRAIN [1][2400/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00100)	Tok/s 41706 (53403)	Loss/tok 3.2767 (3.3727)	Learning Rate [0.00125]
3: TRAIN [1][2400/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00094)	Tok/s 41728 (53305)	Loss/tok 3.0350 (3.3702)	Learning Rate [0.00125]
7: TRAIN [1][2400/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00097)	Tok/s 41757 (53649)	Loss/tok 3.0457 (3.3710)	Learning Rate [0.00125]
14: TRAIN [1][2400/3416]	Time 0.047 (0.058)	Data 0.00078 (0.00092)	Tok/s 41949 (54254)	Loss/tok 2.9912 (3.3722)	Learning Rate [0.00125]
9: TRAIN [1][2400/3416]	Time 0.048 (0.058)	Data 0.00081 (0.00092)	Tok/s 41767 (53791)	Loss/tok 3.2156 (3.3635)	Learning Rate [0.00125]
13: TRAIN [1][2400/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00098)	Tok/s 41993 (54156)	Loss/tok 2.8906 (3.3698)	Learning Rate [0.00125]
6: TRAIN [1][2400/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00092)	Tok/s 41603 (53558)	Loss/tok 2.8748 (3.3714)	Learning Rate [0.00125]
11: TRAIN [1][2400/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00091)	Tok/s 41888 (53954)	Loss/tok 3.2183 (3.3703)	Learning Rate [0.00125]
5: TRAIN [1][2400/3416]	Time 0.048 (0.058)	Data 0.00078 (0.00092)	Tok/s 41547 (53483)	Loss/tok 3.2733 (3.3740)	Learning Rate [0.00125]
12: TRAIN [1][2400/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00096)	Tok/s 41926 (54060)	Loss/tok 2.9986 (3.3675)	Learning Rate [0.00125]
10: TRAIN [1][2400/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00096)	Tok/s 41786 (53872)	Loss/tok 3.4573 (3.3694)	Learning Rate [0.00125]
4: TRAIN [1][2410/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 71730 (53425)	Loss/tok 3.3787 (3.3725)	Learning Rate [0.00125]
6: TRAIN [1][2410/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00091)	Tok/s 71983 (53580)	Loss/tok 3.6065 (3.3715)	Learning Rate [0.00125]
5: TRAIN [1][2410/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 72053 (53505)	Loss/tok 3.4868 (3.3738)	Learning Rate [0.00125]
3: TRAIN [1][2410/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00094)	Tok/s 71135 (53327)	Loss/tok 3.2404 (3.3698)	Learning Rate [0.00125]
7: TRAIN [1][2410/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 71864 (53671)	Loss/tok 3.5054 (3.3709)	Learning Rate [0.00125]
8: TRAIN [1][2410/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 71799 (53754)	Loss/tok 3.3280 (3.3749)	Learning Rate [0.00125]
2: TRAIN [1][2410/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00098)	Tok/s 71088 (53238)	Loss/tok 3.5899 (3.3784)	Learning Rate [0.00125]
1: TRAIN [1][2410/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 71058 (53139)	Loss/tok 3.5398 (3.3775)	Learning Rate [0.00125]
9: TRAIN [1][2410/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 71677 (53812)	Loss/tok 3.6316 (3.3635)	Learning Rate [0.00125]
0: TRAIN [1][2410/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00099)	Tok/s 71027 (53035)	Loss/tok 3.3135 (3.3727)	Learning Rate [0.00125]
15: TRAIN [1][2410/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 72473 (54384)	Loss/tok 3.5935 (3.3698)	Learning Rate [0.00125]
11: TRAIN [1][2410/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00091)	Tok/s 71731 (53975)	Loss/tok 3.3088 (3.3700)	Learning Rate [0.00125]
10: TRAIN [1][2410/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 71635 (53893)	Loss/tok 3.4115 (3.3693)	Learning Rate [0.00125]
14: TRAIN [1][2410/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 71862 (54275)	Loss/tok 3.5183 (3.3722)	Learning Rate [0.00125]
13: TRAIN [1][2410/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 71791 (54177)	Loss/tok 3.5713 (3.3698)	Learning Rate [0.00125]
12: TRAIN [1][2410/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 71615 (54081)	Loss/tok 3.2784 (3.3674)	Learning Rate [0.00125]
1: TRAIN [1][2420/3416]	Time 0.051 (0.058)	Data 0.00111 (0.00097)	Tok/s 53663 (53145)	Loss/tok 3.3082 (3.3776)	Learning Rate [0.00125]
0: TRAIN [1][2420/3416]	Time 0.051 (0.058)	Data 0.00111 (0.00099)	Tok/s 53631 (53042)	Loss/tok 3.1373 (3.3728)	Learning Rate [0.00125]
2: TRAIN [1][2420/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00098)	Tok/s 53530 (53244)	Loss/tok 3.1914 (3.3787)	Learning Rate [0.00125]
3: TRAIN [1][2420/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00094)	Tok/s 53368 (53333)	Loss/tok 3.0370 (3.3693)	Learning Rate [0.00125]
15: TRAIN [1][2420/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00092)	Tok/s 53628 (54390)	Loss/tok 3.5950 (3.3699)	Learning Rate [0.00125]
14: TRAIN [1][2420/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00092)	Tok/s 53661 (54281)	Loss/tok 3.2651 (3.3720)	Learning Rate [0.00125]
13: TRAIN [1][2420/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00098)	Tok/s 53621 (54183)	Loss/tok 3.2439 (3.3701)	Learning Rate [0.00125]
4: TRAIN [1][2420/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00100)	Tok/s 53270 (53430)	Loss/tok 3.1393 (3.3725)	Learning Rate [0.00125]
6: TRAIN [1][2420/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00091)	Tok/s 53344 (53585)	Loss/tok 3.4484 (3.3719)	Learning Rate [0.00125]
5: TRAIN [1][2420/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00092)	Tok/s 53327 (53511)	Loss/tok 3.3262 (3.3738)	Learning Rate [0.00125]
11: TRAIN [1][2420/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00091)	Tok/s 53547 (53981)	Loss/tok 3.4039 (3.3702)	Learning Rate [0.00125]
9: TRAIN [1][2420/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00092)	Tok/s 53381 (53818)	Loss/tok 3.4951 (3.3634)	Learning Rate [0.00125]
7: TRAIN [1][2420/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00097)	Tok/s 53284 (53677)	Loss/tok 3.4057 (3.3707)	Learning Rate [0.00125]
12: TRAIN [1][2420/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00096)	Tok/s 53565 (54087)	Loss/tok 3.2190 (3.3675)	Learning Rate [0.00125]
10: TRAIN [1][2420/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00096)	Tok/s 53404 (53898)	Loss/tok 3.0382 (3.3693)	Learning Rate [0.00125]
8: TRAIN [1][2420/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00096)	Tok/s 53252 (53759)	Loss/tok 3.6301 (3.3748)	Learning Rate [0.00125]
11: TRAIN [1][2430/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00091)	Tok/s 63680 (53976)	Loss/tok 3.3332 (3.3699)	Learning Rate [0.00125]
9: TRAIN [1][2430/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00092)	Tok/s 63650 (53813)	Loss/tok 3.6279 (3.3634)	Learning Rate [0.00125]
10: TRAIN [1][2430/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00096)	Tok/s 63704 (53894)	Loss/tok 3.4142 (3.3692)	Learning Rate [0.00125]
12: TRAIN [1][2430/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00096)	Tok/s 63551 (54082)	Loss/tok 3.4963 (3.3675)	Learning Rate [0.00125]
13: TRAIN [1][2430/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 64284 (54177)	Loss/tok 3.5973 (3.3696)	Learning Rate [0.00125]
8: TRAIN [1][2430/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00096)	Tok/s 63536 (53753)	Loss/tok 3.6007 (3.3750)	Learning Rate [0.00125]
14: TRAIN [1][2430/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 64306 (54275)	Loss/tok 3.6100 (3.3720)	Learning Rate [0.00125]
7: TRAIN [1][2430/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 63397 (53671)	Loss/tok 3.5204 (3.3705)	Learning Rate [0.00125]
15: TRAIN [1][2430/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 64189 (54383)	Loss/tok 3.3418 (3.3696)	Learning Rate [0.00125]
5: TRAIN [1][2430/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 63256 (53505)	Loss/tok 3.6818 (3.3736)	Learning Rate [0.00125]
6: TRAIN [1][2430/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 63250 (53580)	Loss/tok 3.2813 (3.3718)	Learning Rate [0.00125]
0: TRAIN [1][2430/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00099)	Tok/s 63164 (53037)	Loss/tok 3.6734 (3.3729)	Learning Rate [0.00125]
1: TRAIN [1][2430/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 63052 (53140)	Loss/tok 3.2209 (3.3773)	Learning Rate [0.00125]
4: TRAIN [1][2430/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00100)	Tok/s 63082 (53424)	Loss/tok 3.8216 (3.3724)	Learning Rate [0.00125]
3: TRAIN [1][2430/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 63014 (53328)	Loss/tok 3.6115 (3.3693)	Learning Rate [0.00125]
2: TRAIN [1][2430/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 62940 (53239)	Loss/tok 3.3453 (3.3785)	Learning Rate [0.00125]
2: TRAIN [1][2440/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00098)	Tok/s 48829 (53235)	Loss/tok 3.3273 (3.3785)	Learning Rate [0.00125]
1: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00097)	Tok/s 48703 (53137)	Loss/tok 3.4000 (3.3777)	Learning Rate [0.00125]
4: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00100)	Tok/s 48793 (53421)	Loss/tok 3.1478 (3.3723)	Learning Rate [0.00125]
0: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00107 (0.00099)	Tok/s 48593 (53035)	Loss/tok 3.3895 (3.3729)	Learning Rate [0.00125]
3: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00082 (0.00094)	Tok/s 48782 (53324)	Loss/tok 3.4007 (3.3696)	Learning Rate [0.00125]
5: TRAIN [1][2440/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00092)	Tok/s 50825 (53501)	Loss/tok 3.1039 (3.3736)	Learning Rate [0.00125]
15: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00092)	Tok/s 49755 (54380)	Loss/tok 3.3542 (3.3697)	Learning Rate [0.00125]
6: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00091)	Tok/s 49145 (53576)	Loss/tok 2.9197 (3.3717)	Learning Rate [0.00125]
14: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00078 (0.00092)	Tok/s 49774 (54272)	Loss/tok 3.0770 (3.3719)	Learning Rate [0.00125]
13: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00098)	Tok/s 49767 (54174)	Loss/tok 3.2481 (3.3698)	Learning Rate [0.00125]
7: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00097)	Tok/s 50054 (53668)	Loss/tok 3.2567 (3.3705)	Learning Rate [0.00125]
11: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00078 (0.00091)	Tok/s 49797 (53973)	Loss/tok 3.0273 (3.3697)	Learning Rate [0.00125]
9: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00080 (0.00092)	Tok/s 49871 (53810)	Loss/tok 3.1974 (3.3634)	Learning Rate [0.00125]
12: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00107 (0.00096)	Tok/s 49730 (54079)	Loss/tok 3.3411 (3.3679)	Learning Rate [0.00125]
8: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00096)	Tok/s 49971 (53750)	Loss/tok 3.2527 (3.3748)	Learning Rate [0.00125]
10: TRAIN [1][2440/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00096)	Tok/s 49792 (53890)	Loss/tok 3.2891 (3.3689)	Learning Rate [0.00125]
2: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00098)	Tok/s 52076 (53249)	Loss/tok 3.5990 (3.3790)	Learning Rate [0.00125]
1: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00097)	Tok/s 52076 (53152)	Loss/tok 3.2884 (3.3779)	Learning Rate [0.00125]
3: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00094)	Tok/s 51977 (53338)	Loss/tok 3.6677 (3.3694)	Learning Rate [0.00125]
0: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00104 (0.00099)	Tok/s 52085 (53050)	Loss/tok 3.5098 (3.3730)	Learning Rate [0.00125]
4: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00100)	Tok/s 51966 (53435)	Loss/tok 3.4641 (3.3724)	Learning Rate [0.00125]
15: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00092)	Tok/s 52121 (54393)	Loss/tok 3.5933 (3.3695)	Learning Rate [0.00125]
5: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00092)	Tok/s 51987 (53515)	Loss/tok 3.3226 (3.3735)	Learning Rate [0.00125]
14: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00092)	Tok/s 52097 (54285)	Loss/tok 3.3527 (3.3718)	Learning Rate [0.00125]
6: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00091)	Tok/s 51948 (53590)	Loss/tok 3.5172 (3.3715)	Learning Rate [0.00125]
13: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00098)	Tok/s 52116 (54188)	Loss/tok 3.4815 (3.3698)	Learning Rate [0.00125]
7: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00097)	Tok/s 51964 (53681)	Loss/tok 3.4379 (3.3707)	Learning Rate [0.00125]
11: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00091)	Tok/s 52082 (53987)	Loss/tok 3.2222 (3.3696)	Learning Rate [0.00125]
8: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00096)	Tok/s 51978 (53763)	Loss/tok 3.5785 (3.3746)	Learning Rate [0.00125]
9: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00092)	Tok/s 51994 (53823)	Loss/tok 3.5101 (3.3635)	Learning Rate [0.00125]
12: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00096)	Tok/s 52031 (54092)	Loss/tok 3.6541 (3.3676)	Learning Rate [0.00125]
10: TRAIN [1][2450/3416]	Time 0.060 (0.058)	Data 0.00117 (0.00096)	Tok/s 52038 (53904)	Loss/tok 3.5393 (3.3690)	Learning Rate [0.00125]
14: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 69178 (54271)	Loss/tok 3.4074 (3.3715)	Learning Rate [0.00125]
6: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00091)	Tok/s 69393 (53576)	Loss/tok 3.5556 (3.3715)	Learning Rate [0.00125]
13: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00098)	Tok/s 69244 (54173)	Loss/tok 3.5894 (3.3699)	Learning Rate [0.00125]
15: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 69169 (54379)	Loss/tok 3.3114 (3.3694)	Learning Rate [0.00125]
11: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00091)	Tok/s 69245 (53973)	Loss/tok 3.6195 (3.3695)	Learning Rate [0.00125]
1: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00097)	Tok/s 68365 (53137)	Loss/tok 3.5965 (3.3777)	Learning Rate [0.00125]
12: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 69254 (54078)	Loss/tok 3.4634 (3.3676)	Learning Rate [0.00125]
0: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00099)	Tok/s 68259 (53036)	Loss/tok 3.5250 (3.3728)	Learning Rate [0.00125]
7: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 69500 (53667)	Loss/tok 3.2964 (3.3707)	Learning Rate [0.00125]
5: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 68584 (53501)	Loss/tok 3.5571 (3.3735)	Learning Rate [0.00125]
8: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 69352 (53749)	Loss/tok 3.4149 (3.3747)	Learning Rate [0.00125]
4: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00100)	Tok/s 68498 (53421)	Loss/tok 3.2437 (3.3718)	Learning Rate [0.00125]
9: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 69277 (53809)	Loss/tok 3.4038 (3.3633)	Learning Rate [0.00125]
10: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00113 (0.00096)	Tok/s 69226 (53890)	Loss/tok 3.5273 (3.3690)	Learning Rate [0.00125]
3: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 68363 (53324)	Loss/tok 3.6335 (3.3694)	Learning Rate [0.00125]
2: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00098)	Tok/s 68300 (53235)	Loss/tok 3.6177 (3.3792)	Learning Rate [0.00125]
9: TRAIN [1][2470/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00092)	Tok/s 50961 (53800)	Loss/tok 3.3130 (3.3630)	Learning Rate [0.00125]
6: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00091)	Tok/s 50744 (53565)	Loss/tok 3.4784 (3.3713)	Learning Rate [0.00125]
8: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00096)	Tok/s 50821 (53740)	Loss/tok 3.1928 (3.3743)	Learning Rate [0.00125]
12: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00096)	Tok/s 50813 (54068)	Loss/tok 3.4302 (3.3675)	Learning Rate [0.00125]
11: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00091)	Tok/s 50821 (53963)	Loss/tok 3.1325 (3.3691)	Learning Rate [0.00125]
10: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00115 (0.00096)	Tok/s 50888 (53880)	Loss/tok 3.2638 (3.3687)	Learning Rate [0.00125]
7: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00097)	Tok/s 50737 (53657)	Loss/tok 3.1163 (3.3703)	Learning Rate [0.00125]
4: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00100)	Tok/s 50503 (53409)	Loss/tok 3.2348 (3.3717)	Learning Rate [0.00125]
13: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00098)	Tok/s 50742 (54164)	Loss/tok 3.3179 (3.3696)	Learning Rate [0.00125]
5: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00092)	Tok/s 50519 (53490)	Loss/tok 3.4264 (3.3729)	Learning Rate [0.00125]
15: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00091)	Tok/s 50453 (54371)	Loss/tok 3.1966 (3.3691)	Learning Rate [0.00125]
14: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00092)	Tok/s 50480 (54262)	Loss/tok 3.0754 (3.3711)	Learning Rate [0.00125]
3: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00094)	Tok/s 50320 (53312)	Loss/tok 3.1143 (3.3691)	Learning Rate [0.00125]
2: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00098)	Tok/s 50172 (53222)	Loss/tok 3.1957 (3.3787)	Learning Rate [0.00125]
1: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00097)	Tok/s 50187 (53123)	Loss/tok 3.3985 (3.3776)	Learning Rate [0.00125]
0: TRAIN [1][2470/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00099)	Tok/s 50231 (53021)	Loss/tok 3.0604 (3.3724)	Learning Rate [0.00125]
1: TRAIN [1][2480/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00097)	Tok/s 50689 (53106)	Loss/tok 3.1456 (3.3772)	Learning Rate [0.00125]
0: TRAIN [1][2480/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00099)	Tok/s 50566 (53004)	Loss/tok 3.1387 (3.3722)	Learning Rate [0.00125]
2: TRAIN [1][2480/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00098)	Tok/s 50600 (53205)	Loss/tok 3.0922 (3.3786)	Learning Rate [0.00125]
3: TRAIN [1][2480/3416]	Time 0.049 (0.058)	Data 0.00083 (0.00094)	Tok/s 50528 (53295)	Loss/tok 3.2560 (3.3688)	Learning Rate [0.00125]
15: TRAIN [1][2480/3416]	Time 0.049 (0.058)	Data 0.00083 (0.00091)	Tok/s 51757 (54352)	Loss/tok 3.2582 (3.3689)	Learning Rate [0.00125]
14: TRAIN [1][2480/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00092)	Tok/s 51706 (54243)	Loss/tok 3.1377 (3.3709)	Learning Rate [0.00125]
4: TRAIN [1][2480/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00100)	Tok/s 50448 (53391)	Loss/tok 3.4484 (3.3714)	Learning Rate [0.00125]
11: TRAIN [1][2480/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00091)	Tok/s 51756 (53944)	Loss/tok 3.6431 (3.3691)	Learning Rate [0.00125]
5: TRAIN [1][2480/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00092)	Tok/s 50503 (53472)	Loss/tok 3.1211 (3.3725)	Learning Rate [0.00125]
13: TRAIN [1][2480/3416]	Time 0.050 (0.058)	Data 0.00121 (0.00098)	Tok/s 51660 (54146)	Loss/tok 3.5094 (3.3693)	Learning Rate [0.00125]
6: TRAIN [1][2480/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00091)	Tok/s 50717 (53548)	Loss/tok 3.1109 (3.3710)	Learning Rate [0.00125]
12: TRAIN [1][2480/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00096)	Tok/s 51637 (54050)	Loss/tok 3.3535 (3.3672)	Learning Rate [0.00125]
9: TRAIN [1][2480/3416]	Time 0.050 (0.058)	Data 0.00080 (0.00092)	Tok/s 51684 (53781)	Loss/tok 3.3061 (3.3627)	Learning Rate [0.00125]
7: TRAIN [1][2480/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00097)	Tok/s 51778 (53639)	Loss/tok 3.3496 (3.3704)	Learning Rate [0.00125]
8: TRAIN [1][2480/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00096)	Tok/s 51697 (53721)	Loss/tok 3.2716 (3.3743)	Learning Rate [0.00125]
10: TRAIN [1][2480/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00096)	Tok/s 51627 (53862)	Loss/tok 3.3143 (3.3684)	Learning Rate [0.00125]
3: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00094)	Tok/s 57008 (53297)	Loss/tok 3.4551 (3.3688)	Learning Rate [0.00125]
5: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 56917 (53474)	Loss/tok 3.5125 (3.3729)	Learning Rate [0.00125]
6: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 56916 (53549)	Loss/tok 3.5155 (3.3713)	Learning Rate [0.00125]
4: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00100)	Tok/s 56935 (53393)	Loss/tok 3.5120 (3.3720)	Learning Rate [0.00125]
2: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00098)	Tok/s 56962 (53207)	Loss/tok 3.6374 (3.3789)	Learning Rate [0.00125]
1: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 56975 (53109)	Loss/tok 3.6184 (3.3772)	Learning Rate [0.00125]
9: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00092)	Tok/s 56959 (53783)	Loss/tok 3.3720 (3.3628)	Learning Rate [0.00125]
7: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 56879 (53640)	Loss/tok 3.6425 (3.3709)	Learning Rate [0.00125]
15: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00091)	Tok/s 57903 (54352)	Loss/tok 3.4994 (3.3692)	Learning Rate [0.00125]
0: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00099)	Tok/s 56981 (53008)	Loss/tok 3.4602 (3.3724)	Learning Rate [0.00125]
8: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00096)	Tok/s 56898 (53723)	Loss/tok 3.5452 (3.3743)	Learning Rate [0.00125]
14: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 57967 (54244)	Loss/tok 3.4147 (3.3712)	Learning Rate [0.00125]
11: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 56915 (53945)	Loss/tok 3.6044 (3.3694)	Learning Rate [0.00125]
10: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 56943 (53862)	Loss/tok 3.6047 (3.3685)	Learning Rate [0.00125]
13: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00098)	Tok/s 57918 (54146)	Loss/tok 3.4244 (3.3692)	Learning Rate [0.00125]
12: TRAIN [1][2490/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00096)	Tok/s 57274 (54050)	Loss/tok 3.7064 (3.3675)	Learning Rate [0.00125]
4: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
1: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00097)	Tok/s 66097 (53096)	Loss/tok 3.4157 (3.3769)	Learning Rate [0.00125]
0: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 65968 (52995)	Loss/tok 3.3534 (3.3722)	Learning Rate [0.00125]
2: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 66063 (53194)	Loss/tok 3.5764 (3.3786)	Learning Rate [0.00125]
3: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00094)	Tok/s 65985 (53283)	Loss/tok 3.3989 (3.3684)	Learning Rate [0.00125]
15: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 66777 (54338)	Loss/tok 3.5408 (3.3692)	Learning Rate [0.00125]
14: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 66665 (54229)	Loss/tok 3.3167 (3.3709)	Learning Rate [0.00125]
4: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00100)	Tok/s 65902 (53379)	Loss/tok 3.3771 (3.3718)	Learning Rate [0.00125]
5: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 65793 (53460)	Loss/tok 3.4326 (3.3728)	Learning Rate [0.00125]
6: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00091)	Tok/s 65675 (53534)	Loss/tok 3.5926 (3.3711)	Learning Rate [0.00125]
13: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 66578 (54131)	Loss/tok 3.6731 (3.3693)	Learning Rate [0.00125]
11: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 66341 (53930)	Loss/tok 3.4698 (3.3695)	Learning Rate [0.00125]
9: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 65615 (53767)	Loss/tok 3.5177 (3.3626)	Learning Rate [0.00125]
7: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 65558 (53625)	Loss/tok 3.7888 (3.3711)	Learning Rate [0.00125]
8: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 65486 (53707)	Loss/tok 3.2175 (3.3739)	Learning Rate [0.00125]
12: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 66395 (54034)	Loss/tok 3.4608 (3.3672)	Learning Rate [0.00125]
10: TRAIN [1][2500/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 66316 (53847)	Loss/tok 3.5331 (3.3686)	Learning Rate [0.00125]
0: TRAIN [1][2510/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00099)	Tok/s 59799 (53005)	Loss/tok 3.3404 (3.3720)	Learning Rate [0.00125]
15: TRAIN [1][2510/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 60192 (54348)	Loss/tok 3.6463 (3.3690)	Learning Rate [0.00125]
1: TRAIN [1][2510/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 60061 (53107)	Loss/tok 3.4813 (3.3772)	Learning Rate [0.00125]
2: TRAIN [1][2510/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 60032 (53205)	Loss/tok 3.3984 (3.3785)	Learning Rate [0.00125]
14: TRAIN [1][2510/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 60183 (54240)	Loss/tok 3.5038 (3.3706)	Learning Rate [0.00125]
3: TRAIN [1][2510/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00094)	Tok/s 59998 (53294)	Loss/tok 3.5173 (3.3681)	Learning Rate [0.00125]
13: TRAIN [1][2510/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 60213 (54142)	Loss/tok 3.5074 (3.3689)	Learning Rate [0.00125]
4: TRAIN [1][2510/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00100)	Tok/s 59917 (53390)	Loss/tok 3.6696 (3.3721)	Learning Rate [0.00125]
11: TRAIN [1][2510/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00091)	Tok/s 59980 (53941)	Loss/tok 3.2622 (3.3694)	Learning Rate [0.00125]
12: TRAIN [1][2510/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 60107 (54045)	Loss/tok 3.6212 (3.3673)	Learning Rate [0.00125]
6: TRAIN [1][2510/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00091)	Tok/s 59806 (53545)	Loss/tok 3.4599 (3.3709)	Learning Rate [0.00125]
5: TRAIN [1][2510/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00092)	Tok/s 59858 (53471)	Loss/tok 3.3072 (3.3726)	Learning Rate [0.00125]
9: TRAIN [1][2510/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 59821 (53778)	Loss/tok 3.2955 (3.3625)	Learning Rate [0.00125]
10: TRAIN [1][2510/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00096)	Tok/s 59911 (53858)	Loss/tok 3.4882 (3.3683)	Learning Rate [0.00125]
8: TRAIN [1][2510/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00096)	Tok/s 59739 (53719)	Loss/tok 3.6638 (3.3738)	Learning Rate [0.00125]
7: TRAIN [1][2510/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 59704 (53637)	Loss/tok 3.4143 (3.3709)	Learning Rate [0.00125]
1: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00097)	Tok/s 54661 (53103)	Loss/tok 3.4314 (3.3772)	Learning Rate [0.00125]
0: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00106 (0.00099)	Tok/s 54627 (53001)	Loss/tok 3.3412 (3.3718)	Learning Rate [0.00125]
15: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00091)	Tok/s 54431 (54343)	Loss/tok 3.1701 (3.3692)	Learning Rate [0.00125]
3: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00094)	Tok/s 54589 (53291)	Loss/tok 3.4215 (3.3678)	Learning Rate [0.00125]
2: TRAIN [1][2520/3416]	Time 0.060 (0.058)	Data 0.00131 (0.00098)	Tok/s 55122 (53201)	Loss/tok 3.5078 (3.3783)	Learning Rate [0.00125]
14: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00080 (0.00092)	Tok/s 54331 (54234)	Loss/tok 3.1140 (3.3704)	Learning Rate [0.00125]
4: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00107 (0.00100)	Tok/s 54610 (53387)	Loss/tok 3.5166 (3.3719)	Learning Rate [0.00125]
5: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00092)	Tok/s 54460 (53467)	Loss/tok 3.4124 (3.3723)	Learning Rate [0.00125]
13: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00098)	Tok/s 54283 (54137)	Loss/tok 3.2836 (3.3684)	Learning Rate [0.00125]
11: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00083 (0.00091)	Tok/s 54130 (53936)	Loss/tok 3.1224 (3.3691)	Learning Rate [0.00125]
6: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00091)	Tok/s 54357 (53541)	Loss/tok 3.2071 (3.3707)	Learning Rate [0.00125]
12: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00096)	Tok/s 54168 (54040)	Loss/tok 3.1545 (3.3672)	Learning Rate [0.00125]
9: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00092)	Tok/s 54170 (53774)	Loss/tok 3.7357 (3.3626)	Learning Rate [0.00125]
10: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00096)	Tok/s 54118 (53853)	Loss/tok 3.4157 (3.3679)	Learning Rate [0.00125]
7: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00097)	Tok/s 54353 (53633)	Loss/tok 3.7310 (3.3710)	Learning Rate [0.00125]
8: TRAIN [1][2520/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00096)	Tok/s 54264 (53714)	Loss/tok 3.2183 (3.3736)	Learning Rate [0.00125]
3: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00094)	Tok/s 50147 (53280)	Loss/tok 3.1392 (3.3676)	Learning Rate [0.00125]
5: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00092)	Tok/s 50288 (53456)	Loss/tok 3.2705 (3.3723)	Learning Rate [0.00125]
6: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00091)	Tok/s 50261 (53530)	Loss/tok 3.0313 (3.3705)	Learning Rate [0.00125]
1: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00097)	Tok/s 49887 (53093)	Loss/tok 3.4024 (3.3771)	Learning Rate [0.00125]
7: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00097)	Tok/s 50283 (53622)	Loss/tok 3.0834 (3.3707)	Learning Rate [0.00125]
0: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00099)	Tok/s 49898 (52991)	Loss/tok 3.0069 (3.3717)	Learning Rate [0.00125]
8: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00111 (0.00096)	Tok/s 50258 (53704)	Loss/tok 3.1181 (3.3736)	Learning Rate [0.00125]
15: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00091)	Tok/s 49863 (54331)	Loss/tok 2.9792 (3.3692)	Learning Rate [0.00125]
9: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00092)	Tok/s 50142 (53763)	Loss/tok 3.2943 (3.3625)	Learning Rate [0.00125]
14: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00092)	Tok/s 49871 (54223)	Loss/tok 3.6186 (3.3704)	Learning Rate [0.00125]
11: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00091)	Tok/s 49981 (53925)	Loss/tok 3.1192 (3.3689)	Learning Rate [0.00125]
13: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00098)	Tok/s 49864 (54126)	Loss/tok 3.1244 (3.3682)	Learning Rate [0.00125]
10: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00096)	Tok/s 50073 (53842)	Loss/tok 3.2429 (3.3675)	Learning Rate [0.00125]
12: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00096)	Tok/s 49936 (54029)	Loss/tok 3.4769 (3.3672)	Learning Rate [0.00125]
4: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00115 (0.00100)	Tok/s 50259 (53376)	Loss/tok 2.9115 (3.3717)	Learning Rate [0.00125]
2: TRAIN [1][2530/3416]	Time 0.047 (0.058)	Data 0.00121 (0.00098)	Tok/s 50031 (53191)	Loss/tok 3.0690 (3.3781)	Learning Rate [0.00125]
11: Gradient norm: inf
12: Gradient norm: inf
10: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
15: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
1: Gradient norm: inf
4: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
3: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00094)	Tok/s 52216 (53291)	Loss/tok 3.1936 (3.3672)	Learning Rate [0.00125]
1: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00097)	Tok/s 52153 (53105)	Loss/tok 3.5906 (3.3766)	Learning Rate [0.00125]
2: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00098)	Tok/s 52081 (53202)	Loss/tok 3.2448 (3.3778)	Learning Rate [0.00125]
4: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00102 (0.00100)	Tok/s 52238 (53388)	Loss/tok 3.5128 (3.3717)	Learning Rate [0.00125]
6: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00091)	Tok/s 52174 (53541)	Loss/tok 3.5251 (3.3703)	Learning Rate [0.00125]
15: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00115 (0.00091)	Tok/s 52179 (54340)	Loss/tok 3.5038 (3.3690)	Learning Rate [0.00125]
0: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00099)	Tok/s 52098 (53003)	Loss/tok 3.3568 (3.3716)	Learning Rate [0.00125]
5: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00106 (0.00092)	Tok/s 52271 (53467)	Loss/tok 3.3000 (3.3717)	Learning Rate [0.00125]
8: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00096)	Tok/s 52244 (53714)	Loss/tok 3.3528 (3.3736)	Learning Rate [0.00125]
14: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00092)	Tok/s 52117 (54232)	Loss/tok 3.3064 (3.3700)	Learning Rate [0.00125]
7: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00108 (0.00097)	Tok/s 52109 (53633)	Loss/tok 3.1789 (3.3704)	Learning Rate [0.00125]
13: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00113 (0.00098)	Tok/s 52120 (54135)	Loss/tok 3.5372 (3.3680)	Learning Rate [0.00125]
9: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00092)	Tok/s 52204 (53773)	Loss/tok 3.1603 (3.3621)	Learning Rate [0.00125]
12: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00096)	Tok/s 52081 (54039)	Loss/tok 3.3410 (3.3668)	Learning Rate [0.00125]
11: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00091)	Tok/s 52106 (53935)	Loss/tok 3.2342 (3.3687)	Learning Rate [0.00125]
10: TRAIN [1][2540/3416]	Time 0.055 (0.058)	Data 0.00108 (0.00096)	Tok/s 52094 (53852)	Loss/tok 3.4609 (3.3673)	Learning Rate [0.00125]
11: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00091)	Tok/s 54553 (53946)	Loss/tok 3.6716 (3.3686)	Learning Rate [0.00125]
14: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 54538 (54243)	Loss/tok 3.5794 (3.3699)	Learning Rate [0.00125]
13: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00098)	Tok/s 54525 (54145)	Loss/tok 3.2925 (3.3677)	Learning Rate [0.00125]
15: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 54562 (54351)	Loss/tok 3.4586 (3.3687)	Learning Rate [0.00125]
9: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00092)	Tok/s 54557 (53784)	Loss/tok 3.4609 (3.3620)	Learning Rate [0.00125]
12: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00096)	Tok/s 54460 (54050)	Loss/tok 3.4329 (3.3667)	Learning Rate [0.00125]
0: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00099)	Tok/s 54546 (53014)	Loss/tok 3.2012 (3.3715)	Learning Rate [0.00125]
10: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00096)	Tok/s 54533 (53863)	Loss/tok 3.4531 (3.3672)	Learning Rate [0.00125]
1: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00097)	Tok/s 54569 (53116)	Loss/tok 3.7370 (3.3770)	Learning Rate [0.00125]
2: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00098)	Tok/s 54560 (53214)	Loss/tok 3.4621 (3.3777)	Learning Rate [0.00125]
8: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00108 (0.00096)	Tok/s 54566 (53725)	Loss/tok 3.3595 (3.3732)	Learning Rate [0.00125]
7: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00109 (0.00097)	Tok/s 54565 (53644)	Loss/tok 3.5438 (3.3701)	Learning Rate [0.00125]
3: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00094)	Tok/s 54556 (53302)	Loss/tok 3.3365 (3.3669)	Learning Rate [0.00125]
4: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00100)	Tok/s 54542 (53399)	Loss/tok 3.3508 (3.3717)	Learning Rate [0.00125]
5: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00114 (0.00092)	Tok/s 54590 (53478)	Loss/tok 3.6335 (3.3712)	Learning Rate [0.00125]
6: TRAIN [1][2550/3416]	Time 0.068 (0.058)	Data 0.00109 (0.00091)	Tok/s 54592 (53552)	Loss/tok 3.4665 (3.3703)	Learning Rate [0.00125]
4: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00106 (0.00100)	Tok/s 33216 (53361)	Loss/tok 3.0841 (3.3712)	Learning Rate [0.00125]
3: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00094)	Tok/s 33191 (53264)	Loss/tok 2.9743 (3.3665)	Learning Rate [0.00125]
5: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00092)	Tok/s 33119 (53441)	Loss/tok 2.9862 (3.3709)	Learning Rate [0.00125]
6: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00091)	Tok/s 33034 (53516)	Loss/tok 3.2291 (3.3699)	Learning Rate [0.00125]
2: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00098)	Tok/s 33197 (53176)	Loss/tok 3.0874 (3.3772)	Learning Rate [0.00125]
1: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00097)	Tok/s 33240 (53079)	Loss/tok 2.9388 (3.3767)	Learning Rate [0.00125]
7: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00097)	Tok/s 33097 (53607)	Loss/tok 2.9540 (3.3699)	Learning Rate [0.00125]
0: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00080 (0.00099)	Tok/s 33160 (52977)	Loss/tok 2.9016 (3.3711)	Learning Rate [0.00125]
8: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00096)	Tok/s 33094 (53688)	Loss/tok 3.1682 (3.3729)	Learning Rate [0.00125]
9: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00080 (0.00092)	Tok/s 33037 (53747)	Loss/tok 2.9002 (3.3615)	Learning Rate [0.00125]
15: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00092)	Tok/s 34453 (54314)	Loss/tok 2.9616 (3.3684)	Learning Rate [0.00125]
10: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00096)	Tok/s 33815 (53826)	Loss/tok 3.1789 (3.3668)	Learning Rate [0.00125]
14: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00092)	Tok/s 34435 (54207)	Loss/tok 3.2240 (3.3697)	Learning Rate [0.00125]
13: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00098)	Tok/s 34513 (54109)	Loss/tok 3.1126 (3.3673)	Learning Rate [0.00125]
11: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00078 (0.00091)	Tok/s 34341 (53909)	Loss/tok 3.2733 (3.3685)	Learning Rate [0.00125]
12: TRAIN [1][2560/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00096)	Tok/s 34339 (54013)	Loss/tok 3.1018 (3.3663)	Learning Rate [0.00125]
2: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00098)	Tok/s 64302 (53157)	Loss/tok 3.4515 (3.3772)	Learning Rate [0.00125]
3: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00094)	Tok/s 64206 (53245)	Loss/tok 3.5297 (3.3666)	Learning Rate [0.00125]
1: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 64291 (53060)	Loss/tok 3.7029 (3.3766)	Learning Rate [0.00125]
0: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 64280 (52958)	Loss/tok 3.6137 (3.3710)	Learning Rate [0.00125]
4: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 64045 (53342)	Loss/tok 3.3087 (3.3709)	Learning Rate [0.00125]
15: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 65208 (54294)	Loss/tok 3.5370 (3.3684)	Learning Rate [0.00125]
6: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00078 (0.00091)	Tok/s 63835 (53496)	Loss/tok 3.4121 (3.3697)	Learning Rate [0.00125]
14: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 65089 (54187)	Loss/tok 3.4580 (3.3694)	Learning Rate [0.00125]
12: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00096)	Tok/s 63962 (53993)	Loss/tok 3.4009 (3.3662)	Learning Rate [0.00125]
13: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00098)	Tok/s 64413 (54089)	Loss/tok 3.4140 (3.3668)	Learning Rate [0.00125]
8: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 63658 (53669)	Loss/tok 3.4916 (3.3726)	Learning Rate [0.00125]
7: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 63754 (53587)	Loss/tok 3.4375 (3.3697)	Learning Rate [0.00125]
11: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 63790 (53889)	Loss/tok 3.5427 (3.3682)	Learning Rate [0.00125]
9: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 63686 (53727)	Loss/tok 3.4342 (3.3614)	Learning Rate [0.00125]
10: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 63785 (53806)	Loss/tok 3.3843 (3.3667)	Learning Rate [0.00125]
5: TRAIN [1][2570/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 63645 (53421)	Loss/tok 3.4918 (3.3705)	Learning Rate [0.00125]
6: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00076 (0.00091)	Tok/s 37156 (53507)	Loss/tok 3.0489 (3.3693)	Learning Rate [0.00125]
11: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00091)	Tok/s 37272 (53900)	Loss/tok 3.1695 (3.3679)	Learning Rate [0.00125]
12: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00096)	Tok/s 37274 (54004)	Loss/tok 3.0822 (3.3663)	Learning Rate [0.00125]
13: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00098)	Tok/s 37227 (54100)	Loss/tok 2.8887 (3.3670)	Learning Rate [0.00125]
7: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00097)	Tok/s 37208 (53598)	Loss/tok 3.3667 (3.3698)	Learning Rate [0.00125]
9: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00092)	Tok/s 37184 (53738)	Loss/tok 3.0180 (3.3616)	Learning Rate [0.00125]
8: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00096)	Tok/s 37213 (53679)	Loss/tok 3.0771 (3.3726)	Learning Rate [0.00125]
10: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00096)	Tok/s 37262 (53817)	Loss/tok 2.9552 (3.3662)	Learning Rate [0.00125]
5: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 37078 (53432)	Loss/tok 2.9864 (3.3705)	Learning Rate [0.00125]
14: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00080 (0.00092)	Tok/s 37079 (54198)	Loss/tok 3.0348 (3.3695)	Learning Rate [0.00125]
15: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00081 (0.00092)	Tok/s 36996 (54305)	Loss/tok 3.0144 (3.3681)	Learning Rate [0.00125]
4: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00100)	Tok/s 36967 (53352)	Loss/tok 3.0947 (3.3708)	Learning Rate [0.00125]
3: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00094)	Tok/s 36894 (53256)	Loss/tok 2.9779 (3.3667)	Learning Rate [0.00125]
0: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00099)	Tok/s 36954 (52969)	Loss/tok 3.0342 (3.3710)	Learning Rate [0.00125]
1: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00097)	Tok/s 36880 (53071)	Loss/tok 3.3757 (3.3764)	Learning Rate [0.00125]
2: TRAIN [1][2580/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00098)	Tok/s 36857 (53167)	Loss/tok 3.0956 (3.3772)	Learning Rate [0.00125]
0: TRAIN [1][2590/3416]	Time 0.041 (0.058)	Data 0.00098 (0.00099)	Tok/s 30849 (52938)	Loss/tok 2.7663 (3.3708)	Learning Rate [0.00125]
15: TRAIN [1][2590/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00092)	Tok/s 32396 (54275)	Loss/tok 2.6673 (3.3677)	Learning Rate [0.00125]
1: TRAIN [1][2590/3416]	Time 0.041 (0.058)	Data 0.00103 (0.00097)	Tok/s 30857 (53040)	Loss/tok 2.8165 (3.3756)	Learning Rate [0.00125]
14: TRAIN [1][2590/3416]	Time 0.042 (0.058)	Data 0.00085 (0.00092)	Tok/s 32300 (54167)	Loss/tok 2.8791 (3.3690)	Learning Rate [0.00125]
2: TRAIN [1][2590/3416]	Time 0.041 (0.058)	Data 0.00101 (0.00098)	Tok/s 30851 (53136)	Loss/tok 2.6695 (3.3766)	Learning Rate [0.00125]
3: TRAIN [1][2590/3416]	Time 0.041 (0.058)	Data 0.00095 (0.00094)	Tok/s 30865 (53225)	Loss/tok 2.6912 (3.3662)	Learning Rate [0.00125]
11: TRAIN [1][2590/3416]	Time 0.042 (0.058)	Data 0.00083 (0.00091)	Tok/s 32049 (53869)	Loss/tok 2.6112 (3.3674)	Learning Rate [0.00125]
6: TRAIN [1][2590/3416]	Time 0.042 (0.058)	Data 0.00082 (0.00091)	Tok/s 32166 (53477)	Loss/tok 2.9156 (3.3692)	Learning Rate [0.00125]
13: TRAIN [1][2590/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00098)	Tok/s 32145 (54070)	Loss/tok 2.7363 (3.3668)	Learning Rate [0.00125]
5: TRAIN [1][2590/3416]	Time 0.042 (0.058)	Data 0.00095 (0.00092)	Tok/s 32249 (53401)	Loss/tok 2.9280 (3.3701)	Learning Rate [0.00125]
4: TRAIN [1][2590/3416]	Time 0.042 (0.058)	Data 0.00098 (0.00100)	Tok/s 31087 (53322)	Loss/tok 2.6531 (3.3702)	Learning Rate [0.00125]
10: TRAIN [1][2590/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00096)	Tok/s 32060 (53786)	Loss/tok 2.5172 (3.3659)	Learning Rate [0.00125]
12: TRAIN [1][2590/3416]	Time 0.042 (0.058)	Data 0.00095 (0.00096)	Tok/s 32057 (53973)	Loss/tok 2.6392 (3.3659)	Learning Rate [0.00125]
9: TRAIN [1][2590/3416]	Time 0.042 (0.058)	Data 0.00083 (0.00092)	Tok/s 32042 (53707)	Loss/tok 2.7124 (3.3613)	Learning Rate [0.00125]
7: TRAIN [1][2590/3416]	Time 0.042 (0.058)	Data 0.00096 (0.00097)	Tok/s 32019 (53567)	Loss/tok 3.0197 (3.3693)	Learning Rate [0.00125]
8: TRAIN [1][2590/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00096)	Tok/s 31965 (53648)	Loss/tok 2.7645 (3.3722)	Learning Rate [0.00125]
6: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00091)	Tok/s 50049 (53481)	Loss/tok 3.2202 (3.3692)	Learning Rate [0.00125]
8: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00096)	Tok/s 50327 (53652)	Loss/tok 3.1199 (3.3721)	Learning Rate [0.00125]
7: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00097)	Tok/s 50282 (53572)	Loss/tok 3.3130 (3.3692)	Learning Rate [0.00125]
9: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00092)	Tok/s 50154 (53711)	Loss/tok 3.4225 (3.3610)	Learning Rate [0.00125]
10: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00096)	Tok/s 50140 (53790)	Loss/tok 3.3000 (3.3658)	Learning Rate [0.00125]
3: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00094)	Tok/s 49775 (53230)	Loss/tok 3.2939 (3.3663)	Learning Rate [0.00125]
11: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00091)	Tok/s 50055 (53873)	Loss/tok 3.3956 (3.3675)	Learning Rate [0.00125]
1: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00097)	Tok/s 49833 (53044)	Loss/tok 3.1754 (3.3754)	Learning Rate [0.00125]
12: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00096)	Tok/s 50015 (53976)	Loss/tok 3.3140 (3.3658)	Learning Rate [0.00125]
0: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00099)	Tok/s 49829 (52943)	Loss/tok 3.2539 (3.3710)	Learning Rate [0.00125]
13: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00098)	Tok/s 50023 (54073)	Loss/tok 3.2441 (3.3664)	Learning Rate [0.00125]
2: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00098)	Tok/s 49805 (53141)	Loss/tok 3.0610 (3.3768)	Learning Rate [0.00125]
14: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00092)	Tok/s 49904 (54170)	Loss/tok 3.4324 (3.3690)	Learning Rate [0.00125]
15: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00092)	Tok/s 50572 (54278)	Loss/tok 3.2947 (3.3675)	Learning Rate [0.00125]
5: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00092)	Tok/s 49752 (53406)	Loss/tok 3.1827 (3.3698)	Learning Rate [0.00125]
4: TRAIN [1][2600/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00100)	Tok/s 49707 (53327)	Loss/tok 3.1890 (3.3701)	Learning Rate [0.00125]
13: TRAIN [1][2610/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00097)	Tok/s 52424 (54064)	Loss/tok 3.1498 (3.3662)	Learning Rate [0.00125]
12: TRAIN [1][2610/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00096)	Tok/s 52478 (53967)	Loss/tok 3.3161 (3.3659)	Learning Rate [0.00125]
14: TRAIN [1][2610/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00092)	Tok/s 52332 (54161)	Loss/tok 3.2734 (3.3689)	Learning Rate [0.00125]
11: TRAIN [1][2610/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00091)	Tok/s 52424 (53864)	Loss/tok 3.2261 (3.3672)	Learning Rate [0.00125]
15: TRAIN [1][2610/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00092)	Tok/s 52235 (54269)	Loss/tok 3.1538 (3.3676)	Learning Rate [0.00125]
0: TRAIN [1][2610/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00099)	Tok/s 52140 (52934)	Loss/tok 3.3545 (3.3711)	Learning Rate [0.00125]
10: TRAIN [1][2610/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00096)	Tok/s 52339 (53782)	Loss/tok 3.3477 (3.3657)	Learning Rate [0.00125]
9: TRAIN [1][2610/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00092)	Tok/s 52221 (53703)	Loss/tok 3.3051 (3.3610)	Learning Rate [0.00125]
1: TRAIN [1][2610/3416]	Time 0.050 (0.058)	Data 0.00111 (0.00097)	Tok/s 52012 (53036)	Loss/tok 3.0646 (3.3750)	Learning Rate [0.00125]
8: TRAIN [1][2610/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00096)	Tok/s 52150 (53644)	Loss/tok 3.3456 (3.3722)	Learning Rate [0.00125]
6: TRAIN [1][2610/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00091)	Tok/s 52008 (53472)	Loss/tok 3.2983 (3.3694)	Learning Rate [0.00125]
2: TRAIN [1][2610/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00098)	Tok/s 51908 (53132)	Loss/tok 3.1091 (3.3768)	Learning Rate [0.00125]
7: TRAIN [1][2610/3416]	Time 0.050 (0.058)	Data 0.00106 (0.00097)	Tok/s 52022 (53563)	Loss/tok 3.1275 (3.3693)	Learning Rate [0.00125]
4: TRAIN [1][2610/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00100)	Tok/s 51855 (53318)	Loss/tok 3.1774 (3.3700)	Learning Rate [0.00125]
3: TRAIN [1][2610/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00094)	Tok/s 51777 (53221)	Loss/tok 3.1204 (3.3664)	Learning Rate [0.00125]
5: TRAIN [1][2610/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00092)	Tok/s 51818 (53397)	Loss/tok 3.5526 (3.3699)	Learning Rate [0.00125]
15: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00092)	Tok/s 52246 (54290)	Loss/tok 3.3904 (3.3677)	Learning Rate [0.00125]
0: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00099)	Tok/s 52130 (52956)	Loss/tok 3.3370 (3.3712)	Learning Rate [0.00125]
14: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00092)	Tok/s 52216 (54182)	Loss/tok 3.3266 (3.3689)	Learning Rate [0.00125]
1: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00106 (0.00098)	Tok/s 52020 (53058)	Loss/tok 3.6981 (3.3752)	Learning Rate [0.00125]
12: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00096)	Tok/s 52291 (53989)	Loss/tok 3.6210 (3.3664)	Learning Rate [0.00125]
13: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00097)	Tok/s 52171 (54085)	Loss/tok 3.6204 (3.3664)	Learning Rate [0.00125]
4: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00100)	Tok/s 51809 (53340)	Loss/tok 3.3526 (3.3701)	Learning Rate [0.00125]
2: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00103 (0.00098)	Tok/s 51919 (53155)	Loss/tok 3.3881 (3.3767)	Learning Rate [0.00125]
11: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00091)	Tok/s 52104 (53885)	Loss/tok 3.5085 (3.3671)	Learning Rate [0.00125]
5: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00092)	Tok/s 51792 (53419)	Loss/tok 3.2916 (3.3702)	Learning Rate [0.00125]
3: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00094)	Tok/s 51791 (53244)	Loss/tok 3.5454 (3.3661)	Learning Rate [0.00125]
6: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00091)	Tok/s 51782 (53494)	Loss/tok 3.5820 (3.3697)	Learning Rate [0.00125]
9: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00092)	Tok/s 51935 (53725)	Loss/tok 3.2453 (3.3609)	Learning Rate [0.00125]
10: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00096)	Tok/s 52063 (53804)	Loss/tok 3.4700 (3.3660)	Learning Rate [0.00125]
8: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00096)	Tok/s 51835 (53665)	Loss/tok 3.3475 (3.3722)	Learning Rate [0.00125]
7: TRAIN [1][2620/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00097)	Tok/s 51721 (53584)	Loss/tok 3.2752 (3.3693)	Learning Rate [0.00125]
5: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00092)	Tok/s 51577 (53438)	Loss/tok 3.1327 (3.3702)	Learning Rate [0.000625]
6: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00091)	Tok/s 51599 (53512)	Loss/tok 3.5440 (3.3697)	Learning Rate [0.000625]
4: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00100)	Tok/s 51539 (53359)	Loss/tok 3.1283 (3.3701)	Learning Rate [0.000625]
3: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00094)	Tok/s 51603 (53263)	Loss/tok 3.4257 (3.3666)	Learning Rate [0.000625]
7: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 51570 (53603)	Loss/tok 3.3767 (3.3693)	Learning Rate [0.000625]
8: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00096)	Tok/s 51585 (53683)	Loss/tok 3.2857 (3.3723)	Learning Rate [0.000625]
9: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00092)	Tok/s 51645 (53742)	Loss/tok 3.0663 (3.3608)	Learning Rate [0.000625]
1: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00098)	Tok/s 51528 (53077)	Loss/tok 3.1307 (3.3753)	Learning Rate [0.000625]
2: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00098)	Tok/s 51590 (53174)	Loss/tok 3.2661 (3.3769)	Learning Rate [0.000625]
15: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00092)	Tok/s 52942 (54307)	Loss/tok 3.2994 (3.3676)	Learning Rate [0.000625]
0: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00099)	Tok/s 51581 (52975)	Loss/tok 3.2050 (3.3711)	Learning Rate [0.000625]
11: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00091)	Tok/s 51598 (53903)	Loss/tok 3.1457 (3.3667)	Learning Rate [0.000625]
10: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00096)	Tok/s 51599 (53821)	Loss/tok 3.4617 (3.3661)	Learning Rate [0.000625]
14: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00092)	Tok/s 52891 (54199)	Loss/tok 3.4118 (3.3688)	Learning Rate [0.000625]
12: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00096)	Tok/s 52522 (54006)	Loss/tok 3.2184 (3.3660)	Learning Rate [0.000625]
13: TRAIN [1][2630/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00097)	Tok/s 52900 (54102)	Loss/tok 3.3398 (3.3665)	Learning Rate [0.000625]
8: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00097)	Tok/s 45703 (53691)	Loss/tok 3.1146 (3.3723)	Learning Rate [0.000625]
7: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00097)	Tok/s 45754 (53610)	Loss/tok 3.3036 (3.3694)	Learning Rate [0.000625]
9: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00092)	Tok/s 45623 (53750)	Loss/tok 3.1186 (3.3608)	Learning Rate [0.000625]
6: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00091)	Tok/s 45704 (53520)	Loss/tok 2.9858 (3.3695)	Learning Rate [0.000625]
10: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00096)	Tok/s 45554 (53829)	Loss/tok 3.0239 (3.3661)	Learning Rate [0.000625]
11: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00091)	Tok/s 45495 (53911)	Loss/tok 3.3791 (3.3667)	Learning Rate [0.000625]
5: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00092)	Tok/s 45688 (53446)	Loss/tok 3.3556 (3.3699)	Learning Rate [0.000625]
4: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00108 (0.00100)	Tok/s 45763 (53367)	Loss/tok 3.1903 (3.3701)	Learning Rate [0.000625]
12: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00096)	Tok/s 45451 (54013)	Loss/tok 3.1704 (3.3657)	Learning Rate [0.000625]
3: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00094)	Tok/s 45658 (53271)	Loss/tok 3.2988 (3.3666)	Learning Rate [0.000625]
13: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00097)	Tok/s 45492 (54109)	Loss/tok 3.1158 (3.3661)	Learning Rate [0.000625]
1: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00104 (0.00098)	Tok/s 45616 (53086)	Loss/tok 3.0593 (3.3754)	Learning Rate [0.000625]
2: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00098)	Tok/s 45655 (53183)	Loss/tok 3.4019 (3.3768)	Learning Rate [0.000625]
15: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00092)	Tok/s 45465 (54314)	Loss/tok 3.1369 (3.3677)	Learning Rate [0.000625]
0: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00099)	Tok/s 45485 (52983)	Loss/tok 3.1096 (3.3708)	Learning Rate [0.000625]
14: TRAIN [1][2640/3416]	Time 0.045 (0.058)	Data 0.00106 (0.00092)	Tok/s 45599 (54206)	Loss/tok 3.1498 (3.3683)	Learning Rate [0.000625]
7: TRAIN [1][2650/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00097)	Tok/s 49223 (53599)	Loss/tok 3.4140 (3.3693)	Learning Rate [0.000625]
6: TRAIN [1][2650/3416]	Time 0.046 (0.058)	Data 0.00081 (0.00091)	Tok/s 49217 (53509)	Loss/tok 3.1256 (3.3693)	Learning Rate [0.000625]
8: TRAIN [1][2650/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00097)	Tok/s 49098 (53680)	Loss/tok 3.2782 (3.3723)	Learning Rate [0.000625]
4: TRAIN [1][2650/3416]	Time 0.045 (0.058)	Data 0.00103 (0.00100)	Tok/s 49283 (53356)	Loss/tok 3.4822 (3.3699)	Learning Rate [0.000625]
9: TRAIN [1][2650/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00092)	Tok/s 48907 (53739)	Loss/tok 3.1556 (3.3603)	Learning Rate [0.000625]
5: TRAIN [1][2650/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00092)	Tok/s 49225 (53435)	Loss/tok 3.2774 (3.3699)	Learning Rate [0.000625]
2: TRAIN [1][2650/3416]	Time 0.045 (0.058)	Data 0.00103 (0.00098)	Tok/s 49268 (53172)	Loss/tok 3.3380 (3.3766)	Learning Rate [0.000625]
1: TRAIN [1][2650/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00098)	Tok/s 49245 (53075)	Loss/tok 3.1704 (3.3749)	Learning Rate [0.000625]
10: TRAIN [1][2650/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00096)	Tok/s 48843 (53817)	Loss/tok 3.1751 (3.3660)	Learning Rate [0.000625]
11: TRAIN [1][2650/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00091)	Tok/s 48877 (53899)	Loss/tok 3.0218 (3.3661)	Learning Rate [0.000625]
0: TRAIN [1][2650/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00099)	Tok/s 49097 (52973)	Loss/tok 3.1902 (3.3705)	Learning Rate [0.000625]
15: TRAIN [1][2650/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00092)	Tok/s 49024 (54302)	Loss/tok 3.3229 (3.3678)	Learning Rate [0.000625]
12: TRAIN [1][2650/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00096)	Tok/s 48781 (54001)	Loss/tok 3.0538 (3.3655)	Learning Rate [0.000625]
14: TRAIN [1][2650/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00092)	Tok/s 48918 (54194)	Loss/tok 3.2521 (3.3680)	Learning Rate [0.000625]
13: TRAIN [1][2650/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00097)	Tok/s 48881 (54097)	Loss/tok 3.3292 (3.3662)	Learning Rate [0.000625]
3: TRAIN [1][2650/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00094)	Tok/s 49249 (53260)	Loss/tok 3.1670 (3.3666)	Learning Rate [0.000625]
6: TRAIN [1][2660/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00091)	Tok/s 54091 (53501)	Loss/tok 3.2491 (3.3688)	Learning Rate [0.000625]
7: TRAIN [1][2660/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00097)	Tok/s 54126 (53591)	Loss/tok 3.2561 (3.3689)	Learning Rate [0.000625]
5: TRAIN [1][2660/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00092)	Tok/s 53318 (53426)	Loss/tok 3.4287 (3.3699)	Learning Rate [0.000625]
4: TRAIN [1][2660/3416]	Time 0.066 (0.058)	Data 0.00118 (0.00100)	Tok/s 53087 (53348)	Loss/tok 3.4638 (3.3698)	Learning Rate [0.000625]
8: TRAIN [1][2660/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00097)	Tok/s 54042 (53671)	Loss/tok 3.4164 (3.3723)	Learning Rate [0.000625]
9: TRAIN [1][2660/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00092)	Tok/s 54045 (53730)	Loss/tok 3.3618 (3.3601)	Learning Rate [0.000625]
1: TRAIN [1][2660/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00098)	Tok/s 52991 (53068)	Loss/tok 3.2221 (3.3747)	Learning Rate [0.000625]
2: TRAIN [1][2660/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00098)	Tok/s 53023 (53164)	Loss/tok 3.4729 (3.3764)	Learning Rate [0.000625]
0: TRAIN [1][2660/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00099)	Tok/s 52872 (52966)	Loss/tok 3.2625 (3.3701)	Learning Rate [0.000625]
11: TRAIN [1][2660/3416]	Time 0.066 (0.058)	Data 0.00083 (0.00091)	Tok/s 53915 (53890)	Loss/tok 3.3340 (3.3659)	Learning Rate [0.000625]
10: TRAIN [1][2660/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00096)	Tok/s 53992 (53809)	Loss/tok 3.3885 (3.3659)	Learning Rate [0.000625]
12: TRAIN [1][2660/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00096)	Tok/s 53877 (53992)	Loss/tok 3.4881 (3.3655)	Learning Rate [0.000625]
14: TRAIN [1][2660/3416]	Time 0.067 (0.058)	Data 0.00081 (0.00092)	Tok/s 53749 (54184)	Loss/tok 3.4036 (3.3681)	Learning Rate [0.000625]
15: TRAIN [1][2660/3416]	Time 0.067 (0.058)	Data 0.00081 (0.00092)	Tok/s 53732 (54293)	Loss/tok 3.3383 (3.3675)	Learning Rate [0.000625]
13: TRAIN [1][2660/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00097)	Tok/s 53794 (54088)	Loss/tok 3.3550 (3.3658)	Learning Rate [0.000625]
3: TRAIN [1][2660/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00093)	Tok/s 53131 (53253)	Loss/tok 3.3153 (3.3663)	Learning Rate [0.000625]
15: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
9: TRAIN [1][2670/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 78460 (53734)	Loss/tok 3.3046 (3.3601)	Learning Rate [0.000625]
11: TRAIN [1][2670/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 79491 (53894)	Loss/tok 3.1439 (3.3657)	Learning Rate [0.000625]
10: TRAIN [1][2670/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00096)	Tok/s 79216 (53813)	Loss/tok 3.4052 (3.3656)	Learning Rate [0.000625]
12: TRAIN [1][2670/3416]	Time 0.070 (0.058)	Data 0.00115 (0.00096)	Tok/s 79489 (53996)	Loss/tok 3.3254 (3.3652)	Learning Rate [0.000625]
8: TRAIN [1][2670/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 78323 (53675)	Loss/tok 3.1669 (3.3718)	Learning Rate [0.000625]
6: TRAIN [1][2670/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00091)	Tok/s 78296 (53505)	Loss/tok 3.3329 (3.3687)	Learning Rate [0.000625]
13: TRAIN [1][2670/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 79432 (54092)	Loss/tok 3.2825 (3.3656)	Learning Rate [0.000625]
7: TRAIN [1][2670/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 78285 (53595)	Loss/tok 3.2997 (3.3686)	Learning Rate [0.000625]
14: TRAIN [1][2670/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 79304 (54188)	Loss/tok 3.2454 (3.3676)	Learning Rate [0.000625]
5: TRAIN [1][2670/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 78162 (53430)	Loss/tok 3.3527 (3.3696)	Learning Rate [0.000625]
4: TRAIN [1][2670/3416]	Time 0.071 (0.058)	Data 0.00109 (0.00100)	Tok/s 78000 (53352)	Loss/tok 3.3415 (3.3695)	Learning Rate [0.000625]
0: TRAIN [1][2670/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00099)	Tok/s 77215 (52970)	Loss/tok 3.2055 (3.3698)	Learning Rate [0.000625]
1: TRAIN [1][2670/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00097)	Tok/s 77080 (53072)	Loss/tok 3.0622 (3.3744)	Learning Rate [0.000625]
2: TRAIN [1][2670/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00098)	Tok/s 77358 (53169)	Loss/tok 3.1134 (3.3759)	Learning Rate [0.000625]
15: TRAIN [1][2670/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 79071 (54297)	Loss/tok 3.2790 (3.3670)	Learning Rate [0.000625]
3: TRAIN [1][2670/3416]	Time 0.071 (0.058)	Data 0.00088 (0.00093)	Tok/s 77955 (53257)	Loss/tok 3.3610 (3.3662)	Learning Rate [0.000625]
6: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00091)	Tok/s 71014 (53528)	Loss/tok 3.3291 (3.3683)	Learning Rate [0.000625]
7: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 71116 (53618)	Loss/tok 3.6721 (3.3690)	Learning Rate [0.000625]
8: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 72004 (53699)	Loss/tok 3.7952 (3.3722)	Learning Rate [0.000625]
9: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 72035 (53758)	Loss/tok 3.5541 (3.3603)	Learning Rate [0.000625]
5: TRAIN [1][2680/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 70894 (53454)	Loss/tok 3.3054 (3.3698)	Learning Rate [0.000625]
4: TRAIN [1][2680/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00100)	Tok/s 70875 (53375)	Loss/tok 3.6001 (3.3698)	Learning Rate [0.000625]
10: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00096)	Tok/s 72016 (53836)	Loss/tok 3.5642 (3.3657)	Learning Rate [0.000625]
2: TRAIN [1][2680/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00098)	Tok/s 70871 (53192)	Loss/tok 3.4182 (3.3762)	Learning Rate [0.000625]
1: TRAIN [1][2680/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 70864 (53095)	Loss/tok 3.3856 (3.3747)	Learning Rate [0.000625]
12: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00118 (0.00096)	Tok/s 72052 (54019)	Loss/tok 3.3363 (3.3650)	Learning Rate [0.000625]
13: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 71935 (54114)	Loss/tok 3.4249 (3.3658)	Learning Rate [0.000625]
11: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00091)	Tok/s 71963 (53916)	Loss/tok 3.3176 (3.3657)	Learning Rate [0.000625]
14: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 71892 (54210)	Loss/tok 3.5106 (3.3673)	Learning Rate [0.000625]
15: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 71836 (54319)	Loss/tok 3.4476 (3.3673)	Learning Rate [0.000625]
0: TRAIN [1][2680/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00099)	Tok/s 70851 (52994)	Loss/tok 3.4213 (3.3697)	Learning Rate [0.000625]
3: TRAIN [1][2680/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 70846 (53281)	Loss/tok 3.3076 (3.3661)	Learning Rate [0.000625]
11: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00078 (0.00091)	Tok/s 52455 (53899)	Loss/tok 2.9880 (3.3653)	Learning Rate [0.000625]
13: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00094 (0.00097)	Tok/s 52729 (54097)	Loss/tok 3.2917 (3.3655)	Learning Rate [0.000625]
12: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00096)	Tok/s 52468 (54001)	Loss/tok 3.1369 (3.3645)	Learning Rate [0.000625]
14: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00084 (0.00092)	Tok/s 53552 (54193)	Loss/tok 3.2424 (3.3670)	Learning Rate [0.000625]
15: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00084 (0.00092)	Tok/s 53465 (54301)	Loss/tok 3.3166 (3.3671)	Learning Rate [0.000625]
10: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00105 (0.00096)	Tok/s 52242 (53818)	Loss/tok 3.1626 (3.3656)	Learning Rate [0.000625]
1: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00097)	Tok/s 52142 (53078)	Loss/tok 3.3028 (3.3741)	Learning Rate [0.000625]
9: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00085 (0.00092)	Tok/s 52153 (53740)	Loss/tok 3.2734 (3.3602)	Learning Rate [0.000625]
8: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00085 (0.00096)	Tok/s 52081 (53681)	Loss/tok 3.1138 (3.3716)	Learning Rate [0.000625]
2: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00097)	Tok/s 52026 (53175)	Loss/tok 3.3103 (3.3760)	Learning Rate [0.000625]
6: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00079 (0.00091)	Tok/s 51904 (53510)	Loss/tok 3.4212 (3.3681)	Learning Rate [0.000625]
4: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00100)	Tok/s 51780 (53358)	Loss/tok 3.3230 (3.3695)	Learning Rate [0.000625]
5: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00092)	Tok/s 51751 (53436)	Loss/tok 3.1714 (3.3695)	Learning Rate [0.000625]
3: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00086 (0.00093)	Tok/s 51931 (53263)	Loss/tok 3.2557 (3.3656)	Learning Rate [0.000625]
0: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00113 (0.00099)	Tok/s 52172 (52977)	Loss/tok 3.2682 (3.3695)	Learning Rate [0.000625]
7: TRAIN [1][2690/3416]	Time 0.054 (0.058)	Data 0.00122 (0.00097)	Tok/s 51865 (53600)	Loss/tok 3.3673 (3.3688)	Learning Rate [0.000625]
4: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00100)	Tok/s 53041 (53359)	Loss/tok 3.2193 (3.3693)	Learning Rate [0.000625]
2: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00097)	Tok/s 52968 (53175)	Loss/tok 3.3839 (3.3754)	Learning Rate [0.000625]
1: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00097)	Tok/s 52989 (53077)	Loss/tok 3.3313 (3.3740)	Learning Rate [0.000625]
0: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00099)	Tok/s 52997 (52975)	Loss/tok 3.2245 (3.3691)	Learning Rate [0.000625]
5: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 52901 (53438)	Loss/tok 3.6977 (3.3693)	Learning Rate [0.000625]
6: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00091)	Tok/s 52922 (53513)	Loss/tok 3.4904 (3.3680)	Learning Rate [0.000625]
7: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00116 (0.00097)	Tok/s 53026 (53603)	Loss/tok 3.2511 (3.3686)	Learning Rate [0.000625]
15: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00081 (0.00092)	Tok/s 53864 (54306)	Loss/tok 3.5695 (3.3668)	Learning Rate [0.000625]
8: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00096)	Tok/s 52998 (53684)	Loss/tok 3.4879 (3.3715)	Learning Rate [0.000625]
9: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 53009 (53743)	Loss/tok 3.5014 (3.3599)	Learning Rate [0.000625]
14: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00092)	Tok/s 53854 (54197)	Loss/tok 3.4231 (3.3668)	Learning Rate [0.000625]
3: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00093)	Tok/s 52960 (53264)	Loss/tok 3.3532 (3.3655)	Learning Rate [0.000625]
13: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00097)	Tok/s 53940 (54100)	Loss/tok 3.4865 (3.3654)	Learning Rate [0.000625]
11: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00091)	Tok/s 53872 (53902)	Loss/tok 3.5579 (3.3649)	Learning Rate [0.000625]
12: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00096)	Tok/s 54012 (54005)	Loss/tok 3.5259 (3.3644)	Learning Rate [0.000625]
10: TRAIN [1][2700/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00096)	Tok/s 53949 (53822)	Loss/tok 3.7493 (3.3655)	Learning Rate [0.000625]
2: TRAIN [1][2710/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 70021 (53205)	Loss/tok 3.3067 (3.3753)	Learning Rate [0.000625]
4: TRAIN [1][2710/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00100)	Tok/s 70041 (53388)	Loss/tok 3.4691 (3.3693)	Learning Rate [0.000625]
1: TRAIN [1][2710/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 70015 (53107)	Loss/tok 3.1778 (3.3736)	Learning Rate [0.000625]
0: TRAIN [1][2710/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00099)	Tok/s 69930 (53006)	Loss/tok 3.2688 (3.3689)	Learning Rate [0.000625]
8: TRAIN [1][2710/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 70196 (53713)	Loss/tok 3.0772 (3.3716)	Learning Rate [0.000625]
9: TRAIN [1][2710/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 70178 (53772)	Loss/tok 3.5429 (3.3597)	Learning Rate [0.000625]
7: TRAIN [1][2710/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 70110 (53632)	Loss/tok 3.5457 (3.3688)	Learning Rate [0.000625]
6: TRAIN [1][2710/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00091)	Tok/s 70023 (53542)	Loss/tok 3.6325 (3.3681)	Learning Rate [0.000625]
15: TRAIN [1][2710/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 70757 (54335)	Loss/tok 3.4053 (3.3668)	Learning Rate [0.000625]
10: TRAIN [1][2710/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 70691 (53850)	Loss/tok 3.4416 (3.3656)	Learning Rate [0.000625]
5: TRAIN [1][2710/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 69963 (53467)	Loss/tok 3.2831 (3.3695)	Learning Rate [0.000625]
11: TRAIN [1][2710/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 70967 (53931)	Loss/tok 3.5078 (3.3650)	Learning Rate [0.000625]
14: TRAIN [1][2710/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 70737 (54225)	Loss/tok 3.5642 (3.3665)	Learning Rate [0.000625]
13: TRAIN [1][2710/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 70740 (54129)	Loss/tok 3.6201 (3.3658)	Learning Rate [0.000625]
12: TRAIN [1][2710/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00096)	Tok/s 70861 (54033)	Loss/tok 3.3104 (3.3641)	Learning Rate [0.000625]
3: TRAIN [1][2710/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 70004 (53294)	Loss/tok 3.4707 (3.3655)	Learning Rate [0.000625]
11: TRAIN [1][2720/3416]	Time 0.061 (0.058)	Data 0.00083 (0.00091)	Tok/s 52458 (53924)	Loss/tok 3.3183 (3.3648)	Learning Rate [0.000625]
10: TRAIN [1][2720/3416]	Time 0.061 (0.058)	Data 0.00084 (0.00096)	Tok/s 52396 (53844)	Loss/tok 3.0705 (3.3656)	Learning Rate [0.000625]
9: TRAIN [1][2720/3416]	Time 0.061 (0.058)	Data 0.00083 (0.00092)	Tok/s 52350 (53765)	Loss/tok 3.5717 (3.3594)	Learning Rate [0.000625]
12: TRAIN [1][2720/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00096)	Tok/s 52307 (54026)	Loss/tok 3.4887 (3.3640)	Learning Rate [0.000625]
13: TRAIN [1][2720/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00097)	Tok/s 52246 (54122)	Loss/tok 3.6902 (3.3655)	Learning Rate [0.000625]
8: TRAIN [1][2720/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00096)	Tok/s 52257 (53706)	Loss/tok 3.1623 (3.3713)	Learning Rate [0.000625]
14: TRAIN [1][2720/3416]	Time 0.061 (0.058)	Data 0.00083 (0.00092)	Tok/s 52137 (54218)	Loss/tok 3.2675 (3.3665)	Learning Rate [0.000625]
6: TRAIN [1][2720/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00091)	Tok/s 52079 (53536)	Loss/tok 3.2066 (3.3678)	Learning Rate [0.000625]
7: TRAIN [1][2720/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00097)	Tok/s 52176 (53626)	Loss/tok 3.4600 (3.3688)	Learning Rate [0.000625]
15: TRAIN [1][2720/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00091)	Tok/s 52048 (54327)	Loss/tok 3.2590 (3.3664)	Learning Rate [0.000625]
0: TRAIN [1][2720/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00099)	Tok/s 51967 (53000)	Loss/tok 3.4132 (3.3687)	Learning Rate [0.000625]
5: TRAIN [1][2720/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00092)	Tok/s 51938 (53460)	Loss/tok 3.4430 (3.3692)	Learning Rate [0.000625]
1: TRAIN [1][2720/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00097)	Tok/s 51880 (53101)	Loss/tok 3.5419 (3.3736)	Learning Rate [0.000625]
4: TRAIN [1][2720/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00100)	Tok/s 51961 (53382)	Loss/tok 3.0817 (3.3688)	Learning Rate [0.000625]
2: TRAIN [1][2720/3416]	Time 0.062 (0.058)	Data 0.00085 (0.00097)	Tok/s 51788 (53199)	Loss/tok 3.2655 (3.3748)	Learning Rate [0.000625]
3: TRAIN [1][2720/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00093)	Tok/s 51792 (53287)	Loss/tok 3.3554 (3.3651)	Learning Rate [0.000625]
9: TRAIN [1][2730/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00092)	Tok/s 33701 (53755)	Loss/tok 3.0072 (3.3592)	Learning Rate [0.000625]
1: TRAIN [1][2730/3416]	Time 0.049 (0.058)	Data 0.00112 (0.00097)	Tok/s 33762 (53093)	Loss/tok 3.2082 (3.3735)	Learning Rate [0.000625]
8: TRAIN [1][2730/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00096)	Tok/s 33498 (53697)	Loss/tok 3.3004 (3.3711)	Learning Rate [0.000625]
4: TRAIN [1][2730/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00100)	Tok/s 33641 (53373)	Loss/tok 3.1554 (3.3686)	Learning Rate [0.000625]
2: TRAIN [1][2730/3416]	Time 0.049 (0.058)	Data 0.00110 (0.00097)	Tok/s 33712 (53191)	Loss/tok 2.9006 (3.3741)	Learning Rate [0.000625]
0: TRAIN [1][2730/3416]	Time 0.049 (0.058)	Data 0.00101 (0.00099)	Tok/s 33779 (52991)	Loss/tok 2.8251 (3.3687)	Learning Rate [0.000625]
10: TRAIN [1][2730/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00096)	Tok/s 33624 (53834)	Loss/tok 3.0065 (3.3654)	Learning Rate [0.000625]
11: TRAIN [1][2730/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00091)	Tok/s 33708 (53914)	Loss/tok 2.9250 (3.3645)	Learning Rate [0.000625]
6: TRAIN [1][2730/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00091)	Tok/s 33465 (53527)	Loss/tok 3.0338 (3.3674)	Learning Rate [0.000625]
7: TRAIN [1][2730/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00097)	Tok/s 33551 (53617)	Loss/tok 2.9271 (3.3686)	Learning Rate [0.000625]
5: TRAIN [1][2730/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00092)	Tok/s 33502 (53452)	Loss/tok 3.1454 (3.3688)	Learning Rate [0.000625]
12: TRAIN [1][2730/3416]	Time 0.049 (0.058)	Data 0.00108 (0.00096)	Tok/s 33699 (54017)	Loss/tok 2.9518 (3.3640)	Learning Rate [0.000625]
15: TRAIN [1][2730/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00091)	Tok/s 35044 (54318)	Loss/tok 3.0824 (3.3663)	Learning Rate [0.000625]
14: TRAIN [1][2730/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00092)	Tok/s 35033 (54209)	Loss/tok 2.9468 (3.3660)	Learning Rate [0.000625]
13: TRAIN [1][2730/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00097)	Tok/s 33971 (54112)	Loss/tok 3.0486 (3.3654)	Learning Rate [0.000625]
3: TRAIN [1][2730/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00093)	Tok/s 33641 (53279)	Loss/tok 3.2583 (3.3650)	Learning Rate [0.000625]
8: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00096)	Tok/s 62887 (53701)	Loss/tok 3.4344 (3.3710)	Learning Rate [0.000625]
9: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00079 (0.00092)	Tok/s 62911 (53759)	Loss/tok 3.2719 (3.3591)	Learning Rate [0.000625]
6: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00091)	Tok/s 62835 (53532)	Loss/tok 3.3607 (3.3673)	Learning Rate [0.000625]
7: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00097)	Tok/s 62793 (53621)	Loss/tok 3.3989 (3.3685)	Learning Rate [0.000625]
5: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00092)	Tok/s 62782 (53457)	Loss/tok 3.1858 (3.3687)	Learning Rate [0.000625]
10: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00096)	Tok/s 62909 (53838)	Loss/tok 3.3776 (3.3654)	Learning Rate [0.000625]
11: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00091)	Tok/s 62928 (53918)	Loss/tok 3.5237 (3.3647)	Learning Rate [0.000625]
4: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00100)	Tok/s 62772 (53378)	Loss/tok 3.0722 (3.3684)	Learning Rate [0.000625]
12: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00107 (0.00096)	Tok/s 62927 (54021)	Loss/tok 3.5727 (3.3641)	Learning Rate [0.000625]
2: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00097)	Tok/s 62800 (53196)	Loss/tok 3.7297 (3.3745)	Learning Rate [0.000625]
13: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00097)	Tok/s 62902 (54117)	Loss/tok 3.3720 (3.3653)	Learning Rate [0.000625]
14: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00092)	Tok/s 62940 (54213)	Loss/tok 3.3576 (3.3659)	Learning Rate [0.000625]
1: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00097)	Tok/s 62798 (53098)	Loss/tok 3.7019 (3.3734)	Learning Rate [0.000625]
0: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00099)	Tok/s 62818 (52997)	Loss/tok 3.5125 (3.3688)	Learning Rate [0.000625]
15: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00079 (0.00091)	Tok/s 62861 (54322)	Loss/tok 3.6283 (3.3660)	Learning Rate [0.000625]
3: TRAIN [1][2740/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00093)	Tok/s 62804 (53284)	Loss/tok 3.5118 (3.3650)	Learning Rate [0.000625]
10: Gradient norm: inf
11: Gradient norm: inf
9: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
7: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
5: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
6: Gradient norm: inf
1: Gradient norm: inf
0: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
5: TRAIN [1][2750/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00092)	Tok/s 39299 (53478)	Loss/tok 2.9922 (3.3685)	Learning Rate [0.000625]
0: TRAIN [1][2750/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00099)	Tok/s 39373 (53019)	Loss/tok 2.9627 (3.3685)	Learning Rate [0.000625]
4: TRAIN [1][2750/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00100)	Tok/s 39406 (53399)	Loss/tok 3.1910 (3.3681)	Learning Rate [0.000625]
1: TRAIN [1][2750/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00097)	Tok/s 39315 (53120)	Loss/tok 3.1699 (3.3730)	Learning Rate [0.000625]
3: TRAIN [1][2750/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00093)	Tok/s 39300 (53306)	Loss/tok 3.2860 (3.3652)	Learning Rate [0.000625]
8: TRAIN [1][2750/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00096)	Tok/s 39161 (53722)	Loss/tok 3.1771 (3.3712)	Learning Rate [0.000625]
10: TRAIN [1][2750/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00096)	Tok/s 38998 (53858)	Loss/tok 2.9555 (3.3651)	Learning Rate [0.000625]
12: TRAIN [1][2750/3416]	Time 0.051 (0.058)	Data 0.00109 (0.00096)	Tok/s 39069 (54043)	Loss/tok 2.8798 (3.3635)	Learning Rate [0.000625]
13: TRAIN [1][2750/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00097)	Tok/s 39229 (54139)	Loss/tok 3.0113 (3.3651)	Learning Rate [0.000625]
11: TRAIN [1][2750/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00091)	Tok/s 39031 (53940)	Loss/tok 2.8470 (3.3647)	Learning Rate [0.000625]
15: TRAIN [1][2750/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00091)	Tok/s 40623 (54345)	Loss/tok 2.9532 (3.3659)	Learning Rate [0.000625]
9: TRAIN [1][2750/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00092)	Tok/s 39146 (53780)	Loss/tok 3.1397 (3.3592)	Learning Rate [0.000625]
6: TRAIN [1][2750/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00091)	Tok/s 39214 (53552)	Loss/tok 3.2634 (3.3670)	Learning Rate [0.000625]
14: TRAIN [1][2750/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00092)	Tok/s 40240 (54235)	Loss/tok 3.1391 (3.3658)	Learning Rate [0.000625]
2: TRAIN [1][2750/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00097)	Tok/s 39389 (53218)	Loss/tok 3.2036 (3.3744)	Learning Rate [0.000625]
7: TRAIN [1][2750/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00097)	Tok/s 39116 (53642)	Loss/tok 2.9308 (3.3682)	Learning Rate [0.000625]
8: TRAIN [1][2760/3416]	Time 0.042 (0.058)	Data 0.00088 (0.00096)	Tok/s 31893 (53722)	Loss/tok 2.9596 (3.3708)	Learning Rate [0.000625]
13: TRAIN [1][2760/3416]	Time 0.042 (0.058)	Data 0.00082 (0.00097)	Tok/s 31710 (54140)	Loss/tok 2.7894 (3.3649)	Learning Rate [0.000625]
9: TRAIN [1][2760/3416]	Time 0.042 (0.058)	Data 0.00083 (0.00092)	Tok/s 31797 (53780)	Loss/tok 2.8468 (3.3587)	Learning Rate [0.000625]
14: TRAIN [1][2760/3416]	Time 0.042 (0.058)	Data 0.00086 (0.00092)	Tok/s 31710 (54236)	Loss/tok 2.5401 (3.3653)	Learning Rate [0.000625]
7: TRAIN [1][2760/3416]	Time 0.042 (0.058)	Data 0.00085 (0.00097)	Tok/s 31872 (53643)	Loss/tok 2.7373 (3.3677)	Learning Rate [0.000625]
15: TRAIN [1][2760/3416]	Time 0.042 (0.058)	Data 0.00089 (0.00091)	Tok/s 31685 (54347)	Loss/tok 2.4732 (3.3652)	Learning Rate [0.000625]
6: TRAIN [1][2760/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00091)	Tok/s 31614 (53553)	Loss/tok 2.8048 (3.3668)	Learning Rate [0.000625]
11: TRAIN [1][2760/3416]	Time 0.042 (0.058)	Data 0.00089 (0.00091)	Tok/s 31732 (53941)	Loss/tok 2.7261 (3.3641)	Learning Rate [0.000625]
12: TRAIN [1][2760/3416]	Time 0.042 (0.058)	Data 0.00101 (0.00096)	Tok/s 31726 (54044)	Loss/tok 2.7730 (3.3633)	Learning Rate [0.000625]
10: TRAIN [1][2760/3416]	Time 0.042 (0.058)	Data 0.00080 (0.00096)	Tok/s 31800 (53859)	Loss/tok 2.7602 (3.3646)	Learning Rate [0.000625]
0: TRAIN [1][2760/3416]	Time 0.042 (0.058)	Data 0.00092 (0.00099)	Tok/s 30212 (53021)	Loss/tok 2.7450 (3.3679)	Learning Rate [0.000625]
5: TRAIN [1][2760/3416]	Time 0.042 (0.058)	Data 0.00090 (0.00092)	Tok/s 30209 (53478)	Loss/tok 2.8443 (3.3678)	Learning Rate [0.000625]
1: TRAIN [1][2760/3416]	Time 0.042 (0.058)	Data 0.00084 (0.00097)	Tok/s 30167 (53121)	Loss/tok 2.5178 (3.3727)	Learning Rate [0.000625]
4: TRAIN [1][2760/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00100)	Tok/s 30070 (53400)	Loss/tok 2.7627 (3.3679)	Learning Rate [0.000625]
2: TRAIN [1][2760/3416]	Time 0.043 (0.058)	Data 0.00083 (0.00097)	Tok/s 30112 (53219)	Loss/tok 3.1340 (3.3740)	Learning Rate [0.000625]
3: TRAIN [1][2760/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00093)	Tok/s 30052 (53307)	Loss/tok 2.9156 (3.3648)	Learning Rate [0.000625]
12: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00096)	Tok/s 69909 (54035)	Loss/tok 3.3158 (3.3629)	Learning Rate [0.000625]
11: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 69862 (53931)	Loss/tok 3.3156 (3.3639)	Learning Rate [0.000625]
13: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 70179 (54131)	Loss/tok 3.3192 (3.3646)	Learning Rate [0.000625]
15: TRAIN [1][2770/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00091)	Tok/s 70916 (54337)	Loss/tok 3.5305 (3.3651)	Learning Rate [0.000625]
14: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 70846 (54227)	Loss/tok 3.5293 (3.3651)	Learning Rate [0.000625]
10: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 69799 (53849)	Loss/tok 3.4188 (3.3645)	Learning Rate [0.000625]
0: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00099)	Tok/s 69051 (53012)	Loss/tok 3.5289 (3.3676)	Learning Rate [0.000625]
1: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 69037 (53112)	Loss/tok 3.4562 (3.3726)	Learning Rate [0.000625]
9: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00091)	Tok/s 69733 (53771)	Loss/tok 3.4041 (3.3585)	Learning Rate [0.000625]
8: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 69763 (53712)	Loss/tok 3.5952 (3.3706)	Learning Rate [0.000625]
2: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 69739 (53210)	Loss/tok 3.5279 (3.3738)	Learning Rate [0.000625]
7: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 69755 (53633)	Loss/tok 3.4364 (3.3672)	Learning Rate [0.000625]
6: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 69724 (53544)	Loss/tok 3.4079 (3.3669)	Learning Rate [0.000625]
5: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 69707 (53469)	Loss/tok 3.6244 (3.3675)	Learning Rate [0.000625]
4: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00100)	Tok/s 69765 (53391)	Loss/tok 3.2865 (3.3674)	Learning Rate [0.000625]
3: TRAIN [1][2770/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00093)	Tok/s 69866 (53298)	Loss/tok 3.2890 (3.3644)	Learning Rate [0.000625]
2: TRAIN [1][2780/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00097)	Tok/s 51425 (53189)	Loss/tok 3.3275 (3.3736)	Learning Rate [0.000625]
1: TRAIN [1][2780/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00097)	Tok/s 51349 (53092)	Loss/tok 3.4521 (3.3722)	Learning Rate [0.000625]
0: TRAIN [1][2780/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00099)	Tok/s 51343 (52992)	Loss/tok 3.4407 (3.3676)	Learning Rate [0.000625]
4: TRAIN [1][2780/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00100)	Tok/s 52466 (53371)	Loss/tok 3.3943 (3.3669)	Learning Rate [0.000625]
15: TRAIN [1][2780/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00091)	Tok/s 52450 (54317)	Loss/tok 3.5347 (3.3648)	Learning Rate [0.000625]
5: TRAIN [1][2780/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00092)	Tok/s 52569 (53449)	Loss/tok 3.5016 (3.3673)	Learning Rate [0.000625]
6: TRAIN [1][2780/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00091)	Tok/s 52569 (53524)	Loss/tok 3.4004 (3.3665)	Learning Rate [0.000625]
14: TRAIN [1][2780/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00092)	Tok/s 52442 (54207)	Loss/tok 3.5926 (3.3648)	Learning Rate [0.000625]
13: TRAIN [1][2780/3416]	Time 0.059 (0.058)	Data 0.00119 (0.00097)	Tok/s 52483 (54111)	Loss/tok 3.0197 (3.3642)	Learning Rate [0.000625]
7: TRAIN [1][2780/3416]	Time 0.058 (0.058)	Data 0.00107 (0.00097)	Tok/s 52554 (53613)	Loss/tok 3.4571 (3.3672)	Learning Rate [0.000625]
11: TRAIN [1][2780/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00091)	Tok/s 52512 (53911)	Loss/tok 3.2003 (3.3637)	Learning Rate [0.000625]
8: TRAIN [1][2780/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00096)	Tok/s 52556 (53693)	Loss/tok 3.5500 (3.3704)	Learning Rate [0.000625]
12: TRAIN [1][2780/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00096)	Tok/s 52556 (54015)	Loss/tok 3.2170 (3.3628)	Learning Rate [0.000625]
9: TRAIN [1][2780/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00091)	Tok/s 52512 (53751)	Loss/tok 3.3332 (3.3584)	Learning Rate [0.000625]
3: TRAIN [1][2780/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00093)	Tok/s 51898 (53278)	Loss/tok 3.2983 (3.3641)	Learning Rate [0.000625]
10: TRAIN [1][2780/3416]	Time 0.059 (0.058)	Data 0.00115 (0.00096)	Tok/s 52437 (53830)	Loss/tok 3.5401 (3.3640)	Learning Rate [0.000625]
6: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 77300 (53540)	Loss/tok 3.5614 (3.3664)	Learning Rate [0.000625]
5: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 77279 (53466)	Loss/tok 3.0827 (3.3670)	Learning Rate [0.000625]
7: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 77185 (53630)	Loss/tok 3.2755 (3.3669)	Learning Rate [0.000625]
4: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 77310 (53389)	Loss/tok 3.4151 (3.3669)	Learning Rate [0.000625]
8: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 77160 (53709)	Loss/tok 3.2238 (3.3701)	Learning Rate [0.000625]
3: TRAIN [1][2790/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00093)	Tok/s 77751 (53295)	Loss/tok 3.3170 (3.3636)	Learning Rate [0.000625]
9: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 77168 (53767)	Loss/tok 3.3425 (3.3581)	Learning Rate [0.000625]
2: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 77323 (53207)	Loss/tok 3.2943 (3.3733)	Learning Rate [0.000625]
1: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 76492 (53109)	Loss/tok 3.3712 (3.3721)	Learning Rate [0.000625]
10: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 77243 (53846)	Loss/tok 3.2725 (3.3639)	Learning Rate [0.000625]
0: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00099)	Tok/s 76389 (53010)	Loss/tok 3.2806 (3.3677)	Learning Rate [0.000625]
11: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00091)	Tok/s 78102 (53928)	Loss/tok 3.4041 (3.3637)	Learning Rate [0.000625]
12: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00119 (0.00096)	Tok/s 78106 (54032)	Loss/tok 3.2451 (3.3624)	Learning Rate [0.000625]
13: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00097)	Tok/s 78146 (54127)	Loss/tok 3.1605 (3.3642)	Learning Rate [0.000625]
15: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00091)	Tok/s 78194 (54333)	Loss/tok 3.2430 (3.3646)	Learning Rate [0.000625]
14: TRAIN [1][2790/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 78138 (54224)	Loss/tok 3.2886 (3.3646)	Learning Rate [0.000625]
6: TRAIN [1][2800/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00091)	Tok/s 31231 (53530)	Loss/tok 2.7883 (3.3662)	Learning Rate [0.000625]
7: TRAIN [1][2800/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00097)	Tok/s 31179 (53619)	Loss/tok 2.6153 (3.3665)	Learning Rate [0.000625]
5: TRAIN [1][2800/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00092)	Tok/s 31114 (53455)	Loss/tok 2.8533 (3.3668)	Learning Rate [0.000625]
4: TRAIN [1][2800/3416]	Time 0.045 (0.058)	Data 0.00107 (0.00100)	Tok/s 31018 (53378)	Loss/tok 2.9101 (3.3669)	Learning Rate [0.000625]
8: TRAIN [1][2800/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00096)	Tok/s 31135 (53698)	Loss/tok 2.8622 (3.3701)	Learning Rate [0.000625]
3: TRAIN [1][2800/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00093)	Tok/s 30958 (53285)	Loss/tok 2.8476 (3.3632)	Learning Rate [0.000625]
9: TRAIN [1][2800/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00091)	Tok/s 31069 (53756)	Loss/tok 2.8837 (3.3578)	Learning Rate [0.000625]
2: TRAIN [1][2800/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00097)	Tok/s 30855 (53197)	Loss/tok 2.7762 (3.3731)	Learning Rate [0.000625]
1: TRAIN [1][2800/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00097)	Tok/s 30791 (53099)	Loss/tok 3.0255 (3.3719)	Learning Rate [0.000625]
10: TRAIN [1][2800/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00096)	Tok/s 30958 (53834)	Loss/tok 3.0387 (3.3634)	Learning Rate [0.000625]
0: TRAIN [1][2800/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00099)	Tok/s 30101 (53000)	Loss/tok 2.6795 (3.3674)	Learning Rate [0.000625]
11: TRAIN [1][2800/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00091)	Tok/s 30918 (53916)	Loss/tok 2.8641 (3.3632)	Learning Rate [0.000625]
12: TRAIN [1][2800/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00096)	Tok/s 30888 (54020)	Loss/tok 2.7235 (3.3622)	Learning Rate [0.000625]
15: TRAIN [1][2800/3416]	Time 0.046 (0.058)	Data 0.00081 (0.00091)	Tok/s 32147 (54321)	Loss/tok 2.9652 (3.3644)	Learning Rate [0.000625]
13: TRAIN [1][2800/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00097)	Tok/s 31727 (54116)	Loss/tok 2.5596 (3.3640)	Learning Rate [0.000625]
14: TRAIN [1][2800/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00092)	Tok/s 32121 (54212)	Loss/tok 2.9663 (3.3642)	Learning Rate [0.000625]
6: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00091)	Tok/s 51943 (53545)	Loss/tok 3.2883 (3.3660)	Learning Rate [0.000625]
5: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00092)	Tok/s 52013 (53471)	Loss/tok 3.4583 (3.3664)	Learning Rate [0.000625]
7: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00097)	Tok/s 51971 (53634)	Loss/tok 3.2516 (3.3663)	Learning Rate [0.000625]
4: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00100)	Tok/s 52005 (53393)	Loss/tok 3.3885 (3.3664)	Learning Rate [0.000625]
8: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00096)	Tok/s 51944 (53713)	Loss/tok 2.9174 (3.3696)	Learning Rate [0.000625]
3: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00093)	Tok/s 52018 (53299)	Loss/tok 3.4508 (3.3630)	Learning Rate [0.000625]
13: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00097)	Tok/s 53154 (54130)	Loss/tok 3.5190 (3.3638)	Learning Rate [0.000625]
2: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00097)	Tok/s 52031 (53211)	Loss/tok 3.3736 (3.3730)	Learning Rate [0.000625]
1: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00097)	Tok/s 51994 (53114)	Loss/tok 3.2566 (3.3718)	Learning Rate [0.000625]
10: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00096)	Tok/s 51857 (53849)	Loss/tok 3.3747 (3.3633)	Learning Rate [0.000625]
14: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00092)	Tok/s 53134 (54226)	Loss/tok 3.3402 (3.3642)	Learning Rate [0.000625]
11: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00091)	Tok/s 51787 (53931)	Loss/tok 3.3976 (3.3627)	Learning Rate [0.000625]
12: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00096)	Tok/s 52437 (54034)	Loss/tok 3.3191 (3.3621)	Learning Rate [0.000625]
0: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00099)	Tok/s 51968 (53015)	Loss/tok 3.3982 (3.3672)	Learning Rate [0.000625]
9: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00123 (0.00091)	Tok/s 51995 (53771)	Loss/tok 3.2876 (3.3575)	Learning Rate [0.000625]
15: TRAIN [1][2810/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00091)	Tok/s 53134 (54335)	Loss/tok 3.4359 (3.3643)	Learning Rate [0.000625]
3: TRAIN [1][2820/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00093)	Tok/s 65734 (53321)	Loss/tok 3.1949 (3.3630)	Learning Rate [0.000625]
2: TRAIN [1][2820/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00097)	Tok/s 65714 (53233)	Loss/tok 3.4350 (3.3729)	Learning Rate [0.000625]
1: TRAIN [1][2820/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00097)	Tok/s 65753 (53136)	Loss/tok 3.4411 (3.3716)	Learning Rate [0.000625]
4: TRAIN [1][2820/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00100)	Tok/s 65501 (53414)	Loss/tok 3.4488 (3.3661)	Learning Rate [0.000625]
0: TRAIN [1][2820/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00099)	Tok/s 65719 (53036)	Loss/tok 3.4440 (3.3672)	Learning Rate [0.000625]
5: TRAIN [1][2820/3416]	Time 0.068 (0.058)	Data 0.00081 (0.00092)	Tok/s 65541 (53491)	Loss/tok 3.2372 (3.3660)	Learning Rate [0.000625]
6: TRAIN [1][2820/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 65358 (53565)	Loss/tok 3.3918 (3.3657)	Learning Rate [0.000625]
15: TRAIN [1][2820/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00091)	Tok/s 66610 (54356)	Loss/tok 3.4126 (3.3639)	Learning Rate [0.000625]
7: TRAIN [1][2820/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 65318 (53654)	Loss/tok 3.3761 (3.3662)	Learning Rate [0.000625]
8: TRAIN [1][2820/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 65221 (53733)	Loss/tok 3.3664 (3.3701)	Learning Rate [0.000625]
14: TRAIN [1][2820/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00092)	Tok/s 66511 (54246)	Loss/tok 3.4385 (3.3640)	Learning Rate [0.000625]
13: TRAIN [1][2820/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00097)	Tok/s 65637 (54150)	Loss/tok 3.4124 (3.3636)	Learning Rate [0.000625]
9: TRAIN [1][2820/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 65241 (53791)	Loss/tok 3.4659 (3.3572)	Learning Rate [0.000625]
11: TRAIN [1][2820/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00091)	Tok/s 65320 (53951)	Loss/tok 3.3381 (3.3626)	Learning Rate [0.000625]
12: TRAIN [1][2820/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 65381 (54055)	Loss/tok 3.2246 (3.3619)	Learning Rate [0.000625]
10: TRAIN [1][2820/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 65141 (53869)	Loss/tok 3.6094 (3.3632)	Learning Rate [0.000625]
13: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00097)	Tok/s 53021 (54161)	Loss/tok 3.2246 (3.3632)	Learning Rate [0.000625]
9: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00091)	Tok/s 53018 (53803)	Loss/tok 3.2445 (3.3571)	Learning Rate [0.000625]
14: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00111 (0.00092)	Tok/s 53018 (54257)	Loss/tok 3.1315 (3.3639)	Learning Rate [0.000625]
12: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00096)	Tok/s 52917 (54066)	Loss/tok 3.0910 (3.3614)	Learning Rate [0.000625]
2: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00097)	Tok/s 52935 (53245)	Loss/tok 3.1507 (3.3725)	Learning Rate [0.000625]
11: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00115 (0.00091)	Tok/s 52923 (53962)	Loss/tok 3.2397 (3.3624)	Learning Rate [0.000625]
15: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00112 (0.00091)	Tok/s 52934 (54367)	Loss/tok 3.4949 (3.3637)	Learning Rate [0.000625]
6: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00091)	Tok/s 53052 (53576)	Loss/tok 3.0528 (3.3654)	Learning Rate [0.000625]
0: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00099)	Tok/s 51938 (53048)	Loss/tok 3.1174 (3.3668)	Learning Rate [0.000625]
1: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00097)	Tok/s 52449 (53148)	Loss/tok 3.2902 (3.3712)	Learning Rate [0.000625]
8: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00096)	Tok/s 52936 (53745)	Loss/tok 3.1696 (3.3700)	Learning Rate [0.000625]
10: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00133 (0.00096)	Tok/s 52972 (53881)	Loss/tok 3.3112 (3.3630)	Learning Rate [0.000625]
4: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00100)	Tok/s 53012 (53425)	Loss/tok 3.2592 (3.3659)	Learning Rate [0.000625]
7: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00097)	Tok/s 52967 (53665)	Loss/tok 3.1469 (3.3658)	Learning Rate [0.000625]
3: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00093)	Tok/s 52847 (53332)	Loss/tok 3.0276 (3.3626)	Learning Rate [0.000625]
5: TRAIN [1][2830/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00092)	Tok/s 52841 (53502)	Loss/tok 3.5128 (3.3659)	Learning Rate [0.000625]
2: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00097)	Tok/s 58850 (53233)	Loss/tok 3.2122 (3.3721)	Learning Rate [0.000625]
1: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00097)	Tok/s 58881 (53136)	Loss/tok 3.2749 (3.3708)	Learning Rate [0.000625]
14: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00092)	Tok/s 59812 (54245)	Loss/tok 3.2609 (3.3635)	Learning Rate [0.000625]
12: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00096)	Tok/s 59547 (54053)	Loss/tok 3.3620 (3.3611)	Learning Rate [0.000625]
9: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00091)	Tok/s 58878 (53790)	Loss/tok 3.4446 (3.3568)	Learning Rate [0.000625]
0: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00099)	Tok/s 58901 (53037)	Loss/tok 3.6236 (3.3666)	Learning Rate [0.000625]
6: TRAIN [1][2840/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00091)	Tok/s 58736 (53564)	Loss/tok 3.5936 (3.3651)	Learning Rate [0.000625]
11: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00091)	Tok/s 58938 (53949)	Loss/tok 3.7465 (3.3621)	Learning Rate [0.000625]
15: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00091)	Tok/s 59838 (54354)	Loss/tok 3.4237 (3.3635)	Learning Rate [0.000625]
8: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00096)	Tok/s 58965 (53733)	Loss/tok 3.3108 (3.3696)	Learning Rate [0.000625]
5: TRAIN [1][2840/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 58752 (53490)	Loss/tok 3.4832 (3.3655)	Learning Rate [0.000625]
13: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00097)	Tok/s 59876 (54149)	Loss/tok 3.4452 (3.3631)	Learning Rate [0.000625]
7: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00097)	Tok/s 58854 (53653)	Loss/tok 3.3367 (3.3655)	Learning Rate [0.000625]
10: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00107 (0.00096)	Tok/s 58928 (53868)	Loss/tok 3.5627 (3.3629)	Learning Rate [0.000625]
3: TRAIN [1][2840/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 58738 (53321)	Loss/tok 3.2024 (3.3622)	Learning Rate [0.000625]
4: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00100)	Tok/s 58788 (53413)	Loss/tok 3.2467 (3.3655)	Learning Rate [0.000625]
4: TRAIN [1][2850/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00100)	Tok/s 75495 (53424)	Loss/tok 3.1752 (3.3653)	Learning Rate [0.000625]
5: TRAIN [1][2850/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 75572 (53501)	Loss/tok 3.3899 (3.3656)	Learning Rate [0.000625]
6: TRAIN [1][2850/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00091)	Tok/s 75611 (53575)	Loss/tok 3.2314 (3.3649)	Learning Rate [0.000625]
2: TRAIN [1][2850/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 75477 (53236)	Loss/tok 3.4737 (3.3724)	Learning Rate [0.000625]
3: TRAIN [1][2850/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00093)	Tok/s 75457 (53332)	Loss/tok 3.0594 (3.3620)	Learning Rate [0.000625]
9: TRAIN [1][2850/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00091)	Tok/s 76530 (53801)	Loss/tok 3.2892 (3.3568)	Learning Rate [0.000625]
7: TRAIN [1][2850/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 75655 (53663)	Loss/tok 3.0670 (3.3652)	Learning Rate [0.000625]
8: TRAIN [1][2850/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 75803 (53743)	Loss/tok 3.1650 (3.3691)	Learning Rate [0.000625]
1: TRAIN [1][2850/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 75393 (53139)	Loss/tok 3.4511 (3.3707)	Learning Rate [0.000625]
11: TRAIN [1][2850/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00091)	Tok/s 76580 (53959)	Loss/tok 3.2778 (3.3615)	Learning Rate [0.000625]
0: TRAIN [1][2850/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 75460 (53048)	Loss/tok 3.2568 (3.3664)	Learning Rate [0.000625]
15: TRAIN [1][2850/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00091)	Tok/s 76383 (54364)	Loss/tok 3.1790 (3.3628)	Learning Rate [0.000625]
13: TRAIN [1][2850/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 76567 (54159)	Loss/tok 3.2220 (3.3631)	Learning Rate [0.000625]
14: TRAIN [1][2850/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 76416 (54255)	Loss/tok 3.1099 (3.3633)	Learning Rate [0.000625]
12: TRAIN [1][2850/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 76432 (54063)	Loss/tok 3.4494 (3.3612)	Learning Rate [0.000625]
10: TRAIN [1][2850/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 76567 (53878)	Loss/tok 3.3423 (3.3624)	Learning Rate [0.000625]
14: TRAIN [1][2860/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 69306 (54282)	Loss/tok 3.3658 (3.3635)	Learning Rate [0.000625]
0: TRAIN [1][2860/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00099)	Tok/s 68219 (53075)	Loss/tok 3.5860 (3.3662)	Learning Rate [0.000625]
1: TRAIN [1][2860/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 68208 (53166)	Loss/tok 3.6282 (3.3711)	Learning Rate [0.000625]
2: TRAIN [1][2860/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 68264 (53263)	Loss/tok 3.4088 (3.3721)	Learning Rate [0.000625]
15: TRAIN [1][2860/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00091)	Tok/s 69955 (54391)	Loss/tok 3.2764 (3.3625)	Learning Rate [0.000625]
3: TRAIN [1][2860/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 69002 (53359)	Loss/tok 3.3260 (3.3619)	Learning Rate [0.000625]
12: TRAIN [1][2860/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00096)	Tok/s 69060 (54090)	Loss/tok 3.3121 (3.3609)	Learning Rate [0.000625]
13: TRAIN [1][2860/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 68904 (54186)	Loss/tok 3.4322 (3.3635)	Learning Rate [0.000625]
4: TRAIN [1][2860/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00100)	Tok/s 68998 (53451)	Loss/tok 3.3166 (3.3652)	Learning Rate [0.000625]
9: TRAIN [1][2860/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 69061 (53827)	Loss/tok 3.2118 (3.3568)	Learning Rate [0.000625]
5: TRAIN [1][2860/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 68948 (53528)	Loss/tok 3.2086 (3.3653)	Learning Rate [0.000625]
11: TRAIN [1][2860/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00091)	Tok/s 68962 (53985)	Loss/tok 3.2832 (3.3615)	Learning Rate [0.000625]
6: TRAIN [1][2860/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00091)	Tok/s 68812 (53602)	Loss/tok 3.3851 (3.3653)	Learning Rate [0.000625]
8: TRAIN [1][2860/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 68864 (53769)	Loss/tok 3.7055 (3.3693)	Learning Rate [0.000625]
7: TRAIN [1][2860/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 68816 (53690)	Loss/tok 3.4654 (3.3649)	Learning Rate [0.000625]
10: TRAIN [1][2860/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00096)	Tok/s 68947 (53904)	Loss/tok 3.6374 (3.3627)	Learning Rate [0.000625]
9: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00091)	Tok/s 56377 (53834)	Loss/tok 3.7388 (3.3570)	Learning Rate [0.000625]
10: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00096)	Tok/s 56345 (53911)	Loss/tok 3.5418 (3.3627)	Learning Rate [0.000625]
11: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00091)	Tok/s 56337 (53992)	Loss/tok 3.3311 (3.3615)	Learning Rate [0.000625]
8: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00096)	Tok/s 56369 (53776)	Loss/tok 3.3575 (3.3693)	Learning Rate [0.000625]
7: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00097)	Tok/s 56364 (53697)	Loss/tok 3.3514 (3.3645)	Learning Rate [0.000625]
12: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00096)	Tok/s 56362 (54096)	Loss/tok 3.3748 (3.3611)	Learning Rate [0.000625]
6: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00091)	Tok/s 56355 (53609)	Loss/tok 3.2838 (3.3651)	Learning Rate [0.000625]
13: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00097)	Tok/s 56353 (54192)	Loss/tok 3.4981 (3.3637)	Learning Rate [0.000625]
14: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00092)	Tok/s 56365 (54288)	Loss/tok 3.3097 (3.3633)	Learning Rate [0.000625]
5: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 55781 (53535)	Loss/tok 3.3428 (3.3654)	Learning Rate [0.000625]
15: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00091)	Tok/s 56366 (54397)	Loss/tok 3.2206 (3.3625)	Learning Rate [0.000625]
1: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00097)	Tok/s 55423 (53173)	Loss/tok 3.4023 (3.3709)	Learning Rate [0.000625]
4: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00109 (0.00100)	Tok/s 55412 (53458)	Loss/tok 3.4051 (3.3649)	Learning Rate [0.000625]
0: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00099)	Tok/s 55452 (53083)	Loss/tok 3.2207 (3.3660)	Learning Rate [0.000625]
3: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 55419 (53366)	Loss/tok 3.3616 (3.3619)	Learning Rate [0.000625]
2: TRAIN [1][2870/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00097)	Tok/s 55415 (53270)	Loss/tok 3.2970 (3.3720)	Learning Rate [0.000625]
4: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
9: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00091)	Tok/s 61644 (53836)	Loss/tok 3.4366 (3.3569)	Learning Rate [0.000625]
10: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00096)	Tok/s 61661 (53914)	Loss/tok 3.5000 (3.3629)	Learning Rate [0.000625]
8: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 61547 (53778)	Loss/tok 3.4733 (3.3692)	Learning Rate [0.000625]
11: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00091)	Tok/s 61600 (53994)	Loss/tok 3.4683 (3.3615)	Learning Rate [0.000625]
7: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00097)	Tok/s 61442 (53700)	Loss/tok 3.6311 (3.3645)	Learning Rate [0.000625]
12: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 61480 (54099)	Loss/tok 3.2283 (3.3609)	Learning Rate [0.000625]
13: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 61386 (54195)	Loss/tok 3.5725 (3.3638)	Learning Rate [0.000625]
6: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00091)	Tok/s 61351 (53612)	Loss/tok 3.5154 (3.3650)	Learning Rate [0.000625]
14: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00092)	Tok/s 61422 (54290)	Loss/tok 3.5079 (3.3633)	Learning Rate [0.000625]
15: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00091)	Tok/s 62140 (54399)	Loss/tok 3.2812 (3.3622)	Learning Rate [0.000625]
5: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00092)	Tok/s 61246 (53538)	Loss/tok 3.5230 (3.3654)	Learning Rate [0.000625]
1: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 61034 (53176)	Loss/tok 3.3555 (3.3706)	Learning Rate [0.000625]
4: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00100)	Tok/s 61125 (53461)	Loss/tok 3.3470 (3.3646)	Learning Rate [0.000625]
3: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00093)	Tok/s 61064 (53369)	Loss/tok 3.4868 (3.3618)	Learning Rate [0.000625]
2: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 60952 (53273)	Loss/tok 3.4504 (3.3720)	Learning Rate [0.000625]
0: TRAIN [1][2880/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 61013 (53086)	Loss/tok 3.3666 (3.3657)	Learning Rate [0.000625]
6: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00091)	Tok/s 32910 (53610)	Loss/tok 3.0763 (3.3646)	Learning Rate [0.000625]
7: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 32948 (53697)	Loss/tok 3.1268 (3.3643)	Learning Rate [0.000625]
5: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00080 (0.00092)	Tok/s 32878 (53536)	Loss/tok 2.8686 (3.3650)	Learning Rate [0.000625]
4: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00100)	Tok/s 32810 (53459)	Loss/tok 2.9587 (3.3644)	Learning Rate [0.000625]
8: TRAIN [1][2890/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00096)	Tok/s 32961 (53776)	Loss/tok 2.8666 (3.3686)	Learning Rate [0.000625]
2: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00097)	Tok/s 32813 (53271)	Loss/tok 3.0529 (3.3716)	Learning Rate [0.000625]
3: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00093)	Tok/s 32793 (53367)	Loss/tok 3.0723 (3.3614)	Learning Rate [0.000625]
9: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00091)	Tok/s 32942 (53833)	Loss/tok 3.0328 (3.3566)	Learning Rate [0.000625]
1: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00097)	Tok/s 32798 (53175)	Loss/tok 2.8095 (3.3701)	Learning Rate [0.000625]
10: TRAIN [1][2890/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00096)	Tok/s 32970 (53911)	Loss/tok 2.6962 (3.3625)	Learning Rate [0.000625]
11: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00091)	Tok/s 32939 (53992)	Loss/tok 3.0755 (3.3613)	Learning Rate [0.000625]
0: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00099)	Tok/s 32779 (53085)	Loss/tok 3.1741 (3.3653)	Learning Rate [0.000625]
15: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00091)	Tok/s 34059 (54397)	Loss/tok 2.9791 (3.3622)	Learning Rate [0.000625]
14: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00092)	Tok/s 34076 (54288)	Loss/tok 2.9532 (3.3628)	Learning Rate [0.000625]
12: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00096)	Tok/s 33735 (54097)	Loss/tok 2.9475 (3.3605)	Learning Rate [0.000625]
13: TRAIN [1][2890/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 34068 (54193)	Loss/tok 3.3753 (3.3637)	Learning Rate [0.000625]
11: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00091)	Tok/s 54873 (53996)	Loss/tok 3.3530 (3.3612)	Learning Rate [0.000625]
9: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00091)	Tok/s 54827 (53837)	Loss/tok 3.4614 (3.3564)	Learning Rate [0.000625]
10: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00096)	Tok/s 54862 (53915)	Loss/tok 3.5657 (3.3626)	Learning Rate [0.000625]
8: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00100 (0.00096)	Tok/s 54822 (53780)	Loss/tok 3.4829 (3.3687)	Learning Rate [0.000625]
12: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00096)	Tok/s 54863 (54101)	Loss/tok 3.3541 (3.3603)	Learning Rate [0.000625]
7: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00097)	Tok/s 54854 (53701)	Loss/tok 3.1647 (3.3639)	Learning Rate [0.000625]
6: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00091)	Tok/s 54888 (53613)	Loss/tok 3.3774 (3.3646)	Learning Rate [0.000625]
13: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00097)	Tok/s 54845 (54197)	Loss/tok 3.1534 (3.3634)	Learning Rate [0.000625]
14: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00092)	Tok/s 54885 (54292)	Loss/tok 3.1468 (3.3627)	Learning Rate [0.000625]
5: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00092)	Tok/s 54915 (53539)	Loss/tok 3.2852 (3.3651)	Learning Rate [0.000625]
15: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00091)	Tok/s 54883 (54401)	Loss/tok 3.6537 (3.3623)	Learning Rate [0.000625]
2: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00100 (0.00097)	Tok/s 54943 (53272)	Loss/tok 3.3138 (3.3718)	Learning Rate [0.000625]
0: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00099)	Tok/s 54881 (53085)	Loss/tok 3.3433 (3.3655)	Learning Rate [0.000625]
3: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00093)	Tok/s 54900 (53369)	Loss/tok 3.4618 (3.3616)	Learning Rate [0.000625]
4: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00100 (0.00100)	Tok/s 54859 (53461)	Loss/tok 3.2997 (3.3644)	Learning Rate [0.000625]
1: TRAIN [1][2900/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00097)	Tok/s 54887 (53175)	Loss/tok 3.4832 (3.3699)	Learning Rate [0.000625]
5: TRAIN [1][2910/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00092)	Tok/s 54475 (53538)	Loss/tok 3.5824 (3.3651)	Learning Rate [0.000625]
4: TRAIN [1][2910/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00100)	Tok/s 54373 (53460)	Loss/tok 3.3668 (3.3643)	Learning Rate [0.000625]
6: TRAIN [1][2910/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00091)	Tok/s 54405 (53612)	Loss/tok 3.1898 (3.3645)	Learning Rate [0.000625]
3: TRAIN [1][2910/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 54244 (53368)	Loss/tok 3.4267 (3.3614)	Learning Rate [0.000625]
7: TRAIN [1][2910/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00097)	Tok/s 54420 (53700)	Loss/tok 3.4685 (3.3639)	Learning Rate [0.000625]
2: TRAIN [1][2910/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 54168 (53272)	Loss/tok 3.2763 (3.3715)	Learning Rate [0.000625]
8: TRAIN [1][2910/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00096)	Tok/s 54484 (53779)	Loss/tok 3.5782 (3.3687)	Learning Rate [0.000625]
1: TRAIN [1][2910/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 54065 (53175)	Loss/tok 3.5158 (3.3699)	Learning Rate [0.000625]
0: TRAIN [1][2910/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00099)	Tok/s 54063 (53084)	Loss/tok 3.5133 (3.3654)	Learning Rate [0.000625]
9: TRAIN [1][2910/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00091)	Tok/s 54368 (53836)	Loss/tok 3.3046 (3.3565)	Learning Rate [0.000625]
11: TRAIN [1][2910/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00091)	Tok/s 54218 (53994)	Loss/tok 3.2512 (3.3610)	Learning Rate [0.000625]
15: TRAIN [1][2910/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 54988 (54400)	Loss/tok 3.5584 (3.3622)	Learning Rate [0.000625]
10: TRAIN [1][2910/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00096)	Tok/s 54265 (53914)	Loss/tok 3.1405 (3.3625)	Learning Rate [0.000625]
14: TRAIN [1][2910/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 54705 (54290)	Loss/tok 3.1967 (3.3624)	Learning Rate [0.000625]
12: TRAIN [1][2910/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 54127 (54100)	Loss/tok 3.3784 (3.3603)	Learning Rate [0.000625]
13: TRAIN [1][2910/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 54012 (54195)	Loss/tok 3.5612 (3.3633)	Learning Rate [0.000625]
5: TRAIN [1][2920/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00092)	Tok/s 33400 (53523)	Loss/tok 2.9687 (3.3645)	Learning Rate [0.000625]
6: TRAIN [1][2920/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00091)	Tok/s 33391 (53597)	Loss/tok 3.0485 (3.3641)	Learning Rate [0.000625]
4: TRAIN [1][2920/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00100)	Tok/s 32729 (53446)	Loss/tok 3.2627 (3.3641)	Learning Rate [0.000625]
3: TRAIN [1][2920/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00093)	Tok/s 32688 (53354)	Loss/tok 2.8826 (3.3609)	Learning Rate [0.000625]
7: TRAIN [1][2920/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 32743 (53685)	Loss/tok 3.1191 (3.3634)	Learning Rate [0.000625]
2: TRAIN [1][2920/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00097)	Tok/s 32645 (53258)	Loss/tok 2.8334 (3.3710)	Learning Rate [0.000625]
8: TRAIN [1][2920/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00096)	Tok/s 32685 (53764)	Loss/tok 2.9668 (3.3687)	Learning Rate [0.000625]
9: TRAIN [1][2920/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00091)	Tok/s 32601 (53821)	Loss/tok 2.8950 (3.3561)	Learning Rate [0.000625]
1: TRAIN [1][2920/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00097)	Tok/s 32550 (53161)	Loss/tok 3.0461 (3.3696)	Learning Rate [0.000625]
0: TRAIN [1][2920/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00099)	Tok/s 32459 (53070)	Loss/tok 3.0120 (3.3650)	Learning Rate [0.000625]
15: TRAIN [1][2920/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00091)	Tok/s 33645 (54385)	Loss/tok 3.0182 (3.3619)	Learning Rate [0.000625]
11: TRAIN [1][2920/3416]	Time 0.051 (0.058)	Data 0.00077 (0.00091)	Tok/s 32534 (53979)	Loss/tok 3.0188 (3.3606)	Learning Rate [0.000625]
10: TRAIN [1][2920/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00096)	Tok/s 32512 (53899)	Loss/tok 2.8390 (3.3623)	Learning Rate [0.000625]
14: TRAIN [1][2920/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00092)	Tok/s 33572 (54276)	Loss/tok 3.1606 (3.3622)	Learning Rate [0.000625]
12: TRAIN [1][2920/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00096)	Tok/s 33619 (54085)	Loss/tok 3.0573 (3.3601)	Learning Rate [0.000625]
13: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00097)	Tok/s 33514 (54181)	Loss/tok 3.1086 (3.3631)	Learning Rate [0.000625]
3: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 54899 (53345)	Loss/tok 3.2694 (3.3608)	Learning Rate [0.000625]
2: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00097)	Tok/s 54874 (53250)	Loss/tok 3.2612 (3.3705)	Learning Rate [0.000625]
1: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00097)	Tok/s 54796 (53152)	Loss/tok 3.3659 (3.3693)	Learning Rate [0.000625]
4: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00100)	Tok/s 54769 (53437)	Loss/tok 3.2002 (3.3639)	Learning Rate [0.000625]
0: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00099)	Tok/s 54396 (53062)	Loss/tok 3.6323 (3.3648)	Learning Rate [0.000625]
6: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00091)	Tok/s 54668 (53588)	Loss/tok 3.6160 (3.3640)	Learning Rate [0.000625]
5: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00081 (0.00092)	Tok/s 54747 (53514)	Loss/tok 3.5555 (3.3644)	Learning Rate [0.000625]
15: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00091)	Tok/s 54648 (54375)	Loss/tok 3.0814 (3.3616)	Learning Rate [0.000625]
7: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00097)	Tok/s 54586 (53676)	Loss/tok 3.3193 (3.3632)	Learning Rate [0.000625]
14: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00092)	Tok/s 54560 (54266)	Loss/tok 3.5568 (3.3620)	Learning Rate [0.000625]
9: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00091)	Tok/s 54442 (53812)	Loss/tok 3.4135 (3.3560)	Learning Rate [0.000625]
8: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00096)	Tok/s 54509 (53755)	Loss/tok 3.3841 (3.3683)	Learning Rate [0.000625]
13: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00097)	Tok/s 54434 (54171)	Loss/tok 3.5226 (3.3632)	Learning Rate [0.000625]
11: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00091)	Tok/s 54305 (53970)	Loss/tok 3.5582 (3.3605)	Learning Rate [0.000625]
12: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00096)	Tok/s 54372 (54076)	Loss/tok 3.4959 (3.3603)	Learning Rate [0.000625]
10: TRAIN [1][2930/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00096)	Tok/s 54312 (53890)	Loss/tok 3.6192 (3.3622)	Learning Rate [0.000625]
5: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00087 (0.00092)	Tok/s 30059 (53494)	Loss/tok 2.8969 (3.3641)	Learning Rate [0.000625]
6: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00084 (0.00091)	Tok/s 31163 (53568)	Loss/tok 2.6932 (3.3637)	Learning Rate [0.000625]
4: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00105 (0.00100)	Tok/s 30050 (53417)	Loss/tok 2.7953 (3.3634)	Learning Rate [0.000625]
3: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00085 (0.00093)	Tok/s 30055 (53326)	Loss/tok 2.7582 (3.3603)	Learning Rate [0.000625]
7: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00087 (0.00097)	Tok/s 31573 (53657)	Loss/tok 2.8409 (3.3629)	Learning Rate [0.000625]
2: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00098 (0.00097)	Tok/s 30058 (53230)	Loss/tok 2.7176 (3.3703)	Learning Rate [0.000625]
9: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00086 (0.00091)	Tok/s 31606 (53793)	Loss/tok 2.7330 (3.3557)	Learning Rate [0.000625]
1: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00091 (0.00097)	Tok/s 30015 (53133)	Loss/tok 2.7014 (3.3690)	Learning Rate [0.000625]
8: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00090 (0.00096)	Tok/s 31571 (53735)	Loss/tok 2.6065 (3.3679)	Learning Rate [0.000625]
0: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00089 (0.00099)	Tok/s 30060 (53043)	Loss/tok 2.8990 (3.3643)	Learning Rate [0.000625]
15: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00091)	Tok/s 31598 (54356)	Loss/tok 2.7444 (3.3611)	Learning Rate [0.000625]
10: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00088 (0.00096)	Tok/s 31584 (53870)	Loss/tok 2.8285 (3.3618)	Learning Rate [0.000625]
14: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00092)	Tok/s 31578 (54247)	Loss/tok 2.6658 (3.3613)	Learning Rate [0.000625]
13: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00097)	Tok/s 31576 (54153)	Loss/tok 2.6887 (3.3627)	Learning Rate [0.000625]
12: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00096)	Tok/s 31517 (54057)	Loss/tok 2.5589 (3.3599)	Learning Rate [0.000625]
11: TRAIN [1][2940/3416]	Time 0.043 (0.058)	Data 0.00086 (0.00091)	Tok/s 31579 (53951)	Loss/tok 2.4865 (3.3603)	Learning Rate [0.000625]
7: Gradient norm: inf
6: Gradient norm: inf
8: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
3: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
7: TRAIN [1][2950/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 87422 (53670)	Loss/tok 3.1596 (3.3624)	Learning Rate [0.000625]
10: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
6: TRAIN [1][2950/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00091)	Tok/s 86629 (53581)	Loss/tok 3.1582 (3.3636)	Learning Rate [0.000625]
3: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
8: TRAIN [1][2950/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00096)	Tok/s 87568 (53749)	Loss/tok 3.0537 (3.3676)	Learning Rate [0.000625]
11: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
9: TRAIN [1][2950/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00091)	Tok/s 88022 (53806)	Loss/tok 3.3188 (3.3554)	Learning Rate [0.000625]
5: TRAIN [1][2950/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 86669 (53507)	Loss/tok 3.0717 (3.3639)	Learning Rate [0.000625]
1: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
4: TRAIN [1][2950/3416]	Time 0.069 (0.058)	Data 0.00121 (0.00100)	Tok/s 86634 (53431)	Loss/tok 3.2075 (3.3629)	Learning Rate [0.000625]
10: TRAIN [1][2950/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 88240 (53884)	Loss/tok 3.1447 (3.3617)	Learning Rate [0.000625]
1: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
15: Gradient norm: inf
14: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
11: TRAIN [1][2950/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00091)	Tok/s 88461 (53965)	Loss/tok 3.2303 (3.3602)	Learning Rate [0.000625]
3: TRAIN [1][2950/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 86212 (53339)	Loss/tok 3.0569 (3.3603)	Learning Rate [0.000625]
15: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
2: TRAIN [1][2950/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 85709 (53244)	Loss/tok 3.3327 (3.3701)	Learning Rate [0.000625]
0: Skipped batch, new scale: 1024.0
12: TRAIN [1][2950/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00096)	Tok/s 88826 (54071)	Loss/tok 3.0447 (3.3598)	Learning Rate [0.000625]
1: TRAIN [1][2950/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 85683 (53147)	Loss/tok 3.1712 (3.3688)	Learning Rate [0.000625]
13: TRAIN [1][2950/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00097)	Tok/s 89261 (54167)	Loss/tok 3.3099 (3.3625)	Learning Rate [0.000625]
14: TRAIN [1][2950/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00092)	Tok/s 89764 (54261)	Loss/tok 3.3979 (3.3612)	Learning Rate [0.000625]
15: TRAIN [1][2950/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00091)	Tok/s 90800 (54370)	Loss/tok 3.2183 (3.3608)	Learning Rate [0.000625]
0: TRAIN [1][2950/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00099)	Tok/s 85616 (53057)	Loss/tok 3.0627 (3.3639)	Learning Rate [0.000625]
13: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00097)	Tok/s 52446 (54162)	Loss/tok 3.2773 (3.3625)	Learning Rate [0.000625]
12: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00096)	Tok/s 52312 (54065)	Loss/tok 3.2560 (3.3596)	Learning Rate [0.000625]
11: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00091)	Tok/s 52270 (53959)	Loss/tok 3.0474 (3.3599)	Learning Rate [0.000625]
0: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00099)	Tok/s 50905 (53053)	Loss/tok 3.0324 (3.3639)	Learning Rate [0.000625]
14: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00092)	Tok/s 52249 (54255)	Loss/tok 2.9970 (3.3609)	Learning Rate [0.000625]
10: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00096)	Tok/s 52156 (53878)	Loss/tok 3.0800 (3.3614)	Learning Rate [0.000625]
15: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00082 (0.00091)	Tok/s 52223 (54364)	Loss/tok 2.9719 (3.3605)	Learning Rate [0.000625]
8: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00096)	Tok/s 52323 (53743)	Loss/tok 3.0618 (3.3676)	Learning Rate [0.000625]
7: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00097)	Tok/s 52296 (53665)	Loss/tok 3.2047 (3.3622)	Learning Rate [0.000625]
6: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00091)	Tok/s 52248 (53576)	Loss/tok 3.0533 (3.3634)	Learning Rate [0.000625]
1: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00097)	Tok/s 51023 (53143)	Loss/tok 3.1597 (3.3684)	Learning Rate [0.000625]
2: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00097)	Tok/s 51030 (53239)	Loss/tok 3.6043 (3.3699)	Learning Rate [0.000625]
5: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00092)	Tok/s 52248 (53502)	Loss/tok 3.3291 (3.3638)	Learning Rate [0.000625]
3: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00093)	Tok/s 51610 (53335)	Loss/tok 3.2592 (3.3601)	Learning Rate [0.000625]
4: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00100)	Tok/s 52162 (53426)	Loss/tok 3.3481 (3.3627)	Learning Rate [0.000625]
9: TRAIN [1][2960/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00091)	Tok/s 52239 (53801)	Loss/tok 3.5312 (3.3554)	Learning Rate [0.000625]
2: TRAIN [1][2970/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 77329 (53251)	Loss/tok 3.1217 (3.3696)	Learning Rate [0.000625]
1: TRAIN [1][2970/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 77010 (53155)	Loss/tok 3.2214 (3.3684)	Learning Rate [0.000625]
8: TRAIN [1][2970/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 77345 (53754)	Loss/tok 3.0191 (3.3672)	Learning Rate [0.000625]
7: TRAIN [1][2970/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 77392 (53675)	Loss/tok 3.2996 (3.3620)	Learning Rate [0.000625]
10: TRAIN [1][2970/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00096)	Tok/s 77650 (53889)	Loss/tok 3.2753 (3.3610)	Learning Rate [0.000625]
3: TRAIN [1][2970/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00093)	Tok/s 77199 (53346)	Loss/tok 3.1932 (3.3600)	Learning Rate [0.000625]
6: TRAIN [1][2970/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00091)	Tok/s 77231 (53587)	Loss/tok 3.2010 (3.3634)	Learning Rate [0.000625]
11: TRAIN [1][2970/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00091)	Tok/s 78106 (53970)	Loss/tok 3.3150 (3.3595)	Learning Rate [0.000625]
0: TRAIN [1][2970/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 76297 (53065)	Loss/tok 3.2285 (3.3639)	Learning Rate [0.000625]
4: TRAIN [1][2970/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00100)	Tok/s 77287 (53437)	Loss/tok 3.2450 (3.3628)	Learning Rate [0.000625]
5: TRAIN [1][2970/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 77224 (53513)	Loss/tok 3.2479 (3.3635)	Learning Rate [0.000625]
14: TRAIN [1][2970/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 78261 (54266)	Loss/tok 3.4848 (3.3607)	Learning Rate [0.000625]
15: TRAIN [1][2970/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00091)	Tok/s 78228 (54374)	Loss/tok 3.2653 (3.3604)	Learning Rate [0.000625]
13: TRAIN [1][2970/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 78274 (54172)	Loss/tok 3.2443 (3.3624)	Learning Rate [0.000625]
12: TRAIN [1][2970/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00096)	Tok/s 78206 (54076)	Loss/tok 3.3329 (3.3595)	Learning Rate [0.000625]
9: TRAIN [1][2970/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 77199 (53811)	Loss/tok 3.1729 (3.3552)	Learning Rate [0.000625]
3: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00080 (0.00093)	Tok/s 50423 (53341)	Loss/tok 3.2626 (3.3600)	Learning Rate [0.000625]
2: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00097)	Tok/s 50425 (53246)	Loss/tok 3.2643 (3.3694)	Learning Rate [0.000625]
4: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00100)	Tok/s 50441 (53432)	Loss/tok 3.1842 (3.3623)	Learning Rate [0.000625]
1: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00097)	Tok/s 50406 (53149)	Loss/tok 3.1302 (3.3680)	Learning Rate [0.000625]
5: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00077 (0.00092)	Tok/s 50405 (53508)	Loss/tok 3.1888 (3.3631)	Learning Rate [0.000625]
0: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00099)	Tok/s 50413 (53060)	Loss/tok 3.1652 (3.3637)	Learning Rate [0.000625]
6: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00082 (0.00091)	Tok/s 50390 (53582)	Loss/tok 3.3457 (3.3634)	Learning Rate [0.000625]
7: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00097)	Tok/s 50461 (53670)	Loss/tok 3.7305 (3.3619)	Learning Rate [0.000625]
14: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00092)	Tok/s 51618 (54261)	Loss/tok 3.2908 (3.3607)	Learning Rate [0.000625]
8: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00096)	Tok/s 50432 (53749)	Loss/tok 3.1628 (3.3669)	Learning Rate [0.000625]
15: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00079 (0.00091)	Tok/s 51613 (54369)	Loss/tok 3.2029 (3.3600)	Learning Rate [0.000625]
11: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00091)	Tok/s 51280 (53965)	Loss/tok 3.3544 (3.3592)	Learning Rate [0.000625]
13: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00097)	Tok/s 51625 (54167)	Loss/tok 3.5059 (3.3623)	Learning Rate [0.000625]
10: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00096)	Tok/s 50498 (53884)	Loss/tok 3.2219 (3.3611)	Learning Rate [0.000625]
12: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00096)	Tok/s 51631 (54071)	Loss/tok 3.6140 (3.3597)	Learning Rate [0.000625]
9: TRAIN [1][2980/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00091)	Tok/s 50424 (53806)	Loss/tok 3.1267 (3.3548)	Learning Rate [0.000625]
13: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00097)	Tok/s 56366 (54143)	Loss/tok 3.4561 (3.3621)	Learning Rate [0.000625]
12: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00105 (0.00096)	Tok/s 56344 (54047)	Loss/tok 3.4889 (3.3595)	Learning Rate [0.000625]
14: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00092)	Tok/s 56216 (54237)	Loss/tok 3.2649 (3.3603)	Learning Rate [0.000625]
11: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00091)	Tok/s 56210 (53941)	Loss/tok 3.4682 (3.3588)	Learning Rate [0.000625]
15: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00091)	Tok/s 56110 (54345)	Loss/tok 3.3503 (3.3596)	Learning Rate [0.000625]
10: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00096)	Tok/s 55920 (53860)	Loss/tok 3.2793 (3.3607)	Learning Rate [0.000625]
0: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00099)	Tok/s 55062 (53037)	Loss/tok 3.4247 (3.3634)	Learning Rate [0.000625]
1: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00097)	Tok/s 54998 (53127)	Loss/tok 3.3962 (3.3679)	Learning Rate [0.000625]
8: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00096)	Tok/s 55119 (53724)	Loss/tok 3.3904 (3.3668)	Learning Rate [0.000625]
6: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00091)	Tok/s 54849 (53558)	Loss/tok 3.4442 (3.3630)	Learning Rate [0.000625]
3: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00093)	Tok/s 54752 (53318)	Loss/tok 3.4894 (3.3599)	Learning Rate [0.000625]
5: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00092)	Tok/s 54784 (53484)	Loss/tok 3.5304 (3.3629)	Learning Rate [0.000625]
4: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00108 (0.00100)	Tok/s 54777 (53409)	Loss/tok 3.2042 (3.3620)	Learning Rate [0.000625]
7: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00097)	Tok/s 54954 (53646)	Loss/tok 3.3043 (3.3617)	Learning Rate [0.000625]
2: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00097)	Tok/s 54886 (53223)	Loss/tok 3.3796 (3.3691)	Learning Rate [0.000625]
9: TRAIN [1][2990/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00091)	Tok/s 55124 (53782)	Loss/tok 3.2395 (3.3545)	Learning Rate [0.000625]
15: TRAIN [1][3000/3416]	Time 0.041 (0.058)	Data 0.00102 (0.00091)	Tok/s 31082 (54329)	Loss/tok 2.7878 (3.3594)	Learning Rate [0.000625]
0: TRAIN [1][3000/3416]	Time 0.041 (0.058)	Data 0.00104 (0.00099)	Tok/s 27893 (53015)	Loss/tok 2.4289 (3.3631)	Learning Rate [0.000625]
14: TRAIN [1][3000/3416]	Time 0.041 (0.058)	Data 0.00109 (0.00092)	Tok/s 31092 (54219)	Loss/tok 2.7492 (3.3600)	Learning Rate [0.000625]
1: TRAIN [1][3000/3416]	Time 0.041 (0.058)	Data 0.00098 (0.00097)	Tok/s 27814 (53105)	Loss/tok 2.6568 (3.3676)	Learning Rate [0.000625]
11: TRAIN [1][3000/3416]	Time 0.041 (0.058)	Data 0.00105 (0.00091)	Tok/s 29599 (53923)	Loss/tok 2.8042 (3.3586)	Learning Rate [0.000625]
13: TRAIN [1][3000/3416]	Time 0.041 (0.058)	Data 0.00101 (0.00097)	Tok/s 30479 (54125)	Loss/tok 2.7357 (3.3617)	Learning Rate [0.000625]
2: TRAIN [1][3000/3416]	Time 0.042 (0.058)	Data 0.00106 (0.00097)	Tok/s 27754 (53202)	Loss/tok 2.5866 (3.3688)	Learning Rate [0.000625]
4: TRAIN [1][3000/3416]	Time 0.041 (0.058)	Data 0.00120 (0.00100)	Tok/s 28752 (53389)	Loss/tok 2.5621 (3.3615)	Learning Rate [0.000625]
12: TRAIN [1][3000/3416]	Time 0.041 (0.058)	Data 0.00106 (0.00096)	Tok/s 29485 (54029)	Loss/tok 2.8653 (3.3594)	Learning Rate [0.000625]
10: TRAIN [1][3000/3416]	Time 0.041 (0.058)	Data 0.00101 (0.00096)	Tok/s 29437 (53841)	Loss/tok 2.6687 (3.3603)	Learning Rate [0.000625]
8: TRAIN [1][3000/3416]	Time 0.041 (0.058)	Data 0.00104 (0.00096)	Tok/s 29327 (53706)	Loss/tok 2.6104 (3.3664)	Learning Rate [0.000625]
5: TRAIN [1][3000/3416]	Time 0.042 (0.058)	Data 0.00101 (0.00092)	Tok/s 29214 (53465)	Loss/tok 2.5305 (3.3624)	Learning Rate [0.000625]
3: TRAIN [1][3000/3416]	Time 0.042 (0.058)	Data 0.00098 (0.00093)	Tok/s 27662 (53297)	Loss/tok 2.5212 (3.3594)	Learning Rate [0.000625]
6: TRAIN [1][3000/3416]	Time 0.042 (0.058)	Data 0.00096 (0.00091)	Tok/s 29185 (53539)	Loss/tok 2.6851 (3.3626)	Learning Rate [0.000625]
7: TRAIN [1][3000/3416]	Time 0.042 (0.058)	Data 0.00098 (0.00097)	Tok/s 29272 (53628)	Loss/tok 2.4924 (3.3613)	Learning Rate [0.000625]
9: TRAIN [1][3000/3416]	Time 0.041 (0.058)	Data 0.00092 (0.00091)	Tok/s 29458 (53764)	Loss/tok 2.6163 (3.3541)	Learning Rate [0.000625]
2: TRAIN [1][3010/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00097)	Tok/s 52791 (53208)	Loss/tok 3.3531 (3.3686)	Learning Rate [0.000625]
1: TRAIN [1][3010/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 52819 (53111)	Loss/tok 3.1358 (3.3675)	Learning Rate [0.000625]
3: TRAIN [1][3010/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00093)	Tok/s 52746 (53303)	Loss/tok 3.2831 (3.3593)	Learning Rate [0.000625]
0: TRAIN [1][3010/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00099)	Tok/s 52762 (53021)	Loss/tok 3.2726 (3.3631)	Learning Rate [0.000625]
4: TRAIN [1][3010/3416]	Time 0.052 (0.058)	Data 0.00106 (0.00100)	Tok/s 52638 (53395)	Loss/tok 3.4028 (3.3613)	Learning Rate [0.000625]
6: TRAIN [1][3010/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00091)	Tok/s 52456 (53544)	Loss/tok 3.3088 (3.3624)	Learning Rate [0.000625]
10: TRAIN [1][3010/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00096)	Tok/s 52405 (53846)	Loss/tok 3.1741 (3.3603)	Learning Rate [0.000625]
5: TRAIN [1][3010/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 52535 (53471)	Loss/tok 3.2837 (3.3625)	Learning Rate [0.000625]
15: TRAIN [1][3010/3416]	Time 0.052 (0.058)	Data 0.00115 (0.00091)	Tok/s 52681 (54333)	Loss/tok 3.1718 (3.3592)	Learning Rate [0.000625]
11: TRAIN [1][3010/3416]	Time 0.053 (0.058)	Data 0.00108 (0.00091)	Tok/s 52383 (53928)	Loss/tok 3.3183 (3.3583)	Learning Rate [0.000625]
14: TRAIN [1][3010/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00092)	Tok/s 52525 (54224)	Loss/tok 3.4307 (3.3597)	Learning Rate [0.000625]
8: TRAIN [1][3010/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00096)	Tok/s 52264 (53711)	Loss/tok 3.1530 (3.3662)	Learning Rate [0.000625]
7: TRAIN [1][3010/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00097)	Tok/s 52311 (53633)	Loss/tok 3.0158 (3.3609)	Learning Rate [0.000625]
13: TRAIN [1][3010/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00097)	Tok/s 52463 (54130)	Loss/tok 3.4656 (3.3617)	Learning Rate [0.000625]
12: TRAIN [1][3010/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00096)	Tok/s 52392 (54033)	Loss/tok 3.2591 (3.3591)	Learning Rate [0.000625]
9: TRAIN [1][3010/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00091)	Tok/s 52293 (53769)	Loss/tok 3.4704 (3.3538)	Learning Rate [0.000625]
2: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00097)	Tok/s 52945 (53212)	Loss/tok 3.1341 (3.3684)	Learning Rate [0.000625]
1: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00097)	Tok/s 52820 (53114)	Loss/tok 3.2373 (3.3673)	Learning Rate [0.000625]
3: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00093)	Tok/s 52925 (53307)	Loss/tok 3.5170 (3.3591)	Learning Rate [0.000625]
0: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00099)	Tok/s 52741 (53025)	Loss/tok 3.1595 (3.3628)	Learning Rate [0.000625]
4: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00100)	Tok/s 52916 (53398)	Loss/tok 3.1318 (3.3611)	Learning Rate [0.000625]
15: TRAIN [1][3020/3416]	Time 0.060 (0.058)	Data 0.00080 (0.00091)	Tok/s 52704 (54335)	Loss/tok 3.1941 (3.3590)	Learning Rate [0.000625]
6: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00091)	Tok/s 52958 (53547)	Loss/tok 3.2484 (3.3624)	Learning Rate [0.000625]
5: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00092)	Tok/s 52914 (53474)	Loss/tok 3.3074 (3.3623)	Learning Rate [0.000625]
14: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00092)	Tok/s 52724 (54226)	Loss/tok 3.1299 (3.3596)	Learning Rate [0.000625]
7: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00097)	Tok/s 52889 (53636)	Loss/tok 3.2751 (3.3607)	Learning Rate [0.000625]
13: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00097)	Tok/s 52709 (54131)	Loss/tok 3.6401 (3.3618)	Learning Rate [0.000625]
8: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00096)	Tok/s 52876 (53714)	Loss/tok 3.3025 (3.3659)	Learning Rate [0.000625]
12: TRAIN [1][3020/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00096)	Tok/s 52669 (54035)	Loss/tok 3.5187 (3.3589)	Learning Rate [0.000625]
10: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00096)	Tok/s 52782 (53848)	Loss/tok 3.1093 (3.3599)	Learning Rate [0.000625]
11: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00091)	Tok/s 52773 (53929)	Loss/tok 3.2253 (3.3582)	Learning Rate [0.000625]
9: TRAIN [1][3020/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00091)	Tok/s 52737 (53771)	Loss/tok 3.2064 (3.3537)	Learning Rate [0.000625]
3: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 50453 (53289)	Loss/tok 3.1448 (3.3588)	Learning Rate [0.000625]
4: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00107 (0.00100)	Tok/s 50361 (53380)	Loss/tok 2.9620 (3.3607)	Learning Rate [0.000625]
1: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00097)	Tok/s 50440 (53096)	Loss/tok 3.1851 (3.3669)	Learning Rate [0.000625]
2: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00097)	Tok/s 50448 (53194)	Loss/tok 3.2268 (3.3680)	Learning Rate [0.000625]
6: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00091)	Tok/s 50364 (53529)	Loss/tok 3.1867 (3.3620)	Learning Rate [0.000625]
5: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00092)	Tok/s 50382 (53456)	Loss/tok 3.1273 (3.3620)	Learning Rate [0.000625]
0: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00099)	Tok/s 50385 (53006)	Loss/tok 3.0695 (3.3627)	Learning Rate [0.000625]
7: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00097)	Tok/s 50366 (53617)	Loss/tok 3.2338 (3.3606)	Learning Rate [0.000625]
14: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 51523 (54207)	Loss/tok 3.2759 (3.3593)	Learning Rate [0.000625]
9: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00091)	Tok/s 50333 (53752)	Loss/tok 3.2089 (3.3536)	Learning Rate [0.000625]
11: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00091)	Tok/s 51536 (53910)	Loss/tok 3.3622 (3.3581)	Learning Rate [0.000625]
13: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00097)	Tok/s 51496 (54112)	Loss/tok 3.2995 (3.3615)	Learning Rate [0.000625]
12: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00096)	Tok/s 51458 (54016)	Loss/tok 3.3316 (3.3589)	Learning Rate [0.000625]
10: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00096)	Tok/s 50375 (53829)	Loss/tok 3.2916 (3.3595)	Learning Rate [0.000625]
8: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00096)	Tok/s 50122 (53695)	Loss/tok 3.2500 (3.3655)	Learning Rate [0.000625]
15: TRAIN [1][3030/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00091)	Tok/s 51558 (54316)	Loss/tok 2.9951 (3.3588)	Learning Rate [0.000625]
13: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00097)	Tok/s 49802 (54112)	Loss/tok 3.0567 (3.3614)	Learning Rate [0.000625]
12: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00096)	Tok/s 49773 (54016)	Loss/tok 3.0536 (3.3589)	Learning Rate [0.000625]
11: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00091)	Tok/s 49771 (53911)	Loss/tok 3.1061 (3.3578)	Learning Rate [0.000625]
14: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00092)	Tok/s 49677 (54207)	Loss/tok 3.1815 (3.3589)	Learning Rate [0.000625]
0: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00099)	Tok/s 49404 (53007)	Loss/tok 3.1524 (3.3625)	Learning Rate [0.000625]
1: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00097)	Tok/s 49296 (53097)	Loss/tok 3.3379 (3.3667)	Learning Rate [0.000625]
10: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00096)	Tok/s 49702 (53829)	Loss/tok 3.3543 (3.3593)	Learning Rate [0.000625]
9: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00091)	Tok/s 49609 (53752)	Loss/tok 3.2179 (3.3536)	Learning Rate [0.000625]
8: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00096)	Tok/s 49549 (53695)	Loss/tok 3.2696 (3.3654)	Learning Rate [0.000625]
7: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00097)	Tok/s 49461 (53617)	Loss/tok 3.3665 (3.3605)	Learning Rate [0.000625]
3: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00093)	Tok/s 49171 (53289)	Loss/tok 3.3892 (3.3587)	Learning Rate [0.000625]
4: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00108 (0.00100)	Tok/s 49208 (53381)	Loss/tok 3.2303 (3.3608)	Learning Rate [0.000625]
6: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00091)	Tok/s 49344 (53529)	Loss/tok 3.1579 (3.3619)	Learning Rate [0.000625]
2: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00097)	Tok/s 49126 (53194)	Loss/tok 3.2916 (3.3679)	Learning Rate [0.000625]
5: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00092)	Tok/s 49254 (53457)	Loss/tok 3.2759 (3.3620)	Learning Rate [0.000625]
15: TRAIN [1][3040/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00091)	Tok/s 49520 (54316)	Loss/tok 3.2684 (3.3586)	Learning Rate [0.000625]
11: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00091)	Tok/s 52198 (53930)	Loss/tok 3.1495 (3.3575)	Learning Rate [0.000625]
10: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00096)	Tok/s 52078 (53849)	Loss/tok 3.2214 (3.3590)	Learning Rate [0.000625]
13: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00097)	Tok/s 52202 (54131)	Loss/tok 3.1572 (3.3610)	Learning Rate [0.000625]
12: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00096)	Tok/s 52204 (54035)	Loss/tok 3.0682 (3.3587)	Learning Rate [0.000625]
9: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00091)	Tok/s 51970 (53772)	Loss/tok 3.3974 (3.3537)	Learning Rate [0.000625]
14: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00092)	Tok/s 52192 (54226)	Loss/tok 3.2196 (3.3589)	Learning Rate [0.000625]
8: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00096)	Tok/s 51848 (53715)	Loss/tok 3.1068 (3.3652)	Learning Rate [0.000625]
0: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00099)	Tok/s 52076 (53027)	Loss/tok 3.2458 (3.3627)	Learning Rate [0.000625]
7: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00102 (0.00097)	Tok/s 51752 (53637)	Loss/tok 3.3318 (3.3601)	Learning Rate [0.000625]
1: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00103 (0.00097)	Tok/s 52005 (53117)	Loss/tok 3.1965 (3.3666)	Learning Rate [0.000625]
6: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00091)	Tok/s 51678 (53549)	Loss/tok 3.1224 (3.3615)	Learning Rate [0.000625]
2: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00101 (0.00097)	Tok/s 51907 (53214)	Loss/tok 3.2096 (3.3676)	Learning Rate [0.000625]
4: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00104 (0.00100)	Tok/s 51713 (53400)	Loss/tok 3.4809 (3.3608)	Learning Rate [0.000625]
3: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00093)	Tok/s 51837 (53309)	Loss/tok 3.4971 (3.3588)	Learning Rate [0.000625]
5: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00092)	Tok/s 51768 (53476)	Loss/tok 3.3091 (3.3620)	Learning Rate [0.000625]
15: TRAIN [1][3050/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00091)	Tok/s 52147 (54335)	Loss/tok 3.2881 (3.3586)	Learning Rate [0.000625]
5: TRAIN [1][3060/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00092)	Tok/s 56639 (53491)	Loss/tok 3.5052 (3.3618)	Learning Rate [0.000625]
6: TRAIN [1][3060/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00091)	Tok/s 56573 (53563)	Loss/tok 3.3205 (3.3614)	Learning Rate [0.000625]
4: TRAIN [1][3060/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00100)	Tok/s 56554 (53415)	Loss/tok 3.5815 (3.3607)	Learning Rate [0.000625]
7: TRAIN [1][3060/3416]	Time 0.063 (0.058)	Data 0.00105 (0.00097)	Tok/s 56520 (53651)	Loss/tok 3.6292 (3.3601)	Learning Rate [0.000625]
3: TRAIN [1][3060/3416]	Time 0.063 (0.058)	Data 0.00107 (0.00093)	Tok/s 56303 (53323)	Loss/tok 3.2961 (3.3586)	Learning Rate [0.000625]
9: TRAIN [1][3060/3416]	Time 0.064 (0.058)	Data 0.00099 (0.00091)	Tok/s 56388 (53786)	Loss/tok 3.6941 (3.3536)	Learning Rate [0.000625]
11: TRAIN [1][3060/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00091)	Tok/s 56263 (53944)	Loss/tok 3.1003 (3.3571)	Learning Rate [0.000625]
2: TRAIN [1][3060/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00097)	Tok/s 55346 (53228)	Loss/tok 3.6298 (3.3675)	Learning Rate [0.000625]
10: TRAIN [1][3060/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00096)	Tok/s 56327 (53862)	Loss/tok 3.4465 (3.3588)	Learning Rate [0.000625]
8: TRAIN [1][3060/3416]	Time 0.064 (0.058)	Data 0.00101 (0.00096)	Tok/s 56411 (53729)	Loss/tok 3.5121 (3.3650)	Learning Rate [0.000625]
1: TRAIN [1][3060/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00097)	Tok/s 55248 (53131)	Loss/tok 3.3631 (3.3665)	Learning Rate [0.000625]
12: TRAIN [1][3060/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00096)	Tok/s 56187 (54048)	Loss/tok 3.1965 (3.3584)	Learning Rate [0.000625]
0: TRAIN [1][3060/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00099)	Tok/s 55155 (53041)	Loss/tok 3.1955 (3.3623)	Learning Rate [0.000625]
13: TRAIN [1][3060/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00097)	Tok/s 56094 (54144)	Loss/tok 3.4304 (3.3611)	Learning Rate [0.000625]
14: TRAIN [1][3060/3416]	Time 0.064 (0.058)	Data 0.00083 (0.00092)	Tok/s 56022 (54239)	Loss/tok 3.3221 (3.3584)	Learning Rate [0.000625]
15: TRAIN [1][3060/3416]	Time 0.064 (0.058)	Data 0.00101 (0.00091)	Tok/s 56079 (54347)	Loss/tok 3.5640 (3.3585)	Learning Rate [0.000625]
9: TRAIN [1][3070/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00091)	Tok/s 47623 (53799)	Loss/tok 3.1836 (3.3534)	Learning Rate [0.000625]
11: TRAIN [1][3070/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00091)	Tok/s 47417 (53957)	Loss/tok 2.8816 (3.3568)	Learning Rate [0.000625]
12: TRAIN [1][3070/3416]	Time 0.044 (0.058)	Data 0.00107 (0.00096)	Tok/s 47581 (54061)	Loss/tok 2.8771 (3.3585)	Learning Rate [0.000625]
8: TRAIN [1][3070/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00096)	Tok/s 47589 (53742)	Loss/tok 2.8524 (3.3645)	Learning Rate [0.000625]
7: TRAIN [1][3070/3416]	Time 0.044 (0.058)	Data 0.00114 (0.00097)	Tok/s 47649 (53664)	Loss/tok 3.2010 (3.3600)	Learning Rate [0.000625]
6: TRAIN [1][3070/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00091)	Tok/s 47744 (53576)	Loss/tok 2.9554 (3.3612)	Learning Rate [0.000625]
13: TRAIN [1][3070/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00097)	Tok/s 47462 (54157)	Loss/tok 2.9466 (3.3608)	Learning Rate [0.000625]
10: TRAIN [1][3070/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00096)	Tok/s 47567 (53875)	Loss/tok 3.3498 (3.3588)	Learning Rate [0.000625]
14: TRAIN [1][3070/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00092)	Tok/s 47472 (54251)	Loss/tok 3.2589 (3.3583)	Learning Rate [0.000625]
5: TRAIN [1][3070/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00092)	Tok/s 47589 (53503)	Loss/tok 3.0715 (3.3616)	Learning Rate [0.000625]
4: TRAIN [1][3070/3416]	Time 0.044 (0.058)	Data 0.00103 (0.00100)	Tok/s 47493 (53428)	Loss/tok 3.1127 (3.3603)	Learning Rate [0.000625]
0: TRAIN [1][3070/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00099)	Tok/s 45872 (53054)	Loss/tok 3.1051 (3.3620)	Learning Rate [0.000625]
2: TRAIN [1][3070/3416]	Time 0.045 (0.058)	Data 0.00111 (0.00097)	Tok/s 46011 (53241)	Loss/tok 3.0241 (3.3673)	Learning Rate [0.000625]
1: TRAIN [1][3070/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00097)	Tok/s 45811 (53144)	Loss/tok 3.0533 (3.3662)	Learning Rate [0.000625]
3: TRAIN [1][3070/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00093)	Tok/s 47390 (53336)	Loss/tok 3.0603 (3.3586)	Learning Rate [0.000625]
15: TRAIN [1][3070/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00091)	Tok/s 47406 (54359)	Loss/tok 3.0746 (3.3586)	Learning Rate [0.000625]
4: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
9: TRAIN [1][3080/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00091)	Tok/s 71334 (53818)	Loss/tok 3.4127 (3.3531)	Learning Rate [0.000625]
8: TRAIN [1][3080/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00096)	Tok/s 71272 (53761)	Loss/tok 3.5699 (3.3643)	Learning Rate [0.000625]
6: TRAIN [1][3080/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00091)	Tok/s 70241 (53595)	Loss/tok 3.2336 (3.3609)	Learning Rate [0.000625]
7: TRAIN [1][3080/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00097)	Tok/s 70181 (53682)	Loss/tok 3.4395 (3.3599)	Learning Rate [0.000625]
3: TRAIN [1][3080/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 70026 (53355)	Loss/tok 3.1549 (3.3585)	Learning Rate [0.000625]
4: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00100)	Tok/s 69929 (53447)	Loss/tok 3.2055 (3.3600)	Learning Rate [0.000625]
10: TRAIN [1][3080/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00096)	Tok/s 71343 (53894)	Loss/tok 3.4775 (3.3585)	Learning Rate [0.000625]
11: TRAIN [1][3080/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 71258 (53976)	Loss/tok 3.2952 (3.3565)	Learning Rate [0.000625]
2: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00097)	Tok/s 69821 (53260)	Loss/tok 3.3362 (3.3671)	Learning Rate [0.000625]
1: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 69780 (53163)	Loss/tok 3.3967 (3.3660)	Learning Rate [0.000625]
12: TRAIN [1][3080/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00096)	Tok/s 71138 (54080)	Loss/tok 3.1445 (3.3582)	Learning Rate [0.000625]
14: TRAIN [1][3080/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 70951 (54270)	Loss/tok 3.2001 (3.3579)	Learning Rate [0.000625]
0: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 69866 (53073)	Loss/tok 3.1326 (3.3617)	Learning Rate [0.000625]
13: TRAIN [1][3080/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 71005 (54176)	Loss/tok 3.3548 (3.3605)	Learning Rate [0.000625]
5: TRAIN [1][3080/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 70029 (53522)	Loss/tok 3.4904 (3.3614)	Learning Rate [0.000625]
15: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 70969 (54378)	Loss/tok 3.5024 (3.3585)	Learning Rate [0.000625]
0: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00099)	Tok/s 53700 (53048)	Loss/tok 3.1543 (3.3614)	Learning Rate [0.000625]
14: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00092)	Tok/s 53822 (54244)	Loss/tok 3.0348 (3.3576)	Learning Rate [0.000625]
1: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00097)	Tok/s 53710 (53138)	Loss/tok 2.9386 (3.3656)	Learning Rate [0.000625]
13: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00097)	Tok/s 53709 (54149)	Loss/tok 3.0821 (3.3599)	Learning Rate [0.000625]
2: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00110 (0.00097)	Tok/s 53939 (53235)	Loss/tok 3.1330 (3.3666)	Learning Rate [0.000625]
12: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00104 (0.00096)	Tok/s 53692 (54054)	Loss/tok 3.2164 (3.3579)	Learning Rate [0.000625]
3: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00093)	Tok/s 53705 (53330)	Loss/tok 3.1936 (3.3582)	Learning Rate [0.000625]
11: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00119 (0.00091)	Tok/s 53705 (53950)	Loss/tok 3.4074 (3.3562)	Learning Rate [0.000625]
9: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00091)	Tok/s 53738 (53793)	Loss/tok 3.0636 (3.3526)	Learning Rate [0.000625]
4: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00111 (0.00100)	Tok/s 53746 (53421)	Loss/tok 3.2098 (3.3597)	Learning Rate [0.000625]
10: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00102 (0.00096)	Tok/s 53726 (53869)	Loss/tok 3.1349 (3.3582)	Learning Rate [0.000625]
8: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00096)	Tok/s 53716 (53735)	Loss/tok 3.2057 (3.3639)	Learning Rate [0.000625]
15: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00091)	Tok/s 54908 (54352)	Loss/tok 3.2932 (3.3580)	Learning Rate [0.000625]
6: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00091)	Tok/s 53692 (53570)	Loss/tok 3.4906 (3.3607)	Learning Rate [0.000625]
7: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00112 (0.00097)	Tok/s 53706 (53657)	Loss/tok 3.3410 (3.3596)	Learning Rate [0.000625]
5: TRAIN [1][3090/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00092)	Tok/s 53655 (53497)	Loss/tok 3.4173 (3.3611)	Learning Rate [0.000625]
9: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00091)	Tok/s 72692 (53810)	Loss/tok 3.3695 (3.3524)	Learning Rate [0.000625]
14: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 73348 (54263)	Loss/tok 3.1246 (3.3571)	Learning Rate [0.000625]
6: TRAIN [1][3100/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00091)	Tok/s 72777 (53587)	Loss/tok 3.2190 (3.3598)	Learning Rate [0.000625]
13: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00097)	Tok/s 73173 (54167)	Loss/tok 3.2895 (3.3592)	Learning Rate [0.000625]
12: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00096)	Tok/s 72587 (54072)	Loss/tok 3.1753 (3.3574)	Learning Rate [0.000625]
10: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00096)	Tok/s 72607 (53887)	Loss/tok 3.2708 (3.3576)	Learning Rate [0.000625]
0: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00099)	Tok/s 71531 (53064)	Loss/tok 3.3972 (3.3608)	Learning Rate [0.000625]
8: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00096)	Tok/s 72674 (53753)	Loss/tok 3.1654 (3.3634)	Learning Rate [0.000625]
11: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 72619 (53968)	Loss/tok 3.2259 (3.3554)	Learning Rate [0.000625]
7: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00097)	Tok/s 72703 (53674)	Loss/tok 3.2753 (3.3588)	Learning Rate [0.000625]
1: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 71717 (53154)	Loss/tok 3.2156 (3.3651)	Learning Rate [0.000625]
5: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 72732 (53514)	Loss/tok 3.4302 (3.3604)	Learning Rate [0.000625]
2: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00114 (0.00097)	Tok/s 72442 (53251)	Loss/tok 3.3580 (3.3662)	Learning Rate [0.000625]
3: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 72500 (53346)	Loss/tok 3.3328 (3.3575)	Learning Rate [0.000625]
4: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00100)	Tok/s 72532 (53438)	Loss/tok 3.7562 (3.3594)	Learning Rate [0.000625]
15: TRAIN [1][3100/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 73506 (54371)	Loss/tok 3.4431 (3.3575)	Learning Rate [0.000625]
6: TRAIN [1][3110/3416]	Time 0.070 (0.058)	Data 0.00078 (0.00091)	Tok/s 75408 (53599)	Loss/tok 3.2684 (3.3595)	Learning Rate [0.000625]
5: TRAIN [1][3110/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 75511 (53527)	Loss/tok 3.3138 (3.3602)	Learning Rate [0.000625]
3: TRAIN [1][3110/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 75534 (53359)	Loss/tok 3.3129 (3.3575)	Learning Rate [0.000625]
4: TRAIN [1][3110/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00100)	Tok/s 75536 (53451)	Loss/tok 3.1583 (3.3590)	Learning Rate [0.000625]
1: TRAIN [1][3110/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 75527 (53167)	Loss/tok 3.5809 (3.3654)	Learning Rate [0.000625]
7: TRAIN [1][3110/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 75275 (53687)	Loss/tok 3.4482 (3.3588)	Learning Rate [0.000625]
0: TRAIN [1][3110/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00099)	Tok/s 74675 (53077)	Loss/tok 3.2971 (3.3605)	Learning Rate [0.000625]
2: TRAIN [1][3110/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 75547 (53264)	Loss/tok 3.1716 (3.3661)	Learning Rate [0.000625]
8: TRAIN [1][3110/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 75196 (53764)	Loss/tok 3.4556 (3.3630)	Learning Rate [0.000625]
9: TRAIN [1][3110/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00091)	Tok/s 75258 (53822)	Loss/tok 3.1198 (3.3521)	Learning Rate [0.000625]
14: TRAIN [1][3110/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 76392 (54274)	Loss/tok 3.1727 (3.3571)	Learning Rate [0.000625]
13: TRAIN [1][3110/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 76327 (54179)	Loss/tok 3.2487 (3.3593)	Learning Rate [0.000625]
10: TRAIN [1][3110/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 76151 (53899)	Loss/tok 3.2894 (3.3575)	Learning Rate [0.000625]
11: TRAIN [1][3110/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00091)	Tok/s 76151 (53981)	Loss/tok 3.4992 (3.3553)	Learning Rate [0.000625]
12: TRAIN [1][3110/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 76266 (54084)	Loss/tok 3.6241 (3.3574)	Learning Rate [0.000625]
15: TRAIN [1][3110/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00091)	Tok/s 76437 (54383)	Loss/tok 3.3720 (3.3575)	Learning Rate [0.000625]
13: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00096 (0.00097)	Tok/s 31425 (54170)	Loss/tok 2.8185 (3.3590)	Learning Rate [0.000625]
12: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00098 (0.00096)	Tok/s 30225 (54075)	Loss/tok 2.6500 (3.3571)	Learning Rate [0.000625]
14: TRAIN [1][3120/3416]	Time 0.040 (0.058)	Data 0.00112 (0.00092)	Tok/s 31713 (54265)	Loss/tok 2.6128 (3.3568)	Learning Rate [0.000625]
11: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00086 (0.00091)	Tok/s 29536 (53971)	Loss/tok 2.5159 (3.3549)	Learning Rate [0.000625]
0: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00096 (0.00099)	Tok/s 28221 (53066)	Loss/tok 2.6770 (3.3604)	Learning Rate [0.000625]
9: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00087 (0.00091)	Tok/s 29391 (53813)	Loss/tok 2.5990 (3.3520)	Learning Rate [0.000625]
10: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00087 (0.00096)	Tok/s 29558 (53890)	Loss/tok 2.5201 (3.3572)	Learning Rate [0.000625]
1: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00088 (0.00097)	Tok/s 28200 (53157)	Loss/tok 2.6368 (3.3652)	Learning Rate [0.000625]
8: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00097 (0.00096)	Tok/s 29506 (53755)	Loss/tok 2.7045 (3.3627)	Learning Rate [0.000625]
2: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00098 (0.00097)	Tok/s 28105 (53254)	Loss/tok 2.8441 (3.3659)	Learning Rate [0.000625]
6: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00091)	Tok/s 29452 (53590)	Loss/tok 2.6237 (3.3593)	Learning Rate [0.000625]
7: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00108 (0.00097)	Tok/s 29422 (53677)	Loss/tok 2.4581 (3.3584)	Learning Rate [0.000625]
3: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00094 (0.00093)	Tok/s 28071 (53348)	Loss/tok 2.5607 (3.3573)	Learning Rate [0.000625]
4: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00103 (0.00100)	Tok/s 28385 (53441)	Loss/tok 2.5083 (3.3588)	Learning Rate [0.000625]
5: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00104 (0.00092)	Tok/s 29525 (53517)	Loss/tok 2.5526 (3.3600)	Learning Rate [0.000625]
15: TRAIN [1][3120/3416]	Time 0.041 (0.058)	Data 0.00094 (0.00091)	Tok/s 31316 (54373)	Loss/tok 2.5618 (3.3572)	Learning Rate [0.000625]
4: TRAIN [1][3130/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00100)	Tok/s 57283 (53446)	Loss/tok 3.4833 (3.3585)	Learning Rate [0.0003125]
2: TRAIN [1][3130/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 57366 (53260)	Loss/tok 3.1334 (3.3657)	Learning Rate [0.0003125]
3: TRAIN [1][3130/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00093)	Tok/s 57366 (53354)	Loss/tok 3.4694 (3.3570)	Learning Rate [0.0003125]
5: TRAIN [1][3130/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 57280 (53522)	Loss/tok 3.2570 (3.3596)	Learning Rate [0.0003125]
1: TRAIN [1][3130/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00097)	Tok/s 57353 (53163)	Loss/tok 3.2411 (3.3651)	Learning Rate [0.0003125]
6: TRAIN [1][3130/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00091)	Tok/s 57110 (53595)	Loss/tok 3.4526 (3.3589)	Learning Rate [0.0003125]
7: TRAIN [1][3130/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00097)	Tok/s 57053 (53682)	Loss/tok 3.4416 (3.3585)	Learning Rate [0.0003125]
0: TRAIN [1][3130/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00099)	Tok/s 57103 (53072)	Loss/tok 3.2947 (3.3603)	Learning Rate [0.0003125]
9: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00078 (0.00091)	Tok/s 56902 (53818)	Loss/tok 3.3841 (3.3520)	Learning Rate [0.0003125]
14: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 57907 (54270)	Loss/tok 3.2572 (3.3567)	Learning Rate [0.0003125]
8: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 56902 (53759)	Loss/tok 3.6941 (3.3625)	Learning Rate [0.0003125]
13: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00097)	Tok/s 57781 (54175)	Loss/tok 3.3821 (3.3591)	Learning Rate [0.0003125]
12: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 57213 (54080)	Loss/tok 3.3860 (3.3569)	Learning Rate [0.0003125]
11: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 56729 (53976)	Loss/tok 3.4702 (3.3546)	Learning Rate [0.0003125]
10: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00077 (0.00096)	Tok/s 56750 (53895)	Loss/tok 3.4406 (3.3571)	Learning Rate [0.0003125]
15: TRAIN [1][3130/3416]	Time 0.068 (0.058)	Data 0.00079 (0.00091)	Tok/s 57952 (54378)	Loss/tok 3.3169 (3.3571)	Learning Rate [0.0003125]
3: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00093)	Tok/s 30781 (53351)	Loss/tok 2.8670 (3.3566)	Learning Rate [0.0003125]
2: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00097)	Tok/s 30668 (53257)	Loss/tok 2.7903 (3.3653)	Learning Rate [0.0003125]
4: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00100)	Tok/s 30711 (53443)	Loss/tok 2.7602 (3.3579)	Learning Rate [0.0003125]
1: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00097)	Tok/s 30649 (53160)	Loss/tok 2.7867 (3.3648)	Learning Rate [0.0003125]
0: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00099)	Tok/s 30686 (53070)	Loss/tok 2.8200 (3.3599)	Learning Rate [0.0003125]
14: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00092)	Tok/s 32025 (54267)	Loss/tok 2.6753 (3.3561)	Learning Rate [0.0003125]
7: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00097)	Tok/s 30792 (53679)	Loss/tok 2.7626 (3.3582)	Learning Rate [0.0003125]
8: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00096)	Tok/s 30737 (53757)	Loss/tok 3.0282 (3.3624)	Learning Rate [0.0003125]
9: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00091)	Tok/s 30679 (53815)	Loss/tok 2.8603 (3.3518)	Learning Rate [0.0003125]
13: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00097)	Tok/s 31961 (54173)	Loss/tok 3.0663 (3.3589)	Learning Rate [0.0003125]
11: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00091)	Tok/s 30992 (53974)	Loss/tok 2.9159 (3.3543)	Learning Rate [0.0003125]
12: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00096)	Tok/s 31975 (54077)	Loss/tok 2.7408 (3.3568)	Learning Rate [0.0003125]
10: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00096)	Tok/s 30638 (53892)	Loss/tok 2.7841 (3.3564)	Learning Rate [0.0003125]
5: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00119 (0.00092)	Tok/s 30825 (53520)	Loss/tok 2.7374 (3.3591)	Learning Rate [0.0003125]
6: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00128 (0.00091)	Tok/s 30746 (53592)	Loss/tok 2.7797 (3.3588)	Learning Rate [0.0003125]
15: TRAIN [1][3140/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00091)	Tok/s 32049 (54376)	Loss/tok 3.1453 (3.3567)	Learning Rate [0.0003125]
9: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 74213 (53820)	Loss/tok 3.5642 (3.3516)	Learning Rate [0.0003125]
8: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 74121 (53762)	Loss/tok 3.4451 (3.3623)	Learning Rate [0.0003125]
10: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 74208 (53896)	Loss/tok 3.2902 (3.3563)	Learning Rate [0.0003125]
6: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00091)	Tok/s 73834 (53598)	Loss/tok 3.1729 (3.3585)	Learning Rate [0.0003125]
11: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00091)	Tok/s 74212 (53978)	Loss/tok 3.4499 (3.3539)	Learning Rate [0.0003125]
12: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00096)	Tok/s 74302 (54082)	Loss/tok 3.5788 (3.3566)	Learning Rate [0.0003125]
13: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00097)	Tok/s 74272 (54176)	Loss/tok 3.4113 (3.3589)	Learning Rate [0.0003125]
14: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 74546 (54272)	Loss/tok 3.3494 (3.3562)	Learning Rate [0.0003125]
4: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00100)	Tok/s 73310 (53449)	Loss/tok 3.5838 (3.3578)	Learning Rate [0.0003125]
15: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00091)	Tok/s 75080 (54380)	Loss/tok 3.2532 (3.3565)	Learning Rate [0.0003125]
5: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 73860 (53526)	Loss/tok 3.3577 (3.3589)	Learning Rate [0.0003125]
3: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 72987 (53357)	Loss/tok 3.2108 (3.3564)	Learning Rate [0.0003125]
0: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00099)	Tok/s 73161 (53076)	Loss/tok 3.2800 (3.3597)	Learning Rate [0.0003125]
1: TRAIN [1][3150/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 73033 (53166)	Loss/tok 3.4575 (3.3646)	Learning Rate [0.0003125]
7: TRAIN [1][3150/3416]	Time 0.071 (0.058)	Data 0.00116 (0.00097)	Tok/s 73052 (53685)	Loss/tok 3.3356 (3.3580)	Learning Rate [0.0003125]
2: TRAIN [1][3150/3416]	Time 0.071 (0.058)	Data 0.00111 (0.00097)	Tok/s 72070 (53262)	Loss/tok 3.2741 (3.3653)	Learning Rate [0.0003125]
15: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 60660 (54371)	Loss/tok 3.3212 (3.3564)	Learning Rate [0.0003125]
14: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 60214 (54263)	Loss/tok 3.2479 (3.3561)	Learning Rate [0.0003125]
0: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00099)	Tok/s 59652 (53068)	Loss/tok 3.3643 (3.3593)	Learning Rate [0.0003125]
12: TRAIN [1][3160/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00096)	Tok/s 59847 (54073)	Loss/tok 3.3166 (3.3564)	Learning Rate [0.0003125]
1: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 59535 (53158)	Loss/tok 3.2941 (3.3645)	Learning Rate [0.0003125]
3: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 59405 (53349)	Loss/tok 3.4871 (3.3564)	Learning Rate [0.0003125]
13: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 59761 (54168)	Loss/tok 3.5001 (3.3587)	Learning Rate [0.0003125]
2: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00097)	Tok/s 59380 (53254)	Loss/tok 3.3248 (3.3649)	Learning Rate [0.0003125]
11: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00091)	Tok/s 59609 (53969)	Loss/tok 3.6809 (3.3538)	Learning Rate [0.0003125]
10: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00096)	Tok/s 59701 (53888)	Loss/tok 3.4373 (3.3560)	Learning Rate [0.0003125]
6: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 59301 (53589)	Loss/tok 3.4506 (3.3582)	Learning Rate [0.0003125]
9: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00091)	Tok/s 59475 (53811)	Loss/tok 3.4108 (3.3514)	Learning Rate [0.0003125]
4: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 59251 (53440)	Loss/tok 3.4585 (3.3576)	Learning Rate [0.0003125]
8: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00096)	Tok/s 59336 (53753)	Loss/tok 3.5041 (3.3619)	Learning Rate [0.0003125]
5: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 59230 (53517)	Loss/tok 3.3532 (3.3586)	Learning Rate [0.0003125]
7: TRAIN [1][3160/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 59332 (53675)	Loss/tok 3.5963 (3.3579)	Learning Rate [0.0003125]
9: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00091)	Tok/s 53513 (53807)	Loss/tok 3.2158 (3.3511)	Learning Rate [0.0003125]
12: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00096)	Tok/s 53653 (54069)	Loss/tok 3.5242 (3.3560)	Learning Rate [0.0003125]
13: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00097)	Tok/s 54580 (54164)	Loss/tok 3.4966 (3.3588)	Learning Rate [0.0003125]
10: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00096)	Tok/s 53505 (53884)	Loss/tok 3.3906 (3.3556)	Learning Rate [0.0003125]
8: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00106 (0.00096)	Tok/s 53296 (53749)	Loss/tok 3.1171 (3.3615)	Learning Rate [0.0003125]
14: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00092)	Tok/s 54639 (54259)	Loss/tok 3.4242 (3.3560)	Learning Rate [0.0003125]
7: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00102 (0.00097)	Tok/s 53250 (53672)	Loss/tok 3.4170 (3.3578)	Learning Rate [0.0003125]
1: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00106 (0.00097)	Tok/s 53437 (53155)	Loss/tok 3.3450 (3.3642)	Learning Rate [0.0003125]
5: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00092)	Tok/s 53289 (53513)	Loss/tok 3.4970 (3.3584)	Learning Rate [0.0003125]
6: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00091)	Tok/s 53147 (53585)	Loss/tok 3.3722 (3.3580)	Learning Rate [0.0003125]
15: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00091)	Tok/s 54580 (54368)	Loss/tok 3.3170 (3.3562)	Learning Rate [0.0003125]
0: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00104 (0.00099)	Tok/s 53453 (53065)	Loss/tok 3.5042 (3.3593)	Learning Rate [0.0003125]
2: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00097)	Tok/s 53270 (53251)	Loss/tok 3.3077 (3.3648)	Learning Rate [0.0003125]
3: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00093)	Tok/s 53196 (53345)	Loss/tok 3.6536 (3.3563)	Learning Rate [0.0003125]
4: TRAIN [1][3170/3416]	Time 0.061 (0.058)	Data 0.00110 (0.00100)	Tok/s 53143 (53437)	Loss/tok 3.2113 (3.3573)	Learning Rate [0.0003125]
11: TRAIN [1][3170/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00091)	Tok/s 52739 (53965)	Loss/tok 3.2919 (3.3535)	Learning Rate [0.0003125]
11: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00091)	Tok/s 56598 (53979)	Loss/tok 3.3545 (3.3532)	Learning Rate [0.0003125]
0: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00099)	Tok/s 56293 (53079)	Loss/tok 3.5184 (3.3592)	Learning Rate [0.0003125]
12: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00096)	Tok/s 56499 (54083)	Loss/tok 3.1526 (3.3556)	Learning Rate [0.0003125]
10: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00081 (0.00096)	Tok/s 56557 (53897)	Loss/tok 3.5041 (3.3553)	Learning Rate [0.0003125]
9: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00081 (0.00091)	Tok/s 56563 (53821)	Loss/tok 3.4718 (3.3507)	Learning Rate [0.0003125]
15: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00091)	Tok/s 56289 (54382)	Loss/tok 3.5310 (3.3559)	Learning Rate [0.0003125]
1: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00082 (0.00097)	Tok/s 56125 (53169)	Loss/tok 3.2561 (3.3639)	Learning Rate [0.0003125]
14: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00092)	Tok/s 56321 (54273)	Loss/tok 3.4374 (3.3556)	Learning Rate [0.0003125]
13: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00104 (0.00097)	Tok/s 56358 (54178)	Loss/tok 3.3523 (3.3583)	Learning Rate [0.0003125]
8: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00084 (0.00096)	Tok/s 56403 (53763)	Loss/tok 3.1933 (3.3612)	Learning Rate [0.0003125]
2: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00081 (0.00097)	Tok/s 56106 (53265)	Loss/tok 3.1927 (3.3640)	Learning Rate [0.0003125]
6: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00091)	Tok/s 56287 (53599)	Loss/tok 3.3498 (3.3573)	Learning Rate [0.0003125]
7: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00084 (0.00097)	Tok/s 56323 (53685)	Loss/tok 3.5201 (3.3575)	Learning Rate [0.0003125]
3: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00093)	Tok/s 56112 (53359)	Loss/tok 3.2689 (3.3560)	Learning Rate [0.0003125]
4: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00104 (0.00100)	Tok/s 56105 (53450)	Loss/tok 3.3826 (3.3571)	Learning Rate [0.0003125]
5: TRAIN [1][3180/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00092)	Tok/s 56113 (53526)	Loss/tok 3.4550 (3.3581)	Learning Rate [0.0003125]
1: TRAIN [1][3190/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 78454 (53166)	Loss/tok 3.2761 (3.3638)	Learning Rate [0.0003125]
4: TRAIN [1][3190/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00100)	Tok/s 79177 (53449)	Loss/tok 3.1984 (3.3569)	Learning Rate [0.0003125]
0: TRAIN [1][3190/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 78472 (53075)	Loss/tok 3.0253 (3.3588)	Learning Rate [0.0003125]
2: TRAIN [1][3190/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00097)	Tok/s 79087 (53263)	Loss/tok 3.2008 (3.3636)	Learning Rate [0.0003125]
15: TRAIN [1][3190/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00091)	Tok/s 80319 (54382)	Loss/tok 3.0145 (3.3555)	Learning Rate [0.0003125]
3: TRAIN [1][3190/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 79119 (53357)	Loss/tok 3.0829 (3.3555)	Learning Rate [0.0003125]
5: TRAIN [1][3190/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 79035 (53525)	Loss/tok 3.3269 (3.3578)	Learning Rate [0.0003125]
14: TRAIN [1][3190/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 80240 (54273)	Loss/tok 3.4816 (3.3553)	Learning Rate [0.0003125]
6: TRAIN [1][3190/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 79021 (53598)	Loss/tok 3.1272 (3.3568)	Learning Rate [0.0003125]
13: TRAIN [1][3190/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 80118 (54178)	Loss/tok 3.5508 (3.3581)	Learning Rate [0.0003125]
7: TRAIN [1][3190/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 79041 (53685)	Loss/tok 3.1573 (3.3572)	Learning Rate [0.0003125]
8: TRAIN [1][3190/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 79045 (53763)	Loss/tok 3.1613 (3.3609)	Learning Rate [0.0003125]
11: TRAIN [1][3190/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00091)	Tok/s 80115 (53979)	Loss/tok 3.1709 (3.3527)	Learning Rate [0.0003125]
10: TRAIN [1][3190/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00096)	Tok/s 80086 (53897)	Loss/tok 3.2431 (3.3549)	Learning Rate [0.0003125]
9: TRAIN [1][3190/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 79154 (53820)	Loss/tok 3.1803 (3.3505)	Learning Rate [0.0003125]
12: TRAIN [1][3190/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 80049 (54083)	Loss/tok 3.3622 (3.3553)	Learning Rate [0.0003125]
4: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00100)	Tok/s 49254 (53450)	Loss/tok 3.2231 (3.3564)	Learning Rate [0.0003125]
3: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00082 (0.00093)	Tok/s 49329 (53359)	Loss/tok 3.2548 (3.3552)	Learning Rate [0.0003125]
6: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00091)	Tok/s 49085 (53600)	Loss/tok 2.9857 (3.3562)	Learning Rate [0.0003125]
2: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00097)	Tok/s 49357 (53265)	Loss/tok 3.2584 (3.3634)	Learning Rate [0.0003125]
5: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00092)	Tok/s 49172 (53527)	Loss/tok 3.1883 (3.3576)	Learning Rate [0.0003125]
7: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00097)	Tok/s 49179 (53686)	Loss/tok 2.9937 (3.3569)	Learning Rate [0.0003125]
1: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00097)	Tok/s 49357 (53169)	Loss/tok 3.0589 (3.3634)	Learning Rate [0.0003125]
0: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00099)	Tok/s 49321 (53078)	Loss/tok 3.2225 (3.3584)	Learning Rate [0.0003125]
8: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00096)	Tok/s 49156 (53764)	Loss/tok 3.1495 (3.3606)	Learning Rate [0.0003125]
15: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00091)	Tok/s 50759 (54383)	Loss/tok 2.9562 (3.3550)	Learning Rate [0.0003125]
14: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00092)	Tok/s 49762 (54274)	Loss/tok 3.0848 (3.3549)	Learning Rate [0.0003125]
9: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00091)	Tok/s 49048 (53822)	Loss/tok 3.0591 (3.3502)	Learning Rate [0.0003125]
10: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00096)	Tok/s 49098 (53898)	Loss/tok 3.0524 (3.3550)	Learning Rate [0.0003125]
13: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00097)	Tok/s 49200 (54179)	Loss/tok 3.2598 (3.3577)	Learning Rate [0.0003125]
11: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00091)	Tok/s 49204 (53980)	Loss/tok 2.9297 (3.3526)	Learning Rate [0.0003125]
12: TRAIN [1][3200/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00096)	Tok/s 49126 (54084)	Loss/tok 3.6227 (3.3552)	Learning Rate [0.0003125]
11: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
13: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00097)	Tok/s 52843 (54158)	Loss/tok 3.2614 (3.3576)	Learning Rate [0.0003125]
11: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00091)	Tok/s 52630 (53959)	Loss/tok 3.3708 (3.3524)	Learning Rate [0.0003125]
12: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00096)	Tok/s 52701 (54063)	Loss/tok 3.3053 (3.3548)	Learning Rate [0.0003125]
14: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00092)	Tok/s 52828 (54254)	Loss/tok 3.2420 (3.3545)	Learning Rate [0.0003125]
15: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00091)	Tok/s 52835 (54363)	Loss/tok 3.0699 (3.3547)	Learning Rate [0.0003125]
0: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00099)	Tok/s 51673 (53059)	Loss/tok 3.4586 (3.3581)	Learning Rate [0.0003125]
10: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00096)	Tok/s 52509 (53877)	Loss/tok 3.4200 (3.3547)	Learning Rate [0.0003125]
1: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00104 (0.00097)	Tok/s 51608 (53149)	Loss/tok 3.4947 (3.3633)	Learning Rate [0.0003125]
9: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00091)	Tok/s 52405 (53801)	Loss/tok 3.2523 (3.3500)	Learning Rate [0.0003125]
8: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00096)	Tok/s 52387 (53743)	Loss/tok 3.4243 (3.3603)	Learning Rate [0.0003125]
2: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00097)	Tok/s 51537 (53245)	Loss/tok 3.1925 (3.3629)	Learning Rate [0.0003125]
6: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00091)	Tok/s 52113 (53579)	Loss/tok 3.5167 (3.3560)	Learning Rate [0.0003125]
4: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00108 (0.00100)	Tok/s 51393 (53430)	Loss/tok 3.5693 (3.3562)	Learning Rate [0.0003125]
7: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00097)	Tok/s 52394 (53665)	Loss/tok 3.2542 (3.3566)	Learning Rate [0.0003125]
3: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00084 (0.00093)	Tok/s 51403 (53338)	Loss/tok 3.2644 (3.3548)	Learning Rate [0.0003125]
5: TRAIN [1][3210/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00092)	Tok/s 51308 (53506)	Loss/tok 3.0839 (3.3573)	Learning Rate [0.0003125]
4: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00100)	Tok/s 70737 (53427)	Loss/tok 3.2470 (3.3558)	Learning Rate [0.0003125]
6: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00091)	Tok/s 71544 (53576)	Loss/tok 3.3421 (3.3558)	Learning Rate [0.0003125]
3: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 70688 (53336)	Loss/tok 3.5409 (3.3547)	Learning Rate [0.0003125]
5: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 70655 (53503)	Loss/tok 3.3804 (3.3570)	Learning Rate [0.0003125]
1: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 70573 (53146)	Loss/tok 3.2373 (3.3630)	Learning Rate [0.0003125]
2: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 70566 (53242)	Loss/tok 3.1685 (3.3625)	Learning Rate [0.0003125]
8: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 71533 (53740)	Loss/tok 3.3003 (3.3598)	Learning Rate [0.0003125]
7: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 71472 (53662)	Loss/tok 3.2645 (3.3561)	Learning Rate [0.0003125]
0: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00099)	Tok/s 70518 (53055)	Loss/tok 3.2838 (3.3577)	Learning Rate [0.0003125]
15: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 71482 (54358)	Loss/tok 3.4422 (3.3547)	Learning Rate [0.0003125]
13: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 71539 (54154)	Loss/tok 3.3283 (3.3571)	Learning Rate [0.0003125]
9: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 71453 (53798)	Loss/tok 3.4784 (3.3500)	Learning Rate [0.0003125]
14: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 71476 (54249)	Loss/tok 3.4028 (3.3545)	Learning Rate [0.0003125]
10: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 71477 (53874)	Loss/tok 3.2918 (3.3546)	Learning Rate [0.0003125]
11: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00091)	Tok/s 71566 (53956)	Loss/tok 3.6172 (3.3522)	Learning Rate [0.0003125]
12: TRAIN [1][3220/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 71388 (54059)	Loss/tok 3.3462 (3.3546)	Learning Rate [0.0003125]
5: Gradient norm: inf
4: Gradient norm: inf
6: Gradient norm: inf
5: Skipped batch, new scale: 2048.0
4: Skipped batch, new scale: 2048.0
3: Gradient norm: inf
6: Skipped batch, new scale: 2048.0
2: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
7: Gradient norm: inf
12: Gradient norm: inf
2: Skipped batch, new scale: 2048.0
7: Skipped batch, new scale: 2048.0
1: Gradient norm: inf
8: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
13: Gradient norm: inf
9: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
11: Skipped batch, new scale: 2048.0
8: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
14: Gradient norm: inf
10: Skipped batch, new scale: 2048.0
13: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
0: Skipped batch, new scale: 2048.0
14: Skipped batch, new scale: 2048.0
15: Skipped batch, new scale: 2048.0
6: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00098 (0.00091)	Tok/s 22316 (53571)	Loss/tok 2.2283 (3.3552)	Learning Rate [0.0003125]
7: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00096 (0.00097)	Tok/s 23500 (53657)	Loss/tok 2.1180 (3.3557)	Learning Rate [0.0003125]
5: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00099 (0.00092)	Tok/s 20728 (53498)	Loss/tok 2.1254 (3.3568)	Learning Rate [0.0003125]
9: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00092 (0.00091)	Tok/s 24497 (53792)	Loss/tok 1.9649 (3.3493)	Learning Rate [0.0003125]
4: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00119 (0.00100)	Tok/s 18985 (53421)	Loss/tok 1.9962 (3.3553)	Learning Rate [0.0003125]
8: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00092 (0.00096)	Tok/s 24383 (53735)	Loss/tok 1.8832 (3.3591)	Learning Rate [0.0003125]
3: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00094 (0.00093)	Tok/s 17144 (53329)	Loss/tok 1.6495 (3.3544)	Learning Rate [0.0003125]
11: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00109 (0.00091)	Tok/s 24996 (53951)	Loss/tok 2.0515 (3.3518)	Learning Rate [0.0003125]
2: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00088 (0.00097)	Tok/s 16146 (53236)	Loss/tok 1.6703 (3.3621)	Learning Rate [0.0003125]
1: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00101 (0.00097)	Tok/s 12832 (53138)	Loss/tok 1.8670 (3.3626)	Learning Rate [0.0003125]
12: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00101 (0.00096)	Tok/s 26392 (54055)	Loss/tok 2.3178 (3.3542)	Learning Rate [0.0003125]
10: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00094 (0.00096)	Tok/s 24400 (53869)	Loss/tok 1.9867 (3.3543)	Learning Rate [0.0003125]
0: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00096 (0.00099)	Tok/s 9418 (53047)	Loss/tok 1.6268 (3.3571)	Learning Rate [0.0003125]
13: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00095 (0.00097)	Tok/s 26300 (54149)	Loss/tok 2.6266 (3.3568)	Learning Rate [0.0003125]
14: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00102 (0.00092)	Tok/s 27594 (54245)	Loss/tok 2.2318 (3.3540)	Learning Rate [0.0003125]
15: TRAIN [1][3230/3416]	Time 0.034 (0.058)	Data 0.00095 (0.00091)	Tok/s 28337 (54354)	Loss/tok 2.1429 (3.3545)	Learning Rate [0.0003125]
4: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00100)	Tok/s 51069 (53412)	Loss/tok 3.0344 (3.3550)	Learning Rate [0.0003125]
6: TRAIN [1][3240/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00091)	Tok/s 51219 (53562)	Loss/tok 3.2929 (3.3549)	Learning Rate [0.0003125]
8: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00096)	Tok/s 51197 (53726)	Loss/tok 3.3046 (3.3588)	Learning Rate [0.0003125]
3: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00093)	Tok/s 51017 (53320)	Loss/tok 3.0969 (3.3542)	Learning Rate [0.0003125]
7: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00097)	Tok/s 51117 (53648)	Loss/tok 2.9823 (3.3555)	Learning Rate [0.0003125]
2: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00097)	Tok/s 50992 (53227)	Loss/tok 2.8141 (3.3618)	Learning Rate [0.0003125]
1: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00097)	Tok/s 50970 (53129)	Loss/tok 3.4593 (3.3623)	Learning Rate [0.0003125]
9: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00091)	Tok/s 51117 (53783)	Loss/tok 3.2390 (3.3490)	Learning Rate [0.0003125]
0: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00099)	Tok/s 50981 (53038)	Loss/tok 2.9221 (3.3566)	Learning Rate [0.0003125]
11: TRAIN [1][3240/3416]	Time 0.047 (0.058)	Data 0.00111 (0.00091)	Tok/s 51251 (53941)	Loss/tok 3.0644 (3.3514)	Learning Rate [0.0003125]
10: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00096)	Tok/s 51096 (53859)	Loss/tok 3.2910 (3.3541)	Learning Rate [0.0003125]
12: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00096)	Tok/s 51456 (54045)	Loss/tok 3.1288 (3.3540)	Learning Rate [0.0003125]
15: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00091)	Tok/s 52295 (54344)	Loss/tok 3.0442 (3.3542)	Learning Rate [0.0003125]
5: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00092)	Tok/s 51095 (53488)	Loss/tok 3.0622 (3.3567)	Learning Rate [0.0003125]
14: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 52338 (54235)	Loss/tok 3.1032 (3.3537)	Learning Rate [0.0003125]
13: TRAIN [1][3240/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00097)	Tok/s 52339 (54140)	Loss/tok 3.1756 (3.3567)	Learning Rate [0.0003125]
8: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00096 (0.00096)	Tok/s 29816 (53726)	Loss/tok 2.4364 (3.3582)	Learning Rate [0.0003125]
7: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00094 (0.00097)	Tok/s 29797 (53649)	Loss/tok 2.6775 (3.3553)	Learning Rate [0.0003125]
6: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00100 (0.00091)	Tok/s 29615 (53563)	Loss/tok 2.5081 (3.3546)	Learning Rate [0.0003125]
9: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00091)	Tok/s 29852 (53784)	Loss/tok 2.5186 (3.3488)	Learning Rate [0.0003125]
4: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00104 (0.00100)	Tok/s 28094 (53413)	Loss/tok 2.4790 (3.3548)	Learning Rate [0.0003125]
3: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00093)	Tok/s 28099 (53321)	Loss/tok 2.5398 (3.3539)	Learning Rate [0.0003125]
10: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00098 (0.00096)	Tok/s 29721 (53860)	Loss/tok 2.7889 (3.3538)	Learning Rate [0.0003125]
11: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00108 (0.00091)	Tok/s 29799 (53942)	Loss/tok 2.6929 (3.3515)	Learning Rate [0.0003125]
2: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00097 (0.00097)	Tok/s 28082 (53227)	Loss/tok 2.6361 (3.3619)	Learning Rate [0.0003125]
0: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00099 (0.00099)	Tok/s 28132 (53039)	Loss/tok 2.6086 (3.3563)	Learning Rate [0.0003125]
1: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00109 (0.00097)	Tok/s 28076 (53130)	Loss/tok 2.4256 (3.3622)	Learning Rate [0.0003125]
12: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00098 (0.00096)	Tok/s 29816 (54046)	Loss/tok 2.5760 (3.3539)	Learning Rate [0.0003125]
13: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00097 (0.00097)	Tok/s 30255 (54140)	Loss/tok 2.5912 (3.3565)	Learning Rate [0.0003125]
15: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00088 (0.00091)	Tok/s 31138 (54345)	Loss/tok 2.7259 (3.3541)	Learning Rate [0.0003125]
14: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00093 (0.00092)	Tok/s 31255 (54236)	Loss/tok 2.6339 (3.3534)	Learning Rate [0.0003125]
5: TRAIN [1][3250/3416]	Time 0.041 (0.058)	Data 0.00097 (0.00092)	Tok/s 29196 (53490)	Loss/tok 2.7293 (3.3567)	Learning Rate [0.0003125]
8: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 68776 (53720)	Loss/tok 3.4563 (3.3578)	Learning Rate [0.0003125]
9: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 68694 (53778)	Loss/tok 3.3325 (3.3485)	Learning Rate [0.0003125]
6: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00091)	Tok/s 68715 (53556)	Loss/tok 3.2174 (3.3543)	Learning Rate [0.0003125]
10: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 68544 (53854)	Loss/tok 3.0889 (3.3534)	Learning Rate [0.0003125]
7: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 68702 (53642)	Loss/tok 3.2675 (3.3551)	Learning Rate [0.0003125]
11: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00091)	Tok/s 68446 (53935)	Loss/tok 3.2568 (3.3513)	Learning Rate [0.0003125]
12: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00096)	Tok/s 68344 (54039)	Loss/tok 3.1409 (3.3533)	Learning Rate [0.0003125]
13: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 68429 (54133)	Loss/tok 3.2833 (3.3561)	Learning Rate [0.0003125]
4: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00100)	Tok/s 68695 (53406)	Loss/tok 3.4254 (3.3547)	Learning Rate [0.0003125]
14: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 68364 (54229)	Loss/tok 3.3477 (3.3532)	Learning Rate [0.0003125]
3: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 68621 (53314)	Loss/tok 3.3204 (3.3536)	Learning Rate [0.0003125]
0: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00099)	Tok/s 67497 (53032)	Loss/tok 3.3795 (3.3559)	Learning Rate [0.0003125]
15: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 68333 (54338)	Loss/tok 3.3421 (3.3539)	Learning Rate [0.0003125]
2: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 67638 (53220)	Loss/tok 3.3998 (3.3616)	Learning Rate [0.0003125]
1: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 67493 (53123)	Loss/tok 3.5226 (3.3620)	Learning Rate [0.0003125]
5: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 68702 (53483)	Loss/tok 3.2483 (3.3563)	Learning Rate [0.0003125]
8: TRAIN [1][3270/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 59110 (53709)	Loss/tok 3.5223 (3.3573)	Learning Rate [0.0003125]
9: TRAIN [1][3270/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 58970 (53767)	Loss/tok 3.4233 (3.3480)	Learning Rate [0.0003125]
11: TRAIN [1][3270/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 59040 (53925)	Loss/tok 3.3589 (3.3508)	Learning Rate [0.0003125]
7: TRAIN [1][3270/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 59086 (53631)	Loss/tok 3.0964 (3.3544)	Learning Rate [0.0003125]
12: TRAIN [1][3270/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 59012 (54028)	Loss/tok 3.8478 (3.3530)	Learning Rate [0.0003125]
13: TRAIN [1][3270/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 58940 (54123)	Loss/tok 3.2275 (3.3557)	Learning Rate [0.0003125]
6: TRAIN [1][3270/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 58952 (53546)	Loss/tok 3.3287 (3.3540)	Learning Rate [0.0003125]
4: TRAIN [1][3270/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00100)	Tok/s 59069 (53396)	Loss/tok 3.3599 (3.3543)	Learning Rate [0.0003125]
15: TRAIN [1][3270/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00091)	Tok/s 59755 (54327)	Loss/tok 3.2010 (3.3535)	Learning Rate [0.0003125]
14: TRAIN [1][3270/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 59263 (54218)	Loss/tok 3.3177 (3.3527)	Learning Rate [0.0003125]
0: TRAIN [1][3270/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00099)	Tok/s 58895 (53022)	Loss/tok 3.2611 (3.3555)	Learning Rate [0.0003125]
3: TRAIN [1][3270/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 59013 (53303)	Loss/tok 3.4950 (3.3533)	Learning Rate [0.0003125]
1: TRAIN [1][3270/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 58892 (53112)	Loss/tok 3.4621 (3.3618)	Learning Rate [0.0003125]
2: TRAIN [1][3270/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 58947 (53210)	Loss/tok 3.6810 (3.3613)	Learning Rate [0.0003125]
5: TRAIN [1][3270/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 59013 (53472)	Loss/tok 3.6229 (3.3560)	Learning Rate [0.0003125]
10: TRAIN [1][3270/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 58350 (53842)	Loss/tok 3.3063 (3.3529)	Learning Rate [0.0003125]
6: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00091)	Tok/s 50241 (53567)	Loss/tok 3.0772 (3.3535)	Learning Rate [0.0003125]
7: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00097)	Tok/s 50405 (53652)	Loss/tok 3.1171 (3.3542)	Learning Rate [0.0003125]
8: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00096)	Tok/s 50435 (53730)	Loss/tok 3.4851 (3.3571)	Learning Rate [0.0003125]
9: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00077 (0.00091)	Tok/s 50367 (53788)	Loss/tok 3.3045 (3.3478)	Learning Rate [0.0003125]
4: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00100)	Tok/s 50303 (53417)	Loss/tok 2.8967 (3.3538)	Learning Rate [0.0003125]
11: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00091)	Tok/s 50504 (53946)	Loss/tok 3.1668 (3.3507)	Learning Rate [0.0003125]
10: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00096)	Tok/s 50321 (53864)	Loss/tok 3.2635 (3.3524)	Learning Rate [0.0003125]
3: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00082 (0.00093)	Tok/s 50242 (53325)	Loss/tok 3.0132 (3.3529)	Learning Rate [0.0003125]
2: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00097)	Tok/s 50318 (53231)	Loss/tok 3.0703 (3.3609)	Learning Rate [0.0003125]
1: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00097)	Tok/s 50321 (53134)	Loss/tok 2.9827 (3.3613)	Learning Rate [0.0003125]
12: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00096)	Tok/s 50615 (54050)	Loss/tok 3.0218 (3.3526)	Learning Rate [0.0003125]
0: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00099)	Tok/s 50205 (53044)	Loss/tok 3.4380 (3.3552)	Learning Rate [0.0003125]
13: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00097)	Tok/s 51238 (54144)	Loss/tok 3.2281 (3.3555)	Learning Rate [0.0003125]
15: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00091)	Tok/s 51680 (54349)	Loss/tok 3.0042 (3.3530)	Learning Rate [0.0003125]
14: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00092)	Tok/s 51701 (54240)	Loss/tok 2.9040 (3.3523)	Learning Rate [0.0003125]
5: TRAIN [1][3280/3416]	Time 0.046 (0.058)	Data 0.00081 (0.00092)	Tok/s 50259 (53494)	Loss/tok 3.2926 (3.3558)	Learning Rate [0.0003125]
15: TRAIN [1][3290/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00091)	Tok/s 68476 (54340)	Loss/tok 3.3782 (3.3528)	Learning Rate [0.0003125]
14: TRAIN [1][3290/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00092)	Tok/s 68499 (54231)	Loss/tok 3.3636 (3.3521)	Learning Rate [0.0003125]
0: TRAIN [1][3290/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 67481 (53035)	Loss/tok 3.4852 (3.3551)	Learning Rate [0.0003125]
9: TRAIN [1][3290/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 68240 (53780)	Loss/tok 3.1766 (3.3471)	Learning Rate [0.0003125]
8: TRAIN [1][3290/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00096)	Tok/s 68222 (53721)	Loss/tok 3.5400 (3.3568)	Learning Rate [0.0003125]
13: TRAIN [1][3290/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 68487 (54135)	Loss/tok 3.3737 (3.3553)	Learning Rate [0.0003125]
11: TRAIN [1][3290/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00091)	Tok/s 68326 (53938)	Loss/tok 3.5370 (3.3505)	Learning Rate [0.0003125]
1: TRAIN [1][3290/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 67410 (53125)	Loss/tok 3.3679 (3.3609)	Learning Rate [0.0003125]
7: TRAIN [1][3290/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00097)	Tok/s 67907 (53643)	Loss/tok 3.4412 (3.3539)	Learning Rate [0.0003125]
12: TRAIN [1][3290/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00096)	Tok/s 68475 (54041)	Loss/tok 3.3274 (3.3523)	Learning Rate [0.0003125]
6: TRAIN [1][3290/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00091)	Tok/s 67096 (53558)	Loss/tok 3.3798 (3.3532)	Learning Rate [0.0003125]
2: TRAIN [1][3290/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 67284 (53222)	Loss/tok 3.5271 (3.3606)	Learning Rate [0.0003125]
4: TRAIN [1][3290/3416]	Time 0.069 (0.058)	Data 0.00117 (0.00100)	Tok/s 67353 (53408)	Loss/tok 3.4724 (3.3536)	Learning Rate [0.0003125]
10: TRAIN [1][3290/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 68212 (53855)	Loss/tok 3.3818 (3.3520)	Learning Rate [0.0003125]
3: TRAIN [1][3290/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00093)	Tok/s 67145 (53315)	Loss/tok 3.3527 (3.3527)	Learning Rate [0.0003125]
5: TRAIN [1][3290/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 67096 (53484)	Loss/tok 3.5747 (3.3558)	Learning Rate [0.0003125]
6: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00091)	Tok/s 50661 (53537)	Loss/tok 3.3067 (3.3530)	Learning Rate [0.0003125]
7: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00101 (0.00097)	Tok/s 50653 (53623)	Loss/tok 2.9688 (3.3534)	Learning Rate [0.0003125]
4: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00105 (0.00100)	Tok/s 50733 (53386)	Loss/tok 3.2792 (3.3533)	Learning Rate [0.0003125]
8: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00084 (0.00096)	Tok/s 50535 (53701)	Loss/tok 3.1002 (3.3566)	Learning Rate [0.0003125]
3: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00093)	Tok/s 50686 (53294)	Loss/tok 3.3017 (3.3522)	Learning Rate [0.0003125]
9: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00091)	Tok/s 50589 (53760)	Loss/tok 2.9406 (3.3465)	Learning Rate [0.0003125]
1: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00097)	Tok/s 50710 (53102)	Loss/tok 3.3264 (3.3605)	Learning Rate [0.0003125]
11: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00091)	Tok/s 50650 (53918)	Loss/tok 3.2675 (3.3502)	Learning Rate [0.0003125]
0: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00099)	Tok/s 50838 (53011)	Loss/tok 3.2135 (3.3548)	Learning Rate [0.0003125]
2: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00097)	Tok/s 50612 (53200)	Loss/tok 3.3440 (3.3602)	Learning Rate [0.0003125]
10: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00085 (0.00096)	Tok/s 50503 (53835)	Loss/tok 3.3750 (3.3517)	Learning Rate [0.0003125]
15: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00091)	Tok/s 50663 (54320)	Loss/tok 3.1749 (3.3523)	Learning Rate [0.0003125]
14: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00099 (0.00092)	Tok/s 50639 (54211)	Loss/tok 3.2768 (3.3516)	Learning Rate [0.0003125]
12: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00100 (0.00096)	Tok/s 50690 (54021)	Loss/tok 3.1779 (3.3518)	Learning Rate [0.0003125]
5: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00083 (0.00092)	Tok/s 50664 (53464)	Loss/tok 3.0347 (3.3553)	Learning Rate [0.0003125]
13: TRAIN [1][3300/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00097)	Tok/s 50623 (54115)	Loss/tok 3.3425 (3.3552)	Learning Rate [0.0003125]
6: TRAIN [1][3310/3416]	Time 0.033 (0.058)	Data 0.00094 (0.00091)	Tok/s 22223 (53508)	Loss/tok 2.0572 (3.3528)	Learning Rate [0.0003125]
7: TRAIN [1][3310/3416]	Time 0.034 (0.058)	Data 0.00099 (0.00097)	Tok/s 22877 (53594)	Loss/tok 2.1908 (3.3530)	Learning Rate [0.0003125]
8: TRAIN [1][3310/3416]	Time 0.034 (0.058)	Data 0.00095 (0.00096)	Tok/s 24652 (53673)	Loss/tok 2.0156 (3.3563)	Learning Rate [0.0003125]
4: TRAIN [1][3310/3416]	Time 0.033 (0.058)	Data 0.00112 (0.00100)	Tok/s 19074 (53356)	Loss/tok 2.0920 (3.3529)	Learning Rate [0.0003125]
3: TRAIN [1][3310/3416]	Time 0.033 (0.058)	Data 0.00094 (0.00093)	Tok/s 17207 (53263)	Loss/tok 1.5677 (3.3519)	Learning Rate [0.0003125]
9: TRAIN [1][3310/3416]	Time 0.034 (0.058)	Data 0.00096 (0.00091)	Tok/s 24645 (53731)	Loss/tok 1.9796 (3.3459)	Learning Rate [0.0003125]
10: TRAIN [1][3310/3416]	Time 0.034 (0.058)	Data 0.00096 (0.00096)	Tok/s 24585 (53807)	Loss/tok 1.8219 (3.3511)	Learning Rate [0.0003125]
11: TRAIN [1][3310/3416]	Time 0.034 (0.058)	Data 0.00104 (0.00091)	Tok/s 24645 (53889)	Loss/tok 1.8673 (3.3496)	Learning Rate [0.0003125]
1: TRAIN [1][3310/3416]	Time 0.034 (0.058)	Data 0.00104 (0.00097)	Tok/s 12729 (53070)	Loss/tok 1.7740 (3.3601)	Learning Rate [0.0003125]
0: TRAIN [1][3310/3416]	Time 0.034 (0.058)	Data 0.00112 (0.00099)	Tok/s 9522 (52979)	Loss/tok 1.5273 (3.3544)	Learning Rate [0.0003125]
15: TRAIN [1][3310/3416]	Time 0.034 (0.058)	Data 0.00097 (0.00091)	Tok/s 28441 (54292)	Loss/tok 2.2061 (3.3520)	Learning Rate [0.0003125]
5: TRAIN [1][3310/3416]	Time 0.033 (0.058)	Data 0.00095 (0.00092)	Tok/s 21044 (53434)	Loss/tok 1.8783 (3.3548)	Learning Rate [0.0003125]
14: TRAIN [1][3310/3416]	Time 0.034 (0.058)	Data 0.00097 (0.00092)	Tok/s 26491 (54182)	Loss/tok 2.3166 (3.3513)	Learning Rate [0.0003125]
12: TRAIN [1][3310/3416]	Time 0.034 (0.058)	Data 0.00113 (0.00096)	Tok/s 26413 (53992)	Loss/tok 2.4030 (3.3514)	Learning Rate [0.0003125]
13: TRAIN [1][3310/3416]	Time 0.034 (0.058)	Data 0.00095 (0.00097)	Tok/s 26424 (54086)	Loss/tok 2.2737 (3.3550)	Learning Rate [0.0003125]
2: TRAIN [1][3310/3416]	Time 0.034 (0.058)	Data 0.00114 (0.00097)	Tok/s 15930 (53169)	Loss/tok 1.7863 (3.3599)	Learning Rate [0.0003125]
13: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 77977 (54100)	Loss/tok 3.1943 (3.3547)	Learning Rate [0.0003125]
12: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00096)	Tok/s 78030 (54006)	Loss/tok 3.3326 (3.3511)	Learning Rate [0.0003125]
11: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00091)	Tok/s 77942 (53903)	Loss/tok 3.2467 (3.3493)	Learning Rate [0.0003125]
14: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 77959 (54196)	Loss/tok 3.0882 (3.3509)	Learning Rate [0.0003125]
15: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00091)	Tok/s 77970 (54306)	Loss/tok 3.2061 (3.3517)	Learning Rate [0.0003125]
8: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 77209 (53687)	Loss/tok 3.4111 (3.3562)	Learning Rate [0.0003125]
9: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00091)	Tok/s 77124 (53745)	Loss/tok 3.0331 (3.3453)	Learning Rate [0.0003125]
0: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00099)	Tok/s 76139 (52993)	Loss/tok 3.1436 (3.3544)	Learning Rate [0.0003125]
10: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 77014 (53821)	Loss/tok 3.1398 (3.3509)	Learning Rate [0.0003125]
7: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 77212 (53608)	Loss/tok 3.2144 (3.3526)	Learning Rate [0.0003125]
1: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 76141 (53084)	Loss/tok 3.3203 (3.3597)	Learning Rate [0.0003125]
6: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 77189 (53522)	Loss/tok 3.4245 (3.3527)	Learning Rate [0.0003125]
2: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 76330 (53183)	Loss/tok 3.5856 (3.3600)	Learning Rate [0.0003125]
4: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00100)	Tok/s 77132 (53370)	Loss/tok 3.3452 (3.3528)	Learning Rate [0.0003125]
3: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00093)	Tok/s 77066 (53278)	Loss/tok 3.0503 (3.3517)	Learning Rate [0.0003125]
5: TRAIN [1][3320/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 77215 (53448)	Loss/tok 3.2542 (3.3544)	Learning Rate [0.0003125]
6: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00091)	Tok/s 31864 (53519)	Loss/tok 3.0316 (3.3525)	Learning Rate [0.0003125]
7: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00109 (0.00097)	Tok/s 31908 (53604)	Loss/tok 3.0377 (3.3524)	Learning Rate [0.0003125]
4: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00110 (0.00100)	Tok/s 31816 (53368)	Loss/tok 2.9525 (3.3525)	Learning Rate [0.0003125]
8: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00096)	Tok/s 31848 (53683)	Loss/tok 2.7181 (3.3559)	Learning Rate [0.0003125]
9: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00081 (0.00091)	Tok/s 31733 (53741)	Loss/tok 2.9260 (3.3450)	Learning Rate [0.0003125]
2: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00097)	Tok/s 31695 (53181)	Loss/tok 2.8825 (3.3598)	Learning Rate [0.0003125]
1: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00097)	Tok/s 31654 (53082)	Loss/tok 3.0349 (3.3592)	Learning Rate [0.0003125]
10: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00096)	Tok/s 32474 (53817)	Loss/tok 2.9324 (3.3507)	Learning Rate [0.0003125]
3: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00093)	Tok/s 31726 (53275)	Loss/tok 2.9248 (3.3513)	Learning Rate [0.0003125]
0: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00099)	Tok/s 31517 (52991)	Loss/tok 3.1327 (3.3540)	Learning Rate [0.0003125]
12: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00096)	Tok/s 32899 (54003)	Loss/tok 2.7751 (3.3506)	Learning Rate [0.0003125]
15: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00102 (0.00091)	Tok/s 32766 (54303)	Loss/tok 2.8525 (3.3512)	Learning Rate [0.0003125]
5: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00092)	Tok/s 31854 (53446)	Loss/tok 2.9154 (3.3537)	Learning Rate [0.0003125]
14: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00092)	Tok/s 32766 (54193)	Loss/tok 2.8412 (3.3507)	Learning Rate [0.0003125]
11: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00091)	Tok/s 32848 (53900)	Loss/tok 2.9282 (3.3489)	Learning Rate [0.0003125]
13: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00097)	Tok/s 32806 (54097)	Loss/tok 2.9926 (3.3544)	Learning Rate [0.0003125]
7: TRAIN [1][3340/3416]	Time 0.035 (0.058)	Data 0.00087 (0.00097)	Tok/s 23638 (53596)	Loss/tok 2.0468 (3.3523)	Learning Rate [0.0003125]
8: TRAIN [1][3340/3416]	Time 0.035 (0.058)	Data 0.00085 (0.00096)	Tok/s 23580 (53675)	Loss/tok 1.9738 (3.3555)	Learning Rate [0.0003125]
6: TRAIN [1][3340/3416]	Time 0.035 (0.058)	Data 0.00089 (0.00091)	Tok/s 23614 (53511)	Loss/tok 2.0025 (3.3520)	Learning Rate [0.0003125]
4: TRAIN [1][3340/3416]	Time 0.035 (0.058)	Data 0.00092 (0.00100)	Tok/s 20692 (53359)	Loss/tok 1.9683 (3.3521)	Learning Rate [0.0003125]
10: TRAIN [1][3340/3416]	Time 0.036 (0.058)	Data 0.00083 (0.00096)	Tok/s 25214 (53809)	Loss/tok 2.4487 (3.3503)	Learning Rate [0.0003125]
3: TRAIN [1][3340/3416]	Time 0.036 (0.058)	Data 0.00081 (0.00093)	Tok/s 19154 (53266)	Loss/tok 2.1373 (3.3511)	Learning Rate [0.0003125]
11: TRAIN [1][3340/3416]	Time 0.036 (0.058)	Data 0.00087 (0.00092)	Tok/s 26672 (53892)	Loss/tok 2.1819 (3.3490)	Learning Rate [0.0003125]
9: TRAIN [1][3340/3416]	Time 0.035 (0.058)	Data 0.00086 (0.00091)	Tok/s 25006 (53733)	Loss/tok 2.2604 (3.3447)	Learning Rate [0.0003125]
2: TRAIN [1][3340/3416]	Time 0.036 (0.058)	Data 0.00087 (0.00097)	Tok/s 16190 (53171)	Loss/tok 1.5614 (3.3594)	Learning Rate [0.0003125]
1: TRAIN [1][3340/3416]	Time 0.036 (0.058)	Data 0.00107 (0.00097)	Tok/s 14230 (53072)	Loss/tok 1.8289 (3.3589)	Learning Rate [0.0003125]
12: TRAIN [1][3340/3416]	Time 0.036 (0.058)	Data 0.00103 (0.00096)	Tok/s 26787 (53996)	Loss/tok 2.2860 (3.3503)	Learning Rate [0.0003125]
0: TRAIN [1][3340/3416]	Time 0.036 (0.058)	Data 0.00098 (0.00099)	Tok/s 9684 (52980)	Loss/tok 1.6577 (3.3536)	Learning Rate [0.0003125]
13: TRAIN [1][3340/3416]	Time 0.036 (0.058)	Data 0.00086 (0.00097)	Tok/s 26738 (54089)	Loss/tok 2.2469 (3.3540)	Learning Rate [0.0003125]
15: TRAIN [1][3340/3416]	Time 0.036 (0.058)	Data 0.00101 (0.00091)	Tok/s 28507 (54296)	Loss/tok 2.4796 (3.3508)	Learning Rate [0.0003125]
14: TRAIN [1][3340/3416]	Time 0.036 (0.058)	Data 0.00098 (0.00092)	Tok/s 27735 (54185)	Loss/tok 2.3465 (3.3502)	Learning Rate [0.0003125]
5: TRAIN [1][3340/3416]	Time 0.035 (0.058)	Data 0.00090 (0.00092)	Tok/s 21789 (53437)	Loss/tok 2.0838 (3.3533)	Learning Rate [0.0003125]
4: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00100)	Tok/s 68850 (53371)	Loss/tok 3.2701 (3.3518)	Learning Rate [0.0003125]
3: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00093)	Tok/s 68860 (53278)	Loss/tok 3.3677 (3.3509)	Learning Rate [0.0003125]
2: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 68641 (53182)	Loss/tok 3.2879 (3.3590)	Learning Rate [0.0003125]
6: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00091)	Tok/s 68609 (53523)	Loss/tok 3.2245 (3.3516)	Learning Rate [0.0003125]
1: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00097)	Tok/s 67957 (53082)	Loss/tok 3.4514 (3.3589)	Learning Rate [0.0003125]
7: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00097)	Tok/s 68786 (53608)	Loss/tok 3.3676 (3.3521)	Learning Rate [0.0003125]
0: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00099)	Tok/s 67805 (52989)	Loss/tok 3.3261 (3.3534)	Learning Rate [0.0003125]
8: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 68762 (53688)	Loss/tok 3.2633 (3.3550)	Learning Rate [0.0003125]
15: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00119 (0.00091)	Tok/s 69723 (54309)	Loss/tok 3.3393 (3.3507)	Learning Rate [0.0003125]
9: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00091)	Tok/s 68769 (53746)	Loss/tok 3.3407 (3.3445)	Learning Rate [0.0003125]
14: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 68842 (54198)	Loss/tok 3.5638 (3.3499)	Learning Rate [0.0003125]
10: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 68775 (53822)	Loss/tok 3.4384 (3.3501)	Learning Rate [0.0003125]
13: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 68868 (54102)	Loss/tok 3.3904 (3.3541)	Learning Rate [0.0003125]
11: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00113 (0.00092)	Tok/s 68718 (53905)	Loss/tok 3.4692 (3.3486)	Learning Rate [0.0003125]
5: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 68640 (53449)	Loss/tok 3.2192 (3.3531)	Learning Rate [0.0003125]
12: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 68851 (54009)	Loss/tok 3.4494 (3.3500)	Learning Rate [0.0003125]
4: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
0: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00100 (0.00099)	Tok/s 51605 (52987)	Loss/tok 3.3020 (3.3531)	Learning Rate [0.0003125]
1: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00097)	Tok/s 51513 (53080)	Loss/tok 3.4037 (3.3587)	Learning Rate [0.0003125]
14: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00104 (0.00092)	Tok/s 52816 (54196)	Loss/tok 3.3187 (3.3497)	Learning Rate [0.0003125]
2: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00097)	Tok/s 51935 (53181)	Loss/tok 3.2448 (3.3588)	Learning Rate [0.0003125]
11: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00111 (0.00092)	Tok/s 52867 (53903)	Loss/tok 3.2489 (3.3486)	Learning Rate [0.0003125]
15: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00104 (0.00091)	Tok/s 52788 (54307)	Loss/tok 3.2057 (3.3507)	Learning Rate [0.0003125]
12: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00099 (0.00096)	Tok/s 52821 (54007)	Loss/tok 3.0948 (3.3497)	Learning Rate [0.0003125]
13: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00097)	Tok/s 52838 (54100)	Loss/tok 3.4950 (3.3541)	Learning Rate [0.0003125]
3: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00093)	Tok/s 52497 (53276)	Loss/tok 3.3561 (3.3507)	Learning Rate [0.0003125]
4: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00101 (0.00100)	Tok/s 52397 (53370)	Loss/tok 2.9578 (3.3513)	Learning Rate [0.0003125]
10: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00096)	Tok/s 52669 (53820)	Loss/tok 3.1819 (3.3500)	Learning Rate [0.0003125]
8: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00096)	Tok/s 52445 (53686)	Loss/tok 2.9984 (3.3547)	Learning Rate [0.0003125]
9: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00091)	Tok/s 52543 (53745)	Loss/tok 3.0260 (3.3441)	Learning Rate [0.0003125]
7: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00112 (0.00097)	Tok/s 52395 (53607)	Loss/tok 3.4739 (3.3520)	Learning Rate [0.0003125]
6: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00106 (0.00091)	Tok/s 52384 (53522)	Loss/tok 3.4002 (3.3516)	Learning Rate [0.0003125]
5: TRAIN [1][3360/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00092)	Tok/s 52374 (53448)	Loss/tok 3.3905 (3.3527)	Learning Rate [0.0003125]
9: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 62558 (53732)	Loss/tok 3.4701 (3.3437)	Learning Rate [0.0003125]
8: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00096)	Tok/s 62483 (53674)	Loss/tok 3.3976 (3.3542)	Learning Rate [0.0003125]
10: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 62578 (53808)	Loss/tok 3.5514 (3.3500)	Learning Rate [0.0003125]
11: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 62427 (53890)	Loss/tok 3.1763 (3.3480)	Learning Rate [0.0003125]
6: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00091)	Tok/s 62214 (53509)	Loss/tok 3.4880 (3.3513)	Learning Rate [0.0003125]
7: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 62341 (53595)	Loss/tok 3.3942 (3.3517)	Learning Rate [0.0003125]
12: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 62447 (53994)	Loss/tok 3.3495 (3.3495)	Learning Rate [0.0003125]
4: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 61979 (53356)	Loss/tok 3.3699 (3.3511)	Learning Rate [0.0003125]
13: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 62266 (54088)	Loss/tok 3.4261 (3.3538)	Learning Rate [0.0003125]
14: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 62191 (54183)	Loss/tok 3.3549 (3.3494)	Learning Rate [0.0003125]
3: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 61903 (53261)	Loss/tok 3.1524 (3.3503)	Learning Rate [0.0003125]
15: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00091)	Tok/s 62107 (54294)	Loss/tok 3.3589 (3.3502)	Learning Rate [0.0003125]
2: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 61877 (53166)	Loss/tok 3.6342 (3.3586)	Learning Rate [0.0003125]
0: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 61762 (52971)	Loss/tok 3.5173 (3.3529)	Learning Rate [0.0003125]
1: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00097)	Tok/s 61882 (53064)	Loss/tok 3.3917 (3.3585)	Learning Rate [0.0003125]
5: TRAIN [1][3370/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 62123 (53435)	Loss/tok 3.4505 (3.3524)	Learning Rate [0.0003125]
13: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00097)	Tok/s 50919 (54076)	Loss/tok 3.1324 (3.3534)	Learning Rate [0.0003125]
11: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00092)	Tok/s 50814 (53878)	Loss/tok 3.1666 (3.3478)	Learning Rate [0.0003125]
12: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00096)	Tok/s 50858 (53982)	Loss/tok 3.3161 (3.3494)	Learning Rate [0.0003125]
14: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00092)	Tok/s 50864 (54173)	Loss/tok 3.2760 (3.3492)	Learning Rate [0.0003125]
9: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00091)	Tok/s 50515 (53720)	Loss/tok 3.1333 (3.3433)	Learning Rate [0.0003125]
15: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00109 (0.00091)	Tok/s 50806 (54284)	Loss/tok 3.0685 (3.3500)	Learning Rate [0.0003125]
8: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00096)	Tok/s 50376 (53662)	Loss/tok 3.3968 (3.3540)	Learning Rate [0.0003125]
0: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00098)	Tok/s 50689 (52954)	Loss/tok 3.1257 (3.3528)	Learning Rate [0.0003125]
6: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00091)	Tok/s 50361 (53496)	Loss/tok 3.3111 (3.3512)	Learning Rate [0.0003125]
10: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00096)	Tok/s 50626 (53795)	Loss/tok 3.0165 (3.3497)	Learning Rate [0.0003125]
1: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00097)	Tok/s 50588 (53048)	Loss/tok 3.1347 (3.3581)	Learning Rate [0.0003125]
7: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00097)	Tok/s 50294 (53582)	Loss/tok 3.2550 (3.3514)	Learning Rate [0.0003125]
2: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00097)	Tok/s 50517 (53151)	Loss/tok 3.3093 (3.3584)	Learning Rate [0.0003125]
4: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00100)	Tok/s 50296 (53342)	Loss/tok 3.1562 (3.3508)	Learning Rate [0.0003125]
3: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00093)	Tok/s 50424 (53248)	Loss/tok 3.3585 (3.3501)	Learning Rate [0.0003125]
5: TRAIN [1][3380/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00092)	Tok/s 50338 (53422)	Loss/tok 3.0859 (3.3521)	Learning Rate [0.0003125]
11: Gradient norm: inf
12: Gradient norm: inf
10: Gradient norm: inf
13: Gradient norm: inf
11: Skipped batch, new scale: 2048.0
12: Skipped batch, new scale: 2048.0
9: Gradient norm: inf
10: Skipped batch, new scale: 2048.0
13: Skipped batch, new scale: 2048.0
14: Gradient norm: inf
9: Skipped batch, new scale: 2048.0
8: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
8: Skipped batch, new scale: 2048.0
7: Gradient norm: inf
12: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 82558 (53976)	Loss/tok 3.0987 (3.3488)	Learning Rate [0.0003125]
11: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 82560 (53872)	Loss/tok 3.0143 (3.3476)	Learning Rate [0.0003125]
0: Gradient norm: inf
10: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 82436 (53790)	Loss/tok 3.2736 (3.3493)	Learning Rate [0.0003125]
15: Skipped batch, new scale: 2048.0
13: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 82608 (54071)	Loss/tok 3.2214 (3.3531)	Learning Rate [0.0003125]
6: Gradient norm: inf
7: Skipped batch, new scale: 2048.0
9: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00091)	Tok/s 82036 (53715)	Loss/tok 3.0276 (3.3429)	Learning Rate [0.0003125]
3: Gradient norm: inf
4: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
1: Gradient norm: inf
2: Gradient norm: inf
5: Gradient norm: inf
6: Skipped batch, new scale: 2048.0
14: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 82610 (54167)	Loss/tok 3.4142 (3.3490)	Learning Rate [0.0003125]
4: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
8: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 81563 (53657)	Loss/tok 3.0683 (3.3538)	Learning Rate [0.0003125]
2: Skipped batch, new scale: 2048.0
1: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
15: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00091)	Tok/s 83150 (54278)	Loss/tok 3.1001 (3.3497)	Learning Rate [0.0003125]
7: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00114 (0.00097)	Tok/s 81579 (53577)	Loss/tok 3.2750 (3.3512)	Learning Rate [0.0003125]
0: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00098)	Tok/s 80697 (52951)	Loss/tok 3.2539 (3.3528)	Learning Rate [0.0003125]
6: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00079 (0.00091)	Tok/s 81469 (53491)	Loss/tok 3.0430 (3.3506)	Learning Rate [0.0003125]
4: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00100)	Tok/s 81576 (53338)	Loss/tok 3.1921 (3.3504)	Learning Rate [0.0003125]
1: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 80699 (53044)	Loss/tok 3.0276 (3.3577)	Learning Rate [0.0003125]
5: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 82013 (53417)	Loss/tok 3.2577 (3.3518)	Learning Rate [0.0003125]
2: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00097)	Tok/s 80750 (53147)	Loss/tok 3.1884 (3.3579)	Learning Rate [0.0003125]
3: TRAIN [1][3390/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 81313 (53243)	Loss/tok 3.4351 (3.3501)	Learning Rate [0.0003125]
11: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00091 (0.00092)	Tok/s 30326 (53862)	Loss/tok 2.4567 (3.3472)	Learning Rate [0.0003125]
12: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00098 (0.00096)	Tok/s 30395 (53966)	Loss/tok 2.5989 (3.3487)	Learning Rate [0.0003125]
13: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00107 (0.00097)	Tok/s 30502 (54061)	Loss/tok 2.6163 (3.3529)	Learning Rate [0.0003125]
10: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00096 (0.00096)	Tok/s 30248 (53779)	Loss/tok 2.4680 (3.3489)	Learning Rate [0.0003125]
0: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00106 (0.00098)	Tok/s 28774 (52942)	Loss/tok 2.4454 (3.3527)	Learning Rate [0.0003125]
15: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00102 (0.00091)	Tok/s 31998 (54268)	Loss/tok 2.6876 (3.3497)	Learning Rate [0.0003125]
9: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00087 (0.00091)	Tok/s 30172 (53704)	Loss/tok 2.7842 (3.3427)	Learning Rate [0.0003125]
14: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00095 (0.00092)	Tok/s 31970 (54157)	Loss/tok 2.7820 (3.3486)	Learning Rate [0.0003125]
1: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00099 (0.00097)	Tok/s 28714 (53035)	Loss/tok 2.5483 (3.3576)	Learning Rate [0.0003125]
8: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00097 (0.00096)	Tok/s 30090 (53647)	Loss/tok 2.8613 (3.3536)	Learning Rate [0.0003125]
7: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00113 (0.00097)	Tok/s 30043 (53567)	Loss/tok 2.6578 (3.3509)	Learning Rate [0.0003125]
6: TRAIN [1][3400/3416]	Time 0.041 (0.058)	Data 0.00086 (0.00091)	Tok/s 29990 (53481)	Loss/tok 2.5546 (3.3504)	Learning Rate [0.0003125]
2: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00105 (0.00097)	Tok/s 28631 (53137)	Loss/tok 2.4851 (3.3575)	Learning Rate [0.0003125]
3: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00086 (0.00093)	Tok/s 28542 (53233)	Loss/tok 2.5300 (3.3500)	Learning Rate [0.0003125]
4: TRAIN [1][3400/3416]	Time 0.040 (0.058)	Data 0.00098 (0.00100)	Tok/s 28491 (53327)	Loss/tok 2.5760 (3.3503)	Learning Rate [0.0003125]
5: TRAIN [1][3400/3416]	Time 0.041 (0.058)	Data 0.00090 (0.00092)	Tok/s 29840 (53407)	Loss/tok 2.6877 (3.3515)	Learning Rate [0.0003125]
14: Gradient norm: inf
13: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
15: Gradient norm: inf
0: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
10: Gradient norm: inf
2: Gradient norm: inf
9: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
5: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
13: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00097)	Tok/s 50366 (54064)	Loss/tok 2.9460 (3.3525)	Learning Rate [0.0003125]
12: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00096)	Tok/s 50322 (53969)	Loss/tok 3.6418 (3.3485)	Learning Rate [0.0003125]
11: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00079 (0.00092)	Tok/s 50362 (53864)	Loss/tok 3.2317 (3.3467)	Learning Rate [0.0003125]
14: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00092)	Tok/s 50262 (54160)	Loss/tok 2.8805 (3.3481)	Learning Rate [0.0003125]
15: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00079 (0.00091)	Tok/s 50149 (54271)	Loss/tok 3.1416 (3.3491)	Learning Rate [0.0003125]
0: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00099)	Tok/s 50135 (52945)	Loss/tok 3.2122 (3.3525)	Learning Rate [0.0003125]
10: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00096)	Tok/s 50313 (53782)	Loss/tok 3.2642 (3.3485)	Learning Rate [0.0003125]
9: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00091)	Tok/s 50207 (53707)	Loss/tok 3.0174 (3.3421)	Learning Rate [0.0003125]
1: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00097)	Tok/s 50256 (53038)	Loss/tok 3.2617 (3.3571)	Learning Rate [0.0003125]
8: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00096)	Tok/s 50254 (53649)	Loss/tok 3.1522 (3.3532)	Learning Rate [0.0003125]
2: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00097)	Tok/s 50183 (53140)	Loss/tok 3.2166 (3.3571)	Learning Rate [0.0003125]
7: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00097)	Tok/s 50237 (53570)	Loss/tok 3.2146 (3.3505)	Learning Rate [0.0003125]
6: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00080 (0.00091)	Tok/s 50195 (53484)	Loss/tok 3.2699 (3.3500)	Learning Rate [0.0003125]
3: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00093)	Tok/s 50120 (53236)	Loss/tok 3.0883 (3.3497)	Learning Rate [0.0003125]
4: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00100)	Tok/s 50119 (53330)	Loss/tok 3.2703 (3.3498)	Learning Rate [0.0003125]
5: TRAIN [1][3410/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00092)	Tok/s 50227 (53410)	Loss/tok 3.1974 (3.3510)	Learning Rate [0.0003125]
0: Running validation on dev set
15: Running validation on dev set
1: Running validation on dev set
2: Running validation on dev set
10: Running validation on dev set
3: Running validation on dev set
14: Running validation on dev set
7: Running validation on dev set
4: Running validation on dev set
5: Running validation on dev set
12: Running validation on dev set
13: Running validation on dev set
6: Running validation on dev set
9: Running validation on dev set
11: Running validation on dev set
8: Running validation on dev set
15: VALIDATION [1][0/5]	Time 0.023 (0.000)	Data 0.00242 (0.00000)	Tok/s 220648 (0)	Loss/tok 3.1218 (0.0000)	Learning Rate [0.0003125]
1: VALIDATION [1][0/5]	Time 0.037 (0.000)	Data 0.00212 (0.00000)	Tok/s 226306 (0)	Loss/tok 3.2871 (0.0000)	Learning Rate [0.0003125]
0: VALIDATION [1][0/5]	Time 0.060 (0.000)	Data 0.00228 (0.00000)	Tok/s 169753 (0)	Loss/tok 3.3764 (0.0000)	Learning Rate [0.0003125]
2: VALIDATION [1][0/5]	Time 0.035 (0.000)	Data 0.00219 (0.00000)	Tok/s 219628 (0)	Loss/tok 3.2618 (0.0000)	Learning Rate [0.0003125]
10: VALIDATION [1][0/5]	Time 0.025 (0.000)	Data 0.00220 (0.00000)	Tok/s 224019 (0)	Loss/tok 3.0942 (0.0000)	Learning Rate [0.0003125]
14: VALIDATION [1][0/5]	Time 0.023 (0.000)	Data 0.00226 (0.00000)	Tok/s 222080 (0)	Loss/tok 3.2702 (0.0000)	Learning Rate [0.0003125]
3: VALIDATION [1][0/5]	Time 0.033 (0.000)	Data 0.00363 (0.00000)	Tok/s 216719 (0)	Loss/tok 3.1576 (0.0000)	Learning Rate [0.0003125]
7: VALIDATION [1][0/5]	Time 0.028 (0.000)	Data 0.00217 (0.00000)	Tok/s 225384 (0)	Loss/tok 3.2745 (0.0000)	Learning Rate [0.0003125]
4: VALIDATION [1][0/5]	Time 0.032 (0.000)	Data 0.00215 (0.00000)	Tok/s 218592 (0)	Loss/tok 3.1097 (0.0000)	Learning Rate [0.0003125]
12: VALIDATION [1][0/5]	Time 0.023 (0.000)	Data 0.00211 (0.00000)	Tok/s 233867 (0)	Loss/tok 3.1306 (0.0000)	Learning Rate [0.0003125]
5: VALIDATION [1][0/5]	Time 0.029 (0.000)	Data 0.00213 (0.00000)	Tok/s 228172 (0)	Loss/tok 3.1562 (0.0000)	Learning Rate [0.0003125]
13: VALIDATION [1][0/5]	Time 0.025 (0.000)	Data 0.00217 (0.00000)	Tok/s 208591 (0)	Loss/tok 3.2592 (0.0000)	Learning Rate [0.0003125]
9: VALIDATION [1][0/5]	Time 0.027 (0.000)	Data 0.00288 (0.00000)	Tok/s 211827 (0)	Loss/tok 3.2402 (0.0000)	Learning Rate [0.0003125]
11: VALIDATION [1][0/5]	Time 0.028 (0.000)	Data 0.00501 (0.00000)	Tok/s 196743 (0)	Loss/tok 3.1475 (0.0000)	Learning Rate [0.0003125]
6: VALIDATION [1][0/5]	Time 0.030 (0.000)	Data 0.00276 (0.00000)	Tok/s 217046 (0)	Loss/tok 3.1130 (0.0000)	Learning Rate [0.0003125]
8: VALIDATION [1][0/5]	Time 0.026 (0.000)	Data 0.00216 (0.00000)	Tok/s 228708 (0)	Loss/tok 3.2479 (0.0000)	Learning Rate [0.0003125]
9: Running evaluation on test set
13: Running evaluation on test set
4: Running evaluation on test set
2: Running evaluation on test set
10: Running evaluation on test set
7: Running evaluation on test set
6: Running evaluation on test set
5: Running evaluation on test set
14: Running evaluation on test set
1: Running evaluation on test set
8: Running evaluation on test set
15: Running evaluation on test set
3: Running evaluation on test set
11: Running evaluation on test set
12: Running evaluation on test set
:::MLPv0.5.0 gnmt 1541784499.568727016 (train.py:459) eval_start: 1
0: Running evaluation on test set
9: TEST [1][0/2]	Time 0.996 (0.996)	Decoder iters 61.0 (61.0)	Tok/s 6768 (6768)
8: TEST [1][0/2]	Time 0.998 (0.998)	Decoder iters 79.0 (79.0)	Tok/s 7510 (7510)
1: TEST [1][0/2]	Time 0.998 (0.998)	Decoder iters 87.0 (87.0)	Tok/s 7676 (7676)
10: TEST [1][0/2]	Time 0.999 (0.999)	Decoder iters 68.0 (68.0)	Tok/s 6681 (6681)
5: TEST [1][0/2]	Time 0.998 (0.998)	Decoder iters 59.0 (59.0)	Tok/s 6637 (6637)
7: TEST [1][0/2]	Time 0.999 (0.999)	Decoder iters 84.0 (84.0)	Tok/s 7351 (7351)
14: TEST [1][0/2]	Time 0.999 (0.999)	Decoder iters 73.0 (73.0)	Tok/s 8129 (8129)
13: TEST [1][0/2]	Time 0.999 (0.999)	Decoder iters 72.0 (72.0)	Tok/s 7026 (7026)
3: TEST [1][0/2]	Time 0.998 (0.998)	Decoder iters 94.0 (94.0)	Tok/s 7708 (7708)
0: TEST [1][0/2]	Time 1.000 (1.000)	Decoder iters 69.0 (69.0)	Tok/s 7003 (7003)
15: TEST [1][0/2]	Time 1.000 (1.000)	Decoder iters 130.0 (130.0)	Tok/s 8192 (8192)
12: TEST [1][0/2]	Time 1.001 (1.001)	Decoder iters 61.0 (61.0)	Tok/s 6387 (6387)
11: TEST [1][0/2]	Time 1.000 (1.000)	Decoder iters 89.0 (89.0)	Tok/s 6420 (6420)
2: TEST [1][0/2]	Time 1.002 (1.002)	Decoder iters 129.0 (129.0)	Tok/s 7346 (7346)
6: TEST [1][0/2]	Time 1.002 (1.002)	Decoder iters 106.0 (106.0)	Tok/s 7807 (7807)
4: TEST [1][0/2]	Time 1.003 (1.003)	Decoder iters 95.0 (95.0)	Tok/s 7837 (7837)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
9: Finished evaluation on test set
15: Finished evaluation on test set
7: Finished evaluation on test set
2: Finished evaluation on test set
14: Finished evaluation on test set
1: Finished evaluation on test set
8: Finished evaluation on test set
13: Finished evaluation on test set
10: Finished evaluation on test set
3: Finished evaluation on test set
6: Finished evaluation on test set
12: Finished evaluation on test set
4: Finished evaluation on test set
11: Finished evaluation on test set
0: Finished evaluation on test set
5: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1541784506.436394215 (train.py:464) eval_accuracy: {"epoch": 1, "value": 21.56999969482422}
:::MLPv0.5.0 gnmt 1541784506.436815023 (train.py:466) eval_target: 21.8
8: Summary: Epoch: 1	Training Loss 3.3503
10: Summary: Epoch: 1	Training Loss 3.3503
12: Summary: Epoch: 1	Training Loss 3.3503
2: Summary: Epoch: 1	Training Loss 3.3503
4: Summary: Epoch: 1	Training Loss 3.3503
1: Summary: Epoch: 1	Training Loss 3.3503
15: Summary: Epoch: 1	Training Loss 3.3503
11: Summary: Epoch: 1	Training Loss 3.3503
14: Summary: Epoch: 1	Training Loss 3.3503
7: Summary: Epoch: 1	Training Loss 3.3503
6: Summary: Epoch: 1	Training Loss 3.3503
13: Summary: Epoch: 1	Training Loss 3.3503
9: Summary: Epoch: 1	Training Loss 3.3503
3: Summary: Epoch: 1	Training Loss 3.3503
5: Summary: Epoch: 1	Training Loss 3.3503
8: Performance: Epoch: 1	Training: 857505 Tok/s
10: Performance: Epoch: 1	Training: 857505 Tok/s
4: Performance: Epoch: 1	Training: 857505 Tok/s
2: Performance: Epoch: 1	Training: 857505 Tok/s
12: Performance: Epoch: 1	Training: 857505 Tok/s
1: Performance: Epoch: 1	Training: 857505 Tok/s
11: Performance: Epoch: 1	Training: 857505 Tok/s
15: Performance: Epoch: 1	Training: 857505 Tok/s
14: Performance: Epoch: 1	Training: 857505 Tok/s
7: Performance: Epoch: 1	Training: 857505 Tok/s
13: Performance: Epoch: 1	Training: 857505 Tok/s
6: Performance: Epoch: 1	Training: 857505 Tok/s
3: Performance: Epoch: 1	Training: 857505 Tok/s
5: Performance: Epoch: 1	Training: 857505 Tok/s
10: Finished epoch 1
8: Finished epoch 1
9: Performance: Epoch: 1	Training: 857505 Tok/s
4: Finished epoch 1
1: Finished epoch 1
2: Finished epoch 1
11: Finished epoch 1
15: Finished epoch 1
14: Finished epoch 1
7: Finished epoch 1
6: Finished epoch 1
12: Finished epoch 1
13: Finished epoch 1
3: Finished epoch 1
10: Starting epoch 2
8: Starting epoch 2
5: Finished epoch 1
1: Starting epoch 2
9: Finished epoch 1
4: Starting epoch 2
15: Starting epoch 2
11: Starting epoch 2
7: Starting epoch 2
6: Starting epoch 2
14: Starting epoch 2
13: Starting epoch 2
2: Starting epoch 2
:::MLPv0.5.0 gnmt 1541784506.437154293 (train.py:467) eval_stop
3: Starting epoch 2
12: Starting epoch 2
5: Starting epoch 2
9: Starting epoch 2
0: Summary: Epoch: 1	Training Loss: 3.3503	Validation Loss: 3.0444	Test BLEU: 21.57
0: Performance: Epoch: 1	Training: 857505 Tok/s	Validation: 2777898 Tok/s
0: Finished epoch 1
0: Starting epoch 2
:::MLPv0.5.0 gnmt 1541784506.437753677 (train.py:443) train_epoch: 2
8: Sampler for epoch 2 uses seed 353795937
2: Sampler for epoch 2 uses seed 353795937
3: Sampler for epoch 2 uses seed 353795937
9: Sampler for epoch 2 uses seed 353795937
7: Sampler for epoch 2 uses seed 353795937
1: Sampler for epoch 2 uses seed 353795937
12: Sampler for epoch 2 uses seed 353795937
10: Sampler for epoch 2 uses seed 353795937
6: Sampler for epoch 2 uses seed 353795937
11: Sampler for epoch 2 uses seed 353795937
13: Sampler for epoch 2 uses seed 353795937
15: Sampler for epoch 2 uses seed 353795937
5: Sampler for epoch 2 uses seed 353795937
4: Sampler for epoch 2 uses seed 353795937
14: Sampler for epoch 2 uses seed 353795937
:::MLPv0.5.0 gnmt 1541784506.785222054 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 2 uses seed 353795937
:::MLPv0.5.0 gnmt 1541784506.950324774 (seq2seq/data/sampler.py:66) input_shard: 81920
15: TRAIN [2][0/3416]	Time 3.426 (0.000)	Data 3.05608 (0.00000)	Tok/s 1083 (0)	Loss/tok 3.2611 (0.0000)	Learning Rate [0.0003125]
9: TRAIN [2][0/3416]	Time 3.427 (0.000)	Data 3.17419 (0.00000)	Tok/s 1083 (0)	Loss/tok 3.2810 (0.0000)	Learning Rate [0.0003125]
14: TRAIN [2][0/3416]	Time 3.426 (0.000)	Data 2.18620 (0.00000)	Tok/s 1083 (0)	Loss/tok 3.4237 (0.0000)	Learning Rate [0.0003125]
7: TRAIN [2][0/3416]	Time 3.426 (0.000)	Data 1.69141 (0.00000)	Tok/s 1083 (0)	Loss/tok 2.9727 (0.0000)	Learning Rate [0.0003125]
10: TRAIN [2][0/3416]	Time 3.426 (0.000)	Data 3.29869 (0.00000)	Tok/s 1084 (0)	Loss/tok 3.1966 (0.0000)	Learning Rate [0.0003125]
13: TRAIN [2][0/3416]	Time 3.427 (0.000)	Data 2.61215 (0.00000)	Tok/s 1083 (0)	Loss/tok 3.3075 (0.0000)	Learning Rate [0.0003125]
1: TRAIN [2][0/3416]	Time 3.426 (0.000)	Data 3.22666 (0.00000)	Tok/s 1083 (0)	Loss/tok 3.1774 (0.0000)	Learning Rate [0.0003125]
2: TRAIN [2][0/3416]	Time 3.427 (0.000)	Data 3.03809 (0.00000)	Tok/s 1083 (0)	Loss/tok 3.3902 (0.0000)	Learning Rate [0.0003125]
0: TRAIN [2][0/3416]	Time 3.427 (0.000)	Data 3.35881 (0.00000)	Tok/s 1083 (0)	Loss/tok 3.1141 (0.0000)	Learning Rate [0.0003125]
8: TRAIN [2][0/3416]	Time 3.426 (0.000)	Data 2.65155 (0.00000)	Tok/s 1084 (0)	Loss/tok 3.3158 (0.0000)	Learning Rate [0.0003125]
11: TRAIN [2][0/3416]	Time 3.426 (0.000)	Data 3.03159 (0.00000)	Tok/s 1084 (0)	Loss/tok 3.3416 (0.0000)	Learning Rate [0.0003125]
12: TRAIN [2][0/3416]	Time 3.427 (0.000)	Data 3.25498 (0.00000)	Tok/s 1083 (0)	Loss/tok 3.1712 (0.0000)	Learning Rate [0.0003125]
3: TRAIN [2][0/3416]	Time 3.427 (0.000)	Data 2.61122 (0.00000)	Tok/s 1083 (0)	Loss/tok 3.2749 (0.0000)	Learning Rate [0.0003125]
6: TRAIN [2][0/3416]	Time 3.426 (0.000)	Data 2.15195 (0.00000)	Tok/s 1083 (0)	Loss/tok 3.2240 (0.0000)	Learning Rate [0.0003125]
5: TRAIN [2][0/3416]	Time 3.426 (0.000)	Data 3.00592 (0.00000)	Tok/s 1084 (0)	Loss/tok 3.1784 (0.0000)	Learning Rate [0.0003125]
4: TRAIN [2][0/3416]	Time 3.426 (0.000)	Data 2.88836 (0.00000)	Tok/s 1084 (0)	Loss/tok 3.1805 (0.0000)	Learning Rate [0.0003125]
15: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00110 (0.00103)	Tok/s 53856 (51369)	Loss/tok 3.1616 (3.0726)	Learning Rate [0.0003125]
0: TRAIN [2][10/3416]	Time 0.060 (0.056)	Data 0.00171 (0.00122)	Tok/s 52939 (50105)	Loss/tok 3.1195 (3.1045)	Learning Rate [0.0003125]
13: TRAIN [2][10/3416]	Time 0.060 (0.056)	Data 0.00141 (0.00099)	Tok/s 53782 (51129)	Loss/tok 3.2344 (3.0510)	Learning Rate [0.0003125]
2: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00105 (0.00091)	Tok/s 52754 (50133)	Loss/tok 3.1225 (3.1351)	Learning Rate [0.0003125]
1: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00146 (0.00128)	Tok/s 52803 (50063)	Loss/tok 3.1049 (3.0081)	Learning Rate [0.0003125]
11: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00101 (0.00108)	Tok/s 52405 (50894)	Loss/tok 3.1911 (3.0775)	Learning Rate [0.0003125]
3: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00131 (0.00113)	Tok/s 52667 (50150)	Loss/tok 3.1575 (3.1010)	Learning Rate [0.0003125]
4: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00111 (0.00111)	Tok/s 52627 (50242)	Loss/tok 3.1754 (3.1629)	Learning Rate [0.0003125]
10: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00099 (0.00106)	Tok/s 52391 (50684)	Loss/tok 2.9504 (3.1240)	Learning Rate [0.0003125]
12: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00115 (0.00095)	Tok/s 52588 (50945)	Loss/tok 3.2253 (3.0333)	Learning Rate [0.0003125]
9: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00107 (0.00100)	Tok/s 52346 (50551)	Loss/tok 3.1722 (3.0896)	Learning Rate [0.0003125]
8: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00109 (0.00123)	Tok/s 52359 (50547)	Loss/tok 3.0799 (3.1206)	Learning Rate [0.0003125]
6: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00106 (0.00108)	Tok/s 52411 (50409)	Loss/tok 2.9766 (3.0873)	Learning Rate [0.0003125]
7: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00097 (0.00095)	Tok/s 52368 (50570)	Loss/tok 3.2198 (3.1470)	Learning Rate [0.0003125]
14: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00100 (0.00103)	Tok/s 53763 (51152)	Loss/tok 3.2333 (3.1173)	Learning Rate [0.0003125]
5: TRAIN [2][10/3416]	Time 0.061 (0.056)	Data 0.00102 (0.00105)	Tok/s 52467 (50366)	Loss/tok 3.2949 (3.0067)	Learning Rate [0.0003125]
8: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00110 (0.00118)	Tok/s 51417 (52179)	Loss/tok 3.2134 (3.1274)	Learning Rate [0.0003125]
9: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00100 (0.00096)	Tok/s 51313 (52175)	Loss/tok 3.1132 (3.1223)	Learning Rate [0.0003125]
10: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00101 (0.00102)	Tok/s 51320 (52290)	Loss/tok 3.0253 (3.1586)	Learning Rate [0.0003125]
7: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00103 (0.00099)	Tok/s 51295 (52180)	Loss/tok 3.2196 (3.1596)	Learning Rate [0.0003125]
11: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00096 (0.00100)	Tok/s 51307 (52456)	Loss/tok 2.8832 (3.1077)	Learning Rate [0.0003125]
6: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00092 (0.00099)	Tok/s 51277 (52099)	Loss/tok 3.0801 (3.1304)	Learning Rate [0.0003125]
4: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00106 (0.00108)	Tok/s 51397 (51937)	Loss/tok 3.1823 (3.1173)	Learning Rate [0.0003125]
12: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00119 (0.00103)	Tok/s 51336 (52490)	Loss/tok 2.9986 (3.0565)	Learning Rate [0.0003125]
5: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00097 (0.00100)	Tok/s 51290 (52076)	Loss/tok 3.1019 (3.0582)	Learning Rate [0.0003125]
13: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00143 (0.00102)	Tok/s 51912 (52642)	Loss/tok 3.1813 (3.1204)	Learning Rate [0.0003125]
15: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00090 (0.00097)	Tok/s 52714 (52883)	Loss/tok 3.1481 (3.1179)	Learning Rate [0.0003125]
3: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00088 (0.00104)	Tok/s 51358 (51815)	Loss/tok 2.9629 (3.0665)	Learning Rate [0.0003125]
2: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00101 (0.00098)	Tok/s 51365 (51803)	Loss/tok 3.1059 (3.1524)	Learning Rate [0.0003125]
0: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00097 (0.00112)	Tok/s 51355 (51674)	Loss/tok 2.7139 (3.0770)	Learning Rate [0.0003125]
1: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00108 (0.00117)	Tok/s 51333 (51708)	Loss/tok 2.8999 (3.0731)	Learning Rate [0.0003125]
14: TRAIN [2][20/3416]	Time 0.050 (0.057)	Data 0.00097 (0.00099)	Tok/s 52627 (52770)	Loss/tok 3.0067 (3.0997)	Learning Rate [0.0003125]
0: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00110)	Tok/s 43662 (53756)	Loss/tok 2.7505 (3.1416)	Learning Rate [0.0003125]
15: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00095)	Tok/s 44933 (54951)	Loss/tok 2.9511 (3.1196)	Learning Rate [0.0003125]
1: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00113)	Tok/s 43664 (53793)	Loss/tok 3.1437 (3.1111)	Learning Rate [0.0003125]
2: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00100)	Tok/s 43660 (53907)	Loss/tok 2.9819 (3.1697)	Learning Rate [0.0003125]
3: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00118)	Tok/s 43641 (53927)	Loss/tok 3.0619 (3.1120)	Learning Rate [0.0003125]
4: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00108)	Tok/s 43758 (53998)	Loss/tok 2.9216 (3.1092)	Learning Rate [0.0003125]
12: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00112 (0.00105)	Tok/s 44686 (54557)	Loss/tok 2.8876 (3.1059)	Learning Rate [0.0003125]
13: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00103)	Tok/s 44647 (54718)	Loss/tok 3.1340 (3.1170)	Learning Rate [0.0003125]
11: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00098)	Tok/s 44672 (54501)	Loss/tok 3.1320 (3.1054)	Learning Rate [0.0003125]
6: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00097)	Tok/s 44917 (54199)	Loss/tok 2.8742 (3.1254)	Learning Rate [0.0003125]
9: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00094)	Tok/s 44763 (54256)	Loss/tok 3.0007 (3.1198)	Learning Rate [0.0003125]
10: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00101)	Tok/s 44680 (54353)	Loss/tok 2.9792 (3.1461)	Learning Rate [0.0003125]
5: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00097)	Tok/s 43600 (54108)	Loss/tok 2.9061 (3.0977)	Learning Rate [0.0003125]
7: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00098)	Tok/s 44805 (54249)	Loss/tok 3.0610 (3.1584)	Learning Rate [0.0003125]
8: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00113)	Tok/s 44726 (54224)	Loss/tok 3.0489 (3.1522)	Learning Rate [0.0003125]
14: TRAIN [2][30/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00098)	Tok/s 44775 (54851)	Loss/tok 3.1890 (3.1156)	Learning Rate [0.0003125]
9: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00094)	Tok/s 56208 (53673)	Loss/tok 3.0720 (3.0952)	Learning Rate [0.0003125]
7: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00098)	Tok/s 56257 (53643)	Loss/tok 3.3006 (3.1422)	Learning Rate [0.0003125]
6: TRAIN [2][40/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00098)	Tok/s 57174 (53554)	Loss/tok 3.2432 (3.1175)	Learning Rate [0.0003125]
5: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00099)	Tok/s 56042 (53457)	Loss/tok 3.1646 (3.0923)	Learning Rate [0.0003125]
11: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00096)	Tok/s 56226 (53916)	Loss/tok 3.1521 (3.1062)	Learning Rate [0.0003125]
10: TRAIN [2][40/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00100)	Tok/s 56320 (53767)	Loss/tok 3.2033 (3.1235)	Learning Rate [0.0003125]
4: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00109 (0.00109)	Tok/s 56134 (53341)	Loss/tok 3.1959 (3.0933)	Learning Rate [0.0003125]
8: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00105 (0.00112)	Tok/s 56313 (53657)	Loss/tok 3.2932 (3.1397)	Learning Rate [0.0003125]
3: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00112)	Tok/s 56014 (53222)	Loss/tok 3.2529 (3.1031)	Learning Rate [0.0003125]
12: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00105)	Tok/s 56191 (54000)	Loss/tok 3.1104 (3.1069)	Learning Rate [0.0003125]
2: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00122 (0.00101)	Tok/s 56073 (53168)	Loss/tok 3.2982 (3.1501)	Learning Rate [0.0003125]
13: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00104)	Tok/s 56196 (54144)	Loss/tok 3.1663 (3.1170)	Learning Rate [0.0003125]
1: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00110)	Tok/s 55999 (53025)	Loss/tok 2.9831 (3.0995)	Learning Rate [0.0003125]
14: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00097)	Tok/s 56143 (54297)	Loss/tok 3.4315 (3.1124)	Learning Rate [0.0003125]
0: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00110 (0.00108)	Tok/s 56138 (52919)	Loss/tok 3.3839 (3.1441)	Learning Rate [0.0003125]
15: TRAIN [2][40/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00094)	Tok/s 56080 (54417)	Loss/tok 3.3128 (3.1235)	Learning Rate [0.0003125]
10: TRAIN [2][50/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00099)	Tok/s 53275 (53982)	Loss/tok 3.3154 (3.1151)	Learning Rate [0.0003125]
9: TRAIN [2][50/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00093)	Tok/s 53342 (53890)	Loss/tok 3.3144 (3.1123)	Learning Rate [0.0003125]
11: TRAIN [2][50/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00095)	Tok/s 53239 (54118)	Loss/tok 3.1860 (3.1249)	Learning Rate [0.0003125]
8: TRAIN [2][50/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00109)	Tok/s 53375 (53880)	Loss/tok 3.3681 (3.1265)	Learning Rate [0.0003125]
12: TRAIN [2][50/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00105)	Tok/s 53118 (54227)	Loss/tok 3.0556 (3.1061)	Learning Rate [0.0003125]
7: TRAIN [2][50/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00097)	Tok/s 53289 (53860)	Loss/tok 3.2803 (3.1400)	Learning Rate [0.0003125]
6: TRAIN [2][50/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00096)	Tok/s 53341 (53750)	Loss/tok 3.1194 (3.1097)	Learning Rate [0.0003125]
14: TRAIN [2][50/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00097)	Tok/s 52918 (54517)	Loss/tok 3.2635 (3.1177)	Learning Rate [0.0003125]
5: TRAIN [2][50/3416]	Time 0.061 (0.058)	Data 0.00086 (0.00098)	Tok/s 53113 (53665)	Loss/tok 3.3150 (3.0888)	Learning Rate [0.0003125]
15: TRAIN [2][50/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00093)	Tok/s 52908 (54632)	Loss/tok 3.1300 (3.1260)	Learning Rate [0.0003125]
4: TRAIN [2][50/3416]	Time 0.061 (0.058)	Data 0.00104 (0.00108)	Tok/s 52141 (53554)	Loss/tok 2.9130 (3.0878)	Learning Rate [0.0003125]
0: TRAIN [2][50/3416]	Time 0.062 (0.058)	Data 0.00104 (0.00109)	Tok/s 51874 (53153)	Loss/tok 3.3420 (3.1574)	Learning Rate [0.0003125]
3: TRAIN [2][50/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00108)	Tok/s 52025 (53440)	Loss/tok 3.3158 (3.1059)	Learning Rate [0.0003125]
13: TRAIN [2][50/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00103)	Tok/s 52992 (54386)	Loss/tok 3.0825 (3.1221)	Learning Rate [0.0003125]
1: TRAIN [2][50/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00108)	Tok/s 51897 (53263)	Loss/tok 3.2651 (3.1050)	Learning Rate [0.0003125]
2: TRAIN [2][50/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00101)	Tok/s 51939 (53379)	Loss/tok 3.0631 (3.1326)	Learning Rate [0.0003125]
8: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00107)	Tok/s 48426 (53023)	Loss/tok 2.9125 (3.1263)	Learning Rate [0.0003125]
10: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00098)	Tok/s 48226 (53107)	Loss/tok 3.0258 (3.1034)	Learning Rate [0.0003125]
7: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00096)	Tok/s 48282 (53006)	Loss/tok 2.8659 (3.1281)	Learning Rate [0.0003125]
11: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00095)	Tok/s 49059 (53250)	Loss/tok 3.0189 (3.1219)	Learning Rate [0.0003125]
12: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00104)	Tok/s 49469 (53410)	Loss/tok 2.9367 (3.0971)	Learning Rate [0.0003125]
4: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00107)	Tok/s 48012 (52729)	Loss/tok 2.9756 (3.0884)	Learning Rate [0.0003125]
5: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00097)	Tok/s 48184 (52820)	Loss/tok 3.0094 (3.0868)	Learning Rate [0.0003125]
13: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00103)	Tok/s 49392 (53572)	Loss/tok 3.2144 (3.1267)	Learning Rate [0.0003125]
3: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00105)	Tok/s 47914 (52591)	Loss/tok 2.9925 (3.1204)	Learning Rate [0.0003125]
6: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00100)	Tok/s 48212 (52912)	Loss/tok 2.9288 (3.1126)	Learning Rate [0.0003125]
14: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00085 (0.00097)	Tok/s 49272 (53695)	Loss/tok 3.0515 (3.1073)	Learning Rate [0.0003125]
15: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00093)	Tok/s 49169 (53805)	Loss/tok 2.8611 (3.1208)	Learning Rate [0.0003125]
2: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00100)	Tok/s 47817 (52514)	Loss/tok 3.0674 (3.1316)	Learning Rate [0.0003125]
9: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00093)	Tok/s 48356 (53025)	Loss/tok 3.0723 (3.1143)	Learning Rate [0.0003125]
1: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00106)	Tok/s 47680 (52404)	Loss/tok 2.9871 (3.1030)	Learning Rate [0.0003125]
0: TRAIN [2][60/3416]	Time 0.044 (0.058)	Data 0.00108 (0.00108)	Tok/s 47563 (52303)	Loss/tok 2.9770 (3.1459)	Learning Rate [0.0003125]
1: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00105)	Tok/s 52625 (52221)	Loss/tok 3.3995 (3.0977)	Learning Rate [0.0003125]
3: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00102)	Tok/s 52540 (52416)	Loss/tok 3.1431 (3.1224)	Learning Rate [0.0003125]
0: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00112 (0.00107)	Tok/s 52645 (52129)	Loss/tok 3.3620 (3.1428)	Learning Rate [0.0003125]
2: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00098 (0.00100)	Tok/s 52663 (52321)	Loss/tok 3.0383 (3.1315)	Learning Rate [0.0003125]
4: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00119 (0.00107)	Tok/s 52451 (52535)	Loss/tok 3.4444 (3.1003)	Learning Rate [0.0003125]
15: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00092)	Tok/s 53571 (53582)	Loss/tok 3.1325 (3.1270)	Learning Rate [0.0003125]
5: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00096)	Tok/s 52295 (52625)	Loss/tok 3.3652 (3.0944)	Learning Rate [0.0003125]
6: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00099)	Tok/s 53279 (52726)	Loss/tok 3.0394 (3.1126)	Learning Rate [0.0003125]
14: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00101 (0.00096)	Tok/s 53653 (53475)	Loss/tok 3.1534 (3.1147)	Learning Rate [0.0003125]
13: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00102)	Tok/s 53648 (53366)	Loss/tok 2.9991 (3.1230)	Learning Rate [0.0003125]
7: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00096)	Tok/s 53394 (52805)	Loss/tok 2.9979 (3.1309)	Learning Rate [0.0003125]
8: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00111 (0.00106)	Tok/s 53404 (52827)	Loss/tok 3.1533 (3.1306)	Learning Rate [0.0003125]
11: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00108 (0.00094)	Tok/s 53526 (53053)	Loss/tok 3.1175 (3.1358)	Learning Rate [0.0003125]
12: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00104 (0.00105)	Tok/s 53545 (53192)	Loss/tok 3.2685 (3.1097)	Learning Rate [0.0003125]
10: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00102 (0.00098)	Tok/s 53440 (52928)	Loss/tok 3.1815 (3.1087)	Learning Rate [0.0003125]
9: TRAIN [2][70/3416]	Time 0.061 (0.058)	Data 0.00101 (0.00093)	Tok/s 53341 (52846)	Loss/tok 3.1762 (3.1062)	Learning Rate [0.0003125]
2: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00099)	Tok/s 51564 (52715)	Loss/tok 3.2794 (3.1317)	Learning Rate [0.0003125]
1: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00103)	Tok/s 51558 (52628)	Loss/tok 3.2855 (3.1059)	Learning Rate [0.0003125]
3: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00100)	Tok/s 51388 (52813)	Loss/tok 3.2359 (3.1238)	Learning Rate [0.0003125]
0: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00107)	Tok/s 51602 (52544)	Loss/tok 3.0802 (3.1484)	Learning Rate [0.0003125]
4: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00107)	Tok/s 51304 (52925)	Loss/tok 3.1653 (3.1125)	Learning Rate [0.0003125]
15: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00092)	Tok/s 52799 (53980)	Loss/tok 3.0247 (3.1309)	Learning Rate [0.0003125]
5: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00095)	Tok/s 51280 (53004)	Loss/tok 3.0391 (3.0904)	Learning Rate [0.0003125]
14: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00096)	Tok/s 52847 (53874)	Loss/tok 2.9971 (3.1158)	Learning Rate [0.0003125]
6: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00098)	Tok/s 51312 (53107)	Loss/tok 3.1898 (3.1157)	Learning Rate [0.0003125]
8: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00105)	Tok/s 51455 (53210)	Loss/tok 3.1833 (3.1341)	Learning Rate [0.0003125]
7: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00095)	Tok/s 51374 (53190)	Loss/tok 3.0628 (3.1292)	Learning Rate [0.0003125]
13: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00101)	Tok/s 52844 (53753)	Loss/tok 2.7438 (3.1272)	Learning Rate [0.0003125]
10: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00098)	Tok/s 51496 (53329)	Loss/tok 3.1991 (3.1114)	Learning Rate [0.0003125]
11: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00094)	Tok/s 51479 (53446)	Loss/tok 3.1443 (3.1356)	Learning Rate [0.0003125]
12: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00104)	Tok/s 51817 (53584)	Loss/tok 3.1116 (3.1161)	Learning Rate [0.0003125]
9: TRAIN [2][80/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00093)	Tok/s 51427 (53238)	Loss/tok 3.0977 (3.1167)	Learning Rate [0.0003125]
1: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00102)	Tok/s 51269 (52401)	Loss/tok 3.2589 (3.1099)	Learning Rate [0.0003125]
2: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00099)	Tok/s 51241 (52477)	Loss/tok 3.0847 (3.1250)	Learning Rate [0.0003125]
3: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00099)	Tok/s 52392 (52576)	Loss/tok 2.8485 (3.1275)	Learning Rate [0.0003125]
15: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00091)	Tok/s 52355 (53705)	Loss/tok 2.8959 (3.1299)	Learning Rate [0.0003125]
14: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00095)	Tok/s 52360 (53601)	Loss/tok 2.9769 (3.1200)	Learning Rate [0.0003125]
0: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00114 (0.00107)	Tok/s 51195 (52324)	Loss/tok 3.1535 (3.1479)	Learning Rate [0.0003125]
13: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00100)	Tok/s 52335 (53493)	Loss/tok 3.0275 (3.1182)	Learning Rate [0.0003125]
6: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00098)	Tok/s 52402 (52842)	Loss/tok 2.9085 (3.1213)	Learning Rate [0.0003125]
5: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00094)	Tok/s 52354 (52746)	Loss/tok 3.1459 (3.0987)	Learning Rate [0.0003125]
4: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00106)	Tok/s 52357 (52677)	Loss/tok 3.1646 (3.1182)	Learning Rate [0.0003125]
7: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00095)	Tok/s 52405 (52924)	Loss/tok 2.9702 (3.1225)	Learning Rate [0.0003125]
12: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00104)	Tok/s 52327 (53336)	Loss/tok 3.1932 (3.1103)	Learning Rate [0.0003125]
11: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00094)	Tok/s 52339 (53195)	Loss/tok 3.0308 (3.1349)	Learning Rate [0.0003125]
10: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00097)	Tok/s 52204 (53082)	Loss/tok 3.0888 (3.1102)	Learning Rate [0.0003125]
8: TRAIN [2][90/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00105)	Tok/s 52211 (52949)	Loss/tok 3.1804 (3.1397)	Learning Rate [0.0003125]
9: TRAIN [2][90/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00093)	Tok/s 52148 (52975)	Loss/tok 3.2509 (3.1198)	Learning Rate [0.0003125]
8: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00104)	Tok/s 86917 (53513)	Loss/tok 3.1038 (3.1370)	Learning Rate [0.0003125]
7: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00095)	Tok/s 86794 (53488)	Loss/tok 3.0834 (3.1241)	Learning Rate [0.0003125]
10: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 87892 (53650)	Loss/tok 2.9971 (3.1043)	Learning Rate [0.0003125]
12: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00104)	Tok/s 88307 (53905)	Loss/tok 3.2015 (3.1256)	Learning Rate [0.0003125]
4: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00105)	Tok/s 86109 (53247)	Loss/tok 3.1204 (3.1208)	Learning Rate [0.0003125]
6: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00098)	Tok/s 85905 (53401)	Loss/tok 3.0323 (3.1241)	Learning Rate [0.0003125]
11: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 87875 (53763)	Loss/tok 3.2241 (3.1307)	Learning Rate [0.0003125]
13: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00100)	Tok/s 88908 (54060)	Loss/tok 3.0545 (3.1236)	Learning Rate [0.0003125]
5: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00094)	Tok/s 85943 (53307)	Loss/tok 3.0766 (3.0980)	Learning Rate [0.0003125]
2: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00099)	Tok/s 85116 (53012)	Loss/tok 2.8004 (3.1266)	Learning Rate [0.0003125]
14: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00095)	Tok/s 89400 (54167)	Loss/tok 3.0310 (3.1260)	Learning Rate [0.0003125]
3: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 85639 (53131)	Loss/tok 3.1312 (3.1214)	Learning Rate [0.0003125]
1: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00101)	Tok/s 85152 (52943)	Loss/tok 3.0572 (3.1120)	Learning Rate [0.0003125]
9: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 86995 (53543)	Loss/tok 3.0379 (3.1102)	Learning Rate [0.0003125]
0: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00116 (0.00107)	Tok/s 85184 (52876)	Loss/tok 3.4486 (3.1522)	Learning Rate [0.0003125]
15: TRAIN [2][100/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 90125 (54277)	Loss/tok 3.1068 (3.1317)	Learning Rate [0.0003125]
1: TRAIN [2][110/3416]	Time 0.068 (0.058)	Data 0.00122 (0.00101)	Tok/s 57639 (52955)	Loss/tok 3.3058 (3.1185)	Learning Rate [0.0003125]
2: TRAIN [2][110/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00098)	Tok/s 57474 (53017)	Loss/tok 3.0917 (3.1230)	Learning Rate [0.0003125]
0: TRAIN [2][110/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00107)	Tok/s 57508 (52895)	Loss/tok 3.3680 (3.1501)	Learning Rate [0.0003125]
3: TRAIN [2][110/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00098)	Tok/s 57401 (53124)	Loss/tok 3.1541 (3.1190)	Learning Rate [0.0003125]
4: TRAIN [2][110/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00105)	Tok/s 57296 (53241)	Loss/tok 3.2614 (3.1317)	Learning Rate [0.0003125]
14: TRAIN [2][110/3416]	Time 0.068 (0.058)	Data 0.00077 (0.00094)	Tok/s 58295 (54130)	Loss/tok 3.0626 (3.1269)	Learning Rate [0.0003125]
5: TRAIN [2][110/3416]	Time 0.068 (0.058)	Data 0.00081 (0.00093)	Tok/s 57179 (53296)	Loss/tok 3.2160 (3.1005)	Learning Rate [0.0003125]
13: TRAIN [2][110/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00100)	Tok/s 58180 (54021)	Loss/tok 3.2139 (3.1305)	Learning Rate [0.0003125]
6: TRAIN [2][110/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00097)	Tok/s 57054 (53380)	Loss/tok 3.3735 (3.1302)	Learning Rate [0.0003125]
12: TRAIN [2][110/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00104)	Tok/s 58084 (53855)	Loss/tok 3.2345 (3.1310)	Learning Rate [0.0003125]
11: TRAIN [2][110/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00093)	Tok/s 57961 (53726)	Loss/tok 3.5187 (3.1363)	Learning Rate [0.0003125]
7: TRAIN [2][110/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00095)	Tok/s 57003 (53457)	Loss/tok 3.1744 (3.1340)	Learning Rate [0.0003125]
10: TRAIN [2][110/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 57820 (53621)	Loss/tok 2.9789 (3.1081)	Learning Rate [0.0003125]
8: TRAIN [2][110/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00104)	Tok/s 57305 (53483)	Loss/tok 3.3093 (3.1410)	Learning Rate [0.0003125]
15: TRAIN [2][110/3416]	Time 0.068 (0.058)	Data 0.00111 (0.00092)	Tok/s 58359 (54233)	Loss/tok 3.1144 (3.1319)	Learning Rate [0.0003125]
9: TRAIN [2][110/3416]	Time 0.069 (0.058)	Data 0.00119 (0.00093)	Tok/s 57835 (53510)	Loss/tok 3.4081 (3.1214)	Learning Rate [0.0003125]
8: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
2: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00097 (0.00098)	Tok/s 51630 (53102)	Loss/tok 3.0895 (3.1300)	Learning Rate [0.0003125]
4: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00107 (0.00104)	Tok/s 51462 (53326)	Loss/tok 3.2343 (3.1340)	Learning Rate [0.0003125]
3: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00096 (0.00097)	Tok/s 51573 (53208)	Loss/tok 3.3030 (3.1222)	Learning Rate [0.0003125]
1: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00103 (0.00102)	Tok/s 51659 (53045)	Loss/tok 3.1866 (3.1195)	Learning Rate [0.0003125]
6: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00098 (0.00097)	Tok/s 51342 (53465)	Loss/tok 2.9513 (3.1320)	Learning Rate [0.0003125]
5: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00098 (0.00093)	Tok/s 51377 (53385)	Loss/tok 3.2781 (3.1068)	Learning Rate [0.0003125]
15: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00106 (0.00094)	Tok/s 52823 (54287)	Loss/tok 3.1904 (3.1392)	Learning Rate [0.0003125]
14: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00100 (0.00095)	Tok/s 52288 (54179)	Loss/tok 3.1365 (3.1310)	Learning Rate [0.0003125]
11: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00100 (0.00093)	Tok/s 51410 (53796)	Loss/tok 3.2940 (3.1383)	Learning Rate [0.0003125]
0: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00097 (0.00106)	Tok/s 51620 (52987)	Loss/tok 3.2564 (3.1514)	Learning Rate [0.0003125]
13: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00100 (0.00099)	Tok/s 51496 (54068)	Loss/tok 3.0792 (3.1351)	Learning Rate [0.0003125]
7: TRAIN [2][120/3416]	Time 0.053 (0.059)	Data 0.00115 (0.00095)	Tok/s 51166 (53542)	Loss/tok 3.3065 (3.1421)	Learning Rate [0.0003125]
9: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00097 (0.00095)	Tok/s 51257 (53600)	Loss/tok 3.0297 (3.1260)	Learning Rate [0.0003125]
8: TRAIN [2][120/3416]	Time 0.053 (0.059)	Data 0.00099 (0.00103)	Tok/s 51180 (53567)	Loss/tok 2.8762 (3.1449)	Learning Rate [0.0003125]
10: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00095 (0.00096)	Tok/s 51220 (53699)	Loss/tok 3.1237 (3.1146)	Learning Rate [0.0003125]
12: TRAIN [2][120/3416]	Time 0.052 (0.059)	Data 0.00110 (0.00105)	Tok/s 51294 (53914)	Loss/tok 3.1742 (3.1374)	Learning Rate [0.0003125]
6: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00097)	Tok/s 29266 (52894)	Loss/tok 2.5711 (3.1314)	Learning Rate [0.0003125]
7: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00105 (0.00096)	Tok/s 30458 (53007)	Loss/tok 2.6081 (3.1368)	Learning Rate [0.0003125]
5: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00093)	Tok/s 29267 (52804)	Loss/tok 2.4168 (3.0997)	Learning Rate [0.0003125]
4: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00103)	Tok/s 29240 (52733)	Loss/tok 2.6194 (3.1267)	Learning Rate [0.0003125]
8: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00102)	Tok/s 30606 (53041)	Loss/tok 2.6735 (3.1410)	Learning Rate [0.0003125]
3: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00096)	Tok/s 29176 (52611)	Loss/tok 2.6280 (3.1239)	Learning Rate [0.0003125]
9: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00095)	Tok/s 30521 (53076)	Loss/tok 2.6223 (3.1266)	Learning Rate [0.0003125]
2: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00098)	Tok/s 29115 (52494)	Loss/tok 2.6259 (3.1260)	Learning Rate [0.0003125]
1: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00112 (0.00103)	Tok/s 29035 (52417)	Loss/tok 2.6840 (3.1182)	Learning Rate [0.0003125]
11: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00093)	Tok/s 30446 (53258)	Loss/tok 2.4666 (3.1363)	Learning Rate [0.0003125]
10: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00096)	Tok/s 30445 (53166)	Loss/tok 2.5399 (3.1116)	Learning Rate [0.0003125]
0: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00105)	Tok/s 29028 (52341)	Loss/tok 2.7102 (3.1443)	Learning Rate [0.0003125]
15: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00094)	Tok/s 30478 (53752)	Loss/tok 2.7740 (3.1366)	Learning Rate [0.0003125]
14: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00095)	Tok/s 30457 (53643)	Loss/tok 2.8110 (3.1244)	Learning Rate [0.0003125]
13: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00099)	Tok/s 30404 (53540)	Loss/tok 2.5918 (3.1296)	Learning Rate [0.0003125]
12: TRAIN [2][130/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00105)	Tok/s 30416 (53386)	Loss/tok 2.5762 (3.1377)	Learning Rate [0.0003125]
13: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00099)	Tok/s 38456 (53473)	Loss/tok 2.9707 (3.1275)	Learning Rate [0.0003125]
14: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00095)	Tok/s 38473 (53571)	Loss/tok 2.9470 (3.1252)	Learning Rate [0.0003125]
12: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00107 (0.00104)	Tok/s 38343 (53324)	Loss/tok 2.9066 (3.1364)	Learning Rate [0.0003125]
15: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00094)	Tok/s 38467 (53680)	Loss/tok 3.0651 (3.1383)	Learning Rate [0.0003125]
11: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00093)	Tok/s 38254 (53203)	Loss/tok 3.3546 (3.1382)	Learning Rate [0.0003125]
0: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00104)	Tok/s 37150 (52304)	Loss/tok 3.0464 (3.1436)	Learning Rate [0.0003125]
10: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00096)	Tok/s 38222 (53117)	Loss/tok 2.8608 (3.1106)	Learning Rate [0.0003125]
9: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00094)	Tok/s 38254 (53028)	Loss/tok 2.8709 (3.1272)	Learning Rate [0.0003125]
1: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00103)	Tok/s 37305 (52379)	Loss/tok 2.9952 (3.1178)	Learning Rate [0.0003125]
8: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00102)	Tok/s 38262 (52992)	Loss/tok 3.2314 (3.1436)	Learning Rate [0.0003125]
2: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00097)	Tok/s 38416 (52469)	Loss/tok 2.8973 (3.1213)	Learning Rate [0.0003125]
3: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00096)	Tok/s 38399 (52578)	Loss/tok 2.9933 (3.1189)	Learning Rate [0.0003125]
4: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00106 (0.00103)	Tok/s 38342 (52691)	Loss/tok 3.0907 (3.1256)	Learning Rate [0.0003125]
7: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00096)	Tok/s 38247 (52957)	Loss/tok 3.1506 (3.1346)	Learning Rate [0.0003125]
6: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00096)	Tok/s 38280 (52846)	Loss/tok 2.8751 (3.1316)	Learning Rate [0.0003125]
5: TRAIN [2][140/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00093)	Tok/s 38265 (52756)	Loss/tok 3.0335 (3.1002)	Learning Rate [0.0003125]
5: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00093)	Tok/s 32964 (52537)	Loss/tok 2.8687 (3.1017)	Learning Rate [0.0003125]
6: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00096)	Tok/s 32927 (52621)	Loss/tok 2.7127 (3.1352)	Learning Rate [0.0003125]
4: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00102)	Tok/s 32914 (52475)	Loss/tok 2.6930 (3.1222)	Learning Rate [0.0003125]
3: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00095)	Tok/s 32864 (52369)	Loss/tok 3.1359 (3.1238)	Learning Rate [0.0003125]
2: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00097)	Tok/s 32795 (52267)	Loss/tok 3.1217 (3.1221)	Learning Rate [0.0003125]
7: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00096)	Tok/s 32842 (52724)	Loss/tok 2.9097 (3.1348)	Learning Rate [0.0003125]
8: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00101)	Tok/s 32720 (52758)	Loss/tok 2.8252 (3.1487)	Learning Rate [0.0003125]
9: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00078 (0.00094)	Tok/s 32687 (52796)	Loss/tok 2.8590 (3.1254)	Learning Rate [0.0003125]
1: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00103)	Tok/s 32727 (52177)	Loss/tok 2.7027 (3.1213)	Learning Rate [0.0003125]
0: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00103)	Tok/s 32657 (52106)	Loss/tok 2.8118 (3.1444)	Learning Rate [0.0003125]
15: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00093)	Tok/s 33891 (53457)	Loss/tok 2.5323 (3.1357)	Learning Rate [0.0003125]
10: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00096)	Tok/s 32603 (52878)	Loss/tok 2.6738 (3.1126)	Learning Rate [0.0003125]
11: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00093)	Tok/s 32540 (52968)	Loss/tok 2.7184 (3.1369)	Learning Rate [0.0003125]
14: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00094)	Tok/s 33796 (53351)	Loss/tok 2.8552 (3.1240)	Learning Rate [0.0003125]
13: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00099)	Tok/s 33723 (53251)	Loss/tok 2.9193 (3.1256)	Learning Rate [0.0003125]
12: TRAIN [2][150/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00104)	Tok/s 32819 (53099)	Loss/tok 2.7253 (3.1355)	Learning Rate [0.0003125]
11: TRAIN [2][160/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00093)	Tok/s 57340 (52911)	Loss/tok 3.2550 (3.1383)	Learning Rate [0.0003125]
10: TRAIN [2][160/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00096)	Tok/s 57407 (52824)	Loss/tok 3.4325 (3.1160)	Learning Rate [0.0003125]
12: TRAIN [2][160/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00104)	Tok/s 57327 (53037)	Loss/tok 3.2698 (3.1363)	Learning Rate [0.0003125]
9: TRAIN [2][160/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00094)	Tok/s 57300 (52742)	Loss/tok 3.1915 (3.1231)	Learning Rate [0.0003125]
13: TRAIN [2][160/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00098)	Tok/s 57161 (53180)	Loss/tok 3.3183 (3.1277)	Learning Rate [0.0003125]
8: TRAIN [2][160/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00101)	Tok/s 56459 (52702)	Loss/tok 3.2565 (3.1466)	Learning Rate [0.0003125]
14: TRAIN [2][160/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00094)	Tok/s 57079 (53287)	Loss/tok 3.2647 (3.1227)	Learning Rate [0.0003125]
7: TRAIN [2][160/3416]	Time 0.068 (0.058)	Data 0.00107 (0.00096)	Tok/s 56423 (52666)	Loss/tok 3.1118 (3.1358)	Learning Rate [0.0003125]
6: TRAIN [2][160/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00096)	Tok/s 56313 (52565)	Loss/tok 3.1820 (3.1361)	Learning Rate [0.0003125]
0: TRAIN [2][160/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00103)	Tok/s 55957 (52068)	Loss/tok 3.0389 (3.1431)	Learning Rate [0.0003125]
15: TRAIN [2][160/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00094)	Tok/s 56972 (53394)	Loss/tok 3.2887 (3.1350)	Learning Rate [0.0003125]
5: TRAIN [2][160/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00093)	Tok/s 56196 (52485)	Loss/tok 3.2827 (3.1029)	Learning Rate [0.0003125]
1: TRAIN [2][160/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00104)	Tok/s 55962 (52137)	Loss/tok 3.2625 (3.1210)	Learning Rate [0.0003125]
4: TRAIN [2][160/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00102)	Tok/s 56076 (52424)	Loss/tok 3.0337 (3.1180)	Learning Rate [0.0003125]
3: TRAIN [2][160/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00095)	Tok/s 56020 (52321)	Loss/tok 3.2476 (3.1223)	Learning Rate [0.0003125]
2: TRAIN [2][160/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 55977 (52223)	Loss/tok 3.2922 (3.1195)	Learning Rate [0.0003125]
11: TRAIN [2][170/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00093)	Tok/s 33861 (52963)	Loss/tok 2.7449 (3.1366)	Learning Rate [0.0003125]
10: TRAIN [2][170/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00096)	Tok/s 33676 (52870)	Loss/tok 2.8136 (3.1166)	Learning Rate [0.0003125]
9: TRAIN [2][170/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00093)	Tok/s 32539 (52780)	Loss/tok 2.7985 (3.1186)	Learning Rate [0.0003125]
12: TRAIN [2][170/3416]	Time 0.049 (0.058)	Data 0.00112 (0.00104)	Tok/s 33766 (53082)	Loss/tok 2.7527 (3.1320)	Learning Rate [0.0003125]
8: TRAIN [2][170/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00101)	Tok/s 32539 (52739)	Loss/tok 2.7641 (3.1443)	Learning Rate [0.0003125]
13: TRAIN [2][170/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00098)	Tok/s 33651 (53217)	Loss/tok 2.8296 (3.1224)	Learning Rate [0.0003125]
14: TRAIN [2][170/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00094)	Tok/s 33615 (53321)	Loss/tok 2.9352 (3.1203)	Learning Rate [0.0003125]
7: TRAIN [2][170/3416]	Time 0.049 (0.058)	Data 0.00111 (0.00097)	Tok/s 32556 (52705)	Loss/tok 2.7907 (3.1334)	Learning Rate [0.0003125]
15: TRAIN [2][170/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00093)	Tok/s 33618 (53438)	Loss/tok 2.7880 (3.1314)	Learning Rate [0.0003125]
0: TRAIN [2][170/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00102)	Tok/s 32322 (52106)	Loss/tok 2.5795 (3.1409)	Learning Rate [0.0003125]
5: TRAIN [2][170/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00092)	Tok/s 32483 (52520)	Loss/tok 2.8850 (3.1032)	Learning Rate [0.0003125]
6: TRAIN [2][170/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00096)	Tok/s 32509 (52606)	Loss/tok 2.8102 (3.1316)	Learning Rate [0.0003125]
3: TRAIN [2][170/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00095)	Tok/s 32369 (52363)	Loss/tok 2.8544 (3.1168)	Learning Rate [0.0003125]
1: TRAIN [2][170/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00103)	Tok/s 32289 (52175)	Loss/tok 2.6577 (3.1164)	Learning Rate [0.0003125]
4: TRAIN [2][170/3416]	Time 0.049 (0.058)	Data 0.00106 (0.00102)	Tok/s 32415 (52462)	Loss/tok 2.7849 (3.1193)	Learning Rate [0.0003125]
2: TRAIN [2][170/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00097)	Tok/s 32311 (52257)	Loss/tok 2.6252 (3.1175)	Learning Rate [0.0003125]
15: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00088 (0.00093)	Tok/s 31970 (53530)	Loss/tok 2.7786 (3.1316)	Learning Rate [0.0003125]
14: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00089 (0.00094)	Tok/s 31889 (53418)	Loss/tok 2.5794 (3.1216)	Learning Rate [0.0003125]
0: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00093 (0.00102)	Tok/s 30410 (52232)	Loss/tok 2.5919 (3.1440)	Learning Rate [0.0003125]
1: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00103)	Tok/s 30369 (52302)	Loss/tok 2.6075 (3.1221)	Learning Rate [0.0003125]
12: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00105 (0.00104)	Tok/s 31791 (53192)	Loss/tok 2.5337 (3.1366)	Learning Rate [0.0003125]
13: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00097 (0.00099)	Tok/s 31806 (53320)	Loss/tok 2.7446 (3.1255)	Learning Rate [0.0003125]
11: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00089 (0.00093)	Tok/s 31663 (53074)	Loss/tok 2.6442 (3.1373)	Learning Rate [0.0003125]
2: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00095 (0.00097)	Tok/s 30279 (52380)	Loss/tok 2.5185 (3.1259)	Learning Rate [0.0003125]
3: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00089 (0.00094)	Tok/s 30235 (52479)	Loss/tok 2.6349 (3.1171)	Learning Rate [0.0003125]
9: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00088 (0.00093)	Tok/s 31716 (52896)	Loss/tok 2.3982 (3.1223)	Learning Rate [0.0003125]
10: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00095 (0.00096)	Tok/s 31674 (52984)	Loss/tok 2.5318 (3.1233)	Learning Rate [0.0003125]
4: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00096 (0.00103)	Tok/s 30221 (52573)	Loss/tok 2.4219 (3.1231)	Learning Rate [0.0003125]
6: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00094 (0.00096)	Tok/s 31323 (52718)	Loss/tok 2.6725 (3.1357)	Learning Rate [0.0003125]
5: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00088 (0.00092)	Tok/s 30238 (52626)	Loss/tok 2.8079 (3.1061)	Learning Rate [0.0003125]
8: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00094 (0.00101)	Tok/s 31666 (52852)	Loss/tok 2.5649 (3.1427)	Learning Rate [0.0003125]
7: TRAIN [2][180/3416]	Time 0.042 (0.058)	Data 0.00100 (0.00097)	Tok/s 31696 (52819)	Loss/tok 2.7687 (3.1401)	Learning Rate [0.0003125]
1: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00103)	Tok/s 76020 (52251)	Loss/tok 3.2211 (3.1203)	Learning Rate [0.0003125]
0: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00101)	Tok/s 76033 (52183)	Loss/tok 3.2764 (3.1432)	Learning Rate [0.0003125]
15: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00093)	Tok/s 78006 (53480)	Loss/tok 3.2041 (3.1330)	Learning Rate [0.0003125]
3: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00094)	Tok/s 76912 (52434)	Loss/tok 3.0054 (3.1141)	Learning Rate [0.0003125]
2: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00097)	Tok/s 76613 (52330)	Loss/tok 3.1464 (3.1264)	Learning Rate [0.0003125]
9: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 77251 (52860)	Loss/tok 3.0958 (3.1221)	Learning Rate [0.0003125]
14: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00094)	Tok/s 78017 (53373)	Loss/tok 3.2016 (3.1210)	Learning Rate [0.0003125]
4: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00102)	Tok/s 76956 (52540)	Loss/tok 3.0882 (3.1215)	Learning Rate [0.0003125]
8: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 77148 (52817)	Loss/tok 2.8831 (3.1389)	Learning Rate [0.0003125]
13: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 78034 (53275)	Loss/tok 3.0198 (3.1245)	Learning Rate [0.0003125]
11: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00093)	Tok/s 78042 (53033)	Loss/tok 2.8704 (3.1345)	Learning Rate [0.0003125]
5: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 76959 (52591)	Loss/tok 3.0538 (3.1080)	Learning Rate [0.0003125]
10: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00096)	Tok/s 78088 (52948)	Loss/tok 3.0566 (3.1238)	Learning Rate [0.0003125]
7: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00097)	Tok/s 77048 (52776)	Loss/tok 3.1165 (3.1377)	Learning Rate [0.0003125]
12: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00117 (0.00104)	Tok/s 78067 (53150)	Loss/tok 3.1142 (3.1392)	Learning Rate [0.0003125]
6: TRAIN [2][190/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00096)	Tok/s 76934 (52677)	Loss/tok 3.1619 (3.1371)	Learning Rate [0.0003125]
6: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00095)	Tok/s 60315 (52600)	Loss/tok 3.0329 (3.1318)	Learning Rate [0.0003125]
7: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 60406 (52701)	Loss/tok 3.0119 (3.1308)	Learning Rate [0.0003125]
8: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 60402 (52739)	Loss/tok 3.2851 (3.1356)	Learning Rate [0.0003125]
9: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 60392 (52779)	Loss/tok 3.2107 (3.1210)	Learning Rate [0.0003125]
5: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 60222 (52511)	Loss/tok 3.4227 (3.1109)	Learning Rate [0.0003125]
4: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00102)	Tok/s 60214 (52457)	Loss/tok 3.0082 (3.1186)	Learning Rate [0.0003125]
3: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00094)	Tok/s 60225 (52356)	Loss/tok 3.3421 (3.1122)	Learning Rate [0.0003125]
11: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 60399 (52948)	Loss/tok 3.3266 (3.1323)	Learning Rate [0.0003125]
10: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 60376 (52867)	Loss/tok 3.1193 (3.1191)	Learning Rate [0.0003125]
2: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 60198 (52253)	Loss/tok 3.0871 (3.1258)	Learning Rate [0.0003125]
1: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00103)	Tok/s 60199 (52176)	Loss/tok 3.3006 (3.1168)	Learning Rate [0.0003125]
12: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00104)	Tok/s 60377 (53061)	Loss/tok 3.1646 (3.1361)	Learning Rate [0.0003125]
0: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00101)	Tok/s 60212 (52112)	Loss/tok 3.1986 (3.1412)	Learning Rate [0.0003125]
15: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 61147 (53414)	Loss/tok 3.2671 (3.1284)	Learning Rate [0.0003125]
14: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 60643 (53307)	Loss/tok 3.6140 (3.1199)	Learning Rate [0.0003125]
13: TRAIN [2][200/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 60345 (53198)	Loss/tok 3.4585 (3.1246)	Learning Rate [0.0003125]
6: TRAIN [2][210/3416]	Time 0.069 (0.058)	Data 0.00118 (0.00095)	Tok/s 73785 (52996)	Loss/tok 3.2801 (3.1322)	Learning Rate [0.0003125]
7: TRAIN [2][210/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 74760 (53101)	Loss/tok 3.0067 (3.1308)	Learning Rate [0.0003125]
8: TRAIN [2][210/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00100)	Tok/s 74758 (53141)	Loss/tok 3.0453 (3.1344)	Learning Rate [0.0003125]
5: TRAIN [2][210/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 73665 (52911)	Loss/tok 3.3854 (3.1133)	Learning Rate [0.0003125]
9: TRAIN [2][210/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00092)	Tok/s 74672 (53182)	Loss/tok 3.1436 (3.1199)	Learning Rate [0.0003125]
10: TRAIN [2][210/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 74679 (53271)	Loss/tok 3.2675 (3.1238)	Learning Rate [0.0003125]
3: TRAIN [2][210/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00094)	Tok/s 73613 (52761)	Loss/tok 3.2501 (3.1131)	Learning Rate [0.0003125]
1: TRAIN [2][210/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00103)	Tok/s 73741 (52582)	Loss/tok 3.0880 (3.1180)	Learning Rate [0.0003125]
11: TRAIN [2][210/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 74806 (53349)	Loss/tok 3.2615 (3.1351)	Learning Rate [0.0003125]
4: TRAIN [2][210/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00102)	Tok/s 73578 (52859)	Loss/tok 3.2509 (3.1219)	Learning Rate [0.0003125]
2: TRAIN [2][210/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 73682 (52660)	Loss/tok 3.1425 (3.1279)	Learning Rate [0.0003125]
0: TRAIN [2][210/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00100)	Tok/s 73739 (52521)	Loss/tok 3.0251 (3.1464)	Learning Rate [0.0003125]
15: TRAIN [2][210/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00092)	Tok/s 74547 (53826)	Loss/tok 3.1995 (3.1299)	Learning Rate [0.0003125]
12: TRAIN [2][210/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00104)	Tok/s 74780 (53465)	Loss/tok 3.2645 (3.1372)	Learning Rate [0.0003125]
14: TRAIN [2][210/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00093)	Tok/s 74689 (53719)	Loss/tok 3.0718 (3.1197)	Learning Rate [0.0003125]
13: TRAIN [2][210/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 74719 (53608)	Loss/tok 3.1761 (3.1248)	Learning Rate [0.0003125]
1: TRAIN [2][220/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00103)	Tok/s 51779 (52780)	Loss/tok 3.2044 (3.1148)	Learning Rate [0.00015625]
2: TRAIN [2][220/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00097)	Tok/s 51741 (52858)	Loss/tok 2.9471 (3.1272)	Learning Rate [0.00015625]
3: TRAIN [2][220/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00094)	Tok/s 51742 (52962)	Loss/tok 3.0588 (3.1128)	Learning Rate [0.00015625]
4: TRAIN [2][220/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00102)	Tok/s 51631 (53058)	Loss/tok 3.0612 (3.1251)	Learning Rate [0.00015625]
0: TRAIN [2][220/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00100)	Tok/s 51648 (52721)	Loss/tok 3.1916 (3.1463)	Learning Rate [0.00015625]
15: TRAIN [2][220/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 51560 (54005)	Loss/tok 3.0916 (3.1259)	Learning Rate [0.00015625]
5: TRAIN [2][220/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00092)	Tok/s 51509 (53106)	Loss/tok 3.0845 (3.1095)	Learning Rate [0.00015625]
6: TRAIN [2][220/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00095)	Tok/s 51438 (53191)	Loss/tok 3.2502 (3.1343)	Learning Rate [0.00015625]
14: TRAIN [2][220/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00093)	Tok/s 51518 (53900)	Loss/tok 3.0618 (3.1229)	Learning Rate [0.00015625]
13: TRAIN [2][220/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00098)	Tok/s 51406 (53795)	Loss/tok 3.1850 (3.1283)	Learning Rate [0.00015625]
7: TRAIN [2][220/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00097)	Tok/s 51220 (53292)	Loss/tok 3.0121 (3.1303)	Learning Rate [0.00015625]
8: TRAIN [2][220/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00100)	Tok/s 51156 (53330)	Loss/tok 3.1125 (3.1345)	Learning Rate [0.00015625]
12: TRAIN [2][220/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00104)	Tok/s 51243 (53654)	Loss/tok 2.9882 (3.1372)	Learning Rate [0.00015625]
11: TRAIN [2][220/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00092)	Tok/s 51093 (53539)	Loss/tok 2.9018 (3.1341)	Learning Rate [0.00015625]
10: TRAIN [2][220/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00095)	Tok/s 51061 (53458)	Loss/tok 3.0837 (3.1199)	Learning Rate [0.00015625]
9: TRAIN [2][220/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00092)	Tok/s 50973 (53371)	Loss/tok 3.2219 (3.1206)	Learning Rate [0.00015625]
8: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00100)	Tok/s 76106 (53240)	Loss/tok 2.9827 (3.1270)	Learning Rate [0.00015625]
6: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00095)	Tok/s 76138 (53096)	Loss/tok 3.0449 (3.1329)	Learning Rate [0.00015625]
9: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00092)	Tok/s 75976 (53279)	Loss/tok 3.3743 (3.1192)	Learning Rate [0.00015625]
10: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00095)	Tok/s 75975 (53367)	Loss/tok 3.0207 (3.1181)	Learning Rate [0.00015625]
5: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00092)	Tok/s 76020 (53013)	Loss/tok 3.1893 (3.1071)	Learning Rate [0.00015625]
7: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00117 (0.00098)	Tok/s 76204 (53197)	Loss/tok 2.9861 (3.1246)	Learning Rate [0.00015625]
4: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00101 (0.00101)	Tok/s 75894 (52967)	Loss/tok 2.9337 (3.1202)	Learning Rate [0.00015625]
12: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00102 (0.00104)	Tok/s 76542 (53571)	Loss/tok 3.2486 (3.1353)	Learning Rate [0.00015625]
3: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00094)	Tok/s 75785 (52875)	Loss/tok 3.1997 (3.1099)	Learning Rate [0.00015625]
11: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00093)	Tok/s 76631 (53453)	Loss/tok 3.1964 (3.1312)	Learning Rate [0.00015625]
13: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00098)	Tok/s 76394 (53706)	Loss/tok 3.1295 (3.1240)	Learning Rate [0.00015625]
2: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00097)	Tok/s 75083 (52770)	Loss/tok 3.1551 (3.1235)	Learning Rate [0.00015625]
14: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00093)	Tok/s 76303 (53810)	Loss/tok 3.0511 (3.1180)	Learning Rate [0.00015625]
0: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00100)	Tok/s 74556 (52636)	Loss/tok 3.1172 (3.1436)	Learning Rate [0.00015625]
15: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00092)	Tok/s 76286 (53919)	Loss/tok 3.2357 (3.1220)	Learning Rate [0.00015625]
1: TRAIN [2][230/3416]	Time 0.071 (0.058)	Data 0.00103 (0.00103)	Tok/s 74658 (52693)	Loss/tok 3.2426 (3.1128)	Learning Rate [0.00015625]
3: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00083 (0.00093)	Tok/s 54094 (52960)	Loss/tok 3.4723 (3.1179)	Learning Rate [0.00015625]
1: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00103)	Tok/s 54202 (52786)	Loss/tok 3.4100 (3.1177)	Learning Rate [0.00015625]
2: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00097)	Tok/s 54096 (52860)	Loss/tok 3.0100 (3.1250)	Learning Rate [0.00015625]
0: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00100)	Tok/s 54136 (52728)	Loss/tok 3.1563 (3.1454)	Learning Rate [0.00015625]
4: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00101)	Tok/s 53932 (53048)	Loss/tok 3.0506 (3.1219)	Learning Rate [0.00015625]
15: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00092)	Tok/s 55133 (53987)	Loss/tok 3.0981 (3.1269)	Learning Rate [0.00015625]
5: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00091)	Tok/s 53815 (53092)	Loss/tok 3.1779 (3.1096)	Learning Rate [0.00015625]
14: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00093)	Tok/s 55106 (53877)	Loss/tok 3.3731 (3.1218)	Learning Rate [0.00015625]
6: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00083 (0.00096)	Tok/s 53691 (53171)	Loss/tok 3.1954 (3.1370)	Learning Rate [0.00015625]
10: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00095)	Tok/s 54895 (53439)	Loss/tok 3.0908 (3.1216)	Learning Rate [0.00015625]
13: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00098)	Tok/s 54986 (53775)	Loss/tok 3.4812 (3.1301)	Learning Rate [0.00015625]
9: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00080 (0.00092)	Tok/s 54751 (53350)	Loss/tok 3.3720 (3.1242)	Learning Rate [0.00015625]
11: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00092)	Tok/s 54890 (53527)	Loss/tok 3.2632 (3.1327)	Learning Rate [0.00015625]
7: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00103 (0.00098)	Tok/s 53646 (53268)	Loss/tok 3.1249 (3.1276)	Learning Rate [0.00015625]
8: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00100)	Tok/s 54593 (53312)	Loss/tok 3.2484 (3.1318)	Learning Rate [0.00015625]
12: TRAIN [2][240/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00104)	Tok/s 54825 (53644)	Loss/tok 3.2694 (3.1393)	Learning Rate [0.00015625]
0: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
10: TRAIN [2][250/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00095)	Tok/s 34244 (53477)	Loss/tok 2.7581 (3.1246)	Learning Rate [0.00015625]
11: TRAIN [2][250/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 34273 (53565)	Loss/tok 3.0361 (3.1342)	Learning Rate [0.00015625]
9: TRAIN [2][250/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00092)	Tok/s 34189 (53386)	Loss/tok 2.9642 (3.1258)	Learning Rate [0.00015625]
8: TRAIN [2][250/3416]	Time 0.052 (0.058)	Data 0.00108 (0.00100)	Tok/s 34165 (53345)	Loss/tok 2.6730 (3.1291)	Learning Rate [0.00015625]
6: TRAIN [2][250/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00096)	Tok/s 33975 (53209)	Loss/tok 2.9540 (3.1353)	Learning Rate [0.00015625]
7: TRAIN [2][250/3416]	Time 0.053 (0.058)	Data 0.00120 (0.00098)	Tok/s 34047 (53302)	Loss/tok 2.9311 (3.1315)	Learning Rate [0.00015625]
12: TRAIN [2][250/3416]	Time 0.052 (0.058)	Data 0.00106 (0.00104)	Tok/s 34238 (53683)	Loss/tok 2.9738 (3.1393)	Learning Rate [0.00015625]
13: TRAIN [2][250/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00098)	Tok/s 34257 (53810)	Loss/tok 2.8339 (3.1326)	Learning Rate [0.00015625]
14: TRAIN [2][250/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00093)	Tok/s 34507 (53914)	Loss/tok 2.9837 (3.1222)	Learning Rate [0.00015625]
15: TRAIN [2][250/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 35396 (54026)	Loss/tok 2.8827 (3.1282)	Learning Rate [0.00015625]
4: TRAIN [2][250/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00101)	Tok/s 34019 (53090)	Loss/tok 2.6638 (3.1235)	Learning Rate [0.00015625]
0: TRAIN [2][250/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00099)	Tok/s 34082 (52773)	Loss/tok 2.8561 (3.1453)	Learning Rate [0.00015625]
5: TRAIN [2][250/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00091)	Tok/s 33917 (53132)	Loss/tok 2.8515 (3.1100)	Learning Rate [0.00015625]
3: TRAIN [2][250/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00093)	Tok/s 33972 (53005)	Loss/tok 2.9084 (3.1193)	Learning Rate [0.00015625]
1: TRAIN [2][250/3416]	Time 0.053 (0.058)	Data 0.00116 (0.00103)	Tok/s 33990 (52829)	Loss/tok 2.6377 (3.1185)	Learning Rate [0.00015625]
2: TRAIN [2][250/3416]	Time 0.053 (0.058)	Data 0.00112 (0.00098)	Tok/s 33981 (52905)	Loss/tok 2.5930 (3.1265)	Learning Rate [0.00015625]
9: TRAIN [2][260/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00092)	Tok/s 57518 (53393)	Loss/tok 3.4583 (3.1291)	Learning Rate [0.00015625]
10: TRAIN [2][260/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00095)	Tok/s 57422 (53480)	Loss/tok 3.0996 (3.1255)	Learning Rate [0.00015625]
8: TRAIN [2][260/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00099)	Tok/s 57443 (53353)	Loss/tok 3.2527 (3.1340)	Learning Rate [0.00015625]
6: TRAIN [2][260/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00095)	Tok/s 57353 (53209)	Loss/tok 3.1588 (3.1349)	Learning Rate [0.00015625]
11: TRAIN [2][260/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00092)	Tok/s 57291 (53572)	Loss/tok 3.3500 (3.1356)	Learning Rate [0.00015625]
7: TRAIN [2][260/3416]	Time 0.067 (0.058)	Data 0.00111 (0.00099)	Tok/s 57423 (53304)	Loss/tok 3.2611 (3.1344)	Learning Rate [0.00015625]
5: TRAIN [2][260/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00091)	Tok/s 57231 (53130)	Loss/tok 3.3617 (3.1124)	Learning Rate [0.00015625]
13: TRAIN [2][260/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00097)	Tok/s 57089 (53815)	Loss/tok 3.3873 (3.1341)	Learning Rate [0.00015625]
4: TRAIN [2][260/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00101)	Tok/s 56294 (53077)	Loss/tok 3.3312 (3.1258)	Learning Rate [0.00015625]
14: TRAIN [2][260/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00093)	Tok/s 56975 (53925)	Loss/tok 3.2490 (3.1242)	Learning Rate [0.00015625]
3: TRAIN [2][260/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00093)	Tok/s 56054 (52988)	Loss/tok 3.2622 (3.1233)	Learning Rate [0.00015625]
15: TRAIN [2][260/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00092)	Tok/s 56866 (54034)	Loss/tok 3.1057 (3.1304)	Learning Rate [0.00015625]
12: TRAIN [2][260/3416]	Time 0.067 (0.058)	Data 0.00120 (0.00103)	Tok/s 57248 (53693)	Loss/tok 3.2358 (3.1441)	Learning Rate [0.00015625]
2: TRAIN [2][260/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00098)	Tok/s 55985 (52880)	Loss/tok 3.3449 (3.1306)	Learning Rate [0.00015625]
0: TRAIN [2][260/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00099)	Tok/s 55829 (52726)	Loss/tok 3.1953 (3.1467)	Learning Rate [0.00015625]
1: TRAIN [2][260/3416]	Time 0.068 (0.058)	Data 0.00111 (0.00104)	Tok/s 55821 (52787)	Loss/tok 3.2021 (3.1203)	Learning Rate [0.00015625]
1: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00104)	Tok/s 71387 (52654)	Loss/tok 3.0359 (3.1181)	Learning Rate [0.00015625]
0: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 71297 (52594)	Loss/tok 3.3496 (3.1456)	Learning Rate [0.00015625]
15: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 73097 (53896)	Loss/tok 3.1872 (3.1320)	Learning Rate [0.00015625]
2: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00098)	Tok/s 71367 (52743)	Loss/tok 3.1162 (3.1303)	Learning Rate [0.00015625]
3: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 72115 (52849)	Loss/tok 3.2166 (3.1230)	Learning Rate [0.00015625]
14: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 72567 (53790)	Loss/tok 3.2515 (3.1272)	Learning Rate [0.00015625]
4: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00101)	Tok/s 72291 (52936)	Loss/tok 3.1519 (3.1256)	Learning Rate [0.00015625]
13: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 71967 (53676)	Loss/tok 3.2690 (3.1356)	Learning Rate [0.00015625]
6: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00095)	Tok/s 72283 (53070)	Loss/tok 3.0602 (3.1331)	Learning Rate [0.00015625]
5: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 72287 (52989)	Loss/tok 3.4692 (3.1154)	Learning Rate [0.00015625]
12: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00103)	Tok/s 71985 (53552)	Loss/tok 3.2401 (3.1413)	Learning Rate [0.00015625]
11: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 71965 (53433)	Loss/tok 3.1005 (3.1342)	Learning Rate [0.00015625]
9: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 72020 (53253)	Loss/tok 3.2337 (3.1278)	Learning Rate [0.00015625]
10: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00095)	Tok/s 71960 (53342)	Loss/tok 2.9818 (3.1221)	Learning Rate [0.00015625]
7: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00099)	Tok/s 72177 (53162)	Loss/tok 3.3654 (3.1336)	Learning Rate [0.00015625]
8: TRAIN [2][270/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00099)	Tok/s 72030 (53211)	Loss/tok 3.2475 (3.1327)	Learning Rate [0.00015625]
6: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00086 (0.00095)	Tok/s 58427 (53341)	Loss/tok 3.4598 (3.1360)	Learning Rate [0.00015625]
7: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00098 (0.00099)	Tok/s 58399 (53429)	Loss/tok 3.1617 (3.1345)	Learning Rate [0.00015625]
8: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00087 (0.00099)	Tok/s 58308 (53483)	Loss/tok 3.2246 (3.1351)	Learning Rate [0.00015625]
5: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00088 (0.00091)	Tok/s 58402 (53257)	Loss/tok 3.0974 (3.1178)	Learning Rate [0.00015625]
9: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00085 (0.00092)	Tok/s 58178 (53527)	Loss/tok 3.4634 (3.1315)	Learning Rate [0.00015625]
10: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00097 (0.00095)	Tok/s 59033 (53626)	Loss/tok 3.0573 (3.1208)	Learning Rate [0.00015625]
3: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00090 (0.00093)	Tok/s 58405 (53106)	Loss/tok 3.1490 (3.1227)	Learning Rate [0.00015625]
11: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00084 (0.00092)	Tok/s 59136 (53717)	Loss/tok 3.3137 (3.1351)	Learning Rate [0.00015625]
2: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00108 (0.00099)	Tok/s 58413 (52992)	Loss/tok 3.2263 (3.1323)	Learning Rate [0.00015625]
12: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00099 (0.00103)	Tok/s 59156 (53834)	Loss/tok 3.3575 (3.1448)	Learning Rate [0.00015625]
1: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00130 (0.00104)	Tok/s 58495 (52891)	Loss/tok 3.2322 (3.1182)	Learning Rate [0.00015625]
0: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00102 (0.00099)	Tok/s 58340 (52811)	Loss/tok 3.0733 (3.1489)	Learning Rate [0.00015625]
13: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00095 (0.00097)	Tok/s 59124 (53958)	Loss/tok 3.2134 (3.1348)	Learning Rate [0.00015625]
15: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00093 (0.00092)	Tok/s 59166 (54175)	Loss/tok 3.2166 (3.1330)	Learning Rate [0.00015625]
14: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00094 (0.00093)	Tok/s 59142 (54070)	Loss/tok 3.2193 (3.1299)	Learning Rate [0.00015625]
4: TRAIN [2][280/3416]	Time 0.068 (0.059)	Data 0.00097 (0.00101)	Tok/s 58125 (53197)	Loss/tok 3.2035 (3.1299)	Learning Rate [0.00015625]
9: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 83525 (53353)	Loss/tok 3.0085 (3.1279)	Learning Rate [0.00015625]
11: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00092)	Tok/s 84477 (53541)	Loss/tok 3.0140 (3.1316)	Learning Rate [0.00015625]
6: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00095)	Tok/s 83155 (53150)	Loss/tok 2.9767 (3.1341)	Learning Rate [0.00015625]
8: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 83342 (53307)	Loss/tok 3.1188 (3.1319)	Learning Rate [0.00015625]
7: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00099)	Tok/s 83263 (53244)	Loss/tok 2.9406 (3.1311)	Learning Rate [0.00015625]
2: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00099)	Tok/s 82449 (52755)	Loss/tok 3.0128 (3.1300)	Learning Rate [0.00015625]
10: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00095)	Tok/s 83965 (53450)	Loss/tok 2.9214 (3.1172)	Learning Rate [0.00015625]
3: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00093)	Tok/s 82410 (52878)	Loss/tok 3.0182 (3.1209)	Learning Rate [0.00015625]
1: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00104)	Tok/s 82480 (52635)	Loss/tok 3.0851 (3.1149)	Learning Rate [0.00015625]
14: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00093)	Tok/s 84490 (53910)	Loss/tok 3.1153 (3.1267)	Learning Rate [0.00015625]
0: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 82536 (52542)	Loss/tok 3.0771 (3.1489)	Learning Rate [0.00015625]
12: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00103)	Tok/s 84463 (53664)	Loss/tok 3.0151 (3.1433)	Learning Rate [0.00015625]
15: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00091)	Tok/s 85150 (54026)	Loss/tok 3.3026 (3.1331)	Learning Rate [0.00015625]
13: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 84457 (53789)	Loss/tok 2.8083 (3.1322)	Learning Rate [0.00015625]
4: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 82745 (52975)	Loss/tok 3.0401 (3.1259)	Learning Rate [0.00015625]
5: TRAIN [2][290/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 83078 (53056)	Loss/tok 2.9158 (3.1141)	Learning Rate [0.00015625]
9: TRAIN [2][300/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00092)	Tok/s 52851 (53444)	Loss/tok 3.2968 (3.1254)	Learning Rate [0.00015625]
8: TRAIN [2][300/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00099)	Tok/s 52887 (53396)	Loss/tok 2.9487 (3.1301)	Learning Rate [0.00015625]
6: TRAIN [2][300/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00095)	Tok/s 52880 (53239)	Loss/tok 3.2044 (3.1335)	Learning Rate [0.00015625]
10: TRAIN [2][300/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00095)	Tok/s 52716 (53541)	Loss/tok 3.2025 (3.1174)	Learning Rate [0.00015625]
5: TRAIN [2][300/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00091)	Tok/s 52947 (53148)	Loss/tok 3.1002 (3.1143)	Learning Rate [0.00015625]
4: TRAIN [2][300/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00100)	Tok/s 52739 (53069)	Loss/tok 2.9012 (3.1228)	Learning Rate [0.00015625]
3: TRAIN [2][300/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00093)	Tok/s 52653 (52972)	Loss/tok 3.1490 (3.1211)	Learning Rate [0.00015625]
2: TRAIN [2][300/3416]	Time 0.063 (0.058)	Data 0.00107 (0.00099)	Tok/s 52556 (52853)	Loss/tok 3.1071 (3.1287)	Learning Rate [0.00015625]
13: TRAIN [2][300/3416]	Time 0.064 (0.058)	Data 0.00097 (0.00097)	Tok/s 52393 (53874)	Loss/tok 3.2301 (3.1319)	Learning Rate [0.00015625]
1: TRAIN [2][300/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00104)	Tok/s 52469 (52736)	Loss/tok 3.1803 (3.1153)	Learning Rate [0.00015625]
14: TRAIN [2][300/3416]	Time 0.064 (0.058)	Data 0.00084 (0.00093)	Tok/s 52332 (53993)	Loss/tok 3.1253 (3.1261)	Learning Rate [0.00015625]
0: TRAIN [2][300/3416]	Time 0.064 (0.058)	Data 0.00099 (0.00100)	Tok/s 52379 (52645)	Loss/tok 3.0304 (3.1484)	Learning Rate [0.00015625]
15: TRAIN [2][300/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00092)	Tok/s 52332 (54107)	Loss/tok 3.1300 (3.1312)	Learning Rate [0.00015625]
11: TRAIN [2][300/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00092)	Tok/s 52618 (53629)	Loss/tok 3.0647 (3.1336)	Learning Rate [0.00015625]
7: TRAIN [2][300/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00099)	Tok/s 52204 (53329)	Loss/tok 3.0909 (3.1291)	Learning Rate [0.00015625]
12: TRAIN [2][300/3416]	Time 0.064 (0.058)	Data 0.00105 (0.00103)	Tok/s 51806 (53749)	Loss/tok 3.1638 (3.1423)	Learning Rate [0.00015625]
12: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00103)	Tok/s 40570 (53734)	Loss/tok 2.9524 (3.1409)	Learning Rate [0.00015625]
9: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00092)	Tok/s 40656 (53430)	Loss/tok 3.1150 (3.1259)	Learning Rate [0.00015625]
6: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00095)	Tok/s 39958 (53214)	Loss/tok 2.9515 (3.1333)	Learning Rate [0.00015625]
10: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00095)	Tok/s 40621 (53524)	Loss/tok 2.8388 (3.1179)	Learning Rate [0.00015625]
13: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00097)	Tok/s 40477 (53857)	Loss/tok 2.9858 (3.1311)	Learning Rate [0.00015625]
8: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00099)	Tok/s 40626 (53377)	Loss/tok 2.9551 (3.1292)	Learning Rate [0.00015625]
15: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00091)	Tok/s 40331 (54090)	Loss/tok 2.8112 (3.1289)	Learning Rate [0.00015625]
14: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00092)	Tok/s 40387 (53974)	Loss/tok 2.9466 (3.1260)	Learning Rate [0.00015625]
5: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00102 (0.00091)	Tok/s 39281 (53120)	Loss/tok 3.0490 (3.1146)	Learning Rate [0.00015625]
7: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00099)	Tok/s 40545 (53312)	Loss/tok 2.8799 (3.1286)	Learning Rate [0.00015625]
4: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00100)	Tok/s 39140 (53035)	Loss/tok 2.6967 (3.1233)	Learning Rate [0.00015625]
3: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00093)	Tok/s 39040 (52932)	Loss/tok 2.9680 (3.1216)	Learning Rate [0.00015625]
0: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00100)	Tok/s 39026 (52585)	Loss/tok 2.8243 (3.1480)	Learning Rate [0.00015625]
1: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00103)	Tok/s 38944 (52685)	Loss/tok 3.1607 (3.1169)	Learning Rate [0.00015625]
2: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00103 (0.00099)	Tok/s 38988 (52811)	Loss/tok 3.0978 (3.1263)	Learning Rate [0.00015625]
11: TRAIN [2][310/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00092)	Tok/s 40443 (53612)	Loss/tok 2.8514 (3.1344)	Learning Rate [0.00015625]
11: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00092)	Tok/s 49983 (53583)	Loss/tok 3.1544 (3.1342)	Learning Rate [0.00015625]
9: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00092)	Tok/s 49980 (53398)	Loss/tok 2.9638 (3.1254)	Learning Rate [0.00015625]
10: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00095)	Tok/s 50002 (53494)	Loss/tok 3.1746 (3.1213)	Learning Rate [0.00015625]
12: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00104 (0.00104)	Tok/s 49989 (53704)	Loss/tok 3.1503 (3.1408)	Learning Rate [0.00015625]
8: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00082 (0.00098)	Tok/s 49968 (53347)	Loss/tok 2.9749 (3.1280)	Learning Rate [0.00015625]
14: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00092)	Tok/s 49807 (53939)	Loss/tok 3.3699 (3.1265)	Learning Rate [0.00015625]
7: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00098)	Tok/s 49931 (53283)	Loss/tok 3.1323 (3.1276)	Learning Rate [0.00015625]
15: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00091)	Tok/s 49732 (54054)	Loss/tok 2.8725 (3.1281)	Learning Rate [0.00015625]
6: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00085 (0.00095)	Tok/s 49932 (53188)	Loss/tok 3.0198 (3.1328)	Learning Rate [0.00015625]
13: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00083 (0.00097)	Tok/s 49788 (53826)	Loss/tok 3.2509 (3.1300)	Learning Rate [0.00015625]
4: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00100)	Tok/s 49938 (53012)	Loss/tok 3.2787 (3.1229)	Learning Rate [0.00015625]
1: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00103)	Tok/s 49714 (52670)	Loss/tok 3.0026 (3.1156)	Learning Rate [0.00015625]
5: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00091)	Tok/s 49983 (53096)	Loss/tok 3.0536 (3.1162)	Learning Rate [0.00015625]
2: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00102 (0.00099)	Tok/s 49746 (52795)	Loss/tok 3.1924 (3.1264)	Learning Rate [0.00015625]
0: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00101)	Tok/s 49742 (52573)	Loss/tok 3.0206 (3.1481)	Learning Rate [0.00015625]
3: TRAIN [2][320/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00093)	Tok/s 49739 (52911)	Loss/tok 3.1905 (3.1216)	Learning Rate [0.00015625]
11: TRAIN [2][330/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00091)	Tok/s 55147 (53679)	Loss/tok 3.3951 (3.1336)	Learning Rate [0.00015625]
13: TRAIN [2][330/3416]	Time 0.060 (0.058)	Data 0.00103 (0.00098)	Tok/s 55063 (53922)	Loss/tok 3.1285 (3.1277)	Learning Rate [0.00015625]
14: TRAIN [2][330/3416]	Time 0.061 (0.058)	Data 0.00107 (0.00092)	Tok/s 54950 (54035)	Loss/tok 2.9669 (3.1263)	Learning Rate [0.00015625]
9: TRAIN [2][330/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00092)	Tok/s 55155 (53499)	Loss/tok 3.1020 (3.1250)	Learning Rate [0.00015625]
10: TRAIN [2][330/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00095)	Tok/s 55167 (53592)	Loss/tok 3.2338 (3.1227)	Learning Rate [0.00015625]
15: TRAIN [2][330/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00092)	Tok/s 54954 (54149)	Loss/tok 3.1215 (3.1284)	Learning Rate [0.00015625]
8: TRAIN [2][330/3416]	Time 0.060 (0.058)	Data 0.00104 (0.00099)	Tok/s 55109 (53449)	Loss/tok 3.0606 (3.1248)	Learning Rate [0.00015625]
0: TRAIN [2][330/3416]	Time 0.061 (0.058)	Data 0.00098 (0.00101)	Tok/s 54914 (52683)	Loss/tok 3.0501 (3.1474)	Learning Rate [0.00015625]
1: TRAIN [2][330/3416]	Time 0.061 (0.058)	Data 0.00098 (0.00103)	Tok/s 54920 (52777)	Loss/tok 3.2374 (3.1177)	Learning Rate [0.00015625]
7: TRAIN [2][330/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00098)	Tok/s 55119 (53384)	Loss/tok 3.2827 (3.1266)	Learning Rate [0.00015625]
4: TRAIN [2][330/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00100)	Tok/s 54970 (53112)	Loss/tok 3.2367 (3.1213)	Learning Rate [0.00015625]
3: TRAIN [2][330/3416]	Time 0.061 (0.058)	Data 0.00098 (0.00093)	Tok/s 54943 (53016)	Loss/tok 3.2478 (3.1214)	Learning Rate [0.00015625]
5: TRAIN [2][330/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00092)	Tok/s 55128 (53194)	Loss/tok 3.1148 (3.1178)	Learning Rate [0.00015625]
12: TRAIN [2][330/3416]	Time 0.060 (0.058)	Data 0.00113 (0.00104)	Tok/s 55603 (53795)	Loss/tok 3.1994 (3.1388)	Learning Rate [0.00015625]
2: TRAIN [2][330/3416]	Time 0.060 (0.058)	Data 0.00107 (0.00099)	Tok/s 55009 (52900)	Loss/tok 3.2598 (3.1263)	Learning Rate [0.00015625]
6: TRAIN [2][330/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00095)	Tok/s 53893 (53280)	Loss/tok 2.9940 (3.1313)	Learning Rate [0.00015625]
3: TRAIN [2][340/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00093)	Tok/s 53860 (52778)	Loss/tok 2.9910 (3.1197)	Learning Rate [0.00015625]
1: TRAIN [2][340/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00103)	Tok/s 53785 (52530)	Loss/tok 3.1749 (3.1158)	Learning Rate [0.00015625]
2: TRAIN [2][340/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00099)	Tok/s 53845 (52664)	Loss/tok 3.3510 (3.1257)	Learning Rate [0.00015625]
4: TRAIN [2][340/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00100)	Tok/s 53686 (52878)	Loss/tok 2.9812 (3.1194)	Learning Rate [0.00015625]
0: TRAIN [2][340/3416]	Time 0.053 (0.058)	Data 0.00085 (0.00101)	Tok/s 53860 (52428)	Loss/tok 3.2294 (3.1462)	Learning Rate [0.00015625]
6: TRAIN [2][340/3416]	Time 0.054 (0.058)	Data 0.00086 (0.00095)	Tok/s 53810 (53063)	Loss/tok 3.0747 (3.1284)	Learning Rate [0.00015625]
5: TRAIN [2][340/3416]	Time 0.054 (0.058)	Data 0.00100 (0.00092)	Tok/s 53761 (52967)	Loss/tok 3.2082 (3.1180)	Learning Rate [0.00015625]
15: TRAIN [2][340/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00092)	Tok/s 53885 (53936)	Loss/tok 2.9174 (3.1273)	Learning Rate [0.00015625]
7: TRAIN [2][340/3416]	Time 0.054 (0.058)	Data 0.00086 (0.00098)	Tok/s 53748 (53161)	Loss/tok 3.1545 (3.1257)	Learning Rate [0.00015625]
14: TRAIN [2][340/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00092)	Tok/s 53914 (53818)	Loss/tok 3.0962 (3.1264)	Learning Rate [0.00015625]
8: TRAIN [2][340/3416]	Time 0.054 (0.058)	Data 0.00085 (0.00098)	Tok/s 53768 (53229)	Loss/tok 3.0577 (3.1229)	Learning Rate [0.00015625]
9: TRAIN [2][340/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00092)	Tok/s 53799 (53277)	Loss/tok 3.1145 (3.1246)	Learning Rate [0.00015625]
13: TRAIN [2][340/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00098)	Tok/s 53839 (53698)	Loss/tok 2.8810 (3.1271)	Learning Rate [0.00015625]
11: TRAIN [2][340/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00091)	Tok/s 53872 (53454)	Loss/tok 3.2545 (3.1326)	Learning Rate [0.00015625]
12: TRAIN [2][340/3416]	Time 0.053 (0.058)	Data 0.00123 (0.00104)	Tok/s 53925 (53574)	Loss/tok 3.0383 (3.1362)	Learning Rate [0.00015625]
10: TRAIN [2][340/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00095)	Tok/s 53784 (53369)	Loss/tok 3.0074 (3.1198)	Learning Rate [0.00015625]
6: TRAIN [2][350/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00095)	Tok/s 53095 (53125)	Loss/tok 2.9503 (3.1308)	Learning Rate [0.00015625]
5: TRAIN [2][350/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00092)	Tok/s 53000 (53032)	Loss/tok 2.9336 (3.1206)	Learning Rate [0.00015625]
7: TRAIN [2][350/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00098)	Tok/s 53101 (53220)	Loss/tok 2.7679 (3.1266)	Learning Rate [0.00015625]
4: TRAIN [2][350/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00099)	Tok/s 52870 (52945)	Loss/tok 3.1442 (3.1215)	Learning Rate [0.00015625]
3: TRAIN [2][350/3416]	Time 0.050 (0.058)	Data 0.00077 (0.00093)	Tok/s 52763 (52848)	Loss/tok 3.0403 (3.1209)	Learning Rate [0.00015625]
8: TRAIN [2][350/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00098)	Tok/s 53069 (53287)	Loss/tok 3.0623 (3.1239)	Learning Rate [0.00015625]
9: TRAIN [2][350/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00092)	Tok/s 53178 (53336)	Loss/tok 3.0664 (3.1248)	Learning Rate [0.00015625]
2: TRAIN [2][350/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00099)	Tok/s 52735 (52735)	Loss/tok 2.9313 (3.1264)	Learning Rate [0.00015625]
0: TRAIN [2][350/3416]	Time 0.050 (0.058)	Data 0.00111 (0.00100)	Tok/s 52834 (52504)	Loss/tok 2.9627 (3.1472)	Learning Rate [0.00015625]
1: TRAIN [2][350/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00103)	Tok/s 52764 (52603)	Loss/tok 3.1987 (3.1172)	Learning Rate [0.00015625]
15: TRAIN [2][350/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 52842 (53991)	Loss/tok 2.8260 (3.1274)	Learning Rate [0.00015625]
11: TRAIN [2][350/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00091)	Tok/s 52994 (53514)	Loss/tok 2.8834 (3.1338)	Learning Rate [0.00015625]
10: TRAIN [2][350/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00095)	Tok/s 53025 (53426)	Loss/tok 2.9923 (3.1210)	Learning Rate [0.00015625]
14: TRAIN [2][350/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00092)	Tok/s 52842 (53871)	Loss/tok 3.1072 (3.1290)	Learning Rate [0.00015625]
12: TRAIN [2][350/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00104)	Tok/s 52929 (53632)	Loss/tok 3.1218 (3.1371)	Learning Rate [0.00015625]
13: TRAIN [2][350/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00098)	Tok/s 52517 (53754)	Loss/tok 3.2024 (3.1277)	Learning Rate [0.00015625]
10: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00095)	Tok/s 52697 (53452)	Loss/tok 3.0535 (3.1210)	Learning Rate [0.00015625]
11: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00091)	Tok/s 52740 (53539)	Loss/tok 3.1203 (3.1306)	Learning Rate [0.00015625]
9: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00079 (0.00092)	Tok/s 52601 (53364)	Loss/tok 2.9807 (3.1225)	Learning Rate [0.00015625]
8: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00098)	Tok/s 52488 (53316)	Loss/tok 3.1159 (3.1219)	Learning Rate [0.00015625]
12: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00103)	Tok/s 52797 (53658)	Loss/tok 3.0198 (3.1342)	Learning Rate [0.00015625]
7: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00098)	Tok/s 52410 (53249)	Loss/tok 3.0018 (3.1257)	Learning Rate [0.00015625]
13: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00098)	Tok/s 52746 (53778)	Loss/tok 3.0753 (3.1250)	Learning Rate [0.00015625]
6: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00094)	Tok/s 52331 (53154)	Loss/tok 2.9714 (3.1298)	Learning Rate [0.00015625]
14: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00080 (0.00092)	Tok/s 53658 (53897)	Loss/tok 3.1565 (3.1279)	Learning Rate [0.00015625]
5: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 52359 (53062)	Loss/tok 2.9632 (3.1189)	Learning Rate [0.00015625]
15: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 53926 (54017)	Loss/tok 3.1063 (3.1248)	Learning Rate [0.00015625]
4: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00099)	Tok/s 52366 (52973)	Loss/tok 3.1935 (3.1190)	Learning Rate [0.00015625]
0: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00100)	Tok/s 52589 (52536)	Loss/tok 3.0823 (3.1468)	Learning Rate [0.00015625]
3: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00092)	Tok/s 52432 (52873)	Loss/tok 3.2201 (3.1202)	Learning Rate [0.00015625]
1: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00102)	Tok/s 52400 (52635)	Loss/tok 3.2564 (3.1171)	Learning Rate [0.00015625]
2: TRAIN [2][360/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00099)	Tok/s 52403 (52763)	Loss/tok 2.8815 (3.1229)	Learning Rate [0.00015625]
9: Upscaling, new scale: 8192.0
6: Upscaling, new scale: 8192.0
10: Upscaling, new scale: 8192.0
7: Upscaling, new scale: 8192.0
9: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00085 (0.00092)	Tok/s 73966 (53449)	Loss/tok 3.1049 (3.1206)	Learning Rate [0.00015625]
15: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
11: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
6: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00085 (0.00094)	Tok/s 73859 (53238)	Loss/tok 3.2105 (3.1300)	Learning Rate [0.00015625]
4: Upscaling, new scale: 8192.0
14: Upscaling, new scale: 8192.0
8: Upscaling, new scale: 8192.0
10: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00088 (0.00095)	Tok/s 74597 (53537)	Loss/tok 3.0935 (3.1199)	Learning Rate [0.00015625]
3: Upscaling, new scale: 8192.0
5: Upscaling, new scale: 8192.0
15: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00086 (0.00092)	Tok/s 74656 (54091)	Loss/tok 3.3499 (3.1260)	Learning Rate [0.00015625]
12: Upscaling, new scale: 8192.0
7: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00098)	Tok/s 73725 (53332)	Loss/tok 3.0035 (3.1236)	Learning Rate [0.00015625]
13: Upscaling, new scale: 8192.0
11: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00088 (0.00091)	Tok/s 74532 (53624)	Loss/tok 3.2412 (3.1299)	Learning Rate [0.00015625]
1: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00102)	Tok/s 73799 (52727)	Loss/tok 3.4107 (3.1197)	Learning Rate [0.00015625]
0: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00100)	Tok/s 73607 (52627)	Loss/tok 3.1895 (3.1470)	Learning Rate [0.00015625]
14: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00092)	Tok/s 74550 (53973)	Loss/tok 3.2666 (3.1271)	Learning Rate [0.00015625]
2: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00099)	Tok/s 73831 (52852)	Loss/tok 3.0749 (3.1234)	Learning Rate [0.00015625]
4: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00099)	Tok/s 73775 (53059)	Loss/tok 3.1691 (3.1187)	Learning Rate [0.00015625]
3: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00084 (0.00092)	Tok/s 73800 (52958)	Loss/tok 2.9099 (3.1189)	Learning Rate [0.00015625]
5: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00101 (0.00092)	Tok/s 73719 (53146)	Loss/tok 2.9948 (3.1183)	Learning Rate [0.00015625]
8: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00098)	Tok/s 73517 (53398)	Loss/tok 3.1046 (3.1227)	Learning Rate [0.00015625]
12: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00118 (0.00104)	Tok/s 74616 (53740)	Loss/tok 3.0247 (3.1332)	Learning Rate [0.00015625]
13: TRAIN [2][370/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00098)	Tok/s 74455 (53856)	Loss/tok 3.2251 (3.1241)	Learning Rate [0.00015625]
10: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00095)	Tok/s 34579 (53573)	Loss/tok 2.8868 (3.1212)	Learning Rate [0.00015625]
9: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00092)	Tok/s 34581 (53486)	Loss/tok 2.8155 (3.1200)	Learning Rate [0.00015625]
11: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00091)	Tok/s 34607 (53662)	Loss/tok 2.9465 (3.1308)	Learning Rate [0.00015625]
8: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00098)	Tok/s 34552 (53437)	Loss/tok 2.8222 (3.1231)	Learning Rate [0.00015625]
12: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00109 (0.00104)	Tok/s 34576 (53780)	Loss/tok 2.8698 (3.1337)	Learning Rate [0.00015625]
13: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00098)	Tok/s 34583 (53894)	Loss/tok 2.8506 (3.1246)	Learning Rate [0.00015625]
7: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00097)	Tok/s 34517 (53372)	Loss/tok 2.8041 (3.1236)	Learning Rate [0.00015625]
3: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00092)	Tok/s 34697 (53003)	Loss/tok 2.8389 (3.1187)	Learning Rate [0.00015625]
6: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00094)	Tok/s 34550 (53278)	Loss/tok 2.9115 (3.1344)	Learning Rate [0.00015625]
1: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00102)	Tok/s 33573 (52774)	Loss/tok 3.0163 (3.1217)	Learning Rate [0.00015625]
4: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00099)	Tok/s 34631 (53101)	Loss/tok 2.9323 (3.1188)	Learning Rate [0.00015625]
2: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00099)	Tok/s 34687 (52899)	Loss/tok 2.9068 (3.1226)	Learning Rate [0.00015625]
14: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00092)	Tok/s 34564 (54012)	Loss/tok 2.6139 (3.1281)	Learning Rate [0.00015625]
15: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00092)	Tok/s 34586 (54132)	Loss/tok 2.9664 (3.1287)	Learning Rate [0.00015625]
0: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00100)	Tok/s 33358 (52677)	Loss/tok 2.8907 (3.1477)	Learning Rate [0.00015625]
5: TRAIN [2][380/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00092)	Tok/s 34596 (53188)	Loss/tok 2.9743 (3.1200)	Learning Rate [0.00015625]
11: TRAIN [2][390/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00091)	Tok/s 50879 (53725)	Loss/tok 3.0076 (3.1321)	Learning Rate [0.00015625]
10: TRAIN [2][390/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00095)	Tok/s 50829 (53636)	Loss/tok 2.9864 (3.1205)	Learning Rate [0.00015625]
9: TRAIN [2][390/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00092)	Tok/s 50807 (53547)	Loss/tok 2.8379 (3.1200)	Learning Rate [0.00015625]
12: TRAIN [2][390/3416]	Time 0.054 (0.058)	Data 0.00100 (0.00104)	Tok/s 50662 (53839)	Loss/tok 3.3428 (3.1357)	Learning Rate [0.00015625]
8: TRAIN [2][390/3416]	Time 0.054 (0.058)	Data 0.00081 (0.00098)	Tok/s 50656 (53496)	Loss/tok 3.0606 (3.1220)	Learning Rate [0.00015625]
13: TRAIN [2][390/3416]	Time 0.054 (0.058)	Data 0.00099 (0.00098)	Tok/s 50715 (53954)	Loss/tok 2.9471 (3.1248)	Learning Rate [0.00015625]
14: TRAIN [2][390/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00092)	Tok/s 50548 (54075)	Loss/tok 3.1282 (3.1283)	Learning Rate [0.00015625]
6: TRAIN [2][390/3416]	Time 0.054 (0.058)	Data 0.00079 (0.00094)	Tok/s 50528 (53335)	Loss/tok 3.0439 (3.1338)	Learning Rate [0.00015625]
7: TRAIN [2][390/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00097)	Tok/s 50655 (53427)	Loss/tok 2.9919 (3.1227)	Learning Rate [0.00015625]
15: TRAIN [2][390/3416]	Time 0.055 (0.058)	Data 0.00086 (0.00092)	Tok/s 50378 (54193)	Loss/tok 3.1110 (3.1297)	Learning Rate [0.00015625]
5: TRAIN [2][390/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00092)	Tok/s 50473 (53245)	Loss/tok 2.9326 (3.1217)	Learning Rate [0.00015625]
0: TRAIN [2][390/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00100)	Tok/s 50378 (52740)	Loss/tok 2.8584 (3.1457)	Learning Rate [0.00015625]
4: TRAIN [2][390/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00099)	Tok/s 50559 (53160)	Loss/tok 3.2443 (3.1202)	Learning Rate [0.00015625]
1: TRAIN [2][390/3416]	Time 0.055 (0.058)	Data 0.00085 (0.00102)	Tok/s 50384 (52833)	Loss/tok 3.1468 (3.1205)	Learning Rate [0.00015625]
3: TRAIN [2][390/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00092)	Tok/s 50397 (53060)	Loss/tok 3.4573 (3.1228)	Learning Rate [0.00015625]
2: TRAIN [2][390/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00099)	Tok/s 50323 (52955)	Loss/tok 3.1774 (3.1210)	Learning Rate [0.00015625]
9: Gradient norm: inf
8: Gradient norm: inf
7: Gradient norm: inf
9: Skipped batch, new scale: 4096.0
8: Skipped batch, new scale: 4096.0
10: Gradient norm: inf
6: Gradient norm: inf
7: Skipped batch, new scale: 4096.0
5: Gradient norm: inf
10: Skipped batch, new scale: 4096.0
11: Gradient norm: inf
6: Skipped batch, new scale: 4096.0
5: Skipped batch, new scale: 4096.0
11: Skipped batch, new scale: 4096.0
12: Gradient norm: inf
4: Gradient norm: inf
13: Gradient norm: inf
3: Gradient norm: inf
12: Skipped batch, new scale: 4096.0
4: Skipped batch, new scale: 4096.0
2: Gradient norm: inf
14: Gradient norm: inf
3: Skipped batch, new scale: 4096.0
13: Skipped batch, new scale: 4096.0
15: Gradient norm: inf
0: Gradient norm: inf
14: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
1: Gradient norm: inf
15: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
4: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 57503 (53138)	Loss/tok 3.2700 (3.1198)	Learning Rate [0.00015625]
5: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00092)	Tok/s 57504 (53221)	Loss/tok 2.9877 (3.1208)	Learning Rate [0.00015625]
6: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00094)	Tok/s 57450 (53311)	Loss/tok 3.3518 (3.1363)	Learning Rate [0.00015625]
3: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00126 (0.00093)	Tok/s 57410 (53040)	Loss/tok 3.2109 (3.1223)	Learning Rate [0.00015625]
2: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00099)	Tok/s 57284 (52937)	Loss/tok 3.1072 (3.1214)	Learning Rate [0.00015625]
1: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00102)	Tok/s 57225 (52816)	Loss/tok 3.1657 (3.1212)	Learning Rate [0.00015625]
0: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00100)	Tok/s 57261 (52725)	Loss/tok 3.3558 (3.1469)	Learning Rate [0.00015625]
7: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00097)	Tok/s 57443 (53403)	Loss/tok 3.4349 (3.1235)	Learning Rate [0.00015625]
9: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 57425 (53523)	Loss/tok 3.2674 (3.1210)	Learning Rate [0.00015625]
15: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 58208 (54164)	Loss/tok 3.1695 (3.1309)	Learning Rate [0.00015625]
8: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00098)	Tok/s 57450 (53471)	Loss/tok 3.4374 (3.1232)	Learning Rate [0.00015625]
14: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 58228 (54044)	Loss/tok 3.4033 (3.1294)	Learning Rate [0.00015625]
11: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00091)	Tok/s 58266 (53699)	Loss/tok 3.2550 (3.1335)	Learning Rate [0.00015625]
10: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00095)	Tok/s 58054 (53611)	Loss/tok 3.2989 (3.1213)	Learning Rate [0.00015625]
13: TRAIN [2][400/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 58246 (53925)	Loss/tok 3.0493 (3.1248)	Learning Rate [0.00015625]
12: TRAIN [2][400/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00105)	Tok/s 59703 (53809)	Loss/tok 3.1847 (3.1351)	Learning Rate [0.00015625]
2: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00099)	Tok/s 41584 (52826)	Loss/tok 3.0822 (3.1203)	Learning Rate [0.00015625]
1: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00102)	Tok/s 41635 (52708)	Loss/tok 2.9089 (3.1196)	Learning Rate [0.00015625]
3: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00093)	Tok/s 41503 (52932)	Loss/tok 2.7939 (3.1222)	Learning Rate [0.00015625]
0: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00100)	Tok/s 41620 (52614)	Loss/tok 3.0259 (3.1454)	Learning Rate [0.00015625]
4: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00099)	Tok/s 41426 (53027)	Loss/tok 2.8098 (3.1193)	Learning Rate [0.00015625]
15: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00092)	Tok/s 42948 (54054)	Loss/tok 2.9723 (3.1302)	Learning Rate [0.00015625]
5: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00092)	Tok/s 41413 (53108)	Loss/tok 2.9207 (3.1206)	Learning Rate [0.00015625]
6: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00080 (0.00094)	Tok/s 41356 (53196)	Loss/tok 2.6936 (3.1348)	Learning Rate [0.00015625]
13: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00098)	Tok/s 41651 (53811)	Loss/tok 3.1183 (3.1227)	Learning Rate [0.00015625]
7: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00097)	Tok/s 41421 (53289)	Loss/tok 2.8269 (3.1237)	Learning Rate [0.00015625]
11: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00091)	Tok/s 41492 (53583)	Loss/tok 2.7635 (3.1330)	Learning Rate [0.00015625]
9: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00091)	Tok/s 41403 (53408)	Loss/tok 3.0105 (3.1201)	Learning Rate [0.00015625]
8: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00098)	Tok/s 41439 (53357)	Loss/tok 2.7858 (3.1221)	Learning Rate [0.00015625]
12: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00107 (0.00105)	Tok/s 41597 (53693)	Loss/tok 3.0321 (3.1326)	Learning Rate [0.00015625]
10: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00095)	Tok/s 41419 (53495)	Loss/tok 3.1277 (3.1221)	Learning Rate [0.00015625]
14: TRAIN [2][410/3416]	Time 0.048 (0.058)	Data 0.00080 (0.00092)	Tok/s 42863 (53936)	Loss/tok 2.9669 (3.1297)	Learning Rate [0.00015625]
14: Gradient norm: inf
15: Gradient norm: inf
13: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
12: Gradient norm: inf
0: Gradient norm: inf
15: Skipped batch, new scale: 2048.0
13: Skipped batch, new scale: 2048.0
11: Gradient norm: inf
12: Skipped batch, new scale: 2048.0
0: Skipped batch, new scale: 2048.0
1: Gradient norm: inf
10: Gradient norm: inf
11: Skipped batch, new scale: 2048.0
9: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
2: Gradient norm: inf
10: Skipped batch, new scale: 2048.0
3: Gradient norm: inf
9: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
8: Gradient norm: inf
4: Gradient norm: inf
7: Gradient norm: inf
8: Skipped batch, new scale: 2048.0
4: Skipped batch, new scale: 2048.0
6: Gradient norm: inf
5: Gradient norm: inf
7: Skipped batch, new scale: 2048.0
6: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
0: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00100)	Tok/s 33866 (52527)	Loss/tok 2.8376 (3.1450)	Learning Rate [0.00015625]
15: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00085 (0.00092)	Tok/s 34175 (53967)	Loss/tok 2.7397 (3.1288)	Learning Rate [0.00015625]
1: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00102)	Tok/s 33874 (52618)	Loss/tok 2.8127 (3.1172)	Learning Rate [0.00015625]
13: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00104 (0.00098)	Tok/s 33865 (53716)	Loss/tok 2.8162 (3.1198)	Learning Rate [0.00015625]
2: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00099)	Tok/s 33863 (52735)	Loss/tok 2.8228 (3.1186)	Learning Rate [0.00015625]
11: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00091)	Tok/s 33886 (53491)	Loss/tok 2.7165 (3.1316)	Learning Rate [0.00015625]
12: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00112 (0.00105)	Tok/s 33854 (53601)	Loss/tok 2.9125 (3.1323)	Learning Rate [0.00015625]
3: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00085 (0.00093)	Tok/s 33867 (52840)	Loss/tok 2.9287 (3.1227)	Learning Rate [0.00015625]
9: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00091)	Tok/s 33853 (53318)	Loss/tok 2.7603 (3.1183)	Learning Rate [0.00015625]
10: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00095)	Tok/s 33850 (53405)	Loss/tok 2.8703 (3.1210)	Learning Rate [0.00015625]
5: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00092)	Tok/s 33872 (53019)	Loss/tok 2.7809 (3.1198)	Learning Rate [0.00015625]
6: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00094)	Tok/s 33853 (53105)	Loss/tok 2.5771 (3.1345)	Learning Rate [0.00015625]
8: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00098)	Tok/s 33868 (53266)	Loss/tok 2.8917 (3.1196)	Learning Rate [0.00015625]
14: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00092)	Tok/s 33891 (53843)	Loss/tok 2.8827 (3.1288)	Learning Rate [0.00015625]
7: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00097)	Tok/s 33851 (53198)	Loss/tok 2.8833 (3.1211)	Learning Rate [0.00015625]
4: TRAIN [2][420/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00099)	Tok/s 33856 (52937)	Loss/tok 3.1510 (3.1175)	Learning Rate [0.00015625]
0: TRAIN [2][430/3416]	Time 0.054 (0.058)	Data 0.00100 (0.00099)	Tok/s 50676 (52303)	Loss/tok 3.2596 (3.1438)	Learning Rate [0.00015625]
15: TRAIN [2][430/3416]	Time 0.054 (0.058)	Data 0.00094 (0.00092)	Tok/s 51790 (53746)	Loss/tok 3.0524 (3.1273)	Learning Rate [0.00015625]
14: TRAIN [2][430/3416]	Time 0.054 (0.058)	Data 0.00084 (0.00092)	Tok/s 51696 (53624)	Loss/tok 3.0089 (3.1265)	Learning Rate [0.00015625]
3: TRAIN [2][430/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00093)	Tok/s 50573 (52612)	Loss/tok 3.0045 (3.1201)	Learning Rate [0.00015625]
2: TRAIN [2][430/3416]	Time 0.054 (0.058)	Data 0.00104 (0.00099)	Tok/s 50520 (52508)	Loss/tok 3.0325 (3.1157)	Learning Rate [0.00015625]
12: TRAIN [2][430/3416]	Time 0.054 (0.058)	Data 0.00117 (0.00105)	Tok/s 51929 (53379)	Loss/tok 3.1483 (3.1291)	Learning Rate [0.00015625]
11: TRAIN [2][430/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00091)	Tok/s 51618 (53267)	Loss/tok 3.0521 (3.1291)	Learning Rate [0.00015625]
13: TRAIN [2][430/3416]	Time 0.054 (0.058)	Data 0.00106 (0.00098)	Tok/s 51683 (53495)	Loss/tok 3.0688 (3.1187)	Learning Rate [0.00015625]
6: TRAIN [2][430/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00094)	Tok/s 51625 (52886)	Loss/tok 2.9977 (3.1312)	Learning Rate [0.00015625]
4: TRAIN [2][430/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00099)	Tok/s 50431 (52712)	Loss/tok 2.9195 (3.1145)	Learning Rate [0.00015625]
5: TRAIN [2][430/3416]	Time 0.055 (0.058)	Data 0.00084 (0.00092)	Tok/s 51182 (52795)	Loss/tok 3.1631 (3.1186)	Learning Rate [0.00015625]
9: TRAIN [2][430/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00091)	Tok/s 51599 (53097)	Loss/tok 3.0550 (3.1161)	Learning Rate [0.00015625]
10: TRAIN [2][430/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00095)	Tok/s 51601 (53181)	Loss/tok 2.8450 (3.1187)	Learning Rate [0.00015625]
1: TRAIN [2][430/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00102)	Tok/s 50269 (52391)	Loss/tok 2.7822 (3.1146)	Learning Rate [0.00015625]
8: TRAIN [2][430/3416]	Time 0.055 (0.058)	Data 0.00110 (0.00098)	Tok/s 51578 (53045)	Loss/tok 2.9881 (3.1184)	Learning Rate [0.00015625]
7: TRAIN [2][430/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00097)	Tok/s 51578 (52977)	Loss/tok 3.1583 (3.1196)	Learning Rate [0.00015625]
0: TRAIN [2][440/3416]	Time 0.054 (0.058)	Data 0.00094 (0.00099)	Tok/s 50548 (52251)	Loss/tok 3.2506 (3.1419)	Learning Rate [0.00015625]
2: TRAIN [2][440/3416]	Time 0.054 (0.058)	Data 0.00102 (0.00099)	Tok/s 50606 (52453)	Loss/tok 2.9322 (3.1150)	Learning Rate [0.00015625]
4: TRAIN [2][440/3416]	Time 0.054 (0.058)	Data 0.00103 (0.00099)	Tok/s 50671 (52655)	Loss/tok 3.3538 (3.1151)	Learning Rate [0.00015625]
14: TRAIN [2][440/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00092)	Tok/s 50452 (53564)	Loss/tok 3.0394 (3.1251)	Learning Rate [0.00015625]
3: TRAIN [2][440/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00093)	Tok/s 50644 (52555)	Loss/tok 3.0903 (3.1178)	Learning Rate [0.00015625]
5: TRAIN [2][440/3416]	Time 0.054 (0.058)	Data 0.00100 (0.00092)	Tok/s 50682 (52738)	Loss/tok 3.1226 (3.1172)	Learning Rate [0.00015625]
6: TRAIN [2][440/3416]	Time 0.054 (0.058)	Data 0.00099 (0.00094)	Tok/s 50720 (52832)	Loss/tok 3.0477 (3.1276)	Learning Rate [0.00015625]
1: TRAIN [2][440/3416]	Time 0.054 (0.058)	Data 0.00137 (0.00102)	Tok/s 50585 (52339)	Loss/tok 3.0775 (3.1130)	Learning Rate [0.00015625]
13: TRAIN [2][440/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00098)	Tok/s 50445 (53437)	Loss/tok 3.1836 (3.1181)	Learning Rate [0.00015625]
11: TRAIN [2][440/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00091)	Tok/s 50474 (53211)	Loss/tok 3.1296 (3.1275)	Learning Rate [0.00015625]
12: TRAIN [2][440/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00105)	Tok/s 50473 (53323)	Loss/tok 2.9510 (3.1266)	Learning Rate [0.00015625]
7: TRAIN [2][440/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00097)	Tok/s 50584 (52924)	Loss/tok 3.1185 (3.1181)	Learning Rate [0.00015625]
9: TRAIN [2][440/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00091)	Tok/s 50499 (53041)	Loss/tok 2.9431 (3.1140)	Learning Rate [0.00015625]
8: TRAIN [2][440/3416]	Time 0.054 (0.058)	Data 0.00102 (0.00098)	Tok/s 50514 (52991)	Loss/tok 3.1278 (3.1175)	Learning Rate [0.00015625]
10: TRAIN [2][440/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00095)	Tok/s 50482 (53125)	Loss/tok 3.0443 (3.1167)	Learning Rate [0.00015625]
15: TRAIN [2][440/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00092)	Tok/s 49923 (53685)	Loss/tok 3.0388 (3.1245)	Learning Rate [0.00015625]
11: TRAIN [2][450/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00091)	Tok/s 67234 (53136)	Loss/tok 3.2457 (3.1264)	Learning Rate [0.00015625]
8: TRAIN [2][450/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 67125 (52917)	Loss/tok 3.1223 (3.1176)	Learning Rate [0.00015625]
10: TRAIN [2][450/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00095)	Tok/s 67266 (53052)	Loss/tok 3.0039 (3.1150)	Learning Rate [0.00015625]
12: TRAIN [2][450/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00105)	Tok/s 67147 (53248)	Loss/tok 3.2929 (3.1260)	Learning Rate [0.00015625]
9: TRAIN [2][450/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 67242 (52970)	Loss/tok 3.3587 (3.1134)	Learning Rate [0.00015625]
13: TRAIN [2][450/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 67024 (53361)	Loss/tok 3.3344 (3.1175)	Learning Rate [0.00015625]
14: TRAIN [2][450/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 66927 (53488)	Loss/tok 3.2468 (3.1258)	Learning Rate [0.00015625]
7: TRAIN [2][450/3416]	Time 0.069 (0.058)	Data 0.00114 (0.00097)	Tok/s 66350 (52848)	Loss/tok 3.3064 (3.1178)	Learning Rate [0.00015625]
15: TRAIN [2][450/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00091)	Tok/s 66913 (53610)	Loss/tok 3.2443 (3.1233)	Learning Rate [0.00015625]
0: TRAIN [2][450/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00099)	Tok/s 66047 (52181)	Loss/tok 3.1066 (3.1396)	Learning Rate [0.00015625]
1: TRAIN [2][450/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00102)	Tok/s 66032 (52270)	Loss/tok 3.3128 (3.1131)	Learning Rate [0.00015625]
5: TRAIN [2][450/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 66284 (52662)	Loss/tok 3.0544 (3.1164)	Learning Rate [0.00015625]
4: TRAIN [2][450/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00099)	Tok/s 66139 (52581)	Loss/tok 3.3372 (3.1150)	Learning Rate [0.00015625]
2: TRAIN [2][450/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 66022 (52384)	Loss/tok 3.2201 (3.1138)	Learning Rate [0.00015625]
6: TRAIN [2][450/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00094)	Tok/s 66296 (52755)	Loss/tok 3.4297 (3.1276)	Learning Rate [0.00015625]
3: TRAIN [2][450/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 66035 (52484)	Loss/tok 3.4327 (3.1184)	Learning Rate [0.00015625]
11: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00091)	Tok/s 84463 (53052)	Loss/tok 3.1263 (3.1235)	Learning Rate [0.00015625]
9: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 83621 (52883)	Loss/tok 3.2844 (3.1118)	Learning Rate [0.00015625]
10: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00095)	Tok/s 84280 (52968)	Loss/tok 3.2275 (3.1123)	Learning Rate [0.00015625]
2: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00099)	Tok/s 82730 (52291)	Loss/tok 3.1120 (3.1119)	Learning Rate [0.00015625]
1: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00102)	Tok/s 82656 (52178)	Loss/tok 2.9799 (3.1104)	Learning Rate [0.00015625]
8: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 83743 (52831)	Loss/tok 3.2329 (3.1149)	Learning Rate [0.00015625]
0: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00099)	Tok/s 82520 (52090)	Loss/tok 3.0106 (3.1363)	Learning Rate [0.00015625]
4: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00099)	Tok/s 83158 (52491)	Loss/tok 3.1260 (3.1123)	Learning Rate [0.00015625]
13: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 84243 (53276)	Loss/tok 3.1627 (3.1145)	Learning Rate [0.00015625]
7: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 83704 (52764)	Loss/tok 2.8452 (3.1146)	Learning Rate [0.00015625]
5: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00093)	Tok/s 83661 (52581)	Loss/tok 2.7686 (3.1132)	Learning Rate [0.00015625]
14: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00092)	Tok/s 84114 (53400)	Loss/tok 2.8604 (3.1210)	Learning Rate [0.00015625]
12: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00105)	Tok/s 84448 (53164)	Loss/tok 3.0524 (3.1221)	Learning Rate [0.00015625]
6: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00094)	Tok/s 83535 (52673)	Loss/tok 3.1498 (3.1251)	Learning Rate [0.00015625]
3: TRAIN [2][460/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 82579 (52392)	Loss/tok 3.1983 (3.1164)	Learning Rate [0.00015625]
15: TRAIN [2][460/3416]	Time 0.071 (0.058)	Data 0.00080 (0.00091)	Tok/s 84341 (53523)	Loss/tok 2.9891 (3.1203)	Learning Rate [0.00015625]
12: TRAIN [2][470/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00105)	Tok/s 74518 (53157)	Loss/tok 3.0879 (3.1234)	Learning Rate [0.00015625]
11: TRAIN [2][470/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00091)	Tok/s 74484 (53047)	Loss/tok 3.2310 (3.1247)	Learning Rate [0.00015625]
13: TRAIN [2][470/3416]	Time 0.070 (0.058)	Data 0.00115 (0.00098)	Tok/s 74425 (53266)	Loss/tok 3.1320 (3.1124)	Learning Rate [0.00015625]
10: TRAIN [2][470/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00095)	Tok/s 74469 (52965)	Loss/tok 2.9443 (3.1115)	Learning Rate [0.00015625]
15: TRAIN [2][470/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00091)	Tok/s 75556 (53517)	Loss/tok 3.1423 (3.1203)	Learning Rate [0.00015625]
14: TRAIN [2][470/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 74604 (53389)	Loss/tok 3.2642 (3.1210)	Learning Rate [0.00015625]
9: TRAIN [2][470/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00091)	Tok/s 74447 (52881)	Loss/tok 3.2425 (3.1118)	Learning Rate [0.00015625]
0: TRAIN [2][470/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00099)	Tok/s 73682 (52089)	Loss/tok 3.0514 (3.1366)	Learning Rate [0.00015625]
8: TRAIN [2][470/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00098)	Tok/s 74466 (52827)	Loss/tok 3.1641 (3.1154)	Learning Rate [0.00015625]
1: TRAIN [2][470/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00102)	Tok/s 73672 (52175)	Loss/tok 3.1499 (3.1117)	Learning Rate [0.00015625]
7: TRAIN [2][470/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 74458 (52758)	Loss/tok 3.0405 (3.1158)	Learning Rate [0.00015625]
6: TRAIN [2][470/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00094)	Tok/s 74465 (52668)	Loss/tok 3.3247 (3.1254)	Learning Rate [0.00015625]
4: TRAIN [2][470/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00098)	Tok/s 73468 (52488)	Loss/tok 3.2056 (3.1151)	Learning Rate [0.00015625]
2: TRAIN [2][470/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00099)	Tok/s 73680 (52287)	Loss/tok 3.1255 (3.1115)	Learning Rate [0.00015625]
5: TRAIN [2][470/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 74211 (52578)	Loss/tok 3.0034 (3.1142)	Learning Rate [0.00015625]
3: TRAIN [2][470/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 73572 (52387)	Loss/tok 3.4030 (3.1170)	Learning Rate [0.00015625]
11: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00091)	Tok/s 52064 (53147)	Loss/tok 3.2197 (3.1281)	Learning Rate [0.00015625]
12: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00107 (0.00105)	Tok/s 52033 (53256)	Loss/tok 3.0601 (3.1245)	Learning Rate [0.00015625]
13: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00107 (0.00098)	Tok/s 52054 (53366)	Loss/tok 3.0748 (3.1134)	Learning Rate [0.00015625]
9: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00091)	Tok/s 52097 (52982)	Loss/tok 3.3276 (3.1142)	Learning Rate [0.00015625]
10: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00095)	Tok/s 52073 (53064)	Loss/tok 3.0433 (3.1116)	Learning Rate [0.00015625]
8: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00107 (0.00098)	Tok/s 52072 (52929)	Loss/tok 2.9888 (3.1144)	Learning Rate [0.00015625]
14: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00092)	Tok/s 52024 (53489)	Loss/tok 2.9912 (3.1220)	Learning Rate [0.00015625]
6: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00094)	Tok/s 52135 (52773)	Loss/tok 3.2707 (3.1278)	Learning Rate [0.00015625]
15: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00091)	Tok/s 52398 (53622)	Loss/tok 3.0501 (3.1210)	Learning Rate [0.00015625]
3: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00100 (0.00092)	Tok/s 52186 (52495)	Loss/tok 3.2461 (3.1180)	Learning Rate [0.00015625]
7: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00097)	Tok/s 52064 (52862)	Loss/tok 3.1000 (3.1145)	Learning Rate [0.00015625]
2: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00106 (0.00099)	Tok/s 52139 (52396)	Loss/tok 3.3139 (3.1143)	Learning Rate [0.00015625]
4: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00098)	Tok/s 52110 (52593)	Loss/tok 2.9403 (3.1163)	Learning Rate [0.00015625]
1: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00112 (0.00102)	Tok/s 52021 (52286)	Loss/tok 2.8894 (3.1125)	Learning Rate [0.00015625]
0: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00099)	Tok/s 51999 (52201)	Loss/tok 3.1691 (3.1371)	Learning Rate [0.00015625]
5: TRAIN [2][480/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00093)	Tok/s 52126 (52682)	Loss/tok 3.2140 (3.1155)	Learning Rate [0.00015625]
2: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00099)	Tok/s 80737 (52376)	Loss/tok 3.1652 (3.1130)	Learning Rate [0.00015625]
3: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 80618 (52474)	Loss/tok 2.9392 (3.1160)	Learning Rate [0.00015625]
4: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 80511 (52572)	Loss/tok 2.9670 (3.1165)	Learning Rate [0.00015625]
1: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00102)	Tok/s 79820 (52266)	Loss/tok 2.9905 (3.1116)	Learning Rate [0.00015625]
6: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00094)	Tok/s 80603 (52753)	Loss/tok 3.3085 (3.1279)	Learning Rate [0.00015625]
11: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00091)	Tok/s 81850 (53129)	Loss/tok 3.0368 (3.1270)	Learning Rate [0.00015625]
5: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 80532 (52659)	Loss/tok 3.1077 (3.1146)	Learning Rate [0.00015625]
13: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 81907 (53343)	Loss/tok 2.9123 (3.1122)	Learning Rate [0.00015625]
14: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00091)	Tok/s 81746 (53465)	Loss/tok 3.0156 (3.1214)	Learning Rate [0.00015625]
15: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00091)	Tok/s 82414 (53601)	Loss/tok 3.1584 (3.1215)	Learning Rate [0.00015625]
10: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00095)	Tok/s 81804 (53048)	Loss/tok 2.9697 (3.1114)	Learning Rate [0.00015625]
12: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00104)	Tok/s 81850 (53236)	Loss/tok 3.0036 (3.1233)	Learning Rate [0.00015625]
9: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00091)	Tok/s 81613 (52964)	Loss/tok 3.2408 (3.1155)	Learning Rate [0.00015625]
7: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 80608 (52841)	Loss/tok 2.9793 (3.1141)	Learning Rate [0.00015625]
0: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00099)	Tok/s 79820 (52183)	Loss/tok 3.0115 (3.1361)	Learning Rate [0.00015625]
8: TRAIN [2][490/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 80768 (52907)	Loss/tok 2.9382 (3.1133)	Learning Rate [0.00015625]
3: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00092)	Tok/s 50268 (52570)	Loss/tok 2.9624 (3.1154)	Learning Rate [0.00015625]
4: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00098)	Tok/s 50182 (52666)	Loss/tok 2.9384 (3.1166)	Learning Rate [0.00015625]
2: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00099)	Tok/s 49672 (52471)	Loss/tok 2.9306 (3.1150)	Learning Rate [0.00015625]
1: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00102)	Tok/s 48958 (52362)	Loss/tok 3.0265 (3.1120)	Learning Rate [0.00015625]
5: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00093)	Tok/s 50183 (52752)	Loss/tok 3.0788 (3.1156)	Learning Rate [0.00015625]
0: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00099)	Tok/s 48955 (52278)	Loss/tok 3.1081 (3.1356)	Learning Rate [0.00015625]
6: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00094)	Tok/s 50170 (52843)	Loss/tok 3.0053 (3.1285)	Learning Rate [0.00015625]
15: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00091)	Tok/s 50256 (53684)	Loss/tok 2.7786 (3.1201)	Learning Rate [0.00015625]
14: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00091)	Tok/s 50252 (53548)	Loss/tok 2.8112 (3.1209)	Learning Rate [0.00015625]
8: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00098)	Tok/s 50169 (52995)	Loss/tok 3.1164 (3.1133)	Learning Rate [0.00015625]
7: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00097)	Tok/s 50166 (52930)	Loss/tok 2.9947 (3.1143)	Learning Rate [0.00015625]
9: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00080 (0.00091)	Tok/s 50181 (53053)	Loss/tok 3.0769 (3.1152)	Learning Rate [0.00015625]
11: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00091)	Tok/s 50239 (53217)	Loss/tok 3.3252 (3.1258)	Learning Rate [0.00015625]
13: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00098)	Tok/s 50270 (53428)	Loss/tok 2.8995 (3.1133)	Learning Rate [0.00015625]
12: TRAIN [2][500/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00105)	Tok/s 50272 (53323)	Loss/tok 2.8168 (3.1235)	Learning Rate [0.00015625]
10: TRAIN [2][500/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00095)	Tok/s 50140 (53136)	Loss/tok 3.1159 (3.1113)	Learning Rate [0.00015625]
6: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00094)	Tok/s 52401 (52984)	Loss/tok 3.0339 (3.1289)	Learning Rate [0.00015625]
8: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00098)	Tok/s 52518 (53136)	Loss/tok 3.2456 (3.1144)	Learning Rate [0.00015625]
7: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00097)	Tok/s 52485 (53072)	Loss/tok 3.3694 (3.1154)	Learning Rate [0.00015625]
9: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00091)	Tok/s 52515 (53194)	Loss/tok 3.1509 (3.1162)	Learning Rate [0.00015625]
5: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00093)	Tok/s 52221 (52892)	Loss/tok 3.0467 (3.1172)	Learning Rate [0.00015625]
4: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00098)	Tok/s 52127 (52806)	Loss/tok 3.0349 (3.1183)	Learning Rate [0.00015625]
3: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00092)	Tok/s 51973 (52712)	Loss/tok 3.1364 (3.1168)	Learning Rate [0.00015625]
10: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00095)	Tok/s 52394 (53277)	Loss/tok 3.1858 (3.1117)	Learning Rate [0.00015625]
11: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00091)	Tok/s 52525 (53357)	Loss/tok 3.1305 (3.1248)	Learning Rate [0.00015625]
2: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00099)	Tok/s 51893 (52612)	Loss/tok 3.2727 (3.1164)	Learning Rate [0.00015625]
1: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00101)	Tok/s 51892 (52502)	Loss/tok 3.0987 (3.1138)	Learning Rate [0.00015625]
12: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00105)	Tok/s 53610 (53464)	Loss/tok 2.9382 (3.1236)	Learning Rate [0.00015625]
0: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00099)	Tok/s 51898 (52420)	Loss/tok 3.2663 (3.1365)	Learning Rate [0.00015625]
13: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00111 (0.00098)	Tok/s 53351 (53568)	Loss/tok 3.1809 (3.1136)	Learning Rate [0.00015625]
15: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00081 (0.00091)	Tok/s 53191 (53829)	Loss/tok 3.0777 (3.1203)	Learning Rate [0.00015625]
14: TRAIN [2][510/3416]	Time 0.049 (0.058)	Data 0.00083 (0.00091)	Tok/s 53251 (53690)	Loss/tok 3.0851 (3.1206)	Learning Rate [0.00015625]
11: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00091)	Tok/s 31337 (53250)	Loss/tok 2.7317 (3.1238)	Learning Rate [0.00015625]
13: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00098)	Tok/s 31481 (53462)	Loss/tok 2.6467 (3.1145)	Learning Rate [0.00015625]
14: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00092)	Tok/s 32147 (53583)	Loss/tok 2.6069 (3.1208)	Learning Rate [0.00015625]
12: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00105)	Tok/s 31399 (53359)	Loss/tok 2.7418 (3.1219)	Learning Rate [0.00015625]
9: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00091)	Tok/s 31177 (53087)	Loss/tok 2.6686 (3.1157)	Learning Rate [0.00015625]
10: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00095)	Tok/s 31233 (53169)	Loss/tok 2.6537 (3.1106)	Learning Rate [0.00015625]
15: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00091)	Tok/s 32741 (53724)	Loss/tok 2.8080 (3.1188)	Learning Rate [0.00015625]
8: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00098)	Tok/s 31106 (53029)	Loss/tok 2.8220 (3.1145)	Learning Rate [0.00015625]
0: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00099)	Tok/s 29900 (52289)	Loss/tok 2.5617 (3.1359)	Learning Rate [0.00015625]
6: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00094)	Tok/s 31002 (52874)	Loss/tok 2.7077 (3.1271)	Learning Rate [0.00015625]
1: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00101)	Tok/s 30467 (52378)	Loss/tok 2.6793 (3.1128)	Learning Rate [0.00015625]
7: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00097)	Tok/s 31017 (52963)	Loss/tok 2.8089 (3.1155)	Learning Rate [0.00015625]
2: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00099)	Tok/s 31145 (52496)	Loss/tok 2.7725 (3.1155)	Learning Rate [0.00015625]
5: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00127 (0.00093)	Tok/s 31059 (52781)	Loss/tok 2.6703 (3.1165)	Learning Rate [0.00015625]
4: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00098)	Tok/s 31050 (52691)	Loss/tok 2.7993 (3.1175)	Learning Rate [0.00015625]
3: TRAIN [2][520/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00092)	Tok/s 31093 (52596)	Loss/tok 2.7032 (3.1163)	Learning Rate [0.00015625]
9: TRAIN [2][530/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00092)	Tok/s 52487 (53084)	Loss/tok 3.2649 (3.1149)	Learning Rate [0.00015625]
8: TRAIN [2][530/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 52455 (53026)	Loss/tok 2.9871 (3.1149)	Learning Rate [0.00015625]
10: TRAIN [2][530/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00095)	Tok/s 52208 (53168)	Loss/tok 2.8832 (3.1096)	Learning Rate [0.00015625]
7: TRAIN [2][530/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 52426 (52959)	Loss/tok 2.9683 (3.1154)	Learning Rate [0.00015625]
11: TRAIN [2][530/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00091)	Tok/s 52105 (53248)	Loss/tok 3.4762 (3.1248)	Learning Rate [0.00015625]
6: TRAIN [2][530/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00094)	Tok/s 52325 (52870)	Loss/tok 3.0098 (3.1258)	Learning Rate [0.00015625]
5: TRAIN [2][530/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00093)	Tok/s 52433 (52779)	Loss/tok 2.9357 (3.1157)	Learning Rate [0.00015625]
12: TRAIN [2][530/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00104)	Tok/s 52100 (53356)	Loss/tok 3.2561 (3.1230)	Learning Rate [0.00015625]
4: TRAIN [2][530/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00098)	Tok/s 52355 (52690)	Loss/tok 3.0002 (3.1176)	Learning Rate [0.00015625]
14: TRAIN [2][530/3416]	Time 0.053 (0.058)	Data 0.00081 (0.00091)	Tok/s 51998 (53576)	Loss/tok 2.8952 (3.1199)	Learning Rate [0.00015625]
13: TRAIN [2][530/3416]	Time 0.053 (0.058)	Data 0.00105 (0.00098)	Tok/s 51838 (53457)	Loss/tok 2.9038 (3.1135)	Learning Rate [0.00015625]
15: TRAIN [2][530/3416]	Time 0.053 (0.058)	Data 0.00080 (0.00091)	Tok/s 52017 (53717)	Loss/tok 3.2090 (3.1183)	Learning Rate [0.00015625]
2: TRAIN [2][530/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00099)	Tok/s 52146 (52495)	Loss/tok 3.1013 (3.1167)	Learning Rate [0.00015625]
1: TRAIN [2][530/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00101)	Tok/s 51935 (52380)	Loss/tok 2.8687 (3.1131)	Learning Rate [0.00015625]
3: TRAIN [2][530/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00092)	Tok/s 52157 (52594)	Loss/tok 3.1427 (3.1165)	Learning Rate [0.00015625]
0: TRAIN [2][530/3416]	Time 0.053 (0.058)	Data 0.00107 (0.00099)	Tok/s 51942 (52292)	Loss/tok 3.1265 (3.1361)	Learning Rate [0.00015625]
13: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
13: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00098)	Tok/s 79618 (53531)	Loss/tok 2.9063 (3.1128)	Learning Rate [0.00015625]
10: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
12: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00104)	Tok/s 79591 (53425)	Loss/tok 3.2672 (3.1247)	Learning Rate [0.00015625]
11: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 79254 (53318)	Loss/tok 3.1462 (3.1257)	Learning Rate [0.00015625]
14: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00091)	Tok/s 79438 (53649)	Loss/tok 2.9998 (3.1195)	Learning Rate [0.00015625]
7: Upscaling, new scale: 4096.0
1: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00101)	Tok/s 77596 (52461)	Loss/tok 3.1109 (3.1154)	Learning Rate [0.00015625]
0: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00099)	Tok/s 77544 (52374)	Loss/tok 2.9978 (3.1352)	Learning Rate [0.00015625]
15: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 79320 (53788)	Loss/tok 3.0932 (3.1190)	Learning Rate [0.00015625]
10: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00095)	Tok/s 78747 (53237)	Loss/tok 3.0612 (3.1099)	Learning Rate [0.00015625]
4: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
6: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00094)	Tok/s 78710 (52945)	Loss/tok 3.1619 (3.1280)	Learning Rate [0.00015625]
9: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00092)	Tok/s 78640 (53155)	Loss/tok 3.1335 (3.1166)	Learning Rate [0.00015625]
2: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00099)	Tok/s 77551 (52576)	Loss/tok 3.0658 (3.1161)	Learning Rate [0.00015625]
8: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 78681 (53098)	Loss/tok 3.0861 (3.1160)	Learning Rate [0.00015625]
7: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 78687 (53033)	Loss/tok 2.9999 (3.1147)	Learning Rate [0.00015625]
5: Upscaling, new scale: 4096.0
4: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 78138 (52768)	Loss/tok 3.2394 (3.1220)	Learning Rate [0.00015625]
3: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 77506 (52673)	Loss/tok 3.1420 (3.1159)	Learning Rate [0.00015625]
5: TRAIN [2][540/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00094)	Tok/s 78479 (52856)	Loss/tok 3.0796 (3.1171)	Learning Rate [0.00015625]
10: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00095)	Tok/s 56581 (53223)	Loss/tok 3.1217 (3.1112)	Learning Rate [0.00015625]
9: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00092)	Tok/s 56537 (53139)	Loss/tok 3.3028 (3.1170)	Learning Rate [0.00015625]
11: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00091)	Tok/s 56594 (53302)	Loss/tok 3.3261 (3.1266)	Learning Rate [0.00015625]
8: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00097)	Tok/s 56413 (53082)	Loss/tok 3.1291 (3.1161)	Learning Rate [0.00015625]
7: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00097)	Tok/s 56370 (53016)	Loss/tok 3.1076 (3.1147)	Learning Rate [0.00015625]
6: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00093)	Tok/s 56245 (52931)	Loss/tok 3.2576 (3.1287)	Learning Rate [0.00015625]
12: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00104)	Tok/s 56588 (53407)	Loss/tok 2.9891 (3.1252)	Learning Rate [0.00015625]
13: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00098)	Tok/s 56587 (53511)	Loss/tok 3.2384 (3.1141)	Learning Rate [0.00015625]
5: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00094)	Tok/s 56134 (52838)	Loss/tok 3.2381 (3.1187)	Learning Rate [0.00015625]
4: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00098)	Tok/s 56076 (52750)	Loss/tok 3.0591 (3.1218)	Learning Rate [0.00015625]
14: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00091)	Tok/s 56338 (53629)	Loss/tok 3.3169 (3.1203)	Learning Rate [0.00015625]
3: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00092)	Tok/s 56115 (52657)	Loss/tok 3.2269 (3.1162)	Learning Rate [0.00015625]
15: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00091)	Tok/s 56280 (53767)	Loss/tok 3.2772 (3.1199)	Learning Rate [0.00015625]
1: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00101)	Tok/s 56159 (52446)	Loss/tok 3.5087 (3.1175)	Learning Rate [0.00015625]
0: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00098)	Tok/s 55257 (52359)	Loss/tok 3.1852 (3.1345)	Learning Rate [0.00015625]
2: TRAIN [2][550/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00099)	Tok/s 56141 (52561)	Loss/tok 3.2594 (3.1157)	Learning Rate [0.00015625]
11: TRAIN [2][560/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00091)	Tok/s 37723 (53336)	Loss/tok 2.9792 (3.1263)	Learning Rate [0.00015625]
9: TRAIN [2][560/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00092)	Tok/s 37682 (53175)	Loss/tok 2.9278 (3.1190)	Learning Rate [0.00015625]
10: TRAIN [2][560/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00095)	Tok/s 37755 (53258)	Loss/tok 2.8012 (3.1123)	Learning Rate [0.00015625]
8: TRAIN [2][560/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00097)	Tok/s 37588 (53117)	Loss/tok 2.9808 (3.1162)	Learning Rate [0.00015625]
12: TRAIN [2][560/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00104)	Tok/s 37703 (53439)	Loss/tok 3.0852 (3.1262)	Learning Rate [0.00015625]
7: TRAIN [2][560/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00097)	Tok/s 37482 (53050)	Loss/tok 2.9662 (3.1153)	Learning Rate [0.00015625]
6: TRAIN [2][560/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00093)	Tok/s 37416 (52963)	Loss/tok 2.7938 (3.1301)	Learning Rate [0.00015625]
13: TRAIN [2][560/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00098)	Tok/s 37603 (53542)	Loss/tok 2.9535 (3.1151)	Learning Rate [0.00015625]
14: TRAIN [2][560/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00091)	Tok/s 37540 (53659)	Loss/tok 2.7907 (3.1213)	Learning Rate [0.00015625]
5: TRAIN [2][560/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00094)	Tok/s 37327 (52872)	Loss/tok 2.8886 (3.1199)	Learning Rate [0.00015625]
4: TRAIN [2][560/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00098)	Tok/s 37222 (52784)	Loss/tok 2.8782 (3.1237)	Learning Rate [0.00015625]
15: TRAIN [2][560/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00091)	Tok/s 37446 (53795)	Loss/tok 3.0993 (3.1209)	Learning Rate [0.00015625]
0: TRAIN [2][560/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00098)	Tok/s 36129 (52391)	Loss/tok 3.0095 (3.1335)	Learning Rate [0.00015625]
3: TRAIN [2][560/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 36179 (52690)	Loss/tok 2.9280 (3.1187)	Learning Rate [0.00015625]
1: TRAIN [2][560/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00101)	Tok/s 36049 (52480)	Loss/tok 2.9719 (3.1172)	Learning Rate [0.00015625]
2: TRAIN [2][560/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00099)	Tok/s 35995 (52594)	Loss/tok 3.0168 (3.1167)	Learning Rate [0.00015625]
4: TRAIN [2][570/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00098)	Tok/s 31678 (52703)	Loss/tok 2.7399 (3.1227)	Learning Rate [0.00015625]
1: TRAIN [2][570/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00101)	Tok/s 31600 (52399)	Loss/tok 2.7385 (3.1162)	Learning Rate [0.00015625]
0: TRAIN [2][570/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00098)	Tok/s 31571 (52310)	Loss/tok 2.6381 (3.1318)	Learning Rate [0.00015625]
8: TRAIN [2][570/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00097)	Tok/s 31708 (53034)	Loss/tok 2.6807 (3.1150)	Learning Rate [0.00015625]
7: TRAIN [2][570/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00097)	Tok/s 31696 (52968)	Loss/tok 2.6409 (3.1138)	Learning Rate [0.00015625]
6: TRAIN [2][570/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00093)	Tok/s 31634 (52881)	Loss/tok 2.8488 (3.1292)	Learning Rate [0.00015625]
15: TRAIN [2][570/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00091)	Tok/s 32952 (53706)	Loss/tok 3.1530 (3.1192)	Learning Rate [0.00015625]
9: TRAIN [2][570/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00092)	Tok/s 31694 (53091)	Loss/tok 2.5976 (3.1169)	Learning Rate [0.00015625]
5: TRAIN [2][570/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00094)	Tok/s 31576 (52790)	Loss/tok 2.7462 (3.1208)	Learning Rate [0.00015625]
14: TRAIN [2][570/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00091)	Tok/s 32953 (53573)	Loss/tok 2.6486 (3.1207)	Learning Rate [0.00015625]
11: TRAIN [2][570/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00091)	Tok/s 33009 (53251)	Loss/tok 2.5930 (3.1252)	Learning Rate [0.00015625]
13: TRAIN [2][570/3416]	Time 0.047 (0.058)	Data 0.00110 (0.00098)	Tok/s 32971 (53456)	Loss/tok 2.8228 (3.1151)	Learning Rate [0.00015625]
10: TRAIN [2][570/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00095)	Tok/s 33053 (53174)	Loss/tok 2.9052 (3.1119)	Learning Rate [0.00015625]
2: TRAIN [2][570/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00099)	Tok/s 31514 (52515)	Loss/tok 2.8177 (3.1163)	Learning Rate [0.00015625]
12: TRAIN [2][570/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00104)	Tok/s 32997 (53354)	Loss/tok 2.5357 (3.1250)	Learning Rate [0.00015625]
3: TRAIN [2][570/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00092)	Tok/s 31064 (52608)	Loss/tok 2.6811 (3.1185)	Learning Rate [0.00015625]
9: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00092)	Tok/s 51301 (53023)	Loss/tok 2.9597 (3.1157)	Learning Rate [0.00015625]
11: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00091)	Tok/s 51200 (53183)	Loss/tok 3.1831 (3.1240)	Learning Rate [0.00015625]
10: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00095)	Tok/s 51283 (53107)	Loss/tok 3.0302 (3.1124)	Learning Rate [0.00015625]
8: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00097)	Tok/s 51277 (52965)	Loss/tok 3.0698 (3.1143)	Learning Rate [0.00015625]
12: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00109 (0.00104)	Tok/s 51108 (53285)	Loss/tok 3.2312 (3.1248)	Learning Rate [0.00015625]
7: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00097)	Tok/s 51231 (52899)	Loss/tok 3.0567 (3.1135)	Learning Rate [0.00015625]
13: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00109 (0.00098)	Tok/s 51145 (53387)	Loss/tok 2.8407 (3.1139)	Learning Rate [0.00015625]
6: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 51154 (52813)	Loss/tok 3.3109 (3.1287)	Learning Rate [0.00015625]
14: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00091)	Tok/s 51180 (53505)	Loss/tok 3.0536 (3.1205)	Learning Rate [0.00015625]
15: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00091)	Tok/s 51165 (53637)	Loss/tok 3.0986 (3.1196)	Learning Rate [0.00015625]
5: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00094)	Tok/s 51127 (52723)	Loss/tok 3.0141 (3.1202)	Learning Rate [0.00015625]
0: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00098)	Tok/s 51161 (52249)	Loss/tok 3.0463 (3.1306)	Learning Rate [0.00015625]
4: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00098)	Tok/s 51131 (52637)	Loss/tok 3.1108 (3.1221)	Learning Rate [0.00015625]
3: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00092)	Tok/s 51113 (52545)	Loss/tok 3.3456 (3.1187)	Learning Rate [0.00015625]
1: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00101)	Tok/s 51186 (52337)	Loss/tok 3.0288 (3.1154)	Learning Rate [0.00015625]
2: TRAIN [2][580/3416]	Time 0.051 (0.058)	Data 0.00113 (0.00099)	Tok/s 51171 (52452)	Loss/tok 2.9285 (3.1165)	Learning Rate [0.00015625]
15: TRAIN [2][590/3416]	Time 0.065 (0.058)	Data 0.00103 (0.00091)	Tok/s 56675 (53674)	Loss/tok 3.4084 (3.1194)	Learning Rate [0.00015625]
0: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00110 (0.00098)	Tok/s 55653 (52287)	Loss/tok 3.0066 (3.1286)	Learning Rate [0.00015625]
1: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00107 (0.00101)	Tok/s 55656 (52373)	Loss/tok 3.3272 (3.1152)	Learning Rate [0.00015625]
2: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00112 (0.00099)	Tok/s 55658 (52489)	Loss/tok 3.1687 (3.1168)	Learning Rate [0.00015625]
14: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00104 (0.00091)	Tok/s 55511 (53541)	Loss/tok 3.1006 (3.1208)	Learning Rate [0.00015625]
13: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00118 (0.00098)	Tok/s 55371 (53423)	Loss/tok 3.2254 (3.1137)	Learning Rate [0.00015625]
4: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00112 (0.00098)	Tok/s 55511 (52674)	Loss/tok 3.4596 (3.1226)	Learning Rate [0.00015625]
12: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00104)	Tok/s 55312 (53323)	Loss/tok 3.1777 (3.1238)	Learning Rate [0.00015625]
11: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00111 (0.00091)	Tok/s 55227 (53219)	Loss/tok 3.1407 (3.1241)	Learning Rate [0.00015625]
5: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00107 (0.00094)	Tok/s 55479 (52758)	Loss/tok 3.0292 (3.1193)	Learning Rate [0.00015625]
3: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00092)	Tok/s 55615 (52583)	Loss/tok 3.1387 (3.1180)	Learning Rate [0.00015625]
6: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00107 (0.00093)	Tok/s 55384 (52847)	Loss/tok 3.2396 (3.1288)	Learning Rate [0.00015625]
10: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00108 (0.00095)	Tok/s 55163 (53143)	Loss/tok 3.0224 (3.1121)	Learning Rate [0.00015625]
9: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00107 (0.00092)	Tok/s 55205 (53060)	Loss/tok 3.0355 (3.1153)	Learning Rate [0.00015625]
7: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00107 (0.00097)	Tok/s 55254 (52932)	Loss/tok 3.2409 (3.1149)	Learning Rate [0.00015625]
8: TRAIN [2][590/3416]	Time 0.066 (0.058)	Data 0.00105 (0.00097)	Tok/s 55203 (53001)	Loss/tok 3.2025 (3.1158)	Learning Rate [0.00015625]
4: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00098)	Tok/s 52094 (52680)	Loss/tok 3.1452 (3.1237)	Learning Rate [0.00015625]
2: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00099)	Tok/s 51968 (52496)	Loss/tok 3.1947 (3.1177)	Learning Rate [0.00015625]
5: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00094)	Tok/s 52604 (52765)	Loss/tok 3.1812 (3.1193)	Learning Rate [0.00015625]
3: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00092)	Tok/s 52005 (52590)	Loss/tok 3.0473 (3.1181)	Learning Rate [0.00015625]
6: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00093)	Tok/s 53158 (52857)	Loss/tok 3.1907 (3.1295)	Learning Rate [0.00015625]
1: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00101)	Tok/s 51796 (52380)	Loss/tok 3.0318 (3.1145)	Learning Rate [0.00015625]
7: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00097)	Tok/s 53184 (52944)	Loss/tok 3.2333 (3.1156)	Learning Rate [0.00015625]
0: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00098)	Tok/s 51799 (52295)	Loss/tok 3.0174 (3.1279)	Learning Rate [0.00015625]
8: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00098)	Tok/s 53207 (53012)	Loss/tok 3.3032 (3.1152)	Learning Rate [0.00015625]
15: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00091)	Tok/s 52892 (53684)	Loss/tok 3.1686 (3.1183)	Learning Rate [0.00015625]
9: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00092)	Tok/s 53122 (53070)	Loss/tok 3.1196 (3.1165)	Learning Rate [0.00015625]
14: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00082 (0.00092)	Tok/s 52882 (53552)	Loss/tok 3.3537 (3.1210)	Learning Rate [0.00015625]
10: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00104 (0.00095)	Tok/s 53043 (53154)	Loss/tok 3.2404 (3.1128)	Learning Rate [0.00015625]
13: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00098)	Tok/s 52866 (53435)	Loss/tok 3.2033 (3.1141)	Learning Rate [0.00015625]
11: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00091)	Tok/s 52944 (53231)	Loss/tok 3.2976 (3.1247)	Learning Rate [0.00015625]
12: TRAIN [2][600/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00104)	Tok/s 52903 (53335)	Loss/tok 3.4344 (3.1240)	Learning Rate [0.00015625]
0: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
2: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
5: Gradient norm: inf
14: Gradient norm: inf
3: Gradient norm: inf
4: Gradient norm: inf
2: Skipped batch, new scale: 2048.0
6: Gradient norm: inf
5: Skipped batch, new scale: 2048.0
14: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
4: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
13: Gradient norm: inf
6: Skipped batch, new scale: 2048.0
7: Gradient norm: inf
12: Gradient norm: inf
13: Skipped batch, new scale: 2048.0
15: Skipped batch, new scale: 2048.0
8: Gradient norm: inf
11: Gradient norm: inf
7: Skipped batch, new scale: 2048.0
12: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
9: Gradient norm: inf
8: Skipped batch, new scale: 2048.0
11: Skipped batch, new scale: 2048.0
10: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
2: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00099)	Tok/s 49300 (52552)	Loss/tok 2.8865 (3.1178)	Learning Rate [0.00015625]
1: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00101)	Tok/s 49174 (52435)	Loss/tok 2.9003 (3.1152)	Learning Rate [0.00015625]
3: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 49229 (52646)	Loss/tok 2.8845 (3.1177)	Learning Rate [0.00015625]
0: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00098)	Tok/s 49081 (52348)	Loss/tok 2.9735 (3.1276)	Learning Rate [0.00015625]
4: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00098)	Tok/s 49321 (52734)	Loss/tok 3.2317 (3.1236)	Learning Rate [0.00015625]
13: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00098)	Tok/s 50586 (53488)	Loss/tok 3.3576 (3.1146)	Learning Rate [0.00015625]
12: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00104)	Tok/s 50646 (53389)	Loss/tok 3.0586 (3.1229)	Learning Rate [0.00015625]
10: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00107 (0.00096)	Tok/s 50632 (53207)	Loss/tok 3.2378 (3.1114)	Learning Rate [0.00015625]
11: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00091)	Tok/s 50679 (53284)	Loss/tok 2.9683 (3.1238)	Learning Rate [0.00015625]
15: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00091)	Tok/s 50406 (53737)	Loss/tok 3.1329 (3.1175)	Learning Rate [0.00015625]
14: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 50472 (53606)	Loss/tok 3.0127 (3.1194)	Learning Rate [0.00015625]
5: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00094)	Tok/s 49293 (52818)	Loss/tok 3.3000 (3.1190)	Learning Rate [0.00015625]
6: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 49318 (52908)	Loss/tok 3.1499 (3.1288)	Learning Rate [0.00015625]
9: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00092)	Tok/s 50352 (53124)	Loss/tok 3.0999 (3.1162)	Learning Rate [0.00015625]
7: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00097)	Tok/s 49318 (52994)	Loss/tok 2.9760 (3.1152)	Learning Rate [0.00015625]
8: TRAIN [2][610/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00098)	Tok/s 49320 (53062)	Loss/tok 2.7733 (3.1145)	Learning Rate [0.00015625]
4: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00098)	Tok/s 50629 (52736)	Loss/tok 3.0831 (3.1230)	Learning Rate [0.00015625]
3: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00086 (0.00092)	Tok/s 50173 (52649)	Loss/tok 3.1285 (3.1185)	Learning Rate [0.00015625]
6: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00079 (0.00093)	Tok/s 51224 (52911)	Loss/tok 2.9853 (3.1281)	Learning Rate [0.00015625]
2: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00099)	Tok/s 50188 (52556)	Loss/tok 3.1687 (3.1181)	Learning Rate [0.00015625]
5: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00082 (0.00094)	Tok/s 51236 (52820)	Loss/tok 2.8604 (3.1185)	Learning Rate [0.00015625]
1: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00101)	Tok/s 50186 (52442)	Loss/tok 2.9985 (3.1152)	Learning Rate [0.00015625]
0: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00098)	Tok/s 50200 (52356)	Loss/tok 3.1287 (3.1282)	Learning Rate [0.00015625]
7: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00097)	Tok/s 51329 (52997)	Loss/tok 3.1090 (3.1155)	Learning Rate [0.00015625]
15: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00081 (0.00091)	Tok/s 51268 (53735)	Loss/tok 2.9619 (3.1188)	Learning Rate [0.00015625]
8: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00097)	Tok/s 51212 (53064)	Loss/tok 3.0674 (3.1155)	Learning Rate [0.00015625]
14: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00092)	Tok/s 51331 (53606)	Loss/tok 2.8539 (3.1204)	Learning Rate [0.00015625]
11: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00084 (0.00091)	Tok/s 51263 (53285)	Loss/tok 3.3417 (3.1265)	Learning Rate [0.00015625]
10: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00096)	Tok/s 51235 (53210)	Loss/tok 3.1762 (3.1117)	Learning Rate [0.00015625]
13: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00098)	Tok/s 51323 (53488)	Loss/tok 2.9517 (3.1158)	Learning Rate [0.00015625]
9: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00092)	Tok/s 51227 (53127)	Loss/tok 3.0311 (3.1165)	Learning Rate [0.00015625]
12: TRAIN [2][620/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00104)	Tok/s 51242 (53390)	Loss/tok 3.0102 (3.1238)	Learning Rate [0.00015625]
6: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 86721 (52939)	Loss/tok 3.1905 (3.1273)	Learning Rate [0.00015625]
7: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 87128 (53029)	Loss/tok 3.2038 (3.1154)	Learning Rate [0.00015625]
2: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00118 (0.00099)	Tok/s 85587 (52575)	Loss/tok 3.3839 (3.1185)	Learning Rate [0.00015625]
1: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00101)	Tok/s 85519 (52456)	Loss/tok 2.9759 (3.1134)	Learning Rate [0.00015625]
3: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 86298 (52668)	Loss/tok 2.9141 (3.1178)	Learning Rate [0.00015625]
0: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00098)	Tok/s 85505 (52366)	Loss/tok 2.9706 (3.1272)	Learning Rate [0.00015625]
9: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 87238 (53162)	Loss/tok 3.1920 (3.1170)	Learning Rate [0.00015625]
4: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 86299 (52758)	Loss/tok 2.9255 (3.1215)	Learning Rate [0.00015625]
8: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 87215 (53098)	Loss/tok 3.0399 (3.1146)	Learning Rate [0.00015625]
10: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00095)	Tok/s 88137 (53247)	Loss/tok 3.0697 (3.1118)	Learning Rate [0.00015625]
15: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00091)	Tok/s 90601 (53780)	Loss/tok 3.0512 (3.1179)	Learning Rate [0.00015625]
11: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00091)	Tok/s 88146 (53321)	Loss/tok 3.1494 (3.1254)	Learning Rate [0.00015625]
14: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 89978 (53649)	Loss/tok 3.0705 (3.1190)	Learning Rate [0.00015625]
13: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 89146 (53529)	Loss/tok 3.1107 (3.1152)	Learning Rate [0.00015625]
12: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00104)	Tok/s 88910 (53430)	Loss/tok 2.9868 (3.1224)	Learning Rate [0.00015625]
5: TRAIN [2][630/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00094)	Tok/s 86114 (52845)	Loss/tok 3.0345 (3.1187)	Learning Rate [0.00015625]
6: TRAIN [2][640/3416]	Time 0.044 (0.058)	Data 0.00103 (0.00093)	Tok/s 47784 (52965)	Loss/tok 2.7984 (3.1265)	Learning Rate [0.00015625]
7: TRAIN [2][640/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00097)	Tok/s 47811 (53054)	Loss/tok 2.8942 (3.1138)	Learning Rate [0.00015625]
5: TRAIN [2][640/3416]	Time 0.044 (0.058)	Data 0.00102 (0.00094)	Tok/s 48080 (52872)	Loss/tok 2.9172 (3.1180)	Learning Rate [0.00015625]
4: TRAIN [2][640/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00098)	Tok/s 47552 (52787)	Loss/tok 3.0591 (3.1217)	Learning Rate [0.00015625]
3: TRAIN [2][640/3416]	Time 0.045 (0.058)	Data 0.00112 (0.00092)	Tok/s 47433 (52696)	Loss/tok 2.9035 (3.1176)	Learning Rate [0.00015625]
8: TRAIN [2][640/3416]	Time 0.044 (0.058)	Data 0.00110 (0.00098)	Tok/s 47785 (53123)	Loss/tok 3.1327 (3.1153)	Learning Rate [0.00015625]
9: TRAIN [2][640/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00092)	Tok/s 47825 (53186)	Loss/tok 2.8839 (3.1158)	Learning Rate [0.00015625]
2: TRAIN [2][640/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00099)	Tok/s 47293 (52602)	Loss/tok 3.0613 (3.1166)	Learning Rate [0.00015625]
1: TRAIN [2][640/3416]	Time 0.045 (0.058)	Data 0.00105 (0.00101)	Tok/s 47300 (52486)	Loss/tok 2.8147 (3.1132)	Learning Rate [0.00015625]
11: TRAIN [2][640/3416]	Time 0.044 (0.058)	Data 0.00107 (0.00091)	Tok/s 47645 (53346)	Loss/tok 2.9654 (3.1259)	Learning Rate [0.00015625]
10: TRAIN [2][640/3416]	Time 0.044 (0.058)	Data 0.00110 (0.00096)	Tok/s 47728 (53270)	Loss/tok 3.2243 (3.1099)	Learning Rate [0.00015625]
0: TRAIN [2][640/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00098)	Tok/s 47320 (52394)	Loss/tok 2.8032 (3.1281)	Learning Rate [0.00015625]
15: TRAIN [2][640/3416]	Time 0.045 (0.058)	Data 0.00116 (0.00091)	Tok/s 47322 (53802)	Loss/tok 2.8259 (3.1172)	Learning Rate [0.00015625]
12: TRAIN [2][640/3416]	Time 0.044 (0.058)	Data 0.00113 (0.00104)	Tok/s 47516 (53455)	Loss/tok 2.9898 (3.1220)	Learning Rate [0.00015625]
14: TRAIN [2][640/3416]	Time 0.045 (0.058)	Data 0.00103 (0.00092)	Tok/s 47347 (53673)	Loss/tok 2.9938 (3.1209)	Learning Rate [0.00015625]
13: TRAIN [2][640/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00098)	Tok/s 47366 (53553)	Loss/tok 2.9146 (3.1138)	Learning Rate [0.00015625]
9: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 83617 (53297)	Loss/tok 2.9481 (3.1159)	Learning Rate [0.00015625]
0: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 82741 (52506)	Loss/tok 2.9732 (3.1286)	Learning Rate [0.00015625]
15: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00091)	Tok/s 84760 (53909)	Loss/tok 2.9763 (3.1180)	Learning Rate [0.00015625]
11: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 84558 (53459)	Loss/tok 3.0631 (3.1265)	Learning Rate [0.00015625]
10: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00096)	Tok/s 83627 (53380)	Loss/tok 3.2130 (3.1111)	Learning Rate [0.00015625]
8: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 83424 (53234)	Loss/tok 3.0662 (3.1159)	Learning Rate [0.00015625]
14: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 84680 (53781)	Loss/tok 3.0512 (3.1207)	Learning Rate [0.00015625]
1: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00100)	Tok/s 82519 (52598)	Loss/tok 3.1068 (3.1136)	Learning Rate [0.00015625]
7: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00097)	Tok/s 83316 (53165)	Loss/tok 3.0992 (3.1148)	Learning Rate [0.00015625]
6: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 83100 (53077)	Loss/tok 3.1558 (3.1279)	Learning Rate [0.00015625]
13: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 84621 (53663)	Loss/tok 3.2111 (3.1151)	Learning Rate [0.00015625]
2: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00099)	Tok/s 82499 (52714)	Loss/tok 3.0309 (3.1176)	Learning Rate [0.00015625]
12: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00103)	Tok/s 84541 (53567)	Loss/tok 2.8517 (3.1227)	Learning Rate [0.00015625]
4: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00098)	Tok/s 82260 (52897)	Loss/tok 2.9687 (3.1216)	Learning Rate [0.00015625]
5: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00094)	Tok/s 82797 (52983)	Loss/tok 3.1113 (3.1183)	Learning Rate [0.00015625]
3: TRAIN [2][650/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 82348 (52808)	Loss/tok 2.9773 (3.1187)	Learning Rate [0.00015625]
13: TRAIN [2][660/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00098)	Tok/s 54092 (53649)	Loss/tok 3.2346 (3.1144)	Learning Rate [0.00015625]
14: TRAIN [2][660/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 54009 (53766)	Loss/tok 3.1694 (3.1213)	Learning Rate [0.00015625]
11: TRAIN [2][660/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00092)	Tok/s 54086 (53446)	Loss/tok 3.3338 (3.1271)	Learning Rate [0.00015625]
15: TRAIN [2][660/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00091)	Tok/s 54003 (53892)	Loss/tok 3.2521 (3.1189)	Learning Rate [0.00015625]
12: TRAIN [2][660/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00103)	Tok/s 54076 (53554)	Loss/tok 3.1137 (3.1229)	Learning Rate [0.00015625]
9: TRAIN [2][660/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00092)	Tok/s 54089 (53285)	Loss/tok 3.5174 (3.1163)	Learning Rate [0.00015625]
0: TRAIN [2][660/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00098)	Tok/s 53047 (52495)	Loss/tok 3.3634 (3.1292)	Learning Rate [0.00015625]
10: TRAIN [2][660/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00096)	Tok/s 54026 (53366)	Loss/tok 3.2641 (3.1108)	Learning Rate [0.00015625]
1: TRAIN [2][660/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00100)	Tok/s 53050 (52586)	Loss/tok 3.2447 (3.1139)	Learning Rate [0.00015625]
8: TRAIN [2][660/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00098)	Tok/s 53294 (53222)	Loss/tok 2.9273 (3.1155)	Learning Rate [0.00015625]
2: TRAIN [2][660/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00099)	Tok/s 53065 (52701)	Loss/tok 3.0184 (3.1175)	Learning Rate [0.00015625]
6: TRAIN [2][660/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00093)	Tok/s 53133 (53064)	Loss/tok 3.2861 (3.1284)	Learning Rate [0.00015625]
7: TRAIN [2][660/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00097)	Tok/s 53157 (53152)	Loss/tok 3.1915 (3.1154)	Learning Rate [0.00015625]
3: TRAIN [2][660/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 53076 (52794)	Loss/tok 3.4593 (3.1200)	Learning Rate [0.00015625]
5: TRAIN [2][660/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00094)	Tok/s 53103 (52972)	Loss/tok 3.2493 (3.1179)	Learning Rate [0.00015625]
4: TRAIN [2][660/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00098)	Tok/s 53003 (52885)	Loss/tok 3.1996 (3.1228)	Learning Rate [0.00015625]
4: TRAIN [2][670/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00098)	Tok/s 69825 (52925)	Loss/tok 3.1155 (3.1229)	Learning Rate [0.00015625]
5: TRAIN [2][670/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00094)	Tok/s 69909 (53013)	Loss/tok 3.5100 (3.1193)	Learning Rate [0.00015625]
6: TRAIN [2][670/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 69856 (53104)	Loss/tok 3.4175 (3.1282)	Learning Rate [0.00015625]
7: TRAIN [2][670/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 70673 (53192)	Loss/tok 3.2305 (3.1158)	Learning Rate [0.00015625]
3: TRAIN [2][670/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 69736 (52832)	Loss/tok 3.3171 (3.1211)	Learning Rate [0.00015625]
8: TRAIN [2][670/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00097)	Tok/s 69953 (53260)	Loss/tok 3.1593 (3.1162)	Learning Rate [0.00015625]
2: TRAIN [2][670/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 69748 (52740)	Loss/tok 3.1984 (3.1173)	Learning Rate [0.00015625]
1: TRAIN [2][670/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00100)	Tok/s 69123 (52626)	Loss/tok 3.1910 (3.1135)	Learning Rate [0.00015625]
11: TRAIN [2][670/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 70045 (53485)	Loss/tok 3.0467 (3.1278)	Learning Rate [0.00015625]
9: TRAIN [2][670/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 69893 (53324)	Loss/tok 3.1956 (3.1171)	Learning Rate [0.00015625]
12: TRAIN [2][670/3416]	Time 0.069 (0.058)	Data 0.00141 (0.00103)	Tok/s 70133 (53591)	Loss/tok 3.1412 (3.1233)	Learning Rate [0.00015625]
13: TRAIN [2][670/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 70608 (53686)	Loss/tok 3.2290 (3.1150)	Learning Rate [0.00015625]
10: TRAIN [2][670/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 70070 (53406)	Loss/tok 3.1526 (3.1104)	Learning Rate [0.00015625]
0: TRAIN [2][670/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 68851 (52534)	Loss/tok 3.2661 (3.1306)	Learning Rate [0.00015625]
15: TRAIN [2][670/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 70743 (53929)	Loss/tok 3.1572 (3.1196)	Learning Rate [0.00015625]
14: TRAIN [2][670/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 70783 (53803)	Loss/tok 3.2084 (3.1212)	Learning Rate [0.00015625]
5: TRAIN [2][680/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00094)	Tok/s 31874 (53001)	Loss/tok 2.9894 (3.1208)	Learning Rate [0.00015625]
6: TRAIN [2][680/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00093)	Tok/s 31817 (53090)	Loss/tok 2.7152 (3.1285)	Learning Rate [0.00015625]
4: TRAIN [2][680/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00098)	Tok/s 31897 (52914)	Loss/tok 2.5967 (3.1222)	Learning Rate [0.00015625]
3: TRAIN [2][680/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00092)	Tok/s 31897 (52822)	Loss/tok 2.7910 (3.1218)	Learning Rate [0.00015625]
7: TRAIN [2][680/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00097)	Tok/s 31757 (53177)	Loss/tok 2.8522 (3.1160)	Learning Rate [0.00015625]
2: TRAIN [2][680/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00099)	Tok/s 31890 (52732)	Loss/tok 2.7507 (3.1175)	Learning Rate [0.00015625]
8: TRAIN [2][680/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00097)	Tok/s 31650 (53244)	Loss/tok 2.7887 (3.1175)	Learning Rate [0.00015625]
1: TRAIN [2][680/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00100)	Tok/s 31867 (52619)	Loss/tok 2.7670 (3.1141)	Learning Rate [0.00015625]
9: TRAIN [2][680/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 31581 (53309)	Loss/tok 2.7209 (3.1160)	Learning Rate [0.00015625]
0: TRAIN [2][680/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00098)	Tok/s 31899 (52528)	Loss/tok 2.7253 (3.1306)	Learning Rate [0.00015625]
15: TRAIN [2][680/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 33078 (53916)	Loss/tok 2.7548 (3.1196)	Learning Rate [0.00015625]
11: TRAIN [2][680/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00092)	Tok/s 32859 (53471)	Loss/tok 3.0105 (3.1278)	Learning Rate [0.00015625]
10: TRAIN [2][680/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00096)	Tok/s 32021 (53392)	Loss/tok 2.8868 (3.1092)	Learning Rate [0.00015625]
14: TRAIN [2][680/3416]	Time 0.050 (0.058)	Data 0.00078 (0.00092)	Tok/s 32979 (53790)	Loss/tok 3.1172 (3.1207)	Learning Rate [0.00015625]
13: TRAIN [2][680/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00098)	Tok/s 32947 (53673)	Loss/tok 2.6645 (3.1154)	Learning Rate [0.00015625]
12: TRAIN [2][680/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00103)	Tok/s 32893 (53578)	Loss/tok 2.8874 (3.1235)	Learning Rate [0.00015625]
11: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00092)	Tok/s 54533 (53442)	Loss/tok 3.2227 (3.1273)	Learning Rate [0.00015625]
9: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00084 (0.00091)	Tok/s 54505 (53281)	Loss/tok 2.9690 (3.1163)	Learning Rate [0.00015625]
10: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00096)	Tok/s 54516 (53364)	Loss/tok 3.0056 (3.1085)	Learning Rate [0.00015625]
13: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00098)	Tok/s 55605 (53646)	Loss/tok 2.9498 (3.1148)	Learning Rate [0.00015625]
12: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00103)	Tok/s 55435 (53550)	Loss/tok 3.2232 (3.1233)	Learning Rate [0.00015625]
8: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00097)	Tok/s 54531 (53217)	Loss/tok 3.0438 (3.1166)	Learning Rate [0.00015625]
14: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00092)	Tok/s 55606 (53763)	Loss/tok 3.3694 (3.1203)	Learning Rate [0.00015625]
15: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00092)	Tok/s 55701 (53887)	Loss/tok 2.9202 (3.1189)	Learning Rate [0.00015625]
6: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00093)	Tok/s 54557 (53062)	Loss/tok 3.1977 (3.1287)	Learning Rate [0.00015625]
7: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00097)	Tok/s 54537 (53149)	Loss/tok 3.0471 (3.1173)	Learning Rate [0.00015625]
1: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00100)	Tok/s 54596 (52592)	Loss/tok 3.0154 (3.1145)	Learning Rate [0.00015625]
0: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00098)	Tok/s 54584 (52501)	Loss/tok 3.2594 (3.1301)	Learning Rate [0.00015625]
5: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00094)	Tok/s 54548 (52973)	Loss/tok 3.3394 (3.1204)	Learning Rate [0.00015625]
2: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00099)	Tok/s 54557 (52705)	Loss/tok 3.0854 (3.1171)	Learning Rate [0.00015625]
3: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00092)	Tok/s 54528 (52795)	Loss/tok 3.3479 (3.1226)	Learning Rate [0.00015625]
4: TRAIN [2][690/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00097)	Tok/s 54524 (52888)	Loss/tok 3.1784 (3.1218)	Learning Rate [0.00015625]
4: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00097)	Tok/s 51112 (52883)	Loss/tok 2.8203 (3.1215)	Learning Rate [0.00015625]
3: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00108 (0.00092)	Tok/s 50864 (52791)	Loss/tok 3.1990 (3.1222)	Learning Rate [0.00015625]
5: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00094)	Tok/s 50938 (52967)	Loss/tok 3.1390 (3.1204)	Learning Rate [0.00015625]
6: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00085 (0.00093)	Tok/s 50907 (53055)	Loss/tok 3.1511 (3.1291)	Learning Rate [0.00015625]
2: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00099)	Tok/s 49965 (52699)	Loss/tok 3.1078 (3.1164)	Learning Rate [0.00015625]
1: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00100)	Tok/s 49970 (52586)	Loss/tok 3.0021 (3.1147)	Learning Rate [0.00015625]
0: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00098)	Tok/s 49992 (52496)	Loss/tok 3.2140 (3.1305)	Learning Rate [0.00015625]
7: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00097)	Tok/s 50864 (53142)	Loss/tok 2.9718 (3.1174)	Learning Rate [0.00015625]
15: TRAIN [2][700/3416]	Time 0.053 (0.058)	Data 0.00080 (0.00092)	Tok/s 53049 (53880)	Loss/tok 3.0227 (3.1194)	Learning Rate [0.00015625]
8: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00097)	Tok/s 50888 (53210)	Loss/tok 3.0216 (3.1165)	Learning Rate [0.00015625]
14: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00092)	Tok/s 51100 (53757)	Loss/tok 3.1978 (3.1196)	Learning Rate [0.00015625]
13: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00086 (0.00098)	Tok/s 51099 (53640)	Loss/tok 3.1086 (3.1152)	Learning Rate [0.00015625]
10: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00096)	Tok/s 50931 (53356)	Loss/tok 3.1859 (3.1096)	Learning Rate [0.00015625]
11: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00092)	Tok/s 50927 (53435)	Loss/tok 3.2177 (3.1273)	Learning Rate [0.00015625]
12: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00103)	Tok/s 50983 (53541)	Loss/tok 3.2374 (3.1229)	Learning Rate [0.00015625]
9: TRAIN [2][700/3416]	Time 0.055 (0.058)	Data 0.00081 (0.00092)	Tok/s 50895 (53274)	Loss/tok 3.1795 (3.1163)	Learning Rate [0.00015625]
6: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00093)	Tok/s 68659 (53133)	Loss/tok 3.0622 (3.1284)	Learning Rate [0.00015625]
5: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00094)	Tok/s 68593 (53046)	Loss/tok 3.2191 (3.1212)	Learning Rate [0.00015625]
7: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 68722 (53222)	Loss/tok 3.0115 (3.1167)	Learning Rate [0.00015625]
8: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 68566 (53289)	Loss/tok 3.1495 (3.1167)	Learning Rate [0.00015625]
10: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 68603 (53436)	Loss/tok 3.0702 (3.1094)	Learning Rate [0.00015625]
11: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00092)	Tok/s 68693 (53515)	Loss/tok 3.3672 (3.1283)	Learning Rate [0.00015625]
3: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 67852 (52870)	Loss/tok 3.1216 (3.1218)	Learning Rate [0.00015625]
4: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00098)	Tok/s 67663 (52962)	Loss/tok 3.2033 (3.1210)	Learning Rate [0.00015625]
12: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00103)	Tok/s 68584 (53621)	Loss/tok 3.1300 (3.1218)	Learning Rate [0.00015625]
2: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00099)	Tok/s 67780 (52779)	Loss/tok 3.0449 (3.1164)	Learning Rate [0.00015625]
14: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 68660 (53835)	Loss/tok 3.1329 (3.1199)	Learning Rate [0.00015625]
0: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00098)	Tok/s 67783 (52577)	Loss/tok 3.1755 (3.1313)	Learning Rate [0.00015625]
15: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 68754 (53957)	Loss/tok 3.0400 (3.1189)	Learning Rate [0.00015625]
13: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 68592 (53719)	Loss/tok 3.1710 (3.1160)	Learning Rate [0.00015625]
9: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 68620 (53352)	Loss/tok 3.2660 (3.1173)	Learning Rate [0.00015625]
1: TRAIN [2][710/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 67771 (52667)	Loss/tok 3.3676 (3.1155)	Learning Rate [0.00015625]
5: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00094)	Tok/s 52543 (53114)	Loss/tok 3.0641 (3.1210)	Learning Rate [7.8125e-05]
6: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00084 (0.00093)	Tok/s 52420 (53201)	Loss/tok 3.2641 (3.1287)	Learning Rate [7.8125e-05]
4: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00098)	Tok/s 51584 (53028)	Loss/tok 3.3219 (3.1219)	Learning Rate [7.8125e-05]
3: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00092)	Tok/s 51370 (52937)	Loss/tok 3.0089 (3.1236)	Learning Rate [7.8125e-05]
2: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00086 (0.00099)	Tok/s 51382 (52847)	Loss/tok 3.0287 (3.1170)	Learning Rate [7.8125e-05]
7: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00097)	Tok/s 52407 (53288)	Loss/tok 2.8906 (3.1175)	Learning Rate [7.8125e-05]
1: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00100)	Tok/s 51314 (52736)	Loss/tok 3.0174 (3.1162)	Learning Rate [7.8125e-05]
9: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00092)	Tok/s 52443 (53421)	Loss/tok 3.0361 (3.1172)	Learning Rate [7.8125e-05]
0: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00098)	Tok/s 51388 (52647)	Loss/tok 3.2037 (3.1319)	Learning Rate [7.8125e-05]
15: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00092)	Tok/s 52568 (54023)	Loss/tok 3.0761 (3.1192)	Learning Rate [7.8125e-05]
10: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00096)	Tok/s 52391 (53503)	Loss/tok 3.0385 (3.1101)	Learning Rate [7.8125e-05]
11: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00092)	Tok/s 52461 (53582)	Loss/tok 2.9903 (3.1284)	Learning Rate [7.8125e-05]
8: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00097)	Tok/s 52445 (53358)	Loss/tok 3.2532 (3.1166)	Learning Rate [7.8125e-05]
14: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00084 (0.00092)	Tok/s 52519 (53899)	Loss/tok 2.9138 (3.1201)	Learning Rate [7.8125e-05]
13: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00098)	Tok/s 52476 (53785)	Loss/tok 3.2004 (3.1161)	Learning Rate [7.8125e-05]
12: TRAIN [2][720/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00103)	Tok/s 52426 (53687)	Loss/tok 3.2369 (3.1213)	Learning Rate [7.8125e-05]
9: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00091)	Tok/s 77680 (53433)	Loss/tok 3.1812 (3.1173)	Learning Rate [7.8125e-05]
8: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 76937 (53368)	Loss/tok 3.3486 (3.1180)	Learning Rate [7.8125e-05]
10: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 77878 (53517)	Loss/tok 3.1274 (3.1108)	Learning Rate [7.8125e-05]
7: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 76845 (53299)	Loss/tok 3.1480 (3.1186)	Learning Rate [7.8125e-05]
11: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 77938 (53595)	Loss/tok 2.9729 (3.1281)	Learning Rate [7.8125e-05]
6: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 76708 (53211)	Loss/tok 3.0392 (3.1293)	Learning Rate [7.8125e-05]
5: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00094)	Tok/s 76708 (53125)	Loss/tok 3.2308 (3.1206)	Learning Rate [7.8125e-05]
12: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00121 (0.00103)	Tok/s 77954 (53699)	Loss/tok 3.2338 (3.1224)	Learning Rate [7.8125e-05]
13: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 77926 (53798)	Loss/tok 3.1873 (3.1171)	Learning Rate [7.8125e-05]
4: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 76726 (53041)	Loss/tok 2.9278 (3.1210)	Learning Rate [7.8125e-05]
3: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 76738 (52951)	Loss/tok 3.2032 (3.1238)	Learning Rate [7.8125e-05]
14: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 77863 (53913)	Loss/tok 3.2003 (3.1200)	Learning Rate [7.8125e-05]
15: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 77853 (54035)	Loss/tok 3.0076 (3.1188)	Learning Rate [7.8125e-05]
0: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00098)	Tok/s 76353 (52663)	Loss/tok 3.3077 (3.1337)	Learning Rate [7.8125e-05]
2: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00099)	Tok/s 76546 (52861)	Loss/tok 3.2001 (3.1181)	Learning Rate [7.8125e-05]
1: TRAIN [2][730/3416]	Time 0.070 (0.058)	Data 0.00129 (0.00100)	Tok/s 76553 (52751)	Loss/tok 3.0723 (3.1167)	Learning Rate [7.8125e-05]
11: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
11: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 61870 (53607)	Loss/tok 3.0506 (3.1268)	Learning Rate [7.8125e-05]
10: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 61936 (53529)	Loss/tok 3.3870 (3.1113)	Learning Rate [7.8125e-05]
12: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00103)	Tok/s 61866 (53710)	Loss/tok 3.1601 (3.1228)	Learning Rate [7.8125e-05]
8: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 62009 (53380)	Loss/tok 3.4902 (3.1191)	Learning Rate [7.8125e-05]
9: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 61880 (53446)	Loss/tok 3.2747 (3.1184)	Learning Rate [7.8125e-05]
13: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 61866 (53808)	Loss/tok 3.3548 (3.1178)	Learning Rate [7.8125e-05]
4: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 62134 (53054)	Loss/tok 3.3247 (3.1207)	Learning Rate [7.8125e-05]
7: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 62001 (53311)	Loss/tok 3.3124 (3.1196)	Learning Rate [7.8125e-05]
3: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 62061 (52964)	Loss/tok 3.3806 (3.1240)	Learning Rate [7.8125e-05]
14: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 62291 (53922)	Loss/tok 3.0404 (3.1194)	Learning Rate [7.8125e-05]
2: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00099)	Tok/s 62021 (52875)	Loss/tok 3.2233 (3.1180)	Learning Rate [7.8125e-05]
1: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 61913 (52767)	Loss/tok 3.3590 (3.1172)	Learning Rate [7.8125e-05]
6: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 61972 (53222)	Loss/tok 3.1816 (3.1292)	Learning Rate [7.8125e-05]
0: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 61905 (52679)	Loss/tok 3.1521 (3.1333)	Learning Rate [7.8125e-05]
5: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00094)	Tok/s 61993 (53138)	Loss/tok 3.2376 (3.1206)	Learning Rate [7.8125e-05]
15: TRAIN [2][740/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 62766 (54046)	Loss/tok 3.0849 (3.1187)	Learning Rate [7.8125e-05]
4: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00098)	Tok/s 51258 (52972)	Loss/tok 2.9522 (3.1203)	Learning Rate [7.8125e-05]
6: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00092)	Tok/s 51967 (53145)	Loss/tok 2.9698 (3.1282)	Learning Rate [7.8125e-05]
3: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00092)	Tok/s 50422 (52881)	Loss/tok 3.1802 (3.1236)	Learning Rate [7.8125e-05]
5: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00094)	Tok/s 51886 (53058)	Loss/tok 2.9539 (3.1211)	Learning Rate [7.8125e-05]
2: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00099)	Tok/s 50273 (52793)	Loss/tok 2.7636 (3.1169)	Learning Rate [7.8125e-05]
1: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00100)	Tok/s 50249 (52686)	Loss/tok 2.8254 (3.1157)	Learning Rate [7.8125e-05]
9: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00092)	Tok/s 51947 (53366)	Loss/tok 3.0202 (3.1180)	Learning Rate [7.8125e-05]
7: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00097)	Tok/s 51962 (53233)	Loss/tok 3.2037 (3.1193)	Learning Rate [7.8125e-05]
0: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00098)	Tok/s 50232 (52597)	Loss/tok 2.9105 (3.1330)	Learning Rate [7.8125e-05]
15: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00092)	Tok/s 51642 (53961)	Loss/tok 3.0627 (3.1176)	Learning Rate [7.8125e-05]
13: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00097)	Tok/s 51735 (53725)	Loss/tok 2.8356 (3.1165)	Learning Rate [7.8125e-05]
8: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 51813 (53301)	Loss/tok 3.1823 (3.1186)	Learning Rate [7.8125e-05]
14: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 51644 (53837)	Loss/tok 3.0555 (3.1187)	Learning Rate [7.8125e-05]
10: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00096)	Tok/s 51835 (53447)	Loss/tok 2.9113 (3.1105)	Learning Rate [7.8125e-05]
11: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 51675 (53525)	Loss/tok 2.9868 (3.1257)	Learning Rate [7.8125e-05]
12: TRAIN [2][750/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00103)	Tok/s 51648 (53628)	Loss/tok 3.0952 (3.1221)	Learning Rate [7.8125e-05]
7: TRAIN [2][760/3416]	Time 0.063 (0.058)	Data 0.00110 (0.00097)	Tok/s 53736 (53220)	Loss/tok 3.2454 (3.1189)	Learning Rate [7.8125e-05]
6: TRAIN [2][760/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00092)	Tok/s 53707 (53132)	Loss/tok 3.1633 (3.1281)	Learning Rate [7.8125e-05]
9: TRAIN [2][760/3416]	Time 0.063 (0.058)	Data 0.00108 (0.00092)	Tok/s 54755 (53354)	Loss/tok 3.0838 (3.1170)	Learning Rate [7.8125e-05]
4: TRAIN [2][760/3416]	Time 0.063 (0.058)	Data 0.00106 (0.00097)	Tok/s 53659 (52959)	Loss/tok 3.2083 (3.1201)	Learning Rate [7.8125e-05]
8: TRAIN [2][760/3416]	Time 0.063 (0.058)	Data 0.00114 (0.00097)	Tok/s 54560 (53290)	Loss/tok 3.4401 (3.1189)	Learning Rate [7.8125e-05]
5: TRAIN [2][760/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00094)	Tok/s 53677 (53044)	Loss/tok 3.2180 (3.1211)	Learning Rate [7.8125e-05]
10: TRAIN [2][760/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00096)	Tok/s 54769 (53435)	Loss/tok 3.2974 (3.1107)	Learning Rate [7.8125e-05]
2: TRAIN [2][760/3416]	Time 0.063 (0.058)	Data 0.00106 (0.00099)	Tok/s 53465 (52783)	Loss/tok 3.2516 (3.1169)	Learning Rate [7.8125e-05]
11: TRAIN [2][760/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00092)	Tok/s 54651 (53512)	Loss/tok 3.0297 (3.1259)	Learning Rate [7.8125e-05]
12: TRAIN [2][760/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00103)	Tok/s 54624 (53615)	Loss/tok 3.0264 (3.1215)	Learning Rate [7.8125e-05]
1: TRAIN [2][760/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00100)	Tok/s 53414 (52677)	Loss/tok 3.0912 (3.1168)	Learning Rate [7.8125e-05]
0: TRAIN [2][760/3416]	Time 0.064 (0.058)	Data 0.00106 (0.00098)	Tok/s 53406 (52589)	Loss/tok 3.2503 (3.1326)	Learning Rate [7.8125e-05]
13: TRAIN [2][760/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00097)	Tok/s 54483 (53712)	Loss/tok 3.3673 (3.1160)	Learning Rate [7.8125e-05]
15: TRAIN [2][760/3416]	Time 0.064 (0.058)	Data 0.00104 (0.00092)	Tok/s 54385 (53948)	Loss/tok 3.1719 (3.1179)	Learning Rate [7.8125e-05]
14: TRAIN [2][760/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00091)	Tok/s 54439 (53824)	Loss/tok 3.2973 (3.1189)	Learning Rate [7.8125e-05]
3: TRAIN [2][760/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00092)	Tok/s 53533 (52869)	Loss/tok 3.0319 (3.1243)	Learning Rate [7.8125e-05]
8: Gradient norm: inf
9: Gradient norm: inf
7: Gradient norm: inf
8: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
6: Gradient norm: inf
7: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
11: Gradient norm: inf
0: Gradient norm: inf
5: Gradient norm: inf
6: Skipped batch, new scale: 2048.0
10: Skipped batch, new scale: 2048.0
14: Gradient norm: inf
15: Skipped batch, new scale: 2048.0
11: Skipped batch, new scale: 2048.0
0: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
12: Gradient norm: inf
13: Gradient norm: inf
1: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
3: Gradient norm: inf
4: Gradient norm: inf
12: Skipped batch, new scale: 2048.0
13: Skipped batch, new scale: 2048.0
1: Skipped batch, new scale: 2048.0
2: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
4: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
9: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00092)	Tok/s 33283 (53342)	Loss/tok 2.6077 (3.1152)	Learning Rate [7.8125e-05]
10: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00096)	Tok/s 33245 (53423)	Loss/tok 2.8960 (3.1106)	Learning Rate [7.8125e-05]
11: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 33153 (53500)	Loss/tok 2.8868 (3.1255)	Learning Rate [7.8125e-05]
8: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00097)	Tok/s 33327 (53278)	Loss/tok 2.7824 (3.1188)	Learning Rate [7.8125e-05]
7: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00106 (0.00097)	Tok/s 33300 (53206)	Loss/tok 2.7489 (3.1183)	Learning Rate [7.8125e-05]
6: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00081 (0.00092)	Tok/s 33175 (53119)	Loss/tok 2.6670 (3.1274)	Learning Rate [7.8125e-05]
12: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00103)	Tok/s 34230 (53604)	Loss/tok 2.7126 (3.1208)	Learning Rate [7.8125e-05]
13: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00097)	Tok/s 34392 (53702)	Loss/tok 2.8583 (3.1155)	Learning Rate [7.8125e-05]
14: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00091)	Tok/s 34302 (53813)	Loss/tok 2.9286 (3.1186)	Learning Rate [7.8125e-05]
4: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00097)	Tok/s 33113 (52947)	Loss/tok 2.7196 (3.1184)	Learning Rate [7.8125e-05]
5: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00094)	Tok/s 33072 (53032)	Loss/tok 2.9472 (3.1212)	Learning Rate [7.8125e-05]
15: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 34232 (53937)	Loss/tok 2.8663 (3.1182)	Learning Rate [7.8125e-05]
0: TRAIN [2][770/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00098)	Tok/s 32945 (52578)	Loss/tok 2.6756 (3.1324)	Learning Rate [7.8125e-05]
1: TRAIN [2][770/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00100)	Tok/s 32927 (52665)	Loss/tok 2.7106 (3.1165)	Learning Rate [7.8125e-05]
2: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00099)	Tok/s 32952 (52770)	Loss/tok 2.7257 (3.1167)	Learning Rate [7.8125e-05]
3: TRAIN [2][770/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00091)	Tok/s 32962 (52855)	Loss/tok 3.0261 (3.1239)	Learning Rate [7.8125e-05]
10: TRAIN [2][780/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00096)	Tok/s 55322 (53386)	Loss/tok 3.1582 (3.1104)	Learning Rate [7.8125e-05]
11: TRAIN [2][780/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00092)	Tok/s 55289 (53464)	Loss/tok 3.0944 (3.1241)	Learning Rate [7.8125e-05]
9: TRAIN [2][780/3416]	Time 0.066 (0.058)	Data 0.00103 (0.00092)	Tok/s 55308 (53305)	Loss/tok 3.4114 (3.1156)	Learning Rate [7.8125e-05]
8: TRAIN [2][780/3416]	Time 0.066 (0.058)	Data 0.00109 (0.00097)	Tok/s 55272 (53241)	Loss/tok 3.1760 (3.1187)	Learning Rate [7.8125e-05]
7: TRAIN [2][780/3416]	Time 0.066 (0.058)	Data 0.00103 (0.00097)	Tok/s 55208 (53171)	Loss/tok 3.2690 (3.1188)	Learning Rate [7.8125e-05]
6: TRAIN [2][780/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00092)	Tok/s 55098 (53084)	Loss/tok 2.8700 (3.1267)	Learning Rate [7.8125e-05]
12: TRAIN [2][780/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00103)	Tok/s 55200 (53567)	Loss/tok 3.1237 (3.1207)	Learning Rate [7.8125e-05]
13: TRAIN [2][780/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00097)	Tok/s 55118 (53666)	Loss/tok 3.3720 (3.1156)	Learning Rate [7.8125e-05]
4: TRAIN [2][780/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00097)	Tok/s 54918 (52913)	Loss/tok 3.2736 (3.1182)	Learning Rate [7.8125e-05]
14: TRAIN [2][780/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00091)	Tok/s 55676 (53776)	Loss/tok 3.3904 (3.1191)	Learning Rate [7.8125e-05]
5: TRAIN [2][780/3416]	Time 0.066 (0.058)	Data 0.00103 (0.00094)	Tok/s 54987 (52997)	Loss/tok 3.1318 (3.1210)	Learning Rate [7.8125e-05]
15: TRAIN [2][780/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00092)	Tok/s 55906 (53901)	Loss/tok 3.3206 (3.1187)	Learning Rate [7.8125e-05]
0: TRAIN [2][780/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00098)	Tok/s 54843 (52548)	Loss/tok 3.2775 (3.1328)	Learning Rate [7.8125e-05]
1: TRAIN [2][780/3416]	Time 0.067 (0.058)	Data 0.00102 (0.00100)	Tok/s 54777 (52635)	Loss/tok 3.0022 (3.1170)	Learning Rate [7.8125e-05]
2: TRAIN [2][780/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00099)	Tok/s 54721 (52737)	Loss/tok 2.9709 (3.1161)	Learning Rate [7.8125e-05]
3: TRAIN [2][780/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00091)	Tok/s 54819 (52822)	Loss/tok 3.3255 (3.1235)	Learning Rate [7.8125e-05]
6: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00092)	Tok/s 42479 (53088)	Loss/tok 2.7866 (3.1267)	Learning Rate [7.8125e-05]
7: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 42548 (53173)	Loss/tok 3.0160 (3.1191)	Learning Rate [7.8125e-05]
8: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00097)	Tok/s 42577 (53243)	Loss/tok 2.7521 (3.1203)	Learning Rate [7.8125e-05]
9: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00092)	Tok/s 42555 (53307)	Loss/tok 3.1206 (3.1170)	Learning Rate [7.8125e-05]
4: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00097)	Tok/s 42256 (52919)	Loss/tok 3.0030 (3.1189)	Learning Rate [7.8125e-05]
5: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00094)	Tok/s 42359 (53002)	Loss/tok 2.7904 (3.1213)	Learning Rate [7.8125e-05]
11: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 42757 (53466)	Loss/tok 2.8200 (3.1245)	Learning Rate [7.8125e-05]
10: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00096)	Tok/s 42628 (53387)	Loss/tok 2.7951 (3.1104)	Learning Rate [7.8125e-05]
1: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00100)	Tok/s 42253 (52643)	Loss/tok 2.9053 (3.1175)	Learning Rate [7.8125e-05]
12: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00102)	Tok/s 43899 (53571)	Loss/tok 3.1571 (3.1212)	Learning Rate [7.8125e-05]
2: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00099)	Tok/s 42233 (52745)	Loss/tok 3.0430 (3.1161)	Learning Rate [7.8125e-05]
13: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00097)	Tok/s 43786 (53669)	Loss/tok 2.6719 (3.1157)	Learning Rate [7.8125e-05]
0: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 42237 (52557)	Loss/tok 3.0000 (3.1332)	Learning Rate [7.8125e-05]
15: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00092)	Tok/s 43641 (53902)	Loss/tok 3.0808 (3.1194)	Learning Rate [7.8125e-05]
14: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00091)	Tok/s 43679 (53778)	Loss/tok 2.8195 (3.1191)	Learning Rate [7.8125e-05]
3: TRAIN [2][790/3416]	Time 0.047 (0.058)	Data 0.00082 (0.00091)	Tok/s 42255 (52829)	Loss/tok 3.1092 (3.1240)	Learning Rate [7.8125e-05]
14: TRAIN [2][800/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00091)	Tok/s 55901 (53781)	Loss/tok 3.0946 (3.1193)	Learning Rate [7.8125e-05]
15: TRAIN [2][800/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00092)	Tok/s 55871 (53903)	Loss/tok 3.1344 (3.1193)	Learning Rate [7.8125e-05]
13: TRAIN [2][800/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00097)	Tok/s 55788 (53673)	Loss/tok 3.3296 (3.1166)	Learning Rate [7.8125e-05]
12: TRAIN [2][800/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00102)	Tok/s 55801 (53575)	Loss/tok 3.0233 (3.1210)	Learning Rate [7.8125e-05]
0: TRAIN [2][800/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00097)	Tok/s 54925 (52563)	Loss/tok 3.0205 (3.1323)	Learning Rate [7.8125e-05]
1: TRAIN [2][800/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00100)	Tok/s 54932 (52648)	Loss/tok 3.2126 (3.1175)	Learning Rate [7.8125e-05]
11: TRAIN [2][800/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00092)	Tok/s 55790 (53471)	Loss/tok 3.2948 (3.1248)	Learning Rate [7.8125e-05]
10: TRAIN [2][800/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00096)	Tok/s 55012 (53390)	Loss/tok 3.1605 (3.1102)	Learning Rate [7.8125e-05]
9: TRAIN [2][800/3416]	Time 0.067 (0.058)	Data 0.00111 (0.00092)	Tok/s 54850 (53309)	Loss/tok 3.1710 (3.1171)	Learning Rate [7.8125e-05]
2: TRAIN [2][800/3416]	Time 0.066 (0.058)	Data 0.00100 (0.00099)	Tok/s 54934 (52749)	Loss/tok 3.0365 (3.1162)	Learning Rate [7.8125e-05]
4: TRAIN [2][800/3416]	Time 0.066 (0.058)	Data 0.00100 (0.00097)	Tok/s 54974 (52923)	Loss/tok 3.0686 (3.1191)	Learning Rate [7.8125e-05]
8: TRAIN [2][800/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00097)	Tok/s 54834 (53246)	Loss/tok 3.2161 (3.1212)	Learning Rate [7.8125e-05]
6: TRAIN [2][800/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00092)	Tok/s 54898 (53091)	Loss/tok 3.2602 (3.1265)	Learning Rate [7.8125e-05]
7: TRAIN [2][800/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00097)	Tok/s 54883 (53176)	Loss/tok 3.1252 (3.1191)	Learning Rate [7.8125e-05]
5: TRAIN [2][800/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00094)	Tok/s 54892 (53006)	Loss/tok 3.2159 (3.1212)	Learning Rate [7.8125e-05]
3: TRAIN [2][800/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00091)	Tok/s 54981 (52835)	Loss/tok 3.1142 (3.1244)	Learning Rate [7.8125e-05]
0: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 63010 (52566)	Loss/tok 3.3491 (3.1331)	Learning Rate [7.8125e-05]
1: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 63083 (52651)	Loss/tok 3.2967 (3.1182)	Learning Rate [7.8125e-05]
9: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00092)	Tok/s 63155 (53313)	Loss/tok 3.3336 (3.1175)	Learning Rate [7.8125e-05]
10: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00096)	Tok/s 63266 (53392)	Loss/tok 3.1787 (3.1105)	Learning Rate [7.8125e-05]
8: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 63053 (53249)	Loss/tok 3.1488 (3.1214)	Learning Rate [7.8125e-05]
15: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 64029 (53906)	Loss/tok 3.2432 (3.1200)	Learning Rate [7.8125e-05]
11: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 64102 (53473)	Loss/tok 3.3801 (3.1250)	Learning Rate [7.8125e-05]
2: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 63020 (52751)	Loss/tok 3.2188 (3.1164)	Learning Rate [7.8125e-05]
7: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 62974 (53179)	Loss/tok 3.3664 (3.1202)	Learning Rate [7.8125e-05]
14: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00091)	Tok/s 64110 (53784)	Loss/tok 3.2470 (3.1198)	Learning Rate [7.8125e-05]
6: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 62801 (53094)	Loss/tok 3.1540 (3.1269)	Learning Rate [7.8125e-05]
13: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00097)	Tok/s 64427 (53675)	Loss/tok 3.4322 (3.1169)	Learning Rate [7.8125e-05]
4: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00097)	Tok/s 62861 (52925)	Loss/tok 3.1938 (3.1196)	Learning Rate [7.8125e-05]
12: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00102)	Tok/s 64122 (53577)	Loss/tok 3.2704 (3.1216)	Learning Rate [7.8125e-05]
5: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00094)	Tok/s 62829 (53008)	Loss/tok 3.2091 (3.1226)	Learning Rate [7.8125e-05]
3: TRAIN [2][810/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00091)	Tok/s 62866 (52837)	Loss/tok 3.2707 (3.1255)	Learning Rate [7.8125e-05]
15: TRAIN [2][820/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 73751 (53936)	Loss/tok 3.1736 (3.1210)	Learning Rate [7.8125e-05]
14: TRAIN [2][820/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 73779 (53816)	Loss/tok 3.0955 (3.1199)	Learning Rate [7.8125e-05]
0: TRAIN [2][820/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 71831 (52602)	Loss/tok 3.3522 (3.1341)	Learning Rate [7.8125e-05]
13: TRAIN [2][820/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 73767 (53706)	Loss/tok 3.1204 (3.1183)	Learning Rate [7.8125e-05]
1: TRAIN [2][820/3416]	Time 0.068 (0.058)	Data 0.00115 (0.00100)	Tok/s 74446 (52687)	Loss/tok 3.0533 (3.1180)	Learning Rate [7.8125e-05]
12: TRAIN [2][820/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00102)	Tok/s 73357 (53609)	Loss/tok 3.1978 (3.1221)	Learning Rate [7.8125e-05]
11: TRAIN [2][820/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 72583 (53502)	Loss/tok 3.0169 (3.1251)	Learning Rate [7.8125e-05]
4: TRAIN [2][820/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 72231 (52960)	Loss/tok 3.2864 (3.1198)	Learning Rate [7.8125e-05]
2: TRAIN [2][820/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00099)	Tok/s 72505 (52786)	Loss/tok 3.1150 (3.1161)	Learning Rate [7.8125e-05]
10: TRAIN [2][820/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00097)	Tok/s 72480 (53422)	Loss/tok 3.0892 (3.1106)	Learning Rate [7.8125e-05]
9: TRAIN [2][820/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 72360 (53344)	Loss/tok 3.1847 (3.1173)	Learning Rate [7.8125e-05]
6: TRAIN [2][820/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 72135 (53127)	Loss/tok 3.2976 (3.1278)	Learning Rate [7.8125e-05]
5: TRAIN [2][820/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00094)	Tok/s 72172 (53042)	Loss/tok 3.0138 (3.1224)	Learning Rate [7.8125e-05]
8: TRAIN [2][820/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 72225 (53280)	Loss/tok 3.1974 (3.1222)	Learning Rate [7.8125e-05]
7: TRAIN [2][820/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 72156 (53210)	Loss/tok 3.2773 (3.1210)	Learning Rate [7.8125e-05]
3: TRAIN [2][820/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 72306 (52873)	Loss/tok 3.4145 (3.1260)	Learning Rate [7.8125e-05]
13: TRAIN [2][830/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00097)	Tok/s 55742 (53702)	Loss/tok 3.0638 (3.1172)	Learning Rate [7.8125e-05]
14: TRAIN [2][830/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00091)	Tok/s 55683 (53810)	Loss/tok 3.2113 (3.1195)	Learning Rate [7.8125e-05]
11: TRAIN [2][830/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00092)	Tok/s 55785 (53497)	Loss/tok 3.2023 (3.1254)	Learning Rate [7.8125e-05]
15: TRAIN [2][830/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00092)	Tok/s 55568 (53929)	Loss/tok 3.0280 (3.1198)	Learning Rate [7.8125e-05]
10: TRAIN [2][830/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00097)	Tok/s 55842 (53417)	Loss/tok 3.3434 (3.1102)	Learning Rate [7.8125e-05]
12: TRAIN [2][830/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00102)	Tok/s 55870 (53605)	Loss/tok 3.4913 (3.1224)	Learning Rate [7.8125e-05]
9: TRAIN [2][830/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00092)	Tok/s 55805 (53339)	Loss/tok 3.2906 (3.1165)	Learning Rate [7.8125e-05]
8: TRAIN [2][830/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00097)	Tok/s 55765 (53276)	Loss/tok 3.0653 (3.1218)	Learning Rate [7.8125e-05]
2: TRAIN [2][830/3416]	Time 0.067 (0.058)	Data 0.00109 (0.00099)	Tok/s 55474 (52786)	Loss/tok 3.4511 (3.1158)	Learning Rate [7.8125e-05]
7: TRAIN [2][830/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00096)	Tok/s 55679 (53206)	Loss/tok 3.3214 (3.1212)	Learning Rate [7.8125e-05]
6: TRAIN [2][830/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00092)	Tok/s 55570 (53123)	Loss/tok 2.9679 (3.1287)	Learning Rate [7.8125e-05]
5: TRAIN [2][830/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00094)	Tok/s 55534 (53039)	Loss/tok 3.3498 (3.1225)	Learning Rate [7.8125e-05]
4: TRAIN [2][830/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00097)	Tok/s 55518 (52957)	Loss/tok 3.3357 (3.1202)	Learning Rate [7.8125e-05]
3: TRAIN [2][830/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00092)	Tok/s 55349 (52871)	Loss/tok 3.2414 (3.1260)	Learning Rate [7.8125e-05]
0: TRAIN [2][830/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00097)	Tok/s 54806 (52602)	Loss/tok 3.3665 (3.1332)	Learning Rate [7.8125e-05]
1: TRAIN [2][830/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00100)	Tok/s 54621 (52687)	Loss/tok 3.2543 (3.1178)	Learning Rate [7.8125e-05]
14: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00091)	Tok/s 64151 (53843)	Loss/tok 3.1460 (3.1204)	Learning Rate [7.8125e-05]
15: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 64185 (53961)	Loss/tok 3.2194 (3.1195)	Learning Rate [7.8125e-05]
13: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00097)	Tok/s 64036 (53736)	Loss/tok 3.3103 (3.1182)	Learning Rate [7.8125e-05]
0: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 63278 (52641)	Loss/tok 3.1059 (3.1334)	Learning Rate [7.8125e-05]
1: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00100)	Tok/s 63268 (52725)	Loss/tok 3.1489 (3.1180)	Learning Rate [7.8125e-05]
12: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00102)	Tok/s 63947 (53641)	Loss/tok 3.3556 (3.1226)	Learning Rate [7.8125e-05]
11: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 63886 (53533)	Loss/tok 3.3414 (3.1262)	Learning Rate [7.8125e-05]
10: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 63879 (53453)	Loss/tok 3.2580 (3.1104)	Learning Rate [7.8125e-05]
2: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00099)	Tok/s 63221 (52822)	Loss/tok 3.2110 (3.1166)	Learning Rate [7.8125e-05]
9: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 63781 (53375)	Loss/tok 3.4732 (3.1163)	Learning Rate [7.8125e-05]
8: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 63760 (53312)	Loss/tok 3.1806 (3.1221)	Learning Rate [7.8125e-05]
4: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 63957 (52994)	Loss/tok 3.1363 (3.1205)	Learning Rate [7.8125e-05]
7: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00096)	Tok/s 63688 (53243)	Loss/tok 3.0752 (3.1208)	Learning Rate [7.8125e-05]
6: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 63766 (53159)	Loss/tok 3.2031 (3.1282)	Learning Rate [7.8125e-05]
5: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 63816 (53075)	Loss/tok 3.3165 (3.1228)	Learning Rate [7.8125e-05]
3: TRAIN [2][840/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 63730 (52908)	Loss/tok 2.9778 (3.1257)	Learning Rate [7.8125e-05]
11: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 84234 (53540)	Loss/tok 2.9983 (3.1253)	Learning Rate [7.8125e-05]
9: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 83175 (53382)	Loss/tok 3.0039 (3.1154)	Learning Rate [7.8125e-05]
10: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 83312 (53460)	Loss/tok 2.9922 (3.1101)	Learning Rate [7.8125e-05]
12: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00102)	Tok/s 84316 (53648)	Loss/tok 3.0349 (3.1226)	Learning Rate [7.8125e-05]
8: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 83152 (53318)	Loss/tok 3.0577 (3.1226)	Learning Rate [7.8125e-05]
13: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00097)	Tok/s 84294 (53744)	Loss/tok 3.0392 (3.1178)	Learning Rate [7.8125e-05]
7: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00096)	Tok/s 83146 (53249)	Loss/tok 3.0463 (3.1203)	Learning Rate [7.8125e-05]
14: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 84317 (53850)	Loss/tok 3.0323 (3.1197)	Learning Rate [7.8125e-05]
15: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 84930 (53967)	Loss/tok 3.0713 (3.1187)	Learning Rate [7.8125e-05]
6: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 82616 (53166)	Loss/tok 3.0083 (3.1281)	Learning Rate [7.8125e-05]
5: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00094)	Tok/s 82241 (53082)	Loss/tok 2.9862 (3.1220)	Learning Rate [7.8125e-05]
1: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 82418 (52735)	Loss/tok 3.0390 (3.1168)	Learning Rate [7.8125e-05]
4: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 82290 (53000)	Loss/tok 3.2723 (3.1209)	Learning Rate [7.8125e-05]
2: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00099)	Tok/s 82335 (52830)	Loss/tok 2.8381 (3.1153)	Learning Rate [7.8125e-05]
0: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 81703 (52650)	Loss/tok 2.9631 (3.1331)	Learning Rate [7.8125e-05]
3: TRAIN [2][850/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 82285 (52915)	Loss/tok 3.1943 (3.1247)	Learning Rate [7.8125e-05]
14: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00091)	Tok/s 34406 (53885)	Loss/tok 3.1040 (3.1203)	Learning Rate [7.8125e-05]
5: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00094)	Tok/s 33314 (53118)	Loss/tok 2.9073 (3.1229)	Learning Rate [7.8125e-05]
10: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00097)	Tok/s 33412 (53494)	Loss/tok 2.8735 (3.1113)	Learning Rate [7.8125e-05]
4: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00097)	Tok/s 33256 (53036)	Loss/tok 3.0188 (3.1214)	Learning Rate [7.8125e-05]
15: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 34376 (54000)	Loss/tok 2.9106 (3.1183)	Learning Rate [7.8125e-05]
3: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00092)	Tok/s 33232 (52952)	Loss/tok 2.7229 (3.1243)	Learning Rate [7.8125e-05]
2: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00099)	Tok/s 33238 (52868)	Loss/tok 2.8809 (3.1152)	Learning Rate [7.8125e-05]
9: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00092)	Tok/s 33373 (53416)	Loss/tok 2.6013 (3.1156)	Learning Rate [7.8125e-05]
8: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00115 (0.00097)	Tok/s 33356 (53354)	Loss/tok 2.9691 (3.1231)	Learning Rate [7.8125e-05]
1: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00112 (0.00100)	Tok/s 33296 (52771)	Loss/tok 3.0775 (3.1169)	Learning Rate [7.8125e-05]
6: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 33393 (53203)	Loss/tok 3.0883 (3.1278)	Learning Rate [7.8125e-05]
11: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 33616 (53576)	Loss/tok 2.9631 (3.1258)	Learning Rate [7.8125e-05]
7: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00096)	Tok/s 33372 (53285)	Loss/tok 2.8592 (3.1214)	Learning Rate [7.8125e-05]
12: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00102)	Tok/s 34494 (53683)	Loss/tok 3.0208 (3.1224)	Learning Rate [7.8125e-05]
13: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00097)	Tok/s 34434 (53780)	Loss/tok 2.6174 (3.1179)	Learning Rate [7.8125e-05]
0: TRAIN [2][860/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00097)	Tok/s 33199 (52687)	Loss/tok 2.7066 (3.1331)	Learning Rate [7.8125e-05]
11: TRAIN [2][870/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00092)	Tok/s 53612 (53588)	Loss/tok 3.3791 (3.1261)	Learning Rate [7.8125e-05]
10: TRAIN [2][870/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00097)	Tok/s 53836 (53507)	Loss/tok 3.4039 (3.1113)	Learning Rate [7.8125e-05]
9: TRAIN [2][870/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00092)	Tok/s 53655 (53430)	Loss/tok 3.3049 (3.1159)	Learning Rate [7.8125e-05]
12: TRAIN [2][870/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00102)	Tok/s 53504 (53696)	Loss/tok 2.8611 (3.1222)	Learning Rate [7.8125e-05]
13: TRAIN [2][870/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00097)	Tok/s 53417 (53796)	Loss/tok 3.2101 (3.1183)	Learning Rate [7.8125e-05]
6: TRAIN [2][870/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00092)	Tok/s 52339 (53213)	Loss/tok 3.2588 (3.1271)	Learning Rate [7.8125e-05]
8: TRAIN [2][870/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00097)	Tok/s 53554 (53367)	Loss/tok 3.1822 (3.1243)	Learning Rate [7.8125e-05]
14: TRAIN [2][870/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00091)	Tok/s 53347 (53901)	Loss/tok 2.9310 (3.1202)	Learning Rate [7.8125e-05]
15: TRAIN [2][870/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00092)	Tok/s 53235 (54018)	Loss/tok 3.1632 (3.1180)	Learning Rate [7.8125e-05]
0: TRAIN [2][870/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00097)	Tok/s 52043 (52682)	Loss/tok 3.2742 (3.1328)	Learning Rate [7.8125e-05]
7: TRAIN [2][870/3416]	Time 0.059 (0.058)	Data 0.00107 (0.00096)	Tok/s 53291 (53297)	Loss/tok 3.1230 (3.1212)	Learning Rate [7.8125e-05]
5: TRAIN [2][870/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00093)	Tok/s 52217 (53127)	Loss/tok 3.2039 (3.1223)	Learning Rate [7.8125e-05]
4: TRAIN [2][870/3416]	Time 0.059 (0.058)	Data 0.00129 (0.00097)	Tok/s 52124 (53043)	Loss/tok 3.2662 (3.1218)	Learning Rate [7.8125e-05]
3: TRAIN [2][870/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00092)	Tok/s 52046 (52956)	Loss/tok 3.3377 (3.1243)	Learning Rate [7.8125e-05]
2: TRAIN [2][870/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00099)	Tok/s 51931 (52870)	Loss/tok 3.2046 (3.1154)	Learning Rate [7.8125e-05]
1: TRAIN [2][870/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00100)	Tok/s 51896 (52771)	Loss/tok 3.0315 (3.1172)	Learning Rate [7.8125e-05]
4: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 63991 (53049)	Loss/tok 3.3388 (3.1215)	Learning Rate [7.8125e-05]
3: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 63975 (52962)	Loss/tok 3.1249 (3.1247)	Learning Rate [7.8125e-05]
6: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 63910 (53218)	Loss/tok 3.5522 (3.1274)	Learning Rate [7.8125e-05]
5: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 63893 (53133)	Loss/tok 2.9737 (3.1213)	Learning Rate [7.8125e-05]
2: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 63881 (52876)	Loss/tok 3.2427 (3.1150)	Learning Rate [7.8125e-05]
1: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 64012 (52777)	Loss/tok 3.3089 (3.1165)	Learning Rate [7.8125e-05]
0: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 64001 (52688)	Loss/tok 2.9801 (3.1325)	Learning Rate [7.8125e-05]
7: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 63913 (53301)	Loss/tok 3.0752 (3.1207)	Learning Rate [7.8125e-05]
8: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 63780 (53372)	Loss/tok 3.1530 (3.1234)	Learning Rate [7.8125e-05]
9: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 63877 (53434)	Loss/tok 3.1767 (3.1155)	Learning Rate [7.8125e-05]
15: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 64917 (54025)	Loss/tok 3.4576 (3.1186)	Learning Rate [7.8125e-05]
14: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00091)	Tok/s 64894 (53908)	Loss/tok 3.0769 (3.1198)	Learning Rate [7.8125e-05]
10: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 63800 (53511)	Loss/tok 3.1300 (3.1105)	Learning Rate [7.8125e-05]
13: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 64056 (53804)	Loss/tok 3.1157 (3.1181)	Learning Rate [7.8125e-05]
11: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 63862 (53595)	Loss/tok 3.2249 (3.1261)	Learning Rate [7.8125e-05]
12: TRAIN [2][880/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00102)	Tok/s 63913 (53704)	Loss/tok 3.3291 (3.1214)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
2: TRAIN [2][890/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00099)	Tok/s 55781 (52858)	Loss/tok 3.2789 (3.1147)	Learning Rate [7.8125e-05]
3: TRAIN [2][890/3416]	Time 0.066 (0.058)	Data 0.00082 (0.00092)	Tok/s 55845 (52943)	Loss/tok 3.3008 (3.1243)	Learning Rate [7.8125e-05]
4: TRAIN [2][890/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00097)	Tok/s 55835 (53030)	Loss/tok 3.2144 (3.1210)	Learning Rate [7.8125e-05]
10: Upscaling, new scale: 4096.0
1: TRAIN [2][890/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00100)	Tok/s 55705 (52759)	Loss/tok 3.2131 (3.1171)	Learning Rate [7.8125e-05]
8: Upscaling, new scale: 4096.0
0: TRAIN [2][890/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00097)	Tok/s 55612 (52670)	Loss/tok 3.2452 (3.1317)	Learning Rate [7.8125e-05]
11: TRAIN [2][890/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00092)	Tok/s 55854 (53577)	Loss/tok 2.8702 (3.1249)	Learning Rate [7.8125e-05]
15: TRAIN [2][890/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00092)	Tok/s 56639 (54010)	Loss/tok 3.1486 (3.1184)	Learning Rate [7.8125e-05]
5: TRAIN [2][890/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00093)	Tok/s 55854 (53113)	Loss/tok 3.0696 (3.1207)	Learning Rate [7.8125e-05]
9: TRAIN [2][890/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00092)	Tok/s 55884 (53415)	Loss/tok 3.1859 (3.1157)	Learning Rate [7.8125e-05]
6: TRAIN [2][890/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00092)	Tok/s 55838 (53197)	Loss/tok 3.1710 (3.1269)	Learning Rate [7.8125e-05]
14: TRAIN [2][890/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00091)	Tok/s 56627 (53892)	Loss/tok 3.3565 (3.1199)	Learning Rate [7.8125e-05]
12: TRAIN [2][890/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00102)	Tok/s 55751 (53686)	Loss/tok 3.1889 (3.1212)	Learning Rate [7.8125e-05]
7: Upscaling, new scale: 4096.0
10: TRAIN [2][890/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00097)	Tok/s 55896 (53493)	Loss/tok 3.0189 (3.1102)	Learning Rate [7.8125e-05]
13: TRAIN [2][890/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00097)	Tok/s 56077 (53787)	Loss/tok 3.3730 (3.1180)	Learning Rate [7.8125e-05]
8: TRAIN [2][890/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00097)	Tok/s 55828 (53352)	Loss/tok 3.4183 (3.1235)	Learning Rate [7.8125e-05]
7: TRAIN [2][890/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00096)	Tok/s 55732 (53281)	Loss/tok 3.3082 (3.1209)	Learning Rate [7.8125e-05]
8: TRAIN [2][900/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 64155 (53371)	Loss/tok 3.3936 (3.1241)	Learning Rate [7.8125e-05]
9: TRAIN [2][900/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 64056 (53434)	Loss/tok 3.0812 (3.1158)	Learning Rate [7.8125e-05]
7: TRAIN [2][900/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 64121 (53301)	Loss/tok 3.1147 (3.1207)	Learning Rate [7.8125e-05]
6: TRAIN [2][900/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 64008 (53217)	Loss/tok 3.3480 (3.1268)	Learning Rate [7.8125e-05]
10: TRAIN [2][900/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00097)	Tok/s 64021 (53512)	Loss/tok 3.0177 (3.1092)	Learning Rate [7.8125e-05]
5: TRAIN [2][900/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00093)	Tok/s 64003 (53134)	Loss/tok 3.2619 (3.1211)	Learning Rate [7.8125e-05]
11: TRAIN [2][900/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 63853 (53595)	Loss/tok 3.1634 (3.1251)	Learning Rate [7.8125e-05]
4: TRAIN [2][900/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 63906 (53052)	Loss/tok 3.1801 (3.1218)	Learning Rate [7.8125e-05]
3: TRAIN [2][900/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 63777 (52967)	Loss/tok 3.2446 (3.1238)	Learning Rate [7.8125e-05]
13: TRAIN [2][900/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 63677 (53804)	Loss/tok 3.2773 (3.1186)	Learning Rate [7.8125e-05]
12: TRAIN [2][900/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00102)	Tok/s 63659 (53704)	Loss/tok 3.0747 (3.1204)	Learning Rate [7.8125e-05]
2: TRAIN [2][900/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00099)	Tok/s 63662 (52881)	Loss/tok 3.0848 (3.1152)	Learning Rate [7.8125e-05]
1: TRAIN [2][900/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 62721 (52782)	Loss/tok 3.1345 (3.1169)	Learning Rate [7.8125e-05]
14: TRAIN [2][900/3416]	Time 0.071 (0.058)	Data 0.00079 (0.00091)	Tok/s 63516 (53908)	Loss/tok 3.0022 (3.1197)	Learning Rate [7.8125e-05]
15: TRAIN [2][900/3416]	Time 0.071 (0.058)	Data 0.00081 (0.00092)	Tok/s 63441 (54026)	Loss/tok 3.2989 (3.1185)	Learning Rate [7.8125e-05]
0: TRAIN [2][900/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00097)	Tok/s 62624 (52692)	Loss/tok 3.5914 (3.1324)	Learning Rate [7.8125e-05]
6: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 78782 (53176)	Loss/tok 3.3396 (3.1264)	Learning Rate [7.8125e-05]
5: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 78805 (53092)	Loss/tok 3.1130 (3.1209)	Learning Rate [7.8125e-05]
4: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00097)	Tok/s 78769 (53011)	Loss/tok 3.1972 (3.1214)	Learning Rate [7.8125e-05]
3: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 78795 (52925)	Loss/tok 3.1594 (3.1229)	Learning Rate [7.8125e-05]
9: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 78715 (53394)	Loss/tok 3.0440 (3.1149)	Learning Rate [7.8125e-05]
2: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00099)	Tok/s 78659 (52838)	Loss/tok 3.2010 (3.1146)	Learning Rate [7.8125e-05]
11: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 79828 (53557)	Loss/tok 3.2208 (3.1246)	Learning Rate [7.8125e-05]
1: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00100)	Tok/s 77887 (52736)	Loss/tok 3.1050 (3.1162)	Learning Rate [7.8125e-05]
10: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 79592 (53473)	Loss/tok 3.2957 (3.1092)	Learning Rate [7.8125e-05]
0: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 77936 (52648)	Loss/tok 3.1276 (3.1311)	Learning Rate [7.8125e-05]
7: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 78650 (53261)	Loss/tok 3.1132 (3.1200)	Learning Rate [7.8125e-05]
13: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 79890 (53766)	Loss/tok 3.1380 (3.1187)	Learning Rate [7.8125e-05]
8: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 78679 (53332)	Loss/tok 3.1980 (3.1241)	Learning Rate [7.8125e-05]
15: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 79775 (53990)	Loss/tok 3.1073 (3.1178)	Learning Rate [7.8125e-05]
14: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00091)	Tok/s 79813 (53873)	Loss/tok 3.1477 (3.1192)	Learning Rate [7.8125e-05]
12: TRAIN [2][910/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00102)	Tok/s 79173 (53665)	Loss/tok 2.9442 (3.1190)	Learning Rate [7.8125e-05]
13: Gradient norm: inf
13: Skipped batch, new scale: 2048.0
12: Gradient norm: inf
14: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 2048.0
14: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
11: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
15: Skipped batch, new scale: 2048.0
0: Gradient norm: inf
10: Skipped batch, new scale: 2048.0
9: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
1: Gradient norm: inf
8: Gradient norm: inf
9: Skipped batch, new scale: 2048.0
1: Skipped batch, new scale: 2048.0
8: Skipped batch, new scale: 2048.0
7: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
6: Gradient norm: inf
5: Gradient norm: inf
4: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
7: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
6: Skipped batch, new scale: 2048.0
4: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
15: TRAIN [2][920/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00092)	Tok/s 55141 (54019)	Loss/tok 3.2082 (3.1172)	Learning Rate [7.8125e-05]
14: TRAIN [2][920/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00091)	Tok/s 55207 (53902)	Loss/tok 3.3276 (3.1190)	Learning Rate [7.8125e-05]
0: TRAIN [2][920/3416]	Time 0.062 (0.058)	Data 0.00085 (0.00097)	Tok/s 54063 (52674)	Loss/tok 3.1005 (3.1308)	Learning Rate [7.8125e-05]
13: TRAIN [2][920/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00097)	Tok/s 55209 (53794)	Loss/tok 3.0196 (3.1188)	Learning Rate [7.8125e-05]
1: TRAIN [2][920/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00100)	Tok/s 54070 (52765)	Loss/tok 3.1525 (3.1161)	Learning Rate [7.8125e-05]
2: TRAIN [2][920/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00099)	Tok/s 54648 (52867)	Loss/tok 2.9797 (3.1144)	Learning Rate [7.8125e-05]
12: TRAIN [2][920/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00102)	Tok/s 55250 (53694)	Loss/tok 3.1069 (3.1189)	Learning Rate [7.8125e-05]
4: TRAIN [2][920/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00098)	Tok/s 55164 (53041)	Loss/tok 3.1173 (3.1211)	Learning Rate [7.8125e-05]
11: TRAIN [2][920/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00092)	Tok/s 55213 (53584)	Loss/tok 3.2298 (3.1237)	Learning Rate [7.8125e-05]
3: TRAIN [2][920/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00092)	Tok/s 55110 (52955)	Loss/tok 3.0575 (3.1215)	Learning Rate [7.8125e-05]
10: TRAIN [2][920/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00097)	Tok/s 55329 (53501)	Loss/tok 2.9962 (3.1083)	Learning Rate [7.8125e-05]
9: TRAIN [2][920/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00092)	Tok/s 55234 (53422)	Loss/tok 3.1577 (3.1145)	Learning Rate [7.8125e-05]
8: TRAIN [2][920/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00098)	Tok/s 55201 (53360)	Loss/tok 3.2786 (3.1238)	Learning Rate [7.8125e-05]
6: TRAIN [2][920/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00092)	Tok/s 55129 (53205)	Loss/tok 3.1615 (3.1268)	Learning Rate [7.8125e-05]
5: TRAIN [2][920/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00093)	Tok/s 55115 (53121)	Loss/tok 3.0635 (3.1205)	Learning Rate [7.8125e-05]
7: TRAIN [2][920/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00096)	Tok/s 55148 (53290)	Loss/tok 3.3197 (3.1202)	Learning Rate [7.8125e-05]
8: TRAIN [2][930/3416]	Time 0.066 (0.058)	Data 0.00106 (0.00098)	Tok/s 55211 (53435)	Loss/tok 3.1211 (3.1241)	Learning Rate [7.8125e-05]
6: TRAIN [2][930/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00092)	Tok/s 55277 (53279)	Loss/tok 3.1568 (3.1278)	Learning Rate [7.8125e-05]
7: TRAIN [2][930/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00096)	Tok/s 55221 (53364)	Loss/tok 3.2116 (3.1217)	Learning Rate [7.8125e-05]
10: TRAIN [2][930/3416]	Time 0.066 (0.058)	Data 0.00115 (0.00097)	Tok/s 55068 (53575)	Loss/tok 3.4501 (3.1099)	Learning Rate [7.8125e-05]
9: TRAIN [2][930/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00092)	Tok/s 55045 (53496)	Loss/tok 3.0479 (3.1149)	Learning Rate [7.8125e-05]
5: TRAIN [2][930/3416]	Time 0.066 (0.058)	Data 0.00112 (0.00093)	Tok/s 55207 (53195)	Loss/tok 3.2828 (3.1205)	Learning Rate [7.8125e-05]
4: TRAIN [2][930/3416]	Time 0.066 (0.058)	Data 0.00111 (0.00098)	Tok/s 55143 (53116)	Loss/tok 3.2256 (3.1215)	Learning Rate [7.8125e-05]
2: TRAIN [2][930/3416]	Time 0.066 (0.058)	Data 0.00103 (0.00099)	Tok/s 55039 (52943)	Loss/tok 3.2904 (3.1153)	Learning Rate [7.8125e-05]
3: TRAIN [2][930/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00091)	Tok/s 55058 (53031)	Loss/tok 3.4514 (3.1225)	Learning Rate [7.8125e-05]
12: TRAIN [2][930/3416]	Time 0.066 (0.058)	Data 0.00106 (0.00102)	Tok/s 54983 (53767)	Loss/tok 2.8400 (3.1193)	Learning Rate [7.8125e-05]
11: TRAIN [2][930/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00092)	Tok/s 54947 (53657)	Loss/tok 3.0588 (3.1245)	Learning Rate [7.8125e-05]
0: TRAIN [2][930/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00097)	Tok/s 54858 (52751)	Loss/tok 3.1394 (3.1318)	Learning Rate [7.8125e-05]
1: TRAIN [2][930/3416]	Time 0.066 (0.058)	Data 0.00107 (0.00100)	Tok/s 54863 (52841)	Loss/tok 3.1655 (3.1165)	Learning Rate [7.8125e-05]
15: TRAIN [2][930/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00092)	Tok/s 55436 (54091)	Loss/tok 3.3711 (3.1177)	Learning Rate [7.8125e-05]
14: TRAIN [2][930/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00091)	Tok/s 54836 (53974)	Loss/tok 3.2120 (3.1184)	Learning Rate [7.8125e-05]
13: TRAIN [2][930/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00097)	Tok/s 54823 (53867)	Loss/tok 3.1958 (3.1187)	Learning Rate [7.8125e-05]
7: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00096)	Tok/s 51924 (53444)	Loss/tok 3.2800 (3.1209)	Learning Rate [7.8125e-05]
8: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00098)	Tok/s 51887 (53515)	Loss/tok 3.3687 (3.1247)	Learning Rate [7.8125e-05]
9: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00079 (0.00092)	Tok/s 51916 (53577)	Loss/tok 2.8732 (3.1145)	Learning Rate [7.8125e-05]
6: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00092)	Tok/s 51843 (53359)	Loss/tok 3.0204 (3.1263)	Learning Rate [7.8125e-05]
5: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00082 (0.00093)	Tok/s 51795 (53276)	Loss/tok 2.9694 (3.1206)	Learning Rate [7.8125e-05]
4: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00098)	Tok/s 51805 (53197)	Loss/tok 3.1409 (3.1216)	Learning Rate [7.8125e-05]
10: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00097)	Tok/s 52742 (53656)	Loss/tok 3.2362 (3.1103)	Learning Rate [7.8125e-05]
3: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00082 (0.00091)	Tok/s 51787 (53113)	Loss/tok 3.2886 (3.1225)	Learning Rate [7.8125e-05]
11: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00092)	Tok/s 53019 (53738)	Loss/tok 3.1113 (3.1245)	Learning Rate [7.8125e-05]
2: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00085 (0.00099)	Tok/s 51798 (53026)	Loss/tok 3.1906 (3.1157)	Learning Rate [7.8125e-05]
1: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00100)	Tok/s 51790 (52924)	Loss/tok 3.0845 (3.1167)	Learning Rate [7.8125e-05]
0: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00299 (0.00097)	Tok/s 51807 (52834)	Loss/tok 3.0508 (3.1323)	Learning Rate [7.8125e-05]
13: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00083 (0.00097)	Tok/s 53050 (53948)	Loss/tok 3.3095 (3.1197)	Learning Rate [7.8125e-05]
14: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00091)	Tok/s 53002 (54054)	Loss/tok 3.2820 (3.1192)	Learning Rate [7.8125e-05]
12: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00099 (0.00102)	Tok/s 52932 (53848)	Loss/tok 3.3256 (3.1199)	Learning Rate [7.8125e-05]
15: TRAIN [2][940/3416]	Time 0.057 (0.058)	Data 0.00087 (0.00092)	Tok/s 53061 (54170)	Loss/tok 3.4236 (3.1174)	Learning Rate [7.8125e-05]
3: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00091)	Tok/s 32889 (53153)	Loss/tok 2.7870 (3.1223)	Learning Rate [7.8125e-05]
4: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00098)	Tok/s 32786 (53237)	Loss/tok 2.6750 (3.1217)	Learning Rate [7.8125e-05]
1: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00100)	Tok/s 32853 (52965)	Loss/tok 2.7365 (3.1158)	Learning Rate [7.8125e-05]
5: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00093)	Tok/s 32720 (53316)	Loss/tok 2.7930 (3.1207)	Learning Rate [7.8125e-05]
6: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 32619 (53398)	Loss/tok 2.8534 (3.1255)	Learning Rate [7.8125e-05]
0: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00097)	Tok/s 32851 (52877)	Loss/tok 2.9375 (3.1321)	Learning Rate [7.8125e-05]
15: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 34241 (54212)	Loss/tok 2.7466 (3.1168)	Learning Rate [7.8125e-05]
2: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00099)	Tok/s 32868 (53066)	Loss/tok 2.7847 (3.1154)	Learning Rate [7.8125e-05]
14: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00091)	Tok/s 34136 (54097)	Loss/tok 2.8470 (3.1190)	Learning Rate [7.8125e-05]
7: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00096)	Tok/s 32559 (53483)	Loss/tok 2.8591 (3.1204)	Learning Rate [7.8125e-05]
9: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00092)	Tok/s 32496 (53618)	Loss/tok 2.7568 (3.1143)	Learning Rate [7.8125e-05]
8: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00098)	Tok/s 32501 (53555)	Loss/tok 2.7190 (3.1249)	Learning Rate [7.8125e-05]
11: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00092)	Tok/s 33456 (53781)	Loss/tok 2.6843 (3.1239)	Learning Rate [7.8125e-05]
13: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 34046 (53992)	Loss/tok 2.7535 (3.1187)	Learning Rate [7.8125e-05]
10: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00097)	Tok/s 32461 (53697)	Loss/tok 2.5297 (3.1103)	Learning Rate [7.8125e-05]
12: TRAIN [2][950/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00102)	Tok/s 33911 (53892)	Loss/tok 2.7985 (3.1204)	Learning Rate [7.8125e-05]
6: TRAIN [2][960/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 69572 (53370)	Loss/tok 3.0386 (3.1249)	Learning Rate [7.8125e-05]
3: TRAIN [2][960/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00091)	Tok/s 69555 (53126)	Loss/tok 3.2908 (3.1224)	Learning Rate [7.8125e-05]
5: TRAIN [2][960/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00093)	Tok/s 69572 (53289)	Loss/tok 3.0830 (3.1205)	Learning Rate [7.8125e-05]
2: TRAIN [2][960/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00099)	Tok/s 68716 (53040)	Loss/tok 3.2280 (3.1159)	Learning Rate [7.8125e-05]
4: TRAIN [2][960/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00098)	Tok/s 69579 (53210)	Loss/tok 3.0913 (3.1217)	Learning Rate [7.8125e-05]
1: TRAIN [2][960/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 68416 (52939)	Loss/tok 3.2074 (3.1154)	Learning Rate [7.8125e-05]
8: TRAIN [2][960/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 69352 (53526)	Loss/tok 3.1822 (3.1245)	Learning Rate [7.8125e-05]
0: TRAIN [2][960/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 68562 (52852)	Loss/tok 3.3503 (3.1319)	Learning Rate [7.8125e-05]
7: TRAIN [2][960/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00096)	Tok/s 69429 (53454)	Loss/tok 3.2180 (3.1200)	Learning Rate [7.8125e-05]
9: TRAIN [2][960/3416]	Time 0.069 (0.058)	Data 0.00074 (0.00092)	Tok/s 69194 (53589)	Loss/tok 3.1648 (3.1138)	Learning Rate [7.8125e-05]
10: TRAIN [2][960/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00097)	Tok/s 69164 (53667)	Loss/tok 3.2276 (3.1106)	Learning Rate [7.8125e-05]
15: TRAIN [2][960/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00092)	Tok/s 69734 (54184)	Loss/tok 3.4146 (3.1170)	Learning Rate [7.8125e-05]
14: TRAIN [2][960/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 69057 (54069)	Loss/tok 3.1580 (3.1192)	Learning Rate [7.8125e-05]
13: TRAIN [2][960/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 68941 (53964)	Loss/tok 3.2005 (3.1193)	Learning Rate [7.8125e-05]
11: TRAIN [2][960/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 69024 (53750)	Loss/tok 3.1556 (3.1243)	Learning Rate [7.8125e-05]
12: TRAIN [2][960/3416]	Time 0.070 (0.058)	Data 0.00124 (0.00102)	Tok/s 68945 (53863)	Loss/tok 3.1229 (3.1198)	Learning Rate [7.8125e-05]
8: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00098)	Tok/s 45144 (53585)	Loss/tok 2.9525 (3.1243)	Learning Rate [7.8125e-05]
9: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 45135 (53647)	Loss/tok 3.0397 (3.1136)	Learning Rate [7.8125e-05]
7: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00096)	Tok/s 44950 (53514)	Loss/tok 3.1010 (3.1187)	Learning Rate [7.8125e-05]
10: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00097)	Tok/s 45186 (53725)	Loss/tok 2.9041 (3.1095)	Learning Rate [7.8125e-05]
11: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00092)	Tok/s 45104 (53809)	Loss/tok 3.1259 (3.1238)	Learning Rate [7.8125e-05]
5: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00093)	Tok/s 44762 (53350)	Loss/tok 2.9524 (3.1208)	Learning Rate [7.8125e-05]
4: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00098)	Tok/s 44702 (53270)	Loss/tok 2.7905 (3.1209)	Learning Rate [7.8125e-05]
3: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00091)	Tok/s 44437 (53186)	Loss/tok 2.7780 (3.1221)	Learning Rate [7.8125e-05]
1: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00100)	Tok/s 43466 (52996)	Loss/tok 3.2833 (3.1160)	Learning Rate [7.8125e-05]
13: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 45020 (54022)	Loss/tok 2.8578 (3.1191)	Learning Rate [7.8125e-05]
12: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00102)	Tok/s 45101 (53922)	Loss/tok 3.0865 (3.1194)	Learning Rate [7.8125e-05]
2: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00099)	Tok/s 43404 (53097)	Loss/tok 2.9232 (3.1161)	Learning Rate [7.8125e-05]
14: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00091)	Tok/s 44942 (54127)	Loss/tok 2.8263 (3.1188)	Learning Rate [7.8125e-05]
0: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 43415 (52910)	Loss/tok 3.1306 (3.1323)	Learning Rate [7.8125e-05]
15: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00092)	Tok/s 44810 (54243)	Loss/tok 3.1318 (3.1170)	Learning Rate [7.8125e-05]
6: TRAIN [2][970/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00092)	Tok/s 44892 (53430)	Loss/tok 2.8975 (3.1249)	Learning Rate [7.8125e-05]
3: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00091)	Tok/s 53921 (53135)	Loss/tok 3.2185 (3.1220)	Learning Rate [7.8125e-05]
2: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00099)	Tok/s 53887 (53045)	Loss/tok 3.1682 (3.1161)	Learning Rate [7.8125e-05]
1: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00100)	Tok/s 53910 (52940)	Loss/tok 3.7203 (3.1161)	Learning Rate [7.8125e-05]
4: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00098)	Tok/s 53891 (53220)	Loss/tok 3.1841 (3.1204)	Learning Rate [7.8125e-05]
5: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00109 (0.00093)	Tok/s 53909 (53302)	Loss/tok 3.2985 (3.1203)	Learning Rate [7.8125e-05]
0: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00097)	Tok/s 53905 (52852)	Loss/tok 3.0256 (3.1320)	Learning Rate [7.8125e-05]
15: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00110 (0.00092)	Tok/s 54901 (54199)	Loss/tok 3.0388 (3.1172)	Learning Rate [7.8125e-05]
14: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00091)	Tok/s 54896 (54083)	Loss/tok 3.2193 (3.1177)	Learning Rate [7.8125e-05]
8: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00131 (0.00098)	Tok/s 53936 (53538)	Loss/tok 3.1753 (3.1237)	Learning Rate [7.8125e-05]
9: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00092)	Tok/s 53945 (53600)	Loss/tok 3.2722 (3.1131)	Learning Rate [7.8125e-05]
7: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00108 (0.00096)	Tok/s 53961 (53466)	Loss/tok 3.1502 (3.1188)	Learning Rate [7.8125e-05]
13: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00096)	Tok/s 54902 (53976)	Loss/tok 3.3151 (3.1193)	Learning Rate [7.8125e-05]
11: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00092)	Tok/s 54871 (53762)	Loss/tok 3.0867 (3.1230)	Learning Rate [7.8125e-05]
12: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00102)	Tok/s 54887 (53876)	Loss/tok 3.3801 (3.1194)	Learning Rate [7.8125e-05]
10: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00097)	Tok/s 54402 (53679)	Loss/tok 3.0510 (3.1093)	Learning Rate [7.8125e-05]
6: TRAIN [2][980/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00092)	Tok/s 53910 (53382)	Loss/tok 3.1999 (3.1246)	Learning Rate [7.8125e-05]
5: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00093)	Tok/s 69899 (53347)	Loss/tok 3.1825 (3.1203)	Learning Rate [7.8125e-05]
3: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00091)	Tok/s 69960 (53177)	Loss/tok 3.0831 (3.1224)	Learning Rate [7.8125e-05]
2: TRAIN [2][990/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00099)	Tok/s 70023 (53085)	Loss/tok 3.4076 (3.1168)	Learning Rate [7.8125e-05]
4: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00098)	Tok/s 69924 (53264)	Loss/tok 3.2953 (3.1205)	Learning Rate [7.8125e-05]
15: TRAIN [2][990/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00092)	Tok/s 70988 (54252)	Loss/tok 3.2020 (3.1174)	Learning Rate [7.8125e-05]
9: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 69805 (53648)	Loss/tok 3.1113 (3.1133)	Learning Rate [7.8125e-05]
7: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00096)	Tok/s 69675 (53513)	Loss/tok 3.3506 (3.1197)	Learning Rate [7.8125e-05]
8: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 69656 (53586)	Loss/tok 3.4790 (3.1234)	Learning Rate [7.8125e-05]
14: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00091)	Tok/s 70896 (54134)	Loss/tok 3.1171 (3.1177)	Learning Rate [7.8125e-05]
0: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 69903 (52888)	Loss/tok 3.0676 (3.1313)	Learning Rate [7.8125e-05]
1: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00100)	Tok/s 69798 (52978)	Loss/tok 3.3092 (3.1159)	Learning Rate [7.8125e-05]
11: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 70383 (53810)	Loss/tok 3.1242 (3.1226)	Learning Rate [7.8125e-05]
13: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 70731 (54025)	Loss/tok 3.0458 (3.1188)	Learning Rate [7.8125e-05]
6: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 69855 (53429)	Loss/tok 3.1393 (3.1242)	Learning Rate [7.8125e-05]
10: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 69610 (53727)	Loss/tok 3.0069 (3.1093)	Learning Rate [7.8125e-05]
12: TRAIN [2][990/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00102)	Tok/s 70615 (53925)	Loss/tok 3.3051 (3.1195)	Learning Rate [7.8125e-05]
1: TRAIN [2][1000/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00100)	Tok/s 53153 (52951)	Loss/tok 3.1520 (3.1157)	Learning Rate [7.8125e-05]
0: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00097)	Tok/s 53033 (52862)	Loss/tok 2.9621 (3.1305)	Learning Rate [7.8125e-05]
2: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00099)	Tok/s 52938 (53058)	Loss/tok 3.0798 (3.1165)	Learning Rate [7.8125e-05]
3: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00103 (0.00091)	Tok/s 52857 (53153)	Loss/tok 3.2791 (3.1221)	Learning Rate [7.8125e-05]
6: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00092)	Tok/s 52763 (53403)	Loss/tok 3.1780 (3.1238)	Learning Rate [7.8125e-05]
4: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00098)	Tok/s 52769 (53240)	Loss/tok 3.3011 (3.1196)	Learning Rate [7.8125e-05]
14: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00091)	Tok/s 53837 (54110)	Loss/tok 3.2697 (3.1174)	Learning Rate [7.8125e-05]
12: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00102)	Tok/s 52968 (53900)	Loss/tok 3.1005 (3.1184)	Learning Rate [7.8125e-05]
5: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00110 (0.00093)	Tok/s 52727 (53321)	Loss/tok 3.0575 (3.1196)	Learning Rate [7.8125e-05]
13: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00096)	Tok/s 52911 (54000)	Loss/tok 3.3176 (3.1185)	Learning Rate [7.8125e-05]
15: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00106 (0.00092)	Tok/s 54078 (54227)	Loss/tok 3.1625 (3.1170)	Learning Rate [7.8125e-05]
11: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00092)	Tok/s 52862 (53785)	Loss/tok 3.0629 (3.1226)	Learning Rate [7.8125e-05]
9: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00092)	Tok/s 52655 (53624)	Loss/tok 3.2937 (3.1137)	Learning Rate [7.8125e-05]
7: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00112 (0.00096)	Tok/s 52643 (53487)	Loss/tok 3.4881 (3.1194)	Learning Rate [7.8125e-05]
10: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00097)	Tok/s 52754 (53702)	Loss/tok 3.1408 (3.1089)	Learning Rate [7.8125e-05]
8: TRAIN [2][1000/3416]	Time 0.062 (0.058)	Data 0.00108 (0.00098)	Tok/s 52525 (53559)	Loss/tok 2.9884 (3.1230)	Learning Rate [7.8125e-05]
2: TRAIN [2][1010/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00099)	Tok/s 52619 (53033)	Loss/tok 3.0938 (3.1165)	Learning Rate [7.8125e-05]
0: TRAIN [2][1010/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00097)	Tok/s 52444 (52838)	Loss/tok 3.4158 (3.1309)	Learning Rate [7.8125e-05]
4: TRAIN [2][1010/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00098)	Tok/s 52582 (53214)	Loss/tok 3.0655 (3.1192)	Learning Rate [7.8125e-05]
3: TRAIN [2][1010/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00091)	Tok/s 52535 (53128)	Loss/tok 3.1560 (3.1215)	Learning Rate [7.8125e-05]
15: TRAIN [2][1010/3416]	Time 0.064 (0.058)	Data 0.00107 (0.00092)	Tok/s 53381 (54201)	Loss/tok 3.2344 (3.1166)	Learning Rate [7.8125e-05]
5: TRAIN [2][1010/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00093)	Tok/s 53553 (53297)	Loss/tok 2.9309 (3.1194)	Learning Rate [7.8125e-05]
6: TRAIN [2][1010/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00092)	Tok/s 53565 (53378)	Loss/tok 3.1672 (3.1234)	Learning Rate [7.8125e-05]
14: TRAIN [2][1010/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00091)	Tok/s 53354 (54086)	Loss/tok 3.1188 (3.1175)	Learning Rate [7.8125e-05]
13: TRAIN [2][1010/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00096)	Tok/s 53387 (53976)	Loss/tok 3.3779 (3.1190)	Learning Rate [7.8125e-05]
11: TRAIN [2][1010/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00092)	Tok/s 53310 (53761)	Loss/tok 3.1679 (3.1226)	Learning Rate [7.8125e-05]
9: TRAIN [2][1010/3416]	Time 0.064 (0.058)	Data 0.00080 (0.00091)	Tok/s 53335 (53600)	Loss/tok 3.0552 (3.1134)	Learning Rate [7.8125e-05]
7: TRAIN [2][1010/3416]	Time 0.063 (0.058)	Data 0.00106 (0.00096)	Tok/s 53524 (53464)	Loss/tok 3.0519 (3.1191)	Learning Rate [7.8125e-05]
12: TRAIN [2][1010/3416]	Time 0.064 (0.058)	Data 0.00141 (0.00102)	Tok/s 53347 (53876)	Loss/tok 3.3316 (3.1181)	Learning Rate [7.8125e-05]
8: TRAIN [2][1010/3416]	Time 0.064 (0.058)	Data 0.00107 (0.00098)	Tok/s 53340 (53537)	Loss/tok 3.1329 (3.1224)	Learning Rate [7.8125e-05]
10: TRAIN [2][1010/3416]	Time 0.064 (0.058)	Data 0.00084 (0.00097)	Tok/s 53339 (53679)	Loss/tok 3.2013 (3.1090)	Learning Rate [7.8125e-05]
1: TRAIN [2][1010/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00100)	Tok/s 51663 (52925)	Loss/tok 3.0861 (3.1150)	Learning Rate [7.8125e-05]
15: TRAIN [2][1020/3416]	Time 0.047 (0.058)	Data 0.00077 (0.00092)	Tok/s 33891 (54194)	Loss/tok 2.8024 (3.1170)	Learning Rate [7.8125e-05]
14: TRAIN [2][1020/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00091)	Tok/s 33897 (54079)	Loss/tok 3.0073 (3.1183)	Learning Rate [7.8125e-05]
0: TRAIN [2][1020/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00097)	Tok/s 32411 (52831)	Loss/tok 2.8302 (3.1307)	Learning Rate [7.8125e-05]
13: TRAIN [2][1020/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00096)	Tok/s 33864 (53968)	Loss/tok 2.7058 (3.1190)	Learning Rate [7.8125e-05]
11: TRAIN [2][1020/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00092)	Tok/s 33874 (53754)	Loss/tok 2.8619 (3.1230)	Learning Rate [7.8125e-05]
1: TRAIN [2][1020/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00100)	Tok/s 32313 (52919)	Loss/tok 2.6619 (3.1154)	Learning Rate [7.8125e-05]
2: TRAIN [2][1020/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00099)	Tok/s 32281 (53026)	Loss/tok 2.6924 (3.1167)	Learning Rate [7.8125e-05]
3: TRAIN [2][1020/3416]	Time 0.048 (0.058)	Data 0.00075 (0.00091)	Tok/s 32299 (53121)	Loss/tok 2.8640 (3.1211)	Learning Rate [7.8125e-05]
12: TRAIN [2][1020/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00102)	Tok/s 33814 (53869)	Loss/tok 2.6262 (3.1180)	Learning Rate [7.8125e-05]
4: TRAIN [2][1020/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00098)	Tok/s 32342 (53207)	Loss/tok 2.8987 (3.1196)	Learning Rate [7.8125e-05]
10: TRAIN [2][1020/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00097)	Tok/s 33233 (53672)	Loss/tok 2.9394 (3.1099)	Learning Rate [7.8125e-05]
9: TRAIN [2][1020/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00091)	Tok/s 32477 (53592)	Loss/tok 2.7647 (3.1138)	Learning Rate [7.8125e-05]
5: TRAIN [2][1020/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00093)	Tok/s 32309 (53289)	Loss/tok 2.7987 (3.1199)	Learning Rate [7.8125e-05]
7: TRAIN [2][1020/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00096)	Tok/s 32414 (53454)	Loss/tok 2.9012 (3.1189)	Learning Rate [7.8125e-05]
8: TRAIN [2][1020/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00098)	Tok/s 32330 (53527)	Loss/tok 2.7118 (3.1228)	Learning Rate [7.8125e-05]
6: TRAIN [2][1020/3416]	Time 0.048 (0.058)	Data 0.00122 (0.00092)	Tok/s 32299 (53368)	Loss/tok 2.7868 (3.1231)	Learning Rate [7.8125e-05]
7: TRAIN [2][1030/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00096)	Tok/s 31189 (53444)	Loss/tok 2.7966 (3.1190)	Learning Rate [7.8125e-05]
6: TRAIN [2][1030/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00092)	Tok/s 31193 (53357)	Loss/tok 2.7945 (3.1228)	Learning Rate [7.8125e-05]
8: TRAIN [2][1030/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00098)	Tok/s 31152 (53516)	Loss/tok 2.6308 (3.1233)	Learning Rate [7.8125e-05]
9: TRAIN [2][1030/3416]	Time 0.045 (0.058)	Data 0.00076 (0.00091)	Tok/s 31071 (53580)	Loss/tok 2.8205 (3.1138)	Learning Rate [7.8125e-05]
5: TRAIN [2][1030/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00093)	Tok/s 31186 (53278)	Loss/tok 2.6457 (3.1195)	Learning Rate [7.8125e-05]
4: TRAIN [2][1030/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00098)	Tok/s 31098 (53196)	Loss/tok 2.6944 (3.1193)	Learning Rate [7.8125e-05]
10: TRAIN [2][1030/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00097)	Tok/s 31012 (53660)	Loss/tok 2.7852 (3.1105)	Learning Rate [7.8125e-05]
3: TRAIN [2][1030/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00091)	Tok/s 30993 (53110)	Loss/tok 2.8427 (3.1205)	Learning Rate [7.8125e-05]
2: TRAIN [2][1030/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00099)	Tok/s 29873 (53015)	Loss/tok 2.5205 (3.1164)	Learning Rate [7.8125e-05]
11: TRAIN [2][1030/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00092)	Tok/s 30902 (53743)	Loss/tok 2.7456 (3.1239)	Learning Rate [7.8125e-05]
1: TRAIN [2][1030/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00100)	Tok/s 29447 (52908)	Loss/tok 2.6081 (3.1150)	Learning Rate [7.8125e-05]
12: TRAIN [2][1030/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00102)	Tok/s 30785 (53858)	Loss/tok 2.4811 (3.1185)	Learning Rate [7.8125e-05]
13: TRAIN [2][1030/3416]	Time 0.046 (0.058)	Data 0.00105 (0.00096)	Tok/s 30788 (53957)	Loss/tok 2.5882 (3.1187)	Learning Rate [7.8125e-05]
0: TRAIN [2][1030/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00097)	Tok/s 29388 (52820)	Loss/tok 2.5046 (3.1308)	Learning Rate [7.8125e-05]
15: TRAIN [2][1030/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00092)	Tok/s 31117 (54182)	Loss/tok 2.7495 (3.1174)	Learning Rate [7.8125e-05]
14: TRAIN [2][1030/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00091)	Tok/s 30678 (54067)	Loss/tok 2.5967 (3.1176)	Learning Rate [7.8125e-05]
13: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00096)	Tok/s 53190 (53905)	Loss/tok 2.9991 (3.1190)	Learning Rate [7.8125e-05]
12: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00102)	Tok/s 53220 (53807)	Loss/tok 3.1368 (3.1183)	Learning Rate [7.8125e-05]
11: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00081 (0.00092)	Tok/s 53206 (53692)	Loss/tok 3.3592 (3.1240)	Learning Rate [7.8125e-05]
14: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00091)	Tok/s 53767 (54014)	Loss/tok 3.3166 (3.1180)	Learning Rate [7.8125e-05]
15: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00092)	Tok/s 54322 (54128)	Loss/tok 3.2383 (3.1174)	Learning Rate [7.8125e-05]
0: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00097)	Tok/s 53162 (52771)	Loss/tok 2.9790 (3.1302)	Learning Rate [7.8125e-05]
10: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00097)	Tok/s 53161 (53608)	Loss/tok 2.9629 (3.1095)	Learning Rate [7.8125e-05]
9: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00091)	Tok/s 53201 (53526)	Loss/tok 3.1397 (3.1138)	Learning Rate [7.8125e-05]
8: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00098)	Tok/s 53212 (53462)	Loss/tok 3.1826 (3.1233)	Learning Rate [7.8125e-05]
6: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00092)	Tok/s 53218 (53304)	Loss/tok 3.2377 (3.1227)	Learning Rate [7.8125e-05]
2: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00099)	Tok/s 53051 (52963)	Loss/tok 3.0826 (3.1161)	Learning Rate [7.8125e-05]
7: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00097)	Tok/s 53170 (53390)	Loss/tok 3.2330 (3.1190)	Learning Rate [7.8125e-05]
3: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00080 (0.00091)	Tok/s 53080 (53057)	Loss/tok 2.7858 (3.1199)	Learning Rate [7.8125e-05]
5: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 53148 (53225)	Loss/tok 3.1087 (3.1188)	Learning Rate [7.8125e-05]
1: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00100)	Tok/s 53039 (52858)	Loss/tok 3.1852 (3.1150)	Learning Rate [7.8125e-05]
4: TRAIN [2][1040/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00098)	Tok/s 53030 (53143)	Loss/tok 3.0353 (3.1194)	Learning Rate [7.8125e-05]
10: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
14: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00091)	Tok/s 51244 (53978)	Loss/tok 2.8399 (3.1175)	Learning Rate [7.8125e-05]
15: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00092)	Tok/s 51329 (54092)	Loss/tok 3.1102 (3.1168)	Learning Rate [7.8125e-05]
0: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00097)	Tok/s 51263 (52737)	Loss/tok 3.1734 (3.1301)	Learning Rate [7.8125e-05]
1: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00117 (0.00100)	Tok/s 51414 (52824)	Loss/tok 2.9233 (3.1142)	Learning Rate [7.8125e-05]
13: TRAIN [2][1050/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00096)	Tok/s 52300 (53870)	Loss/tok 2.9220 (3.1192)	Learning Rate [7.8125e-05]
2: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00108 (0.00099)	Tok/s 51404 (52930)	Loss/tok 2.9294 (3.1162)	Learning Rate [7.8125e-05]
11: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00092)	Tok/s 51322 (53658)	Loss/tok 3.0893 (3.1245)	Learning Rate [7.8125e-05]
3: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00091)	Tok/s 51436 (53025)	Loss/tok 2.8772 (3.1202)	Learning Rate [7.8125e-05]
12: TRAIN [2][1050/3416]	Time 0.045 (0.058)	Data 0.00138 (0.00102)	Tok/s 52329 (53773)	Loss/tok 3.0268 (3.1180)	Learning Rate [7.8125e-05]
4: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00106 (0.00098)	Tok/s 51528 (53112)	Loss/tok 2.8768 (3.1187)	Learning Rate [7.8125e-05]
10: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00097)	Tok/s 51350 (53574)	Loss/tok 3.0029 (3.1094)	Learning Rate [7.8125e-05]
8: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00098)	Tok/s 51255 (53428)	Loss/tok 3.0583 (3.1231)	Learning Rate [7.8125e-05]
5: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00093)	Tok/s 51435 (53194)	Loss/tok 3.2239 (3.1192)	Learning Rate [7.8125e-05]
6: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00092)	Tok/s 51410 (53271)	Loss/tok 3.2132 (3.1228)	Learning Rate [7.8125e-05]
7: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00097)	Tok/s 51376 (53357)	Loss/tok 2.9793 (3.1190)	Learning Rate [7.8125e-05]
9: TRAIN [2][1050/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00091)	Tok/s 51021 (53491)	Loss/tok 2.8348 (3.1142)	Learning Rate [7.8125e-05]
3: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00091)	Tok/s 57338 (53001)	Loss/tok 3.3508 (3.1206)	Learning Rate [7.8125e-05]
2: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00099)	Tok/s 57359 (52907)	Loss/tok 3.2614 (3.1163)	Learning Rate [7.8125e-05]
4: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00113 (0.00098)	Tok/s 57266 (53087)	Loss/tok 3.2001 (3.1189)	Learning Rate [7.8125e-05]
1: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00108 (0.00100)	Tok/s 57373 (52801)	Loss/tok 3.2644 (3.1147)	Learning Rate [7.8125e-05]
0: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00097)	Tok/s 57376 (52714)	Loss/tok 3.1610 (3.1299)	Learning Rate [7.8125e-05]
5: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00093)	Tok/s 57268 (53168)	Loss/tok 3.2565 (3.1197)	Learning Rate [7.8125e-05]
6: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00092)	Tok/s 57266 (53245)	Loss/tok 3.4594 (3.1236)	Learning Rate [7.8125e-05]
15: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00108 (0.00092)	Tok/s 58364 (54065)	Loss/tok 3.1234 (3.1167)	Learning Rate [7.8125e-05]
7: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00097)	Tok/s 57320 (53330)	Loss/tok 3.2291 (3.1191)	Learning Rate [7.8125e-05]
8: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00098)	Tok/s 57289 (53400)	Loss/tok 3.3666 (3.1229)	Learning Rate [7.8125e-05]
14: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00091)	Tok/s 58315 (53952)	Loss/tok 3.3888 (3.1174)	Learning Rate [7.8125e-05]
9: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00091)	Tok/s 57547 (53464)	Loss/tok 3.2665 (3.1143)	Learning Rate [7.8125e-05]
13: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00096)	Tok/s 58306 (53845)	Loss/tok 3.4368 (3.1200)	Learning Rate [7.8125e-05]
12: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00102)	Tok/s 58342 (53748)	Loss/tok 3.3624 (3.1182)	Learning Rate [7.8125e-05]
10: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00097)	Tok/s 58207 (53548)	Loss/tok 3.3088 (3.1095)	Learning Rate [7.8125e-05]
11: TRAIN [2][1060/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 58237 (53633)	Loss/tok 3.4494 (3.1251)	Learning Rate [7.8125e-05]
9: TRAIN [2][1070/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00091)	Tok/s 73076 (53482)	Loss/tok 3.2458 (3.1147)	Learning Rate [7.8125e-05]
6: TRAIN [2][1070/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00092)	Tok/s 72740 (53263)	Loss/tok 3.2904 (3.1238)	Learning Rate [7.8125e-05]
8: TRAIN [2][1070/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 72836 (53419)	Loss/tok 3.2318 (3.1230)	Learning Rate [7.8125e-05]
7: TRAIN [2][1070/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00097)	Tok/s 72774 (53349)	Loss/tok 3.2427 (3.1192)	Learning Rate [7.8125e-05]
10: TRAIN [2][1070/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 73108 (53567)	Loss/tok 2.9875 (3.1093)	Learning Rate [7.8125e-05]
11: TRAIN [2][1070/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 73920 (53653)	Loss/tok 3.2063 (3.1250)	Learning Rate [7.8125e-05]
5: TRAIN [2][1070/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 72619 (53184)	Loss/tok 2.9787 (3.1191)	Learning Rate [7.8125e-05]
4: TRAIN [2][1070/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00098)	Tok/s 72584 (53101)	Loss/tok 3.0932 (3.1187)	Learning Rate [7.8125e-05]
13: TRAIN [2][1070/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00096)	Tok/s 73934 (53864)	Loss/tok 3.1039 (3.1201)	Learning Rate [7.8125e-05]
14: TRAIN [2][1070/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 73855 (53971)	Loss/tok 2.9738 (3.1173)	Learning Rate [7.8125e-05]
3: TRAIN [2][1070/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00091)	Tok/s 72637 (53014)	Loss/tok 3.2649 (3.1204)	Learning Rate [7.8125e-05]
12: TRAIN [2][1070/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00102)	Tok/s 73931 (53768)	Loss/tok 3.1700 (3.1171)	Learning Rate [7.8125e-05]
15: TRAIN [2][1070/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 73903 (54086)	Loss/tok 3.2970 (3.1169)	Learning Rate [7.8125e-05]
2: TRAIN [2][1070/3416]	Time 0.070 (0.058)	Data 0.00115 (0.00099)	Tok/s 72665 (52917)	Loss/tok 3.1102 (3.1162)	Learning Rate [7.8125e-05]
1: TRAIN [2][1070/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00100)	Tok/s 72685 (52809)	Loss/tok 3.1765 (3.1146)	Learning Rate [7.8125e-05]
0: TRAIN [2][1070/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 72192 (52719)	Loss/tok 3.0524 (3.1303)	Learning Rate [7.8125e-05]
7: Gradient norm: inf
3: Gradient norm: inf
8: Gradient norm: inf
6: Gradient norm: inf
7: Skipped batch, new scale: 2048.0
2: Gradient norm: inf
4: Gradient norm: inf
9: Gradient norm: inf
5: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
6: Skipped batch, new scale: 2048.0
8: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
4: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
1: Gradient norm: inf
10: Gradient norm: inf
0: Gradient norm: inf
15: Gradient norm: inf
11: Gradient norm: inf
10: Skipped batch, new scale: 2048.0
14: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
0: Skipped batch, new scale: 2048.0
15: Skipped batch, new scale: 2048.0
11: Skipped batch, new scale: 2048.0
13: Gradient norm: inf
12: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
13: Skipped batch, new scale: 2048.0
12: Skipped batch, new scale: 2048.0
4: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00098)	Tok/s 55313 (53143)	Loss/tok 3.2392 (3.1187)	Learning Rate [7.8125e-05]
5: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00093)	Tok/s 55318 (53225)	Loss/tok 3.2278 (3.1190)	Learning Rate [7.8125e-05]
6: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00092)	Tok/s 55205 (53304)	Loss/tok 3.1414 (3.1232)	Learning Rate [7.8125e-05]
7: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00097)	Tok/s 55173 (53389)	Loss/tok 3.1126 (3.1192)	Learning Rate [7.8125e-05]
3: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00091)	Tok/s 55307 (53054)	Loss/tok 3.1046 (3.1203)	Learning Rate [7.8125e-05]
2: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00099)	Tok/s 55315 (52958)	Loss/tok 3.3084 (3.1163)	Learning Rate [7.8125e-05]
8: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00098)	Tok/s 55135 (53459)	Loss/tok 3.2589 (3.1233)	Learning Rate [7.8125e-05]
1: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00100)	Tok/s 55304 (52850)	Loss/tok 3.2560 (3.1142)	Learning Rate [7.8125e-05]
9: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00091)	Tok/s 55144 (53521)	Loss/tok 3.2151 (3.1151)	Learning Rate [7.8125e-05]
0: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00097)	Tok/s 55326 (52759)	Loss/tok 3.4182 (3.1296)	Learning Rate [7.8125e-05]
11: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00092)	Tok/s 55230 (53691)	Loss/tok 3.4650 (3.1248)	Learning Rate [7.8125e-05]
15: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00092)	Tok/s 55421 (54123)	Loss/tok 3.0091 (3.1170)	Learning Rate [7.8125e-05]
10: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00097)	Tok/s 55157 (53606)	Loss/tok 3.2646 (3.1103)	Learning Rate [7.8125e-05]
12: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00102)	Tok/s 55230 (53806)	Loss/tok 2.9908 (3.1175)	Learning Rate [7.8125e-05]
14: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00091)	Tok/s 55287 (54008)	Loss/tok 3.2959 (3.1171)	Learning Rate [7.8125e-05]
13: TRAIN [2][1080/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00096)	Tok/s 55173 (53901)	Loss/tok 3.2158 (3.1203)	Learning Rate [7.8125e-05]
4: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00098)	Tok/s 31577 (53153)	Loss/tok 2.8310 (3.1191)	Learning Rate [7.8125e-05]
3: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00091)	Tok/s 31591 (53065)	Loss/tok 3.0904 (3.1205)	Learning Rate [7.8125e-05]
6: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00092)	Tok/s 31445 (53313)	Loss/tok 2.7521 (3.1226)	Learning Rate [7.8125e-05]
2: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00099)	Tok/s 31648 (52970)	Loss/tok 2.6789 (3.1161)	Learning Rate [7.8125e-05]
5: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00093)	Tok/s 31480 (53234)	Loss/tok 2.8467 (3.1195)	Learning Rate [7.8125e-05]
7: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00097)	Tok/s 31386 (53398)	Loss/tok 2.7620 (3.1189)	Learning Rate [7.8125e-05]
15: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00092)	Tok/s 32854 (54130)	Loss/tok 2.8455 (3.1164)	Learning Rate [7.8125e-05]
0: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00097)	Tok/s 31564 (52772)	Loss/tok 2.6509 (3.1292)	Learning Rate [7.8125e-05]
8: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00098)	Tok/s 31371 (53467)	Loss/tok 2.8998 (3.1232)	Learning Rate [7.8125e-05]
9: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00091)	Tok/s 31391 (53530)	Loss/tok 2.6136 (3.1155)	Learning Rate [7.8125e-05]
1: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00100)	Tok/s 31546 (52862)	Loss/tok 2.6821 (3.1142)	Learning Rate [7.8125e-05]
14: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00091)	Tok/s 32812 (54016)	Loss/tok 2.9632 (3.1170)	Learning Rate [7.8125e-05]
10: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00097)	Tok/s 32063 (53614)	Loss/tok 2.6612 (3.1104)	Learning Rate [7.8125e-05]
11: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00092)	Tok/s 32659 (53701)	Loss/tok 2.7214 (3.1254)	Learning Rate [7.8125e-05]
13: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00096)	Tok/s 32718 (53909)	Loss/tok 2.8813 (3.1210)	Learning Rate [7.8125e-05]
12: TRAIN [2][1090/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00102)	Tok/s 32672 (53815)	Loss/tok 3.0760 (3.1181)	Learning Rate [7.8125e-05]
13: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 76121 (53961)	Loss/tok 3.2210 (3.1212)	Learning Rate [7.8125e-05]
14: TRAIN [2][1100/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00091)	Tok/s 76613 (54068)	Loss/tok 3.1525 (3.1167)	Learning Rate [7.8125e-05]
10: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 76160 (53665)	Loss/tok 3.0264 (3.1105)	Learning Rate [7.8125e-05]
12: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00102)	Tok/s 76092 (53867)	Loss/tok 3.0044 (3.1177)	Learning Rate [7.8125e-05]
11: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 75976 (53752)	Loss/tok 3.0294 (3.1256)	Learning Rate [7.8125e-05]
9: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00091)	Tok/s 75377 (53579)	Loss/tok 3.0765 (3.1164)	Learning Rate [7.8125e-05]
0: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 75169 (52822)	Loss/tok 3.0955 (3.1291)	Learning Rate [7.8125e-05]
1: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00100)	Tok/s 75173 (52912)	Loss/tok 2.9524 (3.1151)	Learning Rate [7.8125e-05]
8: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 75141 (53517)	Loss/tok 2.9040 (3.1222)	Learning Rate [7.8125e-05]
2: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00113 (0.00099)	Tok/s 75152 (53020)	Loss/tok 3.0513 (3.1164)	Learning Rate [7.8125e-05]
3: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00091)	Tok/s 75073 (53116)	Loss/tok 2.9761 (3.1209)	Learning Rate [7.8125e-05]
6: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 75186 (53363)	Loss/tok 3.1965 (3.1229)	Learning Rate [7.8125e-05]
4: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00098)	Tok/s 75225 (53204)	Loss/tok 2.8541 (3.1190)	Learning Rate [7.8125e-05]
7: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 75136 (53448)	Loss/tok 3.2955 (3.1199)	Learning Rate [7.8125e-05]
5: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00093)	Tok/s 75192 (53285)	Loss/tok 2.9548 (3.1191)	Learning Rate [7.8125e-05]
15: TRAIN [2][1100/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 76043 (54181)	Loss/tok 3.0429 (3.1168)	Learning Rate [7.8125e-05]
14: TRAIN [2][1110/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00091)	Tok/s 58243 (54112)	Loss/tok 3.1912 (3.1167)	Learning Rate [7.8125e-05]
1: TRAIN [2][1110/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 58231 (52959)	Loss/tok 3.2004 (3.1147)	Learning Rate [7.8125e-05]
2: TRAIN [2][1110/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00099)	Tok/s 58280 (53066)	Loss/tok 3.1834 (3.1165)	Learning Rate [7.8125e-05]
3: TRAIN [2][1110/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00091)	Tok/s 58234 (53162)	Loss/tok 3.0989 (3.1206)	Learning Rate [7.8125e-05]
13: TRAIN [2][1110/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00096)	Tok/s 58030 (54004)	Loss/tok 3.0287 (3.1205)	Learning Rate [7.8125e-05]
6: TRAIN [2][1110/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00092)	Tok/s 58092 (53409)	Loss/tok 3.1462 (3.1233)	Learning Rate [7.8125e-05]
0: TRAIN [2][1110/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00097)	Tok/s 58116 (52870)	Loss/tok 3.1011 (3.1294)	Learning Rate [7.8125e-05]
11: TRAIN [2][1110/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00092)	Tok/s 58016 (53795)	Loss/tok 3.1307 (3.1254)	Learning Rate [7.8125e-05]
4: TRAIN [2][1110/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00098)	Tok/s 58158 (53250)	Loss/tok 3.1695 (3.1191)	Learning Rate [7.8125e-05]
9: TRAIN [2][1110/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00091)	Tok/s 57946 (53623)	Loss/tok 3.3500 (3.1166)	Learning Rate [7.8125e-05]
5: TRAIN [2][1110/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00093)	Tok/s 58068 (53330)	Loss/tok 3.1256 (3.1186)	Learning Rate [7.8125e-05]
12: TRAIN [2][1110/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00102)	Tok/s 57954 (53910)	Loss/tok 3.4132 (3.1183)	Learning Rate [7.8125e-05]
15: TRAIN [2][1110/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 59201 (54226)	Loss/tok 3.2914 (3.1168)	Learning Rate [7.8125e-05]
10: TRAIN [2][1110/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 57918 (53708)	Loss/tok 3.2762 (3.1099)	Learning Rate [7.8125e-05]
8: TRAIN [2][1110/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00098)	Tok/s 57812 (53561)	Loss/tok 3.3108 (3.1224)	Learning Rate [7.8125e-05]
7: TRAIN [2][1110/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00097)	Tok/s 57868 (53493)	Loss/tok 3.0762 (3.1199)	Learning Rate [7.8125e-05]
4: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00098)	Tok/s 49779 (53203)	Loss/tok 3.1165 (3.1187)	Learning Rate [7.8125e-05]
6: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00092)	Tok/s 49639 (53361)	Loss/tok 3.1220 (3.1230)	Learning Rate [7.8125e-05]
3: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00091)	Tok/s 49653 (53115)	Loss/tok 3.1176 (3.1201)	Learning Rate [7.8125e-05]
5: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00093)	Tok/s 49575 (53282)	Loss/tok 2.8715 (3.1183)	Learning Rate [7.8125e-05]
1: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00110 (0.00100)	Tok/s 49677 (52911)	Loss/tok 3.0296 (3.1147)	Learning Rate [7.8125e-05]
0: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00097)	Tok/s 49686 (52822)	Loss/tok 3.1702 (3.1288)	Learning Rate [7.8125e-05]
2: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00125 (0.00099)	Tok/s 49755 (53018)	Loss/tok 2.7501 (3.1159)	Learning Rate [7.8125e-05]
8: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00112 (0.00098)	Tok/s 49594 (53514)	Loss/tok 3.0114 (3.1220)	Learning Rate [7.8125e-05]
7: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00121 (0.00097)	Tok/s 49629 (53446)	Loss/tok 3.0241 (3.1189)	Learning Rate [7.8125e-05]
15: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00092)	Tok/s 49679 (54181)	Loss/tok 3.1956 (3.1164)	Learning Rate [7.8125e-05]
9: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00091)	Tok/s 49573 (53576)	Loss/tok 3.1078 (3.1155)	Learning Rate [7.8125e-05]
10: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00097)	Tok/s 49680 (53661)	Loss/tok 3.1781 (3.1099)	Learning Rate [7.8125e-05]
14: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00091)	Tok/s 49674 (54067)	Loss/tok 2.9411 (3.1160)	Learning Rate [7.8125e-05]
13: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00096)	Tok/s 49649 (53959)	Loss/tok 3.0813 (3.1194)	Learning Rate [7.8125e-05]
12: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00106 (0.00102)	Tok/s 49693 (53863)	Loss/tok 3.1218 (3.1180)	Learning Rate [7.8125e-05]
11: TRAIN [2][1120/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00092)	Tok/s 49598 (53748)	Loss/tok 3.1039 (3.1246)	Learning Rate [7.8125e-05]
6: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00092)	Tok/s 34339 (53359)	Loss/tok 2.8412 (3.1224)	Learning Rate [7.8125e-05]
5: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00093)	Tok/s 34430 (53279)	Loss/tok 2.6465 (3.1173)	Learning Rate [7.8125e-05]
3: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00091)	Tok/s 34446 (53110)	Loss/tok 2.9517 (3.1197)	Learning Rate [7.8125e-05]
9: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00091)	Tok/s 34320 (53576)	Loss/tok 2.9944 (3.1153)	Learning Rate [7.8125e-05]
4: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00098)	Tok/s 34562 (53197)	Loss/tok 2.9107 (3.1184)	Learning Rate [7.8125e-05]
2: TRAIN [2][1130/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00099)	Tok/s 35050 (53012)	Loss/tok 3.1010 (3.1154)	Learning Rate [7.8125e-05]
7: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00097)	Tok/s 34356 (53443)	Loss/tok 2.8518 (3.1189)	Learning Rate [7.8125e-05]
8: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00098)	Tok/s 34365 (53514)	Loss/tok 2.7166 (3.1209)	Learning Rate [7.8125e-05]
1: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00100)	Tok/s 34385 (52903)	Loss/tok 2.7712 (3.1144)	Learning Rate [7.8125e-05]
15: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00092)	Tok/s 34435 (54184)	Loss/tok 2.6023 (3.1159)	Learning Rate [7.8125e-05]
11: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00092)	Tok/s 34347 (53750)	Loss/tok 2.9634 (3.1251)	Learning Rate [7.8125e-05]
13: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00096)	Tok/s 34455 (53961)	Loss/tok 2.9603 (3.1197)	Learning Rate [7.8125e-05]
0: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00097)	Tok/s 34406 (52810)	Loss/tok 2.7411 (3.1281)	Learning Rate [7.8125e-05]
14: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00092)	Tok/s 34419 (54069)	Loss/tok 2.7160 (3.1154)	Learning Rate [7.8125e-05]
10: TRAIN [2][1130/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00097)	Tok/s 34351 (53661)	Loss/tok 2.9884 (3.1103)	Learning Rate [7.8125e-05]
12: TRAIN [2][1130/3416]	Time 0.051 (0.058)	Data 0.00134 (0.00102)	Tok/s 34956 (53865)	Loss/tok 2.8174 (3.1170)	Learning Rate [7.8125e-05]
15: TRAIN [2][1140/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00092)	Tok/s 56094 (54160)	Loss/tok 3.3452 (3.1154)	Learning Rate [7.8125e-05]
6: TRAIN [2][1140/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00092)	Tok/s 56135 (53330)	Loss/tok 3.0681 (3.1218)	Learning Rate [7.8125e-05]
14: TRAIN [2][1140/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00092)	Tok/s 56011 (54045)	Loss/tok 3.5533 (3.1152)	Learning Rate [7.8125e-05]
0: TRAIN [2][1140/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00097)	Tok/s 55118 (52771)	Loss/tok 3.0839 (3.1274)	Learning Rate [7.8125e-05]
5: TRAIN [2][1140/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00093)	Tok/s 56171 (53249)	Loss/tok 3.3083 (3.1171)	Learning Rate [7.8125e-05]
1: TRAIN [2][1140/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00100)	Tok/s 55652 (52867)	Loss/tok 3.0758 (3.1137)	Learning Rate [7.8125e-05]
4: TRAIN [2][1140/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00098)	Tok/s 56148 (53166)	Loss/tok 3.1293 (3.1176)	Learning Rate [7.8125e-05]
13: TRAIN [2][1140/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 55904 (53936)	Loss/tok 3.1315 (3.1191)	Learning Rate [7.8125e-05]
7: TRAIN [2][1140/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00097)	Tok/s 56041 (53416)	Loss/tok 3.0788 (3.1180)	Learning Rate [7.8125e-05]
3: TRAIN [2][1140/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00091)	Tok/s 56129 (53077)	Loss/tok 3.5066 (3.1194)	Learning Rate [7.8125e-05]
11: TRAIN [2][1140/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00092)	Tok/s 55853 (53723)	Loss/tok 3.3522 (3.1242)	Learning Rate [7.8125e-05]
2: TRAIN [2][1140/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00099)	Tok/s 56080 (52980)	Loss/tok 3.1653 (3.1148)	Learning Rate [7.8125e-05]
8: TRAIN [2][1140/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00098)	Tok/s 55938 (53487)	Loss/tok 3.6457 (3.1204)	Learning Rate [7.8125e-05]
12: TRAIN [2][1140/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00102)	Tok/s 55839 (53839)	Loss/tok 3.2782 (3.1167)	Learning Rate [7.8125e-05]
9: TRAIN [2][1140/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00091)	Tok/s 55893 (53548)	Loss/tok 3.2567 (3.1151)	Learning Rate [7.8125e-05]
10: TRAIN [2][1140/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00097)	Tok/s 55827 (53633)	Loss/tok 3.3045 (3.1100)	Learning Rate [7.8125e-05]
15: TRAIN [2][1150/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 74549 (54188)	Loss/tok 3.0020 (3.1157)	Learning Rate [7.8125e-05]
0: TRAIN [2][1150/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 73562 (52802)	Loss/tok 3.4268 (3.1278)	Learning Rate [7.8125e-05]
14: TRAIN [2][1150/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 74607 (54073)	Loss/tok 3.3573 (3.1153)	Learning Rate [7.8125e-05]
1: TRAIN [2][1150/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00100)	Tok/s 73464 (52897)	Loss/tok 3.3334 (3.1141)	Learning Rate [7.8125e-05]
13: TRAIN [2][1150/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 74620 (53966)	Loss/tok 3.3153 (3.1198)	Learning Rate [7.8125e-05]
2: TRAIN [2][1150/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00099)	Tok/s 73392 (53009)	Loss/tok 3.1021 (3.1151)	Learning Rate [7.8125e-05]
12: TRAIN [2][1150/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00102)	Tok/s 74647 (53869)	Loss/tok 3.1241 (3.1173)	Learning Rate [7.8125e-05]
11: TRAIN [2][1150/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 74563 (53752)	Loss/tok 2.9996 (3.1237)	Learning Rate [7.8125e-05]
3: TRAIN [2][1150/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 73421 (53106)	Loss/tok 3.1565 (3.1198)	Learning Rate [7.8125e-05]
6: TRAIN [2][1150/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 73550 (53360)	Loss/tok 3.1958 (3.1215)	Learning Rate [7.8125e-05]
9: TRAIN [2][1150/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 74621 (53579)	Loss/tok 3.0584 (3.1149)	Learning Rate [7.8125e-05]
10: TRAIN [2][1150/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 74608 (53662)	Loss/tok 2.9586 (3.1096)	Learning Rate [7.8125e-05]
4: TRAIN [2][1150/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 73394 (53197)	Loss/tok 3.1080 (3.1177)	Learning Rate [7.8125e-05]
8: TRAIN [2][1150/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00098)	Tok/s 74558 (53518)	Loss/tok 3.2018 (3.1199)	Learning Rate [7.8125e-05]
7: TRAIN [2][1150/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00097)	Tok/s 74282 (53446)	Loss/tok 3.0088 (3.1181)	Learning Rate [7.8125e-05]
5: TRAIN [2][1150/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00093)	Tok/s 73487 (53279)	Loss/tok 3.2889 (3.1177)	Learning Rate [7.8125e-05]
13: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00096)	Tok/s 68580 (54011)	Loss/tok 3.1391 (3.1198)	Learning Rate [7.8125e-05]
12: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00102)	Tok/s 68620 (53915)	Loss/tok 3.1935 (3.1183)	Learning Rate [7.8125e-05]
11: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00077 (0.00092)	Tok/s 68498 (53798)	Loss/tok 2.9529 (3.1238)	Learning Rate [7.8125e-05]
14: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 68559 (54118)	Loss/tok 3.4598 (3.1163)	Learning Rate [7.8125e-05]
15: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 68538 (54233)	Loss/tok 3.0240 (3.1163)	Learning Rate [7.8125e-05]
0: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00097)	Tok/s 67635 (52851)	Loss/tok 3.0713 (3.1284)	Learning Rate [7.8125e-05]
10: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00079 (0.00097)	Tok/s 68472 (53709)	Loss/tok 3.2858 (3.1101)	Learning Rate [7.8125e-05]
9: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 68338 (53625)	Loss/tok 3.2092 (3.1156)	Learning Rate [7.8125e-05]
1: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00100)	Tok/s 67607 (52946)	Loss/tok 3.0426 (3.1146)	Learning Rate [7.8125e-05]
8: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 68074 (53565)	Loss/tok 3.2107 (3.1207)	Learning Rate [7.8125e-05]
2: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00099)	Tok/s 67532 (53059)	Loss/tok 3.1063 (3.1158)	Learning Rate [7.8125e-05]
7: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00097)	Tok/s 67242 (53493)	Loss/tok 3.0155 (3.1181)	Learning Rate [7.8125e-05]
3: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00091)	Tok/s 67320 (53155)	Loss/tok 3.1467 (3.1204)	Learning Rate [7.8125e-05]
6: TRAIN [2][1160/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 67178 (53407)	Loss/tok 3.1811 (3.1219)	Learning Rate [7.8125e-05]
4: TRAIN [2][1160/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 67290 (53245)	Loss/tok 3.1303 (3.1181)	Learning Rate [7.8125e-05]
5: TRAIN [2][1160/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 67202 (53327)	Loss/tok 3.0123 (3.1177)	Learning Rate [7.8125e-05]
1: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 59663 (52940)	Loss/tok 3.2972 (3.1149)	Learning Rate [7.8125e-05]
0: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 59708 (52845)	Loss/tok 3.1930 (3.1281)	Learning Rate [7.8125e-05]
15: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 60569 (54222)	Loss/tok 3.3155 (3.1170)	Learning Rate [7.8125e-05]
2: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 59577 (53051)	Loss/tok 3.2689 (3.1156)	Learning Rate [7.8125e-05]
3: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00091)	Tok/s 59497 (53146)	Loss/tok 3.2212 (3.1206)	Learning Rate [7.8125e-05]
4: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00098)	Tok/s 59351 (53236)	Loss/tok 3.4377 (3.1190)	Learning Rate [7.8125e-05]
14: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 60649 (54109)	Loss/tok 3.3526 (3.1167)	Learning Rate [7.8125e-05]
13: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 60640 (54002)	Loss/tok 3.1352 (3.1198)	Learning Rate [7.8125e-05]
11: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 60061 (53788)	Loss/tok 3.2458 (3.1240)	Learning Rate [7.8125e-05]
6: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 59311 (53398)	Loss/tok 3.0452 (3.1216)	Learning Rate [7.8125e-05]
12: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00102)	Tok/s 60519 (53905)	Loss/tok 3.1365 (3.1189)	Learning Rate [7.8125e-05]
7: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 59344 (53483)	Loss/tok 3.2212 (3.1178)	Learning Rate [7.8125e-05]
10: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 59413 (53698)	Loss/tok 3.2048 (3.1103)	Learning Rate [7.8125e-05]
9: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00091)	Tok/s 59413 (53614)	Loss/tok 3.3047 (3.1156)	Learning Rate [7.8125e-05]
8: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00098)	Tok/s 59310 (53554)	Loss/tok 3.3688 (3.1210)	Learning Rate [7.8125e-05]
5: TRAIN [2][1170/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 59283 (53318)	Loss/tok 3.3513 (3.1182)	Learning Rate [7.8125e-05]
15: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00083 (0.00092)	Tok/s 50180 (54298)	Loss/tok 2.8350 (3.1172)	Learning Rate [7.8125e-05]
0: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00097)	Tok/s 48701 (52921)	Loss/tok 2.8408 (3.1280)	Learning Rate [7.8125e-05]
14: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00087 (0.00092)	Tok/s 50054 (54184)	Loss/tok 3.1415 (3.1170)	Learning Rate [7.8125e-05]
1: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00089 (0.00100)	Tok/s 48720 (53015)	Loss/tok 2.9633 (3.1151)	Learning Rate [7.8125e-05]
13: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00090 (0.00096)	Tok/s 50058 (54076)	Loss/tok 3.0171 (3.1207)	Learning Rate [7.8125e-05]
3: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00089 (0.00091)	Tok/s 48815 (53221)	Loss/tok 2.8746 (3.1203)	Learning Rate [7.8125e-05]
2: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00099)	Tok/s 48723 (53126)	Loss/tok 2.9129 (3.1165)	Learning Rate [7.8125e-05]
12: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00085 (0.00102)	Tok/s 50049 (53979)	Loss/tok 2.8208 (3.1190)	Learning Rate [7.8125e-05]
11: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00086 (0.00092)	Tok/s 50085 (53862)	Loss/tok 3.1517 (3.1251)	Learning Rate [7.8125e-05]
4: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00100 (0.00098)	Tok/s 48775 (53312)	Loss/tok 2.7786 (3.1191)	Learning Rate [7.8125e-05]
10: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00088 (0.00097)	Tok/s 50086 (53772)	Loss/tok 2.9392 (3.1103)	Learning Rate [7.8125e-05]
9: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00088 (0.00091)	Tok/s 50051 (53688)	Loss/tok 2.9059 (3.1159)	Learning Rate [7.8125e-05]
8: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00107 (0.00098)	Tok/s 49889 (53629)	Loss/tok 2.9024 (3.1207)	Learning Rate [7.8125e-05]
7: TRAIN [2][1180/3416]	Time 0.042 (0.058)	Data 0.00095 (0.00097)	Tok/s 50038 (53557)	Loss/tok 3.1612 (3.1182)	Learning Rate [7.8125e-05]
6: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00090 (0.00092)	Tok/s 48738 (53472)	Loss/tok 3.2981 (3.1229)	Learning Rate [7.8125e-05]
5: TRAIN [2][1180/3416]	Time 0.043 (0.058)	Data 0.00098 (0.00093)	Tok/s 48736 (53393)	Loss/tok 3.0351 (3.1186)	Learning Rate [7.8125e-05]
6: TRAIN [2][1190/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00092)	Tok/s 28992 (53483)	Loss/tok 2.5380 (3.1230)	Learning Rate [7.8125e-05]
4: TRAIN [2][1190/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00098)	Tok/s 28951 (53324)	Loss/tok 2.6553 (3.1194)	Learning Rate [7.8125e-05]
3: TRAIN [2][1190/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00091)	Tok/s 28909 (53234)	Loss/tok 2.8696 (3.1201)	Learning Rate [7.8125e-05]
2: TRAIN [2][1190/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00099)	Tok/s 28854 (53138)	Loss/tok 2.6704 (3.1160)	Learning Rate [7.8125e-05]
7: TRAIN [2][1190/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00097)	Tok/s 29532 (53569)	Loss/tok 2.4759 (3.1182)	Learning Rate [7.8125e-05]
8: TRAIN [2][1190/3416]	Time 0.044 (0.058)	Data 0.00105 (0.00098)	Tok/s 30258 (53641)	Loss/tok 2.5943 (3.1203)	Learning Rate [7.8125e-05]
1: TRAIN [2][1190/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00100)	Tok/s 28777 (53028)	Loss/tok 2.7985 (3.1150)	Learning Rate [7.8125e-05]
0: TRAIN [2][1190/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00097)	Tok/s 28712 (52934)	Loss/tok 2.6301 (3.1279)	Learning Rate [7.8125e-05]
10: TRAIN [2][1190/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00097)	Tok/s 30116 (53784)	Loss/tok 2.7766 (3.1101)	Learning Rate [7.8125e-05]
9: TRAIN [2][1190/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00091)	Tok/s 30166 (53700)	Loss/tok 2.6670 (3.1153)	Learning Rate [7.8125e-05]
5: TRAIN [2][1190/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00093)	Tok/s 29043 (53405)	Loss/tok 2.5487 (3.1190)	Learning Rate [7.8125e-05]
15: TRAIN [2][1190/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00092)	Tok/s 30013 (54308)	Loss/tok 2.4747 (3.1165)	Learning Rate [7.8125e-05]
11: TRAIN [2][1190/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00092)	Tok/s 30030 (53874)	Loss/tok 2.5754 (3.1247)	Learning Rate [7.8125e-05]
13: TRAIN [2][1190/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00096)	Tok/s 29934 (54087)	Loss/tok 2.5431 (3.1207)	Learning Rate [7.8125e-05]
14: TRAIN [2][1190/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00092)	Tok/s 29973 (54195)	Loss/tok 2.5333 (3.1169)	Learning Rate [7.8125e-05]
12: TRAIN [2][1190/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00102)	Tok/s 29955 (53990)	Loss/tok 2.6532 (3.1185)	Learning Rate [7.8125e-05]
0: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 78210 (52913)	Loss/tok 3.1273 (3.1275)	Learning Rate [7.8125e-05]
1: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00100)	Tok/s 78244 (53010)	Loss/tok 3.1994 (3.1148)	Learning Rate [7.8125e-05]
2: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 78270 (53122)	Loss/tok 2.8415 (3.1156)	Learning Rate [7.8125e-05]
15: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 79939 (54299)	Loss/tok 2.9751 (3.1152)	Learning Rate [7.8125e-05]
3: TRAIN [2][1200/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00091)	Tok/s 78274 (53219)	Loss/tok 3.0907 (3.1200)	Learning Rate [7.8125e-05]
14: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 79950 (54186)	Loss/tok 3.0911 (3.1164)	Learning Rate [7.8125e-05]
13: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 79962 (54078)	Loss/tok 3.1342 (3.1199)	Learning Rate [7.8125e-05]
4: TRAIN [2][1200/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 78486 (53310)	Loss/tok 2.9918 (3.1187)	Learning Rate [7.8125e-05]
11: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 78989 (53865)	Loss/tok 3.0230 (3.1243)	Learning Rate [7.8125e-05]
12: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00102)	Tok/s 79642 (53982)	Loss/tok 3.2947 (3.1185)	Learning Rate [7.8125e-05]
6: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 79146 (53472)	Loss/tok 3.2046 (3.1227)	Learning Rate [7.8125e-05]
10: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 78901 (53775)	Loss/tok 3.1374 (3.1096)	Learning Rate [7.8125e-05]
9: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00091)	Tok/s 78976 (53691)	Loss/tok 3.0274 (3.1147)	Learning Rate [7.8125e-05]
7: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 79088 (53558)	Loss/tok 3.0186 (3.1175)	Learning Rate [7.8125e-05]
8: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00098)	Tok/s 78994 (53631)	Loss/tok 3.1077 (3.1201)	Learning Rate [7.8125e-05]
5: TRAIN [2][1200/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00093)	Tok/s 79193 (53392)	Loss/tok 3.2504 (3.1188)	Learning Rate [7.8125e-05]
4: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
14: TRAIN [2][1210/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00092)	Tok/s 51624 (54186)	Loss/tok 3.1178 (3.1162)	Learning Rate [7.8125e-05]
15: TRAIN [2][1210/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00092)	Tok/s 51533 (54299)	Loss/tok 3.2594 (3.1155)	Learning Rate [7.8125e-05]
13: TRAIN [2][1210/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00096)	Tok/s 51743 (54079)	Loss/tok 3.1782 (3.1200)	Learning Rate [7.8125e-05]
0: TRAIN [2][1210/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00097)	Tok/s 50368 (52917)	Loss/tok 3.1215 (3.1278)	Learning Rate [7.8125e-05]
12: TRAIN [2][1210/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00102)	Tok/s 51624 (53982)	Loss/tok 3.0864 (3.1188)	Learning Rate [7.8125e-05]
11: TRAIN [2][1210/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00092)	Tok/s 51616 (53865)	Loss/tok 2.9665 (3.1242)	Learning Rate [7.8125e-05]
9: TRAIN [2][1210/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00091)	Tok/s 51617 (53692)	Loss/tok 3.0974 (3.1150)	Learning Rate [7.8125e-05]
10: TRAIN [2][1210/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00097)	Tok/s 51753 (53775)	Loss/tok 3.2320 (3.1098)	Learning Rate [7.8125e-05]
3: TRAIN [2][1210/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00091)	Tok/s 50268 (53221)	Loss/tok 2.9703 (3.1199)	Learning Rate [7.8125e-05]
1: TRAIN [2][1210/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00100)	Tok/s 50383 (53015)	Loss/tok 3.0089 (3.1149)	Learning Rate [7.8125e-05]
6: TRAIN [2][1210/3416]	Time 0.055 (0.058)	Data 0.00085 (0.00092)	Tok/s 51453 (53474)	Loss/tok 3.1607 (3.1236)	Learning Rate [7.8125e-05]
4: TRAIN [2][1210/3416]	Time 0.055 (0.058)	Data 0.00107 (0.00098)	Tok/s 50952 (53312)	Loss/tok 3.1164 (3.1190)	Learning Rate [7.8125e-05]
7: TRAIN [2][1210/3416]	Time 0.055 (0.058)	Data 0.00084 (0.00097)	Tok/s 51613 (53561)	Loss/tok 3.2633 (3.1176)	Learning Rate [7.8125e-05]
5: TRAIN [2][1210/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00093)	Tok/s 51368 (53394)	Loss/tok 3.0745 (3.1188)	Learning Rate [7.8125e-05]
2: TRAIN [2][1210/3416]	Time 0.056 (0.058)	Data 0.00122 (0.00099)	Tok/s 49538 (53125)	Loss/tok 2.6808 (3.1153)	Learning Rate [7.8125e-05]
8: TRAIN [2][1210/3416]	Time 0.056 (0.058)	Data 0.00119 (0.00099)	Tok/s 50718 (53632)	Loss/tok 3.0484 (3.1203)	Learning Rate [7.8125e-05]
2: TRAIN [2][1220/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00099)	Tok/s 52773 (53113)	Loss/tok 3.1591 (3.1155)	Learning Rate [7.8125e-05]
1: TRAIN [2][1220/3416]	Time 0.060 (0.058)	Data 0.00109 (0.00100)	Tok/s 52665 (53003)	Loss/tok 3.1548 (3.1152)	Learning Rate [7.8125e-05]
3: TRAIN [2][1220/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00091)	Tok/s 52792 (53208)	Loss/tok 3.1730 (3.1200)	Learning Rate [7.8125e-05]
0: TRAIN [2][1220/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00097)	Tok/s 52659 (52906)	Loss/tok 3.2754 (3.1284)	Learning Rate [7.8125e-05]
4: TRAIN [2][1220/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00098)	Tok/s 52834 (53300)	Loss/tok 3.2004 (3.1196)	Learning Rate [7.8125e-05]
6: TRAIN [2][1220/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00092)	Tok/s 52855 (53462)	Loss/tok 3.2600 (3.1236)	Learning Rate [7.8125e-05]
15: TRAIN [2][1220/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00092)	Tok/s 52640 (54287)	Loss/tok 3.0313 (3.1164)	Learning Rate [7.8125e-05]
7: TRAIN [2][1220/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00097)	Tok/s 52862 (53548)	Loss/tok 3.5920 (3.1183)	Learning Rate [7.8125e-05]
9: TRAIN [2][1220/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00091)	Tok/s 52851 (53679)	Loss/tok 3.1910 (3.1155)	Learning Rate [7.8125e-05]
14: TRAIN [2][1220/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00092)	Tok/s 52649 (54173)	Loss/tok 3.0469 (3.1164)	Learning Rate [7.8125e-05]
8: TRAIN [2][1220/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00099)	Tok/s 52838 (53620)	Loss/tok 3.1829 (3.1202)	Learning Rate [7.8125e-05]
13: TRAIN [2][1220/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00096)	Tok/s 52653 (54067)	Loss/tok 2.9528 (3.1204)	Learning Rate [7.8125e-05]
11: TRAIN [2][1220/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00092)	Tok/s 52714 (53852)	Loss/tok 2.9593 (3.1245)	Learning Rate [7.8125e-05]
12: TRAIN [2][1220/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00102)	Tok/s 52711 (53970)	Loss/tok 2.9819 (3.1198)	Learning Rate [7.8125e-05]
10: TRAIN [2][1220/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00097)	Tok/s 52733 (53763)	Loss/tok 3.2151 (3.1099)	Learning Rate [7.8125e-05]
5: TRAIN [2][1220/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00093)	Tok/s 52874 (53383)	Loss/tok 3.4639 (3.1193)	Learning Rate [7.8125e-05]
3: Gradient norm: inf
4: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
2: Gradient norm: inf
1: Gradient norm: inf
5: Gradient norm: inf
4: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
1: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
6: Gradient norm: inf
0: Gradient norm: inf
15: Gradient norm: inf
6: Skipped batch, new scale: 2048.0
14: Gradient norm: inf
15: Skipped batch, new scale: 2048.0
0: Skipped batch, new scale: 2048.0
7: Gradient norm: inf
13: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
9: Gradient norm: inf
8: Gradient norm: inf
13: Skipped batch, new scale: 2048.0
12: Gradient norm: inf
7: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
9: Skipped batch, new scale: 2048.0
11: Gradient norm: inf
10: Skipped batch, new scale: 2048.0
8: Skipped batch, new scale: 2048.0
12: Skipped batch, new scale: 2048.0
11: Skipped batch, new scale: 2048.0
1: TRAIN [2][1230/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00100)	Tok/s 54377 (53010)	Loss/tok 3.2863 (3.1149)	Learning Rate [7.8125e-05]
0: TRAIN [2][1230/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00097)	Tok/s 54388 (52911)	Loss/tok 3.1912 (3.1280)	Learning Rate [7.8125e-05]
15: TRAIN [2][1230/3416]	Time 0.062 (0.058)	Data 0.00084 (0.00092)	Tok/s 55336 (54292)	Loss/tok 3.1357 (3.1159)	Learning Rate [7.8125e-05]
3: TRAIN [2][1230/3416]	Time 0.063 (0.058)	Data 0.00084 (0.00091)	Tok/s 54195 (53214)	Loss/tok 3.1142 (3.1200)	Learning Rate [7.8125e-05]
2: TRAIN [2][1230/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00099)	Tok/s 54149 (53119)	Loss/tok 3.0713 (3.1151)	Learning Rate [7.8125e-05]
6: TRAIN [2][1230/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00092)	Tok/s 54212 (53468)	Loss/tok 3.0018 (3.1228)	Learning Rate [7.8125e-05]
14: TRAIN [2][1230/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00092)	Tok/s 55282 (54179)	Loss/tok 3.2496 (3.1161)	Learning Rate [7.8125e-05]
13: TRAIN [2][1230/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00096)	Tok/s 55294 (54073)	Loss/tok 3.1813 (3.1200)	Learning Rate [7.8125e-05]
4: TRAIN [2][1230/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00098)	Tok/s 54116 (53306)	Loss/tok 3.0495 (3.1193)	Learning Rate [7.8125e-05]
11: TRAIN [2][1230/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00092)	Tok/s 55292 (53858)	Loss/tok 3.0679 (3.1239)	Learning Rate [7.8125e-05]
7: TRAIN [2][1230/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00097)	Tok/s 54712 (53554)	Loss/tok 3.1452 (3.1175)	Learning Rate [7.8125e-05]
12: TRAIN [2][1230/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00102)	Tok/s 55173 (53976)	Loss/tok 3.3426 (3.1199)	Learning Rate [7.8125e-05]
9: TRAIN [2][1230/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00091)	Tok/s 55157 (53684)	Loss/tok 3.2904 (3.1155)	Learning Rate [7.8125e-05]
8: TRAIN [2][1230/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00099)	Tok/s 55121 (53625)	Loss/tok 3.2112 (3.1197)	Learning Rate [7.8125e-05]
10: TRAIN [2][1230/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00097)	Tok/s 55195 (53767)	Loss/tok 3.0756 (3.1094)	Learning Rate [7.8125e-05]
5: TRAIN [2][1230/3416]	Time 0.063 (0.058)	Data 0.00106 (0.00093)	Tok/s 54174 (53389)	Loss/tok 3.0821 (3.1189)	Learning Rate [7.8125e-05]
10: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 55731 (53735)	Loss/tok 3.3897 (3.1099)	Learning Rate [7.8125e-05]
9: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00091)	Tok/s 55701 (53653)	Loss/tok 3.3078 (3.1162)	Learning Rate [7.8125e-05]
11: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 55737 (53825)	Loss/tok 3.3892 (3.1233)	Learning Rate [7.8125e-05]
12: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00102)	Tok/s 55752 (53943)	Loss/tok 3.0484 (3.1201)	Learning Rate [7.8125e-05]
7: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00097)	Tok/s 55520 (53522)	Loss/tok 3.4479 (3.1175)	Learning Rate [7.8125e-05]
6: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 55439 (53437)	Loss/tok 3.2743 (3.1225)	Learning Rate [7.8125e-05]
13: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00096)	Tok/s 55684 (54039)	Loss/tok 3.2227 (3.1195)	Learning Rate [7.8125e-05]
8: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00099)	Tok/s 55604 (53593)	Loss/tok 3.3269 (3.1197)	Learning Rate [7.8125e-05]
14: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00092)	Tok/s 55604 (54146)	Loss/tok 3.0078 (3.1156)	Learning Rate [7.8125e-05]
4: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00098)	Tok/s 55336 (53275)	Loss/tok 3.1813 (3.1187)	Learning Rate [7.8125e-05]
15: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00092)	Tok/s 55539 (54259)	Loss/tok 2.9748 (3.1153)	Learning Rate [7.8125e-05]
2: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00099)	Tok/s 55334 (53088)	Loss/tok 3.2641 (3.1154)	Learning Rate [7.8125e-05]
0: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00097)	Tok/s 54838 (52881)	Loss/tok 3.2975 (3.1281)	Learning Rate [7.8125e-05]
1: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00100)	Tok/s 55372 (52979)	Loss/tok 3.2560 (3.1151)	Learning Rate [7.8125e-05]
3: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00091)	Tok/s 55316 (53182)	Loss/tok 3.3547 (3.1197)	Learning Rate [7.8125e-05]
5: TRAIN [2][1240/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00093)	Tok/s 55362 (53358)	Loss/tok 3.2608 (3.1187)	Learning Rate [7.8125e-05]
8: TRAIN [2][1250/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00099)	Tok/s 33610 (53594)	Loss/tok 2.8102 (3.1200)	Learning Rate [7.8125e-05]
7: TRAIN [2][1250/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00097)	Tok/s 33547 (53523)	Loss/tok 2.7515 (3.1171)	Learning Rate [7.8125e-05]
9: TRAIN [2][1250/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00091)	Tok/s 33588 (53653)	Loss/tok 2.8025 (3.1162)	Learning Rate [7.8125e-05]
6: TRAIN [2][1250/3416]	Time 0.052 (0.058)	Data 0.00081 (0.00092)	Tok/s 33473 (53438)	Loss/tok 2.8775 (3.1231)	Learning Rate [7.8125e-05]
10: TRAIN [2][1250/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00097)	Tok/s 33622 (53735)	Loss/tok 3.0646 (3.1092)	Learning Rate [7.8125e-05]
4: TRAIN [2][1250/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00098)	Tok/s 33395 (53275)	Loss/tok 2.6462 (3.1185)	Learning Rate [7.8125e-05]
3: TRAIN [2][1250/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00091)	Tok/s 33407 (53184)	Loss/tok 2.7510 (3.1192)	Learning Rate [7.8125e-05]
11: TRAIN [2][1250/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00092)	Tok/s 33576 (53825)	Loss/tok 2.8174 (3.1226)	Learning Rate [7.8125e-05]
2: TRAIN [2][1250/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00099)	Tok/s 33435 (53089)	Loss/tok 2.9944 (3.1156)	Learning Rate [7.8125e-05]
1: TRAIN [2][1250/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00100)	Tok/s 33432 (52980)	Loss/tok 2.6101 (3.1151)	Learning Rate [7.8125e-05]
12: TRAIN [2][1250/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00102)	Tok/s 33579 (53944)	Loss/tok 2.8453 (3.1202)	Learning Rate [7.8125e-05]
0: TRAIN [2][1250/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 33435 (52882)	Loss/tok 2.7576 (3.1275)	Learning Rate [7.8125e-05]
13: TRAIN [2][1250/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00096)	Tok/s 33846 (54040)	Loss/tok 2.7559 (3.1197)	Learning Rate [7.8125e-05]
15: TRAIN [2][1250/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 34696 (54259)	Loss/tok 2.8190 (3.1152)	Learning Rate [7.8125e-05]
14: TRAIN [2][1250/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00091)	Tok/s 34717 (54147)	Loss/tok 2.9299 (3.1162)	Learning Rate [7.8125e-05]
5: TRAIN [2][1250/3416]	Time 0.052 (0.058)	Data 0.00079 (0.00093)	Tok/s 33399 (53359)	Loss/tok 2.7052 (3.1187)	Learning Rate [7.8125e-05]
14: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00091)	Tok/s 50650 (54082)	Loss/tok 2.7365 (3.1162)	Learning Rate [7.8125e-05]
15: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00092)	Tok/s 50698 (54194)	Loss/tok 3.1257 (3.1149)	Learning Rate [7.8125e-05]
13: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00096)	Tok/s 50538 (53974)	Loss/tok 3.1551 (3.1192)	Learning Rate [7.8125e-05]
0: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00097)	Tok/s 50661 (52807)	Loss/tok 3.1317 (3.1270)	Learning Rate [7.8125e-05]
12: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00102)	Tok/s 50568 (53876)	Loss/tok 3.0563 (3.1197)	Learning Rate [7.8125e-05]
1: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00100)	Tok/s 50675 (52907)	Loss/tok 3.2000 (3.1149)	Learning Rate [7.8125e-05]
11: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 50509 (53757)	Loss/tok 2.9855 (3.1221)	Learning Rate [7.8125e-05]
2: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00099)	Tok/s 50682 (53018)	Loss/tok 3.0123 (3.1150)	Learning Rate [7.8125e-05]
10: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00097)	Tok/s 50526 (53668)	Loss/tok 3.0403 (3.1086)	Learning Rate [7.8125e-05]
9: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00082 (0.00091)	Tok/s 50532 (53586)	Loss/tok 2.9132 (3.1157)	Learning Rate [7.8125e-05]
3: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00112 (0.00091)	Tok/s 50703 (53113)	Loss/tok 2.9166 (3.1186)	Learning Rate [7.8125e-05]
8: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00099)	Tok/s 50555 (53527)	Loss/tok 2.8669 (3.1198)	Learning Rate [7.8125e-05]
6: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00078 (0.00092)	Tok/s 50560 (53370)	Loss/tok 3.4207 (3.1230)	Learning Rate [7.8125e-05]
4: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00098)	Tok/s 50670 (53206)	Loss/tok 3.1642 (3.1185)	Learning Rate [7.8125e-05]
7: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00097)	Tok/s 50570 (53456)	Loss/tok 3.0579 (3.1169)	Learning Rate [7.8125e-05]
5: TRAIN [2][1260/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00093)	Tok/s 50587 (53291)	Loss/tok 2.9611 (3.1184)	Learning Rate [7.8125e-05]
15: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00092)	Tok/s 57114 (54177)	Loss/tok 3.1393 (3.1148)	Learning Rate [7.8125e-05]
0: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00097)	Tok/s 55999 (52777)	Loss/tok 3.1753 (3.1269)	Learning Rate [7.8125e-05]
14: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00091)	Tok/s 57099 (54063)	Loss/tok 3.0484 (3.1158)	Learning Rate [7.8125e-05]
13: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00096)	Tok/s 57078 (53956)	Loss/tok 3.1847 (3.1189)	Learning Rate [7.8125e-05]
1: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00100)	Tok/s 55970 (52878)	Loss/tok 3.2471 (3.1143)	Learning Rate [7.8125e-05]
2: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00099)	Tok/s 55966 (52990)	Loss/tok 3.3141 (3.1152)	Learning Rate [7.8125e-05]
12: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00103 (0.00102)	Tok/s 56963 (53857)	Loss/tok 3.2801 (3.1196)	Learning Rate [7.8125e-05]
11: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00080 (0.00092)	Tok/s 56795 (53736)	Loss/tok 3.3087 (3.1216)	Learning Rate [7.8125e-05]
3: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00107 (0.00091)	Tok/s 55973 (53087)	Loss/tok 3.2652 (3.1182)	Learning Rate [7.8125e-05]
4: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00098)	Tok/s 55962 (53179)	Loss/tok 3.0047 (3.1179)	Learning Rate [7.8125e-05]
10: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00097)	Tok/s 56766 (53646)	Loss/tok 3.1292 (3.1084)	Learning Rate [7.8125e-05]
9: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00079 (0.00091)	Tok/s 56704 (53565)	Loss/tok 3.2191 (3.1151)	Learning Rate [7.8125e-05]
8: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00099)	Tok/s 56839 (53506)	Loss/tok 3.3198 (3.1197)	Learning Rate [7.8125e-05]
5: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00093)	Tok/s 55914 (53267)	Loss/tok 3.3301 (3.1180)	Learning Rate [7.8125e-05]
6: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00092)	Tok/s 56733 (53349)	Loss/tok 3.3434 (3.1233)	Learning Rate [7.8125e-05]
7: TRAIN [2][1270/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00097)	Tok/s 56831 (53434)	Loss/tok 3.2169 (3.1171)	Learning Rate [7.8125e-05]
4: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00085 (0.00098)	Tok/s 26882 (53138)	Loss/tok 2.3634 (3.1180)	Learning Rate [7.8125e-05]
2: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00085 (0.00099)	Tok/s 25384 (52948)	Loss/tok 2.2217 (3.1152)	Learning Rate [7.8125e-05]
3: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00099 (0.00091)	Tok/s 25460 (53044)	Loss/tok 2.3388 (3.1176)	Learning Rate [7.8125e-05]
1: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00102 (0.00100)	Tok/s 25420 (52836)	Loss/tok 2.1923 (3.1146)	Learning Rate [7.8125e-05]
5: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00080 (0.00093)	Tok/s 27253 (53226)	Loss/tok 2.3902 (3.1174)	Learning Rate [7.8125e-05]
6: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00078 (0.00092)	Tok/s 27209 (53307)	Loss/tok 2.6479 (3.1231)	Learning Rate [7.8125e-05]
0: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00083 (0.00097)	Tok/s 25417 (52735)	Loss/tok 2.1864 (3.1267)	Learning Rate [7.8125e-05]
15: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00098 (0.00092)	Tok/s 30157 (54135)	Loss/tok 2.5998 (3.1146)	Learning Rate [7.8125e-05]
7: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00093 (0.00097)	Tok/s 27189 (53392)	Loss/tok 2.4731 (3.1168)	Learning Rate [7.8125e-05]
8: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00080 (0.00098)	Tok/s 27529 (53464)	Loss/tok 2.4712 (3.1199)	Learning Rate [7.8125e-05]
14: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00094 (0.00091)	Tok/s 28822 (54019)	Loss/tok 2.3866 (3.1158)	Learning Rate [7.8125e-05]
13: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00081 (0.00096)	Tok/s 28809 (53912)	Loss/tok 2.4236 (3.1184)	Learning Rate [7.8125e-05]
12: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00104 (0.00102)	Tok/s 28846 (53813)	Loss/tok 2.3546 (3.1200)	Learning Rate [7.8125e-05]
11: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00086 (0.00092)	Tok/s 28847 (53693)	Loss/tok 2.2719 (3.1209)	Learning Rate [7.8125e-05]
9: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00081 (0.00091)	Tok/s 28920 (53523)	Loss/tok 2.4548 (3.1155)	Learning Rate [7.8125e-05]
10: TRAIN [2][1280/3416]	Time 0.038 (0.058)	Data 0.00096 (0.00097)	Tok/s 28869 (53604)	Loss/tok 2.3833 (3.1083)	Learning Rate [7.8125e-05]
1: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00100)	Tok/s 56689 (52872)	Loss/tok 3.1593 (3.1147)	Learning Rate [7.8125e-05]
0: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 56702 (52772)	Loss/tok 3.1422 (3.1265)	Learning Rate [7.8125e-05]
15: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00092)	Tok/s 57600 (54174)	Loss/tok 3.3516 (3.1151)	Learning Rate [7.8125e-05]
13: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 57478 (53949)	Loss/tok 3.1467 (3.1186)	Learning Rate [7.8125e-05]
2: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00099)	Tok/s 56518 (52983)	Loss/tok 3.2306 (3.1154)	Learning Rate [7.8125e-05]
11: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 57280 (53729)	Loss/tok 3.3386 (3.1208)	Learning Rate [7.8125e-05]
14: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00092)	Tok/s 57529 (54056)	Loss/tok 3.1779 (3.1166)	Learning Rate [7.8125e-05]
12: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00102)	Tok/s 57389 (53849)	Loss/tok 3.0085 (3.1193)	Learning Rate [7.8125e-05]
3: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00092)	Tok/s 56545 (53080)	Loss/tok 3.1194 (3.1178)	Learning Rate [7.8125e-05]
10: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 57175 (53640)	Loss/tok 3.1628 (3.1085)	Learning Rate [7.8125e-05]
9: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00091)	Tok/s 57282 (53560)	Loss/tok 3.2861 (3.1157)	Learning Rate [7.8125e-05]
6: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 57419 (53344)	Loss/tok 3.0367 (3.1229)	Learning Rate [7.8125e-05]
4: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 56469 (53174)	Loss/tok 3.3060 (3.1182)	Learning Rate [7.8125e-05]
5: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 57199 (53262)	Loss/tok 3.2103 (3.1168)	Learning Rate [7.8125e-05]
7: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 57301 (53429)	Loss/tok 3.3481 (3.1174)	Learning Rate [7.8125e-05]
8: TRAIN [2][1290/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 57244 (53501)	Loss/tok 3.2400 (3.1200)	Learning Rate [7.8125e-05]
6: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 58287 (53347)	Loss/tok 3.2798 (3.1230)	Learning Rate [7.8125e-05]
5: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00093)	Tok/s 58329 (53266)	Loss/tok 3.5108 (3.1170)	Learning Rate [7.8125e-05]
7: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00097)	Tok/s 58242 (53431)	Loss/tok 3.1003 (3.1181)	Learning Rate [7.8125e-05]
4: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00098)	Tok/s 58312 (53178)	Loss/tok 3.3708 (3.1189)	Learning Rate [7.8125e-05]
8: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 58249 (53503)	Loss/tok 3.1985 (3.1198)	Learning Rate [7.8125e-05]
9: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 58251 (53561)	Loss/tok 3.1321 (3.1160)	Learning Rate [7.8125e-05]
3: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00092)	Tok/s 58270 (53084)	Loss/tok 3.1074 (3.1184)	Learning Rate [7.8125e-05]
1: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 58324 (52877)	Loss/tok 3.2552 (3.1155)	Learning Rate [7.8125e-05]
10: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 58219 (53642)	Loss/tok 3.4743 (3.1089)	Learning Rate [7.8125e-05]
11: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 58182 (53731)	Loss/tok 3.1511 (3.1211)	Learning Rate [7.8125e-05]
0: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 58280 (52777)	Loss/tok 3.1717 (3.1264)	Learning Rate [7.8125e-05]
2: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 58296 (52988)	Loss/tok 3.2504 (3.1156)	Learning Rate [7.8125e-05]
15: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 58689 (54175)	Loss/tok 3.1482 (3.1151)	Learning Rate [7.8125e-05]
12: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00102)	Tok/s 58200 (53852)	Loss/tok 3.4544 (3.1195)	Learning Rate [7.8125e-05]
14: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 58240 (54058)	Loss/tok 3.4115 (3.1170)	Learning Rate [7.8125e-05]
13: TRAIN [2][1300/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 58179 (53952)	Loss/tok 3.3190 (3.1184)	Learning Rate [7.8125e-05]
9: TRAIN [2][1310/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00091)	Tok/s 63409 (53587)	Loss/tok 3.0850 (3.1160)	Learning Rate [7.8125e-05]
10: TRAIN [2][1310/3416]	Time 0.067 (0.058)	Data 0.00106 (0.00097)	Tok/s 64722 (53668)	Loss/tok 3.0334 (3.1091)	Learning Rate [7.8125e-05]
12: TRAIN [2][1310/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00102)	Tok/s 63539 (53877)	Loss/tok 3.0663 (3.1189)	Learning Rate [7.8125e-05]
8: TRAIN [2][1310/3416]	Time 0.069 (0.058)	Data 0.00078 (0.00098)	Tok/s 63323 (53529)	Loss/tok 3.2750 (3.1202)	Learning Rate [7.8125e-05]
13: TRAIN [2][1310/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00096)	Tok/s 63455 (53976)	Loss/tok 3.1676 (3.1186)	Learning Rate [7.8125e-05]
7: TRAIN [2][1310/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 63185 (53458)	Loss/tok 3.1473 (3.1181)	Learning Rate [7.8125e-05]
6: TRAIN [2][1310/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 63060 (53373)	Loss/tok 3.0826 (3.1229)	Learning Rate [7.8125e-05]
15: TRAIN [2][1310/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 63248 (54199)	Loss/tok 3.3838 (3.1158)	Learning Rate [7.8125e-05]
0: TRAIN [2][1310/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 62232 (52802)	Loss/tok 3.3542 (3.1269)	Learning Rate [7.8125e-05]
5: TRAIN [2][1310/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00093)	Tok/s 63016 (53292)	Loss/tok 3.5225 (3.1177)	Learning Rate [7.8125e-05]
1: TRAIN [2][1310/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00100)	Tok/s 63058 (52903)	Loss/tok 3.0535 (3.1155)	Learning Rate [7.8125e-05]
4: TRAIN [2][1310/3416]	Time 0.069 (0.058)	Data 0.00114 (0.00098)	Tok/s 63526 (53205)	Loss/tok 3.1037 (3.1192)	Learning Rate [7.8125e-05]
2: TRAIN [2][1310/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00099)	Tok/s 62035 (53014)	Loss/tok 3.2368 (3.1155)	Learning Rate [7.8125e-05]
3: TRAIN [2][1310/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00092)	Tok/s 62883 (53111)	Loss/tok 2.8706 (3.1179)	Learning Rate [7.8125e-05]
11: TRAIN [2][1310/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 62776 (53755)	Loss/tok 3.2534 (3.1210)	Learning Rate [7.8125e-05]
14: TRAIN [2][1310/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 62555 (54082)	Loss/tok 3.1751 (3.1167)	Learning Rate [7.8125e-05]
11: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 71951 (53802)	Loss/tok 3.0833 (3.1205)	Learning Rate [7.8125e-05]
9: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 71374 (53634)	Loss/tok 3.4768 (3.1167)	Learning Rate [7.8125e-05]
10: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 71967 (53714)	Loss/tok 3.0732 (3.1088)	Learning Rate [7.8125e-05]
8: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 71078 (53575)	Loss/tok 3.0839 (3.1201)	Learning Rate [7.8125e-05]
13: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 71857 (54022)	Loss/tok 3.0116 (3.1187)	Learning Rate [7.8125e-05]
7: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 71073 (53504)	Loss/tok 3.1343 (3.1176)	Learning Rate [7.8125e-05]
14: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 71868 (54129)	Loss/tok 3.0284 (3.1171)	Learning Rate [7.8125e-05]
12: TRAIN [2][1320/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00102)	Tok/s 71808 (53922)	Loss/tok 3.1456 (3.1196)	Learning Rate [7.8125e-05]
6: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00092)	Tok/s 70923 (53419)	Loss/tok 3.2036 (3.1228)	Learning Rate [7.8125e-05]
15: TRAIN [2][1320/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 71706 (54246)	Loss/tok 2.9968 (3.1151)	Learning Rate [7.8125e-05]
0: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 70943 (52849)	Loss/tok 3.2457 (3.1271)	Learning Rate [7.8125e-05]
1: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00100)	Tok/s 70938 (52949)	Loss/tok 3.2192 (3.1161)	Learning Rate [7.8125e-05]
5: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 71048 (53338)	Loss/tok 3.0218 (3.1176)	Learning Rate [7.8125e-05]
4: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00098)	Tok/s 71345 (53250)	Loss/tok 3.1217 (3.1190)	Learning Rate [7.8125e-05]
2: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 70958 (53059)	Loss/tok 3.2235 (3.1160)	Learning Rate [7.8125e-05]
3: TRAIN [2][1320/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 71031 (53156)	Loss/tok 3.1603 (3.1178)	Learning Rate [7.8125e-05]
6: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00081 (0.00092)	Tok/s 33047 (53404)	Loss/tok 2.9170 (3.1222)	Learning Rate [7.8125e-05]
5: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00093)	Tok/s 33072 (53323)	Loss/tok 2.5743 (3.1168)	Learning Rate [7.8125e-05]
8: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00098)	Tok/s 33079 (53560)	Loss/tok 2.5719 (3.1195)	Learning Rate [7.8125e-05]
4: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00098)	Tok/s 33067 (53235)	Loss/tok 2.7717 (3.1183)	Learning Rate [7.8125e-05]
9: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00091)	Tok/s 33082 (53618)	Loss/tok 2.6541 (3.1164)	Learning Rate [7.8125e-05]
7: TRAIN [2][1330/3416]	Time 0.047 (0.058)	Data 0.00083 (0.00097)	Tok/s 32997 (53488)	Loss/tok 2.7832 (3.1173)	Learning Rate [7.8125e-05]
10: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00097)	Tok/s 33142 (53698)	Loss/tok 2.8575 (3.1078)	Learning Rate [7.8125e-05]
3: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00102 (0.00092)	Tok/s 33052 (53141)	Loss/tok 2.9757 (3.1177)	Learning Rate [7.8125e-05]
11: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00092)	Tok/s 33269 (53785)	Loss/tok 2.7420 (3.1202)	Learning Rate [7.8125e-05]
2: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00099)	Tok/s 33051 (53044)	Loss/tok 2.6649 (3.1157)	Learning Rate [7.8125e-05]
1: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00100)	Tok/s 33067 (52934)	Loss/tok 2.9812 (3.1161)	Learning Rate [7.8125e-05]
0: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00096)	Tok/s 33061 (52834)	Loss/tok 2.8329 (3.1265)	Learning Rate [7.8125e-05]
13: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00096)	Tok/s 34487 (54006)	Loss/tok 2.8214 (3.1179)	Learning Rate [7.8125e-05]
14: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00092)	Tok/s 34463 (54112)	Loss/tok 2.7950 (3.1163)	Learning Rate [7.8125e-05]
15: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00092)	Tok/s 34428 (54229)	Loss/tok 2.8906 (3.1145)	Learning Rate [7.8125e-05]
12: TRAIN [2][1330/3416]	Time 0.046 (0.058)	Data 0.00109 (0.00102)	Tok/s 34441 (53906)	Loss/tok 2.7888 (3.1192)	Learning Rate [7.8125e-05]
13: TRAIN [2][1340/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00096)	Tok/s 50805 (53999)	Loss/tok 2.9462 (3.1178)	Learning Rate [7.8125e-05]
12: TRAIN [2][1340/3416]	Time 0.054 (0.058)	Data 0.00113 (0.00102)	Tok/s 50770 (53899)	Loss/tok 3.4249 (3.1204)	Learning Rate [7.8125e-05]
14: TRAIN [2][1340/3416]	Time 0.054 (0.058)	Data 0.00099 (0.00092)	Tok/s 50636 (54105)	Loss/tok 3.1551 (3.1164)	Learning Rate [7.8125e-05]
11: TRAIN [2][1340/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00092)	Tok/s 50693 (53777)	Loss/tok 3.1399 (3.1206)	Learning Rate [7.8125e-05]
15: TRAIN [2][1340/3416]	Time 0.054 (0.058)	Data 0.00104 (0.00092)	Tok/s 50529 (54221)	Loss/tok 3.1988 (3.1142)	Learning Rate [7.8125e-05]
10: TRAIN [2][1340/3416]	Time 0.054 (0.058)	Data 0.00104 (0.00097)	Tok/s 50576 (53690)	Loss/tok 3.1959 (3.1080)	Learning Rate [7.8125e-05]
0: TRAIN [2][1340/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00096)	Tok/s 50401 (52831)	Loss/tok 2.8090 (3.1266)	Learning Rate [7.8125e-05]
9: TRAIN [2][1340/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00091)	Tok/s 50615 (53610)	Loss/tok 3.0659 (3.1165)	Learning Rate [7.8125e-05]
1: TRAIN [2][1340/3416]	Time 0.055 (0.058)	Data 0.00215 (0.00100)	Tok/s 50371 (52930)	Loss/tok 3.1138 (3.1159)	Learning Rate [7.8125e-05]
8: TRAIN [2][1340/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00098)	Tok/s 50633 (53552)	Loss/tok 3.1606 (3.1202)	Learning Rate [7.8125e-05]
7: TRAIN [2][1340/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00097)	Tok/s 50584 (53481)	Loss/tok 2.9566 (3.1171)	Learning Rate [7.8125e-05]
6: TRAIN [2][1340/3416]	Time 0.055 (0.058)	Data 0.00084 (0.00092)	Tok/s 50485 (53396)	Loss/tok 3.1571 (3.1230)	Learning Rate [7.8125e-05]
2: TRAIN [2][1340/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00099)	Tok/s 50361 (53039)	Loss/tok 3.0867 (3.1158)	Learning Rate [7.8125e-05]
3: TRAIN [2][1340/3416]	Time 0.055 (0.058)	Data 0.00102 (0.00092)	Tok/s 50374 (53135)	Loss/tok 3.0694 (3.1175)	Learning Rate [7.8125e-05]
4: TRAIN [2][1340/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00098)	Tok/s 50409 (53228)	Loss/tok 3.1751 (3.1185)	Learning Rate [7.8125e-05]
5: TRAIN [2][1340/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00093)	Tok/s 50416 (53316)	Loss/tok 3.2472 (3.1170)	Learning Rate [7.8125e-05]
6: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00080 (0.00092)	Tok/s 50011 (53370)	Loss/tok 2.8609 (3.1226)	Learning Rate [7.8125e-05]
7: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00083 (0.00097)	Tok/s 49883 (53454)	Loss/tok 2.9317 (3.1171)	Learning Rate [7.8125e-05]
8: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00098)	Tok/s 49751 (53525)	Loss/tok 2.9723 (3.1202)	Learning Rate [7.8125e-05]
5: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00093)	Tok/s 49877 (53289)	Loss/tok 2.9860 (3.1168)	Learning Rate [7.8125e-05]
9: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00079 (0.00091)	Tok/s 49617 (53583)	Loss/tok 2.9733 (3.1162)	Learning Rate [7.8125e-05]
4: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00098)	Tok/s 49937 (53202)	Loss/tok 3.0044 (3.1186)	Learning Rate [7.8125e-05]
11: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00092)	Tok/s 49460 (53750)	Loss/tok 3.2049 (3.1211)	Learning Rate [7.8125e-05]
10: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00105 (0.00097)	Tok/s 49497 (53663)	Loss/tok 2.9280 (3.1079)	Learning Rate [7.8125e-05]
3: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00092)	Tok/s 49001 (53108)	Loss/tok 2.7992 (3.1171)	Learning Rate [7.8125e-05]
2: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00099)	Tok/s 48335 (53013)	Loss/tok 2.9731 (3.1154)	Learning Rate [7.8125e-05]
1: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00100)	Tok/s 48146 (52904)	Loss/tok 2.9724 (3.1157)	Learning Rate [7.8125e-05]
12: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00102)	Tok/s 49310 (53871)	Loss/tok 2.9991 (3.1202)	Learning Rate [7.8125e-05]
0: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00096)	Tok/s 48075 (52806)	Loss/tok 3.2345 (3.1265)	Learning Rate [7.8125e-05]
13: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00096)	Tok/s 49302 (53970)	Loss/tok 2.9816 (3.1178)	Learning Rate [7.8125e-05]
15: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00092)	Tok/s 49387 (54193)	Loss/tok 3.0811 (3.1143)	Learning Rate [7.8125e-05]
14: TRAIN [2][1350/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00092)	Tok/s 49318 (54076)	Loss/tok 2.9375 (3.1161)	Learning Rate [7.8125e-05]
6: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
15: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00092)	Tok/s 36000 (54200)	Loss/tok 2.9739 (3.1141)	Learning Rate [7.8125e-05]
13: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00096)	Tok/s 35991 (53977)	Loss/tok 2.9543 (3.1177)	Learning Rate [7.8125e-05]
12: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00108 (0.00102)	Tok/s 36004 (53878)	Loss/tok 2.7570 (3.1201)	Learning Rate [7.8125e-05]
0: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00096)	Tok/s 34755 (52814)	Loss/tok 2.9557 (3.1256)	Learning Rate [7.8125e-05]
14: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00092)	Tok/s 35931 (54083)	Loss/tok 2.8219 (3.1160)	Learning Rate [7.8125e-05]
1: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00100)	Tok/s 34763 (52912)	Loss/tok 2.8524 (3.1156)	Learning Rate [7.8125e-05]
2: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00098)	Tok/s 36003 (53021)	Loss/tok 3.0427 (3.1152)	Learning Rate [7.8125e-05]
4: TRAIN [2][1360/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00098)	Tok/s 36050 (53210)	Loss/tok 2.9172 (3.1183)	Learning Rate [7.8125e-05]
10: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00097)	Tok/s 35995 (53671)	Loss/tok 2.8994 (3.1083)	Learning Rate [7.8125e-05]
11: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00092)	Tok/s 35902 (53757)	Loss/tok 3.0515 (3.1212)	Learning Rate [7.8125e-05]
3: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00092)	Tok/s 35978 (53117)	Loss/tok 3.0340 (3.1176)	Learning Rate [7.8125e-05]
5: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00093)	Tok/s 35991 (53298)	Loss/tok 3.0447 (3.1168)	Learning Rate [7.8125e-05]
6: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00092)	Tok/s 35969 (53378)	Loss/tok 2.7697 (3.1227)	Learning Rate [7.8125e-05]
9: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00091)	Tok/s 35920 (53592)	Loss/tok 2.8165 (3.1153)	Learning Rate [7.8125e-05]
7: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00097)	Tok/s 35919 (53462)	Loss/tok 2.9427 (3.1166)	Learning Rate [7.8125e-05]
8: TRAIN [2][1360/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00098)	Tok/s 35914 (53534)	Loss/tok 2.8731 (3.1200)	Learning Rate [7.8125e-05]
6: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 56959 (53404)	Loss/tok 3.4731 (3.1225)	Learning Rate [7.8125e-05]
7: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00097)	Tok/s 56895 (53487)	Loss/tok 3.1542 (3.1165)	Learning Rate [7.8125e-05]
8: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00098)	Tok/s 56839 (53559)	Loss/tok 3.1847 (3.1198)	Learning Rate [7.8125e-05]
1: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 56869 (52938)	Loss/tok 3.2910 (3.1153)	Learning Rate [7.8125e-05]
2: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00098)	Tok/s 56941 (53048)	Loss/tok 3.1204 (3.1147)	Learning Rate [7.8125e-05]
9: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00091)	Tok/s 57505 (53617)	Loss/tok 3.2338 (3.1160)	Learning Rate [7.8125e-05]
3: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 56939 (53143)	Loss/tok 3.2563 (3.1181)	Learning Rate [7.8125e-05]
5: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00093)	Tok/s 56954 (53325)	Loss/tok 3.1570 (3.1165)	Learning Rate [7.8125e-05]
0: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 56859 (52841)	Loss/tok 3.0055 (3.1250)	Learning Rate [7.8125e-05]
13: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 57733 (54001)	Loss/tok 3.1554 (3.1173)	Learning Rate [7.8125e-05]
4: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 56970 (53237)	Loss/tok 3.2506 (3.1182)	Learning Rate [7.8125e-05]
12: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00102)	Tok/s 57646 (53903)	Loss/tok 3.2658 (3.1202)	Learning Rate [7.8125e-05]
10: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 57689 (53696)	Loss/tok 3.5213 (3.1087)	Learning Rate [7.8125e-05]
15: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 57740 (54223)	Loss/tok 3.3004 (3.1146)	Learning Rate [7.8125e-05]
14: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 57683 (54106)	Loss/tok 3.2823 (3.1163)	Learning Rate [7.8125e-05]
11: TRAIN [2][1370/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 57674 (53782)	Loss/tok 3.2930 (3.1214)	Learning Rate [7.8125e-05]
8: Gradient norm: inf
9: Gradient norm: inf
8: Skipped batch, new scale: 2048.0
7: Gradient norm: inf
9: Skipped batch, new scale: 2048.0
6: Gradient norm: inf
7: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
6: Skipped batch, new scale: 2048.0
10: Skipped batch, new scale: 2048.0
11: Gradient norm: inf
5: Gradient norm: inf
4: Gradient norm: inf
12: Gradient norm: inf
11: Skipped batch, new scale: 2048.0
4: Skipped batch, new scale: 2048.0
12: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
13: Gradient norm: inf
3: Gradient norm: inf
13: Skipped batch, new scale: 2048.0
14: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
0: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
0: Skipped batch, new scale: 2048.0
15: Skipped batch, new scale: 2048.0
3: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00083 (0.00092)	Tok/s 52514 (53131)	Loss/tok 3.2631 (3.1176)	Learning Rate [7.8125e-05]
2: TRAIN [2][1380/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00098)	Tok/s 51845 (53034)	Loss/tok 3.3058 (3.1142)	Learning Rate [7.8125e-05]
4: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00098)	Tok/s 52804 (53224)	Loss/tok 3.0757 (3.1178)	Learning Rate [7.8125e-05]
1: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00100)	Tok/s 51824 (52923)	Loss/tok 2.8985 (3.1147)	Learning Rate [7.8125e-05]
0: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00096)	Tok/s 51833 (52826)	Loss/tok 3.1076 (3.1245)	Learning Rate [7.8125e-05]
6: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00092)	Tok/s 52676 (53375)	Loss/tok 3.3381 (3.1223)	Learning Rate [7.8125e-05]
5: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00086 (0.00093)	Tok/s 52684 (53311)	Loss/tok 3.4181 (3.1165)	Learning Rate [7.8125e-05]
15: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00092)	Tok/s 52880 (54209)	Loss/tok 3.1781 (3.1137)	Learning Rate [7.8125e-05]
7: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00104 (0.00097)	Tok/s 52692 (53458)	Loss/tok 2.9858 (3.1162)	Learning Rate [7.8125e-05]
8: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00098)	Tok/s 52726 (53530)	Loss/tok 2.9022 (3.1190)	Learning Rate [7.8125e-05]
14: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00102 (0.00092)	Tok/s 52834 (54092)	Loss/tok 2.9549 (3.1153)	Learning Rate [7.8125e-05]
13: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00096)	Tok/s 52874 (53986)	Loss/tok 3.0574 (3.1169)	Learning Rate [7.8125e-05]
9: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00091)	Tok/s 52667 (53603)	Loss/tok 3.1201 (3.1153)	Learning Rate [7.8125e-05]
12: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00102)	Tok/s 52772 (53887)	Loss/tok 3.3138 (3.1196)	Learning Rate [7.8125e-05]
10: TRAIN [2][1380/3416]	Time 0.060 (0.058)	Data 0.00117 (0.00097)	Tok/s 53323 (53681)	Loss/tok 3.1174 (3.1081)	Learning Rate [7.8125e-05]
11: TRAIN [2][1380/3416]	Time 0.061 (0.058)	Data 0.00083 (0.00092)	Tok/s 52717 (53767)	Loss/tok 3.3673 (3.1212)	Learning Rate [7.8125e-05]
4: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00098)	Tok/s 54098 (53223)	Loss/tok 3.2437 (3.1174)	Learning Rate [7.8125e-05]
2: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00098)	Tok/s 53892 (53034)	Loss/tok 2.9865 (3.1138)	Learning Rate [7.8125e-05]
6: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00081 (0.00092)	Tok/s 53969 (53374)	Loss/tok 3.1065 (3.1217)	Learning Rate [7.8125e-05]
5: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00082 (0.00093)	Tok/s 53961 (53310)	Loss/tok 3.0904 (3.1166)	Learning Rate [7.8125e-05]
8: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00098)	Tok/s 54023 (53530)	Loss/tok 3.1164 (3.1196)	Learning Rate [7.8125e-05]
1: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00100)	Tok/s 53001 (52922)	Loss/tok 3.0790 (3.1144)	Learning Rate [7.8125e-05]
7: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00097)	Tok/s 53970 (53458)	Loss/tok 3.2096 (3.1160)	Learning Rate [7.8125e-05]
15: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00092)	Tok/s 53962 (54206)	Loss/tok 3.3970 (3.1145)	Learning Rate [7.8125e-05]
9: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00091)	Tok/s 53936 (53602)	Loss/tok 3.1460 (3.1152)	Learning Rate [7.8125e-05]
14: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00092)	Tok/s 53970 (54090)	Loss/tok 2.9822 (3.1150)	Learning Rate [7.8125e-05]
0: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00096)	Tok/s 52950 (52825)	Loss/tok 3.2995 (3.1249)	Learning Rate [7.8125e-05]
11: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00076 (0.00092)	Tok/s 53922 (53767)	Loss/tok 3.1273 (3.1209)	Learning Rate [7.8125e-05]
13: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00096)	Tok/s 53930 (53984)	Loss/tok 3.2795 (3.1166)	Learning Rate [7.8125e-05]
10: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00097)	Tok/s 53878 (53680)	Loss/tok 3.2269 (3.1084)	Learning Rate [7.8125e-05]
12: TRAIN [2][1390/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00102)	Tok/s 53865 (53886)	Loss/tok 3.0859 (3.1198)	Learning Rate [7.8125e-05]
3: TRAIN [2][1390/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00092)	Tok/s 53267 (53129)	Loss/tok 3.3309 (3.1176)	Learning Rate [7.8125e-05]
7: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00097)	Tok/s 47451 (53450)	Loss/tok 2.9640 (3.1159)	Learning Rate [7.8125e-05]
6: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00092)	Tok/s 47431 (53365)	Loss/tok 3.0404 (3.1216)	Learning Rate [7.8125e-05]
8: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00098)	Tok/s 47635 (53522)	Loss/tok 2.9536 (3.1187)	Learning Rate [7.8125e-05]
9: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00091)	Tok/s 48620 (53595)	Loss/tok 3.0484 (3.1150)	Learning Rate [7.8125e-05]
5: TRAIN [2][1400/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00093)	Tok/s 47468 (53300)	Loss/tok 2.8872 (3.1167)	Learning Rate [7.8125e-05]
4: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00098)	Tok/s 47409 (53213)	Loss/tok 2.9449 (3.1166)	Learning Rate [7.8125e-05]
10: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 48584 (53673)	Loss/tok 2.9356 (3.1081)	Learning Rate [7.8125e-05]
11: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00083 (0.00092)	Tok/s 48460 (53759)	Loss/tok 3.1024 (3.1207)	Learning Rate [7.8125e-05]
3: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00092)	Tok/s 47420 (53121)	Loss/tok 2.8605 (3.1168)	Learning Rate [7.8125e-05]
2: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00098)	Tok/s 47365 (53025)	Loss/tok 2.7923 (3.1137)	Learning Rate [7.8125e-05]
12: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00102)	Tok/s 48469 (53878)	Loss/tok 3.0793 (3.1198)	Learning Rate [7.8125e-05]
1: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00100)	Tok/s 47286 (52913)	Loss/tok 2.8457 (3.1140)	Learning Rate [7.8125e-05]
13: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00096)	Tok/s 48460 (53975)	Loss/tok 3.0703 (3.1162)	Learning Rate [7.8125e-05]
0: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00096)	Tok/s 47171 (52816)	Loss/tok 3.0871 (3.1251)	Learning Rate [7.8125e-05]
14: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00092)	Tok/s 48436 (54080)	Loss/tok 3.2265 (3.1151)	Learning Rate [7.8125e-05]
15: TRAIN [2][1400/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00092)	Tok/s 48524 (54196)	Loss/tok 3.1502 (3.1141)	Learning Rate [7.8125e-05]
4: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00094 (0.00098)	Tok/s 17646 (53176)	Loss/tok 1.7356 (3.1163)	Learning Rate [7.8125e-05]
6: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00096 (0.00092)	Tok/s 21187 (53329)	Loss/tok 1.9051 (3.1211)	Learning Rate [7.8125e-05]
3: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00091 (0.00092)	Tok/s 17073 (53084)	Loss/tok 1.5693 (3.1166)	Learning Rate [7.8125e-05]
5: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00101 (0.00093)	Tok/s 20728 (53265)	Loss/tok 1.9954 (3.1162)	Learning Rate [7.8125e-05]
2: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00092 (0.00098)	Tok/s 14794 (52988)	Loss/tok 1.9085 (3.1133)	Learning Rate [7.8125e-05]
7: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00101 (0.00097)	Tok/s 22909 (53415)	Loss/tok 2.0997 (3.1158)	Learning Rate [7.8125e-05]
1: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00097 (0.00100)	Tok/s 11651 (52874)	Loss/tok 1.7260 (3.1140)	Learning Rate [7.8125e-05]
8: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00100 (0.00098)	Tok/s 23963 (53488)	Loss/tok 1.9414 (3.1186)	Learning Rate [7.8125e-05]
15: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00089 (0.00092)	Tok/s 27400 (54165)	Loss/tok 2.2991 (3.1139)	Learning Rate [7.8125e-05]
0: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00104 (0.00096)	Tok/s 9369 (52775)	Loss/tok 1.5756 (3.1247)	Learning Rate [7.8125e-05]
9: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00094 (0.00091)	Tok/s 24611 (53562)	Loss/tok 1.9808 (3.1143)	Learning Rate [7.8125e-05]
14: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00084 (0.00092)	Tok/s 26216 (54048)	Loss/tok 2.1758 (3.1147)	Learning Rate [7.8125e-05]
11: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00096 (0.00092)	Tok/s 24479 (53726)	Loss/tok 1.9725 (3.1207)	Learning Rate [7.8125e-05]
13: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00095 (0.00096)	Tok/s 26212 (53943)	Loss/tok 2.1642 (3.1158)	Learning Rate [7.8125e-05]
12: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00102 (0.00102)	Tok/s 25225 (53845)	Loss/tok 2.1011 (3.1194)	Learning Rate [7.8125e-05]
10: TRAIN [2][1410/3416]	Time 0.034 (0.058)	Data 0.00115 (0.00097)	Tok/s 24429 (53640)	Loss/tok 1.8988 (3.1079)	Learning Rate [7.8125e-05]
8: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 67958 (53496)	Loss/tok 3.2081 (3.1183)	Learning Rate [7.8125e-05]
7: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 67285 (53423)	Loss/tok 3.3038 (3.1159)	Learning Rate [7.8125e-05]
1: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 66691 (52882)	Loss/tok 3.2077 (3.1137)	Learning Rate [7.8125e-05]
9: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 67860 (53570)	Loss/tok 3.2849 (3.1144)	Learning Rate [7.8125e-05]
6: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 66911 (53336)	Loss/tok 3.0935 (3.1208)	Learning Rate [7.8125e-05]
0: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 66671 (52784)	Loss/tok 3.0713 (3.1238)	Learning Rate [7.8125e-05]
4: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 66739 (53183)	Loss/tok 3.3153 (3.1162)	Learning Rate [7.8125e-05]
10: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 67821 (53648)	Loss/tok 3.0686 (3.1077)	Learning Rate [7.8125e-05]
5: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 66825 (53271)	Loss/tok 3.2556 (3.1156)	Learning Rate [7.8125e-05]
15: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 67617 (54173)	Loss/tok 3.2104 (3.1137)	Learning Rate [7.8125e-05]
2: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 66667 (52995)	Loss/tok 3.2195 (3.1132)	Learning Rate [7.8125e-05]
14: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 67630 (54057)	Loss/tok 3.2090 (3.1142)	Learning Rate [7.8125e-05]
13: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 67653 (53952)	Loss/tok 3.3782 (3.1153)	Learning Rate [7.8125e-05]
12: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00102)	Tok/s 67715 (53853)	Loss/tok 3.1956 (3.1193)	Learning Rate [7.8125e-05]
3: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00092)	Tok/s 66755 (53091)	Loss/tok 3.2211 (3.1165)	Learning Rate [7.8125e-05]
11: TRAIN [2][1420/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 67804 (53733)	Loss/tok 3.3351 (3.1210)	Learning Rate [7.8125e-05]
2: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00098)	Tok/s 70667 (52971)	Loss/tok 3.2871 (3.1128)	Learning Rate [7.8125e-05]
4: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 70514 (53159)	Loss/tok 3.3140 (3.1166)	Learning Rate [7.8125e-05]
3: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 70603 (53067)	Loss/tok 3.3495 (3.1163)	Learning Rate [7.8125e-05]
1: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00100)	Tok/s 70656 (52859)	Loss/tok 3.0983 (3.1136)	Learning Rate [7.8125e-05]
0: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00096)	Tok/s 70660 (52762)	Loss/tok 3.1068 (3.1231)	Learning Rate [7.8125e-05]
6: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 70768 (53311)	Loss/tok 3.0417 (3.1204)	Learning Rate [7.8125e-05]
15: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 71567 (54146)	Loss/tok 3.3349 (3.1138)	Learning Rate [7.8125e-05]
7: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00097)	Tok/s 71455 (53398)	Loss/tok 3.2553 (3.1157)	Learning Rate [7.8125e-05]
14: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00092)	Tok/s 71577 (54029)	Loss/tok 2.9362 (3.1139)	Learning Rate [7.8125e-05]
8: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 71372 (53471)	Loss/tok 3.0182 (3.1178)	Learning Rate [7.8125e-05]
9: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 71452 (53544)	Loss/tok 3.1641 (3.1141)	Learning Rate [7.8125e-05]
10: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 71417 (53621)	Loss/tok 3.2531 (3.1075)	Learning Rate [7.8125e-05]
11: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00092)	Tok/s 71574 (53707)	Loss/tok 3.1469 (3.1206)	Learning Rate [7.8125e-05]
12: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00102)	Tok/s 71541 (53826)	Loss/tok 3.0830 (3.1189)	Learning Rate [7.8125e-05]
13: TRAIN [2][1430/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 71394 (53924)	Loss/tok 3.2537 (3.1154)	Learning Rate [7.8125e-05]
5: TRAIN [2][1430/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00093)	Tok/s 69372 (53246)	Loss/tok 3.4267 (3.1159)	Learning Rate [7.8125e-05]
6: TRAIN [2][1440/3416]	Time 0.039 (0.058)	Data 0.00088 (0.00092)	Tok/s 31073 (53259)	Loss/tok 2.5101 (3.1202)	Learning Rate [7.8125e-05]
5: TRAIN [2][1440/3416]	Time 0.039 (0.058)	Data 0.00095 (0.00093)	Tok/s 30711 (53192)	Loss/tok 2.6160 (3.1157)	Learning Rate [7.8125e-05]
4: TRAIN [2][1440/3416]	Time 0.039 (0.058)	Data 0.00094 (0.00098)	Tok/s 29366 (53103)	Loss/tok 2.4919 (3.1164)	Learning Rate [7.8125e-05]
8: TRAIN [2][1440/3416]	Time 0.039 (0.058)	Data 0.00093 (0.00098)	Tok/s 30881 (53420)	Loss/tok 2.6451 (3.1171)	Learning Rate [7.8125e-05]
9: TRAIN [2][1440/3416]	Time 0.039 (0.058)	Data 0.00089 (0.00091)	Tok/s 30810 (53492)	Loss/tok 2.3560 (3.1136)	Learning Rate [7.8125e-05]
3: TRAIN [2][1440/3416]	Time 0.039 (0.058)	Data 0.00089 (0.00092)	Tok/s 29265 (53010)	Loss/tok 2.4184 (3.1159)	Learning Rate [7.8125e-05]
7: TRAIN [2][1440/3416]	Time 0.039 (0.058)	Data 0.00097 (0.00097)	Tok/s 31011 (53347)	Loss/tok 2.4493 (3.1154)	Learning Rate [7.8125e-05]
2: TRAIN [2][1440/3416]	Time 0.039 (0.058)	Data 0.00093 (0.00098)	Tok/s 29186 (52913)	Loss/tok 2.4521 (3.1130)	Learning Rate [7.8125e-05]
1: TRAIN [2][1440/3416]	Time 0.040 (0.058)	Data 0.00099 (0.00100)	Tok/s 29108 (52800)	Loss/tok 2.4779 (3.1137)	Learning Rate [7.8125e-05]
10: TRAIN [2][1440/3416]	Time 0.040 (0.058)	Data 0.00088 (0.00097)	Tok/s 30654 (53569)	Loss/tok 2.5707 (3.1071)	Learning Rate [7.8125e-05]
11: TRAIN [2][1440/3416]	Time 0.040 (0.058)	Data 0.00087 (0.00092)	Tok/s 30618 (53656)	Loss/tok 2.4235 (3.1201)	Learning Rate [7.8125e-05]
0: TRAIN [2][1440/3416]	Time 0.040 (0.058)	Data 0.00091 (0.00096)	Tok/s 29016 (52701)	Loss/tok 2.5518 (3.1228)	Learning Rate [7.8125e-05]
15: TRAIN [2][1440/3416]	Time 0.040 (0.058)	Data 0.00085 (0.00092)	Tok/s 32167 (54096)	Loss/tok 2.5932 (3.1136)	Learning Rate [7.8125e-05]
12: TRAIN [2][1440/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00102)	Tok/s 30516 (53776)	Loss/tok 2.6717 (3.1189)	Learning Rate [7.8125e-05]
14: TRAIN [2][1440/3416]	Time 0.040 (0.058)	Data 0.00086 (0.00092)	Tok/s 32098 (53980)	Loss/tok 2.6997 (3.1138)	Learning Rate [7.8125e-05]
13: TRAIN [2][1440/3416]	Time 0.040 (0.058)	Data 0.00091 (0.00096)	Tok/s 31674 (53875)	Loss/tok 2.3631 (3.1149)	Learning Rate [7.8125e-05]
2: TRAIN [2][1450/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00098)	Tok/s 53858 (52894)	Loss/tok 3.3505 (3.1131)	Learning Rate [7.8125e-05]
3: TRAIN [2][1450/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00092)	Tok/s 54600 (52991)	Loss/tok 2.9472 (3.1158)	Learning Rate [7.8125e-05]
4: TRAIN [2][1450/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00098)	Tok/s 54515 (53085)	Loss/tok 2.9902 (3.1163)	Learning Rate [7.8125e-05]
1: TRAIN [2][1450/3416]	Time 0.056 (0.058)	Data 0.00086 (0.00100)	Tok/s 53456 (52778)	Loss/tok 3.1189 (3.1135)	Learning Rate [7.8125e-05]
0: TRAIN [2][1450/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00096)	Tok/s 53324 (52677)	Loss/tok 3.2965 (3.1227)	Learning Rate [7.8125e-05]
6: TRAIN [2][1450/3416]	Time 0.057 (0.058)	Data 0.00089 (0.00092)	Tok/s 54278 (53242)	Loss/tok 3.1798 (3.1203)	Learning Rate [7.8125e-05]
15: TRAIN [2][1450/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00092)	Tok/s 54410 (54080)	Loss/tok 3.2339 (3.1138)	Learning Rate [7.8125e-05]
7: TRAIN [2][1450/3416]	Time 0.057 (0.058)	Data 0.00106 (0.00097)	Tok/s 54156 (53330)	Loss/tok 3.1644 (3.1157)	Learning Rate [7.8125e-05]
8: TRAIN [2][1450/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00098)	Tok/s 54118 (53403)	Loss/tok 3.1655 (3.1172)	Learning Rate [7.8125e-05]
14: TRAIN [2][1450/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00092)	Tok/s 54362 (53963)	Loss/tok 3.2725 (3.1135)	Learning Rate [7.8125e-05]
13: TRAIN [2][1450/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00096)	Tok/s 54258 (53858)	Loss/tok 3.0706 (3.1148)	Learning Rate [7.8125e-05]
9: TRAIN [2][1450/3416]	Time 0.057 (0.058)	Data 0.00080 (0.00091)	Tok/s 54037 (53475)	Loss/tok 3.1200 (3.1134)	Learning Rate [7.8125e-05]
11: TRAIN [2][1450/3416]	Time 0.057 (0.058)	Data 0.00089 (0.00092)	Tok/s 54132 (53639)	Loss/tok 3.1058 (3.1208)	Learning Rate [7.8125e-05]
12: TRAIN [2][1450/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00102)	Tok/s 54133 (53759)	Loss/tok 3.0445 (3.1192)	Learning Rate [7.8125e-05]
5: TRAIN [2][1450/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00093)	Tok/s 54423 (53174)	Loss/tok 3.2165 (3.1152)	Learning Rate [7.8125e-05]
10: TRAIN [2][1450/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00097)	Tok/s 53985 (53553)	Loss/tok 3.0881 (3.1072)	Learning Rate [7.8125e-05]
1: TRAIN [2][1460/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00100)	Tok/s 54244 (52768)	Loss/tok 3.3746 (3.1134)	Learning Rate [7.8125e-05]
0: TRAIN [2][1460/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00096)	Tok/s 54163 (52668)	Loss/tok 2.9103 (3.1225)	Learning Rate [7.8125e-05]
2: TRAIN [2][1460/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00098)	Tok/s 54452 (52883)	Loss/tok 3.2892 (3.1130)	Learning Rate [7.8125e-05]
14: TRAIN [2][1460/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00092)	Tok/s 55047 (53954)	Loss/tok 2.8879 (3.1134)	Learning Rate [7.8125e-05]
12: TRAIN [2][1460/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00101)	Tok/s 54730 (53749)	Loss/tok 3.1814 (3.1192)	Learning Rate [7.8125e-05]
13: TRAIN [2][1460/3416]	Time 0.062 (0.058)	Data 0.00106 (0.00096)	Tok/s 54920 (53847)	Loss/tok 3.0327 (3.1149)	Learning Rate [7.8125e-05]
10: TRAIN [2][1460/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00097)	Tok/s 54609 (53542)	Loss/tok 2.9313 (3.1069)	Learning Rate [7.8125e-05]
8: TRAIN [2][1460/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00098)	Tok/s 54669 (53392)	Loss/tok 3.3330 (3.1167)	Learning Rate [7.8125e-05]
7: TRAIN [2][1460/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00097)	Tok/s 54757 (53319)	Loss/tok 3.2478 (3.1163)	Learning Rate [7.8125e-05]
11: TRAIN [2][1460/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00092)	Tok/s 54701 (53628)	Loss/tok 3.0376 (3.1206)	Learning Rate [7.8125e-05]
15: TRAIN [2][1460/3416]	Time 0.062 (0.058)	Data 0.00076 (0.00092)	Tok/s 55112 (54070)	Loss/tok 3.4154 (3.1142)	Learning Rate [7.8125e-05]
9: TRAIN [2][1460/3416]	Time 0.062 (0.058)	Data 0.00084 (0.00091)	Tok/s 54638 (53464)	Loss/tok 3.2210 (3.1137)	Learning Rate [7.8125e-05]
5: TRAIN [2][1460/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00093)	Tok/s 54938 (53164)	Loss/tok 2.9873 (3.1155)	Learning Rate [7.8125e-05]
6: TRAIN [2][1460/3416]	Time 0.062 (0.058)	Data 0.00084 (0.00092)	Tok/s 54854 (53231)	Loss/tok 2.9652 (3.1202)	Learning Rate [7.8125e-05]
4: TRAIN [2][1460/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00098)	Tok/s 55043 (53075)	Loss/tok 3.0400 (3.1159)	Learning Rate [7.8125e-05]
3: TRAIN [2][1460/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00092)	Tok/s 55141 (52980)	Loss/tok 3.1561 (3.1159)	Learning Rate [7.8125e-05]
3: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00258 (0.00092)	Tok/s 79476 (53024)	Loss/tok 3.0067 (3.1166)	Learning Rate [7.8125e-05]
1: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00103 (0.00100)	Tok/s 78618 (52800)	Loss/tok 3.2076 (3.1141)	Learning Rate [7.8125e-05]
0: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00103 (0.00096)	Tok/s 78600 (52700)	Loss/tok 3.1109 (3.1231)	Learning Rate [7.8125e-05]
4: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00101 (0.00098)	Tok/s 79352 (53120)	Loss/tok 3.0719 (3.1166)	Learning Rate [7.8125e-05]
15: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00116 (0.00092)	Tok/s 81040 (54111)	Loss/tok 2.9550 (3.1145)	Learning Rate [7.8125e-05]
6: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00092)	Tok/s 79161 (53275)	Loss/tok 3.1913 (3.1206)	Learning Rate [7.8125e-05]
14: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00092)	Tok/s 80211 (53995)	Loss/tok 3.0191 (3.1139)	Learning Rate [7.8125e-05]
11: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00092)	Tok/s 80022 (53670)	Loss/tok 2.9459 (3.1209)	Learning Rate [7.8125e-05]
13: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00113 (0.00096)	Tok/s 80079 (53889)	Loss/tok 3.0064 (3.1156)	Learning Rate [7.8125e-05]
7: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00107 (0.00097)	Tok/s 79017 (53362)	Loss/tok 3.0066 (3.1168)	Learning Rate [7.8125e-05]
9: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00091)	Tok/s 79769 (53508)	Loss/tok 3.1234 (3.1142)	Learning Rate [7.8125e-05]
8: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00101 (0.00098)	Tok/s 79122 (53435)	Loss/tok 2.9817 (3.1180)	Learning Rate [7.8125e-05]
12: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00102 (0.00102)	Tok/s 79949 (53791)	Loss/tok 3.0087 (3.1195)	Learning Rate [7.8125e-05]
10: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00109 (0.00097)	Tok/s 79841 (53585)	Loss/tok 2.9113 (3.1073)	Learning Rate [7.8125e-05]
5: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00093)	Tok/s 79238 (53208)	Loss/tok 3.0167 (3.1163)	Learning Rate [7.8125e-05]
2: TRAIN [2][1470/3416]	Time 0.071 (0.058)	Data 0.00103 (0.00098)	Tok/s 78876 (52914)	Loss/tok 3.2243 (3.1135)	Learning Rate [7.8125e-05]
0: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00096)	Tok/s 49310 (52710)	Loss/tok 3.2622 (3.1232)	Learning Rate [7.8125e-05]
1: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00100)	Tok/s 49182 (52810)	Loss/tok 2.8974 (3.1139)	Learning Rate [7.8125e-05]
15: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00092)	Tok/s 50682 (54122)	Loss/tok 2.9705 (3.1151)	Learning Rate [7.8125e-05]
14: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00092)	Tok/s 49350 (54005)	Loss/tok 3.1132 (3.1139)	Learning Rate [7.8125e-05]
2: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00098)	Tok/s 49147 (52924)	Loss/tok 3.0897 (3.1137)	Learning Rate [7.8125e-05]
3: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00092)	Tok/s 48935 (53034)	Loss/tok 2.7051 (3.1163)	Learning Rate [7.8125e-05]
13: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00096)	Tok/s 49271 (53899)	Loss/tok 3.2031 (3.1158)	Learning Rate [7.8125e-05]
11: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00092)	Tok/s 49036 (53681)	Loss/tok 2.8962 (3.1207)	Learning Rate [7.8125e-05]
4: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00098)	Tok/s 48835 (53130)	Loss/tok 2.9765 (3.1171)	Learning Rate [7.8125e-05]
12: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00102)	Tok/s 49144 (53801)	Loss/tok 2.9754 (3.1195)	Learning Rate [7.8125e-05]
5: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00093)	Tok/s 48665 (53218)	Loss/tok 3.2120 (3.1157)	Learning Rate [7.8125e-05]
9: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00091)	Tok/s 48710 (53519)	Loss/tok 3.0284 (3.1143)	Learning Rate [7.8125e-05]
6: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00092)	Tok/s 48597 (53285)	Loss/tok 3.0432 (3.1207)	Learning Rate [7.8125e-05]
10: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00116 (0.00097)	Tok/s 48901 (53596)	Loss/tok 2.9581 (3.1071)	Learning Rate [7.8125e-05]
8: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00114 (0.00098)	Tok/s 48682 (53447)	Loss/tok 3.1104 (3.1186)	Learning Rate [7.8125e-05]
7: TRAIN [2][1480/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00097)	Tok/s 48582 (53372)	Loss/tok 2.9786 (3.1166)	Learning Rate [7.8125e-05]
0: TRAIN [2][1490/3416]	Time 0.040 (0.058)	Data 0.00088 (0.00096)	Tok/s 28650 (52675)	Loss/tok 2.4240 (3.1229)	Learning Rate [7.8125e-05]
1: TRAIN [2][1490/3416]	Time 0.040 (0.058)	Data 0.00089 (0.00100)	Tok/s 28582 (52778)	Loss/tok 2.3813 (3.1136)	Learning Rate [7.8125e-05]
15: TRAIN [2][1490/3416]	Time 0.040 (0.058)	Data 0.00087 (0.00092)	Tok/s 31734 (54098)	Loss/tok 2.5828 (3.1153)	Learning Rate [7.8125e-05]
2: TRAIN [2][1490/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00098)	Tok/s 28497 (52894)	Loss/tok 2.5566 (3.1135)	Learning Rate [7.8125e-05]
14: TRAIN [2][1490/3416]	Time 0.040 (0.058)	Data 0.00081 (0.00092)	Tok/s 31772 (53981)	Loss/tok 2.5919 (3.1139)	Learning Rate [7.8125e-05]
3: TRAIN [2][1490/3416]	Time 0.041 (0.058)	Data 0.00087 (0.00092)	Tok/s 28432 (53004)	Loss/tok 2.6039 (3.1158)	Learning Rate [7.8125e-05]
13: TRAIN [2][1490/3416]	Time 0.040 (0.058)	Data 0.00096 (0.00096)	Tok/s 31155 (53874)	Loss/tok 2.6814 (3.1156)	Learning Rate [7.8125e-05]
12: TRAIN [2][1490/3416]	Time 0.040 (0.058)	Data 0.00092 (0.00101)	Tok/s 30097 (53776)	Loss/tok 2.3430 (3.1190)	Learning Rate [7.8125e-05]
4: TRAIN [2][1490/3416]	Time 0.041 (0.058)	Data 0.00083 (0.00098)	Tok/s 28758 (53102)	Loss/tok 2.3665 (3.1171)	Learning Rate [7.8125e-05]
11: TRAIN [2][1490/3416]	Time 0.041 (0.058)	Data 0.00099 (0.00092)	Tok/s 29963 (53655)	Loss/tok 2.5748 (3.1207)	Learning Rate [7.8125e-05]
5: TRAIN [2][1490/3416]	Time 0.041 (0.058)	Data 0.00085 (0.00093)	Tok/s 29861 (53191)	Loss/tok 2.5642 (3.1158)	Learning Rate [7.8125e-05]
6: TRAIN [2][1490/3416]	Time 0.041 (0.058)	Data 0.00087 (0.00092)	Tok/s 29805 (53258)	Loss/tok 2.2167 (3.1207)	Learning Rate [7.8125e-05]
10: TRAIN [2][1490/3416]	Time 0.041 (0.058)	Data 0.00102 (0.00097)	Tok/s 29791 (53570)	Loss/tok 2.5841 (3.1070)	Learning Rate [7.8125e-05]
8: TRAIN [2][1490/3416]	Time 0.041 (0.058)	Data 0.00093 (0.00098)	Tok/s 29782 (53421)	Loss/tok 2.4550 (3.1185)	Learning Rate [7.8125e-05]
9: TRAIN [2][1490/3416]	Time 0.041 (0.058)	Data 0.00090 (0.00091)	Tok/s 29822 (53493)	Loss/tok 2.6641 (3.1144)	Learning Rate [7.8125e-05]
7: TRAIN [2][1490/3416]	Time 0.041 (0.058)	Data 0.00084 (0.00097)	Tok/s 29620 (53346)	Loss/tok 2.5296 (3.1164)	Learning Rate [7.8125e-05]
6: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00092)	Tok/s 51304 (53243)	Loss/tok 3.0718 (3.1205)	Learning Rate [7.8125e-05]
4: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00098)	Tok/s 51292 (53087)	Loss/tok 2.9319 (3.1170)	Learning Rate [7.8125e-05]
5: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00093)	Tok/s 51327 (53176)	Loss/tok 3.2667 (3.1156)	Learning Rate [7.8125e-05]
7: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00106 (0.00097)	Tok/s 51273 (53329)	Loss/tok 3.1160 (3.1162)	Learning Rate [7.8125e-05]
3: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00092)	Tok/s 50286 (52989)	Loss/tok 3.1333 (3.1162)	Learning Rate [7.8125e-05]
2: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00102 (0.00098)	Tok/s 49911 (52879)	Loss/tok 3.0721 (3.1136)	Learning Rate [7.8125e-05]
1: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00100)	Tok/s 49846 (52763)	Loss/tok 3.0127 (3.1136)	Learning Rate [7.8125e-05]
8: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00098)	Tok/s 51126 (53404)	Loss/tok 2.9963 (3.1180)	Learning Rate [7.8125e-05]
0: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00110 (0.00096)	Tok/s 49750 (52662)	Loss/tok 2.8336 (3.1223)	Learning Rate [7.8125e-05]
9: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00091)	Tok/s 50994 (53476)	Loss/tok 2.9910 (3.1139)	Learning Rate [7.8125e-05]
15: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00105 (0.00092)	Tok/s 50925 (54080)	Loss/tok 3.1545 (3.1152)	Learning Rate [7.8125e-05]
10: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00107 (0.00097)	Tok/s 50922 (53553)	Loss/tok 3.1368 (3.1071)	Learning Rate [7.8125e-05]
11: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00092)	Tok/s 50798 (53638)	Loss/tok 3.0686 (3.1202)	Learning Rate [7.8125e-05]
14: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00092)	Tok/s 50825 (53963)	Loss/tok 3.0509 (3.1138)	Learning Rate [7.8125e-05]
13: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00107 (0.00096)	Tok/s 50846 (53857)	Loss/tok 2.9154 (3.1152)	Learning Rate [7.8125e-05]
12: TRAIN [2][1500/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00101)	Tok/s 50813 (53758)	Loss/tok 3.1811 (3.1189)	Learning Rate [7.8125e-05]
12: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
12: TRAIN [2][1510/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00101)	Tok/s 69049 (53787)	Loss/tok 3.0847 (3.1190)	Learning Rate [7.8125e-05]
13: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00109 (0.00096)	Tok/s 68979 (53885)	Loss/tok 3.2683 (3.1154)	Learning Rate [7.8125e-05]
11: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00102 (0.00092)	Tok/s 68948 (53667)	Loss/tok 2.8979 (3.1204)	Learning Rate [7.8125e-05]
10: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00103 (0.00097)	Tok/s 68859 (53582)	Loss/tok 3.2247 (3.1075)	Learning Rate [7.8125e-05]
14: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00092)	Tok/s 69628 (53991)	Loss/tok 3.3045 (3.1145)	Learning Rate [7.8125e-05]
9: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00085 (0.00091)	Tok/s 68745 (53506)	Loss/tok 3.2082 (3.1144)	Learning Rate [7.8125e-05]
15: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00092)	Tok/s 69757 (54107)	Loss/tok 3.2066 (3.1154)	Learning Rate [7.8125e-05]
8: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00124 (0.00098)	Tok/s 68771 (53433)	Loss/tok 3.0929 (3.1184)	Learning Rate [7.8125e-05]
0: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00100 (0.00096)	Tok/s 67943 (52694)	Loss/tok 3.0476 (3.1217)	Learning Rate [7.8125e-05]
7: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00101 (0.00097)	Tok/s 68768 (53359)	Loss/tok 3.4141 (3.1170)	Learning Rate [7.8125e-05]
6: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00099 (0.00092)	Tok/s 68765 (53273)	Loss/tok 3.2254 (3.1200)	Learning Rate [7.8125e-05]
1: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00100)	Tok/s 68061 (52796)	Loss/tok 2.9897 (3.1135)	Learning Rate [7.8125e-05]
2: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00099 (0.00098)	Tok/s 68873 (52911)	Loss/tok 3.2112 (3.1139)	Learning Rate [7.8125e-05]
5: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00088 (0.00093)	Tok/s 68721 (53206)	Loss/tok 3.2346 (3.1156)	Learning Rate [7.8125e-05]
3: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00092)	Tok/s 68803 (53020)	Loss/tok 3.1096 (3.1166)	Learning Rate [7.8125e-05]
4: TRAIN [2][1510/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00098)	Tok/s 68749 (53118)	Loss/tok 3.4161 (3.1174)	Learning Rate [7.8125e-05]
9: TRAIN [2][1520/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 79089 (53540)	Loss/tok 3.1670 (3.1147)	Learning Rate [7.8125e-05]
6: TRAIN [2][1520/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 79179 (53307)	Loss/tok 3.2054 (3.1208)	Learning Rate [7.8125e-05]
5: TRAIN [2][1520/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 79274 (53241)	Loss/tok 2.9789 (3.1163)	Learning Rate [7.8125e-05]
10: TRAIN [2][1520/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 79520 (53616)	Loss/tok 3.0467 (3.1074)	Learning Rate [7.8125e-05]
2: TRAIN [2][1520/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 78586 (52946)	Loss/tok 3.0640 (3.1150)	Learning Rate [7.8125e-05]
4: TRAIN [2][1520/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 79300 (53154)	Loss/tok 2.9747 (3.1174)	Learning Rate [7.8125e-05]
11: TRAIN [2][1520/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 79808 (53701)	Loss/tok 2.9487 (3.1208)	Learning Rate [7.8125e-05]
7: TRAIN [2][1520/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 79182 (53394)	Loss/tok 3.2646 (3.1177)	Learning Rate [7.8125e-05]
3: TRAIN [2][1520/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 79252 (53056)	Loss/tok 3.1497 (3.1166)	Learning Rate [7.8125e-05]
1: TRAIN [2][1520/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00100)	Tok/s 78201 (52831)	Loss/tok 3.1290 (3.1146)	Learning Rate [7.8125e-05]
0: TRAIN [2][1520/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 78085 (52729)	Loss/tok 3.0128 (3.1219)	Learning Rate [7.8125e-05]
8: TRAIN [2][1520/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 79133 (53468)	Loss/tok 3.0753 (3.1184)	Learning Rate [7.8125e-05]
12: TRAIN [2][1520/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00101)	Tok/s 79729 (53820)	Loss/tok 3.2120 (3.1197)	Learning Rate [7.8125e-05]
13: TRAIN [2][1520/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 79714 (53918)	Loss/tok 3.1767 (3.1160)	Learning Rate [7.8125e-05]
14: TRAIN [2][1520/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 79706 (54023)	Loss/tok 3.2392 (3.1152)	Learning Rate [7.8125e-05]
15: TRAIN [2][1520/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 79769 (54139)	Loss/tok 3.2668 (3.1155)	Learning Rate [7.8125e-05]
6: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00092)	Tok/s 54011 (53283)	Loss/tok 3.0415 (3.1208)	Learning Rate [7.8125e-05]
5: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00093)	Tok/s 54088 (53217)	Loss/tok 3.1416 (3.1159)	Learning Rate [7.8125e-05]
4: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00098)	Tok/s 54041 (53128)	Loss/tok 3.0361 (3.1177)	Learning Rate [7.8125e-05]
3: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00092)	Tok/s 54085 (53030)	Loss/tok 3.0431 (3.1165)	Learning Rate [7.8125e-05]
8: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00110 (0.00098)	Tok/s 53813 (53445)	Loss/tok 3.1987 (3.1184)	Learning Rate [7.8125e-05]
2: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00098)	Tok/s 54023 (52920)	Loss/tok 3.4239 (3.1155)	Learning Rate [7.8125e-05]
7: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00107 (0.00097)	Tok/s 53839 (53370)	Loss/tok 3.2947 (3.1182)	Learning Rate [7.8125e-05]
1: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00100)	Tok/s 54079 (52804)	Loss/tok 3.1380 (3.1143)	Learning Rate [7.8125e-05]
9: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00091)	Tok/s 53688 (53518)	Loss/tok 3.1917 (3.1146)	Learning Rate [7.8125e-05]
0: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00097)	Tok/s 53895 (52701)	Loss/tok 3.2860 (3.1223)	Learning Rate [7.8125e-05]
11: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00092)	Tok/s 53598 (53678)	Loss/tok 3.2686 (3.1207)	Learning Rate [7.8125e-05]
10: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00097)	Tok/s 53564 (53594)	Loss/tok 3.3545 (3.1076)	Learning Rate [7.8125e-05]
14: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00092)	Tok/s 53754 (54000)	Loss/tok 3.2357 (3.1153)	Learning Rate [7.8125e-05]
12: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00104 (0.00101)	Tok/s 53673 (53798)	Loss/tok 3.3148 (3.1199)	Learning Rate [7.8125e-05]
13: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00096)	Tok/s 53646 (53896)	Loss/tok 3.3082 (3.1161)	Learning Rate [7.8125e-05]
15: TRAIN [2][1530/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00092)	Tok/s 53838 (54117)	Loss/tok 3.2999 (3.1153)	Learning Rate [7.8125e-05]
9: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00091)	Tok/s 57354 (53502)	Loss/tok 3.1465 (3.1144)	Learning Rate [7.8125e-05]
10: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00097)	Tok/s 57338 (53578)	Loss/tok 3.1645 (3.1071)	Learning Rate [7.8125e-05]
8: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00110 (0.00098)	Tok/s 56474 (53428)	Loss/tok 3.1926 (3.1176)	Learning Rate [7.8125e-05]
6: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00092)	Tok/s 56475 (53268)	Loss/tok 3.0883 (3.1202)	Learning Rate [7.8125e-05]
11: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00092)	Tok/s 57261 (53662)	Loss/tok 3.2310 (3.1204)	Learning Rate [7.8125e-05]
7: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00097)	Tok/s 56421 (53354)	Loss/tok 3.1960 (3.1178)	Learning Rate [7.8125e-05]
5: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00093)	Tok/s 56439 (53201)	Loss/tok 3.0384 (3.1153)	Learning Rate [7.8125e-05]
13: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00096)	Tok/s 57373 (53880)	Loss/tok 3.4148 (3.1161)	Learning Rate [7.8125e-05]
12: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00101)	Tok/s 57267 (53781)	Loss/tok 3.2479 (3.1197)	Learning Rate [7.8125e-05]
14: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00092)	Tok/s 57301 (53984)	Loss/tok 3.2379 (3.1147)	Learning Rate [7.8125e-05]
3: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 56441 (53016)	Loss/tok 3.2117 (3.1161)	Learning Rate [7.8125e-05]
4: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00098)	Tok/s 56416 (53113)	Loss/tok 2.9625 (3.1173)	Learning Rate [7.8125e-05]
2: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00098)	Tok/s 56419 (52906)	Loss/tok 2.9975 (3.1152)	Learning Rate [7.8125e-05]
0: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00096)	Tok/s 56342 (52686)	Loss/tok 3.1395 (3.1216)	Learning Rate [7.8125e-05]
1: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00100)	Tok/s 56456 (52790)	Loss/tok 3.3220 (3.1142)	Learning Rate [7.8125e-05]
15: TRAIN [2][1540/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 57291 (54101)	Loss/tok 3.2613 (3.1153)	Learning Rate [7.8125e-05]
4: TRAIN [2][1550/3416]	Time 0.068 (0.058)	Data 0.00282 (0.00098)	Tok/s 59809 (53111)	Loss/tok 3.1390 (3.1172)	Learning Rate [7.8125e-05]
2: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00098)	Tok/s 59693 (52904)	Loss/tok 3.5079 (3.1152)	Learning Rate [7.8125e-05]
1: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00115 (0.00100)	Tok/s 59660 (52788)	Loss/tok 3.4136 (3.1147)	Learning Rate [7.8125e-05]
5: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 59760 (53199)	Loss/tok 3.1470 (3.1155)	Learning Rate [7.8125e-05]
3: TRAIN [2][1550/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00092)	Tok/s 59818 (53013)	Loss/tok 2.9801 (3.1168)	Learning Rate [7.8125e-05]
6: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00092)	Tok/s 59649 (53265)	Loss/tok 3.2693 (3.1206)	Learning Rate [7.8125e-05]
0: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 59506 (52685)	Loss/tok 3.3167 (3.1214)	Learning Rate [7.8125e-05]
7: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00097)	Tok/s 59549 (53351)	Loss/tok 3.0757 (3.1176)	Learning Rate [7.8125e-05]
14: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 60227 (53982)	Loss/tok 3.0787 (3.1145)	Learning Rate [7.8125e-05]
8: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00122 (0.00098)	Tok/s 59424 (53427)	Loss/tok 3.2620 (3.1179)	Learning Rate [7.8125e-05]
9: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00091)	Tok/s 59372 (53500)	Loss/tok 3.1541 (3.1146)	Learning Rate [7.8125e-05]
13: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00096)	Tok/s 59413 (53877)	Loss/tok 3.1421 (3.1159)	Learning Rate [7.8125e-05]
12: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00101)	Tok/s 59265 (53778)	Loss/tok 3.3415 (3.1198)	Learning Rate [7.8125e-05]
11: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 59232 (53659)	Loss/tok 3.3897 (3.1206)	Learning Rate [7.8125e-05]
10: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 59238 (53576)	Loss/tok 3.0897 (3.1072)	Learning Rate [7.8125e-05]
15: TRAIN [2][1550/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00092)	Tok/s 60367 (54099)	Loss/tok 3.3745 (3.1157)	Learning Rate [7.8125e-05]
6: TRAIN [2][1560/3416]	Time 0.057 (0.058)	Data 0.00089 (0.00092)	Tok/s 51558 (53288)	Loss/tok 3.4056 (3.1212)	Learning Rate [7.8125e-05]
7: TRAIN [2][1560/3416]	Time 0.057 (0.058)	Data 0.00114 (0.00097)	Tok/s 51676 (53374)	Loss/tok 2.9758 (3.1175)	Learning Rate [7.8125e-05]
8: TRAIN [2][1560/3416]	Time 0.057 (0.058)	Data 0.00100 (0.00098)	Tok/s 51597 (53449)	Loss/tok 3.1794 (3.1184)	Learning Rate [7.8125e-05]
9: TRAIN [2][1560/3416]	Time 0.057 (0.058)	Data 0.00100 (0.00091)	Tok/s 51537 (53523)	Loss/tok 3.0378 (3.1150)	Learning Rate [7.8125e-05]
5: TRAIN [2][1560/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00093)	Tok/s 51413 (53221)	Loss/tok 3.1242 (3.1161)	Learning Rate [7.8125e-05]
4: TRAIN [2][1560/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00098)	Tok/s 51256 (53134)	Loss/tok 3.1402 (3.1172)	Learning Rate [7.8125e-05]
3: TRAIN [2][1560/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00092)	Tok/s 51227 (53037)	Loss/tok 2.9923 (3.1169)	Learning Rate [7.8125e-05]
10: TRAIN [2][1560/3416]	Time 0.057 (0.058)	Data 0.00111 (0.00097)	Tok/s 51444 (53599)	Loss/tok 3.0793 (3.1073)	Learning Rate [7.8125e-05]
11: TRAIN [2][1560/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00092)	Tok/s 52197 (53683)	Loss/tok 3.1180 (3.1204)	Learning Rate [7.8125e-05]
2: TRAIN [2][1560/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00098)	Tok/s 51083 (52927)	Loss/tok 2.9212 (3.1151)	Learning Rate [7.8125e-05]
1: TRAIN [2][1560/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00100)	Tok/s 50987 (52812)	Loss/tok 2.9623 (3.1145)	Learning Rate [7.8125e-05]
0: TRAIN [2][1560/3416]	Time 0.058 (0.058)	Data 0.00083 (0.00097)	Tok/s 50991 (52709)	Loss/tok 3.2461 (3.1211)	Learning Rate [7.8125e-05]
12: TRAIN [2][1560/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00101)	Tok/s 52331 (53801)	Loss/tok 3.0658 (3.1202)	Learning Rate [7.8125e-05]
13: TRAIN [2][1560/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00096)	Tok/s 52238 (53900)	Loss/tok 3.1903 (3.1165)	Learning Rate [7.8125e-05]
14: TRAIN [2][1560/3416]	Time 0.058 (0.058)	Data 0.00081 (0.00092)	Tok/s 52143 (54005)	Loss/tok 2.8191 (3.1144)	Learning Rate [7.8125e-05]
15: TRAIN [2][1560/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00092)	Tok/s 52145 (54122)	Loss/tok 3.1771 (3.1158)	Learning Rate [7.8125e-05]
4: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00098)	Tok/s 53510 (53134)	Loss/tok 3.1602 (3.1169)	Learning Rate [7.8125e-05]
6: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00092)	Tok/s 53368 (53289)	Loss/tok 3.2170 (3.1215)	Learning Rate [7.8125e-05]
5: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00093)	Tok/s 53415 (53222)	Loss/tok 3.2272 (3.1161)	Learning Rate [7.8125e-05]
3: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00092)	Tok/s 53460 (53036)	Loss/tok 3.0610 (3.1167)	Learning Rate [7.8125e-05]
2: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00098)	Tok/s 53480 (52925)	Loss/tok 3.0165 (3.1145)	Learning Rate [7.8125e-05]
7: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00097)	Tok/s 53247 (53375)	Loss/tok 3.1158 (3.1176)	Learning Rate [7.8125e-05]
0: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00097)	Tok/s 53477 (52704)	Loss/tok 3.0049 (3.1208)	Learning Rate [7.8125e-05]
8: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00098)	Tok/s 53264 (53451)	Loss/tok 3.1355 (3.1186)	Learning Rate [7.8125e-05]
9: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00091)	Tok/s 53300 (53524)	Loss/tok 3.2628 (3.1151)	Learning Rate [7.8125e-05]
14: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00092)	Tok/s 53426 (54006)	Loss/tok 3.1758 (3.1151)	Learning Rate [7.8125e-05]
10: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00097)	Tok/s 53292 (53600)	Loss/tok 3.0898 (3.1075)	Learning Rate [7.8125e-05]
13: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00096)	Tok/s 53336 (53902)	Loss/tok 3.1514 (3.1168)	Learning Rate [7.8125e-05]
11: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00092)	Tok/s 53362 (53684)	Loss/tok 3.1375 (3.1205)	Learning Rate [7.8125e-05]
12: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00101)	Tok/s 53325 (53803)	Loss/tok 3.2656 (3.1201)	Learning Rate [7.8125e-05]
15: TRAIN [2][1570/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00092)	Tok/s 53481 (54123)	Loss/tok 3.3955 (3.1163)	Learning Rate [7.8125e-05]
1: TRAIN [2][1570/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00100)	Tok/s 52315 (52807)	Loss/tok 3.0309 (3.1151)	Learning Rate [7.8125e-05]
13: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 66661 (53914)	Loss/tok 3.2060 (3.1169)	Learning Rate [7.8125e-05]
14: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 66657 (54017)	Loss/tok 3.2588 (3.1153)	Learning Rate [7.8125e-05]
12: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00101)	Tok/s 66606 (53815)	Loss/tok 3.2052 (3.1200)	Learning Rate [7.8125e-05]
11: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 66496 (53696)	Loss/tok 3.2486 (3.1208)	Learning Rate [7.8125e-05]
0: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 65711 (52719)	Loss/tok 3.1813 (3.1214)	Learning Rate [7.8125e-05]
1: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00100)	Tok/s 65773 (52822)	Loss/tok 3.4317 (3.1154)	Learning Rate [7.8125e-05]
10: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 66393 (53612)	Loss/tok 3.3418 (3.1077)	Learning Rate [7.8125e-05]
9: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 66325 (53537)	Loss/tok 3.1134 (3.1152)	Learning Rate [7.8125e-05]
15: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00092)	Tok/s 66666 (54134)	Loss/tok 3.2207 (3.1168)	Learning Rate [7.8125e-05]
2: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 65633 (52939)	Loss/tok 3.1555 (3.1145)	Learning Rate [7.8125e-05]
8: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00098)	Tok/s 65549 (53463)	Loss/tok 3.2740 (3.1188)	Learning Rate [7.8125e-05]
7: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00097)	Tok/s 65386 (53387)	Loss/tok 3.2392 (3.1179)	Learning Rate [7.8125e-05]
6: TRAIN [2][1580/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 65367 (53301)	Loss/tok 3.3439 (3.1210)	Learning Rate [7.8125e-05]
4: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 65473 (53147)	Loss/tok 3.0082 (3.1171)	Learning Rate [7.8125e-05]
5: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 65396 (53234)	Loss/tok 3.1552 (3.1160)	Learning Rate [7.8125e-05]
3: TRAIN [2][1580/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 65524 (53049)	Loss/tok 3.1883 (3.1168)	Learning Rate [7.8125e-05]
13: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 58481 (53899)	Loss/tok 3.1117 (3.1168)	Learning Rate [7.8125e-05]
14: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 58546 (54004)	Loss/tok 3.1508 (3.1156)	Learning Rate [7.8125e-05]
15: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 58373 (54121)	Loss/tok 3.2305 (3.1167)	Learning Rate [7.8125e-05]
0: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 57451 (52697)	Loss/tok 3.2720 (3.1214)	Learning Rate [7.8125e-05]
12: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00101)	Tok/s 58558 (53801)	Loss/tok 3.0600 (3.1200)	Learning Rate [7.8125e-05]
9: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 58382 (53522)	Loss/tok 3.2535 (3.1157)	Learning Rate [7.8125e-05]
2: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00098)	Tok/s 57268 (52921)	Loss/tok 3.1788 (3.1142)	Learning Rate [7.8125e-05]
10: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 58405 (53597)	Loss/tok 3.2755 (3.1083)	Learning Rate [7.8125e-05]
8: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00098)	Tok/s 57312 (53448)	Loss/tok 2.9741 (3.1185)	Learning Rate [7.8125e-05]
3: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 57284 (53031)	Loss/tok 3.1744 (3.1165)	Learning Rate [7.8125e-05]
6: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00092)	Tok/s 57220 (53286)	Loss/tok 3.2393 (3.1212)	Learning Rate [7.8125e-05]
7: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 57223 (53372)	Loss/tok 3.3497 (3.1182)	Learning Rate [7.8125e-05]
4: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00098)	Tok/s 57285 (53129)	Loss/tok 3.3120 (3.1172)	Learning Rate [7.8125e-05]
1: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00100)	Tok/s 57276 (52802)	Loss/tok 3.0550 (3.1151)	Learning Rate [7.8125e-05]
5: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 57142 (53217)	Loss/tok 3.4411 (3.1162)	Learning Rate [7.8125e-05]
11: TRAIN [2][1590/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 58470 (53680)	Loss/tok 3.4112 (3.1211)	Learning Rate [7.8125e-05]
9: TRAIN [2][1600/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00092)	Tok/s 55999 (53527)	Loss/tok 3.0923 (3.1161)	Learning Rate [7.8125e-05]
10: TRAIN [2][1600/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00096)	Tok/s 56030 (53603)	Loss/tok 2.8320 (3.1081)	Learning Rate [7.8125e-05]
8: TRAIN [2][1600/3416]	Time 0.058 (0.058)	Data 0.00106 (0.00098)	Tok/s 55420 (53453)	Loss/tok 3.3442 (3.1190)	Learning Rate [7.8125e-05]
7: TRAIN [2][1600/3416]	Time 0.058 (0.058)	Data 0.00102 (0.00097)	Tok/s 54838 (53377)	Loss/tok 3.2352 (3.1181)	Learning Rate [7.8125e-05]
0: TRAIN [2][1600/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00097)	Tok/s 54560 (52706)	Loss/tok 3.1557 (3.1216)	Learning Rate [7.8125e-05]
6: TRAIN [2][1600/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00092)	Tok/s 54660 (53292)	Loss/tok 3.3511 (3.1213)	Learning Rate [7.8125e-05]
12: TRAIN [2][1600/3416]	Time 0.058 (0.058)	Data 0.00105 (0.00101)	Tok/s 55824 (53807)	Loss/tok 3.1345 (3.1201)	Learning Rate [7.8125e-05]
13: TRAIN [2][1600/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00096)	Tok/s 55719 (53904)	Loss/tok 3.0935 (3.1170)	Learning Rate [7.8125e-05]
1: TRAIN [2][1600/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00100)	Tok/s 54553 (52811)	Loss/tok 3.2708 (3.1149)	Learning Rate [7.8125e-05]
5: TRAIN [2][1600/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00093)	Tok/s 54719 (53224)	Loss/tok 3.1832 (3.1160)	Learning Rate [7.8125e-05]
4: TRAIN [2][1600/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00098)	Tok/s 54681 (53136)	Loss/tok 3.1925 (3.1176)	Learning Rate [7.8125e-05]
14: TRAIN [2][1600/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00091)	Tok/s 55612 (54008)	Loss/tok 3.2791 (3.1158)	Learning Rate [7.8125e-05]
15: TRAIN [2][1600/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00092)	Tok/s 55540 (54126)	Loss/tok 3.3801 (3.1168)	Learning Rate [7.8125e-05]
2: TRAIN [2][1600/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00098)	Tok/s 54536 (52929)	Loss/tok 3.1853 (3.1142)	Learning Rate [7.8125e-05]
3: TRAIN [2][1600/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00092)	Tok/s 54604 (53038)	Loss/tok 3.2211 (3.1164)	Learning Rate [7.8125e-05]
11: TRAIN [2][1600/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00092)	Tok/s 55855 (53685)	Loss/tok 3.0743 (3.1210)	Learning Rate [7.8125e-05]
15: TRAIN [2][1610/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00092)	Tok/s 49635 (54138)	Loss/tok 2.8619 (3.1170)	Learning Rate [7.8125e-05]
1: TRAIN [2][1610/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00100)	Tok/s 48042 (52825)	Loss/tok 2.8787 (3.1150)	Learning Rate [7.8125e-05]
0: TRAIN [2][1610/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00096)	Tok/s 48029 (52720)	Loss/tok 2.8541 (3.1216)	Learning Rate [7.8125e-05]
14: TRAIN [2][1610/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00091)	Tok/s 49548 (54020)	Loss/tok 3.1251 (3.1164)	Learning Rate [7.8125e-05]
13: TRAIN [2][1610/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00096)	Tok/s 49529 (53916)	Loss/tok 3.1905 (3.1167)	Learning Rate [7.8125e-05]
2: TRAIN [2][1610/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00098)	Tok/s 48039 (52943)	Loss/tok 2.8823 (3.1148)	Learning Rate [7.8125e-05]
12: TRAIN [2][1610/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00101)	Tok/s 49668 (53819)	Loss/tok 3.2522 (3.1204)	Learning Rate [7.8125e-05]
10: TRAIN [2][1610/3416]	Time 0.046 (0.058)	Data 0.00102 (0.00096)	Tok/s 49557 (53616)	Loss/tok 3.1034 (3.1078)	Learning Rate [7.8125e-05]
4: TRAIN [2][1610/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00098)	Tok/s 47955 (53150)	Loss/tok 3.2628 (3.1180)	Learning Rate [7.8125e-05]
3: TRAIN [2][1610/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00092)	Tok/s 47931 (53052)	Loss/tok 2.9395 (3.1162)	Learning Rate [7.8125e-05]
8: TRAIN [2][1610/3416]	Time 0.046 (0.058)	Data 0.00106 (0.00098)	Tok/s 49669 (53467)	Loss/tok 2.9559 (3.1189)	Learning Rate [7.8125e-05]
7: TRAIN [2][1610/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00097)	Tok/s 49555 (53391)	Loss/tok 3.0696 (3.1178)	Learning Rate [7.8125e-05]
9: TRAIN [2][1610/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00092)	Tok/s 49495 (53541)	Loss/tok 3.1012 (3.1155)	Learning Rate [7.8125e-05]
5: TRAIN [2][1610/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00093)	Tok/s 47913 (53238)	Loss/tok 2.9786 (3.1164)	Learning Rate [7.8125e-05]
6: TRAIN [2][1610/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00092)	Tok/s 48424 (53306)	Loss/tok 3.1170 (3.1220)	Learning Rate [7.8125e-05]
11: TRAIN [2][1610/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00092)	Tok/s 49638 (53699)	Loss/tok 2.9418 (3.1209)	Learning Rate [7.8125e-05]
0: TRAIN [2][1620/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00096)	Tok/s 57000 (52705)	Loss/tok 3.3113 (3.1218)	Learning Rate [7.8125e-05]
1: TRAIN [2][1620/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00100)	Tok/s 56969 (52810)	Loss/tok 3.0362 (3.1153)	Learning Rate [7.8125e-05]
15: TRAIN [2][1620/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 57833 (54120)	Loss/tok 3.3209 (3.1170)	Learning Rate [7.8125e-05]
14: TRAIN [2][1620/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 57844 (54002)	Loss/tok 3.2780 (3.1165)	Learning Rate [7.8125e-05]
2: TRAIN [2][1620/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00098)	Tok/s 56957 (52927)	Loss/tok 3.3314 (3.1149)	Learning Rate [7.8125e-05]
3: TRAIN [2][1620/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00092)	Tok/s 57023 (53036)	Loss/tok 3.1977 (3.1166)	Learning Rate [7.8125e-05]
13: TRAIN [2][1620/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00096)	Tok/s 58084 (53898)	Loss/tok 3.1493 (3.1168)	Learning Rate [7.8125e-05]
12: TRAIN [2][1620/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00101)	Tok/s 57817 (53802)	Loss/tok 2.9909 (3.1203)	Learning Rate [7.8125e-05]
4: TRAIN [2][1620/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 56963 (53133)	Loss/tok 3.1746 (3.1180)	Learning Rate [7.8125e-05]
6: TRAIN [2][1620/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00092)	Tok/s 57935 (53290)	Loss/tok 3.2836 (3.1225)	Learning Rate [7.8125e-05]
5: TRAIN [2][1620/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 57325 (53220)	Loss/tok 3.3381 (3.1162)	Learning Rate [7.8125e-05]
10: TRAIN [2][1620/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00096)	Tok/s 57756 (53599)	Loss/tok 3.4033 (3.1081)	Learning Rate [7.8125e-05]
9: TRAIN [2][1620/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 57827 (53524)	Loss/tok 3.1555 (3.1160)	Learning Rate [7.8125e-05]
8: TRAIN [2][1620/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00098)	Tok/s 57845 (53451)	Loss/tok 3.2822 (3.1187)	Learning Rate [7.8125e-05]
7: TRAIN [2][1620/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 57854 (53375)	Loss/tok 3.1388 (3.1176)	Learning Rate [7.8125e-05]
11: TRAIN [2][1620/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 57802 (53681)	Loss/tok 3.2430 (3.1208)	Learning Rate [7.8125e-05]
6: TRAIN [2][1630/3416]	Time 0.039 (0.058)	Data 0.00095 (0.00092)	Tok/s 26678 (53257)	Loss/tok 2.3341 (3.1221)	Learning Rate [7.8125e-05]
5: TRAIN [2][1630/3416]	Time 0.039 (0.058)	Data 0.00100 (0.00093)	Tok/s 26028 (53187)	Loss/tok 2.2067 (3.1159)	Learning Rate [7.8125e-05]
7: TRAIN [2][1630/3416]	Time 0.039 (0.058)	Data 0.00094 (0.00097)	Tok/s 27683 (53344)	Loss/tok 2.3565 (3.1174)	Learning Rate [7.8125e-05]
9: TRAIN [2][1630/3416]	Time 0.039 (0.058)	Data 0.00101 (0.00092)	Tok/s 27754 (53494)	Loss/tok 2.2870 (3.1154)	Learning Rate [7.8125e-05]
8: TRAIN [2][1630/3416]	Time 0.039 (0.058)	Data 0.00099 (0.00098)	Tok/s 27688 (53421)	Loss/tok 2.3775 (3.1182)	Learning Rate [7.8125e-05]
4: TRAIN [2][1630/3416]	Time 0.040 (0.058)	Data 0.00106 (0.00098)	Tok/s 25877 (53099)	Loss/tok 2.4363 (3.1176)	Learning Rate [7.8125e-05]
3: TRAIN [2][1630/3416]	Time 0.040 (0.058)	Data 0.00092 (0.00092)	Tok/s 25836 (53002)	Loss/tok 2.4265 (3.1162)	Learning Rate [7.8125e-05]
10: TRAIN [2][1630/3416]	Time 0.039 (0.058)	Data 0.00098 (0.00096)	Tok/s 27635 (53569)	Loss/tok 2.3052 (3.1078)	Learning Rate [7.8125e-05]
2: TRAIN [2][1630/3416]	Time 0.040 (0.058)	Data 0.00109 (0.00098)	Tok/s 25107 (52892)	Loss/tok 2.1985 (3.1148)	Learning Rate [7.8125e-05]
1: TRAIN [2][1630/3416]	Time 0.040 (0.058)	Data 0.00112 (0.00100)	Tok/s 24186 (52773)	Loss/tok 2.1460 (3.1146)	Learning Rate [7.8125e-05]
0: TRAIN [2][1630/3416]	Time 0.040 (0.058)	Data 0.00091 (0.00097)	Tok/s 24214 (52666)	Loss/tok 2.1492 (3.1222)	Learning Rate [7.8125e-05]
13: TRAIN [2][1630/3416]	Time 0.040 (0.058)	Data 0.00090 (0.00096)	Tok/s 29135 (53871)	Loss/tok 2.3919 (3.1167)	Learning Rate [7.8125e-05]
15: TRAIN [2][1630/3416]	Time 0.040 (0.058)	Data 0.00099 (0.00092)	Tok/s 29046 (54092)	Loss/tok 2.3658 (3.1168)	Learning Rate [7.8125e-05]
14: TRAIN [2][1630/3416]	Time 0.040 (0.058)	Data 0.00093 (0.00091)	Tok/s 29082 (53974)	Loss/tok 2.5413 (3.1160)	Learning Rate [7.8125e-05]
11: TRAIN [2][1630/3416]	Time 0.039 (0.058)	Data 0.00105 (0.00092)	Tok/s 27704 (53651)	Loss/tok 2.4183 (3.1208)	Learning Rate [7.8125e-05]
12: TRAIN [2][1630/3416]	Time 0.040 (0.058)	Data 0.00103 (0.00101)	Tok/s 27363 (53773)	Loss/tok 2.3604 (3.1205)	Learning Rate [7.8125e-05]
13: Upscaling, new scale: 8192.0
12: Upscaling, new scale: 8192.0
14: Upscaling, new scale: 8192.0
15: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
9: Upscaling, new scale: 8192.0
10: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
8: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
6: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
7: Upscaling, new scale: 8192.0
5: Upscaling, new scale: 8192.0
4: Upscaling, new scale: 8192.0
11: Upscaling, new scale: 8192.0
7: Gradient norm: inf
8: Gradient norm: inf
6: Gradient norm: inf
9: Gradient norm: inf
7: Skipped batch, new scale: 4096.0
8: Skipped batch, new scale: 4096.0
5: Gradient norm: inf
4: Gradient norm: inf
6: Skipped batch, new scale: 4096.0
9: Skipped batch, new scale: 4096.0
10: Gradient norm: inf
5: Skipped batch, new scale: 4096.0
4: Skipped batch, new scale: 4096.0
3: Gradient norm: inf
11: Gradient norm: inf
10: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: Gradient norm: inf
12: Gradient norm: inf
11: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
1: Gradient norm: inf
12: Skipped batch, new scale: 4096.0
13: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
15: Gradient norm: inf
13: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
14: Gradient norm: inf
15: Skipped batch, new scale: 4096.0
14: Skipped batch, new scale: 4096.0
8: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00098)	Tok/s 36247 (53424)	Loss/tok 3.2031 (3.1183)	Learning Rate [7.8125e-05]
6: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00092)	Tok/s 36247 (53260)	Loss/tok 3.1628 (3.1224)	Learning Rate [7.8125e-05]
9: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00092)	Tok/s 36148 (53497)	Loss/tok 2.9862 (3.1156)	Learning Rate [7.8125e-05]
11: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00092)	Tok/s 36280 (53653)	Loss/tok 2.8595 (3.1215)	Learning Rate [7.8125e-05]
7: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00097)	Tok/s 36192 (53346)	Loss/tok 2.9274 (3.1173)	Learning Rate [7.8125e-05]
10: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00096)	Tok/s 36169 (53572)	Loss/tok 2.9131 (3.1081)	Learning Rate [7.8125e-05]
5: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00093)	Tok/s 36253 (53190)	Loss/tok 3.1218 (3.1157)	Learning Rate [7.8125e-05]
13: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00096)	Tok/s 36225 (53871)	Loss/tok 2.8319 (3.1165)	Learning Rate [7.8125e-05]
12: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00101)	Tok/s 36174 (53775)	Loss/tok 3.0724 (3.1204)	Learning Rate [7.8125e-05]
4: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00098)	Tok/s 36230 (53102)	Loss/tok 2.8733 (3.1169)	Learning Rate [7.8125e-05]
3: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00092)	Tok/s 36247 (53004)	Loss/tok 2.7709 (3.1162)	Learning Rate [7.8125e-05]
14: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00091)	Tok/s 36227 (53974)	Loss/tok 2.9609 (3.1159)	Learning Rate [7.8125e-05]
15: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00092)	Tok/s 36702 (54092)	Loss/tok 2.8108 (3.1169)	Learning Rate [7.8125e-05]
1: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00100)	Tok/s 34980 (52775)	Loss/tok 2.8420 (3.1147)	Learning Rate [7.8125e-05]
0: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00097)	Tok/s 34971 (52669)	Loss/tok 2.8142 (3.1223)	Learning Rate [7.8125e-05]
2: TRAIN [2][1640/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00098)	Tok/s 35376 (52893)	Loss/tok 2.7739 (3.1144)	Learning Rate [7.8125e-05]
3: Gradient norm: inf
2: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
4: Gradient norm: inf
2: Skipped batch, new scale: 2048.0
1: Gradient norm: inf
4: Skipped batch, new scale: 2048.0
5: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
0: Gradient norm: inf
6: Gradient norm: inf
5: Skipped batch, new scale: 2048.0
0: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
6: Skipped batch, new scale: 2048.0
7: Gradient norm: inf
14: Gradient norm: inf
15: Skipped batch, new scale: 2048.0
7: Skipped batch, new scale: 2048.0
8: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
13: Gradient norm: inf
9: Gradient norm: inf
8: Skipped batch, new scale: 2048.0
12: Gradient norm: inf
11: Gradient norm: inf
10: Gradient norm: inf
9: Skipped batch, new scale: 2048.0
13: Skipped batch, new scale: 2048.0
12: Skipped batch, new scale: 2048.0
11: Skipped batch, new scale: 2048.0
10: Skipped batch, new scale: 2048.0
6: TRAIN [2][1650/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00092)	Tok/s 52060 (53277)	Loss/tok 3.1297 (3.1218)	Learning Rate [7.8125e-05]
7: TRAIN [2][1650/3416]	Time 0.054 (0.058)	Data 0.00101 (0.00097)	Tok/s 52048 (53363)	Loss/tok 3.2445 (3.1169)	Learning Rate [7.8125e-05]
8: TRAIN [2][1650/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00098)	Tok/s 51955 (53441)	Loss/tok 3.1115 (3.1177)	Learning Rate [7.8125e-05]
9: TRAIN [2][1650/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00092)	Tok/s 51902 (53516)	Loss/tok 3.0575 (3.1156)	Learning Rate [7.8125e-05]
5: TRAIN [2][1650/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00093)	Tok/s 51660 (53207)	Loss/tok 3.1078 (3.1154)	Learning Rate [7.8125e-05]
10: TRAIN [2][1650/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00096)	Tok/s 51744 (53591)	Loss/tok 3.1913 (3.1077)	Learning Rate [7.8125e-05]
11: TRAIN [2][1650/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00092)	Tok/s 51640 (53673)	Loss/tok 2.9332 (3.1205)	Learning Rate [7.8125e-05]
2: TRAIN [2][1650/3416]	Time 0.054 (0.058)	Data 0.00113 (0.00098)	Tok/s 50499 (52909)	Loss/tok 3.0018 (3.1138)	Learning Rate [7.8125e-05]
12: TRAIN [2][1650/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00101)	Tok/s 51539 (53793)	Loss/tok 3.1598 (3.1203)	Learning Rate [7.8125e-05]
4: TRAIN [2][1650/3416]	Time 0.054 (0.058)	Data 0.00105 (0.00098)	Tok/s 50560 (53118)	Loss/tok 3.0758 (3.1169)	Learning Rate [7.8125e-05]
1: TRAIN [2][1650/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00100)	Tok/s 50390 (52791)	Loss/tok 3.1153 (3.1141)	Learning Rate [7.8125e-05]
13: TRAIN [2][1650/3416]	Time 0.055 (0.058)	Data 0.00085 (0.00096)	Tok/s 51396 (53890)	Loss/tok 3.0595 (3.1155)	Learning Rate [7.8125e-05]
0: TRAIN [2][1650/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00097)	Tok/s 50294 (52685)	Loss/tok 3.1054 (3.1219)	Learning Rate [7.8125e-05]
14: TRAIN [2][1650/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00091)	Tok/s 51394 (53994)	Loss/tok 3.2756 (3.1155)	Learning Rate [7.8125e-05]
15: TRAIN [2][1650/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00092)	Tok/s 51435 (54111)	Loss/tok 3.2018 (3.1164)	Learning Rate [7.8125e-05]
3: TRAIN [2][1650/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00092)	Tok/s 50622 (53019)	Loss/tok 3.2246 (3.1157)	Learning Rate [7.8125e-05]
11: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 37784 (53620)	Loss/tok 2.9762 (3.1203)	Learning Rate [7.8125e-05]
9: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 37848 (53463)	Loss/tok 2.7987 (3.1155)	Learning Rate [7.8125e-05]
10: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00096)	Tok/s 37857 (53538)	Loss/tok 3.0121 (3.1074)	Learning Rate [7.8125e-05]
8: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00098)	Tok/s 37857 (53389)	Loss/tok 2.8137 (3.1173)	Learning Rate [7.8125e-05]
12: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00101)	Tok/s 37724 (53742)	Loss/tok 2.9222 (3.1200)	Learning Rate [7.8125e-05]
6: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00092)	Tok/s 37797 (53224)	Loss/tok 2.8336 (3.1215)	Learning Rate [7.8125e-05]
7: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00097)	Tok/s 37839 (53311)	Loss/tok 3.1060 (3.1169)	Learning Rate [7.8125e-05]
13: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00096)	Tok/s 37584 (53838)	Loss/tok 3.0378 (3.1152)	Learning Rate [7.8125e-05]
14: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00091)	Tok/s 37503 (53941)	Loss/tok 3.0847 (3.1153)	Learning Rate [7.8125e-05]
5: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00093)	Tok/s 37720 (53154)	Loss/tok 2.9332 (3.1150)	Learning Rate [7.8125e-05]
15: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 37441 (54058)	Loss/tok 3.0452 (3.1165)	Learning Rate [7.8125e-05]
2: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00098)	Tok/s 37510 (52858)	Loss/tok 3.0164 (3.1136)	Learning Rate [7.8125e-05]
0: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00097)	Tok/s 36216 (52634)	Loss/tok 2.8228 (3.1217)	Learning Rate [7.8125e-05]
4: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00107 (0.00098)	Tok/s 37650 (53066)	Loss/tok 3.0598 (3.1165)	Learning Rate [7.8125e-05]
1: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00100)	Tok/s 36229 (52739)	Loss/tok 3.2546 (3.1141)	Learning Rate [7.8125e-05]
3: TRAIN [2][1660/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 37611 (52968)	Loss/tok 2.7850 (3.1155)	Learning Rate [7.8125e-05]
10: TRAIN [2][1670/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00096)	Tok/s 62823 (53525)	Loss/tok 3.1752 (3.1073)	Learning Rate [7.8125e-05]
9: TRAIN [2][1670/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 62733 (53451)	Loss/tok 3.0627 (3.1154)	Learning Rate [7.8125e-05]
11: TRAIN [2][1670/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 62609 (53607)	Loss/tok 3.4027 (3.1207)	Learning Rate [7.8125e-05]
12: TRAIN [2][1670/3416]	Time 0.070 (0.058)	Data 0.00115 (0.00101)	Tok/s 62611 (53728)	Loss/tok 3.1994 (3.1203)	Learning Rate [7.8125e-05]
8: TRAIN [2][1670/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 62791 (53376)	Loss/tok 3.0978 (3.1173)	Learning Rate [7.8125e-05]
6: TRAIN [2][1670/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00092)	Tok/s 62774 (53212)	Loss/tok 3.2651 (3.1214)	Learning Rate [7.8125e-05]
7: TRAIN [2][1670/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 62748 (53299)	Loss/tok 3.3437 (3.1172)	Learning Rate [7.8125e-05]
13: TRAIN [2][1670/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 62429 (53824)	Loss/tok 3.1045 (3.1152)	Learning Rate [7.8125e-05]
14: TRAIN [2][1670/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00091)	Tok/s 62910 (53927)	Loss/tok 3.3356 (3.1155)	Learning Rate [7.8125e-05]
5: TRAIN [2][1670/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00093)	Tok/s 62648 (53142)	Loss/tok 3.1603 (3.1146)	Learning Rate [7.8125e-05]
15: TRAIN [2][1670/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 63181 (54045)	Loss/tok 3.2169 (3.1164)	Learning Rate [7.8125e-05]
4: TRAIN [2][1670/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00098)	Tok/s 62552 (53054)	Loss/tok 3.0408 (3.1164)	Learning Rate [7.8125e-05]
0: TRAIN [2][1670/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 62312 (52624)	Loss/tok 3.0882 (3.1215)	Learning Rate [7.8125e-05]
1: TRAIN [2][1670/3416]	Time 0.070 (0.058)	Data 0.00118 (0.00100)	Tok/s 62291 (52729)	Loss/tok 3.3162 (3.1143)	Learning Rate [7.8125e-05]
2: TRAIN [2][1670/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00098)	Tok/s 62342 (52847)	Loss/tok 3.4475 (3.1137)	Learning Rate [7.8125e-05]
3: TRAIN [2][1670/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 62514 (52956)	Loss/tok 3.1274 (3.1153)	Learning Rate [7.8125e-05]
1: TRAIN [2][1680/3416]	Time 0.052 (0.058)	Data 0.00109 (0.00100)	Tok/s 52630 (52765)	Loss/tok 2.9891 (3.1140)	Learning Rate [7.8125e-05]
2: TRAIN [2][1680/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00098)	Tok/s 53487 (52883)	Loss/tok 3.0142 (3.1145)	Learning Rate [7.8125e-05]
0: TRAIN [2][1680/3416]	Time 0.051 (0.058)	Data 0.00114 (0.00097)	Tok/s 53586 (52661)	Loss/tok 3.1929 (3.1218)	Learning Rate [7.8125e-05]
15: TRAIN [2][1680/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 52606 (54079)	Loss/tok 2.7030 (3.1163)	Learning Rate [7.8125e-05]
4: TRAIN [2][1680/3416]	Time 0.053 (0.058)	Data 0.00103 (0.00098)	Tok/s 52236 (53089)	Loss/tok 3.0724 (3.1164)	Learning Rate [7.8125e-05]
14: TRAIN [2][1680/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00091)	Tok/s 52572 (53962)	Loss/tok 2.9898 (3.1157)	Learning Rate [7.8125e-05]
6: TRAIN [2][1680/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00092)	Tok/s 52180 (53246)	Loss/tok 2.9496 (3.1215)	Learning Rate [7.8125e-05]
11: TRAIN [2][1680/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00092)	Tok/s 52460 (53640)	Loss/tok 3.0866 (3.1209)	Learning Rate [7.8125e-05]
5: TRAIN [2][1680/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00093)	Tok/s 52135 (53176)	Loss/tok 3.3447 (3.1149)	Learning Rate [7.8125e-05]
13: TRAIN [2][1680/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00096)	Tok/s 52510 (53859)	Loss/tok 3.1481 (3.1156)	Learning Rate [7.8125e-05]
7: TRAIN [2][1680/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00097)	Tok/s 52086 (53333)	Loss/tok 3.0358 (3.1176)	Learning Rate [7.8125e-05]
9: TRAIN [2][1680/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00092)	Tok/s 52189 (53484)	Loss/tok 3.3403 (3.1158)	Learning Rate [7.8125e-05]
12: TRAIN [2][1680/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00101)	Tok/s 52352 (53762)	Loss/tok 3.4178 (3.1205)	Learning Rate [7.8125e-05]
8: TRAIN [2][1680/3416]	Time 0.053 (0.058)	Data 0.00103 (0.00098)	Tok/s 52053 (53410)	Loss/tok 3.0075 (3.1173)	Learning Rate [7.8125e-05]
3: TRAIN [2][1680/3416]	Time 0.053 (0.058)	Data 0.00081 (0.00092)	Tok/s 52377 (52992)	Loss/tok 2.9987 (3.1157)	Learning Rate [7.8125e-05]
10: TRAIN [2][1680/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00096)	Tok/s 52204 (53559)	Loss/tok 3.1742 (3.1076)	Learning Rate [7.8125e-05]
1: TRAIN [2][1690/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00100)	Tok/s 76424 (52818)	Loss/tok 3.0374 (3.1141)	Learning Rate [7.8125e-05]
4: TRAIN [2][1690/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 77207 (53142)	Loss/tok 3.1587 (3.1170)	Learning Rate [7.8125e-05]
0: TRAIN [2][1690/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 76437 (52714)	Loss/tok 3.1442 (3.1220)	Learning Rate [7.8125e-05]
2: TRAIN [2][1690/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00098)	Tok/s 76357 (52935)	Loss/tok 3.0388 (3.1149)	Learning Rate [7.8125e-05]
15: TRAIN [2][1690/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 78341 (54130)	Loss/tok 3.2347 (3.1167)	Learning Rate [7.8125e-05]
5: TRAIN [2][1690/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00093)	Tok/s 77221 (53229)	Loss/tok 3.2029 (3.1151)	Learning Rate [7.8125e-05]
6: TRAIN [2][1690/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 77128 (53299)	Loss/tok 2.7937 (3.1209)	Learning Rate [7.8125e-05]
13: TRAIN [2][1690/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00096)	Tok/s 78316 (53911)	Loss/tok 2.8759 (3.1153)	Learning Rate [7.8125e-05]
7: TRAIN [2][1690/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 77147 (53385)	Loss/tok 3.0446 (3.1175)	Learning Rate [7.8125e-05]
12: TRAIN [2][1690/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00101)	Tok/s 78287 (53815)	Loss/tok 3.1785 (3.1208)	Learning Rate [7.8125e-05]
8: TRAIN [2][1690/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 77093 (53462)	Loss/tok 2.9763 (3.1174)	Learning Rate [7.8125e-05]
14: TRAIN [2][1690/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00091)	Tok/s 78316 (54013)	Loss/tok 3.2228 (3.1157)	Learning Rate [7.8125e-05]
9: TRAIN [2][1690/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 77199 (53537)	Loss/tok 3.0975 (3.1155)	Learning Rate [7.8125e-05]
11: TRAIN [2][1690/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 77352 (53692)	Loss/tok 3.2229 (3.1212)	Learning Rate [7.8125e-05]
10: TRAIN [2][1690/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00097)	Tok/s 77221 (53611)	Loss/tok 3.1001 (3.1079)	Learning Rate [7.8125e-05]
3: TRAIN [2][1690/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 77083 (53045)	Loss/tok 3.4990 (3.1166)	Learning Rate [7.8125e-05]
12: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00101)	Tok/s 53519 (53813)	Loss/tok 3.3124 (3.1207)	Learning Rate [7.8125e-05]
13: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00085 (0.00096)	Tok/s 53531 (53909)	Loss/tok 3.2311 (3.1156)	Learning Rate [7.8125e-05]
11: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00077 (0.00092)	Tok/s 53593 (53691)	Loss/tok 3.1467 (3.1212)	Learning Rate [7.8125e-05]
2: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00100 (0.00098)	Tok/s 52174 (52929)	Loss/tok 3.2236 (3.1152)	Learning Rate [7.8125e-05]
3: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00085 (0.00092)	Tok/s 52166 (53039)	Loss/tok 3.1771 (3.1169)	Learning Rate [7.8125e-05]
10: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00082 (0.00097)	Tok/s 53509 (53610)	Loss/tok 3.2186 (3.1075)	Learning Rate [7.8125e-05]
4: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00098)	Tok/s 52160 (53137)	Loss/tok 3.1272 (3.1173)	Learning Rate [7.8125e-05]
1: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00100)	Tok/s 52178 (52809)	Loss/tok 2.8955 (3.1146)	Learning Rate [7.8125e-05]
14: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00086 (0.00091)	Tok/s 53419 (54011)	Loss/tok 3.1904 (3.1162)	Learning Rate [7.8125e-05]
0: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00097)	Tok/s 52221 (52705)	Loss/tok 2.9810 (3.1229)	Learning Rate [7.8125e-05]
9: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00079 (0.00092)	Tok/s 52388 (53534)	Loss/tok 3.0098 (3.1155)	Learning Rate [7.8125e-05]
15: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00080 (0.00092)	Tok/s 53330 (54129)	Loss/tok 2.9212 (3.1166)	Learning Rate [7.8125e-05]
8: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00098)	Tok/s 52297 (53460)	Loss/tok 2.8932 (3.1176)	Learning Rate [7.8125e-05]
5: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00078 (0.00093)	Tok/s 52195 (53225)	Loss/tok 3.3268 (3.1154)	Learning Rate [7.8125e-05]
6: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00082 (0.00092)	Tok/s 52180 (53295)	Loss/tok 3.0395 (3.1204)	Learning Rate [7.8125e-05]
7: TRAIN [2][1700/3416]	Time 0.054 (0.058)	Data 0.00086 (0.00097)	Tok/s 52287 (53383)	Loss/tok 3.0797 (3.1173)	Learning Rate [7.8125e-05]
15: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00101 (0.00092)	Tok/s 55383 (54121)	Loss/tok 3.2120 (3.1163)	Learning Rate [7.8125e-05]
14: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00091)	Tok/s 55303 (54003)	Loss/tok 3.3361 (3.1158)	Learning Rate [7.8125e-05]
0: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00097)	Tok/s 55381 (52700)	Loss/tok 3.1794 (3.1228)	Learning Rate [7.8125e-05]
1: TRAIN [2][1710/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00100)	Tok/s 55438 (52803)	Loss/tok 3.0927 (3.1144)	Learning Rate [7.8125e-05]
13: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00096)	Tok/s 55210 (53901)	Loss/tok 3.2807 (3.1158)	Learning Rate [7.8125e-05]
2: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00102 (0.00098)	Tok/s 55402 (52922)	Loss/tok 3.1765 (3.1153)	Learning Rate [7.8125e-05]
12: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00101)	Tok/s 55097 (53805)	Loss/tok 3.2030 (3.1207)	Learning Rate [7.8125e-05]
11: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00092)	Tok/s 54988 (53683)	Loss/tok 2.9273 (3.1208)	Learning Rate [7.8125e-05]
3: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00092)	Tok/s 55352 (53032)	Loss/tok 3.2494 (3.1167)	Learning Rate [7.8125e-05]
4: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00098)	Tok/s 55280 (53130)	Loss/tok 3.2161 (3.1169)	Learning Rate [7.8125e-05]
10: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00097)	Tok/s 54953 (53602)	Loss/tok 3.2439 (3.1073)	Learning Rate [7.8125e-05]
9: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00092)	Tok/s 54972 (53527)	Loss/tok 3.0266 (3.1156)	Learning Rate [7.8125e-05]
7: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00097)	Tok/s 55052 (53376)	Loss/tok 3.5676 (3.1172)	Learning Rate [7.8125e-05]
8: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00098)	Tok/s 54977 (53453)	Loss/tok 3.2938 (3.1173)	Learning Rate [7.8125e-05]
6: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00092)	Tok/s 55095 (53287)	Loss/tok 3.3266 (3.1200)	Learning Rate [7.8125e-05]
5: TRAIN [2][1710/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00093)	Tok/s 55157 (53217)	Loss/tok 2.8198 (3.1148)	Learning Rate [7.8125e-05]
0: TRAIN [2][1720/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00097)	Tok/s 52134 (52700)	Loss/tok 2.7966 (3.1225)	Learning Rate [7.8125e-05]
1: TRAIN [2][1720/3416]	Time 0.050 (0.058)	Data 0.00124 (0.00100)	Tok/s 52066 (52804)	Loss/tok 3.1219 (3.1145)	Learning Rate [7.8125e-05]
15: TRAIN [2][1720/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00092)	Tok/s 52182 (54119)	Loss/tok 3.0861 (3.1162)	Learning Rate [7.8125e-05]
2: TRAIN [2][1720/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00098)	Tok/s 51945 (52923)	Loss/tok 3.2154 (3.1152)	Learning Rate [7.8125e-05]
14: TRAIN [2][1720/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00091)	Tok/s 52178 (54002)	Loss/tok 3.1568 (3.1160)	Learning Rate [7.8125e-05]
13: TRAIN [2][1720/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00096)	Tok/s 52185 (53900)	Loss/tok 3.0263 (3.1159)	Learning Rate [7.8125e-05]
3: TRAIN [2][1720/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00092)	Tok/s 51866 (53032)	Loss/tok 3.0869 (3.1166)	Learning Rate [7.8125e-05]
4: TRAIN [2][1720/3416]	Time 0.051 (0.058)	Data 0.00127 (0.00098)	Tok/s 51883 (53129)	Loss/tok 2.9520 (3.1167)	Learning Rate [7.8125e-05]
10: TRAIN [2][1720/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00097)	Tok/s 52264 (53601)	Loss/tok 2.9547 (3.1075)	Learning Rate [7.8125e-05]
12: TRAIN [2][1720/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00101)	Tok/s 52179 (53804)	Loss/tok 3.0833 (3.1208)	Learning Rate [7.8125e-05]
11: TRAIN [2][1720/3416]	Time 0.050 (0.058)	Data 0.00107 (0.00092)	Tok/s 52181 (53682)	Loss/tok 2.9981 (3.1203)	Learning Rate [7.8125e-05]
6: TRAIN [2][1720/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 51843 (53286)	Loss/tok 2.8243 (3.1199)	Learning Rate [7.8125e-05]
5: TRAIN [2][1720/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00093)	Tok/s 51866 (53216)	Loss/tok 3.2743 (3.1146)	Learning Rate [7.8125e-05]
9: TRAIN [2][1720/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00092)	Tok/s 52011 (53526)	Loss/tok 3.1103 (3.1150)	Learning Rate [7.8125e-05]
8: TRAIN [2][1720/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00098)	Tok/s 51938 (53451)	Loss/tok 3.0043 (3.1172)	Learning Rate [7.8125e-05]
7: TRAIN [2][1720/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00097)	Tok/s 51852 (53374)	Loss/tok 3.0690 (3.1171)	Learning Rate [7.8125e-05]
6: TRAIN [2][1730/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00092)	Tok/s 33799 (53303)	Loss/tok 2.9267 (3.1201)	Learning Rate [7.8125e-05]
7: TRAIN [2][1730/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00097)	Tok/s 33793 (53391)	Loss/tok 2.8247 (3.1172)	Learning Rate [7.8125e-05]
8: TRAIN [2][1730/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00098)	Tok/s 33741 (53468)	Loss/tok 2.7435 (3.1175)	Learning Rate [7.8125e-05]
9: TRAIN [2][1730/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00092)	Tok/s 33664 (53542)	Loss/tok 3.1105 (3.1146)	Learning Rate [7.8125e-05]
5: TRAIN [2][1730/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00093)	Tok/s 33690 (53233)	Loss/tok 3.1443 (3.1148)	Learning Rate [7.8125e-05]
4: TRAIN [2][1730/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00098)	Tok/s 33600 (53144)	Loss/tok 2.9142 (3.1167)	Learning Rate [7.8125e-05]
3: TRAIN [2][1730/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00092)	Tok/s 33597 (53048)	Loss/tok 2.8662 (3.1169)	Learning Rate [7.8125e-05]
10: TRAIN [2][1730/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00097)	Tok/s 33669 (53617)	Loss/tok 3.0805 (3.1080)	Learning Rate [7.8125e-05]
2: TRAIN [2][1730/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00098)	Tok/s 33535 (52939)	Loss/tok 2.9508 (3.1152)	Learning Rate [7.8125e-05]
11: TRAIN [2][1730/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 33637 (53699)	Loss/tok 2.9114 (3.1199)	Learning Rate [7.8125e-05]
12: TRAIN [2][1730/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00101)	Tok/s 33707 (53821)	Loss/tok 2.8278 (3.1209)	Learning Rate [7.8125e-05]
1: TRAIN [2][1730/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00100)	Tok/s 33512 (52820)	Loss/tok 2.9125 (3.1143)	Learning Rate [7.8125e-05]
0: TRAIN [2][1730/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00097)	Tok/s 33507 (52716)	Loss/tok 2.9516 (3.1226)	Learning Rate [7.8125e-05]
13: TRAIN [2][1730/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00096)	Tok/s 33618 (53916)	Loss/tok 2.8486 (3.1161)	Learning Rate [7.8125e-05]
14: TRAIN [2][1730/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00091)	Tok/s 33525 (54017)	Loss/tok 2.9748 (3.1162)	Learning Rate [7.8125e-05]
15: TRAIN [2][1730/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00092)	Tok/s 33687 (54134)	Loss/tok 2.8894 (3.1163)	Learning Rate [7.8125e-05]
9: TRAIN [2][1740/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00092)	Tok/s 59790 (53577)	Loss/tok 3.2985 (3.1150)	Learning Rate [7.8125e-05]
8: TRAIN [2][1740/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00098)	Tok/s 59411 (53503)	Loss/tok 3.2381 (3.1174)	Learning Rate [7.8125e-05]
10: TRAIN [2][1740/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00097)	Tok/s 59829 (53652)	Loss/tok 3.0643 (3.1079)	Learning Rate [7.8125e-05]
7: TRAIN [2][1740/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00097)	Tok/s 58663 (53425)	Loss/tok 3.3642 (3.1175)	Learning Rate [7.8125e-05]
11: TRAIN [2][1740/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00092)	Tok/s 59821 (53733)	Loss/tok 3.2085 (3.1197)	Learning Rate [7.8125e-05]
5: TRAIN [2][1740/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00093)	Tok/s 58529 (53267)	Loss/tok 3.2330 (3.1149)	Learning Rate [7.8125e-05]
4: TRAIN [2][1740/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00098)	Tok/s 58557 (53178)	Loss/tok 3.1632 (3.1170)	Learning Rate [7.8125e-05]
13: TRAIN [2][1740/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00096)	Tok/s 59804 (53950)	Loss/tok 3.3788 (3.1161)	Learning Rate [7.8125e-05]
3: TRAIN [2][1740/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 58588 (53082)	Loss/tok 3.2006 (3.1172)	Learning Rate [7.8125e-05]
12: TRAIN [2][1740/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00101)	Tok/s 59820 (53855)	Loss/tok 3.5050 (3.1213)	Learning Rate [7.8125e-05]
14: TRAIN [2][1740/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00091)	Tok/s 59708 (54051)	Loss/tok 3.1894 (3.1162)	Learning Rate [7.8125e-05]
15: TRAIN [2][1740/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 59633 (54168)	Loss/tok 3.4743 (3.1166)	Learning Rate [7.8125e-05]
0: TRAIN [2][1740/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00097)	Tok/s 58613 (52750)	Loss/tok 3.3071 (3.1227)	Learning Rate [7.8125e-05]
1: TRAIN [2][1740/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00100)	Tok/s 58592 (52854)	Loss/tok 3.0640 (3.1142)	Learning Rate [7.8125e-05]
2: TRAIN [2][1740/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00098)	Tok/s 58571 (52973)	Loss/tok 3.0706 (3.1153)	Learning Rate [7.8125e-05]
6: TRAIN [2][1740/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00092)	Tok/s 58573 (53338)	Loss/tok 3.0091 (3.1202)	Learning Rate [7.8125e-05]
0: TRAIN [2][1750/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00097)	Tok/s 53009 (52766)	Loss/tok 3.2202 (3.1232)	Learning Rate [7.8125e-05]
1: TRAIN [2][1750/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00100)	Tok/s 52992 (52870)	Loss/tok 3.1666 (3.1150)	Learning Rate [7.8125e-05]
15: TRAIN [2][1750/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00092)	Tok/s 53881 (54181)	Loss/tok 3.2825 (3.1163)	Learning Rate [7.8125e-05]
2: TRAIN [2][1750/3416]	Time 0.053 (0.058)	Data 0.00102 (0.00098)	Tok/s 52900 (52989)	Loss/tok 3.1136 (3.1160)	Learning Rate [7.8125e-05]
14: TRAIN [2][1750/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00091)	Tok/s 52820 (54063)	Loss/tok 3.3424 (3.1166)	Learning Rate [7.8125e-05]
13: TRAIN [2][1750/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00096)	Tok/s 52714 (53962)	Loss/tok 2.9224 (3.1164)	Learning Rate [7.8125e-05]
3: TRAIN [2][1750/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00092)	Tok/s 52758 (53098)	Loss/tok 2.9291 (3.1170)	Learning Rate [7.8125e-05]
11: TRAIN [2][1750/3416]	Time 0.054 (0.058)	Data 0.00086 (0.00092)	Tok/s 52484 (53746)	Loss/tok 2.8959 (3.1194)	Learning Rate [7.8125e-05]
12: TRAIN [2][1750/3416]	Time 0.054 (0.058)	Data 0.00083 (0.00101)	Tok/s 52540 (53867)	Loss/tok 3.1904 (3.1216)	Learning Rate [7.8125e-05]
5: TRAIN [2][1750/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00093)	Tok/s 52541 (53282)	Loss/tok 3.0734 (3.1152)	Learning Rate [7.8125e-05]
9: TRAIN [2][1750/3416]	Time 0.054 (0.058)	Data 0.00086 (0.00092)	Tok/s 52289 (53589)	Loss/tok 2.8766 (3.1154)	Learning Rate [7.8125e-05]
8: TRAIN [2][1750/3416]	Time 0.054 (0.058)	Data 0.00083 (0.00098)	Tok/s 52303 (53516)	Loss/tok 3.2803 (3.1179)	Learning Rate [7.8125e-05]
7: TRAIN [2][1750/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00097)	Tok/s 52346 (53439)	Loss/tok 3.0726 (3.1175)	Learning Rate [7.8125e-05]
6: TRAIN [2][1750/3416]	Time 0.054 (0.058)	Data 0.00084 (0.00092)	Tok/s 52429 (53352)	Loss/tok 3.0511 (3.1209)	Learning Rate [7.8125e-05]
4: TRAIN [2][1750/3416]	Time 0.054 (0.058)	Data 0.00117 (0.00098)	Tok/s 52602 (53193)	Loss/tok 3.0610 (3.1167)	Learning Rate [7.8125e-05]
10: TRAIN [2][1750/3416]	Time 0.054 (0.058)	Data 0.00115 (0.00097)	Tok/s 52321 (53664)	Loss/tok 3.1512 (3.1081)	Learning Rate [7.8125e-05]
11: TRAIN [2][1760/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00092)	Tok/s 53224 (53723)	Loss/tok 3.1275 (3.1192)	Learning Rate [7.8125e-05]
12: TRAIN [2][1760/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00101)	Tok/s 53157 (53845)	Loss/tok 3.1003 (3.1215)	Learning Rate [7.8125e-05]
10: TRAIN [2][1760/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00097)	Tok/s 53180 (53642)	Loss/tok 3.1596 (3.1083)	Learning Rate [7.8125e-05]
9: TRAIN [2][1760/3416]	Time 0.055 (0.058)	Data 0.00086 (0.00092)	Tok/s 53292 (53567)	Loss/tok 3.2337 (3.1151)	Learning Rate [7.8125e-05]
13: TRAIN [2][1760/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00096)	Tok/s 52993 (53940)	Loss/tok 2.9331 (3.1167)	Learning Rate [7.8125e-05]
8: TRAIN [2][1760/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00098)	Tok/s 53273 (53494)	Loss/tok 3.0404 (3.1179)	Learning Rate [7.8125e-05]
7: TRAIN [2][1760/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00097)	Tok/s 53285 (53418)	Loss/tok 3.1582 (3.1175)	Learning Rate [7.8125e-05]
0: TRAIN [2][1760/3416]	Time 0.056 (0.058)	Data 0.00138 (0.00097)	Tok/s 51726 (52744)	Loss/tok 3.0719 (3.1231)	Learning Rate [7.8125e-05]
14: TRAIN [2][1760/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00091)	Tok/s 52851 (54041)	Loss/tok 3.0251 (3.1161)	Learning Rate [7.8125e-05]
15: TRAIN [2][1760/3416]	Time 0.056 (0.058)	Data 0.00099 (0.00092)	Tok/s 52888 (54159)	Loss/tok 3.1378 (3.1158)	Learning Rate [7.8125e-05]
5: TRAIN [2][1760/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00093)	Tok/s 52121 (53261)	Loss/tok 2.9476 (3.1147)	Learning Rate [7.8125e-05]
4: TRAIN [2][1760/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00098)	Tok/s 51925 (53173)	Loss/tok 3.1439 (3.1165)	Learning Rate [7.8125e-05]
2: TRAIN [2][1760/3416]	Time 0.056 (0.058)	Data 0.00112 (0.00098)	Tok/s 51716 (52968)	Loss/tok 3.0985 (3.1159)	Learning Rate [7.8125e-05]
3: TRAIN [2][1760/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00092)	Tok/s 51863 (53077)	Loss/tok 3.1103 (3.1170)	Learning Rate [7.8125e-05]
1: TRAIN [2][1760/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00100)	Tok/s 51773 (52850)	Loss/tok 3.2700 (3.1150)	Learning Rate [7.8125e-05]
6: TRAIN [2][1760/3416]	Time 0.055 (0.058)	Data 0.00084 (0.00092)	Tok/s 52773 (53331)	Loss/tok 3.0146 (3.1203)	Learning Rate [7.8125e-05]
8: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
8: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00098)	Tok/s 62112 (53520)	Loss/tok 3.2461 (3.1182)	Learning Rate [7.8125e-05]
7: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 62206 (53443)	Loss/tok 3.1635 (3.1180)	Learning Rate [7.8125e-05]
6: TRAIN [2][1770/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00092)	Tok/s 62633 (53356)	Loss/tok 3.4662 (3.1211)	Learning Rate [7.8125e-05]
5: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 62253 (53286)	Loss/tok 3.3331 (3.1156)	Learning Rate [7.8125e-05]
4: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 62265 (53199)	Loss/tok 3.2131 (3.1166)	Learning Rate [7.8125e-05]
10: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 62101 (53667)	Loss/tok 3.0883 (3.1080)	Learning Rate [7.8125e-05]
9: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00092)	Tok/s 62023 (53592)	Loss/tok 3.2873 (3.1156)	Learning Rate [7.8125e-05]
2: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 62260 (52996)	Loss/tok 3.1114 (3.1165)	Learning Rate [7.8125e-05]
3: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 62258 (53103)	Loss/tok 3.1943 (3.1172)	Learning Rate [7.8125e-05]
11: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 62143 (53748)	Loss/tok 3.3859 (3.1194)	Learning Rate [7.8125e-05]
1: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00100)	Tok/s 62205 (52878)	Loss/tok 3.2496 (3.1163)	Learning Rate [7.8125e-05]
13: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 62187 (53966)	Loss/tok 3.2217 (3.1171)	Learning Rate [7.8125e-05]
12: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00101)	Tok/s 62138 (53870)	Loss/tok 3.3771 (3.1219)	Learning Rate [7.8125e-05]
0: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 62228 (52773)	Loss/tok 3.3414 (3.1235)	Learning Rate [7.8125e-05]
15: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 62228 (54184)	Loss/tok 3.1673 (3.1159)	Learning Rate [7.8125e-05]
14: TRAIN [2][1770/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00091)	Tok/s 62251 (54067)	Loss/tok 3.4853 (3.1164)	Learning Rate [7.8125e-05]
9: TRAIN [2][1780/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00092)	Tok/s 57029 (53570)	Loss/tok 3.2682 (3.1158)	Learning Rate [7.8125e-05]
11: TRAIN [2][1780/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00092)	Tok/s 56958 (53727)	Loss/tok 3.3963 (3.1197)	Learning Rate [7.8125e-05]
8: TRAIN [2][1780/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00098)	Tok/s 57107 (53498)	Loss/tok 3.1707 (3.1183)	Learning Rate [7.8125e-05]
10: TRAIN [2][1780/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00097)	Tok/s 56993 (53645)	Loss/tok 3.1455 (3.1081)	Learning Rate [7.8125e-05]
12: TRAIN [2][1780/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00101)	Tok/s 56909 (53849)	Loss/tok 3.1641 (3.1217)	Learning Rate [7.8125e-05]
13: TRAIN [2][1780/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00096)	Tok/s 56899 (53945)	Loss/tok 3.0918 (3.1169)	Learning Rate [7.8125e-05]
7: TRAIN [2][1780/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00097)	Tok/s 57018 (53421)	Loss/tok 3.2685 (3.1176)	Learning Rate [7.8125e-05]
0: TRAIN [2][1780/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00097)	Tok/s 56359 (52752)	Loss/tok 2.9723 (3.1233)	Learning Rate [7.8125e-05]
14: TRAIN [2][1780/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00091)	Tok/s 56878 (54045)	Loss/tok 3.3253 (3.1160)	Learning Rate [7.8125e-05]
1: TRAIN [2][1780/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00100)	Tok/s 56867 (52857)	Loss/tok 3.5281 (3.1164)	Learning Rate [7.8125e-05]
5: TRAIN [2][1780/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00093)	Tok/s 56967 (53264)	Loss/tok 3.0312 (3.1155)	Learning Rate [7.8125e-05]
4: TRAIN [2][1780/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00098)	Tok/s 56929 (53177)	Loss/tok 3.2399 (3.1170)	Learning Rate [7.8125e-05]
2: TRAIN [2][1780/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00098)	Tok/s 56923 (52974)	Loss/tok 3.1888 (3.1164)	Learning Rate [7.8125e-05]
15: TRAIN [2][1780/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 56778 (54161)	Loss/tok 2.9806 (3.1159)	Learning Rate [7.8125e-05]
3: TRAIN [2][1780/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00092)	Tok/s 56875 (53081)	Loss/tok 3.0271 (3.1172)	Learning Rate [7.8125e-05]
6: TRAIN [2][1780/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 56786 (53334)	Loss/tok 3.2686 (3.1213)	Learning Rate [7.8125e-05]
6: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00092)	Tok/s 54905 (53359)	Loss/tok 2.9749 (3.1211)	Learning Rate [7.8125e-05]
7: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00097)	Tok/s 55017 (53445)	Loss/tok 3.2839 (3.1179)	Learning Rate [7.8125e-05]
8: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00098)	Tok/s 55009 (53521)	Loss/tok 3.0727 (3.1186)	Learning Rate [7.8125e-05]
9: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00092)	Tok/s 55010 (53594)	Loss/tok 3.2681 (3.1155)	Learning Rate [7.8125e-05]
5: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00093)	Tok/s 54834 (53289)	Loss/tok 3.0496 (3.1148)	Learning Rate [7.8125e-05]
4: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00098)	Tok/s 54761 (53202)	Loss/tok 3.0067 (3.1172)	Learning Rate [7.8125e-05]
3: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00092)	Tok/s 54733 (53106)	Loss/tok 3.2521 (3.1168)	Learning Rate [7.8125e-05]
10: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00097)	Tok/s 55528 (53669)	Loss/tok 3.1228 (3.1078)	Learning Rate [7.8125e-05]
2: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00098)	Tok/s 54716 (52999)	Loss/tok 3.1940 (3.1166)	Learning Rate [7.8125e-05]
11: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00092)	Tok/s 55951 (53751)	Loss/tok 3.3756 (3.1197)	Learning Rate [7.8125e-05]
1: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00100)	Tok/s 54709 (52882)	Loss/tok 3.3004 (3.1166)	Learning Rate [7.8125e-05]
0: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00097)	Tok/s 54720 (52778)	Loss/tok 3.2275 (3.1230)	Learning Rate [7.8125e-05]
12: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00110 (0.00101)	Tok/s 56002 (53873)	Loss/tok 2.9576 (3.1215)	Learning Rate [7.8125e-05]
13: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00083 (0.00096)	Tok/s 55803 (53969)	Loss/tok 3.1599 (3.1168)	Learning Rate [7.8125e-05]
15: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00092)	Tok/s 55800 (54185)	Loss/tok 3.2997 (3.1160)	Learning Rate [7.8125e-05]
14: TRAIN [2][1790/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00091)	Tok/s 55777 (54068)	Loss/tok 3.1716 (3.1162)	Learning Rate [7.8125e-05]
14: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00091)	Tok/s 51953 (54070)	Loss/tok 3.5205 (3.1164)	Learning Rate [7.8125e-05]
15: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00092)	Tok/s 51903 (54186)	Loss/tok 3.2477 (3.1159)	Learning Rate [7.8125e-05]
13: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00096)	Tok/s 51888 (53970)	Loss/tok 2.9721 (3.1165)	Learning Rate [7.8125e-05]
0: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00097)	Tok/s 51787 (52780)	Loss/tok 3.1368 (3.1227)	Learning Rate [7.8125e-05]
12: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00104 (0.00101)	Tok/s 51826 (53874)	Loss/tok 2.9248 (3.1213)	Learning Rate [7.8125e-05]
10: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00097)	Tok/s 51727 (53669)	Loss/tok 3.1997 (3.1073)	Learning Rate [7.8125e-05]
1: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00340 (0.00100)	Tok/s 51683 (52884)	Loss/tok 3.2530 (3.1166)	Learning Rate [7.8125e-05]
11: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00092)	Tok/s 51746 (53752)	Loss/tok 3.2262 (3.1192)	Learning Rate [7.8125e-05]
9: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00092)	Tok/s 51547 (53594)	Loss/tok 3.0929 (3.1153)	Learning Rate [7.8125e-05]
2: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00098)	Tok/s 51608 (53000)	Loss/tok 3.0705 (3.1162)	Learning Rate [7.8125e-05]
8: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00105 (0.00098)	Tok/s 51511 (53521)	Loss/tok 3.3428 (3.1185)	Learning Rate [7.8125e-05]
4: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00098)	Tok/s 51618 (53202)	Loss/tok 3.1866 (3.1168)	Learning Rate [7.8125e-05]
7: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00097)	Tok/s 51531 (53445)	Loss/tok 3.1854 (3.1178)	Learning Rate [7.8125e-05]
5: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00093)	Tok/s 51565 (53289)	Loss/tok 3.0210 (3.1149)	Learning Rate [7.8125e-05]
3: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00092)	Tok/s 51608 (53107)	Loss/tok 2.9689 (3.1167)	Learning Rate [7.8125e-05]
6: TRAIN [2][1800/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00092)	Tok/s 51540 (53358)	Loss/tok 3.2636 (3.1206)	Learning Rate [7.8125e-05]
9: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00092)	Tok/s 54229 (53613)	Loss/tok 3.2126 (3.1151)	Learning Rate [7.8125e-05]
8: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00098)	Tok/s 54236 (53540)	Loss/tok 3.2186 (3.1185)	Learning Rate [7.8125e-05]
6: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00082 (0.00092)	Tok/s 53117 (53377)	Loss/tok 3.1172 (3.1202)	Learning Rate [7.8125e-05]
7: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00097)	Tok/s 53460 (53464)	Loss/tok 3.2454 (3.1183)	Learning Rate [7.8125e-05]
11: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00092)	Tok/s 54088 (53770)	Loss/tok 3.1952 (3.1192)	Learning Rate [7.8125e-05]
5: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00093)	Tok/s 53130 (53306)	Loss/tok 2.8636 (3.1153)	Learning Rate [7.8125e-05]
10: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00096)	Tok/s 54122 (53688)	Loss/tok 3.1999 (3.1079)	Learning Rate [7.8125e-05]
4: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00098)	Tok/s 53063 (53219)	Loss/tok 3.1547 (3.1171)	Learning Rate [7.8125e-05]
3: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00082 (0.00092)	Tok/s 53050 (53124)	Loss/tok 3.0092 (3.1163)	Learning Rate [7.8125e-05]
12: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00101)	Tok/s 53900 (53893)	Loss/tok 2.9366 (3.1205)	Learning Rate [7.8125e-05]
2: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00098)	Tok/s 52981 (53018)	Loss/tok 3.3601 (3.1165)	Learning Rate [7.8125e-05]
1: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00100)	Tok/s 52836 (52903)	Loss/tok 3.1012 (3.1168)	Learning Rate [7.8125e-05]
0: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00097)	Tok/s 52747 (52799)	Loss/tok 3.0366 (3.1229)	Learning Rate [7.8125e-05]
15: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00083 (0.00092)	Tok/s 53829 (54205)	Loss/tok 3.0096 (3.1161)	Learning Rate [7.8125e-05]
14: TRAIN [2][1810/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00091)	Tok/s 53746 (54088)	Loss/tok 3.0474 (3.1168)	Learning Rate [7.8125e-05]
13: TRAIN [2][1810/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00096)	Tok/s 52920 (53988)	Loss/tok 3.1853 (3.1166)	Learning Rate [7.8125e-05]
4: TRAIN [2][1820/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00098)	Tok/s 51989 (53255)	Loss/tok 2.9512 (3.1172)	Learning Rate [7.8125e-05]
5: TRAIN [2][1820/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00093)	Tok/s 51437 (53341)	Loss/tok 3.1363 (3.1154)	Learning Rate [7.8125e-05]
6: TRAIN [2][1820/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 51360 (53412)	Loss/tok 3.0478 (3.1201)	Learning Rate [7.8125e-05]
12: TRAIN [2][1820/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00101)	Tok/s 51383 (53928)	Loss/tok 3.0271 (3.1206)	Learning Rate [7.8125e-05]
13: TRAIN [2][1820/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00095)	Tok/s 51349 (54024)	Loss/tok 3.0287 (3.1166)	Learning Rate [7.8125e-05]
3: TRAIN [2][1820/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00092)	Tok/s 51293 (53160)	Loss/tok 3.0709 (3.1162)	Learning Rate [7.8125e-05]
7: TRAIN [2][1820/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00097)	Tok/s 51208 (53499)	Loss/tok 3.0827 (3.1183)	Learning Rate [7.8125e-05]
2: TRAIN [2][1820/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00098)	Tok/s 51188 (53054)	Loss/tok 3.1566 (3.1168)	Learning Rate [7.8125e-05]
8: TRAIN [2][1820/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00098)	Tok/s 51092 (53575)	Loss/tok 3.0576 (3.1183)	Learning Rate [7.8125e-05]
9: TRAIN [2][1820/3416]	Time 0.048 (0.058)	Data 0.00115 (0.00092)	Tok/s 51057 (53649)	Loss/tok 2.9646 (3.1153)	Learning Rate [7.8125e-05]
10: TRAIN [2][1820/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00096)	Tok/s 51079 (53725)	Loss/tok 2.9629 (3.1078)	Learning Rate [7.8125e-05]
15: TRAIN [2][1820/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 52680 (54240)	Loss/tok 3.1133 (3.1162)	Learning Rate [7.8125e-05]
1: TRAIN [2][1820/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00100)	Tok/s 51215 (52938)	Loss/tok 2.8807 (3.1164)	Learning Rate [7.8125e-05]
14: TRAIN [2][1820/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00091)	Tok/s 51993 (54123)	Loss/tok 2.9681 (3.1171)	Learning Rate [7.8125e-05]
11: TRAIN [2][1820/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00092)	Tok/s 51171 (53806)	Loss/tok 2.7516 (3.1193)	Learning Rate [7.8125e-05]
0: TRAIN [2][1820/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00097)	Tok/s 51221 (52836)	Loss/tok 2.9301 (3.1232)	Learning Rate [7.8125e-05]
4: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00098)	Tok/s 54292 (53273)	Loss/tok 3.0830 (3.1171)	Learning Rate [7.8125e-05]
5: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00093)	Tok/s 54196 (53358)	Loss/tok 3.4114 (3.1155)	Learning Rate [7.8125e-05]
7: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00097 (0.00097)	Tok/s 54016 (53515)	Loss/tok 3.1908 (3.1181)	Learning Rate [7.8125e-05]
9: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00092)	Tok/s 53900 (53664)	Loss/tok 3.0938 (3.1153)	Learning Rate [7.8125e-05]
6: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00092)	Tok/s 54181 (53429)	Loss/tok 3.2077 (3.1201)	Learning Rate [7.8125e-05]
3: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00092)	Tok/s 54142 (53178)	Loss/tok 3.1328 (3.1164)	Learning Rate [7.8125e-05]
8: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00098)	Tok/s 54023 (53591)	Loss/tok 3.0834 (3.1185)	Learning Rate [7.8125e-05]
2: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00084 (0.00098)	Tok/s 54138 (53071)	Loss/tok 3.1737 (3.1167)	Learning Rate [7.8125e-05]
1: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00100)	Tok/s 54062 (52955)	Loss/tok 3.1025 (3.1161)	Learning Rate [7.8125e-05]
10: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00096)	Tok/s 53846 (53740)	Loss/tok 3.0313 (3.1078)	Learning Rate [7.8125e-05]
11: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00084 (0.00092)	Tok/s 53727 (53822)	Loss/tok 3.2071 (3.1191)	Learning Rate [7.8125e-05]
12: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00101)	Tok/s 53847 (53944)	Loss/tok 3.1776 (3.1205)	Learning Rate [7.8125e-05]
0: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00097)	Tok/s 53966 (52853)	Loss/tok 3.4550 (3.1236)	Learning Rate [7.8125e-05]
15: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00092)	Tok/s 54538 (54256)	Loss/tok 3.4031 (3.1164)	Learning Rate [7.8125e-05]
14: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00091)	Tok/s 53783 (54138)	Loss/tok 3.2457 (3.1173)	Learning Rate [7.8125e-05]
13: TRAIN [2][1830/3416]	Time 0.064 (0.058)	Data 0.00081 (0.00095)	Tok/s 53784 (54039)	Loss/tok 3.2521 (3.1171)	Learning Rate [7.8125e-05]
11: TRAIN [2][1840/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 60819 (53850)	Loss/tok 3.2222 (3.1190)	Learning Rate [7.8125e-05]
10: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 60768 (53768)	Loss/tok 3.2709 (3.1074)	Learning Rate [7.8125e-05]
9: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 60637 (53692)	Loss/tok 3.2468 (3.1150)	Learning Rate [7.8125e-05]
12: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00101)	Tok/s 60762 (53971)	Loss/tok 3.4076 (3.1207)	Learning Rate [7.8125e-05]
13: TRAIN [2][1840/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00095)	Tok/s 60872 (54065)	Loss/tok 3.0438 (3.1167)	Learning Rate [7.8125e-05]
8: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 60538 (53618)	Loss/tok 3.5466 (3.1184)	Learning Rate [7.8125e-05]
14: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00091)	Tok/s 60737 (54165)	Loss/tok 3.0842 (3.1170)	Learning Rate [7.8125e-05]
7: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 60425 (53542)	Loss/tok 3.3571 (3.1181)	Learning Rate [7.8125e-05]
6: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 60292 (53456)	Loss/tok 3.2551 (3.1205)	Learning Rate [7.8125e-05]
15: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 61370 (54283)	Loss/tok 3.2463 (3.1163)	Learning Rate [7.8125e-05]
0: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00097)	Tok/s 60574 (52881)	Loss/tok 2.9837 (3.1234)	Learning Rate [7.8125e-05]
5: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 60302 (53386)	Loss/tok 3.2766 (3.1157)	Learning Rate [7.8125e-05]
1: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 60423 (52983)	Loss/tok 3.3465 (3.1160)	Learning Rate [7.8125e-05]
4: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00098)	Tok/s 60308 (53300)	Loss/tok 3.1979 (3.1170)	Learning Rate [7.8125e-05]
2: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 60398 (53099)	Loss/tok 3.2337 (3.1162)	Learning Rate [7.8125e-05]
3: TRAIN [2][1840/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 60328 (53205)	Loss/tok 3.4338 (3.1159)	Learning Rate [7.8125e-05]
0: TRAIN [2][1850/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00097)	Tok/s 74012 (52860)	Loss/tok 3.2024 (3.1231)	Learning Rate [7.8125e-05]
10: TRAIN [2][1850/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 74541 (53746)	Loss/tok 3.1503 (3.1071)	Learning Rate [7.8125e-05]
11: TRAIN [2][1850/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 74561 (53827)	Loss/tok 2.9684 (3.1185)	Learning Rate [7.8125e-05]
8: TRAIN [2][1850/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 74574 (53597)	Loss/tok 3.1652 (3.1181)	Learning Rate [7.8125e-05]
9: TRAIN [2][1850/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 74593 (53670)	Loss/tok 3.1166 (3.1147)	Learning Rate [7.8125e-05]
14: TRAIN [2][1850/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00091)	Tok/s 74748 (54143)	Loss/tok 2.9709 (3.1167)	Learning Rate [7.8125e-05]
1: TRAIN [2][1850/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 73907 (52962)	Loss/tok 2.9718 (3.1153)	Learning Rate [7.8125e-05]
12: TRAIN [2][1850/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00101)	Tok/s 74633 (53948)	Loss/tok 3.0124 (3.1200)	Learning Rate [7.8125e-05]
2: TRAIN [2][1850/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 73744 (53077)	Loss/tok 3.1257 (3.1160)	Learning Rate [7.8125e-05]
6: TRAIN [2][1850/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 73430 (53434)	Loss/tok 3.1912 (3.1205)	Learning Rate [7.8125e-05]
13: TRAIN [2][1850/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00095)	Tok/s 74666 (54043)	Loss/tok 2.9704 (3.1166)	Learning Rate [7.8125e-05]
7: TRAIN [2][1850/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 74277 (53521)	Loss/tok 3.0147 (3.1177)	Learning Rate [7.8125e-05]
15: TRAIN [2][1850/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 74844 (54260)	Loss/tok 3.0777 (3.1161)	Learning Rate [7.8125e-05]
3: TRAIN [2][1850/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 73636 (53183)	Loss/tok 3.1463 (3.1154)	Learning Rate [7.8125e-05]
4: TRAIN [2][1850/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00098)	Tok/s 73445 (53278)	Loss/tok 3.0579 (3.1169)	Learning Rate [7.8125e-05]
5: TRAIN [2][1850/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00093)	Tok/s 73496 (53364)	Loss/tok 3.1898 (3.1156)	Learning Rate [7.8125e-05]
11: TRAIN [2][1860/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 69154 (53880)	Loss/tok 2.8570 (3.1185)	Learning Rate [7.8125e-05]
9: TRAIN [2][1860/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00092)	Tok/s 69202 (53724)	Loss/tok 3.2050 (3.1146)	Learning Rate [7.8125e-05]
3: TRAIN [2][1860/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 69414 (53237)	Loss/tok 3.0263 (3.1160)	Learning Rate [7.8125e-05]
4: TRAIN [2][1860/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 69403 (53333)	Loss/tok 2.9927 (3.1168)	Learning Rate [7.8125e-05]
10: TRAIN [2][1860/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 69122 (53800)	Loss/tok 2.9562 (3.1069)	Learning Rate [7.8125e-05]
12: TRAIN [2][1860/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00101)	Tok/s 69496 (54002)	Loss/tok 3.4095 (3.1198)	Learning Rate [7.8125e-05]
2: TRAIN [2][1860/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 69268 (53131)	Loss/tok 3.0799 (3.1157)	Learning Rate [7.8125e-05]
5: TRAIN [2][1860/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 69322 (53418)	Loss/tok 3.3427 (3.1156)	Learning Rate [7.8125e-05]
6: TRAIN [2][1860/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 69228 (53488)	Loss/tok 3.3829 (3.1201)	Learning Rate [7.8125e-05]
8: TRAIN [2][1860/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 69126 (53650)	Loss/tok 3.0618 (3.1177)	Learning Rate [7.8125e-05]
14: TRAIN [2][1860/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00091)	Tok/s 69989 (54196)	Loss/tok 3.2263 (3.1167)	Learning Rate [7.8125e-05]
1: TRAIN [2][1860/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00100)	Tok/s 69192 (53016)	Loss/tok 3.2881 (3.1157)	Learning Rate [7.8125e-05]
13: TRAIN [2][1860/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00095)	Tok/s 69891 (54097)	Loss/tok 3.0368 (3.1166)	Learning Rate [7.8125e-05]
0: TRAIN [2][1860/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 68944 (52915)	Loss/tok 3.1995 (3.1229)	Learning Rate [7.8125e-05]
7: TRAIN [2][1860/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 69151 (53575)	Loss/tok 3.1694 (3.1179)	Learning Rate [7.8125e-05]
15: TRAIN [2][1860/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 69978 (54313)	Loss/tok 3.2244 (3.1160)	Learning Rate [7.8125e-05]
6: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00084 (0.00092)	Tok/s 51806 (53468)	Loss/tok 3.1988 (3.1198)	Learning Rate [7.8125e-05]
5: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00093)	Tok/s 51729 (53399)	Loss/tok 3.1909 (3.1151)	Learning Rate [7.8125e-05]
4: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00098)	Tok/s 51701 (53314)	Loss/tok 2.8465 (3.1163)	Learning Rate [7.8125e-05]
7: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00097)	Tok/s 51745 (53555)	Loss/tok 3.1997 (3.1175)	Learning Rate [7.8125e-05]
8: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00100 (0.00098)	Tok/s 51604 (53631)	Loss/tok 3.2156 (3.1175)	Learning Rate [7.8125e-05]
3: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00083 (0.00092)	Tok/s 51679 (53217)	Loss/tok 3.1374 (3.1157)	Learning Rate [7.8125e-05]
9: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00092)	Tok/s 51539 (53703)	Loss/tok 2.9759 (3.1139)	Learning Rate [7.8125e-05]
2: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00082 (0.00098)	Tok/s 51676 (53111)	Loss/tok 3.2701 (3.1154)	Learning Rate [7.8125e-05]
1: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00100)	Tok/s 51632 (52997)	Loss/tok 3.4782 (3.1151)	Learning Rate [7.8125e-05]
10: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00096)	Tok/s 51360 (53780)	Loss/tok 2.9996 (3.1067)	Learning Rate [7.8125e-05]
0: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00097)	Tok/s 51527 (52897)	Loss/tok 3.0717 (3.1223)	Learning Rate [7.8125e-05]
11: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00092)	Tok/s 52126 (53861)	Loss/tok 3.2214 (3.1182)	Learning Rate [7.8125e-05]
15: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00085 (0.00092)	Tok/s 52582 (54295)	Loss/tok 3.0886 (3.1156)	Learning Rate [7.8125e-05]
12: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00101)	Tok/s 52559 (53983)	Loss/tok 2.9876 (3.1196)	Learning Rate [7.8125e-05]
14: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00079 (0.00091)	Tok/s 52602 (54178)	Loss/tok 3.0644 (3.1166)	Learning Rate [7.8125e-05]
13: TRAIN [2][1870/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00095)	Tok/s 52529 (54078)	Loss/tok 3.3990 (3.1164)	Learning Rate [7.8125e-05]
6: TRAIN [2][1880/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 31676 (53484)	Loss/tok 2.9905 (3.1203)	Learning Rate [7.8125e-05]
5: TRAIN [2][1880/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 31673 (53414)	Loss/tok 2.9487 (3.1148)	Learning Rate [7.8125e-05]
7: TRAIN [2][1880/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00097)	Tok/s 31616 (53572)	Loss/tok 2.8758 (3.1176)	Learning Rate [7.8125e-05]
4: TRAIN [2][1880/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00098)	Tok/s 31671 (53330)	Loss/tok 2.6725 (3.1164)	Learning Rate [7.8125e-05]
3: TRAIN [2][1880/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00092)	Tok/s 31700 (53234)	Loss/tok 2.8019 (3.1155)	Learning Rate [7.8125e-05]
8: TRAIN [2][1880/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00098)	Tok/s 31605 (53647)	Loss/tok 2.9467 (3.1171)	Learning Rate [7.8125e-05]
9: TRAIN [2][1880/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00092)	Tok/s 31605 (53720)	Loss/tok 2.9395 (3.1140)	Learning Rate [7.8125e-05]
2: TRAIN [2][1880/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00098)	Tok/s 31663 (53127)	Loss/tok 2.6244 (3.1154)	Learning Rate [7.8125e-05]
1: TRAIN [2][1880/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00100)	Tok/s 31650 (53013)	Loss/tok 2.6763 (3.1152)	Learning Rate [7.8125e-05]
11: TRAIN [2][1880/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00092)	Tok/s 32920 (53879)	Loss/tok 2.9578 (3.1182)	Learning Rate [7.8125e-05]
10: TRAIN [2][1880/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00096)	Tok/s 32337 (53797)	Loss/tok 2.8029 (3.1062)	Learning Rate [7.8125e-05]
0: TRAIN [2][1880/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00097)	Tok/s 31648 (52913)	Loss/tok 2.6610 (3.1221)	Learning Rate [7.8125e-05]
15: TRAIN [2][1880/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00092)	Tok/s 32966 (54313)	Loss/tok 2.6589 (3.1152)	Learning Rate [7.8125e-05]
12: TRAIN [2][1880/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00101)	Tok/s 32901 (54001)	Loss/tok 2.8257 (3.1196)	Learning Rate [7.8125e-05]
14: TRAIN [2][1880/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00091)	Tok/s 32959 (54196)	Loss/tok 3.0705 (3.1168)	Learning Rate [7.8125e-05]
13: TRAIN [2][1880/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00095)	Tok/s 32887 (54096)	Loss/tok 2.7613 (3.1163)	Learning Rate [7.8125e-05]
11: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00092)	Tok/s 56438 (53831)	Loss/tok 2.8770 (3.1177)	Learning Rate [7.8125e-05]
12: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00101)	Tok/s 56346 (53953)	Loss/tok 2.9641 (3.1193)	Learning Rate [7.8125e-05]
13: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00096)	Tok/s 56289 (54049)	Loss/tok 3.2149 (3.1158)	Learning Rate [7.8125e-05]
10: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00096)	Tok/s 56390 (53749)	Loss/tok 3.2784 (3.1058)	Learning Rate [7.8125e-05]
9: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00092)	Tok/s 56368 (53672)	Loss/tok 3.2449 (3.1138)	Learning Rate [7.8125e-05]
14: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00091)	Tok/s 56167 (54150)	Loss/tok 3.5587 (3.1163)	Learning Rate [7.8125e-05]
15: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00107 (0.00092)	Tok/s 56108 (54267)	Loss/tok 3.0469 (3.1149)	Learning Rate [7.8125e-05]
8: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00104 (0.00098)	Tok/s 56363 (53599)	Loss/tok 3.2048 (3.1166)	Learning Rate [7.8125e-05]
0: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00097)	Tok/s 56114 (52861)	Loss/tok 3.1169 (3.1216)	Learning Rate [7.8125e-05]
7: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00097)	Tok/s 56364 (53524)	Loss/tok 3.0740 (3.1171)	Learning Rate [7.8125e-05]
1: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00100)	Tok/s 56126 (52962)	Loss/tok 3.2670 (3.1149)	Learning Rate [7.8125e-05]
6: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00092)	Tok/s 56280 (53436)	Loss/tok 3.2221 (3.1198)	Learning Rate [7.8125e-05]
4: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00098)	Tok/s 56168 (53281)	Loss/tok 3.1984 (3.1162)	Learning Rate [7.8125e-05]
2: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00098)	Tok/s 56105 (53078)	Loss/tok 3.1629 (3.1145)	Learning Rate [7.8125e-05]
5: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00093)	Tok/s 56241 (53366)	Loss/tok 3.1349 (3.1144)	Learning Rate [7.8125e-05]
3: TRAIN [2][1890/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00092)	Tok/s 56125 (53184)	Loss/tok 3.1509 (3.1150)	Learning Rate [7.8125e-05]
11: Upscaling, new scale: 8192.0
10: Upscaling, new scale: 8192.0
9: Upscaling, new scale: 8192.0
8: Upscaling, new scale: 8192.0
12: Upscaling, new scale: 8192.0
7: Upscaling, new scale: 8192.0
13: Upscaling, new scale: 8192.0
6: Upscaling, new scale: 8192.0
14: Upscaling, new scale: 8192.0
5: Upscaling, new scale: 8192.0
4: Upscaling, new scale: 8192.0
15: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
1: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00109 (0.00100)	Tok/s 49782 (52966)	Loss/tok 2.9663 (3.1150)	Learning Rate [7.8125e-05]
0: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00097)	Tok/s 48564 (52865)	Loss/tok 3.0300 (3.1210)	Learning Rate [7.8125e-05]
15: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00092)	Tok/s 49966 (54270)	Loss/tok 3.1063 (3.1150)	Learning Rate [7.8125e-05]
14: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00091)	Tok/s 49911 (54153)	Loss/tok 2.8125 (3.1162)	Learning Rate [7.8125e-05]
4: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00098)	Tok/s 49571 (53284)	Loss/tok 2.9655 (3.1164)	Learning Rate [7.8125e-05]
2: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00098)	Tok/s 49718 (53081)	Loss/tok 3.1336 (3.1139)	Learning Rate [7.8125e-05]
13: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00096)	Tok/s 49777 (54051)	Loss/tok 2.9382 (3.1158)	Learning Rate [7.8125e-05]
3: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00092)	Tok/s 49584 (53187)	Loss/tok 2.8166 (3.1149)	Learning Rate [7.8125e-05]
6: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00092)	Tok/s 49347 (53438)	Loss/tok 2.8605 (3.1195)	Learning Rate [7.8125e-05]
12: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00112 (0.00101)	Tok/s 49641 (53955)	Loss/tok 2.8363 (3.1193)	Learning Rate [7.8125e-05]
11: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00092)	Tok/s 49481 (53832)	Loss/tok 2.8919 (3.1175)	Learning Rate [7.8125e-05]
5: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00093)	Tok/s 49335 (53368)	Loss/tok 2.8762 (3.1144)	Learning Rate [7.8125e-05]
9: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00092)	Tok/s 49255 (53674)	Loss/tok 3.0110 (3.1139)	Learning Rate [7.8125e-05]
10: TRAIN [2][1900/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00096)	Tok/s 49375 (53751)	Loss/tok 3.0955 (3.1056)	Learning Rate [7.8125e-05]
7: TRAIN [2][1900/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00097)	Tok/s 49102 (53525)	Loss/tok 2.9736 (3.1169)	Learning Rate [7.8125e-05]
8: TRAIN [2][1900/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00098)	Tok/s 49180 (53601)	Loss/tok 3.1452 (3.1166)	Learning Rate [7.8125e-05]
9: TRAIN [2][1910/3416]	Time 0.042 (0.058)	Data 0.00094 (0.00092)	Tok/s 31877 (53604)	Loss/tok 2.5593 (3.1135)	Learning Rate [7.8125e-05]
8: TRAIN [2][1910/3416]	Time 0.042 (0.058)	Data 0.00102 (0.00098)	Tok/s 31863 (53532)	Loss/tok 2.6025 (3.1167)	Learning Rate [7.8125e-05]
11: TRAIN [2][1910/3416]	Time 0.042 (0.058)	Data 0.00098 (0.00092)	Tok/s 31804 (53763)	Loss/tok 2.5738 (3.1170)	Learning Rate [7.8125e-05]
10: TRAIN [2][1910/3416]	Time 0.042 (0.058)	Data 0.00102 (0.00096)	Tok/s 31820 (53681)	Loss/tok 2.5958 (3.1054)	Learning Rate [7.8125e-05]
7: TRAIN [2][1910/3416]	Time 0.042 (0.058)	Data 0.00104 (0.00097)	Tok/s 31784 (53455)	Loss/tok 2.5298 (3.1165)	Learning Rate [7.8125e-05]
12: TRAIN [2][1910/3416]	Time 0.042 (0.058)	Data 0.00114 (0.00101)	Tok/s 31734 (53886)	Loss/tok 2.4902 (3.1187)	Learning Rate [7.8125e-05]
13: TRAIN [2][1910/3416]	Time 0.043 (0.058)	Data 0.00102 (0.00096)	Tok/s 31600 (53982)	Loss/tok 2.4479 (3.1154)	Learning Rate [7.8125e-05]
6: TRAIN [2][1910/3416]	Time 0.043 (0.058)	Data 0.00100 (0.00092)	Tok/s 31020 (53368)	Loss/tok 2.6230 (3.1190)	Learning Rate [7.8125e-05]
4: TRAIN [2][1910/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00098)	Tok/s 30046 (53211)	Loss/tok 2.5653 (3.1159)	Learning Rate [7.8125e-05]
5: TRAIN [2][1910/3416]	Time 0.043 (0.058)	Data 0.00105 (0.00093)	Tok/s 30115 (53297)	Loss/tok 2.7230 (3.1138)	Learning Rate [7.8125e-05]
3: TRAIN [2][1910/3416]	Time 0.043 (0.058)	Data 0.00099 (0.00092)	Tok/s 30024 (53114)	Loss/tok 2.4050 (3.1142)	Learning Rate [7.8125e-05]
14: TRAIN [2][1910/3416]	Time 0.043 (0.058)	Data 0.00100 (0.00091)	Tok/s 31545 (54084)	Loss/tok 2.5726 (3.1159)	Learning Rate [7.8125e-05]
2: TRAIN [2][1910/3416]	Time 0.043 (0.058)	Data 0.00096 (0.00098)	Tok/s 30023 (53008)	Loss/tok 2.5661 (3.1133)	Learning Rate [7.8125e-05]
15: TRAIN [2][1910/3416]	Time 0.043 (0.058)	Data 0.00108 (0.00092)	Tok/s 31541 (54201)	Loss/tok 2.5149 (3.1146)	Learning Rate [7.8125e-05]
1: TRAIN [2][1910/3416]	Time 0.043 (0.058)	Data 0.00113 (0.00100)	Tok/s 30015 (52892)	Loss/tok 2.4732 (3.1144)	Learning Rate [7.8125e-05]
0: TRAIN [2][1910/3416]	Time 0.043 (0.058)	Data 0.00102 (0.00097)	Tok/s 30015 (52789)	Loss/tok 2.5861 (3.1206)	Learning Rate [7.8125e-05]
12: TRAIN [2][1920/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00101)	Tok/s 54524 (53890)	Loss/tok 2.9920 (3.1188)	Learning Rate [7.8125e-05]
11: TRAIN [2][1920/3416]	Time 0.055 (0.058)	Data 0.00086 (0.00092)	Tok/s 54363 (53767)	Loss/tok 3.0631 (3.1172)	Learning Rate [7.8125e-05]
10: TRAIN [2][1920/3416]	Time 0.055 (0.058)	Data 0.00082 (0.00096)	Tok/s 53875 (53686)	Loss/tok 3.1470 (3.1055)	Learning Rate [7.8125e-05]
13: TRAIN [2][1920/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00096)	Tok/s 54409 (53985)	Loss/tok 3.1088 (3.1158)	Learning Rate [7.8125e-05]
9: TRAIN [2][1920/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00092)	Tok/s 52981 (53609)	Loss/tok 3.0887 (3.1136)	Learning Rate [7.8125e-05]
14: TRAIN [2][1920/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00091)	Tok/s 54437 (54087)	Loss/tok 3.2576 (3.1157)	Learning Rate [7.8125e-05]
15: TRAIN [2][1920/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00092)	Tok/s 54453 (54204)	Loss/tok 3.0528 (3.1149)	Learning Rate [7.8125e-05]
8: TRAIN [2][1920/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00098)	Tok/s 52940 (53536)	Loss/tok 3.1455 (3.1167)	Learning Rate [7.8125e-05]
6: TRAIN [2][1920/3416]	Time 0.056 (0.058)	Data 0.00084 (0.00092)	Tok/s 52980 (53372)	Loss/tok 3.0681 (3.1194)	Learning Rate [7.8125e-05]
0: TRAIN [2][1920/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00097)	Tok/s 53233 (52793)	Loss/tok 3.1604 (3.1207)	Learning Rate [7.8125e-05]
1: TRAIN [2][1920/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00100)	Tok/s 53268 (52895)	Loss/tok 3.0686 (3.1147)	Learning Rate [7.8125e-05]
7: TRAIN [2][1920/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00097)	Tok/s 52913 (53459)	Loss/tok 3.0097 (3.1165)	Learning Rate [7.8125e-05]
2: TRAIN [2][1920/3416]	Time 0.055 (0.058)	Data 0.00083 (0.00098)	Tok/s 53126 (53012)	Loss/tok 3.1442 (3.1137)	Learning Rate [7.8125e-05]
5: TRAIN [2][1920/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00093)	Tok/s 52980 (53300)	Loss/tok 3.0892 (3.1141)	Learning Rate [7.8125e-05]
3: TRAIN [2][1920/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00092)	Tok/s 53042 (53118)	Loss/tok 2.9516 (3.1140)	Learning Rate [7.8125e-05]
4: TRAIN [2][1920/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00098)	Tok/s 52906 (53214)	Loss/tok 2.9602 (3.1161)	Learning Rate [7.8125e-05]
9: TRAIN [2][1930/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00092)	Tok/s 52240 (53590)	Loss/tok 3.0472 (3.1129)	Learning Rate [7.8125e-05]
7: TRAIN [2][1930/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00097)	Tok/s 52123 (53441)	Loss/tok 3.1028 (3.1158)	Learning Rate [7.8125e-05]
6: TRAIN [2][1930/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00092)	Tok/s 51972 (53354)	Loss/tok 3.0233 (3.1194)	Learning Rate [7.8125e-05]
10: TRAIN [2][1930/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00096)	Tok/s 52105 (53667)	Loss/tok 2.7440 (3.1049)	Learning Rate [7.8125e-05]
5: TRAIN [2][1930/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00093)	Tok/s 51960 (53282)	Loss/tok 3.1269 (3.1139)	Learning Rate [7.8125e-05]
11: TRAIN [2][1930/3416]	Time 0.050 (0.058)	Data 0.00078 (0.00092)	Tok/s 52078 (53749)	Loss/tok 3.1833 (3.1166)	Learning Rate [7.8125e-05]
8: TRAIN [2][1930/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00098)	Tok/s 52199 (53518)	Loss/tok 3.0896 (3.1162)	Learning Rate [7.8125e-05]
4: TRAIN [2][1930/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00098)	Tok/s 51901 (53196)	Loss/tok 3.0464 (3.1156)	Learning Rate [7.8125e-05]
3: TRAIN [2][1930/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00092)	Tok/s 51905 (53100)	Loss/tok 3.3025 (3.1140)	Learning Rate [7.8125e-05]
12: TRAIN [2][1930/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00101)	Tok/s 51992 (53872)	Loss/tok 3.0294 (3.1184)	Learning Rate [7.8125e-05]
13: TRAIN [2][1930/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00096)	Tok/s 51833 (53967)	Loss/tok 3.0184 (3.1158)	Learning Rate [7.8125e-05]
14: TRAIN [2][1930/3416]	Time 0.051 (0.058)	Data 0.00078 (0.00091)	Tok/s 51751 (54068)	Loss/tok 2.9070 (3.1156)	Learning Rate [7.8125e-05]
1: TRAIN [2][1930/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00100)	Tok/s 51764 (52879)	Loss/tok 3.0666 (3.1143)	Learning Rate [7.8125e-05]
2: TRAIN [2][1930/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00098)	Tok/s 51902 (52994)	Loss/tok 3.0543 (3.1136)	Learning Rate [7.8125e-05]
15: TRAIN [2][1930/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 51629 (54186)	Loss/tok 3.2631 (3.1148)	Learning Rate [7.8125e-05]
0: TRAIN [2][1930/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00097)	Tok/s 51620 (52777)	Loss/tok 3.1869 (3.1206)	Learning Rate [7.8125e-05]
0: Gradient norm: inf
15: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
15: Skipped batch, new scale: 4096.0
14: Gradient norm: inf
2: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
13: Gradient norm: inf
14: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Gradient norm: inf
12: Gradient norm: inf
13: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
0: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 86284 (52773)	Loss/tok 2.8730 (3.1201)	Learning Rate [7.8125e-05]
4: Gradient norm: inf
12: Skipped batch, new scale: 4096.0
15: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 91594 (54182)	Loss/tok 2.9972 (3.1143)	Learning Rate [7.8125e-05]
11: Gradient norm: inf
1: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 86157 (52874)	Loss/tok 3.0302 (3.1135)	Learning Rate [7.8125e-05]
4: Skipped batch, new scale: 4096.0
5: Gradient norm: inf
11: Skipped batch, new scale: 4096.0
14: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00091)	Tok/s 90693 (54064)	Loss/tok 2.9862 (3.1153)	Learning Rate [7.8125e-05]
10: Gradient norm: inf
2: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00098)	Tok/s 86034 (52990)	Loss/tok 2.8945 (3.1129)	Learning Rate [7.8125e-05]
13: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 90036 (53962)	Loss/tok 2.8970 (3.1154)	Learning Rate [7.8125e-05]
5: Skipped batch, new scale: 4096.0
6: Gradient norm: inf
10: Skipped batch, new scale: 4096.0
9: Gradient norm: inf
3: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 86801 (53095)	Loss/tok 3.0603 (3.1142)	Learning Rate [7.8125e-05]
12: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00101)	Tok/s 89761 (53867)	Loss/tok 3.0357 (3.1184)	Learning Rate [7.8125e-05]
6: Skipped batch, new scale: 4096.0
7: Gradient norm: inf
8: Gradient norm: inf
9: Skipped batch, new scale: 4096.0
4: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 86678 (53191)	Loss/tok 3.1164 (3.1155)	Learning Rate [7.8125e-05]
11: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 89047 (53744)	Loss/tok 2.8343 (3.1163)	Learning Rate [7.8125e-05]
7: Skipped batch, new scale: 4096.0
8: Skipped batch, new scale: 4096.0
5: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 86726 (53277)	Loss/tok 2.9589 (3.1135)	Learning Rate [7.8125e-05]
10: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 88908 (53662)	Loss/tok 3.0490 (3.1046)	Learning Rate [7.8125e-05]
6: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 86934 (53348)	Loss/tok 2.9589 (3.1193)	Learning Rate [7.8125e-05]
9: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 87939 (53585)	Loss/tok 2.9553 (3.1122)	Learning Rate [7.8125e-05]
7: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 87630 (53436)	Loss/tok 3.1673 (3.1154)	Learning Rate [7.8125e-05]
8: TRAIN [2][1940/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 87706 (53512)	Loss/tok 2.9805 (3.1157)	Learning Rate [7.8125e-05]
9: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00092)	Tok/s 51896 (53627)	Loss/tok 3.0812 (3.1120)	Learning Rate [7.8125e-05]
6: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00081 (0.00092)	Tok/s 51954 (53390)	Loss/tok 3.0046 (3.1188)	Learning Rate [7.8125e-05]
8: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00098)	Tok/s 51874 (53554)	Loss/tok 2.6868 (3.1158)	Learning Rate [7.8125e-05]
7: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00097)	Tok/s 51921 (53477)	Loss/tok 2.9545 (3.1150)	Learning Rate [7.8125e-05]
10: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00096)	Tok/s 51724 (53704)	Loss/tok 2.8888 (3.1044)	Learning Rate [7.8125e-05]
11: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00092)	Tok/s 51666 (53785)	Loss/tok 3.1218 (3.1165)	Learning Rate [7.8125e-05]
5: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00093)	Tok/s 51905 (53317)	Loss/tok 3.0737 (3.1133)	Learning Rate [7.8125e-05]
12: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00111 (0.00101)	Tok/s 51639 (53908)	Loss/tok 3.2292 (3.1181)	Learning Rate [7.8125e-05]
4: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00098)	Tok/s 51862 (53231)	Loss/tok 3.3100 (3.1155)	Learning Rate [7.8125e-05]
13: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00096)	Tok/s 51550 (54003)	Loss/tok 3.0967 (3.1151)	Learning Rate [7.8125e-05]
1: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00108 (0.00100)	Tok/s 51686 (52915)	Loss/tok 3.0823 (3.1133)	Learning Rate [7.8125e-05]
3: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00082 (0.00092)	Tok/s 51841 (53136)	Loss/tok 3.1900 (3.1143)	Learning Rate [7.8125e-05]
2: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00098)	Tok/s 51717 (53030)	Loss/tok 3.2428 (3.1131)	Learning Rate [7.8125e-05]
14: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00085 (0.00091)	Tok/s 51569 (54104)	Loss/tok 3.0960 (3.1151)	Learning Rate [7.8125e-05]
15: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00092)	Tok/s 51572 (54221)	Loss/tok 3.1431 (3.1143)	Learning Rate [7.8125e-05]
0: TRAIN [2][1950/3416]	Time 0.053 (0.058)	Data 0.00105 (0.00097)	Tok/s 51587 (52814)	Loss/tok 3.0471 (3.1196)	Learning Rate [7.8125e-05]
6: TRAIN [2][1960/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00092)	Tok/s 52034 (53407)	Loss/tok 3.5623 (3.1193)	Learning Rate [7.8125e-05]
5: TRAIN [2][1960/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00093)	Tok/s 52029 (53335)	Loss/tok 3.0693 (3.1134)	Learning Rate [7.8125e-05]
4: TRAIN [2][1960/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00098)	Tok/s 51892 (53249)	Loss/tok 3.1809 (3.1159)	Learning Rate [7.8125e-05]
1: TRAIN [2][1960/3416]	Time 0.059 (0.058)	Data 0.00106 (0.00100)	Tok/s 51861 (52934)	Loss/tok 3.1964 (3.1138)	Learning Rate [7.8125e-05]
7: TRAIN [2][1960/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00097)	Tok/s 51848 (53494)	Loss/tok 3.2421 (3.1154)	Learning Rate [7.8125e-05]
3: TRAIN [2][1960/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00092)	Tok/s 51911 (53154)	Loss/tok 3.1292 (3.1147)	Learning Rate [7.8125e-05]
8: TRAIN [2][1960/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00098)	Tok/s 51835 (53570)	Loss/tok 3.1308 (3.1158)	Learning Rate [7.8125e-05]
2: TRAIN [2][1960/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00098)	Tok/s 51801 (53050)	Loss/tok 3.0569 (3.1135)	Learning Rate [7.8125e-05]
9: TRAIN [2][1960/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00092)	Tok/s 52777 (53644)	Loss/tok 2.9311 (3.1123)	Learning Rate [7.8125e-05]
0: TRAIN [2][1960/3416]	Time 0.059 (0.058)	Data 0.00106 (0.00097)	Tok/s 51652 (52834)	Loss/tok 3.0545 (3.1200)	Learning Rate [7.8125e-05]
12: TRAIN [2][1960/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00101)	Tok/s 52720 (53925)	Loss/tok 3.1527 (3.1179)	Learning Rate [7.8125e-05]
15: TRAIN [2][1960/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00092)	Tok/s 52641 (54237)	Loss/tok 3.2597 (3.1149)	Learning Rate [7.8125e-05]
10: TRAIN [2][1960/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00096)	Tok/s 52680 (53720)	Loss/tok 3.3823 (3.1049)	Learning Rate [7.8125e-05]
11: TRAIN [2][1960/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00092)	Tok/s 52688 (53802)	Loss/tok 3.3887 (3.1165)	Learning Rate [7.8125e-05]
14: TRAIN [2][1960/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00091)	Tok/s 52539 (54119)	Loss/tok 3.1747 (3.1151)	Learning Rate [7.8125e-05]
13: TRAIN [2][1960/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00096)	Tok/s 52566 (54018)	Loss/tok 3.0232 (3.1154)	Learning Rate [7.8125e-05]
4: Gradient norm: inf
3: Gradient norm: inf
5: Gradient norm: inf
4: Skipped batch, new scale: 2048.0
2: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
6: Gradient norm: inf
2: Skipped batch, new scale: 2048.0
1: Gradient norm: inf
6: Skipped batch, new scale: 2048.0
7: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
7: Skipped batch, new scale: 2048.0
8: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
15: Skipped batch, new scale: 2048.0
13: Gradient norm: inf
14: Gradient norm: inf
8: Skipped batch, new scale: 2048.0
9: Gradient norm: inf
12: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
13: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
9: Skipped batch, new scale: 2048.0
11: Gradient norm: inf
12: Skipped batch, new scale: 2048.0
10: Skipped batch, new scale: 2048.0
11: Skipped batch, new scale: 2048.0
6: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00082 (0.00092)	Tok/s 53913 (53406)	Loss/tok 3.3418 (3.1189)	Learning Rate [7.8125e-05]
4: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00098)	Tok/s 53928 (53250)	Loss/tok 3.2035 (3.1158)	Learning Rate [7.8125e-05]
7: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00097)	Tok/s 53802 (53493)	Loss/tok 3.3596 (3.1149)	Learning Rate [7.8125e-05]
8: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00098)	Tok/s 53734 (53570)	Loss/tok 3.1639 (3.1155)	Learning Rate [7.8125e-05]
9: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00092)	Tok/s 54010 (53642)	Loss/tok 3.2421 (3.1119)	Learning Rate [7.8125e-05]
5: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00093)	Tok/s 53802 (53335)	Loss/tok 3.1827 (3.1133)	Learning Rate [7.8125e-05]
3: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00084 (0.00092)	Tok/s 53815 (53155)	Loss/tok 2.9161 (3.1145)	Learning Rate [7.8125e-05]
2: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00098)	Tok/s 53804 (53050)	Loss/tok 3.0924 (3.1134)	Learning Rate [7.8125e-05]
1: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00100)	Tok/s 53801 (52934)	Loss/tok 3.1130 (3.1133)	Learning Rate [7.8125e-05]
12: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00101)	Tok/s 54665 (53924)	Loss/tok 3.2695 (3.1177)	Learning Rate [7.8125e-05]
10: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00096)	Tok/s 54516 (53719)	Loss/tok 3.1067 (3.1047)	Learning Rate [7.8125e-05]
0: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00097)	Tok/s 53695 (52834)	Loss/tok 3.4722 (3.1201)	Learning Rate [7.8125e-05]
15: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00092)	Tok/s 54658 (54238)	Loss/tok 3.2879 (3.1150)	Learning Rate [7.8125e-05]
13: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00096)	Tok/s 54557 (54018)	Loss/tok 3.0565 (3.1151)	Learning Rate [7.8125e-05]
14: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00082 (0.00091)	Tok/s 54580 (54119)	Loss/tok 3.6445 (3.1151)	Learning Rate [7.8125e-05]
11: TRAIN [2][1970/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00092)	Tok/s 54588 (53801)	Loss/tok 3.3107 (3.1165)	Learning Rate [7.8125e-05]
6: TRAIN [2][1980/3416]	Time 0.041 (0.058)	Data 0.00085 (0.00092)	Tok/s 29440 (53411)	Loss/tok 2.3171 (3.1185)	Learning Rate [7.8125e-05]
8: TRAIN [2][1980/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00098)	Tok/s 29396 (53573)	Loss/tok 2.6574 (3.1154)	Learning Rate [7.8125e-05]
7: TRAIN [2][1980/3416]	Time 0.041 (0.058)	Data 0.00102 (0.00097)	Tok/s 29404 (53497)	Loss/tok 2.4964 (3.1153)	Learning Rate [7.8125e-05]
9: TRAIN [2][1980/3416]	Time 0.042 (0.058)	Data 0.00090 (0.00092)	Tok/s 29295 (53646)	Loss/tok 2.4533 (3.1122)	Learning Rate [7.8125e-05]
5: TRAIN [2][1980/3416]	Time 0.041 (0.058)	Data 0.00098 (0.00093)	Tok/s 29342 (53340)	Loss/tok 2.7010 (3.1130)	Learning Rate [7.8125e-05]
4: TRAIN [2][1980/3416]	Time 0.042 (0.058)	Data 0.00102 (0.00098)	Tok/s 29172 (53254)	Loss/tok 2.6606 (3.1158)	Learning Rate [7.8125e-05]
3: TRAIN [2][1980/3416]	Time 0.042 (0.058)	Data 0.00092 (0.00092)	Tok/s 27636 (53158)	Loss/tok 2.6486 (3.1149)	Learning Rate [7.8125e-05]
10: TRAIN [2][1980/3416]	Time 0.042 (0.058)	Data 0.00088 (0.00096)	Tok/s 29189 (53723)	Loss/tok 2.5180 (3.1044)	Learning Rate [7.8125e-05]
12: TRAIN [2][1980/3416]	Time 0.042 (0.058)	Data 0.00089 (0.00101)	Tok/s 29864 (53928)	Loss/tok 2.4700 (3.1178)	Learning Rate [7.8125e-05]
2: TRAIN [2][1980/3416]	Time 0.042 (0.058)	Data 0.00088 (0.00098)	Tok/s 27520 (53054)	Loss/tok 2.4143 (3.1134)	Learning Rate [7.8125e-05]
1: TRAIN [2][1980/3416]	Time 0.042 (0.058)	Data 0.00101 (0.00100)	Tok/s 27443 (52938)	Loss/tok 2.5285 (3.1132)	Learning Rate [7.8125e-05]
13: TRAIN [2][1980/3416]	Time 0.042 (0.058)	Data 0.00090 (0.00096)	Tok/s 30526 (54022)	Loss/tok 2.5946 (3.1152)	Learning Rate [7.8125e-05]
0: TRAIN [2][1980/3416]	Time 0.042 (0.058)	Data 0.00275 (0.00097)	Tok/s 27364 (52838)	Loss/tok 2.5698 (3.1196)	Learning Rate [7.8125e-05]
15: TRAIN [2][1980/3416]	Time 0.042 (0.058)	Data 0.00097 (0.00092)	Tok/s 30374 (54242)	Loss/tok 2.7398 (3.1149)	Learning Rate [7.8125e-05]
14: TRAIN [2][1980/3416]	Time 0.042 (0.058)	Data 0.00095 (0.00091)	Tok/s 30403 (54123)	Loss/tok 2.5863 (3.1154)	Learning Rate [7.8125e-05]
11: TRAIN [2][1980/3416]	Time 0.042 (0.058)	Data 0.00106 (0.00092)	Tok/s 29072 (53805)	Loss/tok 2.4898 (3.1164)	Learning Rate [7.8125e-05]
4: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 66408 (53282)	Loss/tok 3.2616 (3.1161)	Learning Rate [7.8125e-05]
3: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 66453 (53185)	Loss/tok 3.3694 (3.1149)	Learning Rate [7.8125e-05]
2: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00098)	Tok/s 66400 (53081)	Loss/tok 3.1799 (3.1132)	Learning Rate [7.8125e-05]
6: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 66368 (53438)	Loss/tok 3.4391 (3.1184)	Learning Rate [7.8125e-05]
5: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 66377 (53367)	Loss/tok 3.1082 (3.1129)	Learning Rate [7.8125e-05]
0: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00097)	Tok/s 66491 (52867)	Loss/tok 3.0153 (3.1194)	Learning Rate [7.8125e-05]
1: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00100)	Tok/s 66351 (52966)	Loss/tok 3.4073 (3.1132)	Learning Rate [7.8125e-05]
7: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 66364 (53525)	Loss/tok 3.3270 (3.1152)	Learning Rate [7.8125e-05]
8: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 66413 (53601)	Loss/tok 3.2620 (3.1154)	Learning Rate [7.8125e-05]
9: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00077 (0.00092)	Tok/s 66563 (53673)	Loss/tok 3.0950 (3.1119)	Learning Rate [7.8125e-05]
15: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 67352 (54271)	Loss/tok 3.3835 (3.1148)	Learning Rate [7.8125e-05]
12: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00101)	Tok/s 67395 (53956)	Loss/tok 3.3685 (3.1178)	Learning Rate [7.8125e-05]
14: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 67327 (54152)	Loss/tok 3.0735 (3.1153)	Learning Rate [7.8125e-05]
13: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 67364 (54050)	Loss/tok 3.5543 (3.1156)	Learning Rate [7.8125e-05]
11: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 67351 (53834)	Loss/tok 3.0991 (3.1162)	Learning Rate [7.8125e-05]
10: TRAIN [2][1990/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 67339 (53751)	Loss/tok 2.9969 (3.1044)	Learning Rate [7.8125e-05]
0: TRAIN [2][2000/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00097)	Tok/s 49118 (52920)	Loss/tok 2.9881 (3.1195)	Learning Rate [7.8125e-05]
1: TRAIN [2][2000/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00100)	Tok/s 49011 (53019)	Loss/tok 2.8307 (3.1130)	Learning Rate [7.8125e-05]
15: TRAIN [2][2000/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00092)	Tok/s 49088 (54323)	Loss/tok 2.9738 (3.1149)	Learning Rate [7.8125e-05]
2: TRAIN [2][2000/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00098)	Tok/s 48897 (53134)	Loss/tok 2.8601 (3.1133)	Learning Rate [7.8125e-05]
14: TRAIN [2][2000/3416]	Time 0.044 (0.058)	Data 0.00083 (0.00091)	Tok/s 49114 (54205)	Loss/tok 3.0903 (3.1150)	Learning Rate [7.8125e-05]
3: TRAIN [2][2000/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00092)	Tok/s 48895 (53238)	Loss/tok 3.1169 (3.1153)	Learning Rate [7.8125e-05]
13: TRAIN [2][2000/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00096)	Tok/s 49110 (54102)	Loss/tok 3.1589 (3.1157)	Learning Rate [7.8125e-05]
4: TRAIN [2][2000/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00098)	Tok/s 48919 (53334)	Loss/tok 3.0580 (3.1160)	Learning Rate [7.8125e-05]
12: TRAIN [2][2000/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00101)	Tok/s 49115 (54009)	Loss/tok 3.3368 (3.1182)	Learning Rate [7.8125e-05]
11: TRAIN [2][2000/3416]	Time 0.044 (0.058)	Data 0.00085 (0.00092)	Tok/s 49076 (53886)	Loss/tok 2.9443 (3.1163)	Learning Rate [7.8125e-05]
5: TRAIN [2][2000/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00093)	Tok/s 48858 (53419)	Loss/tok 3.1711 (3.1128)	Learning Rate [7.8125e-05]
6: TRAIN [2][2000/3416]	Time 0.045 (0.058)	Data 0.00080 (0.00092)	Tok/s 48809 (53490)	Loss/tok 2.9562 (3.1187)	Learning Rate [7.8125e-05]
10: TRAIN [2][2000/3416]	Time 0.044 (0.058)	Data 0.00108 (0.00096)	Tok/s 50009 (53803)	Loss/tok 3.1132 (3.1047)	Learning Rate [7.8125e-05]
9: TRAIN [2][2000/3416]	Time 0.044 (0.058)	Data 0.00079 (0.00092)	Tok/s 49013 (53725)	Loss/tok 2.9307 (3.1119)	Learning Rate [7.8125e-05]
8: TRAIN [2][2000/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00098)	Tok/s 48921 (53653)	Loss/tok 2.9904 (3.1154)	Learning Rate [7.8125e-05]
7: TRAIN [2][2000/3416]	Time 0.044 (0.058)	Data 0.00120 (0.00097)	Tok/s 49792 (53577)	Loss/tok 2.9368 (3.1155)	Learning Rate [7.8125e-05]
9: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00092)	Tok/s 52879 (53714)	Loss/tok 2.8691 (3.1117)	Learning Rate [7.8125e-05]
8: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00098)	Tok/s 52769 (53642)	Loss/tok 3.0343 (3.1150)	Learning Rate [7.8125e-05]
6: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00092)	Tok/s 52849 (53479)	Loss/tok 3.1210 (3.1191)	Learning Rate [7.8125e-05]
10: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00101 (0.00096)	Tok/s 52854 (53791)	Loss/tok 2.9928 (3.1050)	Learning Rate [7.8125e-05]
11: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00103 (0.00092)	Tok/s 52915 (53875)	Loss/tok 3.0681 (3.1163)	Learning Rate [7.8125e-05]
7: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00105 (0.00097)	Tok/s 52783 (53567)	Loss/tok 3.0795 (3.1153)	Learning Rate [7.8125e-05]
5: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00111 (0.00093)	Tok/s 52813 (53409)	Loss/tok 2.8970 (3.1126)	Learning Rate [7.8125e-05]
12: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00101)	Tok/s 53828 (53998)	Loss/tok 3.3131 (3.1185)	Learning Rate [7.8125e-05]
4: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00108 (0.00098)	Tok/s 52699 (53324)	Loss/tok 3.0598 (3.1158)	Learning Rate [7.8125e-05]
13: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00096)	Tok/s 54075 (54092)	Loss/tok 3.0622 (3.1154)	Learning Rate [7.8125e-05]
3: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00104 (0.00092)	Tok/s 52818 (53227)	Loss/tok 3.0918 (3.1153)	Learning Rate [7.8125e-05]
2: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00105 (0.00098)	Tok/s 52777 (53123)	Loss/tok 3.0800 (3.1133)	Learning Rate [7.8125e-05]
15: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00104 (0.00092)	Tok/s 54121 (54312)	Loss/tok 2.8797 (3.1142)	Learning Rate [7.8125e-05]
14: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00109 (0.00091)	Tok/s 54092 (54193)	Loss/tok 3.1336 (3.1144)	Learning Rate [7.8125e-05]
1: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00108 (0.00100)	Tok/s 52882 (53009)	Loss/tok 3.2453 (3.1129)	Learning Rate [7.8125e-05]
0: TRAIN [2][2010/3416]	Time 0.053 (0.058)	Data 0.00111 (0.00097)	Tok/s 52860 (52910)	Loss/tok 2.9164 (3.1194)	Learning Rate [7.8125e-05]
13: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00096)	Tok/s 52401 (54104)	Loss/tok 2.8232 (3.1154)	Learning Rate [7.8125e-05]
12: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00101)	Tok/s 52448 (54009)	Loss/tok 2.9822 (3.1184)	Learning Rate [7.8125e-05]
11: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00092)	Tok/s 52417 (53887)	Loss/tok 2.9380 (3.1164)	Learning Rate [7.8125e-05]
14: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00091)	Tok/s 52203 (54206)	Loss/tok 2.8843 (3.1145)	Learning Rate [7.8125e-05]
1: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00100)	Tok/s 51907 (53022)	Loss/tok 3.0980 (3.1135)	Learning Rate [7.8125e-05]
15: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 52095 (54325)	Loss/tok 3.0922 (3.1144)	Learning Rate [7.8125e-05]
3: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00092)	Tok/s 51965 (53240)	Loss/tok 2.9651 (3.1158)	Learning Rate [7.8125e-05]
0: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00097)	Tok/s 52013 (52924)	Loss/tok 3.1853 (3.1195)	Learning Rate [7.8125e-05]
5: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00093)	Tok/s 51976 (53421)	Loss/tok 2.9070 (3.1126)	Learning Rate [7.8125e-05]
4: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00098)	Tok/s 51868 (53336)	Loss/tok 2.9515 (3.1158)	Learning Rate [7.8125e-05]
9: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00079 (0.00092)	Tok/s 52238 (53725)	Loss/tok 3.0120 (3.1117)	Learning Rate [7.8125e-05]
6: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00092)	Tok/s 52074 (53491)	Loss/tok 3.1870 (3.1191)	Learning Rate [7.8125e-05]
2: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00098)	Tok/s 51885 (53136)	Loss/tok 3.4242 (3.1137)	Learning Rate [7.8125e-05]
10: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00096)	Tok/s 52176 (53802)	Loss/tok 3.0774 (3.1052)	Learning Rate [7.8125e-05]
8: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00098)	Tok/s 52165 (53653)	Loss/tok 3.0647 (3.1150)	Learning Rate [7.8125e-05]
7: TRAIN [2][2020/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00097)	Tok/s 51931 (53578)	Loss/tok 3.0929 (3.1152)	Learning Rate [7.8125e-05]
5: TRAIN [2][2030/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00093)	Tok/s 50291 (53427)	Loss/tok 2.9260 (3.1123)	Learning Rate [7.8125e-05]
6: TRAIN [2][2030/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00092)	Tok/s 50334 (53497)	Loss/tok 2.9924 (3.1191)	Learning Rate [7.8125e-05]
4: TRAIN [2][2030/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00098)	Tok/s 50055 (53342)	Loss/tok 3.1167 (3.1159)	Learning Rate [7.8125e-05]
3: TRAIN [2][2030/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00092)	Tok/s 49977 (53246)	Loss/tok 3.1098 (3.1163)	Learning Rate [7.8125e-05]
2: TRAIN [2][2030/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00098)	Tok/s 49971 (53141)	Loss/tok 3.2760 (3.1136)	Learning Rate [7.8125e-05]
7: TRAIN [2][2030/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00097)	Tok/s 50330 (53585)	Loss/tok 3.0319 (3.1155)	Learning Rate [7.8125e-05]
8: TRAIN [2][2030/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00098)	Tok/s 50332 (53659)	Loss/tok 2.9913 (3.1149)	Learning Rate [7.8125e-05]
10: TRAIN [2][2030/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00096)	Tok/s 50436 (53808)	Loss/tok 3.2144 (3.1056)	Learning Rate [7.8125e-05]
9: TRAIN [2][2030/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00091)	Tok/s 50347 (53730)	Loss/tok 2.9561 (3.1119)	Learning Rate [7.8125e-05]
1: TRAIN [2][2030/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00100)	Tok/s 49950 (53028)	Loss/tok 3.0265 (3.1136)	Learning Rate [7.8125e-05]
0: TRAIN [2][2030/3416]	Time 0.049 (0.058)	Data 0.00110 (0.00097)	Tok/s 49949 (52930)	Loss/tok 2.7471 (3.1194)	Learning Rate [7.8125e-05]
12: TRAIN [2][2030/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00101)	Tok/s 50237 (54013)	Loss/tok 3.0419 (3.1184)	Learning Rate [7.8125e-05]
15: TRAIN [2][2030/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00092)	Tok/s 51289 (54329)	Loss/tok 3.0631 (3.1143)	Learning Rate [7.8125e-05]
11: TRAIN [2][2030/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00092)	Tok/s 50188 (53891)	Loss/tok 3.1777 (3.1165)	Learning Rate [7.8125e-05]
13: TRAIN [2][2030/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00096)	Tok/s 49898 (54107)	Loss/tok 2.9085 (3.1153)	Learning Rate [7.8125e-05]
14: TRAIN [2][2030/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00091)	Tok/s 50980 (54210)	Loss/tok 3.0078 (3.1149)	Learning Rate [7.8125e-05]
2: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00098)	Tok/s 51061 (53132)	Loss/tok 2.9713 (3.1134)	Learning Rate [7.8125e-05]
1: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00100)	Tok/s 51132 (53018)	Loss/tok 3.0065 (3.1136)	Learning Rate [7.8125e-05]
4: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00098)	Tok/s 50861 (53335)	Loss/tok 3.0387 (3.1155)	Learning Rate [7.8125e-05]
3: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00092)	Tok/s 50921 (53238)	Loss/tok 2.9372 (3.1161)	Learning Rate [7.8125e-05]
9: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00091)	Tok/s 50995 (53726)	Loss/tok 2.7507 (3.1115)	Learning Rate [7.8125e-05]
0: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00097)	Tok/s 51115 (52918)	Loss/tok 2.8352 (3.1191)	Learning Rate [7.8125e-05]
8: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00098)	Tok/s 50936 (53654)	Loss/tok 2.9873 (3.1147)	Learning Rate [7.8125e-05]
5: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00093)	Tok/s 50773 (53420)	Loss/tok 3.2247 (3.1121)	Learning Rate [7.8125e-05]
6: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00092)	Tok/s 50739 (53491)	Loss/tok 3.0789 (3.1188)	Learning Rate [7.8125e-05]
10: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00096)	Tok/s 51105 (53803)	Loss/tok 2.9491 (3.1053)	Learning Rate [7.8125e-05]
15: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00092)	Tok/s 52569 (54324)	Loss/tok 2.7035 (3.1138)	Learning Rate [7.8125e-05]
7: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00097)	Tok/s 50837 (53579)	Loss/tok 2.9106 (3.1152)	Learning Rate [7.8125e-05]
11: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00092)	Tok/s 51047 (53886)	Loss/tok 2.9244 (3.1164)	Learning Rate [7.8125e-05]
14: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00091)	Tok/s 52498 (54206)	Loss/tok 3.0752 (3.1148)	Learning Rate [7.8125e-05]
12: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00101)	Tok/s 51750 (54008)	Loss/tok 2.9433 (3.1181)	Learning Rate [7.8125e-05]
13: TRAIN [2][2040/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00096)	Tok/s 52510 (54103)	Loss/tok 3.0351 (3.1153)	Learning Rate [7.8125e-05]
0: TRAIN [2][2050/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00097)	Tok/s 51877 (52961)	Loss/tok 3.2337 (3.1192)	Learning Rate [7.8125e-05]
1: TRAIN [2][2050/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00100)	Tok/s 51831 (53061)	Loss/tok 3.1210 (3.1136)	Learning Rate [7.8125e-05]
2: TRAIN [2][2050/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00098)	Tok/s 51812 (53175)	Loss/tok 3.2434 (3.1135)	Learning Rate [7.8125e-05]
15: TRAIN [2][2050/3416]	Time 0.060 (0.058)	Data 0.00104 (0.00092)	Tok/s 51851 (54367)	Loss/tok 3.0124 (3.1138)	Learning Rate [7.8125e-05]
14: TRAIN [2][2050/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00091)	Tok/s 51852 (54248)	Loss/tok 3.0702 (3.1142)	Learning Rate [7.8125e-05]
3: TRAIN [2][2050/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00092)	Tok/s 51803 (53280)	Loss/tok 2.8662 (3.1162)	Learning Rate [7.8125e-05]
13: TRAIN [2][2050/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00096)	Tok/s 51832 (54145)	Loss/tok 2.9868 (3.1154)	Learning Rate [7.8125e-05]
4: TRAIN [2][2050/3416]	Time 0.061 (0.058)	Data 0.00102 (0.00098)	Tok/s 51774 (53377)	Loss/tok 3.1795 (3.1155)	Learning Rate [7.8125e-05]
11: TRAIN [2][2050/3416]	Time 0.061 (0.058)	Data 0.00098 (0.00092)	Tok/s 51776 (53929)	Loss/tok 3.1790 (3.1166)	Learning Rate [7.8125e-05]
5: TRAIN [2][2050/3416]	Time 0.061 (0.058)	Data 0.00098 (0.00093)	Tok/s 51735 (53462)	Loss/tok 2.9558 (3.1115)	Learning Rate [7.8125e-05]
6: TRAIN [2][2050/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00092)	Tok/s 51656 (53533)	Loss/tok 2.9508 (3.1183)	Learning Rate [7.8125e-05]
9: TRAIN [2][2050/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00091)	Tok/s 51623 (53767)	Loss/tok 3.0697 (3.1112)	Learning Rate [7.8125e-05]
10: TRAIN [2][2050/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00096)	Tok/s 51664 (53845)	Loss/tok 3.3944 (3.1054)	Learning Rate [7.8125e-05]
7: TRAIN [2][2050/3416]	Time 0.061 (0.058)	Data 0.00106 (0.00097)	Tok/s 51555 (53621)	Loss/tok 3.3428 (3.1153)	Learning Rate [7.8125e-05]
12: TRAIN [2][2050/3416]	Time 0.060 (0.058)	Data 0.00117 (0.00101)	Tok/s 51869 (54051)	Loss/tok 3.2404 (3.1182)	Learning Rate [7.8125e-05]
8: TRAIN [2][2050/3416]	Time 0.061 (0.058)	Data 0.00107 (0.00098)	Tok/s 51599 (53696)	Loss/tok 3.0808 (3.1145)	Learning Rate [7.8125e-05]
10: TRAIN [2][2060/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00096)	Tok/s 40142 (53832)	Loss/tok 2.8893 (3.1052)	Learning Rate [7.8125e-05]
9: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00091)	Tok/s 39990 (53755)	Loss/tok 2.7226 (3.1109)	Learning Rate [7.8125e-05]
8: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00098)	Tok/s 39986 (53684)	Loss/tok 3.0462 (3.1145)	Learning Rate [7.8125e-05]
11: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00092)	Tok/s 40387 (53917)	Loss/tok 2.9864 (3.1168)	Learning Rate [7.8125e-05]
12: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00101)	Tok/s 41216 (54040)	Loss/tok 3.0599 (3.1180)	Learning Rate [7.8125e-05]
7: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00097)	Tok/s 39973 (53609)	Loss/tok 2.7357 (3.1150)	Learning Rate [7.8125e-05]
6: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 39834 (53522)	Loss/tok 2.9779 (3.1181)	Learning Rate [7.8125e-05]
13: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00096)	Tok/s 41154 (54134)	Loss/tok 2.7682 (3.1151)	Learning Rate [7.8125e-05]
5: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00093)	Tok/s 39781 (53450)	Loss/tok 2.8933 (3.1113)	Learning Rate [7.8125e-05]
4: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00098)	Tok/s 39703 (53365)	Loss/tok 2.7730 (3.1152)	Learning Rate [7.8125e-05]
14: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00091)	Tok/s 41056 (54236)	Loss/tok 2.9986 (3.1143)	Learning Rate [7.8125e-05]
15: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00092)	Tok/s 40974 (54354)	Loss/tok 3.0569 (3.1137)	Learning Rate [7.8125e-05]
0: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00097)	Tok/s 39574 (52952)	Loss/tok 2.9730 (3.1189)	Learning Rate [7.8125e-05]
3: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00092)	Tok/s 39624 (53269)	Loss/tok 3.2242 (3.1160)	Learning Rate [7.8125e-05]
1: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00100)	Tok/s 39537 (53050)	Loss/tok 2.8479 (3.1132)	Learning Rate [7.8125e-05]
2: TRAIN [2][2060/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00098)	Tok/s 39525 (53164)	Loss/tok 3.0618 (3.1137)	Learning Rate [7.8125e-05]
9: TRAIN [2][2070/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00091)	Tok/s 57636 (53756)	Loss/tok 3.3296 (3.1104)	Learning Rate [7.8125e-05]
8: TRAIN [2][2070/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00098)	Tok/s 57562 (53686)	Loss/tok 3.0552 (3.1138)	Learning Rate [7.8125e-05]
6: TRAIN [2][2070/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 57395 (53522)	Loss/tok 3.3483 (3.1178)	Learning Rate [7.8125e-05]
10: TRAIN [2][2070/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 57579 (53834)	Loss/tok 3.5621 (3.1053)	Learning Rate [7.8125e-05]
11: TRAIN [2][2070/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 57492 (53919)	Loss/tok 3.2146 (3.1163)	Learning Rate [7.8125e-05]
7: TRAIN [2][2070/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 57530 (53610)	Loss/tok 3.4539 (3.1146)	Learning Rate [7.8125e-05]
12: TRAIN [2][2070/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00101)	Tok/s 57387 (54042)	Loss/tok 3.1245 (3.1176)	Learning Rate [7.8125e-05]
5: TRAIN [2][2070/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 57309 (53449)	Loss/tok 3.2089 (3.1110)	Learning Rate [7.8125e-05]
13: TRAIN [2][2070/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 57325 (54137)	Loss/tok 3.0572 (3.1146)	Learning Rate [7.8125e-05]
4: TRAIN [2][2070/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00098)	Tok/s 57098 (53364)	Loss/tok 3.2177 (3.1150)	Learning Rate [7.8125e-05]
14: TRAIN [2][2070/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 57224 (54240)	Loss/tok 3.2933 (3.1138)	Learning Rate [7.8125e-05]
3: TRAIN [2][2070/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 57074 (53266)	Loss/tok 3.2082 (3.1155)	Learning Rate [7.8125e-05]
15: TRAIN [2][2070/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 58011 (54359)	Loss/tok 3.1891 (3.1132)	Learning Rate [7.8125e-05]
2: TRAIN [2][2070/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 56970 (53162)	Loss/tok 3.0762 (3.1132)	Learning Rate [7.8125e-05]
1: TRAIN [2][2070/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 57048 (53047)	Loss/tok 3.5347 (3.1129)	Learning Rate [7.8125e-05]
0: TRAIN [2][2070/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 57059 (52946)	Loss/tok 3.2451 (3.1185)	Learning Rate [7.8125e-05]
2: TRAIN [2][2080/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00098)	Tok/s 61542 (53159)	Loss/tok 3.2501 (3.1133)	Learning Rate [7.8125e-05]
1: TRAIN [2][2080/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00100)	Tok/s 60865 (53045)	Loss/tok 3.3107 (3.1137)	Learning Rate [7.8125e-05]
3: TRAIN [2][2080/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 61913 (53264)	Loss/tok 3.3013 (3.1160)	Learning Rate [7.8125e-05]
0: TRAIN [2][2080/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00097)	Tok/s 60748 (52944)	Loss/tok 3.1807 (3.1187)	Learning Rate [7.8125e-05]
4: TRAIN [2][2080/3416]	Time 0.068 (0.058)	Data 0.00107 (0.00098)	Tok/s 61859 (53361)	Loss/tok 3.0795 (3.1152)	Learning Rate [7.8125e-05]
6: TRAIN [2][2080/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 61750 (53518)	Loss/tok 3.2917 (3.1181)	Learning Rate [7.8125e-05]
15: TRAIN [2][2080/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00092)	Tok/s 61566 (54354)	Loss/tok 3.2681 (3.1135)	Learning Rate [7.8125e-05]
5: TRAIN [2][2080/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00093)	Tok/s 61760 (53446)	Loss/tok 3.3153 (3.1109)	Learning Rate [7.8125e-05]
12: TRAIN [2][2080/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00101)	Tok/s 61509 (54038)	Loss/tok 3.4099 (3.1183)	Learning Rate [7.8125e-05]
8: TRAIN [2][2080/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 61516 (53683)	Loss/tok 3.2623 (3.1138)	Learning Rate [7.8125e-05]
14: TRAIN [2][2080/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 61479 (54236)	Loss/tok 3.3889 (3.1146)	Learning Rate [7.8125e-05]
13: TRAIN [2][2080/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 61385 (54133)	Loss/tok 3.2706 (3.1147)	Learning Rate [7.8125e-05]
7: TRAIN [2][2080/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00097)	Tok/s 61538 (53607)	Loss/tok 3.3610 (3.1148)	Learning Rate [7.8125e-05]
9: TRAIN [2][2080/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 61439 (53753)	Loss/tok 2.9449 (3.1105)	Learning Rate [7.8125e-05]
11: TRAIN [2][2080/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 61385 (53915)	Loss/tok 3.2478 (3.1165)	Learning Rate [7.8125e-05]
10: TRAIN [2][2080/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 61371 (53830)	Loss/tok 3.4590 (3.1056)	Learning Rate [7.8125e-05]
11: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
3: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00092)	Tok/s 54891 (53258)	Loss/tok 3.0805 (3.1160)	Learning Rate [7.8125e-05]
2: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 54819 (53154)	Loss/tok 3.1886 (3.1134)	Learning Rate [7.8125e-05]
4: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00098)	Tok/s 54890 (53355)	Loss/tok 3.2782 (3.1150)	Learning Rate [7.8125e-05]
1: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00115 (0.00100)	Tok/s 54793 (53039)	Loss/tok 3.4012 (3.1135)	Learning Rate [7.8125e-05]
6: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 54767 (53512)	Loss/tok 3.2013 (3.1182)	Learning Rate [7.8125e-05]
15: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 54678 (54347)	Loss/tok 2.9816 (3.1134)	Learning Rate [7.8125e-05]
5: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 54855 (53440)	Loss/tok 3.1243 (3.1112)	Learning Rate [7.8125e-05]
0: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 54719 (52938)	Loss/tok 3.2309 (3.1185)	Learning Rate [7.8125e-05]
7: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00097)	Tok/s 54717 (53600)	Loss/tok 3.3331 (3.1149)	Learning Rate [7.8125e-05]
8: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 54609 (53676)	Loss/tok 3.2146 (3.1142)	Learning Rate [7.8125e-05]
14: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00091)	Tok/s 54563 (54229)	Loss/tok 3.2171 (3.1150)	Learning Rate [7.8125e-05]
13: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 54499 (54125)	Loss/tok 3.3518 (3.1149)	Learning Rate [7.8125e-05]
10: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00096)	Tok/s 54429 (53823)	Loss/tok 3.2453 (3.1060)	Learning Rate [7.8125e-05]
9: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00091)	Tok/s 54508 (53746)	Loss/tok 3.2292 (3.1107)	Learning Rate [7.8125e-05]
11: TRAIN [2][2090/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 54331 (53908)	Loss/tok 2.9947 (3.1160)	Learning Rate [7.8125e-05]
12: TRAIN [2][2090/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00100)	Tok/s 54434 (54031)	Loss/tok 3.2162 (3.1181)	Learning Rate [7.8125e-05]
11: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 62469 (53904)	Loss/tok 3.0122 (3.1159)	Learning Rate [7.8125e-05]
12: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00100)	Tok/s 62496 (54027)	Loss/tok 3.2990 (3.1182)	Learning Rate [7.8125e-05]
9: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00091)	Tok/s 62484 (53743)	Loss/tok 3.1112 (3.1108)	Learning Rate [7.8125e-05]
13: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 62655 (54122)	Loss/tok 3.1459 (3.1150)	Learning Rate [7.8125e-05]
14: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00091)	Tok/s 63446 (54225)	Loss/tok 3.2612 (3.1150)	Learning Rate [7.8125e-05]
10: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00096)	Tok/s 62429 (53820)	Loss/tok 3.0716 (3.1060)	Learning Rate [7.8125e-05]
15: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 63457 (54343)	Loss/tok 3.2791 (3.1135)	Learning Rate [7.8125e-05]
8: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 62444 (53673)	Loss/tok 3.3104 (3.1140)	Learning Rate [7.8125e-05]
0: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 62473 (52937)	Loss/tok 3.1328 (3.1183)	Learning Rate [7.8125e-05]
6: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 62466 (53510)	Loss/tok 3.4334 (3.1183)	Learning Rate [7.8125e-05]
7: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00097)	Tok/s 62411 (53598)	Loss/tok 3.1199 (3.1147)	Learning Rate [7.8125e-05]
1: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00100)	Tok/s 62470 (53038)	Loss/tok 3.1957 (3.1140)	Learning Rate [7.8125e-05]
2: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 62425 (53153)	Loss/tok 3.2063 (3.1135)	Learning Rate [7.8125e-05]
5: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00093)	Tok/s 62457 (53438)	Loss/tok 3.0628 (3.1114)	Learning Rate [7.8125e-05]
4: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00098)	Tok/s 62461 (53354)	Loss/tok 3.1775 (3.1149)	Learning Rate [7.8125e-05]
3: TRAIN [2][2100/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 62464 (53257)	Loss/tok 3.1718 (3.1160)	Learning Rate [7.8125e-05]
6: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 62572 (53528)	Loss/tok 3.1783 (3.1181)	Learning Rate [7.8125e-05]
5: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00093)	Tok/s 62589 (53456)	Loss/tok 3.3576 (3.1115)	Learning Rate [7.8125e-05]
4: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 62567 (53372)	Loss/tok 3.2263 (3.1149)	Learning Rate [7.8125e-05]
8: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 62242 (53691)	Loss/tok 3.2443 (3.1139)	Learning Rate [7.8125e-05]
7: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00097)	Tok/s 62388 (53615)	Loss/tok 3.6419 (3.1152)	Learning Rate [7.8125e-05]
3: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 62541 (53275)	Loss/tok 3.2630 (3.1159)	Learning Rate [7.8125e-05]
9: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00091)	Tok/s 62154 (53760)	Loss/tok 3.3064 (3.1109)	Learning Rate [7.8125e-05]
2: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00098)	Tok/s 62520 (53171)	Loss/tok 3.1808 (3.1137)	Learning Rate [7.8125e-05]
1: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00099)	Tok/s 62487 (53057)	Loss/tok 3.1966 (3.1138)	Learning Rate [7.8125e-05]
10: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 62214 (53837)	Loss/tok 3.3197 (3.1064)	Learning Rate [7.8125e-05]
11: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 62259 (53922)	Loss/tok 3.2008 (3.1158)	Learning Rate [7.8125e-05]
0: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 62450 (52956)	Loss/tok 3.2801 (3.1184)	Learning Rate [7.8125e-05]
15: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 63303 (54360)	Loss/tok 3.3662 (3.1137)	Learning Rate [7.8125e-05]
12: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00100)	Tok/s 62170 (54044)	Loss/tok 3.0731 (3.1183)	Learning Rate [7.8125e-05]
14: TRAIN [2][2110/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00091)	Tok/s 62893 (54241)	Loss/tok 3.4787 (3.1153)	Learning Rate [7.8125e-05]
13: TRAIN [2][2110/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 61526 (54138)	Loss/tok 3.2553 (3.1153)	Learning Rate [7.8125e-05]
2: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 57735 (53191)	Loss/tok 3.1968 (3.1143)	Learning Rate [7.8125e-05]
0: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 57592 (52977)	Loss/tok 3.3245 (3.1184)	Learning Rate [7.8125e-05]
3: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00092)	Tok/s 57733 (53294)	Loss/tok 3.4395 (3.1166)	Learning Rate [7.8125e-05]
4: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00098)	Tok/s 57782 (53391)	Loss/tok 3.1596 (3.1150)	Learning Rate [7.8125e-05]
15: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 58444 (54377)	Loss/tok 3.2361 (3.1147)	Learning Rate [7.8125e-05]
1: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00099)	Tok/s 57649 (53077)	Loss/tok 3.2400 (3.1140)	Learning Rate [7.8125e-05]
5: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 58742 (53475)	Loss/tok 3.3618 (3.1119)	Learning Rate [7.8125e-05]
14: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00091)	Tok/s 58428 (54259)	Loss/tok 3.0554 (3.1156)	Learning Rate [7.8125e-05]
6: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 58702 (53547)	Loss/tok 3.1260 (3.1188)	Learning Rate [7.8125e-05]
13: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 58413 (54156)	Loss/tok 2.9649 (3.1151)	Learning Rate [7.8125e-05]
7: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 58676 (53635)	Loss/tok 3.4039 (3.1158)	Learning Rate [7.8125e-05]
8: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 58572 (53710)	Loss/tok 2.9951 (3.1143)	Learning Rate [7.8125e-05]
11: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 58471 (53940)	Loss/tok 3.2428 (3.1164)	Learning Rate [7.8125e-05]
12: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00100)	Tok/s 58407 (54062)	Loss/tok 3.3448 (3.1185)	Learning Rate [7.8125e-05]
9: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00091)	Tok/s 58514 (53779)	Loss/tok 3.1854 (3.1114)	Learning Rate [7.8125e-05]
10: TRAIN [2][2120/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00096)	Tok/s 58430 (53855)	Loss/tok 3.2937 (3.1069)	Learning Rate [7.8125e-05]
4: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00121 (0.00098)	Tok/s 20019 (53359)	Loss/tok 2.0395 (3.1150)	Learning Rate [7.8125e-05]
3: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00097 (0.00092)	Tok/s 17446 (53261)	Loss/tok 1.5595 (3.1166)	Learning Rate [7.8125e-05]
2: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00101 (0.00098)	Tok/s 16308 (53157)	Loss/tok 1.7992 (3.1142)	Learning Rate [7.8125e-05]
1: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00105 (0.00099)	Tok/s 12797 (53042)	Loss/tok 1.8125 (3.1139)	Learning Rate [7.8125e-05]
5: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00116 (0.00093)	Tok/s 21306 (53444)	Loss/tok 2.0170 (3.1118)	Learning Rate [7.8125e-05]
6: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00101 (0.00092)	Tok/s 23103 (53515)	Loss/tok 2.1389 (3.1187)	Learning Rate [7.8125e-05]
9: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00101 (0.00091)	Tok/s 25197 (53750)	Loss/tok 1.8582 (3.1111)	Learning Rate [7.8125e-05]
0: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00100 (0.00097)	Tok/s 9583 (52940)	Loss/tok 1.5342 (3.1182)	Learning Rate [7.8125e-05]
15: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00100 (0.00092)	Tok/s 28740 (54348)	Loss/tok 2.0652 (3.1143)	Learning Rate [7.8125e-05]
10: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00097 (0.00096)	Tok/s 25152 (53826)	Loss/tok 2.1335 (3.1066)	Learning Rate [7.8125e-05]
8: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00103 (0.00097)	Tok/s 25178 (53681)	Loss/tok 1.8137 (3.1143)	Learning Rate [7.8125e-05]
7: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00115 (0.00097)	Tok/s 23784 (53604)	Loss/tok 2.1057 (3.1155)	Learning Rate [7.8125e-05]
13: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00091 (0.00096)	Tok/s 26887 (54126)	Loss/tok 2.3702 (3.1150)	Learning Rate [7.8125e-05]
14: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00099 (0.00091)	Tok/s 28088 (54230)	Loss/tok 2.3139 (3.1155)	Learning Rate [7.8125e-05]
11: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00107 (0.00092)	Tok/s 25609 (53910)	Loss/tok 2.1044 (3.1160)	Learning Rate [7.8125e-05]
12: TRAIN [2][2130/3416]	Time 0.033 (0.058)	Data 0.00102 (0.00100)	Tok/s 26916 (54032)	Loss/tok 2.3040 (3.1185)	Learning Rate [7.8125e-05]
6: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00092)	Tok/s 42855 (53524)	Loss/tok 2.9147 (3.1187)	Learning Rate [7.8125e-05]
5: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00093)	Tok/s 42690 (53451)	Loss/tok 2.8517 (3.1116)	Learning Rate [7.8125e-05]
7: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00097)	Tok/s 42822 (53612)	Loss/tok 3.0653 (3.1158)	Learning Rate [7.8125e-05]
4: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00116 (0.00098)	Tok/s 42653 (53366)	Loss/tok 3.0406 (3.1151)	Learning Rate [7.8125e-05]
8: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00097)	Tok/s 42812 (53688)	Loss/tok 2.9122 (3.1144)	Learning Rate [7.8125e-05]
3: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00092)	Tok/s 42676 (53269)	Loss/tok 2.9260 (3.1165)	Learning Rate [7.8125e-05]
9: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00091)	Tok/s 42806 (53757)	Loss/tok 3.0217 (3.1111)	Learning Rate [7.8125e-05]
2: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00098)	Tok/s 42715 (53165)	Loss/tok 2.8981 (3.1146)	Learning Rate [7.8125e-05]
11: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00092)	Tok/s 42876 (53918)	Loss/tok 2.8399 (3.1160)	Learning Rate [7.8125e-05]
1: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00159 (0.00099)	Tok/s 42710 (53050)	Loss/tok 3.0013 (3.1138)	Learning Rate [7.8125e-05]
10: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00096)	Tok/s 42713 (53833)	Loss/tok 2.5692 (3.1063)	Learning Rate [7.8125e-05]
0: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00097)	Tok/s 42713 (52949)	Loss/tok 3.0628 (3.1186)	Learning Rate [7.8125e-05]
15: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00092)	Tok/s 42694 (54355)	Loss/tok 3.0792 (3.1148)	Learning Rate [7.8125e-05]
12: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00100)	Tok/s 42710 (54040)	Loss/tok 2.9619 (3.1187)	Learning Rate [7.8125e-05]
14: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00091)	Tok/s 42711 (54237)	Loss/tok 2.9177 (3.1152)	Learning Rate [7.8125e-05]
13: TRAIN [2][2140/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00095)	Tok/s 42753 (54133)	Loss/tok 2.8121 (3.1149)	Learning Rate [7.8125e-05]
1: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00099)	Tok/s 55364 (53072)	Loss/tok 3.2826 (3.1137)	Learning Rate [7.8125e-05]
0: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00097)	Tok/s 55161 (52971)	Loss/tok 3.2304 (3.1184)	Learning Rate [7.8125e-05]
15: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00092)	Tok/s 56247 (54376)	Loss/tok 3.1122 (3.1143)	Learning Rate [7.8125e-05]
14: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00091)	Tok/s 56251 (54258)	Loss/tok 3.0540 (3.1152)	Learning Rate [7.8125e-05]
12: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00100 (0.00100)	Tok/s 56386 (54061)	Loss/tok 3.0301 (3.1185)	Learning Rate [7.8125e-05]
3: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00092)	Tok/s 55124 (53291)	Loss/tok 2.9945 (3.1168)	Learning Rate [7.8125e-05]
13: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00095)	Tok/s 56279 (54154)	Loss/tok 3.5276 (3.1147)	Learning Rate [7.8125e-05]
5: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00103 (0.00093)	Tok/s 55328 (53472)	Loss/tok 3.2354 (3.1113)	Learning Rate [7.8125e-05]
10: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00080 (0.00096)	Tok/s 56315 (53855)	Loss/tok 3.0726 (3.1062)	Learning Rate [7.8125e-05]
11: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00092)	Tok/s 56212 (53939)	Loss/tok 3.2940 (3.1162)	Learning Rate [7.8125e-05]
4: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00098)	Tok/s 55125 (53388)	Loss/tok 3.3057 (3.1152)	Learning Rate [7.8125e-05]
6: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00092)	Tok/s 56156 (53545)	Loss/tok 3.2339 (3.1185)	Learning Rate [7.8125e-05]
9: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00091)	Tok/s 56193 (53779)	Loss/tok 3.2239 (3.1111)	Learning Rate [7.8125e-05]
2: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00098)	Tok/s 55145 (53187)	Loss/tok 3.2252 (3.1146)	Learning Rate [7.8125e-05]
7: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00097)	Tok/s 56217 (53633)	Loss/tok 3.0900 (3.1156)	Learning Rate [7.8125e-05]
8: TRAIN [2][2150/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00098)	Tok/s 56192 (53709)	Loss/tok 3.0241 (3.1147)	Learning Rate [7.8125e-05]
3: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00092)	Tok/s 49010 (53282)	Loss/tok 2.9045 (3.1165)	Learning Rate [7.8125e-05]
4: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00098)	Tok/s 48964 (53379)	Loss/tok 2.9176 (3.1150)	Learning Rate [7.8125e-05]
6: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00092)	Tok/s 49043 (53536)	Loss/tok 2.9538 (3.1185)	Learning Rate [7.8125e-05]
5: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00093)	Tok/s 48993 (53464)	Loss/tok 2.9811 (3.1111)	Learning Rate [7.8125e-05]
1: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00100)	Tok/s 48938 (53064)	Loss/tok 2.9418 (3.1139)	Learning Rate [7.8125e-05]
15: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00092)	Tok/s 48996 (54365)	Loss/tok 3.0615 (3.1144)	Learning Rate [7.8125e-05]
7: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00097)	Tok/s 48876 (53624)	Loss/tok 3.1302 (3.1156)	Learning Rate [7.8125e-05]
14: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00091)	Tok/s 48974 (54248)	Loss/tok 2.9750 (3.1154)	Learning Rate [7.8125e-05]
8: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00097)	Tok/s 48793 (53699)	Loss/tok 2.9359 (3.1147)	Learning Rate [7.8125e-05]
9: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00091)	Tok/s 48764 (53769)	Loss/tok 2.9416 (3.1112)	Learning Rate [7.8125e-05]
11: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00092)	Tok/s 48856 (53929)	Loss/tok 2.9436 (3.1161)	Learning Rate [7.8125e-05]
13: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00231 (0.00096)	Tok/s 48915 (54144)	Loss/tok 2.6654 (3.1145)	Learning Rate [7.8125e-05]
12: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00100)	Tok/s 48887 (54050)	Loss/tok 2.8155 (3.1183)	Learning Rate [7.8125e-05]
10: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00096)	Tok/s 48799 (53844)	Loss/tok 3.0223 (3.1063)	Learning Rate [7.8125e-05]
2: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00109 (0.00098)	Tok/s 49007 (53178)	Loss/tok 3.0181 (3.1141)	Learning Rate [7.8125e-05]
0: TRAIN [2][2160/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00097)	Tok/s 49002 (52962)	Loss/tok 2.8286 (3.1184)	Learning Rate [7.8125e-05]
7: TRAIN [2][2170/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00097)	Tok/s 33787 (53610)	Loss/tok 2.7445 (3.1152)	Learning Rate [7.8125e-05]
8: TRAIN [2][2170/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00098)	Tok/s 33730 (53685)	Loss/tok 3.0394 (3.1145)	Learning Rate [7.8125e-05]
9: TRAIN [2][2170/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00091)	Tok/s 33627 (53755)	Loss/tok 2.9215 (3.1108)	Learning Rate [7.8125e-05]
6: TRAIN [2][2170/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00092)	Tok/s 33726 (53522)	Loss/tok 2.8631 (3.1184)	Learning Rate [7.8125e-05]
11: TRAIN [2][2170/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00092)	Tok/s 33711 (53915)	Loss/tok 2.8847 (3.1159)	Learning Rate [7.8125e-05]
5: TRAIN [2][2170/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00093)	Tok/s 34256 (53449)	Loss/tok 2.8807 (3.1112)	Learning Rate [7.8125e-05]
10: TRAIN [2][2170/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00096)	Tok/s 33506 (53831)	Loss/tok 2.6553 (3.1061)	Learning Rate [7.8125e-05]
3: TRAIN [2][2170/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 33672 (53268)	Loss/tok 2.7919 (3.1163)	Learning Rate [7.8125e-05]
4: TRAIN [2][2170/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00098)	Tok/s 33695 (53364)	Loss/tok 2.7535 (3.1148)	Learning Rate [7.8125e-05]
12: TRAIN [2][2170/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00100)	Tok/s 34671 (54037)	Loss/tok 2.7410 (3.1185)	Learning Rate [7.8125e-05]
14: TRAIN [2][2170/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00091)	Tok/s 35273 (54234)	Loss/tok 2.6994 (3.1151)	Learning Rate [7.8125e-05]
13: TRAIN [2][2170/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00096)	Tok/s 34675 (54130)	Loss/tok 2.7390 (3.1145)	Learning Rate [7.8125e-05]
15: TRAIN [2][2170/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00092)	Tok/s 34707 (54350)	Loss/tok 2.7991 (3.1145)	Learning Rate [7.8125e-05]
1: TRAIN [2][2170/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00100)	Tok/s 33521 (53050)	Loss/tok 2.7763 (3.1137)	Learning Rate [7.8125e-05]
2: TRAIN [2][2170/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00098)	Tok/s 33591 (53164)	Loss/tok 2.8637 (3.1139)	Learning Rate [7.8125e-05]
0: TRAIN [2][2170/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00097)	Tok/s 33475 (52949)	Loss/tok 2.7820 (3.1183)	Learning Rate [7.8125e-05]
7: Gradient norm: inf
8: Gradient norm: inf
6: Gradient norm: inf
7: Skipped batch, new scale: 2048.0
8: Skipped batch, new scale: 2048.0
9: Gradient norm: inf
5: Gradient norm: inf
6: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
4: Gradient norm: inf
10: Gradient norm: inf
3: Gradient norm: inf
4: Skipped batch, new scale: 2048.0
10: Skipped batch, new scale: 2048.0
11: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
2: Gradient norm: inf
11: Skipped batch, new scale: 2048.0
12: Gradient norm: inf
2: Skipped batch, new scale: 2048.0
12: Skipped batch, new scale: 2048.0
1: Gradient norm: inf
13: Gradient norm: inf
0: Gradient norm: inf
15: Gradient norm: inf
14: Gradient norm: inf
13: Skipped batch, new scale: 2048.0
1: Skipped batch, new scale: 2048.0
0: Skipped batch, new scale: 2048.0
15: Skipped batch, new scale: 2048.0
14: Skipped batch, new scale: 2048.0
4: TRAIN [2][2180/3416]	Time 0.059 (0.058)	Data 0.00112 (0.00098)	Tok/s 54011 (53406)	Loss/tok 3.1652 (3.1151)	Learning Rate [7.8125e-05]
3: TRAIN [2][2180/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00092)	Tok/s 53869 (53308)	Loss/tok 3.1584 (3.1166)	Learning Rate [7.8125e-05]
5: TRAIN [2][2180/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00093)	Tok/s 54038 (53490)	Loss/tok 3.0598 (3.1117)	Learning Rate [7.8125e-05]
6: TRAIN [2][2180/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00092)	Tok/s 54039 (53563)	Loss/tok 2.9127 (3.1181)	Learning Rate [7.8125e-05]
2: TRAIN [2][2180/3416]	Time 0.059 (0.058)	Data 0.00106 (0.00098)	Tok/s 52743 (53203)	Loss/tok 3.0248 (3.1137)	Learning Rate [7.8125e-05]
1: TRAIN [2][2180/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00100)	Tok/s 52660 (53090)	Loss/tok 3.2956 (3.1142)	Learning Rate [7.8125e-05]
0: TRAIN [2][2180/3416]	Time 0.060 (0.058)	Data 0.00106 (0.00097)	Tok/s 52543 (52990)	Loss/tok 2.9614 (3.1182)	Learning Rate [7.8125e-05]
7: TRAIN [2][2180/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00097)	Tok/s 54044 (53651)	Loss/tok 2.9811 (3.1153)	Learning Rate [7.8125e-05]
8: TRAIN [2][2180/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00098)	Tok/s 53991 (53726)	Loss/tok 3.0735 (3.1151)	Learning Rate [7.8125e-05]
9: TRAIN [2][2180/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00091)	Tok/s 53957 (53796)	Loss/tok 3.1380 (3.1111)	Learning Rate [7.8125e-05]
15: TRAIN [2][2180/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00092)	Tok/s 53643 (54391)	Loss/tok 3.1222 (3.1145)	Learning Rate [7.8125e-05]
14: TRAIN [2][2180/3416]	Time 0.060 (0.058)	Data 0.00100 (0.00091)	Tok/s 53614 (54275)	Loss/tok 3.2019 (3.1154)	Learning Rate [7.8125e-05]
13: TRAIN [2][2180/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00096)	Tok/s 53616 (54170)	Loss/tok 3.3568 (3.1149)	Learning Rate [7.8125e-05]
11: TRAIN [2][2180/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00092)	Tok/s 53711 (53955)	Loss/tok 3.1572 (3.1161)	Learning Rate [7.8125e-05]
10: TRAIN [2][2180/3416]	Time 0.059 (0.058)	Data 0.00109 (0.00096)	Tok/s 53831 (53871)	Loss/tok 3.0404 (3.1067)	Learning Rate [7.8125e-05]
12: TRAIN [2][2180/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00100)	Tok/s 53665 (54077)	Loss/tok 3.1569 (3.1185)	Learning Rate [7.8125e-05]
15: TRAIN [2][2190/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 71013 (54362)	Loss/tok 3.1055 (3.1143)	Learning Rate [7.8125e-05]
6: TRAIN [2][2190/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 70100 (53533)	Loss/tok 3.2135 (3.1183)	Learning Rate [7.8125e-05]
14: TRAIN [2][2190/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 70955 (54246)	Loss/tok 3.0928 (3.1152)	Learning Rate [7.8125e-05]
0: TRAIN [2][2190/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 69869 (52955)	Loss/tok 3.2378 (3.1183)	Learning Rate [7.8125e-05]
5: TRAIN [2][2190/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 70043 (53459)	Loss/tok 3.2673 (3.1114)	Learning Rate [7.8125e-05]
1: TRAIN [2][2190/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00100)	Tok/s 69819 (53056)	Loss/tok 3.0467 (3.1137)	Learning Rate [7.8125e-05]
13: TRAIN [2][2190/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00096)	Tok/s 70891 (54141)	Loss/tok 3.3574 (3.1148)	Learning Rate [7.8125e-05]
4: TRAIN [2][2190/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00098)	Tok/s 69983 (53374)	Loss/tok 3.4346 (3.1150)	Learning Rate [7.8125e-05]
3: TRAIN [2][2190/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00092)	Tok/s 69850 (53276)	Loss/tok 3.1873 (3.1167)	Learning Rate [7.8125e-05]
10: TRAIN [2][2190/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00096)	Tok/s 70002 (53841)	Loss/tok 3.2543 (3.1066)	Learning Rate [7.8125e-05]
12: TRAIN [2][2190/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00100)	Tok/s 70036 (54047)	Loss/tok 3.2029 (3.1184)	Learning Rate [7.8125e-05]
11: TRAIN [2][2190/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 69925 (53926)	Loss/tok 3.2288 (3.1158)	Learning Rate [7.8125e-05]
2: TRAIN [2][2190/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00098)	Tok/s 69862 (53171)	Loss/tok 3.2227 (3.1136)	Learning Rate [7.8125e-05]
7: TRAIN [2][2190/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 70043 (53621)	Loss/tok 3.1589 (3.1155)	Learning Rate [7.8125e-05]
9: TRAIN [2][2190/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00091)	Tok/s 69967 (53766)	Loss/tok 3.3073 (3.1110)	Learning Rate [7.8125e-05]
8: TRAIN [2][2190/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00098)	Tok/s 69987 (53697)	Loss/tok 3.1376 (3.1149)	Learning Rate [7.8125e-05]
15: TRAIN [2][2200/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00092)	Tok/s 66341 (54360)	Loss/tok 3.1507 (3.1144)	Learning Rate [7.8125e-05]
14: TRAIN [2][2200/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 66394 (54244)	Loss/tok 3.0190 (3.1153)	Learning Rate [7.8125e-05]
0: TRAIN [2][2200/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 65274 (52953)	Loss/tok 3.2023 (3.1184)	Learning Rate [7.8125e-05]
3: TRAIN [2][2200/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 65258 (53273)	Loss/tok 3.1506 (3.1169)	Learning Rate [7.8125e-05]
1: TRAIN [2][2200/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00100)	Tok/s 65232 (53054)	Loss/tok 3.0434 (3.1137)	Learning Rate [7.8125e-05]
2: TRAIN [2][2200/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00098)	Tok/s 65193 (53168)	Loss/tok 3.3110 (3.1138)	Learning Rate [7.8125e-05]
4: TRAIN [2][2200/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00098)	Tok/s 65162 (53372)	Loss/tok 3.0128 (3.1152)	Learning Rate [7.8125e-05]
13: TRAIN [2][2200/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 65452 (54139)	Loss/tok 3.2876 (3.1148)	Learning Rate [7.8125e-05]
12: TRAIN [2][2200/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00100)	Tok/s 65358 (54044)	Loss/tok 3.0445 (3.1185)	Learning Rate [7.8125e-05]
11: TRAIN [2][2200/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 65338 (53923)	Loss/tok 3.2907 (3.1161)	Learning Rate [7.8125e-05]
5: TRAIN [2][2200/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 65269 (53457)	Loss/tok 3.1880 (3.1120)	Learning Rate [7.8125e-05]
10: TRAIN [2][2200/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 65570 (53839)	Loss/tok 3.1325 (3.1066)	Learning Rate [7.8125e-05]
6: TRAIN [2][2200/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 65125 (53530)	Loss/tok 3.0367 (3.1185)	Learning Rate [7.8125e-05]
9: TRAIN [2][2200/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00091)	Tok/s 65352 (53763)	Loss/tok 3.2739 (3.1112)	Learning Rate [7.8125e-05]
7: TRAIN [2][2200/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 65287 (53619)	Loss/tok 3.0083 (3.1154)	Learning Rate [7.8125e-05]
8: TRAIN [2][2200/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00098)	Tok/s 65390 (53694)	Loss/tok 3.5084 (3.1155)	Learning Rate [7.8125e-05]
11: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00092)	Tok/s 52986 (53924)	Loss/tok 2.9873 (3.1159)	Learning Rate [7.8125e-05]
12: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00107 (0.00101)	Tok/s 52982 (54045)	Loss/tok 3.2959 (3.1185)	Learning Rate [7.8125e-05]
13: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00096)	Tok/s 52878 (54140)	Loss/tok 3.0401 (3.1150)	Learning Rate [7.8125e-05]
10: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00109 (0.00096)	Tok/s 53020 (53840)	Loss/tok 3.0976 (3.1066)	Learning Rate [7.8125e-05]
9: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00092)	Tok/s 52968 (53765)	Loss/tok 3.2592 (3.1111)	Learning Rate [7.8125e-05]
14: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00091)	Tok/s 52786 (54246)	Loss/tok 2.9711 (3.1152)	Learning Rate [7.8125e-05]
15: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00087 (0.00092)	Tok/s 52765 (54362)	Loss/tok 3.1987 (3.1140)	Learning Rate [7.8125e-05]
8: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00098)	Tok/s 52895 (53696)	Loss/tok 3.1503 (3.1154)	Learning Rate [7.8125e-05]
0: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00097)	Tok/s 51727 (52955)	Loss/tok 3.2442 (3.1184)	Learning Rate [7.8125e-05]
6: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00092)	Tok/s 52909 (53531)	Loss/tok 3.3447 (3.1184)	Learning Rate [7.8125e-05]
1: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00100)	Tok/s 52710 (53056)	Loss/tok 3.1487 (3.1135)	Learning Rate [7.8125e-05]
7: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00100 (0.00097)	Tok/s 52987 (53621)	Loss/tok 3.4342 (3.1156)	Learning Rate [7.8125e-05]
2: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00098)	Tok/s 52812 (53170)	Loss/tok 3.1037 (3.1136)	Learning Rate [7.8125e-05]
5: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00093)	Tok/s 52892 (53458)	Loss/tok 3.0381 (3.1118)	Learning Rate [7.8125e-05]
3: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00092)	Tok/s 52772 (53275)	Loss/tok 3.1543 (3.1168)	Learning Rate [7.8125e-05]
4: TRAIN [2][2210/3416]	Time 0.057 (0.058)	Data 0.00107 (0.00098)	Tok/s 52753 (53373)	Loss/tok 3.1106 (3.1150)	Learning Rate [7.8125e-05]
11: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00092)	Tok/s 37658 (53898)	Loss/tok 2.9980 (3.1157)	Learning Rate [7.8125e-05]
9: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 37518 (53739)	Loss/tok 2.7890 (3.1105)	Learning Rate [7.8125e-05]
10: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00109 (0.00096)	Tok/s 37656 (53814)	Loss/tok 2.9757 (3.1065)	Learning Rate [7.8125e-05]
12: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00101)	Tok/s 37621 (54019)	Loss/tok 2.9421 (3.1183)	Learning Rate [7.8125e-05]
13: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00096)	Tok/s 37800 (54113)	Loss/tok 2.7343 (3.1144)	Learning Rate [7.8125e-05]
8: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00098)	Tok/s 36450 (53670)	Loss/tok 2.7984 (3.1153)	Learning Rate [7.8125e-05]
14: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00091)	Tok/s 37385 (54218)	Loss/tok 3.0661 (3.1154)	Learning Rate [7.8125e-05]
6: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00079 (0.00092)	Tok/s 36398 (53505)	Loss/tok 2.7120 (3.1180)	Learning Rate [7.8125e-05]
15: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00092)	Tok/s 37400 (54335)	Loss/tok 2.8530 (3.1140)	Learning Rate [7.8125e-05]
7: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00097)	Tok/s 36443 (53595)	Loss/tok 2.9186 (3.1151)	Learning Rate [7.8125e-05]
5: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00093)	Tok/s 36370 (53432)	Loss/tok 2.7092 (3.1116)	Learning Rate [7.8125e-05]
0: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00097)	Tok/s 36184 (52930)	Loss/tok 2.8171 (3.1179)	Learning Rate [7.8125e-05]
1: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00100)	Tok/s 36204 (53031)	Loss/tok 2.9470 (3.1132)	Learning Rate [7.8125e-05]
4: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00098)	Tok/s 36401 (53348)	Loss/tok 2.9895 (3.1149)	Learning Rate [7.8125e-05]
2: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00098)	Tok/s 36173 (53145)	Loss/tok 3.0176 (3.1133)	Learning Rate [7.8125e-05]
3: TRAIN [2][2220/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00092)	Tok/s 36212 (53250)	Loss/tok 2.9439 (3.1166)	Learning Rate [7.8125e-05]
13: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00096)	Tok/s 39791 (54092)	Loss/tok 2.9026 (3.1143)	Learning Rate [7.8125e-05]
14: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00091)	Tok/s 39822 (54198)	Loss/tok 2.6893 (3.1151)	Learning Rate [7.8125e-05]
11: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00092)	Tok/s 39172 (53878)	Loss/tok 3.1197 (3.1157)	Learning Rate [7.8125e-05]
15: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00092)	Tok/s 39824 (54314)	Loss/tok 2.7119 (3.1138)	Learning Rate [7.8125e-05]
12: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00109 (0.00101)	Tok/s 39770 (53999)	Loss/tok 3.0172 (3.1184)	Learning Rate [7.8125e-05]
9: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00092)	Tok/s 38165 (53720)	Loss/tok 3.0180 (3.1100)	Learning Rate [7.8125e-05]
10: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00110 (0.00096)	Tok/s 38240 (53795)	Loss/tok 2.9198 (3.1063)	Learning Rate [7.8125e-05]
0: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00097)	Tok/s 38514 (52912)	Loss/tok 2.8630 (3.1177)	Learning Rate [7.8125e-05]
8: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00098)	Tok/s 38105 (53650)	Loss/tok 2.8539 (3.1152)	Learning Rate [7.8125e-05]
2: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00098)	Tok/s 38450 (53126)	Loss/tok 3.0265 (3.1132)	Learning Rate [7.8125e-05]
7: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00097)	Tok/s 38098 (53575)	Loss/tok 3.0308 (3.1153)	Learning Rate [7.8125e-05]
6: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00092)	Tok/s 38104 (53486)	Loss/tok 2.9626 (3.1181)	Learning Rate [7.8125e-05]
3: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00092)	Tok/s 38293 (53231)	Loss/tok 2.9262 (3.1166)	Learning Rate [7.8125e-05]
5: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00093)	Tok/s 38137 (53413)	Loss/tok 2.8022 (3.1115)	Learning Rate [7.8125e-05]
4: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00098)	Tok/s 38142 (53328)	Loss/tok 3.0266 (3.1150)	Learning Rate [7.8125e-05]
1: TRAIN [2][2230/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00100)	Tok/s 38149 (53013)	Loss/tok 2.9476 (3.1132)	Learning Rate [7.8125e-05]
4: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00098)	Tok/s 52294 (53322)	Loss/tok 3.3138 (3.1150)	Learning Rate [7.8125e-05]
3: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00092)	Tok/s 52335 (53224)	Loss/tok 3.2334 (3.1168)	Learning Rate [7.8125e-05]
5: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00086 (0.00093)	Tok/s 52260 (53406)	Loss/tok 3.0705 (3.1115)	Learning Rate [7.8125e-05]
2: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00098)	Tok/s 52342 (53120)	Loss/tok 3.0215 (3.1127)	Learning Rate [7.8125e-05]
6: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00083 (0.00092)	Tok/s 52160 (53478)	Loss/tok 3.1066 (3.1179)	Learning Rate [7.8125e-05]
1: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00100)	Tok/s 52344 (53007)	Loss/tok 3.2533 (3.1132)	Learning Rate [7.8125e-05]
7: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00097)	Tok/s 52193 (53567)	Loss/tok 3.4697 (3.1154)	Learning Rate [7.8125e-05]
0: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00097)	Tok/s 52354 (52907)	Loss/tok 3.1098 (3.1176)	Learning Rate [7.8125e-05]
8: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00086 (0.00098)	Tok/s 52185 (53644)	Loss/tok 3.0511 (3.1147)	Learning Rate [7.8125e-05]
15: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00092)	Tok/s 53317 (54307)	Loss/tok 3.2058 (3.1134)	Learning Rate [7.8125e-05]
9: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00092)	Tok/s 52160 (53713)	Loss/tok 2.9888 (3.1096)	Learning Rate [7.8125e-05]
14: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00091)	Tok/s 53296 (54192)	Loss/tok 3.2002 (3.1152)	Learning Rate [7.8125e-05]
10: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00096)	Tok/s 52147 (53788)	Loss/tok 3.0027 (3.1062)	Learning Rate [7.8125e-05]
13: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00096)	Tok/s 53252 (54086)	Loss/tok 3.3231 (3.1143)	Learning Rate [7.8125e-05]
12: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00102 (0.00101)	Tok/s 53197 (53992)	Loss/tok 3.3356 (3.1185)	Learning Rate [7.8125e-05]
11: TRAIN [2][2240/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00092)	Tok/s 52845 (53872)	Loss/tok 3.3220 (3.1157)	Learning Rate [7.8125e-05]
6: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 63132 (53512)	Loss/tok 3.1250 (3.1187)	Learning Rate [7.8125e-05]
7: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 62977 (53601)	Loss/tok 3.3698 (3.1160)	Learning Rate [7.8125e-05]
8: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00098)	Tok/s 62904 (53677)	Loss/tok 3.0650 (3.1147)	Learning Rate [7.8125e-05]
3: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00092)	Tok/s 63137 (53259)	Loss/tok 3.3030 (3.1173)	Learning Rate [7.8125e-05]
9: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00092)	Tok/s 62820 (53746)	Loss/tok 3.2172 (3.1095)	Learning Rate [7.8125e-05]
2: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00098)	Tok/s 63056 (53155)	Loss/tok 3.1934 (3.1127)	Learning Rate [7.8125e-05]
5: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 63106 (53440)	Loss/tok 3.4124 (3.1121)	Learning Rate [7.8125e-05]
4: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 63019 (53356)	Loss/tok 3.1100 (3.1152)	Learning Rate [7.8125e-05]
10: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00114 (0.00096)	Tok/s 62622 (53822)	Loss/tok 3.1735 (3.1065)	Learning Rate [7.8125e-05]
1: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 62837 (53042)	Loss/tok 3.2285 (3.1136)	Learning Rate [7.8125e-05]
0: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 62856 (52943)	Loss/tok 3.1300 (3.1175)	Learning Rate [7.8125e-05]
11: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 62630 (53906)	Loss/tok 3.3354 (3.1158)	Learning Rate [7.8125e-05]
12: TRAIN [2][2250/3416]	Time 0.070 (0.058)	Data 0.00116 (0.00101)	Tok/s 62486 (54025)	Loss/tok 3.2526 (3.1183)	Learning Rate [7.8125e-05]
15: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 63680 (54341)	Loss/tok 3.3186 (3.1140)	Learning Rate [7.8125e-05]
14: TRAIN [2][2250/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 63075 (54225)	Loss/tok 3.2612 (3.1151)	Learning Rate [7.8125e-05]
13: TRAIN [2][2250/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00096)	Tok/s 62612 (54119)	Loss/tok 3.3875 (3.1146)	Learning Rate [7.8125e-05]
11: TRAIN [2][2260/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00092)	Tok/s 47416 (53885)	Loss/tok 3.1164 (3.1159)	Learning Rate [7.8125e-05]
9: TRAIN [2][2260/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00092)	Tok/s 47429 (53726)	Loss/tok 3.3923 (3.1095)	Learning Rate [7.8125e-05]
10: TRAIN [2][2260/3416]	Time 0.045 (0.058)	Data 0.00103 (0.00096)	Tok/s 47439 (53801)	Loss/tok 2.6544 (3.1062)	Learning Rate [7.8125e-05]
12: TRAIN [2][2260/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00101)	Tok/s 47272 (54004)	Loss/tok 3.0562 (3.1182)	Learning Rate [7.8125e-05]
8: TRAIN [2][2260/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00098)	Tok/s 47462 (53657)	Loss/tok 2.9835 (3.1146)	Learning Rate [7.8125e-05]
6: TRAIN [2][2260/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00092)	Tok/s 47540 (53493)	Loss/tok 2.9664 (3.1186)	Learning Rate [7.8125e-05]
7: TRAIN [2][2260/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00097)	Tok/s 47465 (53581)	Loss/tok 2.8458 (3.1163)	Learning Rate [7.8125e-05]
13: TRAIN [2][2260/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00096)	Tok/s 47184 (54099)	Loss/tok 3.0889 (3.1147)	Learning Rate [7.8125e-05]
15: TRAIN [2][2260/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00092)	Tok/s 47273 (54320)	Loss/tok 3.1901 (3.1137)	Learning Rate [7.8125e-05]
4: TRAIN [2][2260/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00098)	Tok/s 47465 (53337)	Loss/tok 3.1113 (3.1149)	Learning Rate [7.8125e-05]
5: TRAIN [2][2260/3416]	Time 0.044 (0.058)	Data 0.00083 (0.00093)	Tok/s 47477 (53421)	Loss/tok 3.1253 (3.1119)	Learning Rate [7.8125e-05]
14: TRAIN [2][2260/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00091)	Tok/s 47362 (54205)	Loss/tok 2.9464 (3.1149)	Learning Rate [7.8125e-05]
0: TRAIN [2][2260/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00097)	Tok/s 45909 (52924)	Loss/tok 3.1523 (3.1174)	Learning Rate [7.8125e-05]
1: TRAIN [2][2260/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00100)	Tok/s 47046 (53023)	Loss/tok 2.8166 (3.1132)	Learning Rate [7.8125e-05]
3: TRAIN [2][2260/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00092)	Tok/s 47544 (53240)	Loss/tok 3.1745 (3.1172)	Learning Rate [7.8125e-05]
2: TRAIN [2][2260/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00098)	Tok/s 47405 (53136)	Loss/tok 2.9657 (3.1128)	Learning Rate [7.8125e-05]
2: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00098)	Tok/s 49096 (53129)	Loss/tok 2.9790 (3.1122)	Learning Rate [7.8125e-05]
1: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00100)	Tok/s 49155 (53017)	Loss/tok 3.0022 (3.1129)	Learning Rate [7.8125e-05]
0: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00097)	Tok/s 49020 (52917)	Loss/tok 2.9627 (3.1171)	Learning Rate [7.8125e-05]
15: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00092)	Tok/s 50550 (54313)	Loss/tok 3.0663 (3.1133)	Learning Rate [7.8125e-05]
14: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00082 (0.00091)	Tok/s 49899 (54197)	Loss/tok 2.9453 (3.1148)	Learning Rate [7.8125e-05]
4: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00106 (0.00098)	Tok/s 49152 (53331)	Loss/tok 3.0698 (3.1147)	Learning Rate [7.8125e-05]
3: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00092)	Tok/s 49226 (53233)	Loss/tok 2.9685 (3.1169)	Learning Rate [7.8125e-05]
5: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00093)	Tok/s 49085 (53414)	Loss/tok 2.8516 (3.1115)	Learning Rate [7.8125e-05]
6: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00092)	Tok/s 49239 (53486)	Loss/tok 3.2909 (3.1184)	Learning Rate [7.8125e-05]
11: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00081 (0.00092)	Tok/s 49003 (53877)	Loss/tok 3.1508 (3.1157)	Learning Rate [7.8125e-05]
13: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00102 (0.00096)	Tok/s 49077 (54090)	Loss/tok 3.0292 (3.1148)	Learning Rate [7.8125e-05]
12: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00110 (0.00101)	Tok/s 49197 (53996)	Loss/tok 3.1011 (3.1181)	Learning Rate [7.8125e-05]
8: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00098)	Tok/s 49169 (53650)	Loss/tok 2.9560 (3.1143)	Learning Rate [7.8125e-05]
7: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00097)	Tok/s 49156 (53574)	Loss/tok 2.8007 (3.1160)	Learning Rate [7.8125e-05]
9: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00092)	Tok/s 49097 (53718)	Loss/tok 3.2767 (3.1095)	Learning Rate [7.8125e-05]
10: TRAIN [2][2270/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00096)	Tok/s 48927 (53793)	Loss/tok 3.0742 (3.1062)	Learning Rate [7.8125e-05]
1: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00100)	Tok/s 28317 (52992)	Loss/tok 2.3869 (3.1123)	Learning Rate [7.8125e-05]
0: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00090 (0.00097)	Tok/s 28407 (52892)	Loss/tok 2.3779 (3.1168)	Learning Rate [7.8125e-05]
15: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00085 (0.00092)	Tok/s 31544 (54289)	Loss/tok 2.6520 (3.1131)	Learning Rate [7.8125e-05]
2: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00101 (0.00098)	Tok/s 28236 (53104)	Loss/tok 2.4901 (3.1124)	Learning Rate [7.8125e-05]
14: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00086 (0.00092)	Tok/s 30622 (54173)	Loss/tok 2.5146 (3.1147)	Learning Rate [7.8125e-05]
3: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00087 (0.00092)	Tok/s 28154 (53207)	Loss/tok 2.4178 (3.1164)	Learning Rate [7.8125e-05]
13: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00091 (0.00096)	Tok/s 29946 (54066)	Loss/tok 2.4693 (3.1147)	Learning Rate [7.8125e-05]
12: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00096 (0.00101)	Tok/s 29929 (53971)	Loss/tok 2.6056 (3.1177)	Learning Rate [7.8125e-05]
4: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00096 (0.00098)	Tok/s 28088 (53305)	Loss/tok 2.5381 (3.1144)	Learning Rate [7.8125e-05]
11: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00090 (0.00092)	Tok/s 29808 (53851)	Loss/tok 2.2913 (3.1155)	Learning Rate [7.8125e-05]
5: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00086 (0.00093)	Tok/s 28844 (53388)	Loss/tok 2.5434 (3.1113)	Learning Rate [7.8125e-05]
6: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00083 (0.00092)	Tok/s 29557 (53460)	Loss/tok 2.6044 (3.1182)	Learning Rate [7.8125e-05]
10: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00091 (0.00096)	Tok/s 29762 (53767)	Loss/tok 2.3550 (3.1061)	Learning Rate [7.8125e-05]
8: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00093 (0.00098)	Tok/s 29618 (53625)	Loss/tok 2.5070 (3.1141)	Learning Rate [7.8125e-05]
7: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00092 (0.00097)	Tok/s 29580 (53549)	Loss/tok 2.4807 (3.1157)	Learning Rate [7.8125e-05]
9: TRAIN [2][2280/3416]	Time 0.041 (0.058)	Data 0.00088 (0.00092)	Tok/s 29646 (53693)	Loss/tok 2.4891 (3.1095)	Learning Rate [7.8125e-05]
9: TRAIN [2][2290/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00091)	Tok/s 51740 (53676)	Loss/tok 2.9868 (3.1092)	Learning Rate [7.8125e-05]
10: TRAIN [2][2290/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00096)	Tok/s 51744 (53750)	Loss/tok 2.7604 (3.1062)	Learning Rate [7.8125e-05]
11: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00092)	Tok/s 51690 (53833)	Loss/tok 3.0647 (3.1154)	Learning Rate [7.8125e-05]
7: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 51605 (53532)	Loss/tok 3.0263 (3.1155)	Learning Rate [7.8125e-05]
8: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00098)	Tok/s 51627 (53608)	Loss/tok 2.9240 (3.1140)	Learning Rate [7.8125e-05]
12: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00101)	Tok/s 51692 (53953)	Loss/tok 3.1954 (3.1178)	Learning Rate [7.8125e-05]
13: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00096)	Tok/s 51652 (54048)	Loss/tok 3.0639 (3.1143)	Learning Rate [7.8125e-05]
6: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 51439 (53443)	Loss/tok 3.0024 (3.1179)	Learning Rate [7.8125e-05]
5: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00093)	Tok/s 51318 (53372)	Loss/tok 3.1734 (3.1112)	Learning Rate [7.8125e-05]
14: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00081 (0.00092)	Tok/s 51647 (54154)	Loss/tok 3.2119 (3.1147)	Learning Rate [7.8125e-05]
15: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 52764 (54271)	Loss/tok 2.9561 (3.1127)	Learning Rate [7.8125e-05]
4: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00098)	Tok/s 51217 (53289)	Loss/tok 3.2127 (3.1142)	Learning Rate [7.8125e-05]
0: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 51375 (52877)	Loss/tok 3.3155 (3.1167)	Learning Rate [7.8125e-05]
3: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00092)	Tok/s 51203 (53191)	Loss/tok 3.0406 (3.1166)	Learning Rate [7.8125e-05]
1: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00100)	Tok/s 51291 (52977)	Loss/tok 3.1236 (3.1123)	Learning Rate [7.8125e-05]
2: TRAIN [2][2290/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00098)	Tok/s 51201 (53088)	Loss/tok 3.0025 (3.1122)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
2: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00098)	Tok/s 51185 (53067)	Loss/tok 2.9449 (3.1119)	Learning Rate [7.8125e-05]
1: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00100)	Tok/s 50747 (52955)	Loss/tok 2.8108 (3.1120)	Learning Rate [7.8125e-05]
4: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
0: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00097)	Tok/s 50746 (52857)	Loss/tok 3.1996 (3.1165)	Learning Rate [7.8125e-05]
6: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
15: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00082 (0.00092)	Tok/s 52073 (54249)	Loss/tok 2.9762 (3.1125)	Learning Rate [7.8125e-05]
3: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00092)	Tok/s 51903 (53170)	Loss/tok 2.9701 (3.1163)	Learning Rate [7.8125e-05]
11: Upscaling, new scale: 4096.0
14: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00092)	Tok/s 52069 (54133)	Loss/tok 3.0164 (3.1147)	Learning Rate [7.8125e-05]
12: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
4: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00098)	Tok/s 51750 (53267)	Loss/tok 3.0041 (3.1142)	Learning Rate [7.8125e-05]
7: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
6: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00083 (0.00092)	Tok/s 51546 (53422)	Loss/tok 3.0833 (3.1177)	Learning Rate [7.8125e-05]
5: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00093)	Tok/s 51696 (53350)	Loss/tok 2.8914 (3.1110)	Learning Rate [7.8125e-05]
10: Upscaling, new scale: 4096.0
13: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00096)	Tok/s 51915 (54028)	Loss/tok 2.9426 (3.1139)	Learning Rate [7.8125e-05]
11: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00077 (0.00092)	Tok/s 51705 (53812)	Loss/tok 2.8579 (3.1153)	Learning Rate [7.8125e-05]
12: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00101)	Tok/s 51746 (53932)	Loss/tok 3.2267 (3.1176)	Learning Rate [7.8125e-05]
8: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00097)	Tok/s 51487 (53586)	Loss/tok 2.9873 (3.1139)	Learning Rate [7.8125e-05]
7: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00097)	Tok/s 51419 (53510)	Loss/tok 3.0299 (3.1156)	Learning Rate [7.8125e-05]
10: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00096)	Tok/s 51574 (53729)	Loss/tok 2.8095 (3.1061)	Learning Rate [7.8125e-05]
9: TRAIN [2][2300/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00091)	Tok/s 51499 (53654)	Loss/tok 3.1226 (3.1092)	Learning Rate [7.8125e-05]
12: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00101)	Tok/s 77798 (53948)	Loss/tok 3.0986 (3.1180)	Learning Rate [7.8125e-05]
13: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 77929 (54044)	Loss/tok 3.0514 (3.1140)	Learning Rate [7.8125e-05]
11: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00092)	Tok/s 77249 (53827)	Loss/tok 3.0748 (3.1156)	Learning Rate [7.8125e-05]
10: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 76659 (53744)	Loss/tok 3.0436 (3.1066)	Learning Rate [7.8125e-05]
14: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 77917 (54149)	Loss/tok 3.0057 (3.1149)	Learning Rate [7.8125e-05]
9: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00091)	Tok/s 76725 (53670)	Loss/tok 3.1222 (3.1096)	Learning Rate [7.8125e-05]
15: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 77929 (54265)	Loss/tok 3.1304 (3.1127)	Learning Rate [7.8125e-05]
8: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 76719 (53602)	Loss/tok 3.1222 (3.1144)	Learning Rate [7.8125e-05]
0: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 76114 (52874)	Loss/tok 3.1934 (3.1165)	Learning Rate [7.8125e-05]
7: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00097)	Tok/s 76708 (53526)	Loss/tok 2.9169 (3.1158)	Learning Rate [7.8125e-05]
1: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00100)	Tok/s 76091 (52972)	Loss/tok 3.2261 (3.1125)	Learning Rate [7.8125e-05]
6: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00078 (0.00092)	Tok/s 76635 (53438)	Loss/tok 3.0714 (3.1176)	Learning Rate [7.8125e-05]
2: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 76042 (53084)	Loss/tok 3.0849 (3.1120)	Learning Rate [7.8125e-05]
5: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 76782 (53366)	Loss/tok 3.2256 (3.1114)	Learning Rate [7.8125e-05]
3: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 76585 (53187)	Loss/tok 3.1271 (3.1167)	Learning Rate [7.8125e-05]
4: TRAIN [2][2310/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 76848 (53284)	Loss/tok 3.0934 (3.1142)	Learning Rate [7.8125e-05]
13: Gradient norm: inf
12: Gradient norm: inf
14: Gradient norm: inf
13: Skipped batch, new scale: 2048.0
12: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
15: Skipped batch, new scale: 2048.0
0: Gradient norm: inf
7: Gradient norm: inf
10: Skipped batch, new scale: 2048.0
0: Skipped batch, new scale: 2048.0
7: Skipped batch, new scale: 2048.0
8: Gradient norm: inf
11: Gradient norm: inf
1: Gradient norm: inf
4: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
5: Gradient norm: inf
6: Gradient norm: inf
8: Skipped batch, new scale: 2048.0
1: Skipped batch, new scale: 2048.0
9: Gradient norm: inf
4: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
11: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
6: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
4: TRAIN [2][2320/3416]	Time 0.045 (0.058)	Data 0.00105 (0.00098)	Tok/s 47309 (53269)	Loss/tok 2.9205 (3.1140)	Learning Rate [7.8125e-05]
5: TRAIN [2][2320/3416]	Time 0.044 (0.058)	Data 0.00118 (0.00093)	Tok/s 48055 (53353)	Loss/tok 2.9714 (3.1119)	Learning Rate [7.8125e-05]
7: TRAIN [2][2320/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00097)	Tok/s 48638 (53518)	Loss/tok 2.9855 (3.1159)	Learning Rate [7.8125e-05]
6: TRAIN [2][2320/3416]	Time 0.044 (0.058)	Data 0.00120 (0.00092)	Tok/s 48907 (53426)	Loss/tok 2.9174 (3.1175)	Learning Rate [7.8125e-05]
3: TRAIN [2][2320/3416]	Time 0.045 (0.058)	Data 0.00104 (0.00092)	Tok/s 47132 (53172)	Loss/tok 2.8960 (3.1165)	Learning Rate [7.8125e-05]
2: TRAIN [2][2320/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00098)	Tok/s 47012 (53069)	Loss/tok 3.0704 (3.1120)	Learning Rate [7.8125e-05]
9: TRAIN [2][2320/3416]	Time 0.045 (0.058)	Data 0.00108 (0.00091)	Tok/s 48401 (53659)	Loss/tok 3.0175 (3.1096)	Learning Rate [7.8125e-05]
1: TRAIN [2][2320/3416]	Time 0.045 (0.058)	Data 0.00118 (0.00100)	Tok/s 46862 (52956)	Loss/tok 2.9867 (3.1122)	Learning Rate [7.8125e-05]
10: TRAIN [2][2320/3416]	Time 0.045 (0.058)	Data 0.00106 (0.00096)	Tok/s 48246 (53737)	Loss/tok 3.0217 (3.1066)	Learning Rate [7.8125e-05]
0: TRAIN [2][2320/3416]	Time 0.045 (0.058)	Data 0.00124 (0.00097)	Tok/s 46744 (52859)	Loss/tok 3.1995 (3.1166)	Learning Rate [7.8125e-05]
11: TRAIN [2][2320/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00092)	Tok/s 48087 (53816)	Loss/tok 2.9931 (3.1153)	Learning Rate [7.8125e-05]
14: TRAIN [2][2320/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00092)	Tok/s 47938 (54141)	Loss/tok 3.0577 (3.1147)	Learning Rate [7.8125e-05]
13: TRAIN [2][2320/3416]	Time 0.045 (0.058)	Data 0.00114 (0.00096)	Tok/s 47883 (54036)	Loss/tok 3.0578 (3.1137)	Learning Rate [7.8125e-05]
15: TRAIN [2][2320/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00092)	Tok/s 48042 (54257)	Loss/tok 3.0337 (3.1127)	Learning Rate [7.8125e-05]
8: TRAIN [2][2320/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00097)	Tok/s 47738 (53591)	Loss/tok 3.0972 (3.1141)	Learning Rate [7.8125e-05]
12: TRAIN [2][2320/3416]	Time 0.046 (0.058)	Data 0.00111 (0.00101)	Tok/s 47320 (53939)	Loss/tok 3.3644 (3.1182)	Learning Rate [7.8125e-05]
1: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00114 (0.00100)	Tok/s 48348 (52962)	Loss/tok 2.9589 (3.1122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00097)	Tok/s 48236 (52866)	Loss/tok 2.9971 (3.1167)	Learning Rate [7.8125e-05]
3: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00092)	Tok/s 48356 (53178)	Loss/tok 3.1294 (3.1163)	Learning Rate [7.8125e-05]
15: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00092)	Tok/s 49428 (54262)	Loss/tok 2.9066 (3.1127)	Learning Rate [7.8125e-05]
14: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00092)	Tok/s 49328 (54147)	Loss/tok 2.9493 (3.1147)	Learning Rate [7.8125e-05]
2: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00098)	Tok/s 48243 (53075)	Loss/tok 3.0769 (3.1118)	Learning Rate [7.8125e-05]
13: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00096)	Tok/s 49208 (54041)	Loss/tok 2.8815 (3.1139)	Learning Rate [7.8125e-05]
10: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00096)	Tok/s 49337 (53742)	Loss/tok 2.9750 (3.1066)	Learning Rate [7.8125e-05]
4: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00099)	Tok/s 48169 (53275)	Loss/tok 2.9908 (3.1139)	Learning Rate [7.8125e-05]
11: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00092)	Tok/s 49195 (53821)	Loss/tok 3.2456 (3.1156)	Learning Rate [7.8125e-05]
12: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00101 (0.00101)	Tok/s 49166 (53944)	Loss/tok 2.8855 (3.1185)	Learning Rate [7.8125e-05]
8: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00097)	Tok/s 49224 (53597)	Loss/tok 2.9544 (3.1143)	Learning Rate [7.8125e-05]
7: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00097)	Tok/s 49297 (53524)	Loss/tok 3.0795 (3.1160)	Learning Rate [7.8125e-05]
5: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00093)	Tok/s 48871 (53359)	Loss/tok 2.7958 (3.1122)	Learning Rate [7.8125e-05]
6: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00083 (0.00092)	Tok/s 49393 (53432)	Loss/tok 2.8332 (3.1171)	Learning Rate [7.8125e-05]
9: TRAIN [2][2330/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00091)	Tok/s 49211 (53665)	Loss/tok 2.8838 (3.1097)	Learning Rate [7.8125e-05]
7: TRAIN [2][2340/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 62660 (53526)	Loss/tok 2.9045 (3.1159)	Learning Rate [7.8125e-05]
8: TRAIN [2][2340/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 62657 (53599)	Loss/tok 3.5183 (3.1145)	Learning Rate [7.8125e-05]
6: TRAIN [2][2340/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 62588 (53435)	Loss/tok 3.1979 (3.1176)	Learning Rate [7.8125e-05]
5: TRAIN [2][2340/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 62506 (53361)	Loss/tok 3.0976 (3.1123)	Learning Rate [7.8125e-05]
4: TRAIN [2][2340/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00099)	Tok/s 62416 (53278)	Loss/tok 3.2402 (3.1142)	Learning Rate [7.8125e-05]
9: TRAIN [2][2340/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 62652 (53667)	Loss/tok 3.3270 (3.1099)	Learning Rate [7.8125e-05]
10: TRAIN [2][2340/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 62633 (53744)	Loss/tok 3.1980 (3.1070)	Learning Rate [7.8125e-05]
3: TRAIN [2][2340/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 62393 (53181)	Loss/tok 3.0257 (3.1164)	Learning Rate [7.8125e-05]
2: TRAIN [2][2340/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 62409 (53079)	Loss/tok 3.2993 (3.1117)	Learning Rate [7.8125e-05]
1: TRAIN [2][2340/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00100)	Tok/s 62396 (52966)	Loss/tok 3.0400 (3.1123)	Learning Rate [7.8125e-05]
11: TRAIN [2][2340/3416]	Time 0.069 (0.058)	Data 0.00118 (0.00092)	Tok/s 62884 (53823)	Loss/tok 2.9036 (3.1157)	Learning Rate [7.8125e-05]
12: TRAIN [2][2340/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00101)	Tok/s 63500 (53947)	Loss/tok 3.1468 (3.1190)	Learning Rate [7.8125e-05]
0: TRAIN [2][2340/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 62415 (52869)	Loss/tok 3.0159 (3.1166)	Learning Rate [7.8125e-05]
13: TRAIN [2][2340/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00096)	Tok/s 63506 (54045)	Loss/tok 3.0634 (3.1140)	Learning Rate [7.8125e-05]
15: TRAIN [2][2340/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 63297 (54265)	Loss/tok 3.1622 (3.1129)	Learning Rate [7.8125e-05]
14: TRAIN [2][2340/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 63323 (54150)	Loss/tok 3.2265 (3.1146)	Learning Rate [7.8125e-05]
0: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00096)	Tok/s 53145 (52855)	Loss/tok 3.1241 (3.1166)	Learning Rate [7.8125e-05]
1: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00109 (0.00100)	Tok/s 53077 (52951)	Loss/tok 3.2186 (3.1122)	Learning Rate [7.8125e-05]
15: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00092)	Tok/s 54183 (54250)	Loss/tok 2.9474 (3.1126)	Learning Rate [7.8125e-05]
2: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00098)	Tok/s 52935 (53064)	Loss/tok 3.2075 (3.1117)	Learning Rate [7.8125e-05]
14: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00084 (0.00092)	Tok/s 54203 (54136)	Loss/tok 3.0603 (3.1144)	Learning Rate [7.8125e-05]
3: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00092)	Tok/s 52888 (53166)	Loss/tok 3.2677 (3.1164)	Learning Rate [7.8125e-05]
13: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00106 (0.00096)	Tok/s 53765 (54030)	Loss/tok 3.0244 (3.1138)	Learning Rate [7.8125e-05]
4: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00099)	Tok/s 52865 (53263)	Loss/tok 3.2085 (3.1140)	Learning Rate [7.8125e-05]
12: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00101)	Tok/s 52967 (53933)	Loss/tok 3.1944 (3.1187)	Learning Rate [7.8125e-05]
11: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00081 (0.00092)	Tok/s 52969 (53809)	Loss/tok 3.2973 (3.1157)	Learning Rate [7.8125e-05]
5: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00084 (0.00093)	Tok/s 52894 (53348)	Loss/tok 3.2435 (3.1123)	Learning Rate [7.8125e-05]
10: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00096)	Tok/s 52996 (53729)	Loss/tok 3.1785 (3.1069)	Learning Rate [7.8125e-05]
9: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00080 (0.00091)	Tok/s 52968 (53651)	Loss/tok 2.9772 (3.1096)	Learning Rate [7.8125e-05]
6: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00092)	Tok/s 52878 (53421)	Loss/tok 3.2621 (3.1175)	Learning Rate [7.8125e-05]
8: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00097)	Tok/s 52951 (53584)	Loss/tok 3.1313 (3.1147)	Learning Rate [7.8125e-05]
7: TRAIN [2][2350/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00097)	Tok/s 52901 (53511)	Loss/tok 3.0667 (3.1155)	Learning Rate [7.8125e-05]
11: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00092)	Tok/s 59417 (53792)	Loss/tok 3.0646 (3.1154)	Learning Rate [7.8125e-05]
12: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00101)	Tok/s 59359 (53916)	Loss/tok 3.3675 (3.1186)	Learning Rate [7.8125e-05]
10: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00096)	Tok/s 59338 (53712)	Loss/tok 3.2238 (3.1069)	Learning Rate [7.8125e-05]
8: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00097)	Tok/s 59257 (53567)	Loss/tok 3.3952 (3.1146)	Learning Rate [7.8125e-05]
9: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00091)	Tok/s 59320 (53634)	Loss/tok 3.0780 (3.1095)	Learning Rate [7.8125e-05]
13: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00108 (0.00096)	Tok/s 59287 (54014)	Loss/tok 3.1247 (3.1135)	Learning Rate [7.8125e-05]
14: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00092)	Tok/s 59107 (54119)	Loss/tok 3.3289 (3.1141)	Learning Rate [7.8125e-05]
15: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00092)	Tok/s 58966 (54233)	Loss/tok 2.8957 (3.1122)	Learning Rate [7.8125e-05]
7: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00097)	Tok/s 58961 (53495)	Loss/tok 3.2355 (3.1153)	Learning Rate [7.8125e-05]
6: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00092)	Tok/s 58087 (53404)	Loss/tok 3.3036 (3.1173)	Learning Rate [7.8125e-05]
0: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00096)	Tok/s 57930 (52839)	Loss/tok 3.3432 (3.1165)	Learning Rate [7.8125e-05]
5: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00093)	Tok/s 57972 (53331)	Loss/tok 3.1638 (3.1124)	Learning Rate [7.8125e-05]
1: TRAIN [2][2360/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00100)	Tok/s 57816 (52935)	Loss/tok 3.4114 (3.1119)	Learning Rate [7.8125e-05]
4: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00099)	Tok/s 57846 (53246)	Loss/tok 2.9683 (3.1135)	Learning Rate [7.8125e-05]
2: TRAIN [2][2360/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00098)	Tok/s 57805 (53047)	Loss/tok 3.2201 (3.1118)	Learning Rate [7.8125e-05]
3: TRAIN [2][2360/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00092)	Tok/s 57884 (53150)	Loss/tok 3.2133 (3.1160)	Learning Rate [7.8125e-05]
4: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00098)	Tok/s 69705 (53272)	Loss/tok 3.1627 (3.1139)	Learning Rate [7.8125e-05]
0: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 69924 (52865)	Loss/tok 3.2439 (3.1169)	Learning Rate [7.8125e-05]
2: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 69719 (53074)	Loss/tok 3.0344 (3.1118)	Learning Rate [7.8125e-05]
1: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 69830 (52961)	Loss/tok 3.2858 (3.1120)	Learning Rate [7.8125e-05]
3: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 69744 (53176)	Loss/tok 3.1781 (3.1160)	Learning Rate [7.8125e-05]
6: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00078 (0.00092)	Tok/s 69664 (53430)	Loss/tok 3.1584 (3.1173)	Learning Rate [7.8125e-05]
5: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 69847 (53357)	Loss/tok 2.9454 (3.1126)	Learning Rate [7.8125e-05]
15: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 70825 (54258)	Loss/tok 3.3377 (3.1125)	Learning Rate [7.8125e-05]
7: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 69664 (53521)	Loss/tok 3.1424 (3.1153)	Learning Rate [7.8125e-05]
14: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 70817 (54145)	Loss/tok 3.4983 (3.1143)	Learning Rate [7.8125e-05]
8: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 69685 (53593)	Loss/tok 3.2049 (3.1147)	Learning Rate [7.8125e-05]
9: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00091)	Tok/s 69747 (53660)	Loss/tok 3.3176 (3.1095)	Learning Rate [7.8125e-05]
10: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00096)	Tok/s 69943 (53737)	Loss/tok 3.0112 (3.1070)	Learning Rate [7.8125e-05]
13: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00096)	Tok/s 70860 (54039)	Loss/tok 3.0175 (3.1133)	Learning Rate [7.8125e-05]
11: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 70738 (53818)	Loss/tok 3.1375 (3.1153)	Learning Rate [7.8125e-05]
12: TRAIN [2][2370/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00101)	Tok/s 70750 (53941)	Loss/tok 3.3132 (3.1190)	Learning Rate [7.8125e-05]
8: TRAIN [2][2380/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00097)	Tok/s 38028 (53603)	Loss/tok 2.6937 (3.1150)	Learning Rate [7.8125e-05]
7: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00097)	Tok/s 37992 (53530)	Loss/tok 2.9812 (3.1158)	Learning Rate [7.8125e-05]
6: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 37978 (53439)	Loss/tok 2.7296 (3.1174)	Learning Rate [7.8125e-05]
9: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00091)	Tok/s 37904 (53670)	Loss/tok 3.1522 (3.1097)	Learning Rate [7.8125e-05]
10: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00096)	Tok/s 37794 (53747)	Loss/tok 2.7015 (3.1074)	Learning Rate [7.8125e-05]
11: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00078 (0.00092)	Tok/s 37823 (53827)	Loss/tok 2.8238 (3.1155)	Learning Rate [7.8125e-05]
5: TRAIN [2][2380/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00093)	Tok/s 37624 (53365)	Loss/tok 2.9502 (3.1128)	Learning Rate [7.8125e-05]
4: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00098)	Tok/s 36715 (53280)	Loss/tok 2.6144 (3.1146)	Learning Rate [7.8125e-05]
12: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00101)	Tok/s 37875 (53950)	Loss/tok 3.1528 (3.1191)	Learning Rate [7.8125e-05]
3: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00092)	Tok/s 36715 (53184)	Loss/tok 2.7754 (3.1158)	Learning Rate [7.8125e-05]
13: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00113 (0.00096)	Tok/s 37823 (54047)	Loss/tok 3.0181 (3.1137)	Learning Rate [7.8125e-05]
2: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00098)	Tok/s 36705 (53082)	Loss/tok 3.0776 (3.1121)	Learning Rate [7.8125e-05]
1: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00100)	Tok/s 36651 (52970)	Loss/tok 3.1658 (3.1120)	Learning Rate [7.8125e-05]
14: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00092)	Tok/s 37839 (54152)	Loss/tok 2.6369 (3.1148)	Learning Rate [7.8125e-05]
15: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00092)	Tok/s 37827 (54265)	Loss/tok 2.7704 (3.1127)	Learning Rate [7.8125e-05]
0: TRAIN [2][2380/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00096)	Tok/s 36628 (52875)	Loss/tok 2.9269 (3.1174)	Learning Rate [7.8125e-05]
4: TRAIN [2][2390/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 73001 (53308)	Loss/tok 2.9692 (3.1143)	Learning Rate [7.8125e-05]
5: TRAIN [2][2390/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 72996 (53394)	Loss/tok 3.0937 (3.1128)	Learning Rate [7.8125e-05]
3: TRAIN [2][2390/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 73010 (53212)	Loss/tok 3.0516 (3.1157)	Learning Rate [7.8125e-05]
7: TRAIN [2][2390/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00097)	Tok/s 72810 (53559)	Loss/tok 3.1804 (3.1157)	Learning Rate [7.8125e-05]
2: TRAIN [2][2390/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00098)	Tok/s 72086 (53110)	Loss/tok 3.0939 (3.1120)	Learning Rate [7.8125e-05]
8: TRAIN [2][2390/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 72708 (53631)	Loss/tok 3.1115 (3.1151)	Learning Rate [7.8125e-05]
6: TRAIN [2][2390/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 72965 (53468)	Loss/tok 3.1325 (3.1171)	Learning Rate [7.8125e-05]
1: TRAIN [2][2390/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 71814 (52998)	Loss/tok 3.1239 (3.1122)	Learning Rate [7.8125e-05]
9: TRAIN [2][2390/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 72604 (53699)	Loss/tok 3.1373 (3.1101)	Learning Rate [7.8125e-05]
0: TRAIN [2][2390/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 71684 (52903)	Loss/tok 3.1842 (3.1172)	Learning Rate [7.8125e-05]
10: TRAIN [2][2390/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 72533 (53776)	Loss/tok 3.1809 (3.1076)	Learning Rate [7.8125e-05]
15: TRAIN [2][2390/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 73457 (54294)	Loss/tok 3.1090 (3.1125)	Learning Rate [7.8125e-05]
14: TRAIN [2][2390/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 73447 (54181)	Loss/tok 3.2644 (3.1147)	Learning Rate [7.8125e-05]
11: TRAIN [2][2390/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 72515 (53856)	Loss/tok 3.2510 (3.1155)	Learning Rate [7.8125e-05]
13: TRAIN [2][2390/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00096)	Tok/s 73282 (54077)	Loss/tok 2.9428 (3.1134)	Learning Rate [7.8125e-05]
12: TRAIN [2][2390/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 72500 (53979)	Loss/tok 3.1738 (3.1188)	Learning Rate [7.8125e-05]
2: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00098)	Tok/s 51353 (53098)	Loss/tok 3.1789 (3.1118)	Learning Rate [7.8125e-05]
4: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00098)	Tok/s 51387 (53296)	Loss/tok 3.1522 (3.1144)	Learning Rate [7.8125e-05]
1: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00100)	Tok/s 51248 (52986)	Loss/tok 2.8540 (3.1122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00096)	Tok/s 51150 (52891)	Loss/tok 2.9622 (3.1171)	Learning Rate [7.8125e-05]
5: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00093)	Tok/s 51297 (53382)	Loss/tok 2.8148 (3.1127)	Learning Rate [7.8125e-05]
3: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00081 (0.00092)	Tok/s 51435 (53199)	Loss/tok 2.9519 (3.1154)	Learning Rate [7.8125e-05]
6: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00092)	Tok/s 51153 (53455)	Loss/tok 3.1360 (3.1172)	Learning Rate [7.8125e-05]
7: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 51088 (53546)	Loss/tok 2.9120 (3.1155)	Learning Rate [7.8125e-05]
8: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00097)	Tok/s 50943 (53618)	Loss/tok 3.1412 (3.1151)	Learning Rate [7.8125e-05]
15: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 50988 (54280)	Loss/tok 3.1033 (3.1123)	Learning Rate [7.8125e-05]
9: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00091)	Tok/s 50831 (53685)	Loss/tok 2.8050 (3.1101)	Learning Rate [7.8125e-05]
11: TRAIN [2][2400/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00092)	Tok/s 50685 (53842)	Loss/tok 3.1657 (3.1153)	Learning Rate [7.8125e-05]
13: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00096)	Tok/s 50694 (54062)	Loss/tok 2.9916 (3.1133)	Learning Rate [7.8125e-05]
12: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00108 (0.00100)	Tok/s 50735 (53965)	Loss/tok 2.9767 (3.1187)	Learning Rate [7.8125e-05]
10: TRAIN [2][2400/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00096)	Tok/s 50754 (53762)	Loss/tok 2.9793 (3.1077)	Learning Rate [7.8125e-05]
14: TRAIN [2][2400/3416]	Time 0.051 (0.058)	Data 0.00081 (0.00092)	Tok/s 49984 (54166)	Loss/tok 2.9436 (3.1143)	Learning Rate [7.8125e-05]
4: TRAIN [2][2410/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00098)	Tok/s 54605 (53276)	Loss/tok 3.2665 (3.1143)	Learning Rate [7.8125e-05]
3: TRAIN [2][2410/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00092)	Tok/s 54503 (53180)	Loss/tok 3.2242 (3.1152)	Learning Rate [7.8125e-05]
6: TRAIN [2][2410/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00092)	Tok/s 54576 (53435)	Loss/tok 3.0619 (3.1171)	Learning Rate [7.8125e-05]
2: TRAIN [2][2410/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00098)	Tok/s 53684 (53077)	Loss/tok 2.9663 (3.1115)	Learning Rate [7.8125e-05]
1: TRAIN [2][2410/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00100)	Tok/s 53324 (52964)	Loss/tok 3.0005 (3.1122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2410/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00096)	Tok/s 53244 (52870)	Loss/tok 3.1934 (3.1168)	Learning Rate [7.8125e-05]
7: TRAIN [2][2410/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00097)	Tok/s 54545 (53526)	Loss/tok 3.0811 (3.1153)	Learning Rate [7.8125e-05]
5: TRAIN [2][2410/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00093)	Tok/s 54564 (53362)	Loss/tok 3.2554 (3.1124)	Learning Rate [7.8125e-05]
8: TRAIN [2][2410/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00097)	Tok/s 54461 (53598)	Loss/tok 3.0970 (3.1148)	Learning Rate [7.8125e-05]
15: TRAIN [2][2410/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00092)	Tok/s 54219 (54258)	Loss/tok 3.1372 (3.1123)	Learning Rate [7.8125e-05]
9: TRAIN [2][2410/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00091)	Tok/s 54387 (53665)	Loss/tok 3.1409 (3.1102)	Learning Rate [7.8125e-05]
14: TRAIN [2][2410/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00092)	Tok/s 54211 (54145)	Loss/tok 3.2720 (3.1141)	Learning Rate [7.8125e-05]
10: TRAIN [2][2410/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00096)	Tok/s 54280 (53742)	Loss/tok 3.2701 (3.1080)	Learning Rate [7.8125e-05]
11: TRAIN [2][2410/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00092)	Tok/s 54222 (53821)	Loss/tok 3.2304 (3.1150)	Learning Rate [7.8125e-05]
12: TRAIN [2][2410/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00100)	Tok/s 54176 (53943)	Loss/tok 3.2189 (3.1183)	Learning Rate [7.8125e-05]
13: TRAIN [2][2410/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00096)	Tok/s 54265 (54041)	Loss/tok 3.2496 (3.1133)	Learning Rate [7.8125e-05]
3: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00092)	Tok/s 56851 (53184)	Loss/tok 3.4480 (3.1155)	Learning Rate [7.8125e-05]
9: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00091)	Tok/s 57627 (53668)	Loss/tok 3.2138 (3.1104)	Learning Rate [7.8125e-05]
6: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 56857 (53439)	Loss/tok 3.3002 (3.1174)	Learning Rate [7.8125e-05]
4: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00098)	Tok/s 56801 (53280)	Loss/tok 3.2653 (3.1146)	Learning Rate [7.8125e-05]
5: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00093)	Tok/s 56873 (53366)	Loss/tok 3.3501 (3.1125)	Learning Rate [7.8125e-05]
1: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00100)	Tok/s 56710 (52969)	Loss/tok 3.3296 (3.1124)	Learning Rate [7.8125e-05]
8: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00097)	Tok/s 56773 (53601)	Loss/tok 3.0278 (3.1148)	Learning Rate [7.8125e-05]
10: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00096)	Tok/s 57642 (53745)	Loss/tok 3.3203 (3.1080)	Learning Rate [7.8125e-05]
7: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00097)	Tok/s 56752 (53529)	Loss/tok 3.2886 (3.1152)	Learning Rate [7.8125e-05]
11: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00092)	Tok/s 57545 (53824)	Loss/tok 2.9820 (3.1150)	Learning Rate [7.8125e-05]
0: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00096)	Tok/s 56696 (52875)	Loss/tok 3.3551 (3.1170)	Learning Rate [7.8125e-05]
15: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00092)	Tok/s 57628 (54261)	Loss/tok 3.2517 (3.1128)	Learning Rate [7.8125e-05]
12: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00100)	Tok/s 57486 (53945)	Loss/tok 3.0686 (3.1184)	Learning Rate [7.8125e-05]
13: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00096)	Tok/s 57506 (54043)	Loss/tok 3.2804 (3.1135)	Learning Rate [7.8125e-05]
14: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 57549 (54148)	Loss/tok 3.2023 (3.1141)	Learning Rate [7.8125e-05]
2: TRAIN [2][2420/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00098)	Tok/s 56451 (53081)	Loss/tok 3.0273 (3.1114)	Learning Rate [7.8125e-05]
13: TRAIN [2][2430/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00096)	Tok/s 52428 (54041)	Loss/tok 3.0364 (3.1136)	Learning Rate [7.8125e-05]
11: TRAIN [2][2430/3416]	Time 0.057 (0.058)	Data 0.00086 (0.00092)	Tok/s 51387 (53823)	Loss/tok 3.0734 (3.1154)	Learning Rate [7.8125e-05]
14: TRAIN [2][2430/3416]	Time 0.057 (0.058)	Data 0.00086 (0.00092)	Tok/s 52374 (54146)	Loss/tok 3.1222 (3.1141)	Learning Rate [7.8125e-05]
15: TRAIN [2][2430/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00092)	Tok/s 52369 (54259)	Loss/tok 2.9983 (3.1129)	Learning Rate [7.8125e-05]
0: TRAIN [2][2430/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00096)	Tok/s 51218 (52875)	Loss/tok 2.9081 (3.1167)	Learning Rate [7.8125e-05]
10: TRAIN [2][2430/3416]	Time 0.057 (0.058)	Data 0.00099 (0.00096)	Tok/s 51372 (53743)	Loss/tok 2.9818 (3.1080)	Learning Rate [7.8125e-05]
9: TRAIN [2][2430/3416]	Time 0.057 (0.058)	Data 0.00082 (0.00091)	Tok/s 51306 (53667)	Loss/tok 3.1647 (3.1102)	Learning Rate [7.8125e-05]
8: TRAIN [2][2430/3416]	Time 0.057 (0.058)	Data 0.00099 (0.00097)	Tok/s 51344 (53600)	Loss/tok 3.0301 (3.1148)	Learning Rate [7.8125e-05]
1: TRAIN [2][2430/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00100)	Tok/s 51197 (52969)	Loss/tok 3.1846 (3.1125)	Learning Rate [7.8125e-05]
2: TRAIN [2][2430/3416]	Time 0.057 (0.058)	Data 0.00105 (0.00098)	Tok/s 51233 (53081)	Loss/tok 2.8059 (3.1114)	Learning Rate [7.8125e-05]
6: TRAIN [2][2430/3416]	Time 0.057 (0.058)	Data 0.00084 (0.00092)	Tok/s 51314 (53439)	Loss/tok 3.1082 (3.1173)	Learning Rate [7.8125e-05]
7: TRAIN [2][2430/3416]	Time 0.057 (0.058)	Data 0.00084 (0.00097)	Tok/s 51335 (53529)	Loss/tok 3.1878 (3.1153)	Learning Rate [7.8125e-05]
3: TRAIN [2][2430/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00092)	Tok/s 51273 (53183)	Loss/tok 3.1535 (3.1157)	Learning Rate [7.8125e-05]
5: TRAIN [2][2430/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00093)	Tok/s 51310 (53366)	Loss/tok 3.0617 (3.1125)	Learning Rate [7.8125e-05]
12: TRAIN [2][2430/3416]	Time 0.058 (0.058)	Data 0.00116 (0.00100)	Tok/s 50983 (53943)	Loss/tok 3.2359 (3.1185)	Learning Rate [7.8125e-05]
4: TRAIN [2][2430/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00098)	Tok/s 50627 (53280)	Loss/tok 2.9896 (3.1149)	Learning Rate [7.8125e-05]
6: TRAIN [2][2440/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00092)	Tok/s 40344 (53407)	Loss/tok 3.0877 (3.1170)	Learning Rate [7.8125e-05]
7: TRAIN [2][2440/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00097)	Tok/s 40421 (53497)	Loss/tok 2.9183 (3.1149)	Learning Rate [7.8125e-05]
8: TRAIN [2][2440/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00097)	Tok/s 41074 (53569)	Loss/tok 3.0849 (3.1144)	Learning Rate [7.8125e-05]
4: TRAIN [2][2440/3416]	Time 0.048 (0.058)	Data 0.00107 (0.00098)	Tok/s 40207 (53248)	Loss/tok 2.8605 (3.1142)	Learning Rate [7.8125e-05]
5: TRAIN [2][2440/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00093)	Tok/s 40210 (53333)	Loss/tok 2.8861 (3.1124)	Learning Rate [7.8125e-05]
9: TRAIN [2][2440/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00091)	Tok/s 41730 (53636)	Loss/tok 2.9379 (3.1099)	Learning Rate [7.8125e-05]
13: TRAIN [2][2440/3416]	Time 0.048 (0.058)	Data 0.00113 (0.00096)	Tok/s 41690 (54009)	Loss/tok 3.0660 (3.1133)	Learning Rate [7.8125e-05]
3: TRAIN [2][2440/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00092)	Tok/s 40040 (53151)	Loss/tok 2.8958 (3.1153)	Learning Rate [7.8125e-05]
14: TRAIN [2][2440/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00092)	Tok/s 41525 (54114)	Loss/tok 2.9890 (3.1139)	Learning Rate [7.8125e-05]
2: TRAIN [2][2440/3416]	Time 0.048 (0.058)	Data 0.00125 (0.00098)	Tok/s 40000 (53049)	Loss/tok 2.8918 (3.1113)	Learning Rate [7.8125e-05]
11: TRAIN [2][2440/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00092)	Tok/s 41654 (53791)	Loss/tok 2.8839 (3.1150)	Learning Rate [7.8125e-05]
12: TRAIN [2][2440/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00100)	Tok/s 41672 (53911)	Loss/tok 2.8730 (3.1182)	Learning Rate [7.8125e-05]
10: TRAIN [2][2440/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00096)	Tok/s 41852 (53712)	Loss/tok 3.0510 (3.1079)	Learning Rate [7.8125e-05]
15: TRAIN [2][2440/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00092)	Tok/s 41427 (54226)	Loss/tok 2.7441 (3.1126)	Learning Rate [7.8125e-05]
1: TRAIN [2][2440/3416]	Time 0.048 (0.058)	Data 0.00110 (0.00100)	Tok/s 40002 (52937)	Loss/tok 2.7996 (3.1122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2440/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00096)	Tok/s 40043 (52843)	Loss/tok 2.8342 (3.1166)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
12: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00100)	Tok/s 53404 (53913)	Loss/tok 2.9608 (3.1180)	Learning Rate [7.8125e-05]
11: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 53245 (53793)	Loss/tok 3.1250 (3.1148)	Learning Rate [7.8125e-05]
13: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00096)	Tok/s 53319 (54010)	Loss/tok 2.9557 (3.1129)	Learning Rate [7.8125e-05]
10: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00096)	Tok/s 53150 (53714)	Loss/tok 2.9661 (3.1079)	Learning Rate [7.8125e-05]
14: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00092)	Tok/s 53215 (54115)	Loss/tok 3.0585 (3.1140)	Learning Rate [7.8125e-05]
8: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00097)	Tok/s 52959 (53572)	Loss/tok 3.0590 (3.1139)	Learning Rate [7.8125e-05]
9: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00091)	Tok/s 53039 (53638)	Loss/tok 3.1444 (3.1100)	Learning Rate [7.8125e-05]
0: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00096)	Tok/s 53011 (52846)	Loss/tok 3.0076 (3.1161)	Learning Rate [7.8125e-05]
15: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00092)	Tok/s 53110 (54227)	Loss/tok 3.0778 (3.1123)	Learning Rate [7.8125e-05]
1: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00100)	Tok/s 52927 (52940)	Loss/tok 3.1888 (3.1123)	Learning Rate [7.8125e-05]
2: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00098)	Tok/s 52853 (53051)	Loss/tok 3.0864 (3.1109)	Learning Rate [7.8125e-05]
6: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00081 (0.00092)	Tok/s 52702 (53409)	Loss/tok 2.9610 (3.1168)	Learning Rate [7.8125e-05]
3: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 52739 (53153)	Loss/tok 2.8840 (3.1153)	Learning Rate [7.8125e-05]
7: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00097)	Tok/s 52787 (53499)	Loss/tok 2.8373 (3.1146)	Learning Rate [7.8125e-05]
5: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00093)	Tok/s 52589 (53335)	Loss/tok 3.0674 (3.1124)	Learning Rate [7.8125e-05]
4: TRAIN [2][2450/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00098)	Tok/s 52601 (53250)	Loss/tok 3.3713 (3.1141)	Learning Rate [7.8125e-05]
6: TRAIN [2][2460/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 63505 (53407)	Loss/tok 3.2110 (3.1169)	Learning Rate [7.8125e-05]
5: TRAIN [2][2460/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 63570 (53333)	Loss/tok 3.0644 (3.1126)	Learning Rate [7.8125e-05]
7: TRAIN [2][2460/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 63393 (53497)	Loss/tok 3.4485 (3.1149)	Learning Rate [7.8125e-05]
4: TRAIN [2][2460/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 63556 (53248)	Loss/tok 3.2458 (3.1144)	Learning Rate [7.8125e-05]
3: TRAIN [2][2460/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 63590 (53151)	Loss/tok 3.5316 (3.1155)	Learning Rate [7.8125e-05]
8: TRAIN [2][2460/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 63428 (53570)	Loss/tok 3.1605 (3.1138)	Learning Rate [7.8125e-05]
2: TRAIN [2][2460/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 63623 (53048)	Loss/tok 2.9617 (3.1107)	Learning Rate [7.8125e-05]
1: TRAIN [2][2460/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 63318 (52936)	Loss/tok 3.0214 (3.1122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2460/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00096)	Tok/s 62695 (52840)	Loss/tok 3.3908 (3.1164)	Learning Rate [7.8125e-05]
10: TRAIN [2][2460/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00096)	Tok/s 63475 (53713)	Loss/tok 3.1226 (3.1078)	Learning Rate [7.8125e-05]
9: TRAIN [2][2460/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00091)	Tok/s 63461 (53637)	Loss/tok 3.2780 (3.1105)	Learning Rate [7.8125e-05]
15: TRAIN [2][2460/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 63595 (54227)	Loss/tok 3.4134 (3.1122)	Learning Rate [7.8125e-05]
11: TRAIN [2][2460/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 63433 (53791)	Loss/tok 3.2433 (3.1149)	Learning Rate [7.8125e-05]
14: TRAIN [2][2460/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00092)	Tok/s 63554 (54114)	Loss/tok 3.2596 (3.1143)	Learning Rate [7.8125e-05]
13: TRAIN [2][2460/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 63459 (54009)	Loss/tok 3.2417 (3.1127)	Learning Rate [7.8125e-05]
12: TRAIN [2][2460/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00100)	Tok/s 63430 (53912)	Loss/tok 2.9399 (3.1181)	Learning Rate [7.8125e-05]
3: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 77217 (53130)	Loss/tok 3.1663 (3.1152)	Learning Rate [7.8125e-05]
2: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 76695 (53027)	Loss/tok 3.0896 (3.1105)	Learning Rate [7.8125e-05]
1: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00100)	Tok/s 76330 (52914)	Loss/tok 3.2715 (3.1120)	Learning Rate [7.8125e-05]
4: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 77052 (53228)	Loss/tok 3.0311 (3.1142)	Learning Rate [7.8125e-05]
5: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00093)	Tok/s 77105 (53312)	Loss/tok 2.9016 (3.1122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 76313 (52820)	Loss/tok 3.0080 (3.1161)	Learning Rate [7.8125e-05]
15: TRAIN [2][2470/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00092)	Tok/s 80256 (54207)	Loss/tok 2.9388 (3.1118)	Learning Rate [7.8125e-05]
6: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 77100 (53387)	Loss/tok 3.0749 (3.1166)	Learning Rate [7.8125e-05]
7: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00097)	Tok/s 77121 (53477)	Loss/tok 3.2212 (3.1145)	Learning Rate [7.8125e-05]
8: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 77143 (53550)	Loss/tok 3.1162 (3.1136)	Learning Rate [7.8125e-05]
9: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00091)	Tok/s 77206 (53616)	Loss/tok 3.0336 (3.1100)	Learning Rate [7.8125e-05]
13: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 78199 (53988)	Loss/tok 3.0733 (3.1126)	Learning Rate [7.8125e-05]
11: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00092)	Tok/s 78059 (53771)	Loss/tok 2.9707 (3.1143)	Learning Rate [7.8125e-05]
12: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00100)	Tok/s 78079 (53891)	Loss/tok 3.2181 (3.1178)	Learning Rate [7.8125e-05]
10: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 77756 (53692)	Loss/tok 3.1483 (3.1076)	Learning Rate [7.8125e-05]
14: TRAIN [2][2470/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 78144 (54094)	Loss/tok 3.2187 (3.1140)	Learning Rate [7.8125e-05]
6: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00081 (0.00092)	Tok/s 27593 (53392)	Loss/tok 2.3809 (3.1166)	Learning Rate [7.8125e-05]
4: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00091 (0.00098)	Tok/s 27266 (53233)	Loss/tok 2.3993 (3.1143)	Learning Rate [7.8125e-05]
7: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00086 (0.00097)	Tok/s 28868 (53483)	Loss/tok 2.2973 (3.1142)	Learning Rate [7.8125e-05]
8: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00093 (0.00097)	Tok/s 28921 (53555)	Loss/tok 2.5508 (3.1136)	Learning Rate [7.8125e-05]
5: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00087 (0.00093)	Tok/s 27124 (53318)	Loss/tok 2.3882 (3.1124)	Learning Rate [7.8125e-05]
3: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00088 (0.00092)	Tok/s 27156 (53136)	Loss/tok 2.2282 (3.1149)	Learning Rate [7.8125e-05]
9: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00082 (0.00091)	Tok/s 28836 (53622)	Loss/tok 2.3858 (3.1100)	Learning Rate [7.8125e-05]
1: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00094 (0.00100)	Tok/s 25526 (52920)	Loss/tok 2.2028 (3.1118)	Learning Rate [7.8125e-05]
2: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00107 (0.00098)	Tok/s 26549 (53032)	Loss/tok 2.3800 (3.1105)	Learning Rate [7.8125e-05]
10: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00102 (0.00096)	Tok/s 28827 (53698)	Loss/tok 2.1790 (3.1074)	Learning Rate [7.8125e-05]
11: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00089 (0.00092)	Tok/s 28870 (53777)	Loss/tok 2.4015 (3.1143)	Learning Rate [7.8125e-05]
0: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00099 (0.00096)	Tok/s 25501 (52825)	Loss/tok 2.0120 (3.1160)	Learning Rate [7.8125e-05]
15: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00088 (0.00092)	Tok/s 30573 (54213)	Loss/tok 2.2979 (3.1118)	Learning Rate [7.8125e-05]
13: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00107 (0.00096)	Tok/s 30233 (53994)	Loss/tok 2.3840 (3.1123)	Learning Rate [7.8125e-05]
12: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00088 (0.00100)	Tok/s 28820 (53896)	Loss/tok 2.2456 (3.1174)	Learning Rate [7.8125e-05]
14: TRAIN [2][2480/3416]	Time 0.038 (0.058)	Data 0.00093 (0.00092)	Tok/s 30550 (54100)	Loss/tok 2.5667 (3.1141)	Learning Rate [7.8125e-05]
10: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00096)	Tok/s 39049 (53687)	Loss/tok 2.9230 (3.1074)	Learning Rate [7.8125e-05]
8: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00097)	Tok/s 38938 (53544)	Loss/tok 3.0311 (3.1138)	Learning Rate [7.8125e-05]
7: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 38607 (53472)	Loss/tok 2.9279 (3.1143)	Learning Rate [7.8125e-05]
6: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00092)	Tok/s 37627 (53381)	Loss/tok 3.0008 (3.1165)	Learning Rate [7.8125e-05]
9: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00091)	Tok/s 38880 (53611)	Loss/tok 2.9548 (3.1099)	Learning Rate [7.8125e-05]
11: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 38960 (53766)	Loss/tok 2.9725 (3.1141)	Learning Rate [7.8125e-05]
12: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00100)	Tok/s 39006 (53885)	Loss/tok 2.6722 (3.1175)	Learning Rate [7.8125e-05]
13: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00096)	Tok/s 38939 (53982)	Loss/tok 2.9316 (3.1121)	Learning Rate [7.8125e-05]
4: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00098)	Tok/s 37510 (53223)	Loss/tok 3.1379 (3.1146)	Learning Rate [7.8125e-05]
5: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00093)	Tok/s 37543 (53307)	Loss/tok 2.8277 (3.1127)	Learning Rate [7.8125e-05]
3: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00092)	Tok/s 37396 (53126)	Loss/tok 2.8966 (3.1149)	Learning Rate [7.8125e-05]
0: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00096)	Tok/s 37499 (52816)	Loss/tok 2.8781 (3.1158)	Learning Rate [7.8125e-05]
1: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00100)	Tok/s 37448 (52910)	Loss/tok 3.0016 (3.1120)	Learning Rate [7.8125e-05]
15: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00092)	Tok/s 38716 (54201)	Loss/tok 2.9063 (3.1115)	Learning Rate [7.8125e-05]
2: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00098)	Tok/s 37443 (53023)	Loss/tok 2.9140 (3.1105)	Learning Rate [7.8125e-05]
14: TRAIN [2][2490/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00092)	Tok/s 38888 (54088)	Loss/tok 2.9097 (3.1142)	Learning Rate [7.8125e-05]
3: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00086 (0.00092)	Tok/s 52520 (53094)	Loss/tok 3.1041 (3.1146)	Learning Rate [7.8125e-05]
4: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00086 (0.00098)	Tok/s 52377 (53191)	Loss/tok 3.1700 (3.1144)	Learning Rate [7.8125e-05]
2: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00098)	Tok/s 52478 (52991)	Loss/tok 3.1856 (3.1101)	Learning Rate [7.8125e-05]
1: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00100)	Tok/s 52485 (52879)	Loss/tok 3.2148 (3.1117)	Learning Rate [7.8125e-05]
11: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00105 (0.00092)	Tok/s 53779 (53733)	Loss/tok 3.2435 (3.1140)	Learning Rate [7.8125e-05]
6: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00083 (0.00092)	Tok/s 53483 (53349)	Loss/tok 3.1030 (3.1163)	Learning Rate [7.8125e-05]
9: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00091)	Tok/s 53711 (53579)	Loss/tok 3.1010 (3.1098)	Learning Rate [7.8125e-05]
5: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00093)	Tok/s 53298 (53275)	Loss/tok 3.1104 (3.1126)	Learning Rate [7.8125e-05]
10: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00096)	Tok/s 53757 (53654)	Loss/tok 3.1214 (3.1072)	Learning Rate [7.8125e-05]
8: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00097)	Tok/s 53565 (53512)	Loss/tok 3.1760 (3.1135)	Learning Rate [7.8125e-05]
7: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00097)	Tok/s 53498 (53440)	Loss/tok 3.2103 (3.1142)	Learning Rate [7.8125e-05]
0: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00096)	Tok/s 52491 (52785)	Loss/tok 3.1474 (3.1158)	Learning Rate [7.8125e-05]
15: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00092)	Tok/s 53584 (54168)	Loss/tok 3.1187 (3.1113)	Learning Rate [7.8125e-05]
12: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00100)	Tok/s 53758 (53852)	Loss/tok 3.0740 (3.1173)	Learning Rate [7.8125e-05]
13: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00105 (0.00096)	Tok/s 53722 (53950)	Loss/tok 3.0243 (3.1119)	Learning Rate [7.8125e-05]
14: TRAIN [2][2500/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00092)	Tok/s 53668 (54055)	Loss/tok 3.0985 (3.1141)	Learning Rate [7.8125e-05]
2: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00098)	Tok/s 49162 (52972)	Loss/tok 2.9572 (3.1097)	Learning Rate [7.8125e-05]
4: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00098)	Tok/s 49147 (53171)	Loss/tok 3.0629 (3.1143)	Learning Rate [7.8125e-05]
3: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00092)	Tok/s 49035 (53075)	Loss/tok 3.1813 (3.1143)	Learning Rate [7.8125e-05]
1: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00100)	Tok/s 49136 (52860)	Loss/tok 2.8199 (3.1116)	Learning Rate [7.8125e-05]
5: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00093)	Tok/s 49038 (53255)	Loss/tok 2.9573 (3.1121)	Learning Rate [7.8125e-05]
0: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00113 (0.00096)	Tok/s 49085 (52766)	Loss/tok 3.1559 (3.1157)	Learning Rate [7.8125e-05]
7: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00097)	Tok/s 49049 (53419)	Loss/tok 3.1139 (3.1141)	Learning Rate [7.8125e-05]
15: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 50389 (54148)	Loss/tok 3.0389 (3.1112)	Learning Rate [7.8125e-05]
6: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00075 (0.00091)	Tok/s 48839 (53329)	Loss/tok 3.1109 (3.1159)	Learning Rate [7.8125e-05]
14: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00092)	Tok/s 49916 (54035)	Loss/tok 3.0061 (3.1137)	Learning Rate [7.8125e-05]
8: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 48993 (53491)	Loss/tok 2.8002 (3.1133)	Learning Rate [7.8125e-05]
13: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00096)	Tok/s 49047 (53930)	Loss/tok 2.9684 (3.1115)	Learning Rate [7.8125e-05]
11: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00091)	Tok/s 48999 (53713)	Loss/tok 2.9726 (3.1138)	Learning Rate [7.8125e-05]
10: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00096)	Tok/s 48955 (53634)	Loss/tok 3.1160 (3.1073)	Learning Rate [7.8125e-05]
9: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00091)	Tok/s 48895 (53558)	Loss/tok 2.9557 (3.1094)	Learning Rate [7.8125e-05]
12: TRAIN [2][2510/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00100)	Tok/s 48916 (53832)	Loss/tok 2.9173 (3.1170)	Learning Rate [7.8125e-05]
4: TRAIN [2][2520/3416]	Time 0.069 (0.058)	Data 0.00115 (0.00098)	Tok/s 58807 (53172)	Loss/tok 3.1988 (3.1142)	Learning Rate [7.8125e-05]
3: TRAIN [2][2520/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00092)	Tok/s 58895 (53076)	Loss/tok 3.2399 (3.1144)	Learning Rate [7.8125e-05]
5: TRAIN [2][2520/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 58822 (53256)	Loss/tok 3.2702 (3.1123)	Learning Rate [7.8125e-05]
6: TRAIN [2][2520/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 58591 (53330)	Loss/tok 3.3095 (3.1161)	Learning Rate [7.8125e-05]
2: TRAIN [2][2520/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00098)	Tok/s 58893 (52974)	Loss/tok 3.1113 (3.1098)	Learning Rate [7.8125e-05]
1: TRAIN [2][2520/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00100)	Tok/s 58878 (52862)	Loss/tok 3.0731 (3.1118)	Learning Rate [7.8125e-05]
7: TRAIN [2][2520/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 58596 (53421)	Loss/tok 3.0860 (3.1143)	Learning Rate [7.8125e-05]
0: TRAIN [2][2520/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00096)	Tok/s 58860 (52768)	Loss/tok 3.3901 (3.1160)	Learning Rate [7.8125e-05]
8: TRAIN [2][2520/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 58649 (53493)	Loss/tok 3.0357 (3.1131)	Learning Rate [7.8125e-05]
9: TRAIN [2][2520/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 58676 (53560)	Loss/tok 2.9829 (3.1093)	Learning Rate [7.8125e-05]
15: TRAIN [2][2520/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 59685 (54148)	Loss/tok 3.2416 (3.1112)	Learning Rate [7.8125e-05]
14: TRAIN [2][2520/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 59583 (54036)	Loss/tok 3.3517 (3.1136)	Learning Rate [7.8125e-05]
10: TRAIN [2][2520/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 58577 (53635)	Loss/tok 3.3854 (3.1074)	Learning Rate [7.8125e-05]
13: TRAIN [2][2520/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 59513 (53931)	Loss/tok 3.3216 (3.1115)	Learning Rate [7.8125e-05]
11: TRAIN [2][2520/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 58517 (53714)	Loss/tok 3.1961 (3.1138)	Learning Rate [7.8125e-05]
12: TRAIN [2][2520/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00100)	Tok/s 59112 (53833)	Loss/tok 3.2625 (3.1172)	Learning Rate [7.8125e-05]
2: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00098)	Tok/s 50936 (52987)	Loss/tok 2.9714 (3.1102)	Learning Rate [7.8125e-05]
1: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00100)	Tok/s 50962 (52876)	Loss/tok 2.8027 (3.1121)	Learning Rate [7.8125e-05]
0: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00096)	Tok/s 51023 (52783)	Loss/tok 2.9563 (3.1159)	Learning Rate [7.8125e-05]
3: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00092)	Tok/s 50825 (53089)	Loss/tok 2.9569 (3.1147)	Learning Rate [7.8125e-05]
4: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00098)	Tok/s 50711 (53185)	Loss/tok 3.1505 (3.1141)	Learning Rate [7.8125e-05]
15: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00092)	Tok/s 52122 (54161)	Loss/tok 3.0691 (3.1116)	Learning Rate [7.8125e-05]
6: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00091)	Tok/s 50726 (53343)	Loss/tok 3.0893 (3.1160)	Learning Rate [7.8125e-05]
5: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00093)	Tok/s 50674 (53269)	Loss/tok 2.9743 (3.1123)	Learning Rate [7.8125e-05]
14: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00092)	Tok/s 50934 (54048)	Loss/tok 2.9928 (3.1140)	Learning Rate [7.8125e-05]
13: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00096)	Tok/s 50971 (53944)	Loss/tok 3.2291 (3.1118)	Learning Rate [7.8125e-05]
7: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00097)	Tok/s 50656 (53433)	Loss/tok 2.9420 (3.1142)	Learning Rate [7.8125e-05]
12: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00100)	Tok/s 50899 (53846)	Loss/tok 3.0410 (3.1174)	Learning Rate [7.8125e-05]
11: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00092)	Tok/s 50813 (53726)	Loss/tok 2.8950 (3.1141)	Learning Rate [7.8125e-05]
9: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00091)	Tok/s 50712 (53572)	Loss/tok 3.0846 (3.1095)	Learning Rate [7.8125e-05]
8: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00111 (0.00097)	Tok/s 50675 (53505)	Loss/tok 3.0582 (3.1132)	Learning Rate [7.8125e-05]
10: TRAIN [2][2530/3416]	Time 0.048 (0.058)	Data 0.00113 (0.00096)	Tok/s 50793 (53647)	Loss/tok 2.9214 (3.1074)	Learning Rate [7.8125e-05]
6: TRAIN [2][2540/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00091)	Tok/s 53628 (53351)	Loss/tok 3.3727 (3.1165)	Learning Rate [7.8125e-05]
5: TRAIN [2][2540/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00093)	Tok/s 53617 (53277)	Loss/tok 3.0319 (3.1127)	Learning Rate [7.8125e-05]
4: TRAIN [2][2540/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00098)	Tok/s 53580 (53193)	Loss/tok 2.8896 (3.1143)	Learning Rate [7.8125e-05]
3: TRAIN [2][2540/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00092)	Tok/s 53457 (53097)	Loss/tok 3.1025 (3.1150)	Learning Rate [7.8125e-05]
2: TRAIN [2][2540/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00098)	Tok/s 53378 (52996)	Loss/tok 3.0741 (3.1105)	Learning Rate [7.8125e-05]
8: TRAIN [2][2540/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00097)	Tok/s 54098 (53513)	Loss/tok 3.2563 (3.1133)	Learning Rate [7.8125e-05]
9: TRAIN [2][2540/3416]	Time 0.064 (0.058)	Data 0.00083 (0.00091)	Tok/s 54421 (53579)	Loss/tok 3.1495 (3.1100)	Learning Rate [7.8125e-05]
0: TRAIN [2][2540/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00096)	Tok/s 53165 (52791)	Loss/tok 3.1325 (3.1163)	Learning Rate [7.8125e-05]
10: TRAIN [2][2540/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00096)	Tok/s 54341 (53655)	Loss/tok 3.1423 (3.1080)	Learning Rate [7.8125e-05]
15: TRAIN [2][2540/3416]	Time 0.064 (0.058)	Data 0.00082 (0.00092)	Tok/s 54086 (54166)	Loss/tok 3.0715 (3.1118)	Learning Rate [7.8125e-05]
11: TRAIN [2][2540/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00091)	Tok/s 54252 (53733)	Loss/tok 3.1701 (3.1138)	Learning Rate [7.8125e-05]
12: TRAIN [2][2540/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00100)	Tok/s 54159 (53852)	Loss/tok 3.0311 (3.1173)	Learning Rate [7.8125e-05]
13: TRAIN [2][2540/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00096)	Tok/s 54104 (53950)	Loss/tok 3.3644 (3.1120)	Learning Rate [7.8125e-05]
14: TRAIN [2][2540/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00092)	Tok/s 54082 (54054)	Loss/tok 3.4857 (3.1142)	Learning Rate [7.8125e-05]
7: TRAIN [2][2540/3416]	Time 0.063 (0.058)	Data 0.00107 (0.00097)	Tok/s 53561 (53440)	Loss/tok 3.0404 (3.1145)	Learning Rate [7.8125e-05]
1: TRAIN [2][2540/3416]	Time 0.064 (0.058)	Data 0.00119 (0.00100)	Tok/s 53251 (52884)	Loss/tok 3.2401 (3.1124)	Learning Rate [7.8125e-05]
4: TRAIN [2][2550/3416]	Time 0.064 (0.058)	Data 0.00101 (0.00098)	Tok/s 54808 (53183)	Loss/tok 3.1396 (3.1146)	Learning Rate [7.8125e-05]
6: TRAIN [2][2550/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00091)	Tok/s 54656 (53340)	Loss/tok 3.1059 (3.1164)	Learning Rate [7.8125e-05]
5: TRAIN [2][2550/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00093)	Tok/s 54752 (53267)	Loss/tok 3.2926 (3.1128)	Learning Rate [7.8125e-05]
2: TRAIN [2][2550/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00098)	Tok/s 54695 (52986)	Loss/tok 2.9492 (3.1107)	Learning Rate [7.8125e-05]
1: TRAIN [2][2550/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00100)	Tok/s 54665 (52875)	Loss/tok 3.2869 (3.1124)	Learning Rate [7.8125e-05]
3: TRAIN [2][2550/3416]	Time 0.064 (0.058)	Data 0.00117 (0.00092)	Tok/s 55116 (53087)	Loss/tok 3.1848 (3.1152)	Learning Rate [7.8125e-05]
7: TRAIN [2][2550/3416]	Time 0.065 (0.058)	Data 0.00111 (0.00097)	Tok/s 54538 (53430)	Loss/tok 3.2057 (3.1146)	Learning Rate [7.8125e-05]
0: TRAIN [2][2550/3416]	Time 0.065 (0.058)	Data 0.00104 (0.00096)	Tok/s 54570 (52781)	Loss/tok 3.1658 (3.1160)	Learning Rate [7.8125e-05]
8: TRAIN [2][2550/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00097)	Tok/s 54478 (53502)	Loss/tok 3.2135 (3.1134)	Learning Rate [7.8125e-05]
15: TRAIN [2][2550/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00092)	Tok/s 54516 (54156)	Loss/tok 3.5134 (3.1121)	Learning Rate [7.8125e-05]
9: TRAIN [2][2550/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00091)	Tok/s 54395 (53568)	Loss/tok 3.0680 (3.1099)	Learning Rate [7.8125e-05]
10: TRAIN [2][2550/3416]	Time 0.065 (0.058)	Data 0.00086 (0.00096)	Tok/s 54357 (53644)	Loss/tok 3.2474 (3.1080)	Learning Rate [7.8125e-05]
14: TRAIN [2][2550/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00092)	Tok/s 54414 (54044)	Loss/tok 3.0639 (3.1144)	Learning Rate [7.8125e-05]
13: TRAIN [2][2550/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00096)	Tok/s 54300 (53939)	Loss/tok 2.9964 (3.1120)	Learning Rate [7.8125e-05]
11: TRAIN [2][2550/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00091)	Tok/s 54297 (53722)	Loss/tok 3.1959 (3.1138)	Learning Rate [7.8125e-05]
12: TRAIN [2][2550/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00100)	Tok/s 54222 (53842)	Loss/tok 3.1688 (3.1174)	Learning Rate [7.8125e-05]
6: TRAIN [2][2560/3416]	Time 0.049 (0.058)	Data 0.00075 (0.00091)	Tok/s 51819 (53331)	Loss/tok 2.9546 (3.1163)	Learning Rate [7.8125e-05]
7: TRAIN [2][2560/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00097)	Tok/s 51815 (53420)	Loss/tok 2.9983 (3.1146)	Learning Rate [7.8125e-05]
4: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00098)	Tok/s 50513 (53174)	Loss/tok 2.9073 (3.1144)	Learning Rate [7.8125e-05]
2: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00098)	Tok/s 50190 (52977)	Loss/tok 3.0598 (3.1109)	Learning Rate [7.8125e-05]
3: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00092)	Tok/s 50196 (53078)	Loss/tok 3.0466 (3.1155)	Learning Rate [7.8125e-05]
9: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00091)	Tok/s 51546 (53558)	Loss/tok 2.9401 (3.1100)	Learning Rate [7.8125e-05]
11: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00091)	Tok/s 51411 (53711)	Loss/tok 3.2374 (3.1138)	Learning Rate [7.8125e-05]
5: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00093)	Tok/s 51662 (53257)	Loss/tok 3.1889 (3.1129)	Learning Rate [7.8125e-05]
10: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00096)	Tok/s 51505 (53633)	Loss/tok 3.3586 (3.1083)	Learning Rate [7.8125e-05]
8: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00097)	Tok/s 51513 (53492)	Loss/tok 2.9013 (3.1134)	Learning Rate [7.8125e-05]
0: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00096)	Tok/s 50004 (52773)	Loss/tok 3.0840 (3.1160)	Learning Rate [7.8125e-05]
1: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00100)	Tok/s 50005 (52866)	Loss/tok 2.8511 (3.1125)	Learning Rate [7.8125e-05]
15: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00092)	Tok/s 51257 (54145)	Loss/tok 3.1081 (3.1123)	Learning Rate [7.8125e-05]
12: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00100)	Tok/s 51132 (53831)	Loss/tok 3.0855 (3.1172)	Learning Rate [7.8125e-05]
13: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00096)	Tok/s 51121 (53929)	Loss/tok 3.0627 (3.1120)	Learning Rate [7.8125e-05]
14: TRAIN [2][2560/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 51162 (54033)	Loss/tok 2.9302 (3.1147)	Learning Rate [7.8125e-05]
4: TRAIN [2][2570/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00098)	Tok/s 70429 (53174)	Loss/tok 3.0949 (3.1145)	Learning Rate [7.8125e-05]
5: TRAIN [2][2570/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00093)	Tok/s 70487 (53258)	Loss/tok 3.1195 (3.1128)	Learning Rate [7.8125e-05]
6: TRAIN [2][2570/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00091)	Tok/s 70442 (53331)	Loss/tok 3.1375 (3.1164)	Learning Rate [7.8125e-05]
9: TRAIN [2][2570/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 71296 (53558)	Loss/tok 3.1834 (3.1099)	Learning Rate [7.8125e-05]
3: TRAIN [2][2570/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 70355 (53079)	Loss/tok 2.9639 (3.1152)	Learning Rate [7.8125e-05]
2: TRAIN [2][2570/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 70216 (52978)	Loss/tok 3.1375 (3.1112)	Learning Rate [7.8125e-05]
1: TRAIN [2][2570/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 70148 (52867)	Loss/tok 3.1067 (3.1123)	Learning Rate [7.8125e-05]
7: TRAIN [2][2570/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00097)	Tok/s 70494 (53420)	Loss/tok 3.0432 (3.1149)	Learning Rate [7.8125e-05]
11: TRAIN [2][2570/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00091)	Tok/s 71127 (53711)	Loss/tok 3.1617 (3.1140)	Learning Rate [7.8125e-05]
8: TRAIN [2][2570/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 71312 (53492)	Loss/tok 3.1421 (3.1136)	Learning Rate [7.8125e-05]
10: TRAIN [2][2570/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00096)	Tok/s 71176 (53633)	Loss/tok 3.0074 (3.1085)	Learning Rate [7.8125e-05]
0: TRAIN [2][2570/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 69964 (52774)	Loss/tok 3.5388 (3.1161)	Learning Rate [7.8125e-05]
15: TRAIN [2][2570/3416]	Time 0.070 (0.058)	Data 0.00220 (0.00092)	Tok/s 70774 (54144)	Loss/tok 3.2631 (3.1126)	Learning Rate [7.8125e-05]
12: TRAIN [2][2570/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 71016 (53831)	Loss/tok 3.1441 (3.1174)	Learning Rate [7.8125e-05]
13: TRAIN [2][2570/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 70822 (53928)	Loss/tok 3.0033 (3.1118)	Learning Rate [7.8125e-05]
14: TRAIN [2][2570/3416]	Time 0.071 (0.058)	Data 0.00078 (0.00092)	Tok/s 69747 (54032)	Loss/tok 3.3293 (3.1149)	Learning Rate [7.8125e-05]
4: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
5: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
6: Upscaling, new scale: 8192.0
7: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
8: Upscaling, new scale: 8192.0
15: Upscaling, new scale: 8192.0
10: Upscaling, new scale: 8192.0
14: Upscaling, new scale: 8192.0
9: Upscaling, new scale: 8192.0
13: Upscaling, new scale: 8192.0
11: Upscaling, new scale: 8192.0
12: Upscaling, new scale: 8192.0
2: Gradient norm: inf
1: Gradient norm: inf
2: Skipped batch, new scale: 4096.0
3: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
4: Gradient norm: inf
3: Skipped batch, new scale: 4096.0
15: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
4: Skipped batch, new scale: 4096.0
5: Gradient norm: inf
14: Gradient norm: inf
15: Skipped batch, new scale: 4096.0
6: Gradient norm: inf
5: Skipped batch, new scale: 4096.0
14: Skipped batch, new scale: 4096.0
13: Gradient norm: inf
6: Skipped batch, new scale: 4096.0
13: Skipped batch, new scale: 4096.0
7: Gradient norm: inf
12: Gradient norm: inf
8: Gradient norm: inf
7: Skipped batch, new scale: 4096.0
11: Gradient norm: inf
12: Skipped batch, new scale: 4096.0
10: Gradient norm: inf
8: Skipped batch, new scale: 4096.0
9: Gradient norm: inf
11: Skipped batch, new scale: 4096.0
10: Skipped batch, new scale: 4096.0
9: Skipped batch, new scale: 4096.0
1: Gradient norm: inf
0: Gradient norm: inf
2: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
0: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
2: Skipped batch, new scale: 2048.0
3: Gradient norm: inf
14: Gradient norm: inf
4: Gradient norm: inf
15: Skipped batch, new scale: 2048.0
5: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
6: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
13: Gradient norm: inf
4: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
6: Skipped batch, new scale: 2048.0
7: Gradient norm: inf
12: Gradient norm: inf
13: Skipped batch, new scale: 2048.0
7: Skipped batch, new scale: 2048.0
8: Gradient norm: inf
12: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
8: Skipped batch, new scale: 2048.0
11: Gradient norm: inf
9: Gradient norm: inf
10: Skipped batch, new scale: 2048.0
11: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
1: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00104 (0.00100)	Tok/s 78381 (52888)	Loss/tok 3.1372 (3.1120)	Learning Rate [7.8125e-05]
0: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00109 (0.00096)	Tok/s 77853 (52795)	Loss/tok 2.9392 (3.1159)	Learning Rate [7.8125e-05]
2: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00106 (0.00098)	Tok/s 78383 (52998)	Loss/tok 2.9781 (3.1108)	Learning Rate [7.8125e-05]
6: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00091)	Tok/s 78541 (53351)	Loss/tok 2.9036 (3.1161)	Learning Rate [7.8125e-05]
4: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00098)	Tok/s 78395 (53194)	Loss/tok 3.1801 (3.1143)	Learning Rate [7.8125e-05]
3: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00104 (0.00092)	Tok/s 78355 (53098)	Loss/tok 3.1241 (3.1151)	Learning Rate [7.8125e-05]
15: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00092)	Tok/s 79250 (54165)	Loss/tok 3.2768 (3.1125)	Learning Rate [7.8125e-05]
7: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00114 (0.00097)	Tok/s 78421 (53440)	Loss/tok 3.2999 (3.1146)	Learning Rate [7.8125e-05]
8: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00106 (0.00097)	Tok/s 78482 (53512)	Loss/tok 3.0165 (3.1134)	Learning Rate [7.8125e-05]
5: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00093)	Tok/s 78320 (53278)	Loss/tok 3.2322 (3.1124)	Learning Rate [7.8125e-05]
14: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00092)	Tok/s 79233 (54053)	Loss/tok 3.0928 (3.1149)	Learning Rate [7.8125e-05]
13: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00096)	Tok/s 79253 (53949)	Loss/tok 3.2707 (3.1117)	Learning Rate [7.8125e-05]
9: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00091)	Tok/s 78496 (53578)	Loss/tok 3.1251 (3.1097)	Learning Rate [7.8125e-05]
11: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00091)	Tok/s 79334 (53732)	Loss/tok 3.1190 (3.1135)	Learning Rate [7.8125e-05]
12: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00100)	Tok/s 79252 (53851)	Loss/tok 2.9568 (3.1175)	Learning Rate [7.8125e-05]
10: TRAIN [2][2580/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00096)	Tok/s 79314 (53654)	Loss/tok 3.2902 (3.1085)	Learning Rate [7.8125e-05]
15: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00092)	Tok/s 47287 (54157)	Loss/tok 2.9693 (3.1126)	Learning Rate [7.8125e-05]
0: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00096)	Tok/s 45840 (52788)	Loss/tok 2.8885 (3.1158)	Learning Rate [7.8125e-05]
1: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00100)	Tok/s 46805 (52881)	Loss/tok 2.9820 (3.1122)	Learning Rate [7.8125e-05]
13: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00096)	Tok/s 47139 (53942)	Loss/tok 2.9954 (3.1118)	Learning Rate [7.8125e-05]
2: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00098)	Tok/s 47213 (52992)	Loss/tok 2.8703 (3.1108)	Learning Rate [7.8125e-05]
4: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00098)	Tok/s 47071 (53187)	Loss/tok 2.9342 (3.1142)	Learning Rate [7.8125e-05]
12: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00100)	Tok/s 47038 (53844)	Loss/tok 2.9051 (3.1174)	Learning Rate [7.8125e-05]
10: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00096)	Tok/s 47059 (53646)	Loss/tok 3.0261 (3.1088)	Learning Rate [7.8125e-05]
11: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00091)	Tok/s 46830 (53725)	Loss/tok 2.8985 (3.1137)	Learning Rate [7.8125e-05]
3: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00092)	Tok/s 47103 (53091)	Loss/tok 2.9114 (3.1151)	Learning Rate [7.8125e-05]
9: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00091)	Tok/s 46996 (53570)	Loss/tok 2.9334 (3.1098)	Learning Rate [7.8125e-05]
5: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00093)	Tok/s 47022 (53271)	Loss/tok 2.7877 (3.1125)	Learning Rate [7.8125e-05]
8: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00097)	Tok/s 47010 (53504)	Loss/tok 3.0111 (3.1134)	Learning Rate [7.8125e-05]
14: TRAIN [2][2590/3416]	Time 0.044 (0.058)	Data 0.00130 (0.00092)	Tok/s 47588 (54045)	Loss/tok 2.7903 (3.1150)	Learning Rate [7.8125e-05]
7: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00097)	Tok/s 47043 (53432)	Loss/tok 2.8532 (3.1146)	Learning Rate [7.8125e-05]
6: TRAIN [2][2590/3416]	Time 0.045 (0.058)	Data 0.00111 (0.00091)	Tok/s 47093 (53344)	Loss/tok 3.1710 (3.1163)	Learning Rate [7.8125e-05]
9: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00080 (0.00091)	Tok/s 56821 (53580)	Loss/tok 3.3163 (3.1098)	Learning Rate [7.8125e-05]
8: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00097)	Tok/s 56770 (53515)	Loss/tok 3.0717 (3.1134)	Learning Rate [7.8125e-05]
10: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00096)	Tok/s 56677 (53656)	Loss/tok 3.1372 (3.1090)	Learning Rate [7.8125e-05]
11: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00086 (0.00091)	Tok/s 56598 (53735)	Loss/tok 3.0880 (3.1138)	Learning Rate [7.8125e-05]
7: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00097)	Tok/s 55975 (53442)	Loss/tok 3.2112 (3.1148)	Learning Rate [7.8125e-05]
5: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00093)	Tok/s 55601 (53281)	Loss/tok 3.1379 (3.1126)	Learning Rate [7.8125e-05]
15: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00084 (0.00092)	Tok/s 56291 (54166)	Loss/tok 3.0402 (3.1126)	Learning Rate [7.8125e-05]
13: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00096)	Tok/s 56386 (53951)	Loss/tok 3.2096 (3.1122)	Learning Rate [7.8125e-05]
6: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00081 (0.00091)	Tok/s 55578 (53354)	Loss/tok 3.0884 (3.1163)	Learning Rate [7.8125e-05]
14: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00078 (0.00092)	Tok/s 56259 (54055)	Loss/tok 3.0545 (3.1151)	Learning Rate [7.8125e-05]
12: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00084 (0.00100)	Tok/s 56498 (53854)	Loss/tok 3.4461 (3.1178)	Learning Rate [7.8125e-05]
4: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00098)	Tok/s 55390 (53197)	Loss/tok 2.9506 (3.1142)	Learning Rate [7.8125e-05]
0: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00096)	Tok/s 55159 (52799)	Loss/tok 3.1965 (3.1158)	Learning Rate [7.8125e-05]
3: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00082 (0.00092)	Tok/s 55327 (53101)	Loss/tok 3.0926 (3.1151)	Learning Rate [7.8125e-05]
2: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00098)	Tok/s 55252 (53002)	Loss/tok 3.3040 (3.1110)	Learning Rate [7.8125e-05]
1: TRAIN [2][2600/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00100)	Tok/s 55181 (52892)	Loss/tok 3.0267 (3.1121)	Learning Rate [7.8125e-05]
0: TRAIN [2][2610/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 66639 (52778)	Loss/tok 3.4954 (3.1158)	Learning Rate [7.8125e-05]
1: TRAIN [2][2610/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00100)	Tok/s 66542 (52871)	Loss/tok 3.0156 (3.1120)	Learning Rate [7.8125e-05]
15: TRAIN [2][2610/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 67577 (54151)	Loss/tok 3.0410 (3.1125)	Learning Rate [7.8125e-05]
14: TRAIN [2][2610/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00092)	Tok/s 67794 (54040)	Loss/tok 3.2226 (3.1152)	Learning Rate [7.8125e-05]
13: TRAIN [2][2610/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00096)	Tok/s 67379 (53936)	Loss/tok 3.1386 (3.1121)	Learning Rate [7.8125e-05]
3: TRAIN [2][2610/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 66323 (53083)	Loss/tok 3.1408 (3.1152)	Learning Rate [7.8125e-05]
11: TRAIN [2][2610/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00091)	Tok/s 67248 (53719)	Loss/tok 3.0930 (3.1137)	Learning Rate [7.8125e-05]
12: TRAIN [2][2610/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00100)	Tok/s 67304 (53839)	Loss/tok 3.1959 (3.1178)	Learning Rate [7.8125e-05]
4: TRAIN [2][2610/3416]	Time 0.071 (0.058)	Data 0.00100 (0.00098)	Tok/s 66249 (53179)	Loss/tok 3.1734 (3.1139)	Learning Rate [7.8125e-05]
6: TRAIN [2][2610/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00091)	Tok/s 67038 (53337)	Loss/tok 3.2436 (3.1162)	Learning Rate [7.8125e-05]
2: TRAIN [2][2610/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 66466 (52983)	Loss/tok 3.3860 (3.1108)	Learning Rate [7.8125e-05]
5: TRAIN [2][2610/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00093)	Tok/s 66831 (53264)	Loss/tok 3.4506 (3.1127)	Learning Rate [7.8125e-05]
9: TRAIN [2][2610/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00091)	Tok/s 67027 (53565)	Loss/tok 3.2113 (3.1095)	Learning Rate [7.8125e-05]
10: TRAIN [2][2610/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00096)	Tok/s 67097 (53640)	Loss/tok 3.1301 (3.1086)	Learning Rate [7.8125e-05]
7: TRAIN [2][2610/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00097)	Tok/s 66896 (53426)	Loss/tok 3.1668 (3.1145)	Learning Rate [7.8125e-05]
8: TRAIN [2][2610/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00097)	Tok/s 66859 (53499)	Loss/tok 3.2210 (3.1131)	Learning Rate [7.8125e-05]
9: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00077 (0.00091)	Tok/s 57848 (53555)	Loss/tok 3.2131 (3.1095)	Learning Rate [7.8125e-05]
8: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 57867 (53489)	Loss/tok 3.2703 (3.1131)	Learning Rate [7.8125e-05]
7: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00097)	Tok/s 57868 (53416)	Loss/tok 3.2157 (3.1145)	Learning Rate [7.8125e-05]
10: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00096)	Tok/s 57759 (53630)	Loss/tok 3.1687 (3.1087)	Learning Rate [7.8125e-05]
6: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00091)	Tok/s 57822 (53328)	Loss/tok 3.2994 (3.1162)	Learning Rate [7.8125e-05]
11: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 57624 (53708)	Loss/tok 3.2282 (3.1136)	Learning Rate [7.8125e-05]
5: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 57834 (53255)	Loss/tok 3.0101 (3.1125)	Learning Rate [7.8125e-05]
4: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 57743 (53170)	Loss/tok 3.3343 (3.1137)	Learning Rate [7.8125e-05]
3: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 57666 (53074)	Loss/tok 3.2393 (3.1153)	Learning Rate [7.8125e-05]
12: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00100)	Tok/s 57543 (53828)	Loss/tok 3.1061 (3.1175)	Learning Rate [7.8125e-05]
2: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00098)	Tok/s 57550 (52974)	Loss/tok 3.2379 (3.1108)	Learning Rate [7.8125e-05]
13: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 58357 (53925)	Loss/tok 3.1152 (3.1121)	Learning Rate [7.8125e-05]
1: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 57469 (52862)	Loss/tok 3.3008 (3.1122)	Learning Rate [7.8125e-05]
15: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 58308 (54139)	Loss/tok 2.9964 (3.1123)	Learning Rate [7.8125e-05]
14: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00078 (0.00092)	Tok/s 58273 (54028)	Loss/tok 3.2988 (3.1154)	Learning Rate [7.8125e-05]
0: TRAIN [2][2620/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 57362 (52769)	Loss/tok 3.1811 (3.1159)	Learning Rate [7.8125e-05]
1: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00110 (0.00100)	Tok/s 48844 (52860)	Loss/tok 3.1577 (3.1124)	Learning Rate [7.8125e-05]
0: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00106 (0.00096)	Tok/s 48821 (52766)	Loss/tok 3.1442 (3.1160)	Learning Rate [7.8125e-05]
2: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00098)	Tok/s 48823 (52971)	Loss/tok 2.9256 (3.1107)	Learning Rate [7.8125e-05]
14: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00092)	Tok/s 48814 (54025)	Loss/tok 3.0438 (3.1153)	Learning Rate [7.8125e-05]
3: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00092)	Tok/s 48786 (53071)	Loss/tok 2.9587 (3.1154)	Learning Rate [7.8125e-05]
15: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00103 (0.00092)	Tok/s 48772 (54135)	Loss/tok 2.9564 (3.1123)	Learning Rate [7.8125e-05]
4: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00098)	Tok/s 48809 (53167)	Loss/tok 3.0221 (3.1137)	Learning Rate [7.8125e-05]
12: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00103 (0.00100)	Tok/s 48795 (53823)	Loss/tok 3.1111 (3.1174)	Learning Rate [7.8125e-05]
13: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00106 (0.00096)	Tok/s 48725 (53921)	Loss/tok 3.0991 (3.1122)	Learning Rate [7.8125e-05]
6: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00091)	Tok/s 48774 (53325)	Loss/tok 2.8693 (3.1163)	Learning Rate [7.8125e-05]
5: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00093)	Tok/s 48775 (53252)	Loss/tok 3.2557 (3.1125)	Learning Rate [7.8125e-05]
11: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00091)	Tok/s 48635 (53704)	Loss/tok 2.8834 (3.1134)	Learning Rate [7.8125e-05]
7: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00104 (0.00097)	Tok/s 48627 (53413)	Loss/tok 3.1571 (3.1146)	Learning Rate [7.8125e-05]
9: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00104 (0.00091)	Tok/s 48463 (53551)	Loss/tok 3.0667 (3.1096)	Learning Rate [7.8125e-05]
8: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00097)	Tok/s 48486 (53486)	Loss/tok 2.8535 (3.1132)	Learning Rate [7.8125e-05]
10: TRAIN [2][2630/3416]	Time 0.045 (0.058)	Data 0.00109 (0.00096)	Tok/s 48476 (53626)	Loss/tok 2.9915 (3.1089)	Learning Rate [7.8125e-05]
5: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00081 (0.00093)	Tok/s 48705 (53247)	Loss/tok 2.8991 (3.1124)	Learning Rate [7.8125e-05]
6: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00091)	Tok/s 48709 (53319)	Loss/tok 3.0093 (3.1163)	Learning Rate [7.8125e-05]
4: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00098)	Tok/s 48626 (53162)	Loss/tok 3.1139 (3.1140)	Learning Rate [7.8125e-05]
3: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00092)	Tok/s 48489 (53065)	Loss/tok 3.0341 (3.1153)	Learning Rate [7.8125e-05]
7: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00097)	Tok/s 48775 (53407)	Loss/tok 2.9314 (3.1145)	Learning Rate [7.8125e-05]
2: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00098)	Tok/s 48458 (52965)	Loss/tok 3.1990 (3.1104)	Learning Rate [7.8125e-05]
8: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00097)	Tok/s 48695 (53481)	Loss/tok 3.1107 (3.1134)	Learning Rate [7.8125e-05]
0: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00096)	Tok/s 48410 (52760)	Loss/tok 3.0177 (3.1159)	Learning Rate [7.8125e-05]
10: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00096)	Tok/s 48788 (53620)	Loss/tok 2.9879 (3.1089)	Learning Rate [7.8125e-05]
15: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00081 (0.00092)	Tok/s 48446 (54130)	Loss/tok 3.0908 (3.1126)	Learning Rate [7.8125e-05]
1: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00100)	Tok/s 48484 (52855)	Loss/tok 3.1270 (3.1127)	Learning Rate [7.8125e-05]
11: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00092)	Tok/s 48651 (53698)	Loss/tok 3.2037 (3.1135)	Learning Rate [7.8125e-05]
9: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00109 (0.00091)	Tok/s 48758 (53545)	Loss/tok 2.9232 (3.1094)	Learning Rate [7.8125e-05]
14: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00081 (0.00092)	Tok/s 48481 (54020)	Loss/tok 3.1309 (3.1155)	Learning Rate [7.8125e-05]
12: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00100)	Tok/s 48593 (53817)	Loss/tok 3.1676 (3.1173)	Learning Rate [7.8125e-05]
13: TRAIN [2][2640/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00096)	Tok/s 48499 (53915)	Loss/tok 2.8171 (3.1122)	Learning Rate [7.8125e-05]
9: TRAIN [2][2650/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00091)	Tok/s 72135 (53568)	Loss/tok 3.1745 (3.1094)	Learning Rate [7.8125e-05]
6: TRAIN [2][2650/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00092)	Tok/s 71999 (53342)	Loss/tok 3.2123 (3.1168)	Learning Rate [7.8125e-05]
11: TRAIN [2][2650/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 71983 (53721)	Loss/tok 3.1677 (3.1139)	Learning Rate [7.8125e-05]
8: TRAIN [2][2650/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 72108 (53504)	Loss/tok 3.1970 (3.1134)	Learning Rate [7.8125e-05]
7: TRAIN [2][2650/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 72052 (53430)	Loss/tok 3.2338 (3.1148)	Learning Rate [7.8125e-05]
15: TRAIN [2][2650/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 71796 (54152)	Loss/tok 3.1873 (3.1129)	Learning Rate [7.8125e-05]
5: TRAIN [2][2650/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 71648 (53269)	Loss/tok 3.3800 (3.1129)	Learning Rate [7.8125e-05]
14: TRAIN [2][2650/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 71828 (54041)	Loss/tok 3.3248 (3.1158)	Learning Rate [7.8125e-05]
3: TRAIN [2][2650/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 70776 (53088)	Loss/tok 3.2242 (3.1158)	Learning Rate [7.8125e-05]
0: TRAIN [2][2650/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00096)	Tok/s 70744 (52784)	Loss/tok 3.1383 (3.1158)	Learning Rate [7.8125e-05]
10: TRAIN [2][2650/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00096)	Tok/s 72010 (53642)	Loss/tok 3.0064 (3.1090)	Learning Rate [7.8125e-05]
1: TRAIN [2][2650/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 70651 (52878)	Loss/tok 3.1681 (3.1129)	Learning Rate [7.8125e-05]
12: TRAIN [2][2650/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 71873 (53839)	Loss/tok 3.2020 (3.1178)	Learning Rate [7.8125e-05]
13: TRAIN [2][2650/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 71760 (53937)	Loss/tok 3.0927 (3.1126)	Learning Rate [7.8125e-05]
2: TRAIN [2][2650/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 70636 (52988)	Loss/tok 3.0105 (3.1108)	Learning Rate [7.8125e-05]
4: TRAIN [2][2650/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 70747 (53185)	Loss/tok 3.1466 (3.1140)	Learning Rate [7.8125e-05]
9: TRAIN [2][2660/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00091)	Tok/s 56226 (53557)	Loss/tok 2.9817 (3.1092)	Learning Rate [7.8125e-05]
8: TRAIN [2][2660/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00097)	Tok/s 56280 (53492)	Loss/tok 3.1817 (3.1134)	Learning Rate [7.8125e-05]
10: TRAIN [2][2660/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00096)	Tok/s 56134 (53631)	Loss/tok 3.0028 (3.1088)	Learning Rate [7.8125e-05]
4: TRAIN [2][2660/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00098)	Tok/s 56383 (53174)	Loss/tok 3.2146 (3.1140)	Learning Rate [7.8125e-05]
3: TRAIN [2][2660/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00092)	Tok/s 56415 (53078)	Loss/tok 3.0059 (3.1156)	Learning Rate [7.8125e-05]
7: TRAIN [2][2660/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00097)	Tok/s 56233 (53419)	Loss/tok 2.9988 (3.1144)	Learning Rate [7.8125e-05]
6: TRAIN [2][2660/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00092)	Tok/s 56212 (53331)	Loss/tok 3.3106 (3.1168)	Learning Rate [7.8125e-05]
12: TRAIN [2][2660/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00100)	Tok/s 56113 (53828)	Loss/tok 3.1263 (3.1177)	Learning Rate [7.8125e-05]
11: TRAIN [2][2660/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00092)	Tok/s 56016 (53709)	Loss/tok 3.0501 (3.1137)	Learning Rate [7.8125e-05]
2: TRAIN [2][2660/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00098)	Tok/s 56410 (52978)	Loss/tok 3.1584 (3.1109)	Learning Rate [7.8125e-05]
5: TRAIN [2][2660/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00093)	Tok/s 56320 (53259)	Loss/tok 3.0783 (3.1130)	Learning Rate [7.8125e-05]
1: TRAIN [2][2660/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00100)	Tok/s 56269 (52868)	Loss/tok 3.0490 (3.1128)	Learning Rate [7.8125e-05]
0: TRAIN [2][2660/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00096)	Tok/s 56192 (52774)	Loss/tok 3.1263 (3.1156)	Learning Rate [7.8125e-05]
13: TRAIN [2][2660/3416]	Time 0.063 (0.058)	Data 0.00106 (0.00096)	Tok/s 56070 (53926)	Loss/tok 3.2495 (3.1129)	Learning Rate [7.8125e-05]
15: TRAIN [2][2660/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00092)	Tok/s 56110 (54140)	Loss/tok 3.0578 (3.1127)	Learning Rate [7.8125e-05]
14: TRAIN [2][2660/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00092)	Tok/s 56065 (54030)	Loss/tok 3.1964 (3.1156)	Learning Rate [7.8125e-05]
6: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00092)	Tok/s 53148 (53333)	Loss/tok 3.2186 (3.1166)	Learning Rate [7.8125e-05]
7: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00097)	Tok/s 53286 (53421)	Loss/tok 3.1632 (3.1142)	Learning Rate [7.8125e-05]
8: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00097)	Tok/s 53323 (53494)	Loss/tok 3.0987 (3.1133)	Learning Rate [7.8125e-05]
9: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00091)	Tok/s 53300 (53558)	Loss/tok 2.9519 (3.1093)	Learning Rate [7.8125e-05]
5: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00093)	Tok/s 53099 (53260)	Loss/tok 3.1792 (3.1129)	Learning Rate [7.8125e-05]
4: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00113 (0.00098)	Tok/s 52966 (53176)	Loss/tok 3.1099 (3.1140)	Learning Rate [7.8125e-05]
3: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00092)	Tok/s 52862 (53079)	Loss/tok 2.9793 (3.1155)	Learning Rate [7.8125e-05]
10: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00096)	Tok/s 53241 (53632)	Loss/tok 3.3194 (3.1089)	Learning Rate [7.8125e-05]
11: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00082 (0.00092)	Tok/s 53157 (53711)	Loss/tok 3.1520 (3.1137)	Learning Rate [7.8125e-05]
2: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00098)	Tok/s 52741 (52980)	Loss/tok 3.1600 (3.1108)	Learning Rate [7.8125e-05]
12: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00100)	Tok/s 53096 (53830)	Loss/tok 3.0136 (3.1175)	Learning Rate [7.8125e-05]
0: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00096)	Tok/s 52828 (52777)	Loss/tok 3.2337 (3.1160)	Learning Rate [7.8125e-05]
14: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00082 (0.00092)	Tok/s 52848 (54031)	Loss/tok 3.0381 (3.1155)	Learning Rate [7.8125e-05]
13: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00109 (0.00096)	Tok/s 52955 (53927)	Loss/tok 3.2718 (3.1129)	Learning Rate [7.8125e-05]
15: TRAIN [2][2670/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00092)	Tok/s 53407 (54142)	Loss/tok 3.1984 (3.1126)	Learning Rate [7.8125e-05]
1: TRAIN [2][2670/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00100)	Tok/s 52456 (52870)	Loss/tok 3.3100 (3.1128)	Learning Rate [7.8125e-05]
9: TRAIN [2][2680/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00091)	Tok/s 52782 (53538)	Loss/tok 2.9631 (3.1088)	Learning Rate [7.8125e-05]
10: TRAIN [2][2680/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00096)	Tok/s 52804 (53612)	Loss/tok 3.1842 (3.1087)	Learning Rate [7.8125e-05]
6: TRAIN [2][2680/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00092)	Tok/s 52473 (53312)	Loss/tok 3.0948 (3.1165)	Learning Rate [7.8125e-05]
7: TRAIN [2][2680/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00097)	Tok/s 52553 (53400)	Loss/tok 2.8270 (3.1143)	Learning Rate [7.8125e-05]
8: TRAIN [2][2680/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00097)	Tok/s 52624 (53473)	Loss/tok 3.0415 (3.1129)	Learning Rate [7.8125e-05]
11: TRAIN [2][2680/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00092)	Tok/s 52690 (53690)	Loss/tok 3.1038 (3.1135)	Learning Rate [7.8125e-05]
5: TRAIN [2][2680/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00093)	Tok/s 52284 (53238)	Loss/tok 3.1714 (3.1128)	Learning Rate [7.8125e-05]
12: TRAIN [2][2680/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00100)	Tok/s 52575 (53809)	Loss/tok 3.2588 (3.1175)	Learning Rate [7.8125e-05]
4: TRAIN [2][2680/3416]	Time 0.053 (0.058)	Data 0.00103 (0.00098)	Tok/s 52126 (53153)	Loss/tok 3.0942 (3.1137)	Learning Rate [7.8125e-05]
3: TRAIN [2][2680/3416]	Time 0.053 (0.058)	Data 0.00101 (0.00092)	Tok/s 52069 (53056)	Loss/tok 3.0210 (3.1154)	Learning Rate [7.8125e-05]
14: TRAIN [2][2680/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00092)	Tok/s 52347 (54010)	Loss/tok 2.9535 (3.1151)	Learning Rate [7.8125e-05]
13: TRAIN [2][2680/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00096)	Tok/s 52466 (53907)	Loss/tok 3.2189 (3.1128)	Learning Rate [7.8125e-05]
15: TRAIN [2][2680/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00092)	Tok/s 52223 (54122)	Loss/tok 3.0171 (3.1125)	Learning Rate [7.8125e-05]
1: TRAIN [2][2680/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00100)	Tok/s 52055 (52846)	Loss/tok 3.2116 (3.1125)	Learning Rate [7.8125e-05]
2: TRAIN [2][2680/3416]	Time 0.053 (0.058)	Data 0.00101 (0.00098)	Tok/s 51971 (52957)	Loss/tok 3.0462 (3.1107)	Learning Rate [7.8125e-05]
0: TRAIN [2][2680/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00096)	Tok/s 52109 (52752)	Loss/tok 3.0425 (3.1159)	Learning Rate [7.8125e-05]
0: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00096)	Tok/s 65372 (52767)	Loss/tok 2.9450 (3.1160)	Learning Rate [7.8125e-05]
14: TRAIN [2][2690/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 65927 (54023)	Loss/tok 3.2372 (3.1153)	Learning Rate [7.8125e-05]
15: TRAIN [2][2690/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 66330 (54134)	Loss/tok 3.3771 (3.1129)	Learning Rate [7.8125e-05]
1: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00100)	Tok/s 65241 (52860)	Loss/tok 3.2750 (3.1128)	Learning Rate [7.8125e-05]
2: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00098)	Tok/s 65153 (52971)	Loss/tok 3.0689 (3.1107)	Learning Rate [7.8125e-05]
13: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00118 (0.00096)	Tok/s 65368 (53920)	Loss/tok 3.1409 (3.1128)	Learning Rate [7.8125e-05]
12: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00100)	Tok/s 65313 (53822)	Loss/tok 3.1855 (3.1176)	Learning Rate [7.8125e-05]
3: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 65062 (53070)	Loss/tok 3.1269 (3.1157)	Learning Rate [7.8125e-05]
9: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00091)	Tok/s 65200 (53552)	Loss/tok 3.1104 (3.1087)	Learning Rate [7.8125e-05]
6: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 65048 (53325)	Loss/tok 3.1043 (3.1164)	Learning Rate [7.8125e-05]
5: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 65061 (53252)	Loss/tok 3.1091 (3.1128)	Learning Rate [7.8125e-05]
8: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 65179 (53487)	Loss/tok 3.0318 (3.1131)	Learning Rate [7.8125e-05]
7: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 65126 (53413)	Loss/tok 3.3330 (3.1145)	Learning Rate [7.8125e-05]
11: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 65286 (53704)	Loss/tok 3.2747 (3.1137)	Learning Rate [7.8125e-05]
10: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00096)	Tok/s 65169 (53625)	Loss/tok 3.2740 (3.1091)	Learning Rate [7.8125e-05]
4: TRAIN [2][2690/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00099)	Tok/s 64954 (53166)	Loss/tok 3.0606 (3.1140)	Learning Rate [7.8125e-05]
3: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00104 (0.00092)	Tok/s 30603 (53050)	Loss/tok 2.4573 (3.1156)	Learning Rate [7.8125e-05]
2: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00104 (0.00098)	Tok/s 30647 (52951)	Loss/tok 2.4598 (3.1106)	Learning Rate [7.8125e-05]
4: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00097 (0.00099)	Tok/s 30495 (53146)	Loss/tok 2.5460 (3.1139)	Learning Rate [7.8125e-05]
1: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00094 (0.00100)	Tok/s 30646 (52841)	Loss/tok 2.4188 (3.1128)	Learning Rate [7.8125e-05]
0: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00090 (0.00096)	Tok/s 30640 (52747)	Loss/tok 2.6684 (3.1158)	Learning Rate [7.8125e-05]
6: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00108 (0.00092)	Tok/s 30476 (53304)	Loss/tok 2.5806 (3.1162)	Learning Rate [7.8125e-05]
5: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00108 (0.00093)	Tok/s 30467 (53231)	Loss/tok 2.6498 (3.1128)	Learning Rate [7.8125e-05]
9: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00109 (0.00091)	Tok/s 32096 (53530)	Loss/tok 2.7491 (3.1089)	Learning Rate [7.8125e-05]
8: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00093 (0.00097)	Tok/s 32037 (53466)	Loss/tok 2.6445 (3.1128)	Learning Rate [7.8125e-05]
15: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00108 (0.00092)	Tok/s 32164 (54113)	Loss/tok 2.5191 (3.1129)	Learning Rate [7.8125e-05]
7: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00094 (0.00097)	Tok/s 31237 (53392)	Loss/tok 2.5806 (3.1146)	Learning Rate [7.8125e-05]
14: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00100 (0.00092)	Tok/s 32180 (54002)	Loss/tok 2.4710 (3.1150)	Learning Rate [7.8125e-05]
11: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00110 (0.00092)	Tok/s 32341 (53683)	Loss/tok 2.5110 (3.1136)	Learning Rate [7.8125e-05]
10: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00089 (0.00096)	Tok/s 31999 (53604)	Loss/tok 2.5909 (3.1090)	Learning Rate [7.8125e-05]
13: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00090 (0.00096)	Tok/s 32163 (53899)	Loss/tok 2.5151 (3.1126)	Learning Rate [7.8125e-05]
12: TRAIN [2][2700/3416]	Time 0.042 (0.058)	Data 0.00104 (0.00101)	Tok/s 32182 (53801)	Loss/tok 2.6377 (3.1176)	Learning Rate [7.8125e-05]
6: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
4: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00095 (0.00099)	Tok/s 28451 (53115)	Loss/tok 2.4661 (3.1137)	Learning Rate [7.8125e-05]
3: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00104 (0.00092)	Tok/s 27500 (53019)	Loss/tok 2.3922 (3.1157)	Learning Rate [7.8125e-05]
6: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00107 (0.00092)	Tok/s 28882 (53274)	Loss/tok 2.4955 (3.1157)	Learning Rate [7.8125e-05]
2: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00097 (0.00098)	Tok/s 27517 (52920)	Loss/tok 2.4862 (3.1104)	Learning Rate [7.8125e-05]
5: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00107 (0.00093)	Tok/s 28940 (53200)	Loss/tok 2.5485 (3.1124)	Learning Rate [7.8125e-05]
1: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00087 (0.00100)	Tok/s 27514 (52811)	Loss/tok 2.5616 (3.1128)	Learning Rate [7.8125e-05]
0: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00098 (0.00096)	Tok/s 27497 (52718)	Loss/tok 2.4036 (3.1156)	Learning Rate [7.8125e-05]
7: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00097 (0.00097)	Tok/s 28802 (53361)	Loss/tok 2.5198 (3.1144)	Learning Rate [7.8125e-05]
8: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00106 (0.00097)	Tok/s 28734 (53435)	Loss/tok 2.5079 (3.1127)	Learning Rate [7.8125e-05]
9: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00096 (0.00091)	Tok/s 28738 (53499)	Loss/tok 2.7807 (3.1087)	Learning Rate [7.8125e-05]
15: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00104 (0.00092)	Tok/s 30515 (54082)	Loss/tok 2.5380 (3.1129)	Learning Rate [7.8125e-05]
14: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00092)	Tok/s 30455 (53972)	Loss/tok 2.7170 (3.1148)	Learning Rate [7.8125e-05]
10: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00099 (0.00096)	Tok/s 28749 (53573)	Loss/tok 2.5807 (3.1088)	Learning Rate [7.8125e-05]
13: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00081 (0.00096)	Tok/s 30387 (53869)	Loss/tok 2.7572 (3.1125)	Learning Rate [7.8125e-05]
11: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00084 (0.00092)	Tok/s 28733 (53652)	Loss/tok 2.4878 (3.1134)	Learning Rate [7.8125e-05]
12: TRAIN [2][2710/3416]	Time 0.042 (0.058)	Data 0.00106 (0.00101)	Tok/s 29036 (53770)	Loss/tok 2.5850 (3.1172)	Learning Rate [7.8125e-05]
13: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00096)	Tok/s 51413 (53875)	Loss/tok 2.8313 (3.1125)	Learning Rate [7.8125e-05]
14: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00092)	Tok/s 51410 (53978)	Loss/tok 3.0965 (3.1150)	Learning Rate [7.8125e-05]
0: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00096)	Tok/s 50196 (52725)	Loss/tok 3.1239 (3.1153)	Learning Rate [7.8125e-05]
15: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00092)	Tok/s 51445 (54089)	Loss/tok 2.8677 (3.1130)	Learning Rate [7.8125e-05]
12: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00101)	Tok/s 51243 (53777)	Loss/tok 3.2304 (3.1173)	Learning Rate [7.8125e-05]
1: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00100)	Tok/s 50215 (52818)	Loss/tok 3.0378 (3.1129)	Learning Rate [7.8125e-05]
11: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00091)	Tok/s 51224 (53658)	Loss/tok 2.8826 (3.1134)	Learning Rate [7.8125e-05]
10: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00096)	Tok/s 51232 (53579)	Loss/tok 2.9510 (3.1090)	Learning Rate [7.8125e-05]
4: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00099)	Tok/s 50592 (53122)	Loss/tok 3.0356 (3.1137)	Learning Rate [7.8125e-05]
9: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00091)	Tok/s 51197 (53505)	Loss/tok 3.0172 (3.1089)	Learning Rate [7.8125e-05]
8: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00097)	Tok/s 51258 (53441)	Loss/tok 3.2123 (3.1126)	Learning Rate [7.8125e-05]
6: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00092)	Tok/s 51385 (53280)	Loss/tok 2.8809 (3.1156)	Learning Rate [7.8125e-05]
3: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00092)	Tok/s 50097 (53027)	Loss/tok 3.1602 (3.1156)	Learning Rate [7.8125e-05]
7: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00097)	Tok/s 51192 (53368)	Loss/tok 2.8809 (3.1143)	Learning Rate [7.8125e-05]
2: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00098)	Tok/s 49988 (52928)	Loss/tok 3.1286 (3.1104)	Learning Rate [7.8125e-05]
5: TRAIN [2][2720/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00093)	Tok/s 51272 (53208)	Loss/tok 2.9905 (3.1123)	Learning Rate [7.8125e-05]
9: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00103 (0.00091)	Tok/s 56254 (53500)	Loss/tok 3.2190 (3.1089)	Learning Rate [7.8125e-05]
8: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00104 (0.00097)	Tok/s 56256 (53436)	Loss/tok 3.1727 (3.1127)	Learning Rate [7.8125e-05]
10: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00096)	Tok/s 56165 (53574)	Loss/tok 3.2304 (3.1089)	Learning Rate [7.8125e-05]
7: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00097)	Tok/s 56257 (53363)	Loss/tok 3.2595 (3.1144)	Learning Rate [7.8125e-05]
11: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00079 (0.00091)	Tok/s 56064 (53653)	Loss/tok 3.0568 (3.1134)	Learning Rate [7.8125e-05]
6: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00092)	Tok/s 56139 (53276)	Loss/tok 2.8732 (3.1156)	Learning Rate [7.8125e-05]
12: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00100)	Tok/s 56040 (53771)	Loss/tok 3.0029 (3.1173)	Learning Rate [7.8125e-05]
5: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00099 (0.00093)	Tok/s 56212 (53203)	Loss/tok 3.1574 (3.1121)	Learning Rate [7.8125e-05]
3: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00101 (0.00092)	Tok/s 56102 (53023)	Loss/tok 3.2271 (3.1154)	Learning Rate [7.8125e-05]
4: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00102 (0.00099)	Tok/s 56124 (53118)	Loss/tok 3.2367 (3.1138)	Learning Rate [7.8125e-05]
13: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00096)	Tok/s 55987 (53870)	Loss/tok 2.9451 (3.1126)	Learning Rate [7.8125e-05]
14: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00092)	Tok/s 55989 (53972)	Loss/tok 2.9301 (3.1148)	Learning Rate [7.8125e-05]
1: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00100)	Tok/s 54933 (52814)	Loss/tok 3.3372 (3.1127)	Learning Rate [7.8125e-05]
15: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00084 (0.00092)	Tok/s 55965 (54083)	Loss/tok 3.1647 (3.1130)	Learning Rate [7.8125e-05]
2: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00098)	Tok/s 55010 (52923)	Loss/tok 3.2851 (3.1103)	Learning Rate [7.8125e-05]
0: TRAIN [2][2730/3416]	Time 0.064 (0.058)	Data 0.00101 (0.00096)	Tok/s 54852 (52721)	Loss/tok 3.0993 (3.1153)	Learning Rate [7.8125e-05]
9: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00091)	Tok/s 76839 (53519)	Loss/tok 3.0862 (3.1088)	Learning Rate [7.8125e-05]
10: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00096)	Tok/s 77713 (53594)	Loss/tok 2.9402 (3.1086)	Learning Rate [7.8125e-05]
11: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00091)	Tok/s 77865 (53673)	Loss/tok 3.1767 (3.1132)	Learning Rate [7.8125e-05]
8: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 76838 (53455)	Loss/tok 3.1842 (3.1125)	Learning Rate [7.8125e-05]
12: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00100)	Tok/s 77782 (53790)	Loss/tok 3.0905 (3.1173)	Learning Rate [7.8125e-05]
7: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00097)	Tok/s 76785 (53382)	Loss/tok 3.1287 (3.1143)	Learning Rate [7.8125e-05]
6: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 76858 (53295)	Loss/tok 3.0101 (3.1153)	Learning Rate [7.8125e-05]
13: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 77822 (53889)	Loss/tok 3.0207 (3.1125)	Learning Rate [7.8125e-05]
14: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 77812 (53992)	Loss/tok 2.9987 (3.1147)	Learning Rate [7.8125e-05]
5: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00093)	Tok/s 76811 (53222)	Loss/tok 2.9261 (3.1117)	Learning Rate [7.8125e-05]
15: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00092)	Tok/s 77822 (54102)	Loss/tok 2.9425 (3.1127)	Learning Rate [7.8125e-05]
4: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00099)	Tok/s 76765 (53137)	Loss/tok 3.0484 (3.1140)	Learning Rate [7.8125e-05]
3: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00092)	Tok/s 76841 (53042)	Loss/tok 3.0205 (3.1152)	Learning Rate [7.8125e-05]
0: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00096)	Tok/s 76019 (52739)	Loss/tok 3.1709 (3.1150)	Learning Rate [7.8125e-05]
1: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00100)	Tok/s 76232 (52832)	Loss/tok 3.2036 (3.1126)	Learning Rate [7.8125e-05]
2: TRAIN [2][2740/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00098)	Tok/s 76752 (52943)	Loss/tok 2.8547 (3.1100)	Learning Rate [7.8125e-05]
6: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00081 (0.00092)	Tok/s 54705 (53293)	Loss/tok 3.2149 (3.1154)	Learning Rate [7.8125e-05]
9: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00078 (0.00091)	Tok/s 54655 (53517)	Loss/tok 3.2620 (3.1090)	Learning Rate [7.8125e-05]
5: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00093)	Tok/s 54635 (53221)	Loss/tok 3.1788 (3.1117)	Learning Rate [7.8125e-05]
3: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00092)	Tok/s 54631 (53040)	Loss/tok 3.2667 (3.1155)	Learning Rate [7.8125e-05]
2: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00098)	Tok/s 54712 (52941)	Loss/tok 3.1256 (3.1101)	Learning Rate [7.8125e-05]
7: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00080 (0.00097)	Tok/s 54638 (53380)	Loss/tok 3.4623 (3.1142)	Learning Rate [7.8125e-05]
1: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00100)	Tok/s 54789 (52831)	Loss/tok 3.1357 (3.1128)	Learning Rate [7.8125e-05]
8: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00097)	Tok/s 54631 (53453)	Loss/tok 3.1331 (3.1127)	Learning Rate [7.8125e-05]
14: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 54901 (53990)	Loss/tok 3.0839 (3.1147)	Learning Rate [7.8125e-05]
11: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00077 (0.00091)	Tok/s 54849 (53671)	Loss/tok 3.1379 (3.1135)	Learning Rate [7.8125e-05]
4: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00099)	Tok/s 54619 (53135)	Loss/tok 3.1199 (3.1139)	Learning Rate [7.8125e-05]
15: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 55330 (54100)	Loss/tok 3.0988 (3.1124)	Learning Rate [7.8125e-05]
13: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00096)	Tok/s 54823 (53887)	Loss/tok 3.2685 (3.1128)	Learning Rate [7.8125e-05]
12: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00101)	Tok/s 54845 (53788)	Loss/tok 3.1169 (3.1171)	Learning Rate [7.8125e-05]
10: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00080 (0.00096)	Tok/s 54828 (53592)	Loss/tok 3.2606 (3.1088)	Learning Rate [7.8125e-05]
0: TRAIN [2][2750/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00096)	Tok/s 54819 (52738)	Loss/tok 3.3067 (3.1153)	Learning Rate [7.8125e-05]
9: TRAIN [2][2760/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00091)	Tok/s 35522 (53529)	Loss/tok 2.9166 (3.1091)	Learning Rate [7.8125e-05]
10: TRAIN [2][2760/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00096)	Tok/s 35514 (53604)	Loss/tok 2.8748 (3.1084)	Learning Rate [7.8125e-05]
11: TRAIN [2][2760/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00091)	Tok/s 35414 (53683)	Loss/tok 2.9374 (3.1132)	Learning Rate [7.8125e-05]
8: TRAIN [2][2760/3416]	Time 0.052 (0.058)	Data 0.00112 (0.00097)	Tok/s 35509 (53465)	Loss/tok 3.0351 (3.1127)	Learning Rate [7.8125e-05]
7: TRAIN [2][2760/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00097)	Tok/s 35481 (53393)	Loss/tok 2.7900 (3.1143)	Learning Rate [7.8125e-05]
12: TRAIN [2][2760/3416]	Time 0.053 (0.058)	Data 0.00107 (0.00101)	Tok/s 35342 (53800)	Loss/tok 2.9535 (3.1169)	Learning Rate [7.8125e-05]
6: TRAIN [2][2760/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00092)	Tok/s 35414 (53306)	Loss/tok 2.9854 (3.1154)	Learning Rate [7.8125e-05]
13: TRAIN [2][2760/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00096)	Tok/s 35350 (53899)	Loss/tok 3.1361 (3.1129)	Learning Rate [7.8125e-05]
14: TRAIN [2][2760/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 35353 (54001)	Loss/tok 3.0231 (3.1146)	Learning Rate [7.8125e-05]
5: TRAIN [2][2760/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00093)	Tok/s 35392 (53234)	Loss/tok 3.3076 (3.1117)	Learning Rate [7.8125e-05]
15: TRAIN [2][2760/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 35372 (54111)	Loss/tok 2.8857 (3.1123)	Learning Rate [7.8125e-05]
4: TRAIN [2][2760/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00099)	Tok/s 35351 (53149)	Loss/tok 2.9202 (3.1141)	Learning Rate [7.8125e-05]
0: TRAIN [2][2760/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00097)	Tok/s 34136 (52750)	Loss/tok 2.7183 (3.1152)	Learning Rate [7.8125e-05]
3: TRAIN [2][2760/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00092)	Tok/s 35345 (53053)	Loss/tok 3.1134 (3.1154)	Learning Rate [7.8125e-05]
1: TRAIN [2][2760/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00100)	Tok/s 34144 (52843)	Loss/tok 2.7567 (3.1127)	Learning Rate [7.8125e-05]
2: TRAIN [2][2760/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00098)	Tok/s 34410 (52953)	Loss/tok 2.8717 (3.1099)	Learning Rate [7.8125e-05]
4: Gradient norm: inf
5: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
5: Skipped batch, new scale: 2048.0
4: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
3: Gradient norm: inf
13: Gradient norm: inf
7: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
12: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
13: Skipped batch, new scale: 2048.0
14: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
7: Skipped batch, new scale: 2048.0
11: Gradient norm: inf
6: Gradient norm: inf
12: Skipped batch, new scale: 2048.0
8: Gradient norm: inf
15: Skipped batch, new scale: 2048.0
14: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
9: Gradient norm: inf
11: Skipped batch, new scale: 2048.0
6: Skipped batch, new scale: 2048.0
8: Skipped batch, new scale: 2048.0
10: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
3: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00092)	Tok/s 54400 (53055)	Loss/tok 3.0254 (3.1153)	Learning Rate [7.8125e-05]
2: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00098)	Tok/s 54323 (52955)	Loss/tok 3.1542 (3.1098)	Learning Rate [7.8125e-05]
4: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00099)	Tok/s 54453 (53151)	Loss/tok 2.9922 (3.1139)	Learning Rate [7.8125e-05]
1: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00106 (0.00100)	Tok/s 54331 (52845)	Loss/tok 3.1184 (3.1126)	Learning Rate [7.8125e-05]
0: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00114 (0.00097)	Tok/s 54323 (52752)	Loss/tok 3.3199 (3.1149)	Learning Rate [7.8125e-05]
5: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00093)	Tok/s 55395 (53236)	Loss/tok 3.3664 (3.1118)	Learning Rate [7.8125e-05]
6: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00092)	Tok/s 55506 (53309)	Loss/tok 3.2866 (3.1151)	Learning Rate [7.8125e-05]
13: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00096)	Tok/s 55387 (53901)	Loss/tok 3.3664 (3.1128)	Learning Rate [7.8125e-05]
7: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00097)	Tok/s 55391 (53395)	Loss/tok 3.2196 (3.1142)	Learning Rate [7.8125e-05]
15: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00102 (0.00092)	Tok/s 55434 (54114)	Loss/tok 3.1539 (3.1121)	Learning Rate [7.8125e-05]
14: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00092)	Tok/s 55379 (54003)	Loss/tok 3.1695 (3.1145)	Learning Rate [7.8125e-05]
12: TRAIN [2][2770/3416]	Time 0.056 (0.058)	Data 0.00109 (0.00101)	Tok/s 55333 (53803)	Loss/tok 3.0689 (3.1167)	Learning Rate [7.8125e-05]
10: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00084 (0.00096)	Tok/s 55404 (53607)	Loss/tok 3.2881 (3.1083)	Learning Rate [7.8125e-05]
9: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00091)	Tok/s 55406 (53532)	Loss/tok 3.0820 (3.1090)	Learning Rate [7.8125e-05]
8: TRAIN [2][2770/3416]	Time 0.055 (0.058)	Data 0.00105 (0.00097)	Tok/s 55418 (53468)	Loss/tok 3.1533 (3.1124)	Learning Rate [7.8125e-05]
11: TRAIN [2][2770/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00091)	Tok/s 55283 (53686)	Loss/tok 3.1361 (3.1129)	Learning Rate [7.8125e-05]
4: TRAIN [2][2780/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00099)	Tok/s 54184 (53154)	Loss/tok 3.0671 (3.1139)	Learning Rate [7.8125e-05]
3: TRAIN [2][2780/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00092)	Tok/s 54308 (53058)	Loss/tok 2.9707 (3.1151)	Learning Rate [7.8125e-05]
6: TRAIN [2][2780/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00092)	Tok/s 54092 (53311)	Loss/tok 3.0338 (3.1150)	Learning Rate [7.8125e-05]
5: TRAIN [2][2780/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00093)	Tok/s 54047 (53239)	Loss/tok 3.2803 (3.1120)	Learning Rate [7.8125e-05]
1: TRAIN [2][2780/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00100)	Tok/s 54272 (52848)	Loss/tok 3.0800 (3.1125)	Learning Rate [7.8125e-05]
15: TRAIN [2][2780/3416]	Time 0.055 (0.058)	Data 0.00085 (0.00092)	Tok/s 54260 (54115)	Loss/tok 3.1571 (3.1120)	Learning Rate [7.8125e-05]
0: TRAIN [2][2780/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00097)	Tok/s 54242 (52755)	Loss/tok 3.0335 (3.1147)	Learning Rate [7.8125e-05]
14: TRAIN [2][2780/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00092)	Tok/s 54168 (54005)	Loss/tok 3.0224 (3.1145)	Learning Rate [7.8125e-05]
7: TRAIN [2][2780/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00097)	Tok/s 53935 (53397)	Loss/tok 2.9664 (3.1144)	Learning Rate [7.8125e-05]
12: TRAIN [2][2780/3416]	Time 0.056 (0.058)	Data 0.00103 (0.00101)	Tok/s 53953 (53805)	Loss/tok 3.0717 (3.1168)	Learning Rate [7.8125e-05]
9: TRAIN [2][2780/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00091)	Tok/s 53922 (53533)	Loss/tok 3.2119 (3.1089)	Learning Rate [7.8125e-05]
2: TRAIN [2][2780/3416]	Time 0.056 (0.058)	Data 0.00100 (0.00098)	Tok/s 54190 (52958)	Loss/tok 2.9267 (3.1097)	Learning Rate [7.8125e-05]
11: TRAIN [2][2780/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00091)	Tok/s 53865 (53687)	Loss/tok 3.0106 (3.1128)	Learning Rate [7.8125e-05]
13: TRAIN [2][2780/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00096)	Tok/s 53986 (53903)	Loss/tok 3.2914 (3.1127)	Learning Rate [7.8125e-05]
8: TRAIN [2][2780/3416]	Time 0.056 (0.058)	Data 0.00115 (0.00097)	Tok/s 53850 (53470)	Loss/tok 3.1355 (3.1123)	Learning Rate [7.8125e-05]
10: TRAIN [2][2780/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00096)	Tok/s 53694 (53608)	Loss/tok 3.2022 (3.1083)	Learning Rate [7.8125e-05]
13: TRAIN [2][2790/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 64156 (53906)	Loss/tok 3.3000 (3.1131)	Learning Rate [7.8125e-05]
14: TRAIN [2][2790/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00092)	Tok/s 64392 (54008)	Loss/tok 3.4337 (3.1147)	Learning Rate [7.8125e-05]
12: TRAIN [2][2790/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00101)	Tok/s 63519 (53807)	Loss/tok 3.0901 (3.1170)	Learning Rate [7.8125e-05]
11: TRAIN [2][2790/3416]	Time 0.069 (0.058)	Data 0.00078 (0.00091)	Tok/s 63565 (53691)	Loss/tok 3.2119 (3.1130)	Learning Rate [7.8125e-05]
15: TRAIN [2][2790/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 64380 (54119)	Loss/tok 3.3423 (3.1122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2790/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 63467 (52760)	Loss/tok 3.1314 (3.1148)	Learning Rate [7.8125e-05]
9: TRAIN [2][2790/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00091)	Tok/s 63574 (53537)	Loss/tok 3.1848 (3.1093)	Learning Rate [7.8125e-05]
10: TRAIN [2][2790/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00096)	Tok/s 63555 (53611)	Loss/tok 3.1183 (3.1085)	Learning Rate [7.8125e-05]
1: TRAIN [2][2790/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00100)	Tok/s 63455 (52853)	Loss/tok 3.2055 (3.1128)	Learning Rate [7.8125e-05]
8: TRAIN [2][2790/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00097)	Tok/s 63585 (53474)	Loss/tok 3.4641 (3.1125)	Learning Rate [7.8125e-05]
2: TRAIN [2][2790/3416]	Time 0.070 (0.058)	Data 0.00113 (0.00098)	Tok/s 63463 (52962)	Loss/tok 3.3043 (3.1097)	Learning Rate [7.8125e-05]
6: TRAIN [2][2790/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 63556 (53315)	Loss/tok 3.3606 (3.1152)	Learning Rate [7.8125e-05]
7: TRAIN [2][2790/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00097)	Tok/s 63543 (53401)	Loss/tok 3.2254 (3.1146)	Learning Rate [7.8125e-05]
4: TRAIN [2][2790/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 63517 (53158)	Loss/tok 3.0069 (3.1141)	Learning Rate [7.8125e-05]
3: TRAIN [2][2790/3416]	Time 0.069 (0.058)	Data 0.00131 (0.00092)	Tok/s 63613 (53062)	Loss/tok 3.3522 (3.1153)	Learning Rate [7.8125e-05]
5: TRAIN [2][2790/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 63519 (53243)	Loss/tok 3.3300 (3.1122)	Learning Rate [7.8125e-05]
5: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00093)	Tok/s 32303 (53238)	Loss/tok 2.6590 (3.1122)	Learning Rate [7.8125e-05]
6: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00092)	Tok/s 32251 (53310)	Loss/tok 2.7961 (3.1152)	Learning Rate [7.8125e-05]
3: TRAIN [2][2800/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00092)	Tok/s 32322 (53057)	Loss/tok 2.7859 (3.1157)	Learning Rate [7.8125e-05]
4: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00099)	Tok/s 32272 (53153)	Loss/tok 2.8843 (3.1139)	Learning Rate [7.8125e-05]
2: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00098)	Tok/s 32298 (52957)	Loss/tok 2.8017 (3.1098)	Learning Rate [7.8125e-05]
7: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00097)	Tok/s 32229 (53396)	Loss/tok 2.7234 (3.1144)	Learning Rate [7.8125e-05]
8: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00097)	Tok/s 32428 (53468)	Loss/tok 2.7428 (3.1125)	Learning Rate [7.8125e-05]
1: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00100)	Tok/s 32310 (52848)	Loss/tok 2.6563 (3.1124)	Learning Rate [7.8125e-05]
9: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00082 (0.00091)	Tok/s 33500 (53532)	Loss/tok 2.8599 (3.1092)	Learning Rate [7.8125e-05]
0: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00097)	Tok/s 32298 (52756)	Loss/tok 2.8605 (3.1145)	Learning Rate [7.8125e-05]
11: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00081 (0.00091)	Tok/s 33493 (53686)	Loss/tok 2.9632 (3.1131)	Learning Rate [7.8125e-05]
10: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00096)	Tok/s 33482 (53607)	Loss/tok 2.6332 (3.1081)	Learning Rate [7.8125e-05]
14: TRAIN [2][2800/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 33627 (54003)	Loss/tok 2.8014 (3.1146)	Learning Rate [7.8125e-05]
15: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00080 (0.00092)	Tok/s 33541 (54113)	Loss/tok 2.7311 (3.1122)	Learning Rate [7.8125e-05]
12: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00101)	Tok/s 33541 (53802)	Loss/tok 2.9619 (3.1172)	Learning Rate [7.8125e-05]
13: TRAIN [2][2800/3416]	Time 0.052 (0.058)	Data 0.00082 (0.00096)	Tok/s 33519 (53901)	Loss/tok 2.6783 (3.1130)	Learning Rate [7.8125e-05]
11: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00091)	Tok/s 87971 (53703)	Loss/tok 2.9612 (3.1127)	Learning Rate [7.8125e-05]
15: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 90602 (54132)	Loss/tok 2.9313 (3.1121)	Learning Rate [7.8125e-05]
10: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00096)	Tok/s 87640 (53624)	Loss/tok 3.0755 (3.1081)	Learning Rate [7.8125e-05]
12: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00101)	Tok/s 88311 (53820)	Loss/tok 3.0064 (3.1171)	Learning Rate [7.8125e-05]
13: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00096)	Tok/s 88875 (53919)	Loss/tok 2.9830 (3.1129)	Learning Rate [7.8125e-05]
0: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 85462 (52773)	Loss/tok 3.0918 (3.1144)	Learning Rate [7.8125e-05]
9: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00076 (0.00091)	Tok/s 86868 (53550)	Loss/tok 3.1450 (3.1092)	Learning Rate [7.8125e-05]
14: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 89519 (54021)	Loss/tok 2.8237 (3.1144)	Learning Rate [7.8125e-05]
1: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00100)	Tok/s 85510 (52865)	Loss/tok 2.8729 (3.1121)	Learning Rate [7.8125e-05]
8: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00097)	Tok/s 86945 (53486)	Loss/tok 2.9348 (3.1123)	Learning Rate [7.8125e-05]
7: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00114 (0.00097)	Tok/s 86647 (53414)	Loss/tok 3.0278 (3.1144)	Learning Rate [7.8125e-05]
2: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 85395 (52974)	Loss/tok 2.9420 (3.1095)	Learning Rate [7.8125e-05]
6: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00092)	Tok/s 85998 (53327)	Loss/tok 3.0587 (3.1153)	Learning Rate [7.8125e-05]
3: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 85451 (53074)	Loss/tok 3.0562 (3.1152)	Learning Rate [7.8125e-05]
4: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00099)	Tok/s 86150 (53170)	Loss/tok 2.9484 (3.1139)	Learning Rate [7.8125e-05]
5: TRAIN [2][2810/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00093)	Tok/s 86056 (53255)	Loss/tok 3.0232 (3.1119)	Learning Rate [7.8125e-05]
3: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00092)	Tok/s 52268 (53083)	Loss/tok 3.3107 (3.1151)	Learning Rate [7.8125e-05]
4: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00099)	Tok/s 52140 (53179)	Loss/tok 3.0554 (3.1138)	Learning Rate [7.8125e-05]
2: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00098)	Tok/s 52225 (52983)	Loss/tok 3.2302 (3.1096)	Learning Rate [7.8125e-05]
1: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00100)	Tok/s 52191 (52874)	Loss/tok 2.9190 (3.1119)	Learning Rate [7.8125e-05]
0: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00097)	Tok/s 52194 (52783)	Loss/tok 2.8700 (3.1140)	Learning Rate [7.8125e-05]
5: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00111 (0.00093)	Tok/s 52279 (53264)	Loss/tok 3.2299 (3.1121)	Learning Rate [7.8125e-05]
6: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00092)	Tok/s 52300 (53336)	Loss/tok 3.1650 (3.1149)	Learning Rate [7.8125e-05]
7: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00108 (0.00097)	Tok/s 52379 (53423)	Loss/tok 3.2823 (3.1142)	Learning Rate [7.8125e-05]
15: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00092)	Tok/s 53273 (54141)	Loss/tok 3.1808 (3.1122)	Learning Rate [7.8125e-05]
8: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00097)	Tok/s 52162 (53495)	Loss/tok 3.1415 (3.1122)	Learning Rate [7.8125e-05]
14: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00111 (0.00092)	Tok/s 53278 (54030)	Loss/tok 3.1963 (3.1143)	Learning Rate [7.8125e-05]
13: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00096)	Tok/s 53297 (53928)	Loss/tok 2.8198 (3.1127)	Learning Rate [7.8125e-05]
12: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00107 (0.00101)	Tok/s 53045 (53829)	Loss/tok 3.2357 (3.1168)	Learning Rate [7.8125e-05]
9: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00091)	Tok/s 52283 (53558)	Loss/tok 3.2700 (3.1092)	Learning Rate [7.8125e-05]
11: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00091)	Tok/s 52063 (53712)	Loss/tok 3.3173 (3.1128)	Learning Rate [7.8125e-05]
10: TRAIN [2][2820/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00096)	Tok/s 52211 (53633)	Loss/tok 3.0689 (3.1079)	Learning Rate [7.8125e-05]
6: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00092)	Tok/s 54260 (53338)	Loss/tok 3.0308 (3.1150)	Learning Rate [7.8125e-05]
5: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00093)	Tok/s 54215 (53266)	Loss/tok 3.1642 (3.1123)	Learning Rate [7.8125e-05]
7: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 54137 (53425)	Loss/tok 3.0998 (3.1145)	Learning Rate [7.8125e-05]
3: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00081 (0.00092)	Tok/s 54105 (53086)	Loss/tok 2.9044 (3.1151)	Learning Rate [7.8125e-05]
8: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00098)	Tok/s 53996 (53497)	Loss/tok 2.8063 (3.1124)	Learning Rate [7.8125e-05]
9: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00080 (0.00091)	Tok/s 53904 (53561)	Loss/tok 3.0229 (3.1091)	Learning Rate [7.8125e-05]
10: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00096)	Tok/s 54757 (53636)	Loss/tok 2.9431 (3.1084)	Learning Rate [7.8125e-05]
4: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00111 (0.00099)	Tok/s 54226 (53182)	Loss/tok 3.1207 (3.1140)	Learning Rate [7.8125e-05]
2: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00098)	Tok/s 53975 (52987)	Loss/tok 3.1189 (3.1099)	Learning Rate [7.8125e-05]
1: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00100)	Tok/s 53865 (52878)	Loss/tok 2.9786 (3.1123)	Learning Rate [7.8125e-05]
0: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00097)	Tok/s 53735 (52786)	Loss/tok 2.9477 (3.1139)	Learning Rate [7.8125e-05]
11: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00080 (0.00091)	Tok/s 54958 (53715)	Loss/tok 2.9729 (3.1125)	Learning Rate [7.8125e-05]
12: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00101)	Tok/s 54856 (53832)	Loss/tok 3.1798 (3.1168)	Learning Rate [7.8125e-05]
14: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00092)	Tok/s 54817 (54033)	Loss/tok 2.9225 (3.1143)	Learning Rate [7.8125e-05]
13: TRAIN [2][2830/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00096)	Tok/s 54736 (53931)	Loss/tok 3.1531 (3.1129)	Learning Rate [7.8125e-05]
15: TRAIN [2][2830/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 54482 (54143)	Loss/tok 3.0539 (3.1123)	Learning Rate [7.8125e-05]
11: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00091)	Tok/s 34178 (53701)	Loss/tok 2.9550 (3.1123)	Learning Rate [7.8125e-05]
12: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00101)	Tok/s 34135 (53818)	Loss/tok 2.8180 (3.1166)	Learning Rate [7.8125e-05]
13: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00096)	Tok/s 34386 (53917)	Loss/tok 2.9519 (3.1127)	Learning Rate [7.8125e-05]
15: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00092)	Tok/s 35276 (54129)	Loss/tok 2.7693 (3.1122)	Learning Rate [7.8125e-05]
8: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00098)	Tok/s 34172 (53483)	Loss/tok 2.8726 (3.1122)	Learning Rate [7.8125e-05]
14: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 35304 (54019)	Loss/tok 2.7354 (3.1144)	Learning Rate [7.8125e-05]
9: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00091)	Tok/s 34161 (53547)	Loss/tok 2.5091 (3.1088)	Learning Rate [7.8125e-05]
10: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00096)	Tok/s 34095 (53622)	Loss/tok 2.7197 (3.1083)	Learning Rate [7.8125e-05]
0: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00097)	Tok/s 33870 (52774)	Loss/tok 2.8373 (3.1139)	Learning Rate [7.8125e-05]
2: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00098)	Tok/s 33870 (52974)	Loss/tok 2.6403 (3.1096)	Learning Rate [7.8125e-05]
1: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00100)	Tok/s 33800 (52865)	Loss/tok 2.7426 (3.1120)	Learning Rate [7.8125e-05]
6: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 33951 (53324)	Loss/tok 2.8216 (3.1148)	Learning Rate [7.8125e-05]
7: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00097)	Tok/s 33937 (53411)	Loss/tok 2.9324 (3.1142)	Learning Rate [7.8125e-05]
3: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 34085 (53073)	Loss/tok 2.8651 (3.1150)	Learning Rate [7.8125e-05]
5: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 33913 (53253)	Loss/tok 3.0741 (3.1121)	Learning Rate [7.8125e-05]
4: TRAIN [2][2840/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00099)	Tok/s 33832 (53168)	Loss/tok 3.1039 (3.1138)	Learning Rate [7.8125e-05]
2: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00098)	Tok/s 46189 (52950)	Loss/tok 2.8485 (3.1092)	Learning Rate [7.8125e-05]
3: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00092)	Tok/s 46090 (53049)	Loss/tok 2.8501 (3.1149)	Learning Rate [7.8125e-05]
1: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00100)	Tok/s 46159 (52840)	Loss/tok 2.8554 (3.1120)	Learning Rate [7.8125e-05]
0: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00097)	Tok/s 46146 (52747)	Loss/tok 3.0424 (3.1139)	Learning Rate [7.8125e-05]
4: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00099)	Tok/s 45882 (53145)	Loss/tok 3.0731 (3.1136)	Learning Rate [7.8125e-05]
15: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00092)	Tok/s 47659 (54109)	Loss/tok 2.8854 (3.1121)	Learning Rate [7.8125e-05]
6: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00092)	Tok/s 45766 (53302)	Loss/tok 2.7788 (3.1148)	Learning Rate [7.8125e-05]
14: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00092)	Tok/s 47514 (53998)	Loss/tok 2.9083 (3.1142)	Learning Rate [7.8125e-05]
13: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00096)	Tok/s 47594 (53896)	Loss/tok 2.8674 (3.1128)	Learning Rate [7.8125e-05]
7: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00097)	Tok/s 45717 (53389)	Loss/tok 3.0461 (3.1141)	Learning Rate [7.8125e-05]
5: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00079 (0.00093)	Tok/s 45861 (53230)	Loss/tok 2.8655 (3.1121)	Learning Rate [7.8125e-05]
8: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00098)	Tok/s 46213 (53462)	Loss/tok 2.9717 (3.1120)	Learning Rate [7.8125e-05]
11: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00091)	Tok/s 47157 (53680)	Loss/tok 2.8153 (3.1120)	Learning Rate [7.8125e-05]
12: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00101)	Tok/s 47354 (53797)	Loss/tok 3.0394 (3.1164)	Learning Rate [7.8125e-05]
10: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00096)	Tok/s 47156 (53601)	Loss/tok 2.9423 (3.1084)	Learning Rate [7.8125e-05]
9: TRAIN [2][2850/3416]	Time 0.046 (0.058)	Data 0.00079 (0.00091)	Tok/s 47075 (53525)	Loss/tok 2.8746 (3.1086)	Learning Rate [7.8125e-05]
0: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00095 (0.00097)	Tok/s 24841 (52725)	Loss/tok 2.1803 (3.1139)	Learning Rate [7.8125e-05]
15: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00102 (0.00092)	Tok/s 29740 (54087)	Loss/tok 2.4570 (3.1121)	Learning Rate [7.8125e-05]
13: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00102 (0.00096)	Tok/s 29633 (53875)	Loss/tok 2.5748 (3.1128)	Learning Rate [7.8125e-05]
1: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00092 (0.00100)	Tok/s 24818 (52818)	Loss/tok 2.1358 (3.1117)	Learning Rate [7.8125e-05]
14: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00085 (0.00092)	Tok/s 29672 (53977)	Loss/tok 2.3996 (3.1141)	Learning Rate [7.8125e-05]
2: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00094 (0.00098)	Tok/s 24767 (52928)	Loss/tok 2.2168 (3.1090)	Learning Rate [7.8125e-05]
12: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00091 (0.00101)	Tok/s 27938 (53775)	Loss/tok 2.3756 (3.1161)	Learning Rate [7.8125e-05]
11: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00090 (0.00091)	Tok/s 27959 (53658)	Loss/tok 2.3744 (3.1120)	Learning Rate [7.8125e-05]
4: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00097 (0.00099)	Tok/s 26497 (53123)	Loss/tok 2.2012 (3.1135)	Learning Rate [7.8125e-05]
9: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00088 (0.00091)	Tok/s 27923 (53503)	Loss/tok 2.3353 (3.1083)	Learning Rate [7.8125e-05]
10: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00090 (0.00096)	Tok/s 27940 (53578)	Loss/tok 2.3517 (3.1083)	Learning Rate [7.8125e-05]
6: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00090 (0.00092)	Tok/s 26348 (53280)	Loss/tok 2.4015 (3.1148)	Learning Rate [7.8125e-05]
8: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00093 (0.00098)	Tok/s 27957 (53439)	Loss/tok 2.4002 (3.1117)	Learning Rate [7.8125e-05]
5: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00084 (0.00093)	Tok/s 26415 (53207)	Loss/tok 2.6235 (3.1120)	Learning Rate [7.8125e-05]
7: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00088 (0.00097)	Tok/s 27521 (53367)	Loss/tok 2.4110 (3.1142)	Learning Rate [7.8125e-05]
3: TRAIN [2][2860/3416]	Time 0.039 (0.058)	Data 0.00101 (0.00092)	Tok/s 26132 (53028)	Loss/tok 2.2762 (3.1146)	Learning Rate [7.8125e-05]
3: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00092)	Tok/s 31310 (53053)	Loss/tok 2.5941 (3.1144)	Learning Rate [7.8125e-05]
2: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00098)	Tok/s 31306 (52953)	Loss/tok 2.8011 (3.1092)	Learning Rate [7.8125e-05]
1: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00100)	Tok/s 31326 (52843)	Loss/tok 2.5889 (3.1119)	Learning Rate [7.8125e-05]
4: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00099)	Tok/s 31227 (53148)	Loss/tok 2.5861 (3.1139)	Learning Rate [7.8125e-05]
6: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00092)	Tok/s 31219 (53304)	Loss/tok 2.5962 (3.1151)	Learning Rate [7.8125e-05]
0: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00097)	Tok/s 31316 (52750)	Loss/tok 2.6852 (3.1142)	Learning Rate [7.8125e-05]
5: TRAIN [2][2870/3416]	Time 0.046 (0.058)	Data 0.00119 (0.00093)	Tok/s 31762 (53232)	Loss/tok 2.8576 (3.1121)	Learning Rate [7.8125e-05]
15: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00092)	Tok/s 32713 (54110)	Loss/tok 2.7392 (3.1123)	Learning Rate [7.8125e-05]
7: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00097)	Tok/s 31161 (53391)	Loss/tok 2.7491 (3.1144)	Learning Rate [7.8125e-05]
8: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00097)	Tok/s 31135 (53463)	Loss/tok 2.5831 (3.1117)	Learning Rate [7.8125e-05]
14: TRAIN [2][2870/3416]	Time 0.046 (0.058)	Data 0.00113 (0.00092)	Tok/s 33212 (54000)	Loss/tok 2.4173 (3.1143)	Learning Rate [7.8125e-05]
9: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00076 (0.00091)	Tok/s 32309 (53527)	Loss/tok 2.9631 (3.1086)	Learning Rate [7.8125e-05]
13: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00096)	Tok/s 32564 (53898)	Loss/tok 2.8086 (3.1131)	Learning Rate [7.8125e-05]
11: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00091)	Tok/s 32407 (53683)	Loss/tok 2.7700 (3.1122)	Learning Rate [7.8125e-05]
10: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00096)	Tok/s 32396 (53603)	Loss/tok 2.7080 (3.1084)	Learning Rate [7.8125e-05]
12: TRAIN [2][2870/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00101)	Tok/s 32447 (53800)	Loss/tok 2.7497 (3.1162)	Learning Rate [7.8125e-05]
4: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00090 (0.00099)	Tok/s 19211 (53126)	Loss/tok 2.2258 (3.1137)	Learning Rate [7.8125e-05]
6: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00085 (0.00092)	Tok/s 22394 (53282)	Loss/tok 2.2441 (3.1150)	Learning Rate [7.8125e-05]
5: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00083 (0.00093)	Tok/s 20617 (53210)	Loss/tok 1.9764 (3.1121)	Learning Rate [7.8125e-05]
3: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00090 (0.00092)	Tok/s 16859 (53030)	Loss/tok 1.5240 (3.1143)	Learning Rate [7.8125e-05]
2: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00090 (0.00098)	Tok/s 15961 (52930)	Loss/tok 1.7683 (3.1096)	Learning Rate [7.8125e-05]
12: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00096 (0.00101)	Tok/s 26391 (53779)	Loss/tok 2.5109 (3.1162)	Learning Rate [7.8125e-05]
7: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00096 (0.00097)	Tok/s 23300 (53369)	Loss/tok 2.0503 (3.1143)	Learning Rate [7.8125e-05]
1: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00110 (0.00100)	Tok/s 12536 (52819)	Loss/tok 1.9398 (3.1117)	Learning Rate [7.8125e-05]
9: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00088 (0.00091)	Tok/s 24430 (53506)	Loss/tok 1.8520 (3.1088)	Learning Rate [7.8125e-05]
11: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00091 (0.00091)	Tok/s 24482 (53661)	Loss/tok 1.9440 (3.1121)	Learning Rate [7.8125e-05]
8: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00092 (0.00098)	Tok/s 24395 (53442)	Loss/tok 1.8238 (3.1118)	Learning Rate [7.8125e-05]
0: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00095 (0.00097)	Tok/s 9379 (52725)	Loss/tok 1.5468 (3.1142)	Learning Rate [7.8125e-05]
10: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00083 (0.00096)	Tok/s 24436 (53581)	Loss/tok 2.0802 (3.1084)	Learning Rate [7.8125e-05]
15: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00099 (0.00092)	Tok/s 28134 (54089)	Loss/tok 2.2640 (3.1123)	Learning Rate [7.8125e-05]
14: TRAIN [2][2880/3416]	Time 0.034 (0.058)	Data 0.00092 (0.00092)	Tok/s 26877 (53980)	Loss/tok 2.3433 (3.1142)	Learning Rate [7.8125e-05]
13: TRAIN [2][2880/3416]	Time 0.035 (0.058)	Data 0.00100 (0.00096)	Tok/s 25576 (53878)	Loss/tok 2.4128 (3.1131)	Learning Rate [7.8125e-05]
10: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00096)	Tok/s 53183 (53577)	Loss/tok 3.2007 (3.1087)	Learning Rate [7.8125e-05]
9: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00091)	Tok/s 53188 (53502)	Loss/tok 2.9666 (3.1087)	Learning Rate [7.8125e-05]
11: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00091)	Tok/s 53114 (53657)	Loss/tok 3.4597 (3.1121)	Learning Rate [7.8125e-05]
8: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00098)	Tok/s 53179 (53439)	Loss/tok 2.9221 (3.1116)	Learning Rate [7.8125e-05]
7: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00097)	Tok/s 53113 (53366)	Loss/tok 3.4743 (3.1144)	Learning Rate [7.8125e-05]
6: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00092)	Tok/s 53080 (53279)	Loss/tok 3.1814 (3.1151)	Learning Rate [7.8125e-05]
12: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00106 (0.00101)	Tok/s 53012 (53775)	Loss/tok 2.8330 (3.1160)	Learning Rate [7.8125e-05]
13: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00096)	Tok/s 53059 (53874)	Loss/tok 3.2105 (3.1130)	Learning Rate [7.8125e-05]
14: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00092)	Tok/s 52989 (53975)	Loss/tok 3.1929 (3.1141)	Learning Rate [7.8125e-05]
5: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00093)	Tok/s 53122 (53207)	Loss/tok 3.2611 (3.1121)	Learning Rate [7.8125e-05]
15: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00092)	Tok/s 52963 (54084)	Loss/tok 3.1815 (3.1122)	Learning Rate [7.8125e-05]
4: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00105 (0.00099)	Tok/s 53114 (53123)	Loss/tok 3.1256 (3.1138)	Learning Rate [7.8125e-05]
0: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00097)	Tok/s 52957 (52722)	Loss/tok 3.3217 (3.1142)	Learning Rate [7.8125e-05]
3: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00116 (0.00092)	Tok/s 53143 (53027)	Loss/tok 3.1343 (3.1143)	Learning Rate [7.8125e-05]
1: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00110 (0.00100)	Tok/s 52965 (52816)	Loss/tok 3.1847 (3.1119)	Learning Rate [7.8125e-05]
2: TRAIN [2][2890/3416]	Time 0.063 (0.058)	Data 0.00110 (0.00098)	Tok/s 52994 (52927)	Loss/tok 3.4124 (3.1097)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
1: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00106 (0.00100)	Tok/s 41390 (52811)	Loss/tok 3.1618 (3.1121)	Learning Rate [7.8125e-05]
0: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00097)	Tok/s 41367 (52718)	Loss/tok 2.9453 (3.1141)	Learning Rate [7.8125e-05]
2: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00098)	Tok/s 41288 (52922)	Loss/tok 3.1386 (3.1097)	Learning Rate [7.8125e-05]
15: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00092)	Tok/s 42672 (54080)	Loss/tok 2.8114 (3.1126)	Learning Rate [7.8125e-05]
3: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00092)	Tok/s 41160 (53022)	Loss/tok 2.8433 (3.1144)	Learning Rate [7.8125e-05]
14: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00092)	Tok/s 42702 (53971)	Loss/tok 2.7867 (3.1139)	Learning Rate [7.8125e-05]
4: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00099)	Tok/s 41061 (53118)	Loss/tok 2.8899 (3.1136)	Learning Rate [7.8125e-05]
5: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00093)	Tok/s 41088 (53203)	Loss/tok 2.7609 (3.1119)	Learning Rate [7.8125e-05]
6: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00092)	Tok/s 41077 (53275)	Loss/tok 2.9669 (3.1152)	Learning Rate [7.8125e-05]
13: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00096)	Tok/s 42180 (53869)	Loss/tok 3.0433 (3.1130)	Learning Rate [7.8125e-05]
11: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00091)	Tok/s 41299 (53653)	Loss/tok 2.9991 (3.1121)	Learning Rate [7.8125e-05]
12: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00100)	Tok/s 41368 (53771)	Loss/tok 3.0087 (3.1161)	Learning Rate [7.8125e-05]
7: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00097)	Tok/s 41096 (53361)	Loss/tok 2.8844 (3.1147)	Learning Rate [7.8125e-05]
9: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00091)	Tok/s 41199 (53498)	Loss/tok 2.9674 (3.1088)	Learning Rate [7.8125e-05]
8: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00098)	Tok/s 41053 (53434)	Loss/tok 2.8338 (3.1117)	Learning Rate [7.8125e-05]
10: TRAIN [2][2900/3416]	Time 0.048 (0.058)	Data 0.00118 (0.00096)	Tok/s 41458 (53573)	Loss/tok 3.0319 (3.1085)	Learning Rate [7.8125e-05]
1: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00109 (0.00100)	Tok/s 53087 (52797)	Loss/tok 3.1523 (3.1120)	Learning Rate [7.8125e-05]
0: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00097)	Tok/s 53090 (52702)	Loss/tok 2.9090 (3.1136)	Learning Rate [7.8125e-05]
3: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00092)	Tok/s 53008 (53009)	Loss/tok 3.2387 (3.1141)	Learning Rate [7.8125e-05]
4: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00099)	Tok/s 53030 (53106)	Loss/tok 3.2313 (3.1133)	Learning Rate [7.8125e-05]
2: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00109 (0.00098)	Tok/s 53116 (52909)	Loss/tok 3.1456 (3.1091)	Learning Rate [7.8125e-05]
15: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00092)	Tok/s 53123 (54071)	Loss/tok 2.8124 (3.1121)	Learning Rate [7.8125e-05]
5: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00093)	Tok/s 52992 (53191)	Loss/tok 2.9208 (3.1116)	Learning Rate [7.8125e-05]
6: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00092)	Tok/s 52992 (53263)	Loss/tok 3.1567 (3.1149)	Learning Rate [7.8125e-05]
14: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00092)	Tok/s 53082 (53961)	Loss/tok 3.3181 (3.1135)	Learning Rate [7.8125e-05]
13: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00096)	Tok/s 53097 (53859)	Loss/tok 3.1235 (3.1127)	Learning Rate [7.8125e-05]
11: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00091)	Tok/s 53066 (53643)	Loss/tok 3.1403 (3.1118)	Learning Rate [7.8125e-05]
7: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00097)	Tok/s 52995 (53350)	Loss/tok 3.1095 (3.1143)	Learning Rate [7.8125e-05]
12: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00108 (0.00100)	Tok/s 53072 (53761)	Loss/tok 3.1241 (3.1159)	Learning Rate [7.8125e-05]
9: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00091)	Tok/s 52996 (53486)	Loss/tok 3.1351 (3.1083)	Learning Rate [7.8125e-05]
8: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00109 (0.00098)	Tok/s 52996 (53423)	Loss/tok 2.9814 (3.1114)	Learning Rate [7.8125e-05]
10: TRAIN [2][2910/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00096)	Tok/s 53025 (53563)	Loss/tok 3.4539 (3.1085)	Learning Rate [7.8125e-05]
11: Gradient norm: inf
11: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
12: Gradient norm: inf
9: Gradient norm: inf
13: Gradient norm: inf
12: Skipped batch, new scale: 2048.0
10: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
8: Gradient norm: inf
1: Gradient norm: inf
13: Skipped batch, new scale: 2048.0
14: Gradient norm: inf
2: Gradient norm: inf
0: Gradient norm: inf
7: Gradient norm: inf
15: Gradient norm: inf
8: Skipped batch, new scale: 2048.0
1: Skipped batch, new scale: 2048.0
3: Gradient norm: inf
2: Skipped batch, new scale: 2048.0
14: Skipped batch, new scale: 2048.0
6: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
7: Skipped batch, new scale: 2048.0
15: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
5: Gradient norm: inf
4: Gradient norm: inf
6: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
4: Skipped batch, new scale: 2048.0
13: TRAIN [2][2920/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00096)	Tok/s 58913 (53866)	Loss/tok 3.2003 (3.1125)	Learning Rate [7.8125e-05]
12: TRAIN [2][2920/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00100)	Tok/s 58839 (53768)	Loss/tok 3.1033 (3.1157)	Learning Rate [7.8125e-05]
10: TRAIN [2][2920/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00096)	Tok/s 57551 (53570)	Loss/tok 2.9381 (3.1083)	Learning Rate [7.8125e-05]
14: TRAIN [2][2920/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00092)	Tok/s 58732 (53968)	Loss/tok 3.0900 (3.1133)	Learning Rate [7.8125e-05]
15: TRAIN [2][2920/3416]	Time 0.062 (0.058)	Data 0.00084 (0.00092)	Tok/s 58656 (54078)	Loss/tok 3.1624 (3.1123)	Learning Rate [7.8125e-05]
11: TRAIN [2][2920/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00091)	Tok/s 58280 (53650)	Loss/tok 3.1000 (3.1118)	Learning Rate [7.8125e-05]
0: TRAIN [2][2920/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00097)	Tok/s 57535 (52709)	Loss/tok 3.1155 (3.1137)	Learning Rate [7.8125e-05]
9: TRAIN [2][2920/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00091)	Tok/s 57389 (53494)	Loss/tok 3.1157 (3.1082)	Learning Rate [7.8125e-05]
8: TRAIN [2][2920/3416]	Time 0.063 (0.058)	Data 0.00110 (0.00098)	Tok/s 57316 (53430)	Loss/tok 3.1878 (3.1116)	Learning Rate [7.8125e-05]
1: TRAIN [2][2920/3416]	Time 0.062 (0.058)	Data 0.00103 (0.00100)	Tok/s 57413 (52804)	Loss/tok 3.2356 (3.1120)	Learning Rate [7.8125e-05]
2: TRAIN [2][2920/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00098)	Tok/s 57331 (52916)	Loss/tok 2.9280 (3.1088)	Learning Rate [7.8125e-05]
7: TRAIN [2][2920/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00097)	Tok/s 57185 (53357)	Loss/tok 3.3306 (3.1143)	Learning Rate [7.8125e-05]
6: TRAIN [2][2920/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00092)	Tok/s 56979 (53270)	Loss/tok 3.0917 (3.1147)	Learning Rate [7.8125e-05]
3: TRAIN [2][2920/3416]	Time 0.063 (0.058)	Data 0.00080 (0.00092)	Tok/s 57190 (53016)	Loss/tok 3.2008 (3.1140)	Learning Rate [7.8125e-05]
4: TRAIN [2][2920/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00099)	Tok/s 57092 (53113)	Loss/tok 3.3287 (3.1132)	Learning Rate [7.8125e-05]
5: TRAIN [2][2920/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00093)	Tok/s 57051 (53198)	Loss/tok 3.3969 (3.1114)	Learning Rate [7.8125e-05]
1: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00108 (0.00100)	Tok/s 48244 (52793)	Loss/tok 2.9009 (3.1118)	Learning Rate [7.8125e-05]
2: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00107 (0.00098)	Tok/s 48128 (52905)	Loss/tok 2.9417 (3.1086)	Learning Rate [7.8125e-05]
3: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00085 (0.00092)	Tok/s 48095 (53005)	Loss/tok 2.6786 (3.1139)	Learning Rate [7.8125e-05]
0: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00097)	Tok/s 48181 (52698)	Loss/tok 2.8875 (3.1135)	Learning Rate [7.8125e-05]
9: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00078 (0.00091)	Tok/s 49324 (53482)	Loss/tok 3.0358 (3.1080)	Learning Rate [7.8125e-05]
15: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00085 (0.00092)	Tok/s 49693 (54065)	Loss/tok 2.9195 (3.1123)	Learning Rate [7.8125e-05]
5: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00081 (0.00093)	Tok/s 47857 (53186)	Loss/tok 3.0932 (3.1111)	Learning Rate [7.8125e-05]
4: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00099)	Tok/s 47891 (53101)	Loss/tok 2.8671 (3.1131)	Learning Rate [7.8125e-05]
6: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00085 (0.00092)	Tok/s 47777 (53259)	Loss/tok 3.1919 (3.1146)	Learning Rate [7.8125e-05]
14: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00092)	Tok/s 49631 (53956)	Loss/tok 3.1857 (3.1132)	Learning Rate [7.8125e-05]
10: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00082 (0.00096)	Tok/s 49356 (53559)	Loss/tok 3.2612 (3.1083)	Learning Rate [7.8125e-05]
11: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00085 (0.00091)	Tok/s 49295 (53639)	Loss/tok 3.2053 (3.1116)	Learning Rate [7.8125e-05]
7: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00097)	Tok/s 47801 (53345)	Loss/tok 3.1918 (3.1143)	Learning Rate [7.8125e-05]
8: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00108 (0.00098)	Tok/s 48293 (53419)	Loss/tok 2.8843 (3.1114)	Learning Rate [7.8125e-05]
13: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00096)	Tok/s 49500 (53854)	Loss/tok 2.9160 (3.1124)	Learning Rate [7.8125e-05]
12: TRAIN [2][2930/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00100)	Tok/s 49337 (53756)	Loss/tok 3.2136 (3.1156)	Learning Rate [7.8125e-05]
4: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00099)	Tok/s 48873 (53119)	Loss/tok 3.0897 (3.1128)	Learning Rate [7.8125e-05]
7: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00097)	Tok/s 48797 (53362)	Loss/tok 3.0761 (3.1145)	Learning Rate [7.8125e-05]
9: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00091)	Tok/s 48771 (53500)	Loss/tok 2.9983 (3.1081)	Learning Rate [7.8125e-05]
5: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00093)	Tok/s 48746 (53204)	Loss/tok 2.9751 (3.1111)	Learning Rate [7.8125e-05]
8: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00109 (0.00098)	Tok/s 48722 (53436)	Loss/tok 3.1694 (3.1113)	Learning Rate [7.8125e-05]
3: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00092)	Tok/s 48728 (53022)	Loss/tok 3.1026 (3.1135)	Learning Rate [7.8125e-05]
2: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00098)	Tok/s 48731 (52922)	Loss/tok 3.3605 (3.1087)	Learning Rate [7.8125e-05]
1: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00105 (0.00100)	Tok/s 48803 (52811)	Loss/tok 2.9625 (3.1117)	Learning Rate [7.8125e-05]
10: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00096)	Tok/s 48734 (53576)	Loss/tok 2.9547 (3.1081)	Learning Rate [7.8125e-05]
12: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00100)	Tok/s 49198 (53774)	Loss/tok 3.1135 (3.1157)	Learning Rate [7.8125e-05]
0: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00097)	Tok/s 48704 (52717)	Loss/tok 3.2479 (3.1136)	Learning Rate [7.8125e-05]
15: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00081 (0.00092)	Tok/s 48695 (54084)	Loss/tok 3.0255 (3.1121)	Learning Rate [7.8125e-05]
14: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00092)	Tok/s 48688 (53974)	Loss/tok 2.9580 (3.1130)	Learning Rate [7.8125e-05]
13: TRAIN [2][2940/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00096)	Tok/s 48774 (53872)	Loss/tok 3.0099 (3.1123)	Learning Rate [7.8125e-05]
6: TRAIN [2][2940/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00092)	Tok/s 47877 (53275)	Loss/tok 3.0335 (3.1143)	Learning Rate [7.8125e-05]
11: TRAIN [2][2940/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00091)	Tok/s 47812 (53656)	Loss/tok 2.8138 (3.1116)	Learning Rate [7.8125e-05]
2: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00098)	Tok/s 66790 (52931)	Loss/tok 3.3675 (3.1089)	Learning Rate [7.8125e-05]
1: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 66803 (52820)	Loss/tok 3.3017 (3.1118)	Learning Rate [7.8125e-05]
3: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 66744 (53031)	Loss/tok 3.1268 (3.1135)	Learning Rate [7.8125e-05]
4: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00099)	Tok/s 66778 (53127)	Loss/tok 3.3234 (3.1129)	Learning Rate [7.8125e-05]
0: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 66805 (52726)	Loss/tok 3.2268 (3.1136)	Learning Rate [7.8125e-05]
6: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00092)	Tok/s 67183 (53284)	Loss/tok 3.1316 (3.1144)	Learning Rate [7.8125e-05]
5: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 66808 (53212)	Loss/tok 3.1545 (3.1111)	Learning Rate [7.8125e-05]
14: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 67718 (53981)	Loss/tok 3.0449 (3.1129)	Learning Rate [7.8125e-05]
13: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 67805 (53880)	Loss/tok 3.0052 (3.1122)	Learning Rate [7.8125e-05]
7: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 67771 (53370)	Loss/tok 3.2339 (3.1145)	Learning Rate [7.8125e-05]
12: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 67708 (53781)	Loss/tok 3.3521 (3.1155)	Learning Rate [7.8125e-05]
11: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00091)	Tok/s 67746 (53664)	Loss/tok 3.2915 (3.1118)	Learning Rate [7.8125e-05]
9: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 67733 (53507)	Loss/tok 3.1287 (3.1081)	Learning Rate [7.8125e-05]
8: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00098)	Tok/s 67788 (53443)	Loss/tok 3.2263 (3.1116)	Learning Rate [7.8125e-05]
10: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 67758 (53584)	Loss/tok 3.0836 (3.1083)	Learning Rate [7.8125e-05]
15: TRAIN [2][2950/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 67704 (54091)	Loss/tok 3.2245 (3.1123)	Learning Rate [7.8125e-05]
6: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00107 (0.00092)	Tok/s 29733 (53283)	Loss/tok 2.4663 (3.1143)	Learning Rate [7.8125e-05]
5: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00108 (0.00093)	Tok/s 29679 (53211)	Loss/tok 2.5534 (3.1111)	Learning Rate [7.8125e-05]
7: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00100 (0.00097)	Tok/s 30661 (53370)	Loss/tok 2.7585 (3.1144)	Learning Rate [7.8125e-05]
8: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00099 (0.00098)	Tok/s 31216 (53444)	Loss/tok 2.5598 (3.1117)	Learning Rate [7.8125e-05]
9: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00100 (0.00091)	Tok/s 31347 (53507)	Loss/tok 2.5839 (3.1081)	Learning Rate [7.8125e-05]
3: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00092)	Tok/s 29668 (53031)	Loss/tok 2.6147 (3.1134)	Learning Rate [7.8125e-05]
2: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00112 (0.00098)	Tok/s 29664 (52931)	Loss/tok 2.5945 (3.1089)	Learning Rate [7.8125e-05]
11: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00104 (0.00091)	Tok/s 31163 (53664)	Loss/tok 2.5720 (3.1117)	Learning Rate [7.8125e-05]
1: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00100 (0.00100)	Tok/s 29649 (52820)	Loss/tok 2.5479 (3.1119)	Learning Rate [7.8125e-05]
4: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00130 (0.00099)	Tok/s 29634 (53127)	Loss/tok 2.4131 (3.1127)	Learning Rate [7.8125e-05]
10: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00108 (0.00096)	Tok/s 31129 (53584)	Loss/tok 2.4753 (3.1084)	Learning Rate [7.8125e-05]
0: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00105 (0.00097)	Tok/s 29642 (52727)	Loss/tok 2.6109 (3.1135)	Learning Rate [7.8125e-05]
12: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00104 (0.00100)	Tok/s 31176 (53781)	Loss/tok 2.5215 (3.1154)	Learning Rate [7.8125e-05]
14: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00112 (0.00092)	Tok/s 31140 (53981)	Loss/tok 2.5661 (3.1133)	Learning Rate [7.8125e-05]
13: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00108 (0.00096)	Tok/s 31149 (53880)	Loss/tok 2.7050 (3.1121)	Learning Rate [7.8125e-05]
15: TRAIN [2][2960/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00092)	Tok/s 31097 (54090)	Loss/tok 2.5959 (3.1122)	Learning Rate [7.8125e-05]
3: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00083 (0.00092)	Tok/s 50716 (53024)	Loss/tok 3.0634 (3.1131)	Learning Rate [7.8125e-05]
2: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00106 (0.00098)	Tok/s 50737 (52924)	Loss/tok 3.1218 (3.1087)	Learning Rate [7.8125e-05]
4: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00110 (0.00099)	Tok/s 50581 (53119)	Loss/tok 2.8710 (3.1125)	Learning Rate [7.8125e-05]
1: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00100)	Tok/s 50663 (52813)	Loss/tok 3.3917 (3.1119)	Learning Rate [7.8125e-05]
0: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00097)	Tok/s 50618 (52720)	Loss/tok 2.9382 (3.1133)	Learning Rate [7.8125e-05]
6: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00092)	Tok/s 50414 (53275)	Loss/tok 3.1624 (3.1143)	Learning Rate [7.8125e-05]
5: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00093)	Tok/s 50482 (53203)	Loss/tok 3.0129 (3.1106)	Learning Rate [7.8125e-05]
15: TRAIN [2][2970/3416]	Time 0.055 (0.058)	Data 0.00080 (0.00092)	Tok/s 52049 (54084)	Loss/tok 3.0325 (3.1119)	Learning Rate [7.8125e-05]
7: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00097)	Tok/s 50277 (53362)	Loss/tok 2.8981 (3.1143)	Learning Rate [7.8125e-05]
8: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00098)	Tok/s 50272 (53436)	Loss/tok 3.0214 (3.1114)	Learning Rate [7.8125e-05]
14: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00092)	Tok/s 51596 (53974)	Loss/tok 2.9069 (3.1131)	Learning Rate [7.8125e-05]
13: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00096)	Tok/s 51540 (53872)	Loss/tok 3.1655 (3.1119)	Learning Rate [7.8125e-05]
9: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00091)	Tok/s 50231 (53499)	Loss/tok 3.0461 (3.1079)	Learning Rate [7.8125e-05]
11: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00091)	Tok/s 51056 (53656)	Loss/tok 2.9873 (3.1114)	Learning Rate [7.8125e-05]
10: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00096)	Tok/s 50150 (53576)	Loss/tok 2.8931 (3.1082)	Learning Rate [7.8125e-05]
12: TRAIN [2][2970/3416]	Time 0.056 (0.058)	Data 0.00099 (0.00100)	Tok/s 51410 (53773)	Loss/tok 3.0522 (3.1151)	Learning Rate [7.8125e-05]
11: TRAIN [2][2980/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00091)	Tok/s 47956 (53648)	Loss/tok 2.9834 (3.1111)	Learning Rate [7.8125e-05]
12: TRAIN [2][2980/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00100)	Tok/s 48046 (53765)	Loss/tok 3.2085 (3.1150)	Learning Rate [7.8125e-05]
10: TRAIN [2][2980/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00096)	Tok/s 47874 (53568)	Loss/tok 3.0707 (3.1078)	Learning Rate [7.8125e-05]
9: TRAIN [2][2980/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00091)	Tok/s 47865 (53492)	Loss/tok 3.0821 (3.1076)	Learning Rate [7.8125e-05]
13: TRAIN [2][2980/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00096)	Tok/s 47965 (53864)	Loss/tok 3.1028 (3.1117)	Learning Rate [7.8125e-05]
8: TRAIN [2][2980/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00098)	Tok/s 47862 (53428)	Loss/tok 3.1019 (3.1114)	Learning Rate [7.8125e-05]
14: TRAIN [2][2980/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00092)	Tok/s 47970 (53966)	Loss/tok 2.9188 (3.1129)	Learning Rate [7.8125e-05]
7: TRAIN [2][2980/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00097)	Tok/s 47609 (53354)	Loss/tok 3.0941 (3.1142)	Learning Rate [7.8125e-05]
6: TRAIN [2][2980/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00092)	Tok/s 46368 (53266)	Loss/tok 2.6908 (3.1139)	Learning Rate [7.8125e-05]
0: TRAIN [2][2980/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00097)	Tok/s 46457 (52711)	Loss/tok 2.9318 (3.1131)	Learning Rate [7.8125e-05]
4: TRAIN [2][2980/3416]	Time 0.045 (0.058)	Data 0.00116 (0.00099)	Tok/s 46475 (53110)	Loss/tok 2.9483 (3.1124)	Learning Rate [7.8125e-05]
5: TRAIN [2][2980/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00093)	Tok/s 46325 (53194)	Loss/tok 2.9953 (3.1108)	Learning Rate [7.8125e-05]
1: TRAIN [2][2980/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00100)	Tok/s 46323 (52804)	Loss/tok 2.8349 (3.1119)	Learning Rate [7.8125e-05]
15: TRAIN [2][2980/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00092)	Tok/s 47955 (54075)	Loss/tok 2.9365 (3.1119)	Learning Rate [7.8125e-05]
2: TRAIN [2][2980/3416]	Time 0.046 (0.058)	Data 0.00111 (0.00098)	Tok/s 46372 (52915)	Loss/tok 3.1147 (3.1088)	Learning Rate [7.8125e-05]
3: TRAIN [2][2980/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00092)	Tok/s 46380 (53014)	Loss/tok 2.8112 (3.1132)	Learning Rate [7.8125e-05]
13: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00096)	Tok/s 51345 (53875)	Loss/tok 3.2321 (3.1116)	Learning Rate [7.8125e-05]
14: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00092)	Tok/s 51322 (53977)	Loss/tok 3.0209 (3.1126)	Learning Rate [7.8125e-05]
12: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00100)	Tok/s 51266 (53776)	Loss/tok 2.9995 (3.1151)	Learning Rate [7.8125e-05]
11: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00091)	Tok/s 51111 (53659)	Loss/tok 2.8265 (3.1108)	Learning Rate [7.8125e-05]
15: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00092)	Tok/s 51187 (54087)	Loss/tok 3.0250 (3.1121)	Learning Rate [7.8125e-05]
9: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00091)	Tok/s 50992 (53502)	Loss/tok 3.0823 (3.1081)	Learning Rate [7.8125e-05]
10: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00096)	Tok/s 51099 (53579)	Loss/tok 2.9623 (3.1078)	Learning Rate [7.8125e-05]
8: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00098)	Tok/s 50968 (53439)	Loss/tok 3.3027 (3.1115)	Learning Rate [7.8125e-05]
0: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00097)	Tok/s 51135 (52722)	Loss/tok 3.0361 (3.1132)	Learning Rate [7.8125e-05]
1: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00100)	Tok/s 51029 (52815)	Loss/tok 3.1953 (3.1119)	Learning Rate [7.8125e-05]
7: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00097)	Tok/s 50852 (53365)	Loss/tok 3.0336 (3.1143)	Learning Rate [7.8125e-05]
6: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00102 (0.00092)	Tok/s 50862 (53277)	Loss/tok 3.2246 (3.1138)	Learning Rate [7.8125e-05]
2: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00106 (0.00098)	Tok/s 50887 (52926)	Loss/tok 3.0616 (3.1086)	Learning Rate [7.8125e-05]
4: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00115 (0.00099)	Tok/s 50810 (53122)	Loss/tok 3.1797 (3.1124)	Learning Rate [7.8125e-05]
3: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00092)	Tok/s 50802 (53025)	Loss/tok 2.9544 (3.1132)	Learning Rate [7.8125e-05]
5: TRAIN [2][2990/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00093)	Tok/s 50800 (53205)	Loss/tok 3.1029 (3.1107)	Learning Rate [7.8125e-05]
6: TRAIN [2][3000/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 66363 (53276)	Loss/tok 3.2313 (3.1140)	Learning Rate [7.8125e-05]
5: TRAIN [2][3000/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00093)	Tok/s 66240 (53204)	Loss/tok 3.2130 (3.1108)	Learning Rate [7.8125e-05]
7: TRAIN [2][3000/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 66270 (53363)	Loss/tok 3.3229 (3.1143)	Learning Rate [7.8125e-05]
3: TRAIN [2][3000/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 66181 (53024)	Loss/tok 3.0305 (3.1131)	Learning Rate [7.8125e-05]
4: TRAIN [2][3000/3416]	Time 0.070 (0.058)	Data 0.00120 (0.00099)	Tok/s 66119 (53121)	Loss/tok 3.1728 (3.1126)	Learning Rate [7.8125e-05]
8: TRAIN [2][3000/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00098)	Tok/s 66316 (53437)	Loss/tok 3.1738 (3.1116)	Learning Rate [7.8125e-05]
9: TRAIN [2][3000/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00091)	Tok/s 67171 (53501)	Loss/tok 3.5672 (3.1084)	Learning Rate [7.8125e-05]
2: TRAIN [2][3000/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00098)	Tok/s 66197 (52925)	Loss/tok 3.1620 (3.1088)	Learning Rate [7.8125e-05]
11: TRAIN [2][3000/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00091)	Tok/s 67273 (53657)	Loss/tok 3.1979 (3.1108)	Learning Rate [7.8125e-05]
1: TRAIN [2][3000/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00100)	Tok/s 66175 (52814)	Loss/tok 3.2714 (3.1119)	Learning Rate [7.8125e-05]
12: TRAIN [2][3000/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00100)	Tok/s 67299 (53773)	Loss/tok 3.4127 (3.1153)	Learning Rate [7.8125e-05]
10: TRAIN [2][3000/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00096)	Tok/s 67134 (53576)	Loss/tok 3.2108 (3.1079)	Learning Rate [7.8125e-05]
15: TRAIN [2][3000/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 67168 (54084)	Loss/tok 3.0517 (3.1119)	Learning Rate [7.8125e-05]
0: TRAIN [2][3000/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 66164 (52722)	Loss/tok 3.3639 (3.1133)	Learning Rate [7.8125e-05]
14: TRAIN [2][3000/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 67168 (53975)	Loss/tok 3.4038 (3.1127)	Learning Rate [7.8125e-05]
13: TRAIN [2][3000/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 67185 (53873)	Loss/tok 3.1771 (3.1116)	Learning Rate [7.8125e-05]
7: TRAIN [2][3010/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 61757 (53384)	Loss/tok 3.2031 (3.1142)	Learning Rate [7.8125e-05]
8: TRAIN [2][3010/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 61786 (53458)	Loss/tok 3.3989 (3.1117)	Learning Rate [7.8125e-05]
9: TRAIN [2][3010/3416]	Time 0.069 (0.058)	Data 0.00078 (0.00091)	Tok/s 61709 (53521)	Loss/tok 3.5004 (3.1087)	Learning Rate [7.8125e-05]
5: TRAIN [2][3010/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00093)	Tok/s 61667 (53225)	Loss/tok 3.2108 (3.1112)	Learning Rate [7.8125e-05]
6: TRAIN [2][3010/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 61642 (53297)	Loss/tok 3.4460 (3.1141)	Learning Rate [7.8125e-05]
4: TRAIN [2][3010/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00099)	Tok/s 61610 (53141)	Loss/tok 3.0531 (3.1126)	Learning Rate [7.8125e-05]
10: TRAIN [2][3010/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 61749 (53597)	Loss/tok 3.0491 (3.1077)	Learning Rate [7.8125e-05]
3: TRAIN [2][3010/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 61643 (53045)	Loss/tok 3.2597 (3.1134)	Learning Rate [7.8125e-05]
11: TRAIN [2][3010/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00091)	Tok/s 61756 (53677)	Loss/tok 3.1042 (3.1108)	Learning Rate [7.8125e-05]
2: TRAIN [2][3010/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 61650 (52946)	Loss/tok 3.2286 (3.1092)	Learning Rate [7.8125e-05]
1: TRAIN [2][3010/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 61666 (52836)	Loss/tok 3.1516 (3.1117)	Learning Rate [7.8125e-05]
0: TRAIN [2][3010/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 61653 (52743)	Loss/tok 3.3151 (3.1137)	Learning Rate [7.8125e-05]
13: TRAIN [2][3010/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00096)	Tok/s 61743 (53894)	Loss/tok 3.3140 (3.1117)	Learning Rate [7.8125e-05]
12: TRAIN [2][3010/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 61716 (53794)	Loss/tok 3.1139 (3.1154)	Learning Rate [7.8125e-05]
14: TRAIN [2][3010/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 61635 (53995)	Loss/tok 3.2008 (3.1129)	Learning Rate [7.8125e-05]
15: TRAIN [2][3010/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 62510 (54105)	Loss/tok 3.3755 (3.1123)	Learning Rate [7.8125e-05]
2: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00098)	Tok/s 52565 (52942)	Loss/tok 3.0811 (3.1091)	Learning Rate [7.8125e-05]
3: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00092)	Tok/s 52549 (53041)	Loss/tok 3.2429 (3.1132)	Learning Rate [7.8125e-05]
1: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00082 (0.00100)	Tok/s 52562 (52832)	Loss/tok 3.2050 (3.1116)	Learning Rate [7.8125e-05]
0: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00097)	Tok/s 52560 (52739)	Loss/tok 3.1771 (3.1134)	Learning Rate [7.8125e-05]
15: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00092)	Tok/s 53665 (54101)	Loss/tok 3.0592 (3.1121)	Learning Rate [7.8125e-05]
5: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00093)	Tok/s 52546 (53220)	Loss/tok 3.0539 (3.1110)	Learning Rate [7.8125e-05]
6: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00092)	Tok/s 52513 (53292)	Loss/tok 3.0177 (3.1139)	Learning Rate [7.8125e-05]
4: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00108 (0.00099)	Tok/s 52491 (53137)	Loss/tok 3.2972 (3.1126)	Learning Rate [7.8125e-05]
14: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00092)	Tok/s 53639 (53992)	Loss/tok 3.3577 (3.1127)	Learning Rate [7.8125e-05]
13: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00096)	Tok/s 53593 (53890)	Loss/tok 3.3929 (3.1116)	Learning Rate [7.8125e-05]
12: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00100)	Tok/s 53585 (53791)	Loss/tok 3.4427 (3.1153)	Learning Rate [7.8125e-05]
9: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00091)	Tok/s 52549 (53518)	Loss/tok 3.3731 (3.1086)	Learning Rate [7.8125e-05]
8: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00098)	Tok/s 52529 (53453)	Loss/tok 3.1313 (3.1116)	Learning Rate [7.8125e-05]
11: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00091)	Tok/s 53368 (53674)	Loss/tok 3.2070 (3.1108)	Learning Rate [7.8125e-05]
7: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00097)	Tok/s 52492 (53379)	Loss/tok 3.3329 (3.1142)	Learning Rate [7.8125e-05]
10: TRAIN [2][3020/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00096)	Tok/s 52554 (53594)	Loss/tok 3.3568 (3.1076)	Learning Rate [7.8125e-05]
13: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00096)	Tok/s 57066 (53895)	Loss/tok 3.2634 (3.1118)	Learning Rate [7.8125e-05]
12: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00100)	Tok/s 57087 (53796)	Loss/tok 3.1966 (3.1153)	Learning Rate [7.8125e-05]
11: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00091)	Tok/s 57077 (53679)	Loss/tok 3.4292 (3.1109)	Learning Rate [7.8125e-05]
14: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00092)	Tok/s 56960 (53997)	Loss/tok 3.1375 (3.1125)	Learning Rate [7.8125e-05]
15: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00092)	Tok/s 56955 (54106)	Loss/tok 3.2982 (3.1123)	Learning Rate [7.8125e-05]
0: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00097)	Tok/s 55954 (52744)	Loss/tok 3.0975 (3.1135)	Learning Rate [7.8125e-05]
10: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00096)	Tok/s 57061 (53599)	Loss/tok 3.2746 (3.1078)	Learning Rate [7.8125e-05]
9: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00091)	Tok/s 57041 (53522)	Loss/tok 3.3915 (3.1088)	Learning Rate [7.8125e-05]
1: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00100)	Tok/s 55961 (52837)	Loss/tok 2.8950 (3.1116)	Learning Rate [7.8125e-05]
6: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00092)	Tok/s 56653 (53297)	Loss/tok 3.1862 (3.1141)	Learning Rate [7.8125e-05]
8: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00098)	Tok/s 57083 (53458)	Loss/tok 3.2036 (3.1121)	Learning Rate [7.8125e-05]
2: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00109 (0.00098)	Tok/s 55979 (52947)	Loss/tok 3.0723 (3.1091)	Learning Rate [7.8125e-05]
4: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00114 (0.00099)	Tok/s 56145 (53142)	Loss/tok 3.1333 (3.1126)	Learning Rate [7.8125e-05]
7: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00097)	Tok/s 57093 (53384)	Loss/tok 3.0625 (3.1142)	Learning Rate [7.8125e-05]
3: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00092)	Tok/s 55986 (53046)	Loss/tok 3.2682 (3.1134)	Learning Rate [7.8125e-05]
5: TRAIN [2][3030/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00093)	Tok/s 56153 (53225)	Loss/tok 3.4948 (3.1111)	Learning Rate [7.8125e-05]
6: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 64815 (53296)	Loss/tok 3.2940 (3.1142)	Learning Rate [7.8125e-05]
8: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00098)	Tok/s 64770 (53456)	Loss/tok 3.1489 (3.1120)	Learning Rate [7.8125e-05]
9: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 64799 (53520)	Loss/tok 3.1378 (3.1087)	Learning Rate [7.8125e-05]
7: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00097)	Tok/s 64654 (53382)	Loss/tok 3.1947 (3.1144)	Learning Rate [7.8125e-05]
10: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00096)	Tok/s 64807 (53596)	Loss/tok 3.3997 (3.1081)	Learning Rate [7.8125e-05]
4: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00115 (0.00099)	Tok/s 64752 (53141)	Loss/tok 3.2035 (3.1127)	Learning Rate [7.8125e-05]
5: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 64695 (53224)	Loss/tok 3.1495 (3.1112)	Learning Rate [7.8125e-05]
11: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 65164 (53677)	Loss/tok 2.8597 (3.1111)	Learning Rate [7.8125e-05]
2: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00098)	Tok/s 64817 (52946)	Loss/tok 3.2182 (3.1095)	Learning Rate [7.8125e-05]
3: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 64732 (53045)	Loss/tok 3.3755 (3.1136)	Learning Rate [7.8125e-05]
1: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 64808 (52837)	Loss/tok 3.6279 (3.1119)	Learning Rate [7.8125e-05]
12: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 65753 (53793)	Loss/tok 3.2540 (3.1154)	Learning Rate [7.8125e-05]
13: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 65738 (53892)	Loss/tok 3.3005 (3.1118)	Learning Rate [7.8125e-05]
0: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 64842 (52744)	Loss/tok 3.1702 (3.1137)	Learning Rate [7.8125e-05]
14: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00092)	Tok/s 65748 (53994)	Loss/tok 3.2687 (3.1128)	Learning Rate [7.8125e-05]
15: TRAIN [2][3040/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 65755 (54103)	Loss/tok 3.1643 (3.1125)	Learning Rate [7.8125e-05]
11: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
14: TRAIN [2][3050/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00092)	Tok/s 60032 (53999)	Loss/tok 3.2992 (3.1127)	Learning Rate [7.8125e-05]
13: TRAIN [2][3050/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00096)	Tok/s 60063 (53897)	Loss/tok 3.3176 (3.1120)	Learning Rate [7.8125e-05]
0: TRAIN [2][3050/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00097)	Tok/s 58905 (52750)	Loss/tok 3.2538 (3.1138)	Learning Rate [7.8125e-05]
11: TRAIN [2][3050/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00091)	Tok/s 59145 (53681)	Loss/tok 3.3312 (3.1114)	Learning Rate [7.8125e-05]
12: TRAIN [2][3050/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00100)	Tok/s 59908 (53798)	Loss/tok 3.3248 (3.1156)	Learning Rate [7.8125e-05]
15: TRAIN [2][3050/3416]	Time 0.068 (0.058)	Data 0.00081 (0.00092)	Tok/s 59916 (54107)	Loss/tok 3.1739 (3.1126)	Learning Rate [7.8125e-05]
1: TRAIN [2][3050/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00100)	Tok/s 58767 (52842)	Loss/tok 3.2945 (3.1122)	Learning Rate [7.8125e-05]
2: TRAIN [2][3050/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 58797 (52952)	Loss/tok 3.1308 (3.1097)	Learning Rate [7.8125e-05]
10: TRAIN [2][3050/3416]	Time 0.068 (0.058)	Data 0.00110 (0.00096)	Tok/s 59151 (53601)	Loss/tok 3.4568 (3.1084)	Learning Rate [7.8125e-05]
9: TRAIN [2][3050/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00091)	Tok/s 59078 (53525)	Loss/tok 3.3723 (3.1088)	Learning Rate [7.8125e-05]
3: TRAIN [2][3050/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 58813 (53050)	Loss/tok 2.9518 (3.1136)	Learning Rate [7.8125e-05]
8: TRAIN [2][3050/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00098)	Tok/s 59027 (53461)	Loss/tok 3.1650 (3.1121)	Learning Rate [7.8125e-05]
4: TRAIN [2][3050/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 58793 (53146)	Loss/tok 3.2900 (3.1129)	Learning Rate [7.8125e-05]
6: TRAIN [2][3050/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00092)	Tok/s 58864 (53300)	Loss/tok 3.3871 (3.1146)	Learning Rate [7.8125e-05]
7: TRAIN [2][3050/3416]	Time 0.068 (0.058)	Data 0.00106 (0.00097)	Tok/s 58936 (53387)	Loss/tok 3.2143 (3.1147)	Learning Rate [7.8125e-05]
5: TRAIN [2][3050/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 58789 (53228)	Loss/tok 3.0799 (3.1113)	Learning Rate [7.8125e-05]
0: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00097)	Tok/s 45899 (52747)	Loss/tok 2.5871 (3.1134)	Learning Rate [7.8125e-05]
15: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00083 (0.00092)	Tok/s 47356 (54104)	Loss/tok 2.9145 (3.1125)	Learning Rate [7.8125e-05]
1: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00100)	Tok/s 45814 (52839)	Loss/tok 2.9999 (3.1123)	Learning Rate [7.8125e-05]
2: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00098)	Tok/s 45767 (52948)	Loss/tok 3.1403 (3.1095)	Learning Rate [7.8125e-05]
3: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00092)	Tok/s 45602 (53047)	Loss/tok 3.1374 (3.1136)	Learning Rate [7.8125e-05]
13: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00096)	Tok/s 47047 (53895)	Loss/tok 3.2598 (3.1117)	Learning Rate [7.8125e-05]
12: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00100)	Tok/s 46971 (53796)	Loss/tok 3.1922 (3.1154)	Learning Rate [7.8125e-05]
4: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00099)	Tok/s 46875 (53143)	Loss/tok 3.1617 (3.1128)	Learning Rate [7.8125e-05]
11: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00091)	Tok/s 46938 (53679)	Loss/tok 2.9826 (3.1113)	Learning Rate [7.8125e-05]
6: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00092)	Tok/s 47101 (53298)	Loss/tok 3.0393 (3.1146)	Learning Rate [7.8125e-05]
5: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00093)	Tok/s 47033 (53226)	Loss/tok 2.7622 (3.1112)	Learning Rate [7.8125e-05]
14: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00092)	Tok/s 46947 (53997)	Loss/tok 2.8802 (3.1126)	Learning Rate [7.8125e-05]
8: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00098)	Tok/s 46979 (53458)	Loss/tok 2.8008 (3.1119)	Learning Rate [7.8125e-05]
9: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00091)	Tok/s 46939 (53523)	Loss/tok 3.1366 (3.1089)	Learning Rate [7.8125e-05]
10: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00096)	Tok/s 46901 (53599)	Loss/tok 2.9167 (3.1084)	Learning Rate [7.8125e-05]
7: TRAIN [2][3060/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00097)	Tok/s 46996 (53384)	Loss/tok 2.7444 (3.1148)	Learning Rate [7.8125e-05]
9: TRAIN [2][3070/3416]	Time 0.068 (0.058)	Data 0.00080 (0.00091)	Tok/s 58904 (53526)	Loss/tok 3.1439 (3.1088)	Learning Rate [7.8125e-05]
8: TRAIN [2][3070/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00098)	Tok/s 58926 (53462)	Loss/tok 3.3667 (3.1122)	Learning Rate [7.8125e-05]
7: TRAIN [2][3070/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00097)	Tok/s 57973 (53388)	Loss/tok 3.0783 (3.1148)	Learning Rate [7.8125e-05]
11: TRAIN [2][3070/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00091)	Tok/s 58747 (53683)	Loss/tok 3.1003 (3.1109)	Learning Rate [7.8125e-05]
10: TRAIN [2][3070/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 58857 (53602)	Loss/tok 3.2577 (3.1085)	Learning Rate [7.8125e-05]
6: TRAIN [2][3070/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 57850 (53301)	Loss/tok 3.1366 (3.1149)	Learning Rate [7.8125e-05]
12: TRAIN [2][3070/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 58623 (53799)	Loss/tok 3.0832 (3.1157)	Learning Rate [7.8125e-05]
5: TRAIN [2][3070/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 57715 (53229)	Loss/tok 3.2008 (3.1114)	Learning Rate [7.8125e-05]
13: TRAIN [2][3070/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 58551 (53898)	Loss/tok 3.4506 (3.1121)	Learning Rate [7.8125e-05]
4: TRAIN [2][3070/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00099)	Tok/s 57626 (53147)	Loss/tok 3.0786 (3.1130)	Learning Rate [7.8125e-05]
14: TRAIN [2][3070/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 58501 (54000)	Loss/tok 3.2935 (3.1128)	Learning Rate [7.8125e-05]
3: TRAIN [2][3070/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 57569 (53051)	Loss/tok 3.2504 (3.1139)	Learning Rate [7.8125e-05]
2: TRAIN [2][3070/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 57485 (52952)	Loss/tok 3.1284 (3.1097)	Learning Rate [7.8125e-05]
0: TRAIN [2][3070/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 57349 (52751)	Loss/tok 3.2547 (3.1136)	Learning Rate [7.8125e-05]
15: TRAIN [2][3070/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 58312 (54107)	Loss/tok 3.1280 (3.1125)	Learning Rate [7.8125e-05]
1: TRAIN [2][3070/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00100)	Tok/s 57325 (52843)	Loss/tok 3.1065 (3.1127)	Learning Rate [7.8125e-05]
15: Gradient norm: inf
14: Gradient norm: inf
0: Gradient norm: inf
15: Skipped batch, new scale: 2048.0
14: Skipped batch, new scale: 2048.0
13: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
6: Gradient norm: inf
1: Gradient norm: inf
7: Gradient norm: inf
2: Gradient norm: inf
13: Skipped batch, new scale: 2048.0
12: Gradient norm: inf
5: Gradient norm: inf
6: Skipped batch, new scale: 2048.0
7: Skipped batch, new scale: 2048.0
4: Gradient norm: inf
3: Gradient norm: inf
11: Gradient norm: inf
2: Skipped batch, new scale: 2048.0
12: Skipped batch, new scale: 2048.0
8: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
9: Gradient norm: inf
10: Gradient norm: inf
4: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
11: Skipped batch, new scale: 2048.0
8: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
10: Skipped batch, new scale: 2048.0
4: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00099)	Tok/s 49518 (53176)	Loss/tok 3.2186 (3.1136)	Learning Rate [7.8125e-05]
3: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00092)	Tok/s 49498 (53080)	Loss/tok 3.0722 (3.1140)	Learning Rate [7.8125e-05]
2: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00099)	Tok/s 49477 (52982)	Loss/tok 3.2037 (3.1100)	Learning Rate [7.8125e-05]
5: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00093)	Tok/s 49349 (53259)	Loss/tok 3.2954 (3.1116)	Learning Rate [7.8125e-05]
6: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00092)	Tok/s 49143 (53330)	Loss/tok 2.9311 (3.1148)	Learning Rate [7.8125e-05]
7: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00097)	Tok/s 49113 (53417)	Loss/tok 2.9038 (3.1150)	Learning Rate [7.8125e-05]
1: TRAIN [2][3080/3416]	Time 0.046 (0.058)	Data 0.00109 (0.00100)	Tok/s 49578 (52873)	Loss/tok 3.0862 (3.1129)	Learning Rate [7.8125e-05]
8: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00098)	Tok/s 48965 (53491)	Loss/tok 2.8605 (3.1127)	Learning Rate [7.8125e-05]
0: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00097)	Tok/s 49381 (52780)	Loss/tok 2.7589 (3.1137)	Learning Rate [7.8125e-05]
15: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 50638 (54136)	Loss/tok 2.9663 (3.1125)	Learning Rate [7.8125e-05]
9: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00091)	Tok/s 48856 (53555)	Loss/tok 3.2323 (3.1089)	Learning Rate [7.8125e-05]
14: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00092)	Tok/s 50533 (54029)	Loss/tok 2.9580 (3.1129)	Learning Rate [7.8125e-05]
13: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00096)	Tok/s 50410 (53927)	Loss/tok 2.9418 (3.1123)	Learning Rate [7.8125e-05]
11: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00091)	Tok/s 48893 (53712)	Loss/tok 3.0099 (3.1109)	Learning Rate [7.8125e-05]
12: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00100)	Tok/s 49745 (53828)	Loss/tok 3.3738 (3.1161)	Learning Rate [7.8125e-05]
10: TRAIN [2][3080/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00096)	Tok/s 48888 (53631)	Loss/tok 3.1402 (3.1088)	Learning Rate [7.8125e-05]
15: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 68706 (54163)	Loss/tok 3.2103 (3.1127)	Learning Rate [7.8125e-05]
14: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 68707 (54056)	Loss/tok 3.2976 (3.1131)	Learning Rate [7.8125e-05]
0: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 67820 (52808)	Loss/tok 3.1050 (3.1138)	Learning Rate [7.8125e-05]
13: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 68735 (53954)	Loss/tok 3.3027 (3.1130)	Learning Rate [7.8125e-05]
1: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 67686 (52901)	Loss/tok 3.0979 (3.1129)	Learning Rate [7.8125e-05]
12: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00100)	Tok/s 68847 (53855)	Loss/tok 3.0991 (3.1166)	Learning Rate [7.8125e-05]
11: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00091)	Tok/s 68724 (53739)	Loss/tok 3.1358 (3.1112)	Learning Rate [7.8125e-05]
3: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 67817 (53108)	Loss/tok 3.1605 (3.1144)	Learning Rate [7.8125e-05]
10: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00096)	Tok/s 68630 (53659)	Loss/tok 3.1054 (3.1091)	Learning Rate [7.8125e-05]
2: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00099)	Tok/s 67571 (53010)	Loss/tok 3.1714 (3.1102)	Learning Rate [7.8125e-05]
4: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00099)	Tok/s 67953 (53204)	Loss/tok 3.1193 (3.1136)	Learning Rate [7.8125e-05]
9: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 68732 (53583)	Loss/tok 3.1292 (3.1095)	Learning Rate [7.8125e-05]
8: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 68778 (53519)	Loss/tok 3.0589 (3.1128)	Learning Rate [7.8125e-05]
6: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 68651 (53358)	Loss/tok 3.4872 (3.1151)	Learning Rate [7.8125e-05]
7: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 68732 (53445)	Loss/tok 3.3676 (3.1154)	Learning Rate [7.8125e-05]
5: TRAIN [2][3090/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 68874 (53286)	Loss/tok 3.1416 (3.1114)	Learning Rate [7.8125e-05]
1: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00100)	Tok/s 47549 (52900)	Loss/tok 2.9219 (3.1130)	Learning Rate [7.8125e-05]
2: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00099)	Tok/s 47530 (53009)	Loss/tok 3.0462 (3.1103)	Learning Rate [7.8125e-05]
0: TRAIN [2][3100/3416]	Time 0.045 (0.058)	Data 0.00113 (0.00097)	Tok/s 48295 (52808)	Loss/tok 2.9475 (3.1139)	Learning Rate [7.8125e-05]
15: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00082 (0.00092)	Tok/s 48673 (54162)	Loss/tok 2.9883 (3.1124)	Learning Rate [7.8125e-05]
4: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00099)	Tok/s 48576 (53203)	Loss/tok 2.9343 (3.1135)	Learning Rate [7.8125e-05]
3: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00081 (0.00092)	Tok/s 47503 (53107)	Loss/tok 2.9010 (3.1143)	Learning Rate [7.8125e-05]
14: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00092)	Tok/s 48533 (54055)	Loss/tok 2.9636 (3.1129)	Learning Rate [7.8125e-05]
5: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00093)	Tok/s 48983 (53285)	Loss/tok 3.1613 (3.1115)	Learning Rate [7.8125e-05]
6: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00092)	Tok/s 48792 (53357)	Loss/tok 3.0405 (3.1149)	Learning Rate [7.8125e-05]
11: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00077 (0.00091)	Tok/s 48574 (53737)	Loss/tok 2.7968 (3.1111)	Learning Rate [7.8125e-05]
13: TRAIN [2][3100/3416]	Time 0.045 (0.058)	Data 0.00117 (0.00096)	Tok/s 49380 (53952)	Loss/tok 3.1118 (3.1131)	Learning Rate [7.8125e-05]
12: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00100)	Tok/s 48562 (53853)	Loss/tok 2.9192 (3.1164)	Learning Rate [7.8125e-05]
7: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00097)	Tok/s 48797 (53443)	Loss/tok 2.8968 (3.1153)	Learning Rate [7.8125e-05]
9: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00081 (0.00091)	Tok/s 48584 (53581)	Loss/tok 2.9723 (3.1095)	Learning Rate [7.8125e-05]
8: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00098)	Tok/s 48669 (53517)	Loss/tok 3.2557 (3.1130)	Learning Rate [7.8125e-05]
10: TRAIN [2][3100/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00096)	Tok/s 48532 (53657)	Loss/tok 2.8226 (3.1091)	Learning Rate [7.8125e-05]
0: TRAIN [2][3110/3416]	Time 0.057 (0.058)	Data 0.00086 (0.00097)	Tok/s 52857 (52805)	Loss/tok 2.9017 (3.1136)	Learning Rate [7.8125e-05]
15: TRAIN [2][3110/3416]	Time 0.057 (0.058)	Data 0.00081 (0.00092)	Tok/s 53967 (54160)	Loss/tok 3.0666 (3.1121)	Learning Rate [7.8125e-05]
1: TRAIN [2][3110/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00100)	Tok/s 52663 (52898)	Loss/tok 3.0984 (3.1131)	Learning Rate [7.8125e-05]
2: TRAIN [2][3110/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00098)	Tok/s 52642 (53006)	Loss/tok 2.9360 (3.1100)	Learning Rate [7.8125e-05]
14: TRAIN [2][3110/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00092)	Tok/s 53952 (54052)	Loss/tok 3.2401 (3.1129)	Learning Rate [7.8125e-05]
3: TRAIN [2][3110/3416]	Time 0.057 (0.058)	Data 0.00086 (0.00092)	Tok/s 52507 (53104)	Loss/tok 3.2727 (3.1144)	Learning Rate [7.8125e-05]
13: TRAIN [2][3110/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00096)	Tok/s 53915 (53949)	Loss/tok 3.1012 (3.1131)	Learning Rate [7.8125e-05]
11: TRAIN [2][3110/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00091)	Tok/s 53736 (53734)	Loss/tok 3.3085 (3.1110)	Learning Rate [7.8125e-05]
12: TRAIN [2][3110/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00100)	Tok/s 53896 (53850)	Loss/tok 3.1959 (3.1163)	Learning Rate [7.8125e-05]
4: TRAIN [2][3110/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00099)	Tok/s 52418 (53200)	Loss/tok 3.2742 (3.1136)	Learning Rate [7.8125e-05]
6: TRAIN [2][3110/3416]	Time 0.058 (0.058)	Data 0.00083 (0.00092)	Tok/s 53338 (53354)	Loss/tok 3.0430 (3.1148)	Learning Rate [7.8125e-05]
5: TRAIN [2][3110/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00093)	Tok/s 52310 (53283)	Loss/tok 3.1754 (3.1117)	Learning Rate [7.8125e-05]
10: TRAIN [2][3110/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00096)	Tok/s 53728 (53655)	Loss/tok 3.0447 (3.1090)	Learning Rate [7.8125e-05]
9: TRAIN [2][3110/3416]	Time 0.057 (0.058)	Data 0.00084 (0.00091)	Tok/s 53543 (53578)	Loss/tok 3.1661 (3.1096)	Learning Rate [7.8125e-05]
7: TRAIN [2][3110/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00097)	Tok/s 53442 (53441)	Loss/tok 3.1136 (3.1151)	Learning Rate [7.8125e-05]
8: TRAIN [2][3110/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00098)	Tok/s 53405 (53515)	Loss/tok 3.0325 (3.1132)	Learning Rate [7.8125e-05]
6: TRAIN [2][3120/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00092)	Tok/s 52093 (53352)	Loss/tok 3.2160 (3.1148)	Learning Rate [7.8125e-05]
7: TRAIN [2][3120/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00097)	Tok/s 52162 (53438)	Loss/tok 2.9483 (3.1153)	Learning Rate [7.8125e-05]
8: TRAIN [2][3120/3416]	Time 0.054 (0.058)	Data 0.00083 (0.00098)	Tok/s 52167 (53512)	Loss/tok 3.3762 (3.1130)	Learning Rate [7.8125e-05]
5: TRAIN [2][3120/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00093)	Tok/s 52042 (53280)	Loss/tok 2.9777 (3.1115)	Learning Rate [7.8125e-05]
9: TRAIN [2][3120/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00091)	Tok/s 52015 (53576)	Loss/tok 3.0099 (3.1094)	Learning Rate [7.8125e-05]
4: TRAIN [2][3120/3416]	Time 0.054 (0.058)	Data 0.00094 (0.00099)	Tok/s 51868 (53198)	Loss/tok 2.8549 (3.1136)	Learning Rate [7.8125e-05]
3: TRAIN [2][3120/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00092)	Tok/s 51780 (53102)	Loss/tok 2.9519 (3.1147)	Learning Rate [7.8125e-05]
11: TRAIN [2][3120/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00091)	Tok/s 52486 (53732)	Loss/tok 3.1805 (3.1108)	Learning Rate [7.8125e-05]
10: TRAIN [2][3120/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00096)	Tok/s 51939 (53652)	Loss/tok 2.9110 (3.1088)	Learning Rate [7.8125e-05]
2: TRAIN [2][3120/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00098)	Tok/s 51653 (53004)	Loss/tok 2.9697 (3.1099)	Learning Rate [7.8125e-05]
1: TRAIN [2][3120/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00100)	Tok/s 51527 (52896)	Loss/tok 2.9705 (3.1129)	Learning Rate [7.8125e-05]
0: TRAIN [2][3120/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00097)	Tok/s 51465 (52803)	Loss/tok 3.0654 (3.1135)	Learning Rate [7.8125e-05]
12: TRAIN [2][3120/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00100)	Tok/s 52881 (53847)	Loss/tok 2.8361 (3.1164)	Learning Rate [7.8125e-05]
13: TRAIN [2][3120/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00096)	Tok/s 52867 (53946)	Loss/tok 3.0674 (3.1132)	Learning Rate [7.8125e-05]
14: TRAIN [2][3120/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00092)	Tok/s 52697 (54049)	Loss/tok 3.0058 (3.1129)	Learning Rate [7.8125e-05]
15: TRAIN [2][3120/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00092)	Tok/s 52620 (54156)	Loss/tok 3.2412 (3.1122)	Learning Rate [7.8125e-05]
0: TRAIN [2][3130/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00097)	Tok/s 56717 (52812)	Loss/tok 3.3011 (3.1134)	Learning Rate [7.8125e-05]
1: TRAIN [2][3130/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00100)	Tok/s 57029 (52906)	Loss/tok 3.2072 (3.1128)	Learning Rate [7.8125e-05]
15: TRAIN [2][3130/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00092)	Tok/s 57083 (54165)	Loss/tok 3.3457 (3.1119)	Learning Rate [7.8125e-05]
14: TRAIN [2][3130/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00092)	Tok/s 57024 (54059)	Loss/tok 3.0974 (3.1130)	Learning Rate [7.8125e-05]
2: TRAIN [2][3130/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00098)	Tok/s 56867 (53014)	Loss/tok 3.1645 (3.1100)	Learning Rate [7.8125e-05]
3: TRAIN [2][3130/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00092)	Tok/s 56817 (53112)	Loss/tok 3.0352 (3.1145)	Learning Rate [7.8125e-05]
13: TRAIN [2][3130/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00096)	Tok/s 56930 (53956)	Loss/tok 3.0187 (3.1132)	Learning Rate [7.8125e-05]
4: TRAIN [2][3130/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00099)	Tok/s 56698 (53207)	Loss/tok 3.3078 (3.1136)	Learning Rate [7.8125e-05]
12: TRAIN [2][3130/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00100)	Tok/s 56837 (53857)	Loss/tok 3.2054 (3.1164)	Learning Rate [7.8125e-05]
11: TRAIN [2][3130/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00091)	Tok/s 56702 (53741)	Loss/tok 3.3623 (3.1109)	Learning Rate [7.8125e-05]
6: TRAIN [2][3130/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00092)	Tok/s 56500 (53361)	Loss/tok 3.3830 (3.1147)	Learning Rate [7.8125e-05]
5: TRAIN [2][3130/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00093)	Tok/s 56636 (53290)	Loss/tok 3.2380 (3.1118)	Learning Rate [7.8125e-05]
9: TRAIN [2][3130/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00091)	Tok/s 56556 (53585)	Loss/tok 3.2687 (3.1094)	Learning Rate [7.8125e-05]
8: TRAIN [2][3130/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00098)	Tok/s 56431 (53521)	Loss/tok 3.2151 (3.1129)	Learning Rate [7.8125e-05]
7: TRAIN [2][3130/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00097)	Tok/s 56433 (53447)	Loss/tok 3.0680 (3.1152)	Learning Rate [7.8125e-05]
10: TRAIN [2][3130/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00096)	Tok/s 56582 (53661)	Loss/tok 3.1878 (3.1089)	Learning Rate [7.8125e-05]
11: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 61029 (53734)	Loss/tok 3.1009 (3.1112)	Learning Rate [7.8125e-05]
9: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00091)	Tok/s 60966 (53577)	Loss/tok 3.2988 (3.1094)	Learning Rate [7.8125e-05]
10: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 60937 (53653)	Loss/tok 3.1264 (3.1089)	Learning Rate [7.8125e-05]
12: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 60901 (53849)	Loss/tok 3.0825 (3.1163)	Learning Rate [7.8125e-05]
8: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00098)	Tok/s 60904 (53513)	Loss/tok 3.0496 (3.1125)	Learning Rate [7.8125e-05]
13: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 60842 (53947)	Loss/tok 3.5852 (3.1132)	Learning Rate [7.8125e-05]
14: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 60839 (54050)	Loss/tok 3.2221 (3.1131)	Learning Rate [7.8125e-05]
7: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 60825 (53438)	Loss/tok 3.1946 (3.1154)	Learning Rate [7.8125e-05]
6: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00092)	Tok/s 60845 (53353)	Loss/tok 3.3352 (3.1147)	Learning Rate [7.8125e-05]
15: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 60839 (54157)	Loss/tok 3.2014 (3.1117)	Learning Rate [7.8125e-05]
0: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 59887 (52805)	Loss/tok 3.1426 (3.1132)	Learning Rate [7.8125e-05]
5: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 60979 (53282)	Loss/tok 3.3802 (3.1119)	Learning Rate [7.8125e-05]
1: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00100)	Tok/s 60359 (52898)	Loss/tok 3.1633 (3.1127)	Learning Rate [7.8125e-05]
4: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00099)	Tok/s 60807 (53199)	Loss/tok 3.2154 (3.1136)	Learning Rate [7.8125e-05]
3: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 60886 (53104)	Loss/tok 3.3678 (3.1146)	Learning Rate [7.8125e-05]
2: TRAIN [2][3140/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 60787 (53006)	Loss/tok 3.4963 (3.1101)	Learning Rate [7.8125e-05]
1: TRAIN [2][3150/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 73853 (52915)	Loss/tok 3.1148 (3.1128)	Learning Rate [7.8125e-05]
2: TRAIN [2][3150/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 73864 (53022)	Loss/tok 3.1734 (3.1100)	Learning Rate [7.8125e-05]
0: TRAIN [2][3150/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 73966 (52821)	Loss/tok 3.0307 (3.1132)	Learning Rate [7.8125e-05]
11: TRAIN [2][3150/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00091)	Tok/s 74940 (53749)	Loss/tok 3.1076 (3.1111)	Learning Rate [7.8125e-05]
15: TRAIN [2][3150/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 74891 (54172)	Loss/tok 3.0933 (3.1114)	Learning Rate [7.8125e-05]
3: TRAIN [2][3150/3416]	Time 0.069 (0.058)	Data 0.00078 (0.00092)	Tok/s 73755 (53119)	Loss/tok 3.0262 (3.1144)	Learning Rate [7.8125e-05]
9: TRAIN [2][3150/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00091)	Tok/s 74767 (53592)	Loss/tok 2.9063 (3.1093)	Learning Rate [7.8125e-05]
10: TRAIN [2][3150/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 74837 (53668)	Loss/tok 3.2190 (3.1089)	Learning Rate [7.8125e-05]
4: TRAIN [2][3150/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00099)	Tok/s 73632 (53214)	Loss/tok 3.0560 (3.1135)	Learning Rate [7.8125e-05]
12: TRAIN [2][3150/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 74937 (53864)	Loss/tok 3.0430 (3.1163)	Learning Rate [7.8125e-05]
14: TRAIN [2][3150/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 74868 (54065)	Loss/tok 3.0909 (3.1133)	Learning Rate [7.8125e-05]
13: TRAIN [2][3150/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 74913 (53962)	Loss/tok 3.1167 (3.1132)	Learning Rate [7.8125e-05]
8: TRAIN [2][3150/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00098)	Tok/s 74200 (53528)	Loss/tok 3.1381 (3.1126)	Learning Rate [7.8125e-05]
5: TRAIN [2][3150/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 73559 (53297)	Loss/tok 2.9887 (3.1118)	Learning Rate [7.8125e-05]
6: TRAIN [2][3150/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 73517 (53368)	Loss/tok 2.9604 (3.1146)	Learning Rate [7.8125e-05]
7: TRAIN [2][3150/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 73627 (53453)	Loss/tok 3.0575 (3.1152)	Learning Rate [7.8125e-05]
12: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00100)	Tok/s 58289 (53870)	Loss/tok 3.1114 (3.1164)	Learning Rate [7.8125e-05]
11: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00091)	Tok/s 58183 (53755)	Loss/tok 3.2236 (3.1112)	Learning Rate [7.8125e-05]
4: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00102 (0.00099)	Tok/s 57102 (53221)	Loss/tok 3.2743 (3.1134)	Learning Rate [7.8125e-05]
9: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00091)	Tok/s 58010 (53599)	Loss/tok 3.1720 (3.1097)	Learning Rate [7.8125e-05]
10: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00096)	Tok/s 58098 (53674)	Loss/tok 3.0569 (3.1089)	Learning Rate [7.8125e-05]
3: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00092)	Tok/s 57123 (53126)	Loss/tok 3.4372 (3.1147)	Learning Rate [7.8125e-05]
2: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00102 (0.00098)	Tok/s 57163 (53029)	Loss/tok 3.2365 (3.1098)	Learning Rate [7.8125e-05]
8: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00098)	Tok/s 57205 (53534)	Loss/tok 3.1952 (3.1129)	Learning Rate [7.8125e-05]
15: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00092)	Tok/s 58215 (54178)	Loss/tok 3.2109 (3.1117)	Learning Rate [7.8125e-05]
13: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00096)	Tok/s 58210 (53969)	Loss/tok 3.2503 (3.1134)	Learning Rate [7.8125e-05]
1: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00107 (0.00100)	Tok/s 57154 (52922)	Loss/tok 3.1754 (3.1131)	Learning Rate [7.8125e-05]
0: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00097)	Tok/s 57195 (52829)	Loss/tok 3.1733 (3.1132)	Learning Rate [7.8125e-05]
14: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00092)	Tok/s 58170 (54071)	Loss/tok 2.9583 (3.1135)	Learning Rate [7.8125e-05]
6: TRAIN [2][3160/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00092)	Tok/s 56886 (53374)	Loss/tok 3.5597 (3.1147)	Learning Rate [7.8125e-05]
7: TRAIN [2][3160/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00097)	Tok/s 56889 (53459)	Loss/tok 3.0059 (3.1153)	Learning Rate [7.8125e-05]
5: TRAIN [2][3160/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00093)	Tok/s 56939 (53303)	Loss/tok 3.2729 (3.1123)	Learning Rate [7.8125e-05]
8: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00098)	Tok/s 34118 (53545)	Loss/tok 2.7330 (3.1130)	Learning Rate [7.8125e-05]
9: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00091)	Tok/s 34080 (53610)	Loss/tok 3.0789 (3.1099)	Learning Rate [7.8125e-05]
6: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00092)	Tok/s 34017 (53386)	Loss/tok 2.7165 (3.1148)	Learning Rate [7.8125e-05]
7: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00097)	Tok/s 34062 (53471)	Loss/tok 2.7508 (3.1151)	Learning Rate [7.8125e-05]
10: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00096)	Tok/s 34011 (53686)	Loss/tok 2.7495 (3.1090)	Learning Rate [7.8125e-05]
11: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00080 (0.00091)	Tok/s 33944 (53766)	Loss/tok 2.9619 (3.1112)	Learning Rate [7.8125e-05]
5: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00073 (0.00093)	Tok/s 33954 (53314)	Loss/tok 2.7326 (3.1124)	Learning Rate [7.8125e-05]
12: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00100)	Tok/s 33855 (53881)	Loss/tok 2.7000 (3.1164)	Learning Rate [7.8125e-05]
4: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00099)	Tok/s 33873 (53232)	Loss/tok 2.6940 (3.1134)	Learning Rate [7.8125e-05]
13: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00096)	Tok/s 33771 (53980)	Loss/tok 2.7598 (3.1134)	Learning Rate [7.8125e-05]
3: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 33773 (53137)	Loss/tok 2.7125 (3.1148)	Learning Rate [7.8125e-05]
14: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00092)	Tok/s 33709 (54082)	Loss/tok 2.7331 (3.1135)	Learning Rate [7.8125e-05]
15: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00092)	Tok/s 33666 (54188)	Loss/tok 2.7838 (3.1115)	Learning Rate [7.8125e-05]
2: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00098)	Tok/s 33707 (53041)	Loss/tok 2.7736 (3.1101)	Learning Rate [7.8125e-05]
1: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00100)	Tok/s 33626 (52934)	Loss/tok 2.8232 (3.1131)	Learning Rate [7.8125e-05]
0: TRAIN [2][3170/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00097)	Tok/s 33602 (52841)	Loss/tok 2.8971 (3.1131)	Learning Rate [7.8125e-05]
9: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00091)	Tok/s 51828 (53611)	Loss/tok 2.8540 (3.1099)	Learning Rate [7.8125e-05]
3: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00106 (0.00092)	Tok/s 51733 (53139)	Loss/tok 3.1503 (3.1149)	Learning Rate [7.8125e-05]
11: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00091)	Tok/s 51812 (53766)	Loss/tok 3.0011 (3.1113)	Learning Rate [7.8125e-05]
5: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00093)	Tok/s 51561 (53316)	Loss/tok 3.3138 (3.1127)	Learning Rate [7.8125e-05]
10: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00096)	Tok/s 51728 (53687)	Loss/tok 3.0633 (3.1095)	Learning Rate [7.8125e-05]
6: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00092)	Tok/s 51530 (53387)	Loss/tok 2.9703 (3.1149)	Learning Rate [7.8125e-05]
4: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00109 (0.00099)	Tok/s 51623 (53234)	Loss/tok 2.9233 (3.1137)	Learning Rate [7.8125e-05]
12: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00107 (0.00100)	Tok/s 52706 (53882)	Loss/tok 3.1068 (3.1166)	Learning Rate [7.8125e-05]
1: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00119 (0.00100)	Tok/s 51703 (52936)	Loss/tok 2.9822 (3.1131)	Learning Rate [7.8125e-05]
0: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00121 (0.00097)	Tok/s 51702 (52843)	Loss/tok 2.8921 (3.1132)	Learning Rate [7.8125e-05]
15: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00096 (0.00092)	Tok/s 52898 (54189)	Loss/tok 3.2426 (3.1119)	Learning Rate [7.8125e-05]
8: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00098)	Tok/s 51570 (53546)	Loss/tok 3.2273 (3.1133)	Learning Rate [7.8125e-05]
13: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00111 (0.00096)	Tok/s 52837 (53980)	Loss/tok 3.2543 (3.1136)	Learning Rate [7.8125e-05]
14: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00092)	Tok/s 52874 (54082)	Loss/tok 2.9563 (3.1135)	Learning Rate [7.8125e-05]
7: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00108 (0.00097)	Tok/s 51592 (53472)	Loss/tok 3.1843 (3.1153)	Learning Rate [7.8125e-05]
2: TRAIN [2][3180/3416]	Time 0.056 (0.058)	Data 0.00105 (0.00098)	Tok/s 51711 (53043)	Loss/tok 3.1032 (3.1101)	Learning Rate [7.8125e-05]
14: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00092)	Tok/s 42593 (54065)	Loss/tok 2.9437 (3.1135)	Learning Rate [7.8125e-05]
3: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00092)	Tok/s 41023 (53121)	Loss/tok 2.8948 (3.1150)	Learning Rate [7.8125e-05]
13: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00119 (0.00096)	Tok/s 42180 (53962)	Loss/tok 2.9439 (3.1135)	Learning Rate [7.8125e-05]
2: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00098)	Tok/s 41020 (53025)	Loss/tok 3.1195 (3.1099)	Learning Rate [7.8125e-05]
15: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 42489 (54171)	Loss/tok 2.8408 (3.1117)	Learning Rate [7.8125e-05]
1: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00113 (0.00100)	Tok/s 41060 (52918)	Loss/tok 2.9072 (3.1128)	Learning Rate [7.8125e-05]
4: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00099)	Tok/s 40989 (53216)	Loss/tok 2.8751 (3.1137)	Learning Rate [7.8125e-05]
0: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00097)	Tok/s 41089 (52826)	Loss/tok 2.8714 (3.1130)	Learning Rate [7.8125e-05]
11: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00091)	Tok/s 41227 (53748)	Loss/tok 3.2172 (3.1111)	Learning Rate [7.8125e-05]
12: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00100)	Tok/s 41267 (53863)	Loss/tok 3.1866 (3.1167)	Learning Rate [7.8125e-05]
5: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00093)	Tok/s 41008 (53298)	Loss/tok 2.9900 (3.1127)	Learning Rate [7.8125e-05]
6: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00092)	Tok/s 40974 (53369)	Loss/tok 2.9562 (3.1146)	Learning Rate [7.8125e-05]
9: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00091)	Tok/s 41038 (53592)	Loss/tok 2.8291 (3.1097)	Learning Rate [7.8125e-05]
10: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00096)	Tok/s 41154 (53668)	Loss/tok 2.8035 (3.1093)	Learning Rate [7.8125e-05]
8: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00098)	Tok/s 40959 (53528)	Loss/tok 2.9031 (3.1134)	Learning Rate [7.8125e-05]
7: TRAIN [2][3190/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00097)	Tok/s 40914 (53454)	Loss/tok 2.9348 (3.1152)	Learning Rate [7.8125e-05]
14: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00092)	Tok/s 50156 (54061)	Loss/tok 2.8158 (3.1135)	Learning Rate [7.8125e-05]
13: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00096)	Tok/s 48865 (53959)	Loss/tok 3.2250 (3.1136)	Learning Rate [7.8125e-05]
15: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00092)	Tok/s 50066 (54168)	Loss/tok 2.8330 (3.1119)	Learning Rate [7.8125e-05]
12: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00100)	Tok/s 48707 (53859)	Loss/tok 2.9933 (3.1166)	Learning Rate [7.8125e-05]
0: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 48492 (52823)	Loss/tok 2.8790 (3.1130)	Learning Rate [7.8125e-05]
1: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00100)	Tok/s 48330 (52916)	Loss/tok 3.0290 (3.1126)	Learning Rate [7.8125e-05]
11: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00091)	Tok/s 48536 (53745)	Loss/tok 3.2469 (3.1110)	Learning Rate [7.8125e-05]
2: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00098)	Tok/s 48261 (53023)	Loss/tok 3.0386 (3.1098)	Learning Rate [7.8125e-05]
10: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00096)	Tok/s 48445 (53665)	Loss/tok 3.0182 (3.1092)	Learning Rate [7.8125e-05]
9: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00091)	Tok/s 48322 (53589)	Loss/tok 2.8630 (3.1097)	Learning Rate [7.8125e-05]
3: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00092)	Tok/s 48153 (53119)	Loss/tok 2.9638 (3.1147)	Learning Rate [7.8125e-05]
8: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00098)	Tok/s 48192 (53525)	Loss/tok 2.9563 (3.1135)	Learning Rate [7.8125e-05]
7: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00097)	Tok/s 48099 (53451)	Loss/tok 3.0009 (3.1154)	Learning Rate [7.8125e-05]
5: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00093)	Tok/s 47920 (53295)	Loss/tok 2.9162 (3.1128)	Learning Rate [7.8125e-05]
4: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00099)	Tok/s 48008 (53214)	Loss/tok 3.1929 (3.1137)	Learning Rate [7.8125e-05]
6: TRAIN [2][3200/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00092)	Tok/s 47945 (53366)	Loss/tok 2.8251 (3.1144)	Learning Rate [7.8125e-05]
15: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
12: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00100)	Tok/s 60551 (53880)	Loss/tok 3.3038 (3.1167)	Learning Rate [7.8125e-05]
9: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00091)	Tok/s 60463 (53610)	Loss/tok 3.1772 (3.1099)	Learning Rate [7.8125e-05]
11: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 60425 (53765)	Loss/tok 3.3549 (3.1113)	Learning Rate [7.8125e-05]
13: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 60484 (53979)	Loss/tok 3.3023 (3.1137)	Learning Rate [7.8125e-05]
10: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 60338 (53685)	Loss/tok 3.4575 (3.1093)	Learning Rate [7.8125e-05]
8: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00098)	Tok/s 60374 (53546)	Loss/tok 3.3358 (3.1135)	Learning Rate [7.8125e-05]
6: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 60461 (53387)	Loss/tok 3.3523 (3.1146)	Learning Rate [7.8125e-05]
14: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 60277 (54081)	Loss/tok 3.1051 (3.1133)	Learning Rate [7.8125e-05]
15: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 61139 (54188)	Loss/tok 3.2164 (3.1118)	Learning Rate [7.8125e-05]
7: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00097)	Tok/s 60344 (53472)	Loss/tok 3.1832 (3.1155)	Learning Rate [7.8125e-05]
0: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 60142 (52844)	Loss/tok 3.1033 (3.1128)	Learning Rate [7.8125e-05]
4: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00099)	Tok/s 60335 (53235)	Loss/tok 3.2440 (3.1137)	Learning Rate [7.8125e-05]
5: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 60329 (53316)	Loss/tok 3.1563 (3.1127)	Learning Rate [7.8125e-05]
1: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00100)	Tok/s 60152 (52937)	Loss/tok 3.1163 (3.1127)	Learning Rate [7.8125e-05]
3: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 60226 (53141)	Loss/tok 3.3581 (3.1147)	Learning Rate [7.8125e-05]
2: TRAIN [2][3210/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 60147 (53044)	Loss/tok 3.2062 (3.1097)	Learning Rate [7.8125e-05]
4: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00099)	Tok/s 68579 (53203)	Loss/tok 3.3005 (3.1134)	Learning Rate [7.8125e-05]
2: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00098)	Tok/s 68386 (53012)	Loss/tok 3.1092 (3.1094)	Learning Rate [7.8125e-05]
1: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 68234 (52904)	Loss/tok 3.3481 (3.1125)	Learning Rate [7.8125e-05]
5: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 68819 (53286)	Loss/tok 3.1700 (3.1126)	Learning Rate [7.8125e-05]
6: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 69483 (53358)	Loss/tok 3.0647 (3.1143)	Learning Rate [7.8125e-05]
0: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 68224 (52810)	Loss/tok 3.3109 (3.1127)	Learning Rate [7.8125e-05]
7: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00097)	Tok/s 69552 (53443)	Loss/tok 3.1764 (3.1152)	Learning Rate [7.8125e-05]
8: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00098)	Tok/s 69562 (53517)	Loss/tok 3.1194 (3.1132)	Learning Rate [7.8125e-05]
3: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 68480 (53109)	Loss/tok 3.3997 (3.1146)	Learning Rate [7.8125e-05]
11: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00075 (0.00091)	Tok/s 69402 (53736)	Loss/tok 3.3051 (3.1111)	Learning Rate [7.8125e-05]
12: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 69402 (53851)	Loss/tok 3.4125 (3.1167)	Learning Rate [7.8125e-05]
15: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 69180 (54160)	Loss/tok 3.2040 (3.1116)	Learning Rate [7.8125e-05]
10: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 69472 (53656)	Loss/tok 3.1066 (3.1090)	Learning Rate [7.8125e-05]
13: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 69268 (53949)	Loss/tok 3.2728 (3.1136)	Learning Rate [7.8125e-05]
14: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 69163 (54053)	Loss/tok 3.0941 (3.1130)	Learning Rate [7.8125e-05]
9: TRAIN [2][3220/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 69471 (53581)	Loss/tok 3.0949 (3.1095)	Learning Rate [7.8125e-05]
13: Gradient norm: inf
12: Gradient norm: inf
13: Skipped batch, new scale: 2048.0
14: Gradient norm: inf
12: Skipped batch, new scale: 2048.0
11: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
11: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
15: Skipped batch, new scale: 2048.0
0: Gradient norm: inf
10: Skipped batch, new scale: 2048.0
9: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
1: Gradient norm: inf
8: Gradient norm: inf
2: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
8: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
7: Gradient norm: inf
3: Gradient norm: inf
6: Gradient norm: inf
5: Gradient norm: inf
7: Skipped batch, new scale: 2048.0
4: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
6: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
4: Skipped batch, new scale: 2048.0
5: TRAIN [2][3230/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00093)	Tok/s 55475 (53305)	Loss/tok 3.2218 (3.1129)	Learning Rate [7.8125e-05]
4: TRAIN [2][3230/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00099)	Tok/s 55360 (53222)	Loss/tok 3.1452 (3.1134)	Learning Rate [7.8125e-05]
3: TRAIN [2][3230/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00092)	Tok/s 55304 (53128)	Loss/tok 3.1180 (3.1148)	Learning Rate [7.8125e-05]
7: TRAIN [2][3230/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00097)	Tok/s 55411 (53462)	Loss/tok 3.1069 (3.1153)	Learning Rate [7.8125e-05]
6: TRAIN [2][3230/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00092)	Tok/s 55497 (53377)	Loss/tok 3.4178 (3.1144)	Learning Rate [7.8125e-05]
2: TRAIN [2][3230/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00098)	Tok/s 55213 (53031)	Loss/tok 3.4525 (3.1097)	Learning Rate [7.8125e-05]
8: TRAIN [2][3230/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00098)	Tok/s 55320 (53536)	Loss/tok 3.3371 (3.1131)	Learning Rate [7.8125e-05]
9: TRAIN [2][3230/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00091)	Tok/s 55279 (53600)	Loss/tok 3.3133 (3.1098)	Learning Rate [7.8125e-05]
0: TRAIN [2][3230/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 55119 (52830)	Loss/tok 3.4152 (3.1132)	Learning Rate [7.8125e-05]
11: TRAIN [2][3230/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00091)	Tok/s 55184 (53755)	Loss/tok 3.3134 (3.1114)	Learning Rate [7.8125e-05]
1: TRAIN [2][3230/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00100)	Tok/s 55041 (52923)	Loss/tok 3.3462 (3.1126)	Learning Rate [7.8125e-05]
15: TRAIN [2][3230/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00092)	Tok/s 55153 (54179)	Loss/tok 3.4750 (3.1118)	Learning Rate [7.8125e-05]
10: TRAIN [2][3230/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00096)	Tok/s 55151 (53675)	Loss/tok 3.2223 (3.1090)	Learning Rate [7.8125e-05]
14: TRAIN [2][3230/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00092)	Tok/s 55130 (54072)	Loss/tok 3.1577 (3.1130)	Learning Rate [7.8125e-05]
13: TRAIN [2][3230/3416]	Time 0.069 (0.058)	Data 0.00122 (0.00096)	Tok/s 55069 (53968)	Loss/tok 3.3058 (3.1138)	Learning Rate [7.8125e-05]
12: TRAIN [2][3230/3416]	Time 0.069 (0.058)	Data 0.00123 (0.00100)	Tok/s 55034 (53869)	Loss/tok 3.0413 (3.1166)	Learning Rate [7.8125e-05]
12: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00100)	Tok/s 52679 (53894)	Loss/tok 2.9667 (3.1169)	Learning Rate [7.8125e-05]
9: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00091)	Tok/s 52530 (53624)	Loss/tok 2.7916 (3.1096)	Learning Rate [7.8125e-05]
13: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00096)	Tok/s 52639 (53992)	Loss/tok 3.0103 (3.1139)	Learning Rate [7.8125e-05]
14: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00092)	Tok/s 52722 (54096)	Loss/tok 2.8617 (3.1134)	Learning Rate [7.8125e-05]
15: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00092)	Tok/s 52711 (54203)	Loss/tok 3.1055 (3.1120)	Learning Rate [7.8125e-05]
0: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00097)	Tok/s 51413 (52855)	Loss/tok 2.9441 (3.1134)	Learning Rate [7.8125e-05]
1: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00100)	Tok/s 51452 (52947)	Loss/tok 3.1891 (3.1128)	Learning Rate [7.8125e-05]
10: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00096)	Tok/s 52395 (53700)	Loss/tok 3.0527 (3.1089)	Learning Rate [7.8125e-05]
11: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00091)	Tok/s 52528 (53780)	Loss/tok 3.0980 (3.1119)	Learning Rate [7.8125e-05]
8: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00098)	Tok/s 52369 (53560)	Loss/tok 3.3574 (3.1134)	Learning Rate [7.8125e-05]
2: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00098)	Tok/s 51435 (53055)	Loss/tok 3.1613 (3.1099)	Learning Rate [7.8125e-05]
3: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00092)	Tok/s 51313 (53152)	Loss/tok 3.0425 (3.1149)	Learning Rate [7.8125e-05]
7: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00097)	Tok/s 52381 (53486)	Loss/tok 3.0115 (3.1151)	Learning Rate [7.8125e-05]
6: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 51253 (53401)	Loss/tok 2.9615 (3.1144)	Learning Rate [7.8125e-05]
5: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00093)	Tok/s 51132 (53329)	Loss/tok 3.0769 (3.1130)	Learning Rate [7.8125e-05]
4: TRAIN [2][3240/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00099)	Tok/s 51156 (53246)	Loss/tok 3.0229 (3.1138)	Learning Rate [7.8125e-05]
15: TRAIN [2][3250/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 68529 (54196)	Loss/tok 3.1349 (3.1118)	Learning Rate [7.8125e-05]
14: TRAIN [2][3250/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 68424 (54089)	Loss/tok 3.0993 (3.1134)	Learning Rate [7.8125e-05]
0: TRAIN [2][3250/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 67602 (52849)	Loss/tok 3.0823 (3.1136)	Learning Rate [7.8125e-05]
1: TRAIN [2][3250/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 67544 (52942)	Loss/tok 3.1873 (3.1128)	Learning Rate [7.8125e-05]
2: TRAIN [2][3250/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 67408 (53050)	Loss/tok 3.2665 (3.1100)	Learning Rate [7.8125e-05]
12: TRAIN [2][3250/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 68190 (53888)	Loss/tok 3.3632 (3.1168)	Learning Rate [7.8125e-05]
11: TRAIN [2][3250/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 68156 (53774)	Loss/tok 3.2783 (3.1118)	Learning Rate [7.8125e-05]
3: TRAIN [2][3250/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 67848 (53146)	Loss/tok 3.1677 (3.1148)	Learning Rate [7.8125e-05]
13: TRAIN [2][3250/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 68202 (53986)	Loss/tok 2.9158 (3.1139)	Learning Rate [7.8125e-05]
9: TRAIN [2][3250/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00091)	Tok/s 68110 (53619)	Loss/tok 3.1377 (3.1099)	Learning Rate [7.8125e-05]
4: TRAIN [2][3250/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 68167 (53241)	Loss/tok 3.2504 (3.1138)	Learning Rate [7.8125e-05]
6: TRAIN [2][3250/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 68028 (53396)	Loss/tok 3.0548 (3.1143)	Learning Rate [7.8125e-05]
5: TRAIN [2][3250/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00093)	Tok/s 68032 (53324)	Loss/tok 3.3115 (3.1133)	Learning Rate [7.8125e-05]
7: TRAIN [2][3250/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 68098 (53481)	Loss/tok 3.4367 (3.1152)	Learning Rate [7.8125e-05]
8: TRAIN [2][3250/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00098)	Tok/s 68103 (53555)	Loss/tok 3.0735 (3.1134)	Learning Rate [7.8125e-05]
10: TRAIN [2][3250/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00096)	Tok/s 68081 (53694)	Loss/tok 3.0784 (3.1089)	Learning Rate [7.8125e-05]
10: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00096)	Tok/s 75934 (53717)	Loss/tok 3.0532 (3.1088)	Learning Rate [7.8125e-05]
9: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00091)	Tok/s 75309 (53642)	Loss/tok 3.2310 (3.1101)	Learning Rate [7.8125e-05]
12: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00100)	Tok/s 76201 (53911)	Loss/tok 2.9035 (3.1169)	Learning Rate [7.8125e-05]
7: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 75280 (53504)	Loss/tok 3.0639 (3.1154)	Learning Rate [7.8125e-05]
6: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 75289 (53419)	Loss/tok 3.1032 (3.1145)	Learning Rate [7.8125e-05]
13: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 76187 (54008)	Loss/tok 3.1659 (3.1139)	Learning Rate [7.8125e-05]
8: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00098)	Tok/s 75204 (53577)	Loss/tok 3.1994 (3.1137)	Learning Rate [7.8125e-05]
14: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 76200 (54112)	Loss/tok 3.1636 (3.1138)	Learning Rate [7.8125e-05]
5: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00078 (0.00093)	Tok/s 75288 (53347)	Loss/tok 3.2507 (3.1135)	Learning Rate [7.8125e-05]
4: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 75302 (53264)	Loss/tok 3.1292 (3.1141)	Learning Rate [7.8125e-05]
15: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 76176 (54218)	Loss/tok 3.2171 (3.1121)	Learning Rate [7.8125e-05]
0: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00096)	Tok/s 74347 (52872)	Loss/tok 3.1310 (3.1140)	Learning Rate [7.8125e-05]
1: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00100)	Tok/s 75320 (52965)	Loss/tok 3.2598 (3.1128)	Learning Rate [7.8125e-05]
2: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 75271 (53073)	Loss/tok 3.2140 (3.1102)	Learning Rate [7.8125e-05]
3: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 75252 (53169)	Loss/tok 3.1009 (3.1150)	Learning Rate [7.8125e-05]
11: TRAIN [2][3260/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00091)	Tok/s 75723 (53797)	Loss/tok 3.0341 (3.1123)	Learning Rate [7.8125e-05]
9: TRAIN [2][3270/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 65780 (53642)	Loss/tok 3.2928 (3.1100)	Learning Rate [7.8125e-05]
11: TRAIN [2][3270/3416]	Time 0.069 (0.058)	Data 0.00074 (0.00091)	Tok/s 65890 (53797)	Loss/tok 3.2456 (3.1121)	Learning Rate [7.8125e-05]
10: TRAIN [2][3270/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00096)	Tok/s 65788 (53717)	Loss/tok 3.1790 (3.1085)	Learning Rate [7.8125e-05]
6: TRAIN [2][3270/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 65619 (53419)	Loss/tok 3.1058 (3.1143)	Learning Rate [7.8125e-05]
13: TRAIN [2][3270/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00096)	Tok/s 66465 (54008)	Loss/tok 3.3393 (3.1136)	Learning Rate [7.8125e-05]
7: TRAIN [2][3270/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00097)	Tok/s 65775 (53503)	Loss/tok 3.2134 (3.1154)	Learning Rate [7.8125e-05]
12: TRAIN [2][3270/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 66519 (53910)	Loss/tok 3.0747 (3.1169)	Learning Rate [7.8125e-05]
3: TRAIN [2][3270/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 65526 (53169)	Loss/tok 3.2266 (3.1150)	Learning Rate [7.8125e-05]
14: TRAIN [2][3270/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 66259 (54112)	Loss/tok 3.3291 (3.1137)	Learning Rate [7.8125e-05]
5: TRAIN [2][3270/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 65592 (53347)	Loss/tok 3.4591 (3.1136)	Learning Rate [7.8125e-05]
4: TRAIN [2][3270/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00099)	Tok/s 65608 (53264)	Loss/tok 3.1801 (3.1142)	Learning Rate [7.8125e-05]
15: TRAIN [2][3270/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 66197 (54218)	Loss/tok 2.9383 (3.1120)	Learning Rate [7.8125e-05]
0: TRAIN [2][3270/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 65320 (52873)	Loss/tok 3.1169 (3.1138)	Learning Rate [7.8125e-05]
1: TRAIN [2][3270/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00100)	Tok/s 65403 (52966)	Loss/tok 3.4435 (3.1129)	Learning Rate [7.8125e-05]
8: TRAIN [2][3270/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00098)	Tok/s 65712 (53577)	Loss/tok 3.2371 (3.1138)	Learning Rate [7.8125e-05]
2: TRAIN [2][3270/3416]	Time 0.070 (0.058)	Data 0.00124 (0.00098)	Tok/s 65350 (53073)	Loss/tok 3.0541 (3.1100)	Learning Rate [7.8125e-05]
15: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00092)	Tok/s 50765 (54221)	Loss/tok 2.7784 (3.1119)	Learning Rate [7.8125e-05]
14: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00092)	Tok/s 50780 (54115)	Loss/tok 2.8391 (3.1137)	Learning Rate [7.8125e-05]
0: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00097)	Tok/s 49259 (52877)	Loss/tok 3.0242 (3.1138)	Learning Rate [7.8125e-05]
13: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00096)	Tok/s 50770 (54011)	Loss/tok 2.8725 (3.1135)	Learning Rate [7.8125e-05]
2: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00098)	Tok/s 49100 (53076)	Loss/tok 2.8734 (3.1098)	Learning Rate [7.8125e-05]
1: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00100)	Tok/s 49047 (52969)	Loss/tok 3.0096 (3.1130)	Learning Rate [7.8125e-05]
12: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00100)	Tok/s 50531 (53914)	Loss/tok 3.0014 (3.1168)	Learning Rate [7.8125e-05]
11: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00091)	Tok/s 50637 (53799)	Loss/tok 3.0203 (3.1120)	Learning Rate [7.8125e-05]
3: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00092)	Tok/s 50203 (53173)	Loss/tok 3.1801 (3.1149)	Learning Rate [7.8125e-05]
4: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00118 (0.00099)	Tok/s 50193 (53268)	Loss/tok 3.1088 (3.1143)	Learning Rate [7.8125e-05]
9: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00091)	Tok/s 50378 (53644)	Loss/tok 3.0084 (3.1099)	Learning Rate [7.8125e-05]
10: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00096)	Tok/s 50515 (53720)	Loss/tok 2.9829 (3.1084)	Learning Rate [7.8125e-05]
5: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00093)	Tok/s 50208 (53350)	Loss/tok 3.1498 (3.1135)	Learning Rate [7.8125e-05]
7: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00097)	Tok/s 50251 (53506)	Loss/tok 3.1474 (3.1155)	Learning Rate [7.8125e-05]
6: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00092)	Tok/s 50192 (53422)	Loss/tok 2.8579 (3.1143)	Learning Rate [7.8125e-05]
8: TRAIN [2][3280/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00098)	Tok/s 50218 (53580)	Loss/tok 3.1818 (3.1139)	Learning Rate [7.8125e-05]
2: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00098)	Tok/s 36224 (53081)	Loss/tok 2.6340 (3.1098)	Learning Rate [7.8125e-05]
0: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00097)	Tok/s 35139 (52881)	Loss/tok 3.0946 (3.1142)	Learning Rate [7.8125e-05]
15: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00092)	Tok/s 36302 (54225)	Loss/tok 2.5942 (3.1119)	Learning Rate [7.8125e-05]
3: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00092)	Tok/s 36331 (53178)	Loss/tok 2.8622 (3.1151)	Learning Rate [7.8125e-05]
14: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 36265 (54119)	Loss/tok 2.9341 (3.1141)	Learning Rate [7.8125e-05]
13: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00096)	Tok/s 36305 (54015)	Loss/tok 3.1251 (3.1136)	Learning Rate [7.8125e-05]
6: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00092)	Tok/s 36342 (53426)	Loss/tok 2.8998 (3.1146)	Learning Rate [7.8125e-05]
11: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00091)	Tok/s 36287 (53803)	Loss/tok 2.8791 (3.1123)	Learning Rate [7.8125e-05]
12: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00100)	Tok/s 36226 (53917)	Loss/tok 2.8387 (3.1169)	Learning Rate [7.8125e-05]
5: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00120 (0.00093)	Tok/s 36542 (53355)	Loss/tok 3.0262 (3.1136)	Learning Rate [7.8125e-05]
7: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00097)	Tok/s 36362 (53510)	Loss/tok 3.0168 (3.1157)	Learning Rate [7.8125e-05]
9: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00091)	Tok/s 36253 (53648)	Loss/tok 2.8387 (3.1102)	Learning Rate [7.8125e-05]
10: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00096)	Tok/s 36208 (53723)	Loss/tok 2.9381 (3.1083)	Learning Rate [7.8125e-05]
8: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00098)	Tok/s 36278 (53584)	Loss/tok 3.2286 (3.1143)	Learning Rate [7.8125e-05]
1: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00138 (0.00100)	Tok/s 35187 (52974)	Loss/tok 2.7915 (3.1130)	Learning Rate [7.8125e-05]
4: TRAIN [2][3290/3416]	Time 0.051 (0.058)	Data 0.00115 (0.00099)	Tok/s 36382 (53273)	Loss/tok 2.8156 (3.1146)	Learning Rate [7.8125e-05]
15: TRAIN [2][3300/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00092)	Tok/s 49986 (54215)	Loss/tok 2.9771 (3.1118)	Learning Rate [7.8125e-05]
14: TRAIN [2][3300/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00092)	Tok/s 49964 (54109)	Loss/tok 2.7633 (3.1139)	Learning Rate [7.8125e-05]
0: TRAIN [2][3300/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00097)	Tok/s 49845 (52873)	Loss/tok 2.9296 (3.1141)	Learning Rate [7.8125e-05]
13: TRAIN [2][3300/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00096)	Tok/s 50022 (54005)	Loss/tok 3.0962 (3.1135)	Learning Rate [7.8125e-05]
11: TRAIN [2][3300/3416]	Time 0.047 (0.058)	Data 0.00081 (0.00091)	Tok/s 50041 (53794)	Loss/tok 2.8902 (3.1121)	Learning Rate [7.8125e-05]
1: TRAIN [2][3300/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00100)	Tok/s 49727 (52965)	Loss/tok 3.0454 (3.1129)	Learning Rate [7.8125e-05]
3: TRAIN [2][3300/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00092)	Tok/s 49601 (53169)	Loss/tok 2.9840 (3.1151)	Learning Rate [7.8125e-05]
12: TRAIN [2][3300/3416]	Time 0.047 (0.058)	Data 0.00115 (0.00100)	Tok/s 49987 (53907)	Loss/tok 3.0638 (3.1166)	Learning Rate [7.8125e-05]
2: TRAIN [2][3300/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00098)	Tok/s 49591 (53072)	Loss/tok 3.4577 (3.1097)	Learning Rate [7.8125e-05]
9: TRAIN [2][3300/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00091)	Tok/s 49879 (53638)	Loss/tok 3.1545 (3.1101)	Learning Rate [7.8125e-05]
4: TRAIN [2][3300/3416]	Time 0.048 (0.058)	Data 0.00106 (0.00099)	Tok/s 49544 (53264)	Loss/tok 2.7811 (3.1145)	Learning Rate [7.8125e-05]
5: TRAIN [2][3300/3416]	Time 0.048 (0.058)	Data 0.00081 (0.00093)	Tok/s 49603 (53345)	Loss/tok 3.2209 (3.1137)	Learning Rate [7.8125e-05]
6: TRAIN [2][3300/3416]	Time 0.048 (0.058)	Data 0.00080 (0.00092)	Tok/s 49613 (53417)	Loss/tok 2.9942 (3.1145)	Learning Rate [7.8125e-05]
10: TRAIN [2][3300/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00096)	Tok/s 50027 (53714)	Loss/tok 3.0041 (3.1084)	Learning Rate [7.8125e-05]
8: TRAIN [2][3300/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00098)	Tok/s 49801 (53574)	Loss/tok 3.1390 (3.1143)	Learning Rate [7.8125e-05]
7: TRAIN [2][3300/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00097)	Tok/s 49943 (53501)	Loss/tok 3.0271 (3.1156)	Learning Rate [7.8125e-05]
6: TRAIN [2][3310/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00092)	Tok/s 49488 (53428)	Loss/tok 2.8452 (3.1141)	Learning Rate [7.8125e-05]
5: TRAIN [2][3310/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00093)	Tok/s 49489 (53356)	Loss/tok 3.1069 (3.1136)	Learning Rate [7.8125e-05]
7: TRAIN [2][3310/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00097)	Tok/s 49414 (53512)	Loss/tok 2.8399 (3.1153)	Learning Rate [7.8125e-05]
8: TRAIN [2][3310/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00098)	Tok/s 49274 (53585)	Loss/tok 2.9435 (3.1140)	Learning Rate [7.8125e-05]
9: TRAIN [2][3310/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00091)	Tok/s 49122 (53649)	Loss/tok 3.3459 (3.1102)	Learning Rate [7.8125e-05]
3: TRAIN [2][3310/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00092)	Tok/s 49421 (53179)	Loss/tok 2.9355 (3.1148)	Learning Rate [7.8125e-05]
11: TRAIN [2][3310/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00091)	Tok/s 48967 (53804)	Loss/tok 3.0133 (3.1119)	Learning Rate [7.8125e-05]
4: TRAIN [2][3310/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00099)	Tok/s 49307 (53274)	Loss/tok 3.0463 (3.1142)	Learning Rate [7.8125e-05]
1: TRAIN [2][3310/3416]	Time 0.044 (0.058)	Data 0.00103 (0.00100)	Tok/s 49204 (52975)	Loss/tok 3.0516 (3.1129)	Learning Rate [7.8125e-05]
10: TRAIN [2][3310/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00096)	Tok/s 48976 (53725)	Loss/tok 2.8625 (3.1082)	Learning Rate [7.8125e-05]
15: TRAIN [2][3310/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00092)	Tok/s 50396 (54226)	Loss/tok 2.9340 (3.1115)	Learning Rate [7.8125e-05]
12: TRAIN [2][3310/3416]	Time 0.045 (0.058)	Data 0.00106 (0.00100)	Tok/s 48812 (53918)	Loss/tok 2.9898 (3.1164)	Learning Rate [7.8125e-05]
0: TRAIN [2][3310/3416]	Time 0.044 (0.058)	Data 0.00106 (0.00097)	Tok/s 49049 (52882)	Loss/tok 3.0489 (3.1142)	Learning Rate [7.8125e-05]
2: TRAIN [2][3310/3416]	Time 0.044 (0.058)	Data 0.00129 (0.00098)	Tok/s 49423 (53082)	Loss/tok 3.3708 (3.1098)	Learning Rate [7.8125e-05]
14: TRAIN [2][3310/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00092)	Tok/s 49555 (54120)	Loss/tok 3.1447 (3.1137)	Learning Rate [7.8125e-05]
13: TRAIN [2][3310/3416]	Time 0.045 (0.058)	Data 0.00107 (0.00096)	Tok/s 48832 (54016)	Loss/tok 3.0090 (3.1133)	Learning Rate [7.8125e-05]
11: TRAIN [2][3320/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00091)	Tok/s 55360 (53798)	Loss/tok 3.3984 (3.1119)	Learning Rate [7.8125e-05]
10: TRAIN [2][3320/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00096)	Tok/s 55437 (53718)	Loss/tok 3.3220 (3.1085)	Learning Rate [7.8125e-05]
9: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00091)	Tok/s 55256 (53642)	Loss/tok 2.9161 (3.1102)	Learning Rate [7.8125e-05]
6: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00092)	Tok/s 53961 (53421)	Loss/tok 3.2124 (3.1142)	Learning Rate [7.8125e-05]
5: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00081 (0.00093)	Tok/s 53870 (53348)	Loss/tok 3.2362 (3.1138)	Learning Rate [7.8125e-05]
8: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00098)	Tok/s 54683 (53579)	Loss/tok 3.3681 (3.1143)	Learning Rate [7.8125e-05]
12: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00108 (0.00100)	Tok/s 55273 (53912)	Loss/tok 3.2729 (3.1166)	Learning Rate [7.8125e-05]
14: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00092)	Tok/s 55002 (54114)	Loss/tok 3.4318 (3.1138)	Learning Rate [7.8125e-05]
4: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00108 (0.00099)	Tok/s 53778 (53266)	Loss/tok 3.2218 (3.1144)	Learning Rate [7.8125e-05]
15: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00092)	Tok/s 54895 (54220)	Loss/tok 3.1739 (3.1116)	Learning Rate [7.8125e-05]
13: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00109 (0.00096)	Tok/s 55059 (54010)	Loss/tok 3.1383 (3.1131)	Learning Rate [7.8125e-05]
7: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00097)	Tok/s 54007 (53505)	Loss/tok 3.2385 (3.1154)	Learning Rate [7.8125e-05]
3: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00092)	Tok/s 53610 (53171)	Loss/tok 3.1659 (3.1148)	Learning Rate [7.8125e-05]
0: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00097)	Tok/s 53730 (52872)	Loss/tok 3.1531 (3.1144)	Learning Rate [7.8125e-05]
2: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00098)	Tok/s 53609 (53073)	Loss/tok 3.2546 (3.1099)	Learning Rate [7.8125e-05]
1: TRAIN [2][3320/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00100)	Tok/s 53636 (52965)	Loss/tok 3.3897 (3.1129)	Learning Rate [7.8125e-05]
6: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00078 (0.00092)	Tok/s 47779 (53413)	Loss/tok 2.8624 (3.1143)	Learning Rate [7.8125e-05]
5: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00093)	Tok/s 47952 (53341)	Loss/tok 2.9048 (3.1140)	Learning Rate [7.8125e-05]
3: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00092)	Tok/s 47881 (53163)	Loss/tok 2.8538 (3.1149)	Learning Rate [7.8125e-05]
7: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00097)	Tok/s 47793 (53497)	Loss/tok 3.0169 (3.1152)	Learning Rate [7.8125e-05]
2: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00098)	Tok/s 48009 (53066)	Loss/tok 2.9648 (3.1097)	Learning Rate [7.8125e-05]
8: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00098)	Tok/s 47744 (53571)	Loss/tok 2.8742 (3.1143)	Learning Rate [7.8125e-05]
1: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00100)	Tok/s 47994 (52958)	Loss/tok 2.8423 (3.1127)	Learning Rate [7.8125e-05]
9: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00091)	Tok/s 47695 (53634)	Loss/tok 3.1003 (3.1102)	Learning Rate [7.8125e-05]
10: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00096)	Tok/s 47691 (53710)	Loss/tok 2.9714 (3.1084)	Learning Rate [7.8125e-05]
0: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00097)	Tok/s 47903 (52865)	Loss/tok 3.1194 (3.1145)	Learning Rate [7.8125e-05]
15: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00080 (0.00092)	Tok/s 49217 (54212)	Loss/tok 3.2312 (3.1114)	Learning Rate [7.8125e-05]
11: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00091)	Tok/s 47529 (53789)	Loss/tok 2.7867 (3.1119)	Learning Rate [7.8125e-05]
14: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00092)	Tok/s 49117 (54106)	Loss/tok 2.9849 (3.1136)	Learning Rate [7.8125e-05]
12: TRAIN [2][3330/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00100)	Tok/s 47419 (53904)	Loss/tok 2.9359 (3.1164)	Learning Rate [7.8125e-05]
13: TRAIN [2][3330/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00096)	Tok/s 47971 (54002)	Loss/tok 3.0087 (3.1131)	Learning Rate [7.8125e-05]
4: TRAIN [2][3330/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00099)	Tok/s 47261 (53258)	Loss/tok 2.8142 (3.1142)	Learning Rate [7.8125e-05]
6: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00080 (0.00092)	Tok/s 32473 (53397)	Loss/tok 2.7201 (3.1143)	Learning Rate [7.8125e-05]
7: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 32480 (53481)	Loss/tok 2.7498 (3.1149)	Learning Rate [7.8125e-05]
4: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00099)	Tok/s 32434 (53242)	Loss/tok 2.6147 (3.1140)	Learning Rate [7.8125e-05]
8: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00098)	Tok/s 33693 (53556)	Loss/tok 2.8286 (3.1141)	Learning Rate [7.8125e-05]
3: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00092)	Tok/s 32460 (53148)	Loss/tok 2.8311 (3.1147)	Learning Rate [7.8125e-05]
9: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00091)	Tok/s 33824 (53619)	Loss/tok 2.7124 (3.1102)	Learning Rate [7.8125e-05]
1: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00100)	Tok/s 32476 (52943)	Loss/tok 2.9949 (3.1127)	Learning Rate [7.8125e-05]
2: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00098)	Tok/s 32460 (53050)	Loss/tok 2.7917 (3.1097)	Learning Rate [7.8125e-05]
11: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00091)	Tok/s 33845 (53774)	Loss/tok 3.0209 (3.1118)	Learning Rate [7.8125e-05]
10: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00096)	Tok/s 33786 (53695)	Loss/tok 2.9637 (3.1083)	Learning Rate [7.8125e-05]
0: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00115 (0.00097)	Tok/s 32465 (52850)	Loss/tok 2.8795 (3.1144)	Learning Rate [7.8125e-05]
15: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 33804 (54197)	Loss/tok 2.7959 (3.1114)	Learning Rate [7.8125e-05]
12: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00100)	Tok/s 33789 (53889)	Loss/tok 3.0187 (3.1163)	Learning Rate [7.8125e-05]
14: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00092)	Tok/s 33803 (54090)	Loss/tok 2.6275 (3.1135)	Learning Rate [7.8125e-05]
13: TRAIN [2][3340/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00096)	Tok/s 33814 (53987)	Loss/tok 2.7959 (3.1129)	Learning Rate [7.8125e-05]
5: TRAIN [2][3340/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00093)	Tok/s 31771 (53325)	Loss/tok 3.0202 (3.1138)	Learning Rate [7.8125e-05]
9: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
9: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00109 (0.00091)	Tok/s 40773 (53603)	Loss/tok 3.1562 (3.1103)	Learning Rate [7.8125e-05]
12: Upscaling, new scale: 4096.0
8: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00103 (0.00098)	Tok/s 40648 (53540)	Loss/tok 2.6671 (3.1139)	Learning Rate [7.8125e-05]
6: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00092)	Tok/s 40280 (53381)	Loss/tok 3.2232 (3.1143)	Learning Rate [7.8125e-05]
10: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00096)	Tok/s 40748 (53679)	Loss/tok 3.1126 (3.1082)	Learning Rate [7.8125e-05]
7: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00097)	Tok/s 40562 (53465)	Loss/tok 2.9087 (3.1147)	Learning Rate [7.8125e-05]
13: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
11: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00107 (0.00091)	Tok/s 40706 (53758)	Loss/tok 2.9209 (3.1117)	Learning Rate [7.8125e-05]
14: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
5: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00093)	Tok/s 39117 (53309)	Loss/tok 2.9895 (3.1140)	Learning Rate [7.8125e-05]
12: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00100)	Tok/s 40747 (53872)	Loss/tok 2.8781 (3.1163)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
13: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00096)	Tok/s 40690 (53970)	Loss/tok 3.1598 (3.1129)	Learning Rate [7.8125e-05]
4: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00106 (0.00099)	Tok/s 39058 (53227)	Loss/tok 2.8036 (3.1141)	Learning Rate [7.8125e-05]
14: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00092)	Tok/s 40593 (54074)	Loss/tok 2.8078 (3.1133)	Learning Rate [7.8125e-05]
3: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00092)	Tok/s 39050 (53132)	Loss/tok 2.8234 (3.1145)	Learning Rate [7.8125e-05]
0: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00111 (0.00097)	Tok/s 39116 (52835)	Loss/tok 2.8667 (3.1142)	Learning Rate [7.8125e-05]
1: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00100)	Tok/s 39068 (52927)	Loss/tok 3.0157 (3.1126)	Learning Rate [7.8125e-05]
2: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00103 (0.00098)	Tok/s 39048 (53035)	Loss/tok 2.9288 (3.1096)	Learning Rate [7.8125e-05]
15: TRAIN [2][3350/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00092)	Tok/s 40560 (54180)	Loss/tok 2.8820 (3.1113)	Learning Rate [7.8125e-05]
6: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00092)	Tok/s 55074 (53403)	Loss/tok 2.9453 (3.1146)	Learning Rate [7.8125e-05]
7: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00097)	Tok/s 55087 (53487)	Loss/tok 3.1838 (3.1151)	Learning Rate [7.8125e-05]
8: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00098)	Tok/s 55351 (53562)	Loss/tok 3.2724 (3.1143)	Learning Rate [7.8125e-05]
5: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00093)	Tok/s 55044 (53331)	Loss/tok 3.2263 (3.1142)	Learning Rate [7.8125e-05]
9: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00099 (0.00091)	Tok/s 55798 (53625)	Loss/tok 3.2660 (3.1105)	Learning Rate [7.8125e-05]
4: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00099)	Tok/s 55038 (53249)	Loss/tok 3.0561 (3.1142)	Learning Rate [7.8125e-05]
3: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00092)	Tok/s 54938 (53155)	Loss/tok 3.1758 (3.1146)	Learning Rate [7.8125e-05]
10: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00096)	Tok/s 55862 (53701)	Loss/tok 3.3804 (3.1084)	Learning Rate [7.8125e-05]
11: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00091)	Tok/s 55808 (53780)	Loss/tok 2.9761 (3.1117)	Learning Rate [7.8125e-05]
2: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00098)	Tok/s 54843 (53058)	Loss/tok 3.0906 (3.1099)	Learning Rate [7.8125e-05]
1: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00100)	Tok/s 54793 (52950)	Loss/tok 3.2081 (3.1129)	Learning Rate [7.8125e-05]
12: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00100)	Tok/s 55854 (53894)	Loss/tok 3.1223 (3.1167)	Learning Rate [7.8125e-05]
0: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00097)	Tok/s 54721 (52858)	Loss/tok 3.4016 (3.1146)	Learning Rate [7.8125e-05]
13: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00096)	Tok/s 55795 (53992)	Loss/tok 3.2290 (3.1132)	Learning Rate [7.8125e-05]
14: TRAIN [2][3360/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00092)	Tok/s 55705 (54095)	Loss/tok 3.1599 (3.1135)	Learning Rate [7.8125e-05]
15: TRAIN [2][3360/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00092)	Tok/s 55610 (54201)	Loss/tok 3.2481 (3.1115)	Learning Rate [7.8125e-05]
15: TRAIN [2][3370/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 67665 (54212)	Loss/tok 3.0578 (3.1115)	Learning Rate [7.8125e-05]
14: TRAIN [2][3370/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 67606 (54106)	Loss/tok 3.2446 (3.1134)	Learning Rate [7.8125e-05]
0: TRAIN [2][3370/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 66749 (52871)	Loss/tok 3.0766 (3.1145)	Learning Rate [7.8125e-05]
13: TRAIN [2][3370/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 67538 (54003)	Loss/tok 2.9566 (3.1129)	Learning Rate [7.8125e-05]
1: TRAIN [2][3370/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00100)	Tok/s 66742 (52963)	Loss/tok 3.0899 (3.1129)	Learning Rate [7.8125e-05]
12: TRAIN [2][3370/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 67456 (53906)	Loss/tok 3.0046 (3.1168)	Learning Rate [7.8125e-05]
11: TRAIN [2][3370/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00091)	Tok/s 67289 (53791)	Loss/tok 3.1318 (3.1119)	Learning Rate [7.8125e-05]
2: TRAIN [2][3370/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 66703 (53070)	Loss/tok 3.3391 (3.1100)	Learning Rate [7.8125e-05]
3: TRAIN [2][3370/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 66585 (53167)	Loss/tok 3.1297 (3.1148)	Learning Rate [7.8125e-05]
10: TRAIN [2][3370/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00096)	Tok/s 66888 (53712)	Loss/tok 3.0966 (3.1084)	Learning Rate [7.8125e-05]
8: TRAIN [2][3370/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 66359 (53573)	Loss/tok 3.3404 (3.1144)	Learning Rate [7.8125e-05]
9: TRAIN [2][3370/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00091)	Tok/s 66290 (53636)	Loss/tok 3.2079 (3.1106)	Learning Rate [7.8125e-05]
6: TRAIN [2][3370/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 66299 (53414)	Loss/tok 3.2083 (3.1148)	Learning Rate [7.8125e-05]
7: TRAIN [2][3370/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 66296 (53498)	Loss/tok 3.0375 (3.1149)	Learning Rate [7.8125e-05]
4: TRAIN [2][3370/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00099)	Tok/s 66453 (53261)	Loss/tok 3.4426 (3.1143)	Learning Rate [7.8125e-05]
5: TRAIN [2][3370/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 66387 (53343)	Loss/tok 3.5632 (3.1143)	Learning Rate [7.8125e-05]
15: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00092)	Tok/s 49800 (54222)	Loss/tok 2.9268 (3.1116)	Learning Rate [7.8125e-05]
0: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00097)	Tok/s 48315 (52882)	Loss/tok 3.0165 (3.1148)	Learning Rate [7.8125e-05]
1: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00100)	Tok/s 48218 (52974)	Loss/tok 3.1507 (3.1131)	Learning Rate [7.8125e-05]
14: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00092)	Tok/s 49816 (54116)	Loss/tok 2.8277 (3.1136)	Learning Rate [7.8125e-05]
3: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00092)	Tok/s 49598 (53179)	Loss/tok 3.0575 (3.1149)	Learning Rate [7.8125e-05]
2: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00098)	Tok/s 48614 (53082)	Loss/tok 2.9435 (3.1104)	Learning Rate [7.8125e-05]
13: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00096)	Tok/s 49719 (54013)	Loss/tok 2.9616 (3.1130)	Learning Rate [7.8125e-05]
10: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00096)	Tok/s 49844 (53723)	Loss/tok 2.9176 (3.1083)	Learning Rate [7.8125e-05]
12: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00100)	Tok/s 49794 (53916)	Loss/tok 3.2826 (3.1171)	Learning Rate [7.8125e-05]
5: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00093)	Tok/s 49468 (53354)	Loss/tok 2.8605 (3.1144)	Learning Rate [7.8125e-05]
11: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00091)	Tok/s 49771 (53801)	Loss/tok 3.1213 (3.1119)	Learning Rate [7.8125e-05]
6: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00092)	Tok/s 49482 (53425)	Loss/tok 2.9409 (3.1148)	Learning Rate [7.8125e-05]
9: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00091)	Tok/s 49615 (53647)	Loss/tok 3.1283 (3.1106)	Learning Rate [7.8125e-05]
7: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00097)	Tok/s 49418 (53509)	Loss/tok 3.2320 (3.1150)	Learning Rate [7.8125e-05]
4: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00099)	Tok/s 49308 (53272)	Loss/tok 3.0539 (3.1143)	Learning Rate [7.8125e-05]
8: TRAIN [2][3380/3416]	Time 0.045 (0.058)	Data 0.00083 (0.00098)	Tok/s 49418 (53584)	Loss/tok 2.9028 (3.1145)	Learning Rate [7.8125e-05]
12: TRAIN [2][3390/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00100)	Tok/s 56723 (53917)	Loss/tok 3.2319 (3.1173)	Learning Rate [7.8125e-05]
11: TRAIN [2][3390/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00091)	Tok/s 56044 (53802)	Loss/tok 3.3206 (3.1121)	Learning Rate [7.8125e-05]
13: TRAIN [2][3390/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00096)	Tok/s 56585 (54014)	Loss/tok 3.0858 (3.1132)	Learning Rate [7.8125e-05]
10: TRAIN [2][3390/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00096)	Tok/s 55713 (53723)	Loss/tok 3.0799 (3.1085)	Learning Rate [7.8125e-05]
15: TRAIN [2][3390/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00092)	Tok/s 56382 (54223)	Loss/tok 3.3656 (3.1117)	Learning Rate [7.8125e-05]
0: TRAIN [2][3390/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00097)	Tok/s 55416 (52884)	Loss/tok 3.3284 (3.1149)	Learning Rate [7.8125e-05]
8: TRAIN [2][3390/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00098)	Tok/s 55700 (53585)	Loss/tok 3.3157 (3.1144)	Learning Rate [7.8125e-05]
6: TRAIN [2][3390/3416]	Time 0.066 (0.058)	Data 0.00083 (0.00092)	Tok/s 55662 (53426)	Loss/tok 3.1475 (3.1149)	Learning Rate [7.8125e-05]
7: TRAIN [2][3390/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00097)	Tok/s 55675 (53510)	Loss/tok 3.3294 (3.1150)	Learning Rate [7.8125e-05]
1: TRAIN [2][3390/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00100)	Tok/s 55960 (52976)	Loss/tok 3.1293 (3.1131)	Learning Rate [7.8125e-05]
9: TRAIN [2][3390/3416]	Time 0.065 (0.058)	Data 0.00115 (0.00091)	Tok/s 55748 (53648)	Loss/tok 3.4787 (3.1107)	Learning Rate [7.8125e-05]
2: TRAIN [2][3390/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00098)	Tok/s 55401 (53083)	Loss/tok 3.2541 (3.1105)	Learning Rate [7.8125e-05]
4: TRAIN [2][3390/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00099)	Tok/s 55514 (53273)	Loss/tok 3.2501 (3.1144)	Learning Rate [7.8125e-05]
5: TRAIN [2][3390/3416]	Time 0.066 (0.058)	Data 0.00077 (0.00093)	Tok/s 55517 (53355)	Loss/tok 3.2416 (3.1143)	Learning Rate [7.8125e-05]
3: TRAIN [2][3390/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00092)	Tok/s 55414 (53180)	Loss/tok 3.0343 (3.1149)	Learning Rate [7.8125e-05]
14: TRAIN [2][3390/3416]	Time 0.066 (0.058)	Data 0.00083 (0.00092)	Tok/s 56409 (54117)	Loss/tok 3.2298 (3.1138)	Learning Rate [7.8125e-05]
13: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00109 (0.00096)	Tok/s 47983 (54020)	Loss/tok 3.2363 (3.1132)	Learning Rate [7.8125e-05]
12: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00100)	Tok/s 47901 (53923)	Loss/tok 3.0370 (3.1174)	Learning Rate [7.8125e-05]
14: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00092)	Tok/s 47905 (54124)	Loss/tok 2.9156 (3.1137)	Learning Rate [7.8125e-05]
11: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00103 (0.00091)	Tok/s 47905 (53808)	Loss/tok 3.0376 (3.1120)	Learning Rate [7.8125e-05]
15: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00107 (0.00092)	Tok/s 47749 (54229)	Loss/tok 3.3073 (3.1117)	Learning Rate [7.8125e-05]
0: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00100 (0.00097)	Tok/s 47635 (52890)	Loss/tok 2.9200 (3.1149)	Learning Rate [7.8125e-05]
10: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00096)	Tok/s 47889 (53730)	Loss/tok 3.0823 (3.1085)	Learning Rate [7.8125e-05]
9: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00122 (0.00091)	Tok/s 48089 (53654)	Loss/tok 2.9096 (3.1110)	Learning Rate [7.8125e-05]
6: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00088 (0.00092)	Tok/s 47807 (53433)	Loss/tok 3.0308 (3.1150)	Learning Rate [7.8125e-05]
1: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00104 (0.00100)	Tok/s 47499 (52982)	Loss/tok 2.7444 (3.1133)	Learning Rate [7.8125e-05]
8: TRAIN [2][3400/3416]	Time 0.042 (0.058)	Data 0.00144 (0.00098)	Tok/s 48750 (53591)	Loss/tok 2.9389 (3.1145)	Learning Rate [7.8125e-05]
7: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00098 (0.00097)	Tok/s 47765 (53516)	Loss/tok 2.9452 (3.1150)	Learning Rate [7.8125e-05]
2: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00096 (0.00098)	Tok/s 47496 (53089)	Loss/tok 2.8356 (3.1106)	Learning Rate [7.8125e-05]
3: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00099 (0.00092)	Tok/s 47506 (53186)	Loss/tok 3.1713 (3.1149)	Learning Rate [7.8125e-05]
5: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00093)	Tok/s 47595 (53361)	Loss/tok 3.1325 (3.1141)	Learning Rate [7.8125e-05]
4: TRAIN [2][3400/3416]	Time 0.043 (0.058)	Data 0.00109 (0.00099)	Tok/s 47469 (53280)	Loss/tok 2.8168 (3.1143)	Learning Rate [7.8125e-05]
11: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00091)	Tok/s 50963 (53803)	Loss/tok 3.0438 (3.1118)	Learning Rate [7.8125e-05]
12: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00100)	Tok/s 51092 (53917)	Loss/tok 2.8466 (3.1173)	Learning Rate [7.8125e-05]
13: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00096)	Tok/s 51064 (54014)	Loss/tok 3.1058 (3.1132)	Learning Rate [7.8125e-05]
15: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00092)	Tok/s 52387 (54223)	Loss/tok 3.0927 (3.1115)	Learning Rate [7.8125e-05]
14: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00092)	Tok/s 52272 (54118)	Loss/tok 3.1938 (3.1135)	Learning Rate [7.8125e-05]
9: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00101 (0.00091)	Tok/s 50743 (53649)	Loss/tok 3.2657 (3.1108)	Learning Rate [7.8125e-05]
10: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00096)	Tok/s 50940 (53724)	Loss/tok 3.1842 (3.1084)	Learning Rate [7.8125e-05]
8: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00098)	Tok/s 50757 (53586)	Loss/tok 3.0361 (3.1144)	Learning Rate [7.8125e-05]
0: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00097)	Tok/s 51071 (52885)	Loss/tok 3.1654 (3.1147)	Learning Rate [7.8125e-05]
6: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00092)	Tok/s 50785 (53427)	Loss/tok 3.1493 (3.1149)	Learning Rate [7.8125e-05]
7: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00101 (0.00097)	Tok/s 50741 (53511)	Loss/tok 2.8510 (3.1149)	Learning Rate [7.8125e-05]
1: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00100)	Tok/s 51051 (52977)	Loss/tok 3.2341 (3.1131)	Learning Rate [7.8125e-05]
2: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00098)	Tok/s 50924 (53084)	Loss/tok 3.1254 (3.1106)	Learning Rate [7.8125e-05]
5: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00085 (0.00093)	Tok/s 50777 (53356)	Loss/tok 3.1125 (3.1139)	Learning Rate [7.8125e-05]
3: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00092)	Tok/s 51035 (53181)	Loss/tok 3.0420 (3.1146)	Learning Rate [7.8125e-05]
4: TRAIN [2][3410/3416]	Time 0.053 (0.058)	Data 0.00103 (0.00099)	Tok/s 50776 (53274)	Loss/tok 2.9441 (3.1143)	Learning Rate [7.8125e-05]
15: Running validation on dev set
1: Running validation on dev set
0: Running validation on dev set
4: Running validation on dev set
5: Running validation on dev set
6: Running validation on dev set
3: Running validation on dev set
2: Running validation on dev set
10: Running validation on dev set
9: Running validation on dev set
13: Running validation on dev set
7: Running validation on dev set
8: Running validation on dev set
12: Running validation on dev set
11: Running validation on dev set
14: Running validation on dev set
15: VALIDATION [2][0/5]	Time 0.022 (0.000)	Data 0.00219 (0.00000)	Tok/s 226017 (0)	Loss/tok 3.0752 (0.0000)	Learning Rate [7.8125e-05]
1: VALIDATION [2][0/5]	Time 0.037 (0.000)	Data 0.00215 (0.00000)	Tok/s 225134 (0)	Loss/tok 3.2286 (0.0000)	Learning Rate [7.8125e-05]
0: VALIDATION [2][0/5]	Time 0.061 (0.000)	Data 0.00221 (0.00000)	Tok/s 167529 (0)	Loss/tok 3.2968 (0.0000)	Learning Rate [7.8125e-05]
6: VALIDATION [2][0/5]	Time 0.029 (0.000)	Data 0.00212 (0.00000)	Tok/s 223758 (0)	Loss/tok 3.0755 (0.0000)	Learning Rate [7.8125e-05]
5: VALIDATION [2][0/5]	Time 0.030 (0.000)	Data 0.00216 (0.00000)	Tok/s 224813 (0)	Loss/tok 3.0965 (0.0000)	Learning Rate [7.8125e-05]
4: VALIDATION [2][0/5]	Time 0.033 (0.000)	Data 0.00223 (0.00000)	Tok/s 207442 (0)	Loss/tok 3.0507 (0.0000)	Learning Rate [7.8125e-05]
3: VALIDATION [2][0/5]	Time 0.032 (0.000)	Data 0.00211 (0.00000)	Tok/s 225149 (0)	Loss/tok 3.1013 (0.0000)	Learning Rate [7.8125e-05]
2: VALIDATION [2][0/5]	Time 0.034 (0.000)	Data 0.00213 (0.00000)	Tok/s 225059 (0)	Loss/tok 3.1917 (0.0000)	Learning Rate [7.8125e-05]
10: VALIDATION [2][0/5]	Time 0.025 (0.000)	Data 0.00217 (0.00000)	Tok/s 223956 (0)	Loss/tok 3.0440 (0.0000)	Learning Rate [7.8125e-05]
9: VALIDATION [2][0/5]	Time 0.026 (0.000)	Data 0.00233 (0.00000)	Tok/s 220225 (0)	Loss/tok 3.1868 (0.0000)	Learning Rate [7.8125e-05]
13: VALIDATION [2][0/5]	Time 0.025 (0.000)	Data 0.00218 (0.00000)	Tok/s 211877 (0)	Loss/tok 3.2037 (0.0000)	Learning Rate [7.8125e-05]
7: VALIDATION [2][0/5]	Time 0.028 (0.000)	Data 0.00226 (0.00000)	Tok/s 225283 (0)	Loss/tok 3.2142 (0.0000)	Learning Rate [7.8125e-05]
8: VALIDATION [2][0/5]	Time 0.026 (0.000)	Data 0.00228 (0.00000)	Tok/s 231524 (0)	Loss/tok 3.1902 (0.0000)	Learning Rate [7.8125e-05]
14: VALIDATION [2][0/5]	Time 0.024 (0.000)	Data 0.00222 (0.00000)	Tok/s 217897 (0)	Loss/tok 3.2188 (0.0000)	Learning Rate [7.8125e-05]
12: VALIDATION [2][0/5]	Time 0.024 (0.000)	Data 0.00222 (0.00000)	Tok/s 229033 (0)	Loss/tok 3.0829 (0.0000)	Learning Rate [7.8125e-05]
11: VALIDATION [2][0/5]	Time 0.025 (0.000)	Data 0.00214 (0.00000)	Tok/s 220684 (0)	Loss/tok 3.0886 (0.0000)	Learning Rate [7.8125e-05]
8: Running evaluation on test set
11: Running evaluation on test set
9: Running evaluation on test set
7: Running evaluation on test set
12: Running evaluation on test set
2: Running evaluation on test set
13: Running evaluation on test set
10: Running evaluation on test set
14: Running evaluation on test set
1: Running evaluation on test set
15: Running evaluation on test set
5: Running evaluation on test set
6: Running evaluation on test set
3: Running evaluation on test set
4: Running evaluation on test set
:::MLPv0.5.0 gnmt 1541784710.316100359 (train.py:459) eval_start: 2
0: Running evaluation on test set
7: TEST [2][0/2]	Time 1.133 (1.133)	Decoder iters 83.0 (83.0)	Tok/s 6455 (6455)
12: TEST [2][0/2]	Time 1.133 (1.133)	Decoder iters 62.0 (62.0)	Tok/s 5650 (5650)
5: TEST [2][0/2]	Time 1.133 (1.133)	Decoder iters 59.0 (59.0)	Tok/s 5835 (5835)
8: TEST [2][0/2]	Time 1.134 (1.134)	Decoder iters 74.0 (74.0)	Tok/s 6674 (6674)
9: TEST [2][0/2]	Time 1.134 (1.134)	Decoder iters 65.0 (65.0)	Tok/s 5959 (5959)
11: TEST [2][0/2]	Time 1.134 (1.134)	Decoder iters 85.0 (85.0)	Tok/s 5680 (5680)
10: TEST [2][0/2]	Time 1.135 (1.135)	Decoder iters 88.0 (88.0)	Tok/s 5884 (5884)
14: TEST [2][0/2]	Time 1.135 (1.135)	Decoder iters 70.0 (70.0)	Tok/s 7254 (7254)
1: TEST [2][0/2]	Time 1.135 (1.135)	Decoder iters 79.0 (79.0)	Tok/s 6755 (6755)
4: TEST [2][0/2]	Time 1.135 (1.135)	Decoder iters 95.0 (95.0)	Tok/s 6966 (6966)
3: TEST [2][0/2]	Time 1.135 (1.135)	Decoder iters 149.0 (149.0)	Tok/s 6736 (6736)
2: TEST [2][0/2]	Time 1.135 (1.135)	Decoder iters 118.0 (118.0)	Tok/s 6488 (6488)
13: TEST [2][0/2]	Time 1.135 (1.135)	Decoder iters 72.0 (72.0)	Tok/s 6223 (6223)
15: TEST [2][0/2]	Time 1.135 (1.135)	Decoder iters 135.0 (135.0)	Tok/s 7268 (7268)
0: TEST [2][0/2]	Time 1.136 (1.136)	Decoder iters 73.0 (73.0)	Tok/s 6211 (6211)
6: TEST [2][0/2]	Time 1.139 (1.139)	Decoder iters 95.0 (95.0)	Tok/s 6885 (6885)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
0: Target accuracy reached
13: Finished evaluation on test set
2: Finished evaluation on test set
11: Finished evaluation on test set
9: Finished evaluation on test set
14: Finished evaluation on test set
15: Finished evaluation on test set
7: Finished evaluation on test set
1: Finished evaluation on test set
10: Finished evaluation on test set
4: Finished evaluation on test set
3: Finished evaluation on test set
6: Finished evaluation on test set
12: Finished evaluation on test set
8: Finished evaluation on test set
0: Finished evaluation on test set
5: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1541784717.476060152 (train.py:464) eval_accuracy: {"epoch": 2, "value": 22.0}
:::MLPv0.5.0 gnmt 1541784717.476459503 (train.py:466) eval_target: 21.8
11: Summary: Epoch: 2	Training Loss 3.1132
12: Summary: Epoch: 2	Training Loss 3.1132
13: Summary: Epoch: 2	Training Loss 3.1132
14: Summary: Epoch: 2	Training Loss 3.1132
10: Summary: Epoch: 2	Training Loss 3.1132
15: Summary: Epoch: 2	Training Loss 3.1132
5: Summary: Epoch: 2	Training Loss 3.1132
2: Summary: Epoch: 2	Training Loss 3.1132
9: Summary: Epoch: 2	Training Loss 3.1132
1: Summary: Epoch: 2	Training Loss 3.1132
8: Summary: Epoch: 2	Training Loss 3.1132
7: Summary: Epoch: 2	Training Loss 3.1132
3: Summary: Epoch: 2	Training Loss 3.1132
6: Summary: Epoch: 2	Training Loss 3.1132
4: Summary: Epoch: 2	Training Loss 3.1132
11: Performance: Epoch: 2	Training: 856707 Tok/s
12: Performance: Epoch: 2	Training: 856707 Tok/s
13: Performance: Epoch: 2	Training: 856707 Tok/s
14: Performance: Epoch: 2	Training: 856707 Tok/s
10: Performance: Epoch: 2	Training: 856707 Tok/s
15: Performance: Epoch: 2	Training: 856707 Tok/s
5: Performance: Epoch: 2	Training: 856707 Tok/s
2: Performance: Epoch: 2	Training: 856707 Tok/s
9: Performance: Epoch: 2	Training: 856707 Tok/s
8: Performance: Epoch: 2	Training: 856707 Tok/s
7: Performance: Epoch: 2	Training: 856707 Tok/s
11: Finished epoch 2
14: Finished epoch 2
13: Finished epoch 2
3: Performance: Epoch: 2	Training: 856707 Tok/s
12: Finished epoch 2
1: Performance: Epoch: 2	Training: 856707 Tok/s
10: Finished epoch 2
6: Performance: Epoch: 2	Training: 856707 Tok/s
4: Performance: Epoch: 2	Training: 856707 Tok/s
15: Finished epoch 2
5: Finished epoch 2
2: Finished epoch 2
:::MLPv0.5.0 gnmt 1541784717.476778269 (train.py:467) eval_stop
7: Finished epoch 2
9: Finished epoch 2
8: Finished epoch 2
3: Finished epoch 2
6: Finished epoch 2
4: Finished epoch 2
1: Finished epoch 2
0: Summary: Epoch: 2	Training Loss: 3.1132	Validation Loss: 3.0008	Test BLEU: 22.00
0: Performance: Epoch: 2	Training: 856707 Tok/s	Validation: 2806809 Tok/s
0: Finished epoch 2
:::MLPv0.5.0 gnmt 1541784717.477286100 (train.py:488) run_stop: {"success": true}
:::MLPv0.5.0 gnmt 1541784717.477607012 (train.py:494) train_checkpoint
0: Saving model to results/gnmt_wmt16/model_best.pth
:::MLPv0.5.0 gnmt 1541784723.355779171 (train.py:498) run_final
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2018-11-09 05:32:13 PM
RESULT,RNN_TRANSLATOR,,705,nvidia,2018-11-09 05:20:28 PM
