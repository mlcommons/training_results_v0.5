Beginning trial 1 of 1
Clearing caches
:::MLPv0.5.0 gnmt 1541782194.741144180 (<string>:1) run_clear_caches
Launching on node xpl-dvt-70
+ pids+=($!)
+ set +x
++ eval echo
+++ echo
+ docker exec -e DGXSYSTEM=DGX2_alt -e MULTI_NODE= -e SLURM_JOB_ID=1541782168 -e SLURM_NTASKS_PER_NODE= cont_1541782168 ./run_and_time.sh
Run vars: id 1541782168 gpus 16 mparams 
STARTING TIMING RUN AT 2018-11-09 04:49:55 PM
+ DATASET_DIR=/data
+ RESULTS_DIR=gnmt_wmt16
+ BATCH=64
+ TEST_BATCH_SIZE=128
+ LR=1.25e-3
+ TARGET=21.80
+ WARMUP_ITERS=200
+ REMAIN_STEPS=6000
+ DECAY_STEPS=500
+ echo 'running benchmark'
running benchmark
+ python -m torch.distributed.launch --nproc_per_node 16 train.py --save gnmt_wmt16 --dataset-dir /data --target-bleu 21.80 --epochs 20 --math fp16 --print-freq 10 --batch-size 64 --test-batch-size 128 --model-config '{'\''num_layers'\'': 4, '\''hidden_size'\'': 1024, '\''dropout'\'':0.2, '\''share_embedding'\'': True}' --optimization-config '{'\''optimizer'\'': '\''FusedAdam'\'', '\''lr'\'': 1.25e-3}' --scheduler-config '{'\''lr_method'\'':'\''mlperf'\'', '\''warmup_iters'\'':200, '\''remain_steps'\'':6000, '\''decay_steps'\'':500}'
6: Saving results to: results/gnmt_wmt16
4: Saving results to: results/gnmt_wmt16
3: Saving results to: results/gnmt_wmt16
9: Saving results to: results/gnmt_wmt16
6: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=6, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=6, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
2: Saving results to: results/gnmt_wmt16
7: Saving results to: results/gnmt_wmt16
12: Saving results to: results/gnmt_wmt16
4: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=4, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=4, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
14: Saving results to: results/gnmt_wmt16
3: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=3, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=3, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
9: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=9, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=9, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
2: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=2, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=2, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
10: Saving results to: results/gnmt_wmt16
12: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=12, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=12, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
11: Saving results to: results/gnmt_wmt16
15: Saving results to: results/gnmt_wmt16
14: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=14, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=14, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
7: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=7, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=7, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
10: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=10, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=10, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
11: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=11, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=11, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
15: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=15, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=15, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
6: L2 promotion: 128B
1: Saving results to: results/gnmt_wmt16
5: Saving results to: results/gnmt_wmt16
8: Saving results to: results/gnmt_wmt16
13: Saving results to: results/gnmt_wmt16
1: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=1, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=1, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
5: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=5, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=5, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
8: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=8, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=8, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
13: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=13, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=13, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
4: L2 promotion: 128B
9: L2 promotion: 128B
3: L2 promotion: 128B
2: L2 promotion: 128B
14: L2 promotion: 128B
12: L2 promotion: 128B
7: L2 promotion: 128B
10: L2 promotion: 128B
11: L2 promotion: 128B
15: L2 promotion: 128B
5: L2 promotion: 128B
1: L2 promotion: 128B
8: L2 promotion: 128B
13: L2 promotion: 128B
:::MLPv0.5.0 gnmt 1541782230.583970547 (train.py:242) run_start
0: Saving results to: results/gnmt_wmt16
0: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=64, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=20, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=0, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=0, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
0: L2 promotion: 128B
:::MLPv0.5.0 gnmt 1541782230.585917234 (train.py:265) run_set_random_seed
0: Using random master seed: 3885455737
0: Worker 0 is using worker seed: 4214903374
3: Worker 3 is using worker seed: 701608747
2: Worker 2 is using worker seed: 2348851122
0: Building vocabulary from /data/vocab.bpe.32000
8: Worker 8 is using worker seed: 2734868294
7: Worker 7 is using worker seed: 189173771
13: Worker 13 is using worker seed: 1132570332
12: Worker 12 is using worker seed: 2602881993
15: Worker 15 is using worker seed: 315140919
11: Worker 11 is using worker seed: 1877674962
14: Worker 14 is using worker seed: 2875261884
6: Worker 6 is using worker seed: 2812413021
10: Worker 10 is using worker seed: 2293335394
5: Worker 5 is using worker seed: 2634603496
1: Worker 1 is using worker seed: 624911100
4: Worker 4 is using worker seed: 515434685
9: Worker 9 is using worker seed: 3761902515
2: Building vocabulary from /data/vocab.bpe.32000
14: Building vocabulary from /data/vocab.bpe.32000
6: Building vocabulary from /data/vocab.bpe.32000
7: Building vocabulary from /data/vocab.bpe.32000
12: Building vocabulary from /data/vocab.bpe.32000
9: Building vocabulary from /data/vocab.bpe.32000
5: Building vocabulary from /data/vocab.bpe.32000
3: Building vocabulary from /data/vocab.bpe.32000
10: Building vocabulary from /data/vocab.bpe.32000
4: Building vocabulary from /data/vocab.bpe.32000
11: Building vocabulary from /data/vocab.bpe.32000
15: Building vocabulary from /data/vocab.bpe.32000
13: Building vocabulary from /data/vocab.bpe.32000
8: Building vocabulary from /data/vocab.bpe.32000
1: Building vocabulary from /data/vocab.bpe.32000
2: Size of vocabulary: 32320
14: Size of vocabulary: 32320
9: Size of vocabulary: 32320
0: Size of vocabulary: 32320
3: Size of vocabulary: 32320
12: Size of vocabulary: 32320
13: Size of vocabulary: 32320
8: Size of vocabulary: 32320
4: Size of vocabulary: 32320
7: Size of vocabulary: 32320
6: Size of vocabulary: 32320
1: Size of vocabulary: 32320
15: Size of vocabulary: 32320
11: Size of vocabulary: 32320
5: Size of vocabulary: 32320
10: Size of vocabulary: 32320
:::MLPv0.5.0 gnmt 1541782230.622562408 (train.py:302) preproc_tokenize_training
15: Processing data from /data/train.tok.clean.bpe.32000.en
4: Processing data from /data/train.tok.clean.bpe.32000.en
6: Processing data from /data/train.tok.clean.bpe.32000.en
9: Processing data from /data/train.tok.clean.bpe.32000.en
12: Processing data from /data/train.tok.clean.bpe.32000.en
2: Processing data from /data/train.tok.clean.bpe.32000.en
7: Processing data from /data/train.tok.clean.bpe.32000.en
8: Processing data from /data/train.tok.clean.bpe.32000.en
13: Processing data from /data/train.tok.clean.bpe.32000.en
1: Processing data from /data/train.tok.clean.bpe.32000.en
14: Processing data from /data/train.tok.clean.bpe.32000.en
3: Processing data from /data/train.tok.clean.bpe.32000.en
5: Processing data from /data/train.tok.clean.bpe.32000.en
10: Processing data from /data/train.tok.clean.bpe.32000.en
11: Processing data from /data/train.tok.clean.bpe.32000.en
:::MLPv0.5.0 gnmt 1541782230.623136282 (train.py:304) train_hp_max_sequence_length: 50
0: Processing data from /data/train.tok.clean.bpe.32000.en
2: Processing data from /data/train.tok.clean.bpe.32000.de
8: Processing data from /data/train.tok.clean.bpe.32000.de
12: Processing data from /data/train.tok.clean.bpe.32000.de
3: Processing data from /data/train.tok.clean.bpe.32000.de
6: Processing data from /data/train.tok.clean.bpe.32000.de
7: Processing data from /data/train.tok.clean.bpe.32000.de
14: Processing data from /data/train.tok.clean.bpe.32000.de
4: Processing data from /data/train.tok.clean.bpe.32000.de
9: Processing data from /data/train.tok.clean.bpe.32000.de
15: Processing data from /data/train.tok.clean.bpe.32000.de
13: Processing data from /data/train.tok.clean.bpe.32000.de
11: Processing data from /data/train.tok.clean.bpe.32000.de
1: Processing data from /data/train.tok.clean.bpe.32000.de
5: Processing data from /data/train.tok.clean.bpe.32000.de
0: Processing data from /data/train.tok.clean.bpe.32000.de
10: Processing data from /data/train.tok.clean.bpe.32000.de
7: Filtering data, min len: 0, max len: 50
0: Filtering data, min len: 0, max len: 50
4: Filtering data, min len: 0, max len: 50
15: Filtering data, min len: 0, max len: 50
3: Filtering data, min len: 0, max len: 50
14: Filtering data, min len: 0, max len: 50
2: Filtering data, min len: 0, max len: 50
11: Filtering data, min len: 0, max len: 50
12: Filtering data, min len: 0, max len: 50
8: Filtering data, min len: 0, max len: 50
13: Filtering data, min len: 0, max len: 50
9: Filtering data, min len: 0, max len: 50
1: Filtering data, min len: 0, max len: 50
6: Filtering data, min len: 0, max len: 50
5: Filtering data, min len: 0, max len: 50
10: Filtering data, min len: 0, max len: 50
0: Pairs before: 4068191, after: 3498161
14: Pairs before: 4068191, after: 3498161
9: Pairs before: 4068191, after: 3498161
12: Pairs before: 4068191, after: 3498161
6: Pairs before: 4068191, after: 3498161
7: Pairs before: 4068191, after: 3498161
4: Pairs before: 4068191, after: 3498161
15: Pairs before: 4068191, after: 3498161
8: Pairs before: 4068191, after: 3498161
3: Pairs before: 4068191, after: 3498161
5: Pairs before: 4068191, after: 3498161
2: Pairs before: 4068191, after: 3498161
10: Pairs before: 4068191, after: 3498161
13: Pairs before: 4068191, after: 3498161
11: Pairs before: 4068191, after: 3498161
1: Pairs before: 4068191, after: 3498161
8: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
6: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
5: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
12: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
2: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
10: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
15: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
7: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
3: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
11: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
9: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
14: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
4: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
13: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
1: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
:::MLPv0.5.0 gnmt 1541782241.131419897 (train.py:316) preproc_num_train_examples: 3498161
0: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
14: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
0: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
12: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
10: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
2: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
11: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
5: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
6: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
3: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
15: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
4: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
9: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
7: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
8: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
1: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
13: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
14: Filtering data, min len: 0, max len: 150
14: Pairs before: 5100, after: 5100
0: Filtering data, min len: 0, max len: 150
0: Pairs before: 5100, after: 5100
12: Filtering data, min len: 0, max len: 150
2: Filtering data, min len: 0, max len: 150
10: Filtering data, min len: 0, max len: 150
12: Pairs before: 5100, after: 5100
2: Pairs before: 5100, after: 5100
15: Filtering data, min len: 0, max len: 150
10: Pairs before: 5100, after: 5100
15: Pairs before: 5100, after: 5100
5: Filtering data, min len: 0, max len: 150
5: Pairs before: 5100, after: 5100
11: Filtering data, min len: 0, max len: 150
7: Filtering data, min len: 0, max len: 150
11: Pairs before: 5100, after: 5100
7: Pairs before: 5100, after: 5100
6: Filtering data, min len: 0, max len: 150
6: Pairs before: 5100, after: 5100
1: Filtering data, min len: 0, max len: 150
1: Pairs before: 5100, after: 5100
4: Filtering data, min len: 0, max len: 150
4: Pairs before: 5100, after: 5100
8: Filtering data, min len: 0, max len: 150
9: Filtering data, min len: 0, max len: 150
8: Pairs before: 5100, after: 5100
9: Pairs before: 5100, after: 5100
3: Filtering data, min len: 0, max len: 150
3: Pairs before: 5100, after: 5100
13: Filtering data, min len: 0, max len: 150
13: Pairs before: 5100, after: 5100
9: Processing data from /data/newstest2014.tok.bpe.32000.en
3: Processing data from /data/newstest2014.tok.bpe.32000.en
7: Processing data from /data/newstest2014.tok.bpe.32000.en
11: Processing data from /data/newstest2014.tok.bpe.32000.en
4: Processing data from /data/newstest2014.tok.bpe.32000.en
10: Processing data from /data/newstest2014.tok.bpe.32000.en
6: Processing data from /data/newstest2014.tok.bpe.32000.en
12: Processing data from /data/newstest2014.tok.bpe.32000.en
8: Processing data from /data/newstest2014.tok.bpe.32000.en
1: Processing data from /data/newstest2014.tok.bpe.32000.en
15: Processing data from /data/newstest2014.tok.bpe.32000.en
5: Processing data from /data/newstest2014.tok.bpe.32000.en
13: Processing data from /data/newstest2014.tok.bpe.32000.en
14: Processing data from /data/newstest2014.tok.bpe.32000.en
2: Processing data from /data/newstest2014.tok.bpe.32000.en
:::MLPv0.5.0 gnmt 1541782242.560351133 (train.py:326) preproc_tokenize_eval
0: Processing data from /data/newstest2014.tok.bpe.32000.en
1: Filtering data, min len: 0, max len: 150
7: Filtering data, min len: 0, max len: 150
10: Filtering data, min len: 0, max len: 150
2: Filtering data, min len: 0, max len: 150
15: Filtering data, min len: 0, max len: 150
5: Filtering data, min len: 0, max len: 150
12: Filtering data, min len: 0, max len: 150
7: Pairs before: 3003, after: 3003
1: Pairs before: 3003, after: 3003
6: Filtering data, min len: 0, max len: 150
10: Pairs before: 3003, after: 3003
13: Filtering data, min len: 0, max len: 150
2: Pairs before: 3003, after: 3003
15: Pairs before: 3003, after: 3003
0: Filtering data, min len: 0, max len: 150
4: Filtering data, min len: 0, max len: 150
5: Pairs before: 3003, after: 3003
3: Filtering data, min len: 0, max len: 150
12: Pairs before: 3003, after: 3003
11: Filtering data, min len: 0, max len: 150
6: Pairs before: 3003, after: 3003
8: Filtering data, min len: 0, max len: 150
13: Pairs before: 3003, after: 3003
9: Filtering data, min len: 0, max len: 150
0: Pairs before: 3003, after: 3003
4: Pairs before: 3003, after: 3003
11: Pairs before: 3003, after: 3003
3: Pairs before: 3003, after: 3003
8: Pairs before: 3003, after: 3003
9: Pairs before: 3003, after: 3003
14: Filtering data, min len: 0, max len: 150
14: Pairs before: 3003, after: 3003
:::MLPv0.5.0 gnmt 1541782242.605591297 (train.py:336) preproc_num_eval_examples: 3003
:::MLPv0.5.0 gnmt 1541782242.605991364 (train.py:341) preproc_vocab_size: 32320
:::MLPv0.5.0 gnmt 1541782242.606915236 (seq2seq/models/gnmt.py:37) model_hp_num_layers: 4
:::MLPv0.5.0 gnmt 1541782242.607280016 (seq2seq/models/gnmt.py:39) model_hp_hidden_size: 1024
:::MLPv0.5.0 gnmt 1541782242.607621670 (seq2seq/models/gnmt.py:41) model_hp_dropout: 0.2
10: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
10: Building LabelSmoothingLoss (smoothing: 0.1)
12: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
12: Building LabelSmoothingLoss (smoothing: 0.1)
6: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
6: Building LabelSmoothingLoss (smoothing: 0.1)
2: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
2: Building LabelSmoothingLoss (smoothing: 0.1)
14: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
14: Building LabelSmoothingLoss (smoothing: 0.1)
7: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
7: Building LabelSmoothingLoss (smoothing: 0.1)
15: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
15: Building LabelSmoothingLoss (smoothing: 0.1)
4: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
4: Building LabelSmoothingLoss (smoothing: 0.1)
3: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
3: Building LabelSmoothingLoss (smoothing: 0.1)
11: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
11: Building LabelSmoothingLoss (smoothing: 0.1)
1: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
1: Building LabelSmoothingLoss (smoothing: 0.1)
5: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
5: Building LabelSmoothingLoss (smoothing: 0.1)
8: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
13: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
8: Building LabelSmoothingLoss (smoothing: 0.1)
13: Building LabelSmoothingLoss (smoothing: 0.1)
0: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
0: Building LabelSmoothingLoss (smoothing: 0.1)
9: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
9: Building LabelSmoothingLoss (smoothing: 0.1)
:::MLPv0.5.0 gnmt 1541782244.027651548 (train.py:208) model_hp_loss_fn: "Cross Entropy with label smoothing"
11: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
5: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
12: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
7: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
15: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
4: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
3: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
6: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
1: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
2: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
10: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
11: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
9: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
5: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
8: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
12: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
14: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
7: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
15: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
4: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
3: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
6: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
1: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
2: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
10: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
8: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
9: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
14: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
13: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
:::MLPv0.5.0 gnmt 1541782244.028199673 (train.py:210) model_hp_loss_smoothing: 0.1
13: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
5: Number of parameters: 160671297
12: Number of parameters: 160671297
11: Number of parameters: 160671297
15: Number of parameters: 160671297
4: Number of parameters: 160671297
7: Number of parameters: 160671297
2: Number of parameters: 160671297
6: Number of parameters: 160671297
1: Number of parameters: 160671297
10: Number of parameters: 160671297
3: Number of parameters: 160671297
8: Number of parameters: 160671297
9: Number of parameters: 160671297
0: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
14: Number of parameters: 160671297
0: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
13: Number of parameters: 160671297
0: Number of parameters: 160671297
:::MLPv0.5.0 gnmt 1541782244.029189825 (train.py:370) input_batch_size: 1024
:::MLPv0.5.0 gnmt 1541782244.029565096 (train.py:372) input_size: 3497984
:::MLPv0.5.0 gnmt 1541782244.058632612 (train.py:386) eval_size: 3003
:::MLPv0.5.0 gnmt 1541782244.059684038 (seq2seq/inference/beam_search.py:43) eval_hp_beam_size: 5
:::MLPv0.5.0 gnmt 1541782244.060184002 (seq2seq/inference/beam_search.py:45) eval_hp_max_sequence_length: 150
:::MLPv0.5.0 gnmt 1541782244.060617447 (seq2seq/inference/beam_search.py:47) eval_hp_length_normalization_constant: 5.0
:::MLPv0.5.0 gnmt 1541782244.062150240 (seq2seq/inference/beam_search.py:49) eval_hp_length_normalization_factor: 0.6
3: Saving state of the tokenizer
12: Saving state of the tokenizer
9: Saving state of the tokenizer
2: Saving state of the tokenizer
6: Saving state of the tokenizer
4: Saving state of the tokenizer
7: Saving state of the tokenizer
11: Saving state of the tokenizer
15: Saving state of the tokenizer
5: Saving state of the tokenizer
1: Saving state of the tokenizer
13: Saving state of the tokenizer
14: Saving state of the tokenizer
10: Saving state of the tokenizer
8: Saving state of the tokenizer
:::MLPv0.5.0 gnmt 1541782244.062556982 (seq2seq/inference/beam_search.py:51) eval_hp_coverage_penalty_factor: 0.1
0: Saving state of the tokenizer
15: Initializing fp16 optimizer
15: Initializing fp32 clone weights
2: Initializing fp16 optimizer
2: Initializing fp32 clone weights
12: Initializing fp16 optimizer
12: Initializing fp32 clone weights
4: Initializing fp16 optimizer
4: Initializing fp32 clone weights
6: Initializing fp16 optimizer
6: Initializing fp32 clone weights
5: Initializing fp16 optimizer
5: Initializing fp32 clone weights
11: Initializing fp16 optimizer
11: Initializing fp32 clone weights
3: Initializing fp16 optimizer
3: Initializing fp32 clone weights
7: Initializing fp16 optimizer
7: Initializing fp32 clone weights
9: Initializing fp16 optimizer
9: Initializing fp32 clone weights
14: Initializing fp16 optimizer
14: Initializing fp32 clone weights
1: Initializing fp16 optimizer
1: Initializing fp32 clone weights
10: Initializing fp16 optimizer
10: Initializing fp32 clone weights
13: Initializing fp16 optimizer
13: Initializing fp32 clone weights
8: Initializing fp16 optimizer
8: Initializing fp32 clone weights
0: Initializing fp16 optimizer
0: Initializing fp32 clone weights
:::MLPv0.5.0 gnmt 1541782248.054624796 (seq2seq/train/trainer.py:99) opt_name: "adam"
:::MLPv0.5.0 gnmt 1541782248.055109024 (seq2seq/train/trainer.py:101) opt_learning_rate: 0.00125
:::MLPv0.5.0 gnmt 1541782248.055512428 (seq2seq/train/trainer.py:103) opt_hp_Adam_beta1: 0.9
:::MLPv0.5.0 gnmt 1541782248.055900097 (seq2seq/train/trainer.py:105) opt_hp_Adam_beta2: 0.999
8: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)2: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)12: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)15: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
6: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
5: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)



:::MLPv0.5.0 gnmt 1541782248.056283236 (seq2seq/train/trainer.py:107) opt_hp_Adam_epsilon: 1e-08
3: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)4: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
11: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)7: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)

14: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
13: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)

1: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
10: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
0: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
9: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
6: Starting epoch 0
2: Starting epoch 0
8: Starting epoch 0
10: Starting epoch 0
12: Starting epoch 0
14: Starting epoch 0
11: Starting epoch 0
5: Starting epoch 0
13: Starting epoch 0
7: Starting epoch 0
4: Starting epoch 0
15: Starting epoch 0
3: Starting epoch 0
1: Starting epoch 0
9: Starting epoch 0
:::MLPv0.5.0 gnmt 1541782248.056946516 (train.py:438) train_loop
0: Starting epoch 0
:::MLPv0.5.0 gnmt 1541782248.057391167 (train.py:443) train_epoch: 0
1: Sampler for epoch 0 uses seed 1973501569
2: Sampler for epoch 0 uses seed 1973501569
5: Sampler for epoch 0 uses seed 1973501569
11: Sampler for epoch 0 uses seed 1973501569
6: Sampler for epoch 0 uses seed 1973501569
12: Sampler for epoch 0 uses seed 1973501569
8: Sampler for epoch 0 uses seed 1973501569
13: Sampler for epoch 0 uses seed 1973501569
14: Sampler for epoch 0 uses seed 1973501569
10: Sampler for epoch 0 uses seed 1973501569
7: Sampler for epoch 0 uses seed 1973501569
3: Sampler for epoch 0 uses seed 1973501569
15: Sampler for epoch 0 uses seed 1973501569
9: Sampler for epoch 0 uses seed 1973501569
4: Sampler for epoch 0 uses seed 1973501569
:::MLPv0.5.0 gnmt 1541782251.387899876 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 0 uses seed 1973501569
:::MLPv0.5.0 gnmt 1541782251.545751572 (seq2seq/data/sampler.py:66) input_shard: 81920
13: Gradient norm: inf
12: Gradient norm: inf
11: Gradient norm: inf
13: Skipped batch, new scale: 4096.0
12: Skipped batch, new scale: 4096.0
10: Gradient norm: inf
11: Skipped batch, new scale: 4096.0
14: Gradient norm: inf
9: Gradient norm: inf
10: Skipped batch, new scale: 4096.0
14: Skipped batch, new scale: 4096.0
8: Gradient norm: inf
7: Gradient norm: inf
9: Skipped batch, new scale: 4096.0
2: Gradient norm: inf
8: Skipped batch, new scale: 4096.0
6: Gradient norm: inf
3: Gradient norm: inf
7: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
4: Gradient norm: inf
6: Skipped batch, new scale: 4096.0
13: TRAIN [0][0/3416]	Time 3.525 (0.000)	Data 3.33743 (0.00000)	Tok/s 980 (0)	Loss/tok 10.3811 (0.0000)	Learning Rate [1.2499999999999968e-05]
5: Gradient norm: inf
12: TRAIN [0][0/3416]	Time 3.526 (0.000)	Data 3.30034 (0.00000)	Tok/s 980 (0)	Loss/tok 10.3844 (0.0000)	Learning Rate [1.2499999999999968e-05]
3: Skipped batch, new scale: 4096.0
4: Skipped batch, new scale: 4096.0
11: TRAIN [0][0/3416]	Time 3.525 (0.000)	Data 3.17830 (0.00000)	Tok/s 980 (0)	Loss/tok 10.3851 (0.0000)	Learning Rate [1.2499999999999968e-05]
10: TRAIN [0][0/3416]	Time 3.526 (0.000)	Data 3.29118 (0.00000)	Tok/s 980 (0)	Loss/tok 10.3832 (0.0000)	Learning Rate [1.2499999999999968e-05]
5: Skipped batch, new scale: 4096.0
14: TRAIN [0][0/3416]	Time 3.526 (0.000)	Data 3.06969 (0.00000)	Tok/s 996 (0)	Loss/tok 10.3831 (0.0000)	Learning Rate [1.2499999999999968e-05]
8: TRAIN [0][0/3416]	Time 3.526 (0.000)	Data 2.86819 (0.00000)	Tok/s 980 (0)	Loss/tok 10.3833 (0.0000)	Learning Rate [1.2499999999999968e-05]
6: TRAIN [0][0/3416]	Time 3.526 (0.000)	Data 2.99165 (0.00000)	Tok/s 980 (0)	Loss/tok 10.3841 (0.0000)	Learning Rate [1.2499999999999968e-05]
0: Gradient norm: inf
2: TRAIN [0][0/3416]	Time 3.526 (0.000)	Data 3.06165 (0.00000)	Tok/s 980 (0)	Loss/tok 10.3824 (0.0000)	Learning Rate [1.2499999999999968e-05]
7: TRAIN [0][0/3416]	Time 3.525 (0.000)	Data 3.41929 (0.00000)	Tok/s 980 (0)	Loss/tok 10.3825 (0.0000)	Learning Rate [1.2499999999999968e-05]
4: TRAIN [0][0/3416]	Time 3.526 (0.000)	Data 2.61083 (0.00000)	Tok/s 980 (0)	Loss/tok 10.3825 (0.0000)	Learning Rate [1.2499999999999968e-05]
3: TRAIN [0][0/3416]	Time 3.526 (0.000)	Data 2.90066 (0.00000)	Tok/s 980 (0)	Loss/tok 10.3826 (0.0000)	Learning Rate [1.2499999999999968e-05]
0: Skipped batch, new scale: 4096.0
5: TRAIN [0][0/3416]	Time 3.526 (0.000)	Data 3.46137 (0.00000)	Tok/s 980 (0)	Loss/tok 10.3832 (0.0000)	Learning Rate [1.2499999999999968e-05]
0: TRAIN [0][0/3416]	Time 3.526 (0.000)	Data 3.10872 (0.00000)	Tok/s 980 (0)	Loss/tok 10.3840 (0.0000)	Learning Rate [1.2499999999999968e-05]
15: Gradient norm: inf
15: Skipped batch, new scale: 4096.0
15: TRAIN [0][0/3416]	Time 3.527 (0.000)	Data 1.59788 (0.00000)	Tok/s 998 (0)	Loss/tok 10.3827 (0.0000)	Learning Rate [1.2499999999999968e-05]
9: TRAIN [0][0/3416]	Time 3.525 (0.000)	Data 3.08975 (0.00000)	Tok/s 980 (0)	Loss/tok 10.3825 (0.0000)	Learning Rate [1.2499999999999968e-05]
1: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
1: TRAIN [0][0/3416]	Time 3.539 (0.000)	Data 3.12535 (0.00000)	Tok/s 977 (0)	Loss/tok 10.3825 (0.0000)	Learning Rate [1.2499999999999968e-05]
0: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
15: Skipped batch, new scale: 2048.0
14: Gradient norm: inf
2: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
13: Gradient norm: inf
3: Gradient norm: inf
12: Gradient norm: inf
4: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
13: Skipped batch, new scale: 2048.0
12: Skipped batch, new scale: 2048.0
11: Gradient norm: inf
4: Skipped batch, new scale: 2048.0
5: Gradient norm: inf
10: Gradient norm: inf
11: Skipped batch, new scale: 2048.0
6: Gradient norm: inf
5: Skipped batch, new scale: 2048.0
9: Gradient norm: inf
10: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
6: Skipped batch, new scale: 2048.0
8: Gradient norm: inf
7: Gradient norm: inf
8: Skipped batch, new scale: 2048.0
7: Skipped batch, new scale: 2048.0
14: Gradient norm: inf
15: Gradient norm: inf
13: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
0: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
2: Gradient norm: inf
11: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
10: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
5: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
2: TRAIN [0][10/3416]	Time 0.076 (0.067)	Data 0.00105 (0.00163)	Tok/s 67017 (50198)	Loss/tok 10.3669 (10.3738)	Learning Rate [1.4686219436744084e-05]
3: TRAIN [0][10/3416]	Time 0.076 (0.067)	Data 0.00098 (0.00119)	Tok/s 67059 (50284)	Loss/tok 10.3655 (10.3737)	Learning Rate [1.4686219436744084e-05]
1: TRAIN [0][10/3416]	Time 0.077 (0.066)	Data 0.00086 (0.00076)	Tok/s 66895 (50451)	Loss/tok 10.3667 (10.3740)	Learning Rate [1.4686219436744084e-05]
4: TRAIN [0][10/3416]	Time 0.076 (0.067)	Data 0.00086 (0.00203)	Tok/s 67038 (50339)	Loss/tok 10.3658 (10.3737)	Learning Rate [1.4686219436744084e-05]
15: TRAIN [0][10/3416]	Time 0.076 (0.067)	Data 0.00075 (0.00127)	Tok/s 67791 (51028)	Loss/tok 10.3660 (10.3740)	Learning Rate [1.4686219436744084e-05]
0: TRAIN [0][10/3416]	Time 0.077 (0.067)	Data 0.00083 (0.00076)	Tok/s 66903 (50180)	Loss/tok 10.3682 (10.3738)	Learning Rate [1.4686219436744084e-05]
14: TRAIN [0][10/3416]	Time 0.076 (0.067)	Data 0.00092 (0.00086)	Tok/s 67841 (51014)	Loss/tok 10.3660 (10.3739)	Learning Rate [1.4686219436744084e-05]
5: TRAIN [0][10/3416]	Time 0.076 (0.067)	Data 0.00093 (0.00079)	Tok/s 67015 (50439)	Loss/tok 10.3684 (10.3739)	Learning Rate [1.4686219436744084e-05]
13: TRAIN [0][10/3416]	Time 0.076 (0.067)	Data 0.00093 (0.00116)	Tok/s 67771 (51059)	Loss/tok 10.3652 (10.3735)	Learning Rate [1.4686219436744084e-05]
11: TRAIN [0][10/3416]	Time 0.076 (0.067)	Data 0.00102 (0.00127)	Tok/s 67792 (50814)	Loss/tok 10.3670 (10.3736)	Learning Rate [1.4686219436744084e-05]
12: TRAIN [0][10/3416]	Time 0.076 (0.067)	Data 0.00096 (0.00124)	Tok/s 67796 (51167)	Loss/tok 10.3671 (10.3741)	Learning Rate [1.4686219436744084e-05]
7: TRAIN [0][10/3416]	Time 0.077 (0.067)	Data 0.00090 (0.00083)	Tok/s 67734 (50775)	Loss/tok 10.3681 (10.3739)	Learning Rate [1.4686219436744084e-05]
10: TRAIN [0][10/3416]	Time 0.077 (0.067)	Data 0.00094 (0.00085)	Tok/s 67636 (50846)	Loss/tok 10.3676 (10.3740)	Learning Rate [1.4686219436744084e-05]
9: TRAIN [0][10/3416]	Time 0.075 (0.066)	Data 0.00082 (0.00084)	Tok/s 68959 (51062)	Loss/tok 10.3675 (10.3746)	Learning Rate [1.4686219436744084e-05]
8: TRAIN [0][10/3416]	Time 0.077 (0.067)	Data 0.00097 (0.00115)	Tok/s 67709 (50699)	Loss/tok 10.3659 (10.3736)	Learning Rate [1.4686219436744084e-05]
6: TRAIN [0][10/3416]	Time 0.076 (0.067)	Data 0.00103 (0.00086)	Tok/s 67230 (50546)	Loss/tok 10.3670 (10.3740)	Learning Rate [1.4686219436744084e-05]
7: TRAIN [0][20/3416]	Time 0.068 (0.062)	Data 0.00083 (0.00086)	Tok/s 56846 (51735)	Loss/tok 10.3208 (10.3589)	Learning Rate [1.848885485210255e-05]
8: TRAIN [0][20/3416]	Time 0.067 (0.062)	Data 0.00093 (0.00107)	Tok/s 56894 (51762)	Loss/tok 10.3182 (10.3588)	Learning Rate [1.848885485210255e-05]
5: TRAIN [0][20/3416]	Time 0.068 (0.062)	Data 0.00086 (0.00086)	Tok/s 56816 (51553)	Loss/tok 10.3235 (10.3589)	Learning Rate [1.848885485210255e-05]
6: TRAIN [0][20/3416]	Time 0.068 (0.062)	Data 0.00093 (0.00091)	Tok/s 56772 (51614)	Loss/tok 10.3202 (10.3589)	Learning Rate [1.848885485210255e-05]
9: TRAIN [0][20/3416]	Time 0.068 (0.062)	Data 0.00082 (0.00088)	Tok/s 56830 (51994)	Loss/tok 10.3223 (10.3592)	Learning Rate [1.848885485210255e-05]
4: TRAIN [0][20/3416]	Time 0.068 (0.062)	Data 0.00084 (0.00147)	Tok/s 55879 (51431)	Loss/tok 10.3172 (10.3586)	Learning Rate [1.848885485210255e-05]
10: TRAIN [0][20/3416]	Time 0.068 (0.062)	Data 0.00086 (0.00094)	Tok/s 56851 (51897)	Loss/tok 10.3183 (10.3591)	Learning Rate [1.848885485210255e-05]
3: TRAIN [0][20/3416]	Time 0.068 (0.062)	Data 0.00106 (0.00112)	Tok/s 55903 (51295)	Loss/tok 10.3196 (10.3590)	Learning Rate [1.848885485210255e-05]
2: TRAIN [0][20/3416]	Time 0.067 (0.062)	Data 0.00097 (0.00132)	Tok/s 55957 (51241)	Loss/tok 10.3200 (10.3590)	Learning Rate [1.848885485210255e-05]
11: TRAIN [0][20/3416]	Time 0.066 (0.062)	Data 0.00131 (0.00132)	Tok/s 58251 (51932)	Loss/tok 10.3188 (10.3587)	Learning Rate [1.848885485210255e-05]
12: TRAIN [0][20/3416]	Time 0.068 (0.062)	Data 0.00104 (0.00112)	Tok/s 56783 (52110)	Loss/tok 10.3208 (10.3591)	Learning Rate [1.848885485210255e-05]
0: TRAIN [0][20/3416]	Time 0.068 (0.062)	Data 0.00080 (0.00084)	Tok/s 55905 (51160)	Loss/tok 10.3207 (10.3585)	Learning Rate [1.848885485210255e-05]
13: TRAIN [0][20/3416]	Time 0.068 (0.062)	Data 0.00083 (0.00113)	Tok/s 56789 (52072)	Loss/tok 10.3247 (10.3590)	Learning Rate [1.848885485210255e-05]
14: TRAIN [0][20/3416]	Time 0.068 (0.062)	Data 0.00092 (0.00091)	Tok/s 56879 (52197)	Loss/tok 10.3202 (10.3589)	Learning Rate [1.848885485210255e-05]
15: TRAIN [0][20/3416]	Time 0.068 (0.062)	Data 0.00105 (0.00118)	Tok/s 56858 (52342)	Loss/tok 10.3223 (10.3596)	Learning Rate [1.848885485210255e-05]
1: TRAIN [0][20/3416]	Time 0.070 (0.062)	Data 0.00080 (0.00084)	Tok/s 53671 (51204)	Loss/tok 10.3234 (10.3595)	Learning Rate [1.848885485210255e-05]
3: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00104 (0.00107)	Tok/s 56422 (52416)	Loss/tok 10.1753 (10.3260)	Learning Rate [2.3276089208285794e-05]
2: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00115 (0.00121)	Tok/s 56454 (52337)	Loss/tok 10.1769 (10.3268)	Learning Rate [2.3276089208285794e-05]
1: TRAIN [0][30/3416]	Time 0.067 (0.060)	Data 0.00091 (0.00086)	Tok/s 56296 (52322)	Loss/tok 10.1758 (10.3265)	Learning Rate [2.3276089208285794e-05]
5: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00088 (0.00089)	Tok/s 56367 (52800)	Loss/tok 10.1745 (10.3251)	Learning Rate [2.3276089208285794e-05]
0: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00090 (0.00085)	Tok/s 56081 (52078)	Loss/tok 10.1832 (10.3259)	Learning Rate [2.3276089208285794e-05]
4: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00087 (0.00133)	Tok/s 56385 (52588)	Loss/tok 10.1738 (10.3256)	Learning Rate [2.3276089208285794e-05]
14: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00107 (0.00095)	Tok/s 56062 (53570)	Loss/tok 10.1783 (10.3257)	Learning Rate [2.3276089208285794e-05]
15: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00103 (0.00109)	Tok/s 56087 (53729)	Loss/tok 10.1697 (10.3259)	Learning Rate [2.3276089208285794e-05]
6: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00093 (0.00091)	Tok/s 56342 (52860)	Loss/tok 10.1739 (10.3262)	Learning Rate [2.3276089208285794e-05]
12: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00097 (0.00107)	Tok/s 55992 (53445)	Loss/tok 10.1696 (10.3260)	Learning Rate [2.3276089208285794e-05]
8: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00102 (0.00102)	Tok/s 56271 (53064)	Loss/tok 10.1746 (10.3245)	Learning Rate [2.3276089208285794e-05]
11: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00097 (0.00120)	Tok/s 55983 (53243)	Loss/tok 10.1759 (10.3254)	Learning Rate [2.3276089208285794e-05]
13: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00094 (0.00107)	Tok/s 56000 (53433)	Loss/tok 10.1717 (10.3249)	Learning Rate [2.3276089208285794e-05]
10: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00099 (0.00096)	Tok/s 55955 (53210)	Loss/tok 10.1766 (10.3251)	Learning Rate [2.3276089208285794e-05]
9: TRAIN [0][30/3416]	Time 0.067 (0.060)	Data 0.00099 (0.00089)	Tok/s 56007 (53243)	Loss/tok 10.1816 (10.3256)	Learning Rate [2.3276089208285794e-05]
7: TRAIN [0][30/3416]	Time 0.067 (0.061)	Data 0.00087 (0.00087)	Tok/s 56145 (52962)	Loss/tok 10.1801 (10.3258)	Learning Rate [2.3276089208285794e-05]
6: Gradient norm: inf
5: Gradient norm: inf
1: Gradient norm: inf
4: Gradient norm: inf
6: Skipped batch, new scale: 512.0
5: Skipped batch, new scale: 512.0
2: Gradient norm: inf
1: Skipped batch, new scale: 512.0
7: Gradient norm: inf
4: Skipped batch, new scale: 512.0
15: Gradient norm: inf
3: Gradient norm: inf
2: Skipped batch, new scale: 512.0
7: Skipped batch, new scale: 512.0
15: Skipped batch, new scale: 512.0
14: Gradient norm: inf
3: Skipped batch, new scale: 512.0
10: Gradient norm: inf
9: Gradient norm: inf
0: Gradient norm: inf
12: Gradient norm: inf
14: Skipped batch, new scale: 512.0
13: Gradient norm: inf
10: Skipped batch, new scale: 512.0
9: Skipped batch, new scale: 512.0
0: Skipped batch, new scale: 512.0
12: Skipped batch, new scale: 512.0
11: Gradient norm: inf
8: Gradient norm: inf
13: Skipped batch, new scale: 512.0
11: Skipped batch, new scale: 512.0
8: Skipped batch, new scale: 512.0
15: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00100 (0.00105)	Tok/s 42862 (53794)	Loss/tok 9.2012 (10.1892)	Learning Rate [2.8635845659597103e-05]
0: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00094 (0.00089)	Tok/s 42930 (52298)	Loss/tok 9.2277 (10.1917)	Learning Rate [2.8635845659597103e-05]
3: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00098 (0.00105)	Tok/s 43054 (52543)	Loss/tok 9.1692 (10.1913)	Learning Rate [2.8635845659597103e-05]
14: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00102 (0.00096)	Tok/s 42718 (53654)	Loss/tok 9.2530 (10.1893)	Learning Rate [2.8635845659597103e-05]
2: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00095 (0.00117)	Tok/s 42906 (52472)	Loss/tok 9.1854 (10.1885)	Learning Rate [2.8635845659597103e-05]
13: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00097 (0.00106)	Tok/s 42683 (53542)	Loss/tok 9.2326 (10.1889)	Learning Rate [2.8635845659597103e-05]
1: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00096 (0.00088)	Tok/s 42859 (52458)	Loss/tok 9.1772 (10.1933)	Learning Rate [2.8635845659597103e-05]
12: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00097 (0.00106)	Tok/s 42662 (53533)	Loss/tok 9.2631 (10.1898)	Learning Rate [2.8635845659597103e-05]
10: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00097 (0.00097)	Tok/s 42803 (53340)	Loss/tok 9.2005 (10.1902)	Learning Rate [2.8635845659597103e-05]
4: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00104 (0.00123)	Tok/s 42922 (52738)	Loss/tok 9.1585 (10.1877)	Learning Rate [2.8635845659597103e-05]
5: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00092 (0.00090)	Tok/s 42862 (52897)	Loss/tok 9.2726 (10.1876)	Learning Rate [2.8635845659597103e-05]
11: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00096 (0.00115)	Tok/s 42640 (53369)	Loss/tok 9.1515 (10.1882)	Learning Rate [2.8635845659597103e-05]
7: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00089 (0.00087)	Tok/s 42728 (53080)	Loss/tok 9.2630 (10.1878)	Learning Rate [2.8635845659597103e-05]
9: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00099 (0.00090)	Tok/s 42676 (53317)	Loss/tok 9.2143 (10.1864)	Learning Rate [2.8635845659597103e-05]
6: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00101 (0.00092)	Tok/s 42809 (52944)	Loss/tok 9.1750 (10.1878)	Learning Rate [2.8635845659597103e-05]
8: TRAIN [0][40/3416]	Time 0.048 (0.059)	Data 0.00097 (0.00101)	Tok/s 42689 (53171)	Loss/tok 9.2263 (10.1888)	Learning Rate [2.8635845659597103e-05]
2: Gradient norm: inf
1: Gradient norm: inf
2: Skipped batch, new scale: 256.0
1: Skipped batch, new scale: 256.0
0: Gradient norm: inf
3: Gradient norm: inf
15: Gradient norm: inf
4: Gradient norm: inf
0: Skipped batch, new scale: 256.0
3: Skipped batch, new scale: 256.0
15: Skipped batch, new scale: 256.0
4: Skipped batch, new scale: 256.0
14: Gradient norm: inf
5: Gradient norm: inf
14: Skipped batch, new scale: 256.0
13: Gradient norm: inf
6: Gradient norm: inf
5: Skipped batch, new scale: 256.0
12: Gradient norm: inf
11: Gradient norm: inf
13: Skipped batch, new scale: 256.0
7: Gradient norm: inf
6: Skipped batch, new scale: 256.0
12: Skipped batch, new scale: 256.0
11: Skipped batch, new scale: 256.0
10: Gradient norm: inf
7: Skipped batch, new scale: 256.0
8: Gradient norm: inf
9: Gradient norm: inf
10: Skipped batch, new scale: 256.0
8: Skipped batch, new scale: 256.0
9: Skipped batch, new scale: 256.0
7: Gradient norm: inf
7: Skipped batch, new scale: 128.0
6: Gradient norm: inf
8: Gradient norm: inf
6: Skipped batch, new scale: 128.0
8: Skipped batch, new scale: 128.0
5: Gradient norm: inf
9: Gradient norm: inf
9: Skipped batch, new scale: 128.0
5: Skipped batch, new scale: 128.0
4: Gradient norm: inf
11: Gradient norm: inf
10: Gradient norm: inf
4: Skipped batch, new scale: 128.0
2: Gradient norm: inf
11: Skipped batch, new scale: 128.0
10: Skipped batch, new scale: 128.0
12: Gradient norm: inf
2: Skipped batch, new scale: 128.0
1: Gradient norm: inf
13: Gradient norm: inf
12: Skipped batch, new scale: 128.0
0: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 128.0
13: Skipped batch, new scale: 128.0
15: Gradient norm: inf
14: Gradient norm: inf
0: Skipped batch, new scale: 128.0
3: Skipped batch, new scale: 128.0
15: Skipped batch, new scale: 128.0
14: Skipped batch, new scale: 128.0
5: Gradient norm: inf
6: Gradient norm: inf
4: Gradient norm: inf
5: Skipped batch, new scale: 64.0
6: Skipped batch, new scale: 64.0
7: Gradient norm: inf
3: Gradient norm: inf
4: Skipped batch, new scale: 64.0
7: Skipped batch, new scale: 64.0
3: Skipped batch, new scale: 64.0
8: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
9: Gradient norm: inf
8: Skipped batch, new scale: 64.0
2: Skipped batch, new scale: 64.0
1: Skipped batch, new scale: 64.0
0: Gradient norm: inf
9: Skipped batch, new scale: 64.0
15: Gradient norm: inf
0: Skipped batch, new scale: 64.0
11: Gradient norm: inf
15: Skipped batch, new scale: 64.0
14: Gradient norm: inf
11: Skipped batch, new scale: 64.0
13: Gradient norm: inf
14: Skipped batch, new scale: 64.0
12: Gradient norm: inf
10: Gradient norm: inf
13: Skipped batch, new scale: 64.0
12: Skipped batch, new scale: 64.0
10: Skipped batch, new scale: 64.0
13: TRAIN [0][50/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00104)	Tok/s 33441 (52548)	Loss/tok 9.4822 (10.1549)	Learning Rate [3.3644185049086384e-05]
14: TRAIN [0][50/3416]	Time 0.052 (0.058)	Data 0.00113 (0.00096)	Tok/s 33662 (52669)	Loss/tok 9.4530 (10.1529)	Learning Rate [3.3644185049086384e-05]
11: TRAIN [0][50/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00111)	Tok/s 33459 (52343)	Loss/tok 9.3767 (10.1464)	Learning Rate [3.3644185049086384e-05]
15: TRAIN [0][50/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00104)	Tok/s 34725 (52827)	Loss/tok 9.4457 (10.1515)	Learning Rate [3.3644185049086384e-05]
0: TRAIN [0][50/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00089)	Tok/s 33468 (51417)	Loss/tok 9.4980 (10.1466)	Learning Rate [3.3644185049086384e-05]
12: TRAIN [0][50/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00106)	Tok/s 33595 (52494)	Loss/tok 9.4370 (10.1515)	Learning Rate [3.3644185049086384e-05]
2: TRAIN [0][50/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00116)	Tok/s 33619 (51589)	Loss/tok 9.5222 (10.1456)	Learning Rate [3.3644185049086384e-05]
8: TRAIN [0][50/3416]	Time 0.052 (0.058)	Data 0.00108 (0.00101)	Tok/s 33541 (52188)	Loss/tok 9.5780 (10.1574)	Learning Rate [3.3644185049086384e-05]
10: TRAIN [0][50/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00099)	Tok/s 33429 (52318)	Loss/tok 9.5155 (10.1538)	Learning Rate [3.3644185049086384e-05]
1: TRAIN [0][50/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00089)	Tok/s 33499 (51544)	Loss/tok 9.4309 (10.1552)	Learning Rate [3.3644185049086384e-05]
9: TRAIN [0][50/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00091)	Tok/s 33501 (52299)	Loss/tok 9.5403 (10.1493)	Learning Rate [3.3644185049086384e-05]
5: TRAIN [0][50/3416]	Time 0.052 (0.058)	Data 0.00106 (0.00092)	Tok/s 33553 (51960)	Loss/tok 9.5021 (10.1565)	Learning Rate [3.3644185049086384e-05]
6: TRAIN [0][50/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00093)	Tok/s 33542 (51998)	Loss/tok 9.4192 (10.1501)	Learning Rate [3.3644185049086384e-05]
7: TRAIN [0][50/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00088)	Tok/s 33471 (52107)	Loss/tok 9.5199 (10.1490)	Learning Rate [3.3644185049086384e-05]
3: TRAIN [0][50/3416]	Time 0.049 (0.058)	Data 0.00132 (0.00105)	Tok/s 35011 (51670)	Loss/tok 9.4591 (10.1528)	Learning Rate [3.3644185049086384e-05]
4: TRAIN [0][50/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00118)	Tok/s 33518 (51831)	Loss/tok 9.4853 (10.1553)	Learning Rate [3.3644185049086384e-05]
12: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00105)	Tok/s 52542 (53078)	Loss/tok 8.7110 (10.0065)	Learning Rate [4.235551951740024e-05]
11: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00109)	Tok/s 52540 (52935)	Loss/tok 8.5798 (9.9988)	Learning Rate [4.235551951740024e-05]
14: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00108 (0.00097)	Tok/s 52521 (53248)	Loss/tok 8.6577 (10.0089)	Learning Rate [4.235551951740024e-05]
10: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00099)	Tok/s 52536 (52901)	Loss/tok 8.5724 (10.0151)	Learning Rate [4.235551951740024e-05]
13: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00102)	Tok/s 52413 (53130)	Loss/tok 8.7132 (10.0167)	Learning Rate [4.235551951740024e-05]
8: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00100)	Tok/s 52531 (52731)	Loss/tok 8.5332 (10.0089)	Learning Rate [4.235551951740024e-05]
7: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00088)	Tok/s 52277 (52662)	Loss/tok 8.6036 (10.0093)	Learning Rate [4.235551951740024e-05]
0: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00089)	Tok/s 51041 (52022)	Loss/tok 8.6812 (10.0053)	Learning Rate [4.235551951740024e-05]
9: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00095)	Tok/s 52543 (52857)	Loss/tok 8.5566 (10.0101)	Learning Rate [4.235551951740024e-05]
1: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00090)	Tok/s 51119 (52143)	Loss/tok 8.5525 (10.0207)	Learning Rate [4.235551951740024e-05]
2: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00112)	Tok/s 51105 (52187)	Loss/tok 8.5431 (9.9980)	Learning Rate [4.235551951740024e-05]
5: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00093)	Tok/s 51212 (52498)	Loss/tok 8.5669 (10.0172)	Learning Rate [4.235551951740024e-05]
6: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00093)	Tok/s 51221 (52547)	Loss/tok 8.6231 (10.0048)	Learning Rate [4.235551951740024e-05]
3: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00103)	Tok/s 51128 (52256)	Loss/tok 8.5244 (10.0114)	Learning Rate [4.235551951740024e-05]
4: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00114)	Tok/s 51126 (52391)	Loss/tok 8.5594 (10.0179)	Learning Rate [4.235551951740024e-05]
15: TRAIN [0][60/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00102)	Tok/s 52575 (53383)	Loss/tok 8.5751 (10.0103)	Learning Rate [4.235551951740024e-05]
5: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00094)	Tok/s 86201 (52793)	Loss/tok 8.3299 (9.7870)	Learning Rate [5.3322439850199e-05]
2: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00110)	Tok/s 85338 (52505)	Loss/tok 8.2712 (9.7682)	Learning Rate [5.3322439850199e-05]
6: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00094)	Tok/s 86391 (52863)	Loss/tok 8.3614 (9.7777)	Learning Rate [5.3322439850199e-05]
7: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00089)	Tok/s 87161 (52977)	Loss/tok 8.2810 (9.7849)	Learning Rate [5.3322439850199e-05]
1: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00090)	Tok/s 85292 (52465)	Loss/tok 8.3679 (9.7926)	Learning Rate [5.3322439850199e-05]
8: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00100)	Tok/s 87165 (53034)	Loss/tok 8.3134 (9.7775)	Learning Rate [5.3322439850199e-05]
12: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00105)	Tok/s 88898 (53398)	Loss/tok 8.3245 (9.7816)	Learning Rate [5.3322439850199e-05]
11: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00107)	Tok/s 88269 (53254)	Loss/tok 8.3843 (9.7744)	Learning Rate [5.3322439850199e-05]
0: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00089)	Tok/s 85277 (52359)	Loss/tok 8.3186 (9.7762)	Learning Rate [5.3322439850199e-05]
10: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00100)	Tok/s 88148 (53221)	Loss/tok 8.3441 (9.7874)	Learning Rate [5.3322439850199e-05]
15: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00101)	Tok/s 90475 (53725)	Loss/tok 8.4351 (9.7816)	Learning Rate [5.3322439850199e-05]
14: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00098)	Tok/s 89792 (53589)	Loss/tok 8.4313 (9.7809)	Learning Rate [5.3322439850199e-05]
9: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00095)	Tok/s 87168 (53144)	Loss/tok 8.3624 (9.7835)	Learning Rate [5.3322439850199e-05]
4: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00110)	Tok/s 86086 (52693)	Loss/tok 8.3850 (9.7908)	Learning Rate [5.3322439850199e-05]
3: TRAIN [0][70/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00102)	Tok/s 85072 (52563)	Loss/tok 8.3067 (9.7828)	Learning Rate [5.3322439850199e-05]
13: TRAIN [0][70/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00101)	Tok/s 88063 (53436)	Loss/tok 8.2621 (9.7851)	Learning Rate [5.3322439850199e-05]
15: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00099)	Tok/s 49597 (53326)	Loss/tok 8.0425 (9.5898)	Learning Rate [6.712897454628148e-05]
14: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00099)	Tok/s 49641 (53207)	Loss/tok 8.0633 (9.5900)	Learning Rate [6.712897454628148e-05]
0: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00089)	Tok/s 48276 (51955)	Loss/tok 8.0673 (9.5834)	Learning Rate [6.712897454628148e-05]
13: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00109 (0.00101)	Tok/s 49473 (53071)	Loss/tok 8.0412 (9.5932)	Learning Rate [6.712897454628148e-05]
12: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00104)	Tok/s 49379 (53001)	Loss/tok 8.0473 (9.5906)	Learning Rate [6.712897454628148e-05]
1: TRAIN [0][80/3416]	Time 0.052 (0.057)	Data 0.00104 (0.00090)	Tok/s 48330 (52053)	Loss/tok 7.9530 (9.5991)	Learning Rate [6.712897454628148e-05]
2: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00108)	Tok/s 48149 (52122)	Loss/tok 8.0938 (9.5725)	Learning Rate [6.712897454628148e-05]
11: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00105)	Tok/s 49282 (52873)	Loss/tok 7.9975 (9.5801)	Learning Rate [6.712897454628148e-05]
10: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00100)	Tok/s 49165 (52834)	Loss/tok 8.0305 (9.5891)	Learning Rate [6.712897454628148e-05]
3: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00101)	Tok/s 47999 (52195)	Loss/tok 8.0227 (9.5900)	Learning Rate [6.712897454628148e-05]
4: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00108)	Tok/s 47876 (52307)	Loss/tok 7.9434 (9.5977)	Learning Rate [6.712897454628148e-05]
5: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00081 (0.00094)	Tok/s 47797 (52391)	Loss/tok 8.0741 (9.5946)	Learning Rate [6.712897454628148e-05]
8: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00098)	Tok/s 48961 (52659)	Loss/tok 8.0756 (9.5882)	Learning Rate [6.712897454628148e-05]
9: TRAIN [0][80/3416]	Time 0.052 (0.057)	Data 0.00093 (0.00095)	Tok/s 49057 (52765)	Loss/tok 8.0830 (9.5891)	Learning Rate [6.712897454628148e-05]
7: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00078 (0.00088)	Tok/s 48496 (52571)	Loss/tok 8.1755 (9.5913)	Learning Rate [6.712897454628148e-05]
6: TRAIN [0][80/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00094)	Tok/s 47663 (52451)	Loss/tok 7.9910 (9.5878)	Learning Rate [6.712897454628148e-05]
5: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00095)	Tok/s 54428 (52046)	Loss/tok 7.9990 (9.4238)	Learning Rate [8.45103719239976e-05]
4: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00106)	Tok/s 54451 (51947)	Loss/tok 8.0869 (9.4251)	Learning Rate [8.45103719239976e-05]
6: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00094)	Tok/s 55120 (52117)	Loss/tok 7.9575 (9.4146)	Learning Rate [8.45103719239976e-05]
7: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00088)	Tok/s 55292 (52248)	Loss/tok 7.9175 (9.4211)	Learning Rate [8.45103719239976e-05]
3: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00100)	Tok/s 54430 (51825)	Loss/tok 8.0196 (9.4175)	Learning Rate [8.45103719239976e-05]
8: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00099)	Tok/s 55188 (52349)	Loss/tok 8.0362 (9.4081)	Learning Rate [8.45103719239976e-05]
10: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00100)	Tok/s 55061 (52526)	Loss/tok 7.9714 (9.4132)	Learning Rate [8.45103719239976e-05]
1: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00090)	Tok/s 54362 (51645)	Loss/tok 7.9144 (9.4262)	Learning Rate [8.45103719239976e-05]
2: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00107)	Tok/s 54409 (51734)	Loss/tok 7.9397 (9.4050)	Learning Rate [8.45103719239976e-05]
9: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00094)	Tok/s 55081 (52452)	Loss/tok 7.9133 (9.4105)	Learning Rate [8.45103719239976e-05]
0: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00090)	Tok/s 54269 (51540)	Loss/tok 7.8860 (9.4118)	Learning Rate [8.45103719239976e-05]
14: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00099)	Tok/s 55226 (52865)	Loss/tok 7.9369 (9.4099)	Learning Rate [8.45103719239976e-05]
11: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00104)	Tok/s 55021 (52559)	Loss/tok 8.1303 (9.4074)	Learning Rate [8.45103719239976e-05]
12: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00104)	Tok/s 55027 (52679)	Loss/tok 7.9405 (9.4167)	Learning Rate [8.45103719239976e-05]
13: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00101)	Tok/s 55068 (52744)	Loss/tok 8.0697 (9.4172)	Learning Rate [8.45103719239976e-05]
15: TRAIN [0][90/3416]	Time 0.059 (0.058)	Data 0.00082 (0.00099)	Tok/s 55291 (52983)	Loss/tok 8.0179 (9.4150)	Learning Rate [8.45103719239976e-05]
5: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00095)	Tok/s 45719 (51875)	Loss/tok 7.7754 (9.2826)	Learning Rate [0.00010639225477529692]
1: TRAIN [0][100/3416]	Time 0.045 (0.057)	Data 0.00081 (0.00090)	Tok/s 45949 (51516)	Loss/tok 7.7362 (9.2850)	Learning Rate [0.00010639225477529692]
6: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00094)	Tok/s 45684 (51939)	Loss/tok 7.7518 (9.2719)	Learning Rate [0.00010639225477529692]
4: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00105)	Tok/s 45717 (51786)	Loss/tok 7.7534 (9.2826)	Learning Rate [0.00010639225477529692]
7: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00083 (0.00088)	Tok/s 45534 (52056)	Loss/tok 7.7193 (9.2802)	Learning Rate [0.00010639225477529692]
2: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00106)	Tok/s 45866 (51597)	Loss/tok 7.6750 (9.2648)	Learning Rate [0.00010639225477529692]
0: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00090)	Tok/s 45911 (51419)	Loss/tok 7.8686 (9.2738)	Learning Rate [0.00010639225477529692]
8: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00099)	Tok/s 45481 (52148)	Loss/tok 7.7503 (9.2702)	Learning Rate [0.00010639225477529692]
3: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00100)	Tok/s 45780 (51676)	Loss/tok 7.7197 (9.2742)	Learning Rate [0.00010639225477529692]
15: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00098)	Tok/s 45866 (52794)	Loss/tok 7.7147 (9.2775)	Learning Rate [0.00010639225477529692]
9: TRAIN [0][100/3416]	Time 0.045 (0.057)	Data 0.00085 (0.00094)	Tok/s 45451 (52252)	Loss/tok 7.8804 (9.2732)	Learning Rate [0.00010639225477529692]
10: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00100)	Tok/s 45419 (52322)	Loss/tok 7.6388 (9.2753)	Learning Rate [0.00010639225477529692]
12: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00104)	Tok/s 45595 (52494)	Loss/tok 7.7480 (9.2774)	Learning Rate [0.00010639225477529692]
13: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00101)	Tok/s 45653 (52565)	Loss/tok 7.7725 (9.2805)	Learning Rate [0.00010639225477529692]
14: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00099)	Tok/s 45798 (52685)	Loss/tok 7.6975 (9.2685)	Learning Rate [0.00010639225477529692]
11: TRAIN [0][100/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00103)	Tok/s 45537 (52365)	Loss/tok 7.7473 (9.2680)	Learning Rate [0.00010639225477529692]
6: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00095 (0.00094)	Tok/s 49209 (51669)	Loss/tok 7.7910 (9.1559)	Learning Rate [0.00013393991315470064]
8: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00103 (0.00099)	Tok/s 49868 (51864)	Loss/tok 7.9352 (9.1594)	Learning Rate [0.00013393991315470064]
5: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00097 (0.00095)	Tok/s 49105 (51604)	Loss/tok 8.0143 (9.1701)	Learning Rate [0.00013393991315470064]
10: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00092 (0.00100)	Tok/s 50474 (52051)	Loss/tok 7.9656 (9.1648)	Learning Rate [0.00013393991315470064]
9: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00094 (0.00094)	Tok/s 50436 (51972)	Loss/tok 7.8918 (9.1620)	Learning Rate [0.00013393991315470064]
4: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00089 (0.00104)	Tok/s 49095 (51512)	Loss/tok 7.9347 (9.1749)	Learning Rate [0.00013393991315470064]
11: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00098 (0.00103)	Tok/s 50408 (52089)	Loss/tok 7.9434 (9.1584)	Learning Rate [0.00013393991315470064]
3: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00097 (0.00100)	Tok/s 49076 (51392)	Loss/tok 7.8429 (9.1624)	Learning Rate [0.00013393991315470064]
2: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00094 (0.00105)	Tok/s 49084 (51315)	Loss/tok 7.8626 (9.1511)	Learning Rate [0.00013393991315470064]
7: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00107 (0.00089)	Tok/s 49189 (51775)	Loss/tok 8.0110 (9.1680)	Learning Rate [0.00013393991315470064]
12: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00088 (0.00103)	Tok/s 50438 (52206)	Loss/tok 7.8770 (9.1651)	Learning Rate [0.00013393991315470064]
13: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00099 (0.00101)	Tok/s 50397 (52270)	Loss/tok 7.8234 (9.1712)	Learning Rate [0.00013393991315470064]
14: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00105 (0.00098)	Tok/s 50338 (52387)	Loss/tok 7.8385 (9.1585)	Learning Rate [0.00013393991315470064]
0: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00092 (0.00090)	Tok/s 49109 (51130)	Loss/tok 7.8447 (9.1598)	Learning Rate [0.00013393991315470064]
15: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00085 (0.00098)	Tok/s 50169 (52488)	Loss/tok 8.0139 (9.1664)	Learning Rate [0.00013393991315470064]
1: TRAIN [0][110/3416]	Time 0.056 (0.057)	Data 0.00092 (0.00090)	Tok/s 48948 (51224)	Loss/tok 8.0379 (9.1741)	Learning Rate [0.00013393991315470064]
9: TRAIN [0][120/3416]	Time 0.057 (0.058)	Data 0.00104 (0.00096)	Tok/s 51360 (52337)	Loss/tok 7.9062 (9.0432)	Learning Rate [0.00016862036032395654]
8: TRAIN [0][120/3416]	Time 0.057 (0.058)	Data 0.00111 (0.00100)	Tok/s 51229 (52238)	Loss/tok 7.8714 (9.0375)	Learning Rate [0.00016862036032395654]
10: TRAIN [0][120/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00100)	Tok/s 51378 (52412)	Loss/tok 7.9860 (9.0480)	Learning Rate [0.00016862036032395654]
11: TRAIN [0][120/3416]	Time 0.058 (0.058)	Data 0.00107 (0.00102)	Tok/s 51190 (52466)	Loss/tok 7.8104 (9.0438)	Learning Rate [0.00016862036032395654]
7: TRAIN [0][120/3416]	Time 0.057 (0.058)	Data 0.00098 (0.00089)	Tok/s 51316 (52156)	Loss/tok 7.8584 (9.0480)	Learning Rate [0.00016862036032395654]
6: TRAIN [0][120/3416]	Time 0.057 (0.058)	Data 0.00104 (0.00094)	Tok/s 51245 (52047)	Loss/tok 7.9469 (9.0392)	Learning Rate [0.00016862036032395654]
12: TRAIN [0][120/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00103)	Tok/s 51086 (52576)	Loss/tok 7.7513 (9.0474)	Learning Rate [0.00016862036032395654]
15: TRAIN [0][120/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00097)	Tok/s 52104 (52878)	Loss/tok 7.6682 (9.0462)	Learning Rate [0.00016862036032395654]
0: TRAIN [0][120/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00091)	Tok/s 51053 (51522)	Loss/tok 7.9046 (9.0477)	Learning Rate [0.00016862036032395654]
14: TRAIN [0][120/3416]	Time 0.058 (0.058)	Data 0.00112 (0.00098)	Tok/s 51934 (52773)	Loss/tok 7.7516 (9.0397)	Learning Rate [0.00016862036032395654]
13: TRAIN [0][120/3416]	Time 0.058 (0.058)	Data 0.00115 (0.00102)	Tok/s 51928 (52653)	Loss/tok 7.8874 (9.0514)	Learning Rate [0.00016862036032395654]
1: TRAIN [0][120/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00091)	Tok/s 51037 (51611)	Loss/tok 7.7356 (9.0520)	Learning Rate [0.00016862036032395654]
2: TRAIN [0][120/3416]	Time 0.058 (0.058)	Data 0.00106 (0.00105)	Tok/s 51076 (51706)	Loss/tok 7.9164 (9.0348)	Learning Rate [0.00016862036032395654]
4: TRAIN [0][120/3416]	Time 0.058 (0.058)	Data 0.00103 (0.00103)	Tok/s 51135 (51887)	Loss/tok 7.8901 (9.0567)	Learning Rate [0.00016862036032395654]
3: TRAIN [0][120/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00101)	Tok/s 51112 (51777)	Loss/tok 7.7603 (9.0417)	Learning Rate [0.00016862036032395654]
5: TRAIN [0][120/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00095)	Tok/s 51084 (51981)	Loss/tok 7.8972 (9.0505)	Learning Rate [0.00016862036032395654]
14: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00099)	Tok/s 43990 (52862)	Loss/tok 7.5485 (8.9399)	Learning Rate [0.00021228045655771787]
13: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00102)	Tok/s 43975 (52748)	Loss/tok 7.5919 (8.9493)	Learning Rate [0.00021228045655771787]
12: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00103)	Tok/s 43960 (52674)	Loss/tok 7.6530 (8.9502)	Learning Rate [0.00021228045655771787]
15: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00097)	Tok/s 43975 (52974)	Loss/tok 7.7499 (8.9497)	Learning Rate [0.00021228045655771787]
11: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00102)	Tok/s 43954 (52559)	Loss/tok 7.5873 (8.9437)	Learning Rate [0.00021228045655771787]
0: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00091)	Tok/s 42640 (51510)	Loss/tok 7.5686 (8.9495)	Learning Rate [0.00021228045655771787]
10: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00100)	Tok/s 43946 (52505)	Loss/tok 7.5742 (8.9519)	Learning Rate [0.00021228045655771787]
9: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00096)	Tok/s 43939 (52431)	Loss/tok 7.7656 (8.9438)	Learning Rate [0.00021228045655771787]
1: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00091)	Tok/s 42650 (51627)	Loss/tok 7.6080 (8.9558)	Learning Rate [0.00021228045655771787]
8: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00100)	Tok/s 43878 (52339)	Loss/tok 7.8014 (8.9410)	Learning Rate [0.00021228045655771787]
2: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00105)	Tok/s 42625 (51749)	Loss/tok 7.4685 (8.9357)	Learning Rate [0.00021228045655771787]
7: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00089)	Tok/s 43860 (52249)	Loss/tok 7.5974 (8.9489)	Learning Rate [0.00021228045655771787]
6: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00094)	Tok/s 43859 (52142)	Loss/tok 7.7276 (8.9433)	Learning Rate [0.00021228045655771787]
5: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00095)	Tok/s 43852 (52071)	Loss/tok 7.6507 (8.9569)	Learning Rate [0.00021228045655771787]
3: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00101)	Tok/s 43045 (51830)	Loss/tok 7.6100 (8.9451)	Learning Rate [0.00021228045655771787]
4: TRAIN [0][130/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00102)	Tok/s 43848 (51961)	Loss/tok 7.5058 (8.9604)	Learning Rate [0.00021228045655771787]
12: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00103)	Tok/s 58211 (52405)	Loss/tok 7.7857 (8.8728)	Learning Rate [0.0002672452611877788]
14: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00099)	Tok/s 58204 (52612)	Loss/tok 7.8359 (8.8626)	Learning Rate [0.0002672452611877788]
11: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00102)	Tok/s 58189 (52283)	Loss/tok 8.0853 (8.8693)	Learning Rate [0.0002672452611877788]
10: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00100)	Tok/s 58198 (52229)	Loss/tok 8.0616 (8.8743)	Learning Rate [0.0002672452611877788]
13: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00101)	Tok/s 58119 (52482)	Loss/tok 7.8315 (8.8704)	Learning Rate [0.0002672452611877788]
15: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 58324 (52724)	Loss/tok 7.9585 (8.8746)	Learning Rate [0.0002672452611877788]
8: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00101)	Tok/s 58206 (52070)	Loss/tok 7.9938 (8.8650)	Learning Rate [0.0002672452611877788]
9: TRAIN [0][140/3416]	Time 0.070 (0.057)	Data 0.00092 (0.00096)	Tok/s 58189 (52155)	Loss/tok 7.8349 (8.8662)	Learning Rate [0.0002672452611877788]
0: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 58103 (51143)	Loss/tok 8.0645 (8.8745)	Learning Rate [0.0002672452611877788]
7: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00089)	Tok/s 58161 (51970)	Loss/tok 7.9788 (8.8734)	Learning Rate [0.0002672452611877788]
5: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 58201 (51768)	Loss/tok 7.9539 (8.8819)	Learning Rate [0.0002672452611877788]
2: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00104)	Tok/s 58125 (51406)	Loss/tok 7.9947 (8.8621)	Learning Rate [0.0002672452611877788]
6: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00095)	Tok/s 58228 (51853)	Loss/tok 7.8788 (8.8689)	Learning Rate [0.0002672452611877788]
1: TRAIN [0][140/3416]	Time 0.070 (0.057)	Data 0.00092 (0.00091)	Tok/s 58106 (51271)	Loss/tok 7.9234 (8.8793)	Learning Rate [0.0002672452611877788]
3: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00101)	Tok/s 58107 (51510)	Loss/tok 7.8724 (8.8688)	Learning Rate [0.0002672452611877788]
4: TRAIN [0][140/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00101)	Tok/s 58141 (51650)	Loss/tok 7.8629 (8.8861)	Learning Rate [0.0002672452611877788]
3: TRAIN [0][150/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00101)	Tok/s 77378 (51950)	Loss/tok 7.9065 (8.7840)	Learning Rate [0.00033644185049086424]
2: TRAIN [0][150/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00104)	Tok/s 76866 (51849)	Loss/tok 7.8965 (8.7784)	Learning Rate [0.00033644185049086424]
5: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00096)	Tok/s 77302 (52192)	Loss/tok 7.8112 (8.7956)	Learning Rate [0.00033644185049086424]
1: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 76403 (51712)	Loss/tok 7.8833 (8.7978)	Learning Rate [0.00033644185049086424]
0: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00091)	Tok/s 76302 (51588)	Loss/tok 7.8941 (8.7933)	Learning Rate [0.00033644185049086424]
15: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 78091 (53148)	Loss/tok 7.8727 (8.7906)	Learning Rate [0.00033644185049086424]
14: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00099)	Tok/s 78131 (53042)	Loss/tok 7.8464 (8.7822)	Learning Rate [0.00033644185049086424]
6: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00095)	Tok/s 77275 (52275)	Loss/tok 7.7765 (8.7820)	Learning Rate [0.00033644185049086424]
7: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00089)	Tok/s 77254 (52398)	Loss/tok 7.8444 (8.7912)	Learning Rate [0.00033644185049086424]
4: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00101)	Tok/s 77302 (52081)	Loss/tok 7.8283 (8.8002)	Learning Rate [0.00033644185049086424]
8: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00101)	Tok/s 77315 (52513)	Loss/tok 7.6944 (8.7796)	Learning Rate [0.00033644185049086424]
10: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00100)	Tok/s 77332 (52673)	Loss/tok 7.9634 (8.7943)	Learning Rate [0.00033644185049086424]
11: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00102)	Tok/s 78052 (52734)	Loss/tok 7.7969 (8.7876)	Learning Rate [0.00033644185049086424]
13: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00101)	Tok/s 78096 (52921)	Loss/tok 7.8137 (8.7902)	Learning Rate [0.00033644185049086424]
12: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00102)	Tok/s 77988 (52847)	Loss/tok 7.8287 (8.7897)	Learning Rate [0.00033644185049086424]
9: TRAIN [0][150/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 77258 (52600)	Loss/tok 7.9142 (8.7830)	Learning Rate [0.00033644185049086424]
0: TRAIN [0][160/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00091)	Tok/s 42775 (51459)	Loss/tok 7.4731 (8.7239)	Learning Rate [0.00042355519517400293]
15: TRAIN [0][160/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00096)	Tok/s 44039 (52994)	Loss/tok 7.6346 (8.7251)	Learning Rate [0.00042355519517400293]
1: TRAIN [0][160/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00092)	Tok/s 42782 (51575)	Loss/tok 7.4214 (8.7262)	Learning Rate [0.00042355519517400293]
14: TRAIN [0][160/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00099)	Tok/s 43939 (52886)	Loss/tok 7.4474 (8.7127)	Learning Rate [0.00042355519517400293]
2: TRAIN [0][160/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00103)	Tok/s 42701 (51703)	Loss/tok 7.5277 (8.7091)	Learning Rate [0.00042355519517400293]
3: TRAIN [0][160/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00101)	Tok/s 42627 (51807)	Loss/tok 7.5726 (8.7148)	Learning Rate [0.00042355519517400293]
12: TRAIN [0][160/3416]	Time 0.048 (0.058)	Data 0.00107 (0.00103)	Tok/s 43737 (52675)	Loss/tok 7.5279 (8.7224)	Learning Rate [0.00042355519517400293]
13: TRAIN [0][160/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00101)	Tok/s 43831 (52760)	Loss/tok 7.5210 (8.7211)	Learning Rate [0.00042355519517400293]
4: TRAIN [0][160/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00100)	Tok/s 42531 (51931)	Loss/tok 7.4885 (8.7283)	Learning Rate [0.00042355519517400293]
5: TRAIN [0][160/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00096)	Tok/s 42959 (52037)	Loss/tok 7.4331 (8.7277)	Learning Rate [0.00042355519517400293]
11: TRAIN [0][160/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00101)	Tok/s 43618 (52568)	Loss/tok 7.4489 (8.7170)	Learning Rate [0.00042355519517400293]
9: TRAIN [0][160/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00096)	Tok/s 43498 (52443)	Loss/tok 7.5242 (8.7142)	Learning Rate [0.00042355519517400293]
7: TRAIN [0][160/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00089)	Tok/s 43568 (52247)	Loss/tok 7.4221 (8.7220)	Learning Rate [0.00042355519517400293]
6: TRAIN [0][160/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00095)	Tok/s 43672 (52125)	Loss/tok 7.4095 (8.7106)	Learning Rate [0.00042355519517400293]
10: TRAIN [0][160/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00100)	Tok/s 43519 (52511)	Loss/tok 7.5953 (8.7287)	Learning Rate [0.00042355519517400293]
8: TRAIN [0][160/3416]	Time 0.049 (0.058)	Data 0.00131 (0.00102)	Tok/s 43532 (52360)	Loss/tok 7.4755 (8.7114)	Learning Rate [0.00042355519517400293]
1: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 59470 (51573)	Loss/tok 7.6968 (8.6655)	Learning Rate [0.0005332243985019905]
2: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00103)	Tok/s 59520 (51715)	Loss/tok 7.7251 (8.6471)	Learning Rate [0.0005332243985019905]
0: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00091)	Tok/s 59420 (51438)	Loss/tok 7.7130 (8.6591)	Learning Rate [0.0005332243985019905]
3: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00101)	Tok/s 59445 (51822)	Loss/tok 7.8169 (8.6575)	Learning Rate [0.0005332243985019905]
14: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00124 (0.00100)	Tok/s 59349 (52939)	Loss/tok 7.7400 (8.6541)	Learning Rate [0.0005332243985019905]
4: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 59487 (51957)	Loss/tok 7.7410 (8.6638)	Learning Rate [0.0005332243985019905]
5: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00116 (0.00097)	Tok/s 59444 (52062)	Loss/tok 7.8046 (8.6695)	Learning Rate [0.0005332243985019905]
15: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 59390 (53058)	Loss/tok 7.8173 (8.6616)	Learning Rate [0.0005332243985019905]
13: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00101)	Tok/s 59286 (52805)	Loss/tok 7.6695 (8.6575)	Learning Rate [0.0005332243985019905]
12: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00103)	Tok/s 59328 (52722)	Loss/tok 7.6272 (8.6555)	Learning Rate [0.0005332243985019905]
10: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00100)	Tok/s 59360 (52548)	Loss/tok 7.7817 (8.6653)	Learning Rate [0.0005332243985019905]
6: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00096)	Tok/s 59499 (52156)	Loss/tok 7.5740 (8.6462)	Learning Rate [0.0005332243985019905]
8: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00102)	Tok/s 59410 (52400)	Loss/tok 7.5159 (8.6467)	Learning Rate [0.0005332243985019905]
7: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00089)	Tok/s 59452 (52283)	Loss/tok 7.7025 (8.6600)	Learning Rate [0.0005332243985019905]
11: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00101)	Tok/s 59247 (52611)	Loss/tok 7.8351 (8.6530)	Learning Rate [0.0005332243985019905]
9: TRAIN [0][170/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00096)	Tok/s 59236 (52477)	Loss/tok 7.7475 (8.6510)	Learning Rate [0.0005332243985019905]
12: Upscaling, new scale: 128.0
14: Upscaling, new scale: 128.0
13: Upscaling, new scale: 128.0
10: Upscaling, new scale: 128.0
11: Upscaling, new scale: 128.0
15: Upscaling, new scale: 128.0
9: Upscaling, new scale: 128.0
8: Upscaling, new scale: 128.0
0: Upscaling, new scale: 128.0
7: Upscaling, new scale: 128.0
6: Upscaling, new scale: 128.0
1: Upscaling, new scale: 128.0
5: Upscaling, new scale: 128.0
3: Upscaling, new scale: 128.0
4: Upscaling, new scale: 128.0
2: Upscaling, new scale: 128.0
11: TRAIN [0][180/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00101)	Tok/s 48804 (52549)	Loss/tok 7.5105 (8.5987)	Learning Rate [0.0006712897454628158]
12: TRAIN [0][180/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00103)	Tok/s 48839 (52655)	Loss/tok 7.2428 (8.5969)	Learning Rate [0.0006712897454628158]
10: TRAIN [0][180/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00100)	Tok/s 48742 (52488)	Loss/tok 7.2600 (8.6058)	Learning Rate [0.0006712897454628158]
9: TRAIN [0][180/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00096)	Tok/s 48557 (52421)	Loss/tok 7.5231 (8.5931)	Learning Rate [0.0006712897454628158]
8: TRAIN [0][180/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00102)	Tok/s 48477 (52343)	Loss/tok 7.4027 (8.5903)	Learning Rate [0.0006712897454628158]
13: TRAIN [0][180/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00100)	Tok/s 48717 (52745)	Loss/tok 7.3854 (8.6025)	Learning Rate [0.0006712897454628158]
15: TRAIN [0][180/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00096)	Tok/s 48478 (52992)	Loss/tok 7.3345 (8.6041)	Learning Rate [0.0006712897454628158]
14: TRAIN [0][180/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00100)	Tok/s 48573 (52879)	Loss/tok 7.3443 (8.5980)	Learning Rate [0.0006712897454628158]
5: TRAIN [0][180/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00097)	Tok/s 48145 (52002)	Loss/tok 7.4742 (8.6117)	Learning Rate [0.0006712897454628158]
7: TRAIN [0][180/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00090)	Tok/s 48278 (52227)	Loss/tok 7.1240 (8.6000)	Learning Rate [0.0006712897454628158]
6: TRAIN [0][180/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00096)	Tok/s 48239 (52094)	Loss/tok 7.3389 (8.5886)	Learning Rate [0.0006712897454628158]
0: TRAIN [0][180/3416]	Time 0.046 (0.058)	Data 0.00082 (0.00091)	Tok/s 48374 (51397)	Loss/tok 7.1969 (8.5987)	Learning Rate [0.0006712897454628158]
4: TRAIN [0][180/3416]	Time 0.047 (0.058)	Data 0.00079 (0.00099)	Tok/s 48111 (51896)	Loss/tok 7.3445 (8.6018)	Learning Rate [0.0006712897454628158]
1: TRAIN [0][180/3416]	Time 0.046 (0.058)	Data 0.00080 (0.00092)	Tok/s 48256 (51524)	Loss/tok 7.4856 (8.6067)	Learning Rate [0.0006712897454628158]
2: TRAIN [0][180/3416]	Time 0.046 (0.058)	Data 0.00080 (0.00103)	Tok/s 48188 (51658)	Loss/tok 7.3617 (8.5892)	Learning Rate [0.0006712897454628158]
3: TRAIN [0][180/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00101)	Tok/s 48108 (51766)	Loss/tok 7.4919 (8.6005)	Learning Rate [0.0006712897454628158]
0: TRAIN [0][190/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00091)	Tok/s 54608 (51469)	Loss/tok 7.4917 (8.5340)	Learning Rate [0.000845103719239977]
15: TRAIN [0][190/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00096)	Tok/s 55614 (53053)	Loss/tok 7.4585 (8.5424)	Learning Rate [0.000845103719239977]
1: TRAIN [0][190/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00092)	Tok/s 54387 (51593)	Loss/tok 7.3180 (8.5427)	Learning Rate [0.000845103719239977]
14: TRAIN [0][190/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00100)	Tok/s 55601 (52940)	Loss/tok 7.4944 (8.5382)	Learning Rate [0.000845103719239977]
2: TRAIN [0][190/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00102)	Tok/s 54409 (51720)	Loss/tok 7.5160 (8.5266)	Learning Rate [0.000845103719239977]
13: TRAIN [0][190/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00100)	Tok/s 55620 (52800)	Loss/tok 7.3586 (8.5396)	Learning Rate [0.000845103719239977]
11: TRAIN [0][190/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00101)	Tok/s 55579 (52606)	Loss/tok 7.4286 (8.5387)	Learning Rate [0.000845103719239977]
5: TRAIN [0][190/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00098)	Tok/s 55479 (52063)	Loss/tok 7.3362 (8.5513)	Learning Rate [0.000845103719239977]
3: TRAIN [0][190/3416]	Time 0.065 (0.058)	Data 0.00102 (0.00101)	Tok/s 54431 (51828)	Loss/tok 7.4981 (8.5431)	Learning Rate [0.000845103719239977]
4: TRAIN [0][190/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00099)	Tok/s 55220 (51957)	Loss/tok 7.4247 (8.5436)	Learning Rate [0.000845103719239977]
12: TRAIN [0][190/3416]	Time 0.064 (0.058)	Data 0.00103 (0.00103)	Tok/s 55700 (52708)	Loss/tok 7.6240 (8.5389)	Learning Rate [0.000845103719239977]
10: TRAIN [0][190/3416]	Time 0.064 (0.058)	Data 0.00103 (0.00100)	Tok/s 55572 (52546)	Loss/tok 7.4529 (8.5446)	Learning Rate [0.000845103719239977]
9: TRAIN [0][190/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00096)	Tok/s 55556 (52480)	Loss/tok 7.5498 (8.5335)	Learning Rate [0.000845103719239977]
6: TRAIN [0][190/3416]	Time 0.065 (0.058)	Data 0.00104 (0.00096)	Tok/s 55408 (52162)	Loss/tok 7.3672 (8.5291)	Learning Rate [0.000845103719239977]
8: TRAIN [0][190/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00102)	Tok/s 55544 (52406)	Loss/tok 7.4774 (8.5316)	Learning Rate [0.000845103719239977]
7: TRAIN [0][190/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00090)	Tok/s 55382 (52292)	Loss/tok 7.5139 (8.5385)	Learning Rate [0.000845103719239977]
4: TRAIN [0][200/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00098)	Tok/s 61468 (51808)	Loss/tok 7.4962 (8.4898)	Learning Rate [0.0010639225477529705]
11: TRAIN [0][200/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00101)	Tok/s 61705 (52438)	Loss/tok 7.4078 (8.4794)	Learning Rate [0.0010639225477529705]
5: TRAIN [0][200/3416]	Time 0.067 (0.058)	Data 0.00116 (0.00098)	Tok/s 62277 (51914)	Loss/tok 7.5246 (8.4933)	Learning Rate [0.0010639225477529705]
1: TRAIN [0][200/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00093)	Tok/s 61320 (51432)	Loss/tok 7.2849 (8.4824)	Learning Rate [0.0010639225477529705]
2: TRAIN [0][200/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00102)	Tok/s 61274 (51562)	Loss/tok 7.4558 (8.4711)	Learning Rate [0.0010639225477529705]
6: TRAIN [0][200/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00097)	Tok/s 61506 (52011)	Loss/tok 7.4569 (8.4735)	Learning Rate [0.0010639225477529705]
15: TRAIN [0][200/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00096)	Tok/s 62327 (52880)	Loss/tok 7.3852 (8.4839)	Learning Rate [0.0010639225477529705]
10: TRAIN [0][200/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00100)	Tok/s 61603 (52381)	Loss/tok 7.3648 (8.4875)	Learning Rate [0.0010639225477529705]
9: TRAIN [0][200/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00096)	Tok/s 61589 (52318)	Loss/tok 7.4198 (8.4774)	Learning Rate [0.0010639225477529705]
3: TRAIN [0][200/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00101)	Tok/s 61334 (51674)	Loss/tok 7.4681 (8.4856)	Learning Rate [0.0010639225477529705]
0: TRAIN [0][200/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00091)	Tok/s 61305 (51313)	Loss/tok 7.5154 (8.4784)	Learning Rate [0.0010639225477529705]
12: TRAIN [0][200/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00103)	Tok/s 62318 (52540)	Loss/tok 7.4256 (8.4824)	Learning Rate [0.0010639225477529705]
8: TRAIN [0][200/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00102)	Tok/s 61593 (52244)	Loss/tok 7.3523 (8.4751)	Learning Rate [0.0010639225477529705]
13: TRAIN [0][200/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00099)	Tok/s 61437 (52628)	Loss/tok 7.4157 (8.4850)	Learning Rate [0.0010639225477529705]
7: TRAIN [0][200/3416]	Time 0.068 (0.058)	Data 0.00081 (0.00090)	Tok/s 61563 (52136)	Loss/tok 7.3668 (8.4815)	Learning Rate [0.0010639225477529705]
14: TRAIN [0][200/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00100)	Tok/s 62255 (52772)	Loss/tok 7.4467 (8.4833)	Learning Rate [0.0010639225477529705]
5: TRAIN [0][210/3416]	Time 0.069 (0.057)	Data 0.00090 (0.00098)	Tok/s 73786 (51517)	Loss/tok 7.3634 (8.4457)	Learning Rate [0.00125]
6: TRAIN [0][210/3416]	Time 0.069 (0.057)	Data 0.00100 (0.00096)	Tok/s 73823 (51619)	Loss/tok 7.4020 (8.4252)	Learning Rate [0.00125]
7: TRAIN [0][210/3416]	Time 0.069 (0.057)	Data 0.00087 (0.00090)	Tok/s 73819 (51747)	Loss/tok 7.4723 (8.4338)	Learning Rate [0.00125]
4: TRAIN [0][210/3416]	Time 0.070 (0.057)	Data 0.00090 (0.00098)	Tok/s 73652 (51399)	Loss/tok 7.4379 (8.4403)	Learning Rate [0.00125]
8: TRAIN [0][210/3416]	Time 0.069 (0.057)	Data 0.00092 (0.00103)	Tok/s 74343 (51868)	Loss/tok 7.5029 (8.4271)	Learning Rate [0.00125]
2: TRAIN [0][210/3416]	Time 0.069 (0.057)	Data 0.00095 (0.00102)	Tok/s 73675 (51137)	Loss/tok 7.2975 (8.4247)	Learning Rate [0.00125]
3: TRAIN [0][210/3416]	Time 0.070 (0.057)	Data 0.00087 (0.00100)	Tok/s 73655 (51255)	Loss/tok 7.3751 (8.4366)	Learning Rate [0.00125]
9: TRAIN [0][210/3416]	Time 0.069 (0.057)	Data 0.00103 (0.00097)	Tok/s 74740 (51939)	Loss/tok 7.3594 (8.4290)	Learning Rate [0.00125]
0: TRAIN [0][210/3416]	Time 0.070 (0.057)	Data 0.00093 (0.00091)	Tok/s 73647 (50875)	Loss/tok 7.3318 (8.4305)	Learning Rate [0.00125]
10: TRAIN [0][210/3416]	Time 0.069 (0.057)	Data 0.00095 (0.00100)	Tok/s 74693 (52000)	Loss/tok 7.3960 (8.4378)	Learning Rate [0.00125]
15: TRAIN [0][210/3416]	Time 0.069 (0.057)	Data 0.00091 (0.00096)	Tok/s 74630 (52525)	Loss/tok 7.3221 (8.4340)	Learning Rate [0.00125]
1: TRAIN [0][210/3416]	Time 0.069 (0.057)	Data 0.00109 (0.00093)	Tok/s 73695 (50997)	Loss/tok 7.4314 (8.4348)	Learning Rate [0.00125]
11: TRAIN [0][210/3416]	Time 0.069 (0.057)	Data 0.00092 (0.00100)	Tok/s 74726 (52054)	Loss/tok 7.4127 (8.4296)	Learning Rate [0.00125]
14: TRAIN [0][210/3416]	Time 0.069 (0.057)	Data 0.00101 (0.00100)	Tok/s 74595 (52409)	Loss/tok 7.3487 (8.4335)	Learning Rate [0.00125]
12: TRAIN [0][210/3416]	Time 0.069 (0.057)	Data 0.00092 (0.00103)	Tok/s 74695 (52167)	Loss/tok 7.1910 (8.4328)	Learning Rate [0.00125]
13: TRAIN [0][210/3416]	Time 0.069 (0.057)	Data 0.00087 (0.00099)	Tok/s 74647 (52260)	Loss/tok 7.3928 (8.4344)	Learning Rate [0.00125]
9: TRAIN [0][220/3416]	Time 0.048 (0.057)	Data 0.00096 (0.00097)	Tok/s 51645 (52000)	Loss/tok 6.9555 (8.3701)	Learning Rate [0.00125]
10: TRAIN [0][220/3416]	Time 0.048 (0.057)	Data 0.00092 (0.00100)	Tok/s 51698 (52058)	Loss/tok 6.8332 (8.3779)	Learning Rate [0.00125]
12: TRAIN [0][220/3416]	Time 0.048 (0.057)	Data 0.00100 (0.00103)	Tok/s 51810 (52218)	Loss/tok 6.8077 (8.3735)	Learning Rate [0.00125]
11: TRAIN [0][220/3416]	Time 0.048 (0.057)	Data 0.00095 (0.00100)	Tok/s 51716 (52110)	Loss/tok 7.1735 (8.3704)	Learning Rate [0.00125]
8: TRAIN [0][220/3416]	Time 0.048 (0.057)	Data 0.00084 (0.00102)	Tok/s 51520 (51931)	Loss/tok 7.0801 (8.3704)	Learning Rate [0.00125]
7: TRAIN [0][220/3416]	Time 0.049 (0.057)	Data 0.00084 (0.00090)	Tok/s 51420 (51815)	Loss/tok 6.8896 (8.3759)	Learning Rate [0.00125]
13: TRAIN [0][220/3416]	Time 0.048 (0.057)	Data 0.00089 (0.00099)	Tok/s 51726 (52306)	Loss/tok 6.9148 (8.3742)	Learning Rate [0.00125]
6: TRAIN [0][220/3416]	Time 0.049 (0.057)	Data 0.00094 (0.00096)	Tok/s 51387 (51690)	Loss/tok 6.9056 (8.3637)	Learning Rate [0.00125]
14: TRAIN [0][220/3416]	Time 0.048 (0.057)	Data 0.00116 (0.00100)	Tok/s 51771 (52449)	Loss/tok 6.9184 (8.3744)	Learning Rate [0.00125]
15: TRAIN [0][220/3416]	Time 0.048 (0.057)	Data 0.00088 (0.00095)	Tok/s 51609 (52560)	Loss/tok 6.9983 (8.3750)	Learning Rate [0.00125]
2: TRAIN [0][220/3416]	Time 0.049 (0.057)	Data 0.00100 (0.00101)	Tok/s 51446 (51201)	Loss/tok 6.8597 (8.3652)	Learning Rate [0.00125]
5: TRAIN [0][220/3416]	Time 0.049 (0.057)	Data 0.00088 (0.00097)	Tok/s 51378 (51586)	Loss/tok 6.9546 (8.3865)	Learning Rate [0.00125]
4: TRAIN [0][220/3416]	Time 0.049 (0.057)	Data 0.00090 (0.00098)	Tok/s 51339 (51460)	Loss/tok 6.9068 (8.3798)	Learning Rate [0.00125]
3: TRAIN [0][220/3416]	Time 0.048 (0.057)	Data 0.00092 (0.00100)	Tok/s 51465 (51319)	Loss/tok 6.8673 (8.3747)	Learning Rate [0.00125]
1: TRAIN [0][220/3416]	Time 0.049 (0.057)	Data 0.00088 (0.00094)	Tok/s 51445 (51068)	Loss/tok 7.1416 (8.3737)	Learning Rate [0.00125]
0: TRAIN [0][220/3416]	Time 0.048 (0.057)	Data 0.00090 (0.00091)	Tok/s 51560 (50948)	Loss/tok 6.9458 (8.3712)	Learning Rate [0.00125]
11: TRAIN [0][230/3416]	Time 0.054 (0.057)	Data 0.00103 (0.00100)	Tok/s 53049 (52058)	Loss/tok 7.0814 (8.3112)	Learning Rate [0.00125]
12: TRAIN [0][230/3416]	Time 0.054 (0.057)	Data 0.00091 (0.00103)	Tok/s 52998 (52169)	Loss/tok 7.0182 (8.3133)	Learning Rate [0.00125]
13: TRAIN [0][230/3416]	Time 0.054 (0.057)	Data 0.00088 (0.00099)	Tok/s 52884 (52257)	Loss/tok 7.1963 (8.3154)	Learning Rate [0.00125]
14: TRAIN [0][230/3416]	Time 0.055 (0.057)	Data 0.00087 (0.00100)	Tok/s 52669 (52394)	Loss/tok 6.9521 (8.3127)	Learning Rate [0.00125]
7: TRAIN [0][230/3416]	Time 0.054 (0.057)	Data 0.00092 (0.00091)	Tok/s 52925 (51757)	Loss/tok 6.9588 (8.3190)	Learning Rate [0.00125]
15: TRAIN [0][230/3416]	Time 0.055 (0.057)	Data 0.00092 (0.00095)	Tok/s 52629 (52514)	Loss/tok 7.2358 (8.3144)	Learning Rate [0.00125]
0: TRAIN [0][230/3416]	Time 0.055 (0.057)	Data 0.00091 (0.00091)	Tok/s 52539 (50865)	Loss/tok 7.0624 (8.3133)	Learning Rate [0.00125]
5: TRAIN [0][230/3416]	Time 0.055 (0.057)	Data 0.00087 (0.00097)	Tok/s 52720 (51529)	Loss/tok 7.0299 (8.3262)	Learning Rate [0.00125]
6: TRAIN [0][230/3416]	Time 0.055 (0.057)	Data 0.00097 (0.00096)	Tok/s 52809 (51633)	Loss/tok 7.0528 (8.3079)	Learning Rate [0.00125]
4: TRAIN [0][230/3416]	Time 0.055 (0.057)	Data 0.00093 (0.00097)	Tok/s 52608 (51399)	Loss/tok 6.9225 (8.3195)	Learning Rate [0.00125]
2: TRAIN [0][230/3416]	Time 0.055 (0.057)	Data 0.00100 (0.00101)	Tok/s 52476 (51135)	Loss/tok 7.0234 (8.3075)	Learning Rate [0.00125]
3: TRAIN [0][230/3416]	Time 0.055 (0.057)	Data 0.00090 (0.00100)	Tok/s 52558 (51258)	Loss/tok 7.0754 (8.3144)	Learning Rate [0.00125]
1: TRAIN [0][230/3416]	Time 0.055 (0.057)	Data 0.00092 (0.00094)	Tok/s 52447 (50989)	Loss/tok 6.8749 (8.3150)	Learning Rate [0.00125]
9: TRAIN [0][230/3416]	Time 0.054 (0.057)	Data 0.00113 (0.00097)	Tok/s 52989 (51949)	Loss/tok 7.1333 (8.3133)	Learning Rate [0.00125]
10: TRAIN [0][230/3416]	Time 0.054 (0.057)	Data 0.00109 (0.00100)	Tok/s 53013 (52004)	Loss/tok 6.8672 (8.3170)	Learning Rate [0.00125]
8: TRAIN [0][230/3416]	Time 0.054 (0.057)	Data 0.00103 (0.00102)	Tok/s 52996 (51873)	Loss/tok 6.9535 (8.3094)	Learning Rate [0.00125]
0: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00089 (0.00091)	Tok/s 69523 (50943)	Loss/tok 6.9409 (8.2537)	Learning Rate [0.00125]
2: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00106 (0.00101)	Tok/s 70342 (51212)	Loss/tok 7.0651 (8.2459)	Learning Rate [0.00125]
15: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00216 (0.00096)	Tok/s 71077 (52551)	Loss/tok 6.8726 (8.2538)	Learning Rate [0.00125]
1: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00100 (0.00094)	Tok/s 70283 (51070)	Loss/tok 6.7875 (8.2526)	Learning Rate [0.00125]
14: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00090 (0.00100)	Tok/s 71019 (52435)	Loss/tok 6.8952 (8.2536)	Learning Rate [0.00125]
4: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00091 (0.00097)	Tok/s 70252 (51465)	Loss/tok 6.9536 (8.2586)	Learning Rate [0.00125]
13: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00100 (0.00099)	Tok/s 70990 (52304)	Loss/tok 7.0067 (8.2565)	Learning Rate [0.00125]
12: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00101 (0.00102)	Tok/s 70347 (52216)	Loss/tok 6.8053 (8.2533)	Learning Rate [0.00125]
10: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00096 (0.00099)	Tok/s 70214 (52056)	Loss/tok 6.9060 (8.2563)	Learning Rate [0.00125]
3: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00094 (0.00100)	Tok/s 70196 (51330)	Loss/tok 6.9283 (8.2522)	Learning Rate [0.00125]
5: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00098 (0.00097)	Tok/s 70233 (51589)	Loss/tok 6.8140 (8.2658)	Learning Rate [0.00125]
11: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00098 (0.00100)	Tok/s 70078 (52105)	Loss/tok 6.9229 (8.2511)	Learning Rate [0.00125]
6: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00092 (0.00096)	Tok/s 70195 (51691)	Loss/tok 6.7979 (8.2484)	Learning Rate [0.00125]
8: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00087 (0.00101)	Tok/s 70099 (51925)	Loss/tok 6.9332 (8.2505)	Learning Rate [0.00125]
7: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00090 (0.00091)	Tok/s 70273 (51811)	Loss/tok 6.7719 (8.2571)	Learning Rate [0.00125]
9: TRAIN [0][240/3416]	Time 0.069 (0.057)	Data 0.00091 (0.00097)	Tok/s 70062 (51995)	Loss/tok 6.8027 (8.2534)	Learning Rate [0.00125]
2: TRAIN [0][250/3416]	Time 0.069 (0.057)	Data 0.00109 (0.00101)	Tok/s 66522 (51411)	Loss/tok 6.7998 (8.1785)	Learning Rate [0.00125]
3: TRAIN [0][250/3416]	Time 0.069 (0.057)	Data 0.00093 (0.00100)	Tok/s 66402 (51529)	Loss/tok 6.8971 (8.1884)	Learning Rate [0.00125]
1: TRAIN [0][250/3416]	Time 0.069 (0.057)	Data 0.00094 (0.00094)	Tok/s 66521 (51264)	Loss/tok 6.7597 (8.1861)	Learning Rate [0.00125]
0: TRAIN [0][250/3416]	Time 0.069 (0.057)	Data 0.00093 (0.00092)	Tok/s 66541 (51138)	Loss/tok 6.8463 (8.1847)	Learning Rate [0.00125]
5: TRAIN [0][250/3416]	Time 0.070 (0.057)	Data 0.00087 (0.00097)	Tok/s 66839 (51780)	Loss/tok 6.9553 (8.2020)	Learning Rate [0.00125]
15: TRAIN [0][250/3416]	Time 0.069 (0.057)	Data 0.00084 (0.00095)	Tok/s 67440 (52729)	Loss/tok 6.8351 (8.1878)	Learning Rate [0.00125]
14: TRAIN [0][250/3416]	Time 0.069 (0.057)	Data 0.00090 (0.00100)	Tok/s 67387 (52614)	Loss/tok 6.9494 (8.1874)	Learning Rate [0.00125]
4: TRAIN [0][250/3416]	Time 0.070 (0.057)	Data 0.00086 (0.00097)	Tok/s 66278 (51658)	Loss/tok 6.6793 (8.1914)	Learning Rate [0.00125]
6: TRAIN [0][250/3416]	Time 0.070 (0.057)	Data 0.00093 (0.00096)	Tok/s 67031 (51882)	Loss/tok 6.8103 (8.1809)	Learning Rate [0.00125]
13: TRAIN [0][250/3416]	Time 0.070 (0.057)	Data 0.00098 (0.00100)	Tok/s 67220 (52487)	Loss/tok 6.8199 (8.1879)	Learning Rate [0.00125]
12: TRAIN [0][250/3416]	Time 0.070 (0.057)	Data 0.00102 (0.00102)	Tok/s 67171 (52391)	Loss/tok 6.8859 (8.1883)	Learning Rate [0.00125]
8: TRAIN [0][250/3416]	Time 0.070 (0.057)	Data 0.00087 (0.00101)	Tok/s 66941 (52112)	Loss/tok 6.6368 (8.1844)	Learning Rate [0.00125]
7: TRAIN [0][250/3416]	Time 0.070 (0.057)	Data 0.00104 (0.00091)	Tok/s 66884 (51999)	Loss/tok 6.7716 (8.1875)	Learning Rate [0.00125]
11: TRAIN [0][250/3416]	Time 0.070 (0.057)	Data 0.00091 (0.00099)	Tok/s 67070 (52284)	Loss/tok 6.8301 (8.1844)	Learning Rate [0.00125]
10: TRAIN [0][250/3416]	Time 0.070 (0.057)	Data 0.00083 (0.00099)	Tok/s 66996 (52237)	Loss/tok 6.8108 (8.1929)	Learning Rate [0.00125]
9: TRAIN [0][250/3416]	Time 0.070 (0.057)	Data 0.00092 (0.00097)	Tok/s 66805 (52178)	Loss/tok 6.7740 (8.1871)	Learning Rate [0.00125]
2: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00126 (0.00102)	Tok/s 48106 (51421)	Loss/tok 6.4609 (8.1220)	Learning Rate [0.00125]
3: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00102 (0.00099)	Tok/s 49061 (51537)	Loss/tok 6.4631 (8.1299)	Learning Rate [0.00125]
1: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00105 (0.00094)	Tok/s 47755 (51274)	Loss/tok 6.4940 (8.1296)	Learning Rate [0.00125]
0: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00100 (0.00091)	Tok/s 47750 (51150)	Loss/tok 6.2516 (8.1268)	Learning Rate [0.00125]
4: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00095 (0.00097)	Tok/s 48879 (51662)	Loss/tok 6.6706 (8.1340)	Learning Rate [0.00125]
5: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00098 (0.00097)	Tok/s 48771 (51784)	Loss/tok 6.3758 (8.1412)	Learning Rate [0.00125]
14: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00099 (0.00099)	Tok/s 49150 (52610)	Loss/tok 6.4775 (8.1334)	Learning Rate [0.00125]
13: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00104 (0.00100)	Tok/s 49196 (52481)	Loss/tok 6.3825 (8.1310)	Learning Rate [0.00125]
6: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00108 (0.00096)	Tok/s 48801 (51884)	Loss/tok 6.2767 (8.1242)	Learning Rate [0.00125]
12: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00104 (0.00102)	Tok/s 49073 (52388)	Loss/tok 6.3719 (8.1306)	Learning Rate [0.00125]
15: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00103 (0.00095)	Tok/s 49157 (52728)	Loss/tok 6.4921 (8.1314)	Learning Rate [0.00125]
7: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00110 (0.00091)	Tok/s 48792 (52004)	Loss/tok 6.5869 (8.1292)	Learning Rate [0.00125]
8: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00106 (0.00101)	Tok/s 48796 (52112)	Loss/tok 6.2963 (8.1286)	Learning Rate [0.00125]
11: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00098 (0.00099)	Tok/s 48971 (52285)	Loss/tok 6.4265 (8.1295)	Learning Rate [0.00125]
10: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00100 (0.00099)	Tok/s 48859 (52235)	Loss/tok 6.5610 (8.1387)	Learning Rate [0.00125]
9: TRAIN [0][260/3416]	Time 0.046 (0.057)	Data 0.00101 (0.00097)	Tok/s 48559 (52175)	Loss/tok 6.4079 (8.1270)	Learning Rate [0.00125]
3: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00094 (0.00099)	Tok/s 52960 (51593)	Loss/tok 6.4379 (8.0702)	Learning Rate [0.00125]
2: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00111 (0.00102)	Tok/s 52957 (51480)	Loss/tok 6.5568 (8.0656)	Learning Rate [0.00125]
4: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00086 (0.00097)	Tok/s 53890 (51716)	Loss/tok 6.5499 (8.0755)	Learning Rate [0.00125]
1: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00090 (0.00094)	Tok/s 52960 (51337)	Loss/tok 6.4929 (8.0705)	Learning Rate [0.00125]
0: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00080 (0.00091)	Tok/s 52954 (51216)	Loss/tok 6.4354 (8.0678)	Learning Rate [0.00125]
15: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00083 (0.00095)	Tok/s 54010 (52774)	Loss/tok 6.5753 (8.0715)	Learning Rate [0.00125]
5: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00084 (0.00096)	Tok/s 53899 (51834)	Loss/tok 6.6398 (8.0816)	Learning Rate [0.00125]
14: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00087 (0.00099)	Tok/s 53939 (52657)	Loss/tok 6.6437 (8.0734)	Learning Rate [0.00125]
8: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00086 (0.00101)	Tok/s 53956 (52158)	Loss/tok 6.4256 (8.0696)	Learning Rate [0.00125]
7: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00100 (0.00091)	Tok/s 53932 (52050)	Loss/tok 6.6057 (8.0712)	Learning Rate [0.00125]
12: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00093 (0.00101)	Tok/s 53922 (52428)	Loss/tok 6.5296 (8.0701)	Learning Rate [0.00125]
10: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00101 (0.00099)	Tok/s 53974 (52277)	Loss/tok 6.4065 (8.0791)	Learning Rate [0.00125]
9: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00090 (0.00097)	Tok/s 53953 (52222)	Loss/tok 6.4677 (8.0698)	Learning Rate [0.00125]
6: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00108 (0.00096)	Tok/s 53905 (51931)	Loss/tok 6.3312 (8.0673)	Learning Rate [0.00125]
11: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00107 (0.00099)	Tok/s 53925 (52326)	Loss/tok 6.6574 (8.0698)	Learning Rate [0.00125]
13: TRAIN [0][270/3416]	Time 0.063 (0.057)	Data 0.00100 (0.00100)	Tok/s 53955 (52524)	Loss/tok 6.5837 (8.0724)	Learning Rate [0.00125]
4: TRAIN [0][280/3416]	Time 0.050 (0.057)	Data 0.00106 (0.00096)	Tok/s 32965 (51697)	Loss/tok 5.7812 (8.0150)	Learning Rate [0.00125]
5: TRAIN [0][280/3416]	Time 0.050 (0.057)	Data 0.00096 (0.00096)	Tok/s 32993 (51817)	Loss/tok 5.9614 (8.0233)	Learning Rate [0.00125]
7: TRAIN [0][280/3416]	Time 0.050 (0.057)	Data 0.00109 (0.00091)	Tok/s 32972 (52044)	Loss/tok 5.9909 (8.0126)	Learning Rate [0.00125]
2: TRAIN [0][280/3416]	Time 0.051 (0.057)	Data 0.00105 (0.00102)	Tok/s 32778 (51449)	Loss/tok 5.9556 (8.0052)	Learning Rate [0.00125]
8: TRAIN [0][280/3416]	Time 0.051 (0.057)	Data 0.00096 (0.00101)	Tok/s 32838 (52156)	Loss/tok 5.9240 (8.0092)	Learning Rate [0.00125]
1: TRAIN [0][280/3416]	Time 0.051 (0.057)	Data 0.00103 (0.00094)	Tok/s 32743 (51298)	Loss/tok 6.1376 (8.0129)	Learning Rate [0.00125]
9: TRAIN [0][280/3416]	Time 0.051 (0.057)	Data 0.00089 (0.00097)	Tok/s 33575 (52220)	Loss/tok 6.1165 (8.0088)	Learning Rate [0.00125]
0: TRAIN [0][280/3416]	Time 0.051 (0.057)	Data 0.00092 (0.00091)	Tok/s 32568 (51169)	Loss/tok 6.1323 (8.0114)	Learning Rate [0.00125]
10: TRAIN [0][280/3416]	Time 0.051 (0.057)	Data 0.00089 (0.00099)	Tok/s 33930 (52278)	Loss/tok 5.9010 (8.0162)	Learning Rate [0.00125]
15: TRAIN [0][280/3416]	Time 0.051 (0.057)	Data 0.00092 (0.00095)	Tok/s 33841 (52784)	Loss/tok 6.0396 (8.0113)	Learning Rate [0.00125]
14: TRAIN [0][280/3416]	Time 0.051 (0.057)	Data 0.00102 (0.00099)	Tok/s 33845 (52669)	Loss/tok 6.1887 (8.0126)	Learning Rate [0.00125]
11: TRAIN [0][280/3416]	Time 0.051 (0.057)	Data 0.00092 (0.00099)	Tok/s 33847 (52330)	Loss/tok 5.9347 (8.0082)	Learning Rate [0.00125]
12: TRAIN [0][280/3416]	Time 0.051 (0.057)	Data 0.00094 (0.00101)	Tok/s 33788 (52436)	Loss/tok 6.0053 (8.0109)	Learning Rate [0.00125]
13: TRAIN [0][280/3416]	Time 0.052 (0.057)	Data 0.00102 (0.00100)	Tok/s 33504 (52532)	Loss/tok 6.1488 (8.0113)	Learning Rate [0.00125]
6: TRAIN [0][280/3416]	Time 0.051 (0.057)	Data 0.00112 (0.00097)	Tok/s 32903 (51918)	Loss/tok 6.1828 (8.0104)	Learning Rate [0.00125]
3: TRAIN [0][280/3416]	Time 0.051 (0.057)	Data 0.00134 (0.00099)	Tok/s 32818 (51562)	Loss/tok 5.9680 (8.0103)	Learning Rate [0.00125]
4: TRAIN [0][290/3416]	Time 0.050 (0.057)	Data 0.00083 (0.00096)	Tok/s 31017 (51580)	Loss/tok 5.7918 (7.9613)	Learning Rate [0.00125]
3: TRAIN [0][290/3416]	Time 0.049 (0.057)	Data 0.00112 (0.00099)	Tok/s 31110 (51454)	Loss/tok 5.6562 (7.9582)	Learning Rate [0.00125]
5: TRAIN [0][290/3416]	Time 0.050 (0.057)	Data 0.00090 (0.00096)	Tok/s 30924 (51697)	Loss/tok 5.7228 (7.9698)	Learning Rate [0.00125]
1: TRAIN [0][290/3416]	Time 0.049 (0.057)	Data 0.00088 (0.00094)	Tok/s 31110 (51195)	Loss/tok 5.4244 (7.9581)	Learning Rate [0.00125]
0: TRAIN [0][290/3416]	Time 0.049 (0.057)	Data 0.00084 (0.00091)	Tok/s 31117 (51069)	Loss/tok 5.7424 (7.9581)	Learning Rate [0.00125]
2: TRAIN [0][290/3416]	Time 0.049 (0.057)	Data 0.00101 (0.00102)	Tok/s 31100 (51341)	Loss/tok 5.7999 (7.9516)	Learning Rate [0.00125]
15: TRAIN [0][290/3416]	Time 0.049 (0.057)	Data 0.00085 (0.00095)	Tok/s 32386 (52666)	Loss/tok 5.6757 (7.9591)	Learning Rate [0.00125]
7: TRAIN [0][290/3416]	Time 0.050 (0.057)	Data 0.00087 (0.00092)	Tok/s 30874 (51920)	Loss/tok 5.8133 (7.9600)	Learning Rate [0.00125]
6: TRAIN [0][290/3416]	Time 0.050 (0.057)	Data 0.00091 (0.00097)	Tok/s 30885 (51801)	Loss/tok 5.7792 (7.9568)	Learning Rate [0.00125]
8: TRAIN [0][290/3416]	Time 0.050 (0.057)	Data 0.00091 (0.00101)	Tok/s 30863 (52028)	Loss/tok 5.6186 (7.9572)	Learning Rate [0.00125]
13: TRAIN [0][290/3416]	Time 0.050 (0.057)	Data 0.00106 (0.00100)	Tok/s 32308 (52414)	Loss/tok 5.5973 (7.9597)	Learning Rate [0.00125]
12: TRAIN [0][290/3416]	Time 0.050 (0.057)	Data 0.00099 (0.00101)	Tok/s 32217 (52313)	Loss/tok 5.7391 (7.9585)	Learning Rate [0.00125]
10: TRAIN [0][290/3416]	Time 0.050 (0.057)	Data 0.00090 (0.00099)	Tok/s 30907 (52153)	Loss/tok 5.6488 (7.9627)	Learning Rate [0.00125]
11: TRAIN [0][290/3416]	Time 0.050 (0.057)	Data 0.00094 (0.00099)	Tok/s 31890 (52209)	Loss/tok 5.6935 (7.9562)	Learning Rate [0.00125]
9: TRAIN [0][290/3416]	Time 0.050 (0.057)	Data 0.00085 (0.00097)	Tok/s 30886 (52094)	Loss/tok 5.5348 (7.9548)	Learning Rate [0.00125]
14: TRAIN [0][290/3416]	Time 0.050 (0.057)	Data 0.00094 (0.00099)	Tok/s 32301 (52549)	Loss/tok 5.6616 (7.9589)	Learning Rate [0.00125]
7: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00092 (0.00091)	Tok/s 32755 (51498)	Loss/tok 5.6144 (7.9169)	Learning Rate [0.00125]
6: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00096 (0.00097)	Tok/s 32660 (51380)	Loss/tok 5.5857 (7.9138)	Learning Rate [0.00125]
9: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00091 (0.00097)	Tok/s 32757 (51668)	Loss/tok 5.6641 (7.9130)	Learning Rate [0.00125]
8: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00096 (0.00101)	Tok/s 32723 (51604)	Loss/tok 5.5587 (7.9132)	Learning Rate [0.00125]
4: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00095 (0.00096)	Tok/s 32616 (51159)	Loss/tok 5.6137 (7.9195)	Learning Rate [0.00125]
5: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00100 (0.00096)	Tok/s 32656 (51275)	Loss/tok 5.6950 (7.9268)	Learning Rate [0.00125]
10: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00093 (0.00099)	Tok/s 32723 (51726)	Loss/tok 5.5980 (7.9212)	Learning Rate [0.00125]
11: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00107 (0.00099)	Tok/s 32892 (51784)	Loss/tok 5.3854 (7.9123)	Learning Rate [0.00125]
3: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00112 (0.00100)	Tok/s 32604 (51033)	Loss/tok 5.6117 (7.9158)	Learning Rate [0.00125]
2: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00103 (0.00102)	Tok/s 32602 (50919)	Loss/tok 5.7450 (7.9107)	Learning Rate [0.00125]
12: TRAIN [0][300/3416]	Time 0.048 (0.057)	Data 0.00126 (0.00101)	Tok/s 34343 (51889)	Loss/tok 5.5844 (7.9173)	Learning Rate [0.00125]
0: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00093 (0.00091)	Tok/s 32631 (50650)	Loss/tok 5.6503 (7.9155)	Learning Rate [0.00125]
1: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00099 (0.00094)	Tok/s 32623 (50775)	Loss/tok 5.6498 (7.9146)	Learning Rate [0.00125]
15: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00096 (0.00095)	Tok/s 33931 (52238)	Loss/tok 5.7899 (7.9172)	Learning Rate [0.00125]
13: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00103 (0.00101)	Tok/s 33960 (51995)	Loss/tok 5.3218 (7.9167)	Learning Rate [0.00125]
14: TRAIN [0][300/3416]	Time 0.049 (0.057)	Data 0.00102 (0.00099)	Tok/s 33926 (52127)	Loss/tok 5.7436 (7.9169)	Learning Rate [0.00125]
3: Upscaling, new scale: 256.0
4: Upscaling, new scale: 256.0
1: Upscaling, new scale: 256.0
5: Upscaling, new scale: 256.0
0: Upscaling, new scale: 256.0
15: Upscaling, new scale: 256.0
6: Upscaling, new scale: 256.0
7: Upscaling, new scale: 256.0
14: Upscaling, new scale: 256.0
8: Upscaling, new scale: 256.0
13: Upscaling, new scale: 256.0
10: Upscaling, new scale: 256.0
9: Upscaling, new scale: 256.0
11: Upscaling, new scale: 256.0
2: Upscaling, new scale: 256.0
12: Upscaling, new scale: 256.0
4: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00090 (0.00096)	Tok/s 62260 (51303)	Loss/tok 6.2408 (7.8583)	Learning Rate [0.00125]
1: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00083 (0.00094)	Tok/s 62096 (50931)	Loss/tok 6.3106 (7.8542)	Learning Rate [0.00125]
5: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00105 (0.00097)	Tok/s 62296 (51423)	Loss/tok 6.4304 (7.8696)	Learning Rate [0.00125]
0: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00093 (0.00091)	Tok/s 61633 (50809)	Loss/tok 6.3684 (7.8566)	Learning Rate [0.00125]
3: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00116 (0.00100)	Tok/s 62189 (51181)	Loss/tok 6.3042 (7.8568)	Learning Rate [0.00125]
2: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00106 (0.00102)	Tok/s 62099 (51070)	Loss/tok 6.2679 (7.8501)	Learning Rate [0.00125]
15: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00077 (0.00095)	Tok/s 62152 (52374)	Loss/tok 6.4735 (7.8583)	Learning Rate [0.00125]
14: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00088 (0.00099)	Tok/s 61960 (52263)	Loss/tok 6.4269 (7.8578)	Learning Rate [0.00125]
6: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00096 (0.00097)	Tok/s 62144 (51523)	Loss/tok 6.3450 (7.8547)	Learning Rate [0.00125]
7: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00087 (0.00091)	Tok/s 62147 (51637)	Loss/tok 6.3715 (7.8574)	Learning Rate [0.00125]
9: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00089 (0.00097)	Tok/s 61931 (51803)	Loss/tok 6.5397 (7.8550)	Learning Rate [0.00125]
13: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00109 (0.00101)	Tok/s 61914 (52131)	Loss/tok 6.5440 (7.8571)	Learning Rate [0.00125]
8: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00106 (0.00101)	Tok/s 61926 (51742)	Loss/tok 6.3239 (7.8516)	Learning Rate [0.00125]
12: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00096 (0.00101)	Tok/s 61884 (52028)	Loss/tok 6.3795 (7.8576)	Learning Rate [0.00125]
10: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00094 (0.00099)	Tok/s 61851 (51865)	Loss/tok 6.6569 (7.8632)	Learning Rate [0.00125]
11: TRAIN [0][310/3416]	Time 0.069 (0.057)	Data 0.00113 (0.00099)	Tok/s 61932 (51922)	Loss/tok 6.2629 (7.8490)	Learning Rate [0.00125]
14: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00102 (0.00099)	Tok/s 77613 (52315)	Loss/tok 6.4791 (7.8045)	Learning Rate [0.00125]
0: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00086 (0.00092)	Tok/s 75629 (50881)	Loss/tok 6.3938 (7.8021)	Learning Rate [0.00125]
15: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00090 (0.00095)	Tok/s 77443 (52425)	Loss/tok 6.3080 (7.8043)	Learning Rate [0.00125]
1: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00091 (0.00094)	Tok/s 76325 (51001)	Loss/tok 6.2332 (7.7993)	Learning Rate [0.00125]
4: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00102 (0.00096)	Tok/s 76428 (51362)	Loss/tok 6.2254 (7.8018)	Learning Rate [0.00125]
3: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00119 (0.00100)	Tok/s 76408 (51244)	Loss/tok 6.2283 (7.7991)	Learning Rate [0.00125]
5: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00103 (0.00097)	Tok/s 76436 (51478)	Loss/tok 6.2109 (7.8132)	Learning Rate [0.00125]
12: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00094 (0.00101)	Tok/s 77466 (52078)	Loss/tok 6.2523 (7.8040)	Learning Rate [0.00125]
11: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00114 (0.00100)	Tok/s 77482 (51973)	Loss/tok 6.2956 (7.7944)	Learning Rate [0.00125]
6: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00098 (0.00097)	Tok/s 76456 (51576)	Loss/tok 6.3359 (7.8000)	Learning Rate [0.00125]
13: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00113 (0.00101)	Tok/s 77376 (52185)	Loss/tok 6.2858 (7.8005)	Learning Rate [0.00125]
7: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00088 (0.00091)	Tok/s 76478 (51686)	Loss/tok 6.2771 (7.8025)	Learning Rate [0.00125]
10: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00095 (0.00099)	Tok/s 77443 (51917)	Loss/tok 6.1715 (7.8079)	Learning Rate [0.00125]
8: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00098 (0.00102)	Tok/s 76561 (51789)	Loss/tok 6.0766 (7.7970)	Learning Rate [0.00125]
9: TRAIN [0][320/3416]	Time 0.070 (0.057)	Data 0.00098 (0.00097)	Tok/s 76628 (51852)	Loss/tok 6.1959 (7.8004)	Learning Rate [0.00125]
2: TRAIN [0][320/3416]	Time 0.071 (0.057)	Data 0.00103 (0.00103)	Tok/s 76023 (51135)	Loss/tok 6.4095 (7.7970)	Learning Rate [0.00125]
4: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00097 (0.00096)	Tok/s 62217 (51375)	Loss/tok 6.2045 (7.7488)	Learning Rate [0.00125]
3: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00107 (0.00101)	Tok/s 62125 (51256)	Loss/tok 6.1872 (7.7475)	Learning Rate [0.00125]
5: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00098 (0.00097)	Tok/s 62160 (51489)	Loss/tok 6.1556 (7.7597)	Learning Rate [0.00125]
2: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00100 (0.00102)	Tok/s 62027 (51146)	Loss/tok 6.3266 (7.7456)	Learning Rate [0.00125]
1: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00087 (0.00094)	Tok/s 62016 (51012)	Loss/tok 6.2228 (7.7478)	Learning Rate [0.00125]
0: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00082 (0.00092)	Tok/s 62053 (50895)	Loss/tok 6.1601 (7.7495)	Learning Rate [0.00125]
6: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00100 (0.00097)	Tok/s 62215 (51587)	Loss/tok 6.2209 (7.7460)	Learning Rate [0.00125]
7: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00083 (0.00091)	Tok/s 62192 (51696)	Loss/tok 6.0511 (7.7496)	Learning Rate [0.00125]
8: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00095 (0.00102)	Tok/s 62088 (51796)	Loss/tok 6.1876 (7.7442)	Learning Rate [0.00125]
15: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00090 (0.00095)	Tok/s 62769 (52427)	Loss/tok 6.1814 (7.7527)	Learning Rate [0.00125]
14: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00082 (0.00098)	Tok/s 61993 (52317)	Loss/tok 6.2410 (7.7533)	Learning Rate [0.00125]
12: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00091 (0.00101)	Tok/s 61893 (52080)	Loss/tok 6.3916 (7.7515)	Learning Rate [0.00125]
9: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00090 (0.00097)	Tok/s 62017 (51857)	Loss/tok 6.2186 (7.7463)	Learning Rate [0.00125]
13: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00103 (0.00101)	Tok/s 61886 (52188)	Loss/tok 6.1690 (7.7485)	Learning Rate [0.00125]
11: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00106 (0.00100)	Tok/s 61852 (51974)	Loss/tok 6.2453 (7.7438)	Learning Rate [0.00125]
10: TRAIN [0][330/3416]	Time 0.068 (0.057)	Data 0.00094 (0.00100)	Tok/s 61857 (51919)	Loss/tok 6.2775 (7.7561)	Learning Rate [0.00125]
2: TRAIN [0][340/3416]	Time 0.033 (0.057)	Data 0.00096 (0.00102)	Tok/s 15773 (51221)	Loss/tok 3.9800 (7.6926)	Learning Rate [0.00125]
1: TRAIN [0][340/3416]	Time 0.033 (0.057)	Data 0.00091 (0.00094)	Tok/s 12426 (51079)	Loss/tok 3.4490 (7.6932)	Learning Rate [0.00125]
0: TRAIN [0][340/3416]	Time 0.033 (0.057)	Data 0.00090 (0.00092)	Tok/s 9642 (50957)	Loss/tok 2.2948 (7.6946)	Learning Rate [0.00125]
4: TRAIN [0][340/3416]	Time 0.033 (0.057)	Data 0.00095 (0.00096)	Tok/s 18498 (51454)	Loss/tok 4.1479 (7.6941)	Learning Rate [0.00125]
3: TRAIN [0][340/3416]	Time 0.033 (0.057)	Data 0.00126 (0.00101)	Tok/s 17614 (51332)	Loss/tok 3.1404 (7.6939)	Learning Rate [0.00125]
15: TRAIN [0][340/3416]	Time 0.033 (0.057)	Data 0.00093 (0.00095)	Tok/s 28747 (52529)	Loss/tok 3.8959 (7.6959)	Learning Rate [0.00125]
5: TRAIN [0][340/3416]	Time 0.033 (0.057)	Data 0.00100 (0.00097)	Tok/s 21033 (51576)	Loss/tok 4.1922 (7.7042)	Learning Rate [0.00125]
14: TRAIN [0][340/3416]	Time 0.033 (0.057)	Data 0.00098 (0.00098)	Tok/s 26813 (52409)	Loss/tok 4.7301 (7.6989)	Learning Rate [0.00125]
6: TRAIN [0][340/3416]	Time 0.034 (0.057)	Data 0.00097 (0.00097)	Tok/s 22154 (51675)	Loss/tok 4.1889 (7.6876)	Learning Rate [0.00125]
13: TRAIN [0][340/3416]	Time 0.034 (0.057)	Data 0.00097 (0.00101)	Tok/s 26719 (52281)	Loss/tok 4.2294 (7.6941)	Learning Rate [0.00125]
7: TRAIN [0][340/3416]	Time 0.034 (0.057)	Data 0.00092 (0.00091)	Tok/s 23331 (51787)	Loss/tok 4.1455 (7.6934)	Learning Rate [0.00125]
11: TRAIN [0][340/3416]	Time 0.034 (0.057)	Data 0.00114 (0.00100)	Tok/s 24635 (52066)	Loss/tok 3.3625 (7.6879)	Learning Rate [0.00125]
10: TRAIN [0][340/3416]	Time 0.034 (0.057)	Data 0.00095 (0.00100)	Tok/s 24528 (52012)	Loss/tok 3.3965 (7.6995)	Learning Rate [0.00125]
9: TRAIN [0][340/3416]	Time 0.034 (0.057)	Data 0.00093 (0.00097)	Tok/s 24541 (51951)	Loss/tok 3.4855 (7.6891)	Learning Rate [0.00125]
12: TRAIN [0][340/3416]	Time 0.034 (0.057)	Data 0.00119 (0.00101)	Tok/s 26191 (52172)	Loss/tok 4.2773 (7.6954)	Learning Rate [0.00125]
8: TRAIN [0][340/3416]	Time 0.034 (0.057)	Data 0.00113 (0.00102)	Tok/s 24569 (51886)	Loss/tok 3.3188 (7.6870)	Learning Rate [0.00125]
0: TRAIN [0][350/3416]	Time 0.051 (0.057)	Data 0.00095 (0.00092)	Tok/s 51239 (51026)	Loss/tok 5.8309 (7.6429)	Learning Rate [0.00125]
1: TRAIN [0][350/3416]	Time 0.051 (0.057)	Data 0.00096 (0.00094)	Tok/s 51221 (51147)	Loss/tok 5.8858 (7.6413)	Learning Rate [0.00125]
2: TRAIN [0][350/3416]	Time 0.051 (0.057)	Data 0.00095 (0.00102)	Tok/s 51111 (51285)	Loss/tok 5.6221 (7.6412)	Learning Rate [0.00125]
15: TRAIN [0][350/3416]	Time 0.051 (0.057)	Data 0.00103 (0.00095)	Tok/s 52441 (52585)	Loss/tok 5.8492 (7.6429)	Learning Rate [0.00125]
3: TRAIN [0][350/3416]	Time 0.051 (0.057)	Data 0.00102 (0.00101)	Tok/s 50954 (51393)	Loss/tok 5.9340 (7.6414)	Learning Rate [0.00125]
14: TRAIN [0][350/3416]	Time 0.051 (0.057)	Data 0.00128 (0.00098)	Tok/s 52383 (52468)	Loss/tok 5.9619 (7.6470)	Learning Rate [0.00125]
4: TRAIN [0][350/3416]	Time 0.052 (0.057)	Data 0.00099 (0.00096)	Tok/s 50886 (51513)	Loss/tok 6.0171 (7.6428)	Learning Rate [0.00125]
13: TRAIN [0][350/3416]	Time 0.051 (0.057)	Data 0.00094 (0.00101)	Tok/s 52278 (52342)	Loss/tok 5.7998 (7.6409)	Learning Rate [0.00125]
12: TRAIN [0][350/3416]	Time 0.051 (0.057)	Data 0.00097 (0.00101)	Tok/s 52197 (52236)	Loss/tok 5.9234 (7.6415)	Learning Rate [0.00125]
5: TRAIN [0][350/3416]	Time 0.052 (0.057)	Data 0.00098 (0.00097)	Tok/s 51346 (51640)	Loss/tok 5.7728 (7.6524)	Learning Rate [0.00125]
6: TRAIN [0][350/3416]	Time 0.052 (0.057)	Data 0.00099 (0.00097)	Tok/s 51916 (51742)	Loss/tok 5.9434 (7.6343)	Learning Rate [0.00125]
11: TRAIN [0][350/3416]	Time 0.052 (0.057)	Data 0.00100 (0.00100)	Tok/s 52067 (52129)	Loss/tok 5.6755 (7.6363)	Learning Rate [0.00125]
10: TRAIN [0][350/3416]	Time 0.052 (0.057)	Data 0.00107 (0.00100)	Tok/s 51963 (52076)	Loss/tok 5.8552 (7.6468)	Learning Rate [0.00125]
7: TRAIN [0][350/3416]	Time 0.052 (0.057)	Data 0.00092 (0.00091)	Tok/s 51768 (51852)	Loss/tok 5.8078 (7.6406)	Learning Rate [0.00125]
8: TRAIN [0][350/3416]	Time 0.052 (0.057)	Data 0.00104 (0.00102)	Tok/s 51798 (51951)	Loss/tok 5.9526 (7.6345)	Learning Rate [0.00125]
9: TRAIN [0][350/3416]	Time 0.052 (0.057)	Data 0.00095 (0.00097)	Tok/s 51883 (52014)	Loss/tok 5.9607 (7.6364)	Learning Rate [0.00125]
10: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00099 (0.00100)	Tok/s 33379 (51944)	Loss/tok 5.3214 (7.6009)	Learning Rate [0.00125]
9: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00083 (0.00097)	Tok/s 33436 (51881)	Loss/tok 5.1779 (7.5923)	Learning Rate [0.00125]
8: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00094 (0.00102)	Tok/s 33436 (51817)	Loss/tok 5.2669 (7.5889)	Learning Rate [0.00125]
11: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00082 (0.00100)	Tok/s 33244 (51996)	Loss/tok 5.2856 (7.5903)	Learning Rate [0.00125]
7: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00088 (0.00091)	Tok/s 33414 (51721)	Loss/tok 5.2629 (7.5948)	Learning Rate [0.00125]
12: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00094 (0.00101)	Tok/s 33212 (52099)	Loss/tok 5.3877 (7.5961)	Learning Rate [0.00125]
6: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00089 (0.00097)	Tok/s 33410 (51612)	Loss/tok 5.4329 (7.5893)	Learning Rate [0.00125]
5: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00097 (0.00097)	Tok/s 33321 (51503)	Loss/tok 5.3242 (7.6081)	Learning Rate [0.00125]
13: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00099 (0.00101)	Tok/s 34132 (52205)	Loss/tok 5.3688 (7.5972)	Learning Rate [0.00125]
4: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00086 (0.00096)	Tok/s 33247 (51380)	Loss/tok 5.1156 (7.5987)	Learning Rate [0.00125]
2: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00098 (0.00102)	Tok/s 33108 (51155)	Loss/tok 5.2856 (7.5981)	Learning Rate [0.00125]
15: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00090 (0.00095)	Tok/s 34291 (52442)	Loss/tok 5.4130 (7.5998)	Learning Rate [0.00125]
0: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00088 (0.00092)	Tok/s 33009 (50903)	Loss/tok 5.2338 (7.5962)	Learning Rate [0.00125]
3: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00093 (0.00101)	Tok/s 33168 (51261)	Loss/tok 5.2914 (7.5954)	Learning Rate [0.00125]
1: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00090 (0.00094)	Tok/s 33006 (51020)	Loss/tok 5.0553 (7.5968)	Learning Rate [0.00125]
14: TRAIN [0][360/3416]	Time 0.050 (0.057)	Data 0.00092 (0.00098)	Tok/s 34352 (52328)	Loss/tok 5.3130 (7.6019)	Learning Rate [0.00125]
9: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00084 (0.00097)	Tok/s 44765 (51827)	Loss/tok 5.5042 (7.5470)	Learning Rate [0.00125]
10: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00085 (0.00100)	Tok/s 44720 (51891)	Loss/tok 5.3645 (7.5550)	Learning Rate [0.00125]
8: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00092 (0.00102)	Tok/s 44734 (51764)	Loss/tok 5.2647 (7.5427)	Learning Rate [0.00125]
11: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00087 (0.00100)	Tok/s 44602 (51942)	Loss/tok 5.4255 (7.5451)	Learning Rate [0.00125]
7: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00082 (0.00091)	Tok/s 44646 (51668)	Loss/tok 5.5915 (7.5501)	Learning Rate [0.00125]
12: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00212 (0.00101)	Tok/s 44447 (52045)	Loss/tok 5.2753 (7.5509)	Learning Rate [0.00125]
6: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00086 (0.00097)	Tok/s 44536 (51562)	Loss/tok 5.3493 (7.5442)	Learning Rate [0.00125]
13: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00092 (0.00101)	Tok/s 44332 (52154)	Loss/tok 5.3813 (7.5526)	Learning Rate [0.00125]
3: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00095 (0.00101)	Tok/s 44201 (51221)	Loss/tok 5.5320 (7.5508)	Learning Rate [0.00125]
15: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00111 (0.00095)	Tok/s 44168 (52388)	Loss/tok 5.5600 (7.5535)	Learning Rate [0.00125]
0: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00091 (0.00092)	Tok/s 43602 (50866)	Loss/tok 5.3337 (7.5513)	Learning Rate [0.00125]
4: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00093 (0.00096)	Tok/s 44336 (51336)	Loss/tok 5.2272 (7.5527)	Learning Rate [0.00125]
1: TRAIN [0][370/3416]	Time 0.047 (0.057)	Data 0.00094 (0.00094)	Tok/s 43982 (50985)	Loss/tok 5.4893 (7.5517)	Learning Rate [0.00125]
14: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00093 (0.00098)	Tok/s 44257 (52275)	Loss/tok 5.4482 (7.5559)	Learning Rate [0.00125]
2: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00106 (0.00102)	Tok/s 44079 (51116)	Loss/tok 5.4452 (7.5532)	Learning Rate [0.00125]
5: TRAIN [0][370/3416]	Time 0.046 (0.057)	Data 0.00121 (0.00097)	Tok/s 44479 (51455)	Loss/tok 5.4917 (7.5620)	Learning Rate [0.00125]
10: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00108 (0.00100)	Tok/s 77752 (52029)	Loss/tok 5.9048 (7.5012)	Learning Rate [0.00125]
9: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00091 (0.00096)	Tok/s 76922 (51962)	Loss/tok 5.9625 (7.4955)	Learning Rate [0.00125]
8: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00096 (0.00102)	Tok/s 76976 (51900)	Loss/tok 5.8510 (7.4892)	Learning Rate [0.00125]
11: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00102 (0.00100)	Tok/s 77806 (52080)	Loss/tok 5.9059 (7.4936)	Learning Rate [0.00125]
12: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00094 (0.00101)	Tok/s 77856 (52180)	Loss/tok 5.8905 (7.4981)	Learning Rate [0.00125]
7: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00087 (0.00091)	Tok/s 76980 (51804)	Loss/tok 6.0429 (7.4980)	Learning Rate [0.00125]
13: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00091 (0.00101)	Tok/s 77889 (52290)	Loss/tok 6.0918 (7.5010)	Learning Rate [0.00125]
5: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00094 (0.00097)	Tok/s 76974 (51598)	Loss/tok 5.8873 (7.5086)	Learning Rate [0.00125]
0: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00079 (0.00092)	Tok/s 76254 (51012)	Loss/tok 5.9682 (7.4971)	Learning Rate [0.00125]
3: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00097 (0.00101)	Tok/s 77074 (51364)	Loss/tok 5.9752 (7.4978)	Learning Rate [0.00125]
15: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00082 (0.00094)	Tok/s 77823 (52523)	Loss/tok 6.0778 (7.5013)	Learning Rate [0.00125]
4: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00082 (0.00096)	Tok/s 76960 (51477)	Loss/tok 6.1175 (7.5013)	Learning Rate [0.00125]
2: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00084 (0.00102)	Tok/s 77034 (51264)	Loss/tok 6.0072 (7.5003)	Learning Rate [0.00125]
1: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00104 (0.00094)	Tok/s 76995 (51135)	Loss/tok 6.1711 (7.5008)	Learning Rate [0.00125]
6: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00092 (0.00097)	Tok/s 76878 (51700)	Loss/tok 5.8951 (7.4909)	Learning Rate [0.00125]
14: TRAIN [0][380/3416]	Time 0.070 (0.057)	Data 0.00090 (0.00098)	Tok/s 77892 (52410)	Loss/tok 5.8068 (7.5017)	Learning Rate [0.00125]
10: Gradient norm: inf
11: Gradient norm: inf
9: Gradient norm: inf
10: Skipped batch, new scale: 128.0
11: Skipped batch, new scale: 128.0
9: Skipped batch, new scale: 128.0
8: Gradient norm: inf
12: Gradient norm: inf
8: Skipped batch, new scale: 128.0
7: Gradient norm: inf
12: Skipped batch, new scale: 128.0
13: Gradient norm: inf
7: Skipped batch, new scale: 128.0
6: Gradient norm: inf
13: Skipped batch, new scale: 128.0
9: TRAIN [0][390/3416]	Time 0.069 (0.057)	Data 0.00106 (0.00096)	Tok/s 84514 (52034)	Loss/tok 5.6999 (7.4445)	Learning Rate [0.00125]
14: Gradient norm: inf
10: TRAIN [0][390/3416]	Time 0.069 (0.057)	Data 0.00090 (0.00100)	Tok/s 84208 (52101)	Loss/tok 5.9153 (7.4516)	Learning Rate [0.00125]
6: Skipped batch, new scale: 128.0
11: TRAIN [0][390/3416]	Time 0.069 (0.057)	Data 0.00096 (0.00100)	Tok/s 85054 (52153)	Loss/tok 5.7166 (7.4451)	Learning Rate [0.00125]
5: Gradient norm: inf
15: Gradient norm: inf
8: TRAIN [0][390/3416]	Time 0.069 (0.057)	Data 0.00099 (0.00102)	Tok/s 83827 (51974)	Loss/tok 5.8482 (7.4399)	Learning Rate [0.00125]
12: TRAIN [0][390/3416]	Time 0.069 (0.057)	Data 0.00092 (0.00101)	Tok/s 84931 (52255)	Loss/tok 5.8072 (7.4471)	Learning Rate [0.00125]
14: Skipped batch, new scale: 128.0
5: Skipped batch, new scale: 128.0
4: Gradient norm: inf
15: Skipped batch, new scale: 128.0
7: TRAIN [0][390/3416]	Time 0.070 (0.057)	Data 0.00094 (0.00091)	Tok/s 83722 (51880)	Loss/tok 5.7984 (7.4480)	Learning Rate [0.00125]
13: TRAIN [0][390/3416]	Time 0.069 (0.057)	Data 0.00089 (0.00101)	Tok/s 84835 (52366)	Loss/tok 5.8277 (7.4516)	Learning Rate [0.00125]
3: Gradient norm: inf
4: Skipped batch, new scale: 128.0
1: Gradient norm: inf
6: TRAIN [0][390/3416]	Time 0.070 (0.057)	Data 0.00089 (0.00097)	Tok/s 83630 (51777)	Loss/tok 5.8779 (7.4427)	Learning Rate [0.00125]
2: Gradient norm: inf
3: Skipped batch, new scale: 128.0
1: Skipped batch, new scale: 128.0
0: Gradient norm: inf
5: TRAIN [0][390/3416]	Time 0.070 (0.057)	Data 0.00089 (0.00098)	Tok/s 82941 (51675)	Loss/tok 5.7996 (7.4599)	Learning Rate [0.00125]
14: TRAIN [0][390/3416]	Time 0.069 (0.057)	Data 0.00094 (0.00098)	Tok/s 85124 (52482)	Loss/tok 5.6797 (7.4521)	Learning Rate [0.00125]
2: Skipped batch, new scale: 128.0
15: TRAIN [0][390/3416]	Time 0.070 (0.057)	Data 0.00088 (0.00094)	Tok/s 85240 (52595)	Loss/tok 5.6215 (7.4515)	Learning Rate [0.00125]
0: Skipped batch, new scale: 128.0
1: TRAIN [0][390/3416]	Time 0.070 (0.057)	Data 0.00081 (0.00094)	Tok/s 82489 (51214)	Loss/tok 5.7477 (7.4511)	Learning Rate [0.00125]
3: TRAIN [0][390/3416]	Time 0.070 (0.057)	Data 0.00093 (0.00101)	Tok/s 82367 (51440)	Loss/tok 5.5935 (7.4443)	Learning Rate [0.00125]
4: TRAIN [0][390/3416]	Time 0.070 (0.057)	Data 0.00088 (0.00096)	Tok/s 82323 (51554)	Loss/tok 5.7669 (7.4516)	Learning Rate [0.00125]
0: TRAIN [0][390/3416]	Time 0.070 (0.057)	Data 0.00090 (0.00092)	Tok/s 82448 (51089)	Loss/tok 5.7194 (7.4459)	Learning Rate [0.00125]
2: TRAIN [0][390/3416]	Time 0.069 (0.057)	Data 0.00120 (0.00102)	Tok/s 83550 (51341)	Loss/tok 5.8354 (7.4511)	Learning Rate [0.00125]
4: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00095 (0.00096)	Tok/s 52503 (51613)	Loss/tok 5.5821 (7.4053)	Learning Rate [0.00125]
6: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00107 (0.00097)	Tok/s 52370 (51841)	Loss/tok 5.6583 (7.3962)	Learning Rate [0.00125]
7: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00104 (0.00091)	Tok/s 52114 (51946)	Loss/tok 5.6364 (7.3997)	Learning Rate [0.00125]
10: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00111 (0.00100)	Tok/s 53294 (52178)	Loss/tok 5.6972 (7.4031)	Learning Rate [0.00125]
11: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00103 (0.00100)	Tok/s 53282 (52228)	Loss/tok 5.5479 (7.3976)	Learning Rate [0.00125]
12: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00100 (0.00101)	Tok/s 53264 (52331)	Loss/tok 5.3724 (7.3986)	Learning Rate [0.00125]
8: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00114 (0.00102)	Tok/s 53464 (52044)	Loss/tok 5.6891 (7.3936)	Learning Rate [0.00125]
2: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00102 (0.00102)	Tok/s 52546 (51397)	Loss/tok 5.5510 (7.4033)	Learning Rate [0.00125]
3: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00113 (0.00101)	Tok/s 52376 (51497)	Loss/tok 5.3994 (7.3949)	Learning Rate [0.00125]
5: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00103 (0.00097)	Tok/s 52453 (51739)	Loss/tok 5.4261 (7.4107)	Learning Rate [0.00125]
15: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00097 (0.00094)	Tok/s 53463 (52685)	Loss/tok 5.4025 (7.4025)	Learning Rate [0.00125]
0: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00091 (0.00092)	Tok/s 52429 (51136)	Loss/tok 5.3528 (7.3976)	Learning Rate [0.00125]
14: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00099 (0.00098)	Tok/s 53470 (52563)	Loss/tok 5.5891 (7.4046)	Learning Rate [0.00125]
13: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00100 (0.00101)	Tok/s 53379 (52443)	Loss/tok 5.2265 (7.4018)	Learning Rate [0.00125]
1: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00085 (0.00093)	Tok/s 52540 (51266)	Loss/tok 5.3581 (7.4017)	Learning Rate [0.00125]
9: TRAIN [0][400/3416]	Time 0.050 (0.057)	Data 0.00100 (0.00097)	Tok/s 53321 (52105)	Loss/tok 5.5125 (7.3958)	Learning Rate [0.00125]
1: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00090 (0.00093)	Tok/s 30137 (51345)	Loss/tok 4.6154 (7.3534)	Learning Rate [0.00125]
3: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00098 (0.00101)	Tok/s 31468 (51574)	Loss/tok 4.4198 (7.3469)	Learning Rate [0.00125]
4: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00101 (0.00096)	Tok/s 31471 (51692)	Loss/tok 4.4556 (7.3552)	Learning Rate [0.00125]
0: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00088 (0.00092)	Tok/s 30081 (51217)	Loss/tok 4.2836 (7.3483)	Learning Rate [0.00125]
2: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00090 (0.00102)	Tok/s 30180 (51473)	Loss/tok 4.2060 (7.3532)	Learning Rate [0.00125]
15: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00091 (0.00094)	Tok/s 32663 (52766)	Loss/tok 4.6168 (7.3535)	Learning Rate [0.00125]
13: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00100 (0.00101)	Tok/s 31594 (52522)	Loss/tok 4.7497 (7.3539)	Learning Rate [0.00125]
14: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00089 (0.00098)	Tok/s 31552 (52640)	Loss/tok 4.4414 (7.3568)	Learning Rate [0.00125]
5: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00085 (0.00098)	Tok/s 31423 (51818)	Loss/tok 4.4853 (7.3616)	Learning Rate [0.00125]
6: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00106 (0.00097)	Tok/s 31495 (51919)	Loss/tok 4.5981 (7.3482)	Learning Rate [0.00125]
12: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00095 (0.00100)	Tok/s 31566 (52409)	Loss/tok 4.5902 (7.3487)	Learning Rate [0.00125]
7: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00089 (0.00091)	Tok/s 31470 (52022)	Loss/tok 4.7860 (7.3525)	Learning Rate [0.00125]
10: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00099 (0.00100)	Tok/s 31525 (52252)	Loss/tok 4.6725 (7.3542)	Learning Rate [0.00125]
11: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00097 (0.00100)	Tok/s 31552 (52305)	Loss/tok 4.5249 (7.3485)	Learning Rate [0.00125]
8: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00108 (0.00102)	Tok/s 31430 (52120)	Loss/tok 4.1680 (7.3455)	Learning Rate [0.00125]
9: TRAIN [0][410/3416]	Time 0.045 (0.057)	Data 0.00098 (0.00097)	Tok/s 31490 (52180)	Loss/tok 4.5674 (7.3484)	Learning Rate [0.00125]
1: TRAIN [0][420/3416]	Time 0.063 (0.057)	Data 0.00084 (0.00093)	Tok/s 53733 (51355)	Loss/tok 5.7976 (7.3103)	Learning Rate [0.00125]
15: TRAIN [0][420/3416]	Time 0.063 (0.057)	Data 0.00094 (0.00094)	Tok/s 54547 (52765)	Loss/tok 5.6032 (7.3120)	Learning Rate [0.00125]
2: TRAIN [0][420/3416]	Time 0.063 (0.057)	Data 0.00088 (0.00102)	Tok/s 53741 (51481)	Loss/tok 5.5333 (7.3107)	Learning Rate [0.00125]
0: TRAIN [0][420/3416]	Time 0.063 (0.057)	Data 0.00088 (0.00092)	Tok/s 53590 (51228)	Loss/tok 5.6371 (7.3039)	Learning Rate [0.00125]
3: TRAIN [0][420/3416]	Time 0.063 (0.057)	Data 0.00088 (0.00100)	Tok/s 53639 (51580)	Loss/tok 5.4225 (7.3035)	Learning Rate [0.00125]
4: TRAIN [0][420/3416]	Time 0.062 (0.057)	Data 0.00113 (0.00096)	Tok/s 54372 (51695)	Loss/tok 5.5534 (7.3123)	Learning Rate [0.00125]
13: TRAIN [0][420/3416]	Time 0.064 (0.057)	Data 0.00094 (0.00100)	Tok/s 54375 (52525)	Loss/tok 5.4158 (7.3112)	Learning Rate [0.00125]
5: TRAIN [0][420/3416]	Time 0.063 (0.057)	Data 0.00099 (0.00098)	Tok/s 53591 (51818)	Loss/tok 5.7026 (7.3194)	Learning Rate [0.00125]
14: TRAIN [0][420/3416]	Time 0.064 (0.057)	Data 0.00098 (0.00098)	Tok/s 54417 (52640)	Loss/tok 5.6079 (7.3125)	Learning Rate [0.00125]
11: TRAIN [0][420/3416]	Time 0.064 (0.057)	Data 0.00097 (0.00100)	Tok/s 54124 (52302)	Loss/tok 5.5681 (7.3079)	Learning Rate [0.00125]
6: TRAIN [0][420/3416]	Time 0.064 (0.057)	Data 0.00090 (0.00097)	Tok/s 53394 (51917)	Loss/tok 5.5274 (7.3044)	Learning Rate [0.00125]
10: TRAIN [0][420/3416]	Time 0.064 (0.057)	Data 0.00103 (0.00100)	Tok/s 54152 (52250)	Loss/tok 5.4926 (7.3121)	Learning Rate [0.00125]
12: TRAIN [0][420/3416]	Time 0.064 (0.057)	Data 0.00096 (0.00100)	Tok/s 54234 (52408)	Loss/tok 5.7396 (7.3066)	Learning Rate [0.00125]
8: TRAIN [0][420/3416]	Time 0.064 (0.057)	Data 0.00095 (0.00102)	Tok/s 53208 (52119)	Loss/tok 5.0780 (7.3020)	Learning Rate [0.00125]
9: TRAIN [0][420/3416]	Time 0.064 (0.057)	Data 0.00107 (0.00097)	Tok/s 53531 (52178)	Loss/tok 5.6323 (7.3068)	Learning Rate [0.00125]
7: TRAIN [0][420/3416]	Time 0.063 (0.057)	Data 0.00108 (0.00091)	Tok/s 54052 (52024)	Loss/tok 5.4332 (7.3095)	Learning Rate [0.00125]
8: TRAIN [0][430/3416]	Time 0.063 (0.057)	Data 0.00100 (0.00102)	Tok/s 53234 (52073)	Loss/tok 5.4541 (7.2624)	Learning Rate [0.00125]
9: TRAIN [0][430/3416]	Time 0.062 (0.057)	Data 0.00100 (0.00097)	Tok/s 53275 (52133)	Loss/tok 5.5903 (7.2674)	Learning Rate [0.00125]
7: TRAIN [0][430/3416]	Time 0.063 (0.057)	Data 0.00090 (0.00091)	Tok/s 53184 (51978)	Loss/tok 5.4291 (7.2702)	Learning Rate [0.00125]
10: TRAIN [0][430/3416]	Time 0.062 (0.057)	Data 0.00112 (0.00100)	Tok/s 53281 (52204)	Loss/tok 5.5947 (7.2719)	Learning Rate [0.00125]
6: TRAIN [0][430/3416]	Time 0.063 (0.057)	Data 0.00098 (0.00097)	Tok/s 53053 (51873)	Loss/tok 5.4419 (7.2643)	Learning Rate [0.00125]
5: TRAIN [0][430/3416]	Time 0.063 (0.057)	Data 0.00090 (0.00098)	Tok/s 52942 (51776)	Loss/tok 5.4960 (7.2802)	Learning Rate [0.00125]
4: TRAIN [0][430/3416]	Time 0.063 (0.057)	Data 0.00085 (0.00096)	Tok/s 52870 (51656)	Loss/tok 5.5788 (7.2716)	Learning Rate [0.00125]
11: TRAIN [0][430/3416]	Time 0.062 (0.057)	Data 0.00105 (0.00100)	Tok/s 53282 (52257)	Loss/tok 5.4599 (7.2686)	Learning Rate [0.00125]
13: TRAIN [0][430/3416]	Time 0.063 (0.057)	Data 0.00095 (0.00100)	Tok/s 53163 (52475)	Loss/tok 5.4242 (7.2718)	Learning Rate [0.00125]
12: TRAIN [0][430/3416]	Time 0.063 (0.057)	Data 0.00097 (0.00100)	Tok/s 53181 (52361)	Loss/tok 5.2608 (7.2676)	Learning Rate [0.00125]
3: TRAIN [0][430/3416]	Time 0.063 (0.057)	Data 0.00096 (0.00100)	Tok/s 52869 (51543)	Loss/tok 5.4955 (7.2640)	Learning Rate [0.00125]
2: TRAIN [0][430/3416]	Time 0.063 (0.057)	Data 0.00083 (0.00101)	Tok/s 52875 (51446)	Loss/tok 5.5774 (7.2717)	Learning Rate [0.00125]
0: TRAIN [0][430/3416]	Time 0.063 (0.057)	Data 0.00093 (0.00092)	Tok/s 52901 (51195)	Loss/tok 5.6215 (7.2635)	Learning Rate [0.00125]
1: TRAIN [0][430/3416]	Time 0.063 (0.057)	Data 0.00087 (0.00093)	Tok/s 52869 (51323)	Loss/tok 5.6369 (7.2707)	Learning Rate [0.00125]
14: TRAIN [0][430/3416]	Time 0.063 (0.057)	Data 0.00094 (0.00098)	Tok/s 52991 (52587)	Loss/tok 5.8306 (7.2734)	Learning Rate [0.00125]
15: TRAIN [0][430/3416]	Time 0.063 (0.057)	Data 0.00094 (0.00094)	Tok/s 52937 (52709)	Loss/tok 5.7535 (7.2748)	Learning Rate [0.00125]
5: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00091 (0.00097)	Tok/s 56594 (52059)	Loss/tok 5.4908 (7.2251)	Learning Rate [0.00125]
6: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00103 (0.00097)	Tok/s 56573 (52155)	Loss/tok 5.3942 (7.2080)	Learning Rate [0.00125]
4: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00095 (0.00096)	Tok/s 56614 (51938)	Loss/tok 5.4696 (7.2163)	Learning Rate [0.00125]
8: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00104 (0.00102)	Tok/s 56415 (52354)	Loss/tok 5.5074 (7.2069)	Learning Rate [0.00125]
3: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00096 (0.00100)	Tok/s 56589 (51826)	Loss/tok 5.4921 (7.2081)	Learning Rate [0.00125]
10: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00094 (0.00100)	Tok/s 56209 (52485)	Loss/tok 5.5583 (7.2143)	Learning Rate [0.00125]
1: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00089 (0.00093)	Tok/s 55957 (51610)	Loss/tok 5.6090 (7.2150)	Learning Rate [0.00125]
11: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00094 (0.00100)	Tok/s 56148 (52541)	Loss/tok 5.3412 (7.2124)	Learning Rate [0.00125]
0: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00086 (0.00092)	Tok/s 55409 (51481)	Loss/tok 5.5171 (7.2083)	Learning Rate [0.00125]
9: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00104 (0.00097)	Tok/s 56328 (52412)	Loss/tok 5.4868 (7.2122)	Learning Rate [0.00125]
2: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00096 (0.00101)	Tok/s 56533 (51732)	Loss/tok 5.7360 (7.2153)	Learning Rate [0.00125]
15: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00087 (0.00094)	Tok/s 56290 (52993)	Loss/tok 5.7259 (7.2199)	Learning Rate [0.00125]
12: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00095 (0.00100)	Tok/s 56126 (52644)	Loss/tok 5.7280 (7.2130)	Learning Rate [0.00125]
13: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00097 (0.00100)	Tok/s 56116 (52756)	Loss/tok 5.4733 (7.2170)	Learning Rate [0.00125]
14: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00091 (0.00098)	Tok/s 56167 (52868)	Loss/tok 5.4241 (7.2175)	Learning Rate [0.00125]
7: TRAIN [0][440/3416]	Time 0.067 (0.057)	Data 0.00082 (0.00091)	Tok/s 56067 (52260)	Loss/tok 5.4009 (7.2137)	Learning Rate [0.00125]
5: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00084 (0.00097)	Tok/s 34599 (51902)	Loss/tok 4.5469 (7.1891)	Learning Rate [0.00125]
6: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00095 (0.00097)	Tok/s 34584 (51999)	Loss/tok 4.5078 (7.1719)	Learning Rate [0.00125]
4: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00082 (0.00095)	Tok/s 34468 (51780)	Loss/tok 4.7820 (7.1792)	Learning Rate [0.00125]
10: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00096 (0.00100)	Tok/s 34505 (52329)	Loss/tok 4.8367 (7.1776)	Learning Rate [0.00125]
7: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00090 (0.00091)	Tok/s 34627 (52105)	Loss/tok 4.6741 (7.1780)	Learning Rate [0.00125]
8: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00106 (0.00102)	Tok/s 34570 (52197)	Loss/tok 4.6130 (7.1703)	Learning Rate [0.00125]
9: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00089 (0.00097)	Tok/s 34567 (52255)	Loss/tok 4.8698 (7.1770)	Learning Rate [0.00125]
3: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00092 (0.00100)	Tok/s 34358 (51663)	Loss/tok 4.8226 (7.1741)	Learning Rate [0.00125]
2: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00089 (0.00101)	Tok/s 34285 (51568)	Loss/tok 4.9459 (7.1813)	Learning Rate [0.00125]
1: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00092 (0.00093)	Tok/s 34230 (51442)	Loss/tok 4.7164 (7.1818)	Learning Rate [0.00125]
0: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00088 (0.00092)	Tok/s 34168 (51307)	Loss/tok 4.7727 (7.1735)	Learning Rate [0.00125]
15: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00082 (0.00094)	Tok/s 34188 (52843)	Loss/tok 4.7741 (7.1838)	Learning Rate [0.00125]
11: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00092 (0.00100)	Tok/s 34344 (52387)	Loss/tok 4.8370 (7.1764)	Learning Rate [0.00125]
12: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00087 (0.00100)	Tok/s 34209 (52492)	Loss/tok 4.5241 (7.1776)	Learning Rate [0.00125]
14: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00093 (0.00098)	Tok/s 34143 (52720)	Loss/tok 4.4942 (7.1816)	Learning Rate [0.00125]
13: TRAIN [0][450/3416]	Time 0.052 (0.057)	Data 0.00102 (0.00100)	Tok/s 34202 (52607)	Loss/tok 4.7172 (7.1817)	Learning Rate [0.00125]
12: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00095 (0.00100)	Tok/s 71274 (52509)	Loss/tok 5.5851 (7.1369)	Learning Rate [0.00125]
13: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00092 (0.00100)	Tok/s 71314 (52623)	Loss/tok 5.5959 (7.1417)	Learning Rate [0.00125]
11: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00092 (0.00100)	Tok/s 71172 (52406)	Loss/tok 5.5026 (7.1357)	Learning Rate [0.00125]
10: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00093 (0.00100)	Tok/s 70407 (52344)	Loss/tok 5.6045 (7.1376)	Learning Rate [0.00125]
9: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00100 (0.00097)	Tok/s 70224 (52271)	Loss/tok 5.4685 (7.1369)	Learning Rate [0.00125]
14: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00096 (0.00098)	Tok/s 71282 (52735)	Loss/tok 5.4656 (7.1410)	Learning Rate [0.00125]
15: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00085 (0.00094)	Tok/s 71256 (52856)	Loss/tok 5.4537 (7.1442)	Learning Rate [0.00125]
0: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00091 (0.00092)	Tok/s 70330 (51336)	Loss/tok 5.2453 (7.1313)	Learning Rate [0.00125]
7: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00086 (0.00091)	Tok/s 70021 (52125)	Loss/tok 5.5556 (7.1367)	Learning Rate [0.00125]
8: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00093 (0.00102)	Tok/s 70166 (52215)	Loss/tok 5.4515 (7.1303)	Learning Rate [0.00125]
2: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00087 (0.00101)	Tok/s 70087 (51592)	Loss/tok 5.3555 (7.1399)	Learning Rate [0.00125]
6: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00099 (0.00097)	Tok/s 69989 (52019)	Loss/tok 5.5028 (7.1326)	Learning Rate [0.00125]
5: TRAIN [0][460/3416]	Time 0.070 (0.057)	Data 0.00088 (0.00097)	Tok/s 69904 (51922)	Loss/tok 5.5012 (7.1483)	Learning Rate [0.00125]
1: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00088 (0.00093)	Tok/s 70126 (51468)	Loss/tok 5.4158 (7.1406)	Learning Rate [0.00125]
3: TRAIN [0][460/3416]	Time 0.069 (0.057)	Data 0.00090 (0.00100)	Tok/s 70012 (51687)	Loss/tok 5.4677 (7.1335)	Learning Rate [0.00125]
4: TRAIN [0][460/3416]	Time 0.070 (0.057)	Data 0.00085 (0.00095)	Tok/s 69900 (51802)	Loss/tok 5.4424 (7.1399)	Learning Rate [0.00125]
0: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00104 (0.00092)	Tok/s 54235 (51415)	Loss/tok 5.3219 (7.0863)	Learning Rate [0.00125]
14: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00101 (0.00098)	Tok/s 54263 (52801)	Loss/tok 5.3382 (7.0989)	Learning Rate [0.00125]
1: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00099 (0.00093)	Tok/s 54098 (51546)	Loss/tok 5.2611 (7.0956)	Learning Rate [0.00125]
2: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00125 (0.00101)	Tok/s 54002 (51667)	Loss/tok 5.1320 (7.0967)	Learning Rate [0.00125]
12: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00109 (0.00100)	Tok/s 54208 (52580)	Loss/tok 5.1354 (7.0926)	Learning Rate [0.00125]
13: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00100 (0.00101)	Tok/s 54226 (52692)	Loss/tok 4.9944 (7.0968)	Learning Rate [0.00125]
3: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00105 (0.00100)	Tok/s 53937 (51760)	Loss/tok 5.3671 (7.0923)	Learning Rate [0.00125]
15: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00098 (0.00094)	Tok/s 54195 (52921)	Loss/tok 4.8880 (7.0996)	Learning Rate [0.00125]
4: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00099 (0.00095)	Tok/s 53838 (51873)	Loss/tok 5.3411 (7.0946)	Learning Rate [0.00125]
5: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00111 (0.00097)	Tok/s 53887 (51990)	Loss/tok 5.2306 (7.1046)	Learning Rate [0.00125]
10: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00103 (0.00100)	Tok/s 53983 (52416)	Loss/tok 5.2395 (7.0938)	Learning Rate [0.00125]
9: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00102 (0.00097)	Tok/s 53852 (52337)	Loss/tok 5.2549 (7.0939)	Learning Rate [0.00125]
6: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00112 (0.00097)	Tok/s 53862 (52086)	Loss/tok 5.1243 (7.0891)	Learning Rate [0.00125]
8: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00110 (0.00102)	Tok/s 53870 (52280)	Loss/tok 5.2763 (7.0873)	Learning Rate [0.00125]
11: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00104 (0.00100)	Tok/s 54083 (52477)	Loss/tok 5.0437 (7.0934)	Learning Rate [0.00125]
7: TRAIN [0][470/3416]	Time 0.059 (0.057)	Data 0.00098 (0.00091)	Tok/s 53821 (52190)	Loss/tok 5.2438 (7.0939)	Learning Rate [0.00125]
4: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00090 (0.00095)	Tok/s 52349 (51976)	Loss/tok 5.2697 (7.0474)	Learning Rate [0.00125]
3: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00092 (0.00100)	Tok/s 52242 (51865)	Loss/tok 5.4294 (7.0444)	Learning Rate [0.00125]
5: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00092 (0.00097)	Tok/s 52323 (52091)	Loss/tok 5.1185 (7.0568)	Learning Rate [0.00125]
2: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00097 (0.00101)	Tok/s 52134 (51771)	Loss/tok 5.2142 (7.0478)	Learning Rate [0.00125]
6: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00099 (0.00097)	Tok/s 52312 (52186)	Loss/tok 5.1641 (7.0424)	Learning Rate [0.00125]
1: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00081 (0.00093)	Tok/s 52127 (51651)	Loss/tok 5.0344 (7.0469)	Learning Rate [0.00125]
7: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00091 (0.00091)	Tok/s 52312 (52290)	Loss/tok 4.9739 (7.0458)	Learning Rate [0.00125]
0: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00099 (0.00092)	Tok/s 52131 (51520)	Loss/tok 5.2293 (7.0385)	Learning Rate [0.00125]
8: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00095 (0.00102)	Tok/s 52316 (52379)	Loss/tok 5.2247 (7.0383)	Learning Rate [0.00125]
15: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00098 (0.00094)	Tok/s 53237 (53032)	Loss/tok 5.2580 (7.0532)	Learning Rate [0.00125]
9: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00084 (0.00097)	Tok/s 52998 (52437)	Loss/tok 5.2373 (7.0485)	Learning Rate [0.00125]
14: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00093 (0.00098)	Tok/s 53160 (52912)	Loss/tok 5.2016 (7.0515)	Learning Rate [0.00125]
10: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00099 (0.00100)	Tok/s 53316 (52521)	Loss/tok 5.1968 (7.0485)	Learning Rate [0.00125]
12: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00094 (0.00100)	Tok/s 53266 (52691)	Loss/tok 5.3095 (7.0462)	Learning Rate [0.00125]
11: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00090 (0.00100)	Tok/s 53268 (52586)	Loss/tok 5.1923 (7.0453)	Learning Rate [0.00125]
13: TRAIN [0][480/3416]	Time 0.059 (0.057)	Data 0.00094 (0.00100)	Tok/s 53210 (52800)	Loss/tok 5.2216 (7.0496)	Learning Rate [0.00125]
5: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00099 (0.00097)	Tok/s 71088 (52146)	Loss/tok 5.2029 (7.0143)	Learning Rate [0.00125]
4: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00098 (0.00095)	Tok/s 70602 (52032)	Loss/tok 5.1513 (7.0022)	Learning Rate [0.00125]
7: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00096 (0.00091)	Tok/s 71679 (52342)	Loss/tok 5.3488 (7.0035)	Learning Rate [0.00125]
6: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00098 (0.00097)	Tok/s 71625 (52240)	Loss/tok 5.3267 (6.9977)	Learning Rate [0.00125]
8: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00099 (0.00102)	Tok/s 71674 (52431)	Loss/tok 5.2967 (6.9969)	Learning Rate [0.00125]
2: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00103 (0.00101)	Tok/s 70589 (51824)	Loss/tok 5.1325 (7.0033)	Learning Rate [0.00125]
14: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00094 (0.00098)	Tok/s 71760 (52968)	Loss/tok 4.9906 (7.0078)	Learning Rate [0.00125]
9: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00099 (0.00097)	Tok/s 71678 (52489)	Loss/tok 5.4034 (7.0060)	Learning Rate [0.00125]
10: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00093 (0.00100)	Tok/s 71688 (52574)	Loss/tok 5.2656 (7.0046)	Learning Rate [0.00125]
3: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00107 (0.00100)	Tok/s 70575 (51920)	Loss/tok 5.3475 (7.0020)	Learning Rate [0.00125]
15: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00106 (0.00094)	Tok/s 71604 (53086)	Loss/tok 5.1353 (7.0097)	Learning Rate [0.00125]
13: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00107 (0.00101)	Tok/s 71675 (52856)	Loss/tok 5.2350 (7.0060)	Learning Rate [0.00125]
1: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00094 (0.00093)	Tok/s 70581 (51705)	Loss/tok 5.2919 (7.0044)	Learning Rate [0.00125]
11: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00100 (0.00100)	Tok/s 71699 (52639)	Loss/tok 5.2292 (7.0014)	Learning Rate [0.00125]
0: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00097 (0.00092)	Tok/s 70624 (51577)	Loss/tok 5.3191 (6.9968)	Learning Rate [0.00125]
12: TRAIN [0][490/3416]	Time 0.070 (0.057)	Data 0.00102 (0.00100)	Tok/s 71648 (52745)	Loss/tok 5.1124 (7.0025)	Learning Rate [0.00125]
0: TRAIN [0][500/3416]	Time 0.038 (0.057)	Data 0.00091 (0.00092)	Tok/s 25216 (51522)	Loss/tok 3.2647 (6.9598)	Learning Rate [0.00125]
2: TRAIN [0][500/3416]	Time 0.038 (0.057)	Data 0.00098 (0.00101)	Tok/s 25141 (51764)	Loss/tok 3.2007 (6.9662)	Learning Rate [0.00125]
15: TRAIN [0][500/3416]	Time 0.038 (0.057)	Data 0.00085 (0.00094)	Tok/s 30310 (53024)	Loss/tok 3.8004 (6.9729)	Learning Rate [0.00125]
1: TRAIN [0][500/3416]	Time 0.038 (0.057)	Data 0.00090 (0.00093)	Tok/s 25210 (51647)	Loss/tok 3.2165 (6.9664)	Learning Rate [0.00125]
14: TRAIN [0][500/3416]	Time 0.038 (0.057)	Data 0.00088 (0.00098)	Tok/s 30156 (52906)	Loss/tok 3.8247 (6.9724)	Learning Rate [0.00125]
3: TRAIN [0][500/3416]	Time 0.038 (0.057)	Data 0.00105 (0.00100)	Tok/s 26204 (51860)	Loss/tok 3.6977 (6.9661)	Learning Rate [0.00125]
4: TRAIN [0][500/3416]	Time 0.038 (0.057)	Data 0.00086 (0.00095)	Tok/s 26640 (51971)	Loss/tok 3.6740 (6.9656)	Learning Rate [0.00125]
13: TRAIN [0][500/3416]	Time 0.038 (0.057)	Data 0.00096 (0.00101)	Tok/s 28588 (52791)	Loss/tok 3.3966 (6.9695)	Learning Rate [0.00125]
12: TRAIN [0][500/3416]	Time 0.038 (0.057)	Data 0.00092 (0.00100)	Tok/s 28324 (52680)	Loss/tok 3.4072 (6.9668)	Learning Rate [0.00125]
5: TRAIN [0][500/3416]	Time 0.039 (0.057)	Data 0.00087 (0.00097)	Tok/s 26577 (52082)	Loss/tok 3.8337 (6.9783)	Learning Rate [0.00125]
11: TRAIN [0][500/3416]	Time 0.038 (0.057)	Data 0.00100 (0.00100)	Tok/s 28275 (52574)	Loss/tok 3.7173 (6.9649)	Learning Rate [0.00125]
6: TRAIN [0][500/3416]	Time 0.039 (0.057)	Data 0.00092 (0.00098)	Tok/s 26543 (52176)	Loss/tok 3.8226 (6.9621)	Learning Rate [0.00125]
10: TRAIN [0][500/3416]	Time 0.039 (0.057)	Data 0.00094 (0.00100)	Tok/s 28165 (52510)	Loss/tok 3.5170 (6.9676)	Learning Rate [0.00125]
7: TRAIN [0][500/3416]	Time 0.039 (0.057)	Data 0.00087 (0.00091)	Tok/s 27305 (52278)	Loss/tok 3.6558 (6.9686)	Learning Rate [0.00125]
8: TRAIN [0][500/3416]	Time 0.039 (0.057)	Data 0.00103 (0.00102)	Tok/s 28189 (52367)	Loss/tok 3.4526 (6.9623)	Learning Rate [0.00125]
9: TRAIN [0][500/3416]	Time 0.039 (0.057)	Data 0.00089 (0.00097)	Tok/s 28191 (52425)	Loss/tok 3.6338 (6.9687)	Learning Rate [0.00125]
15: TRAIN [0][510/3416]	Time 0.048 (0.057)	Data 0.00095 (0.00094)	Tok/s 48950 (53117)	Loss/tok 4.8269 (6.9307)	Learning Rate [0.00125]
14: TRAIN [0][510/3416]	Time 0.048 (0.057)	Data 0.00089 (0.00098)	Tok/s 48958 (53001)	Loss/tok 4.6031 (6.9293)	Learning Rate [0.00125]
0: TRAIN [0][510/3416]	Time 0.049 (0.057)	Data 0.00082 (0.00092)	Tok/s 48745 (51626)	Loss/tok 4.7637 (6.9199)	Learning Rate [0.00125]
12: TRAIN [0][510/3416]	Time 0.048 (0.057)	Data 0.00102 (0.00100)	Tok/s 48902 (52777)	Loss/tok 4.9310 (6.9251)	Learning Rate [0.00125]
13: TRAIN [0][510/3416]	Time 0.048 (0.057)	Data 0.00104 (0.00101)	Tok/s 48882 (52888)	Loss/tok 4.7905 (6.9278)	Learning Rate [0.00125]
2: TRAIN [0][510/3416]	Time 0.049 (0.057)	Data 0.00097 (0.00101)	Tok/s 48542 (51867)	Loss/tok 4.6026 (6.9232)	Learning Rate [0.00125]
10: TRAIN [0][510/3416]	Time 0.049 (0.057)	Data 0.00117 (0.00100)	Tok/s 48757 (52605)	Loss/tok 4.5054 (6.9258)	Learning Rate [0.00125]
11: TRAIN [0][510/3416]	Time 0.049 (0.057)	Data 0.00109 (0.00100)	Tok/s 48822 (52671)	Loss/tok 4.8247 (6.9226)	Learning Rate [0.00125]
3: TRAIN [0][510/3416]	Time 0.049 (0.057)	Data 0.00102 (0.00100)	Tok/s 48442 (51963)	Loss/tok 5.0376 (6.9234)	Learning Rate [0.00125]
4: TRAIN [0][510/3416]	Time 0.049 (0.057)	Data 0.00089 (0.00095)	Tok/s 48309 (52072)	Loss/tok 4.7786 (6.9231)	Learning Rate [0.00125]
5: TRAIN [0][510/3416]	Time 0.049 (0.057)	Data 0.00090 (0.00097)	Tok/s 48328 (52181)	Loss/tok 4.9772 (6.9363)	Learning Rate [0.00125]
8: TRAIN [0][510/3416]	Time 0.049 (0.057)	Data 0.00089 (0.00102)	Tok/s 48499 (52465)	Loss/tok 4.7725 (6.9199)	Learning Rate [0.00125]
9: TRAIN [0][510/3416]	Time 0.049 (0.057)	Data 0.00094 (0.00097)	Tok/s 48603 (52521)	Loss/tok 4.6650 (6.9272)	Learning Rate [0.00125]
6: TRAIN [0][510/3416]	Time 0.049 (0.057)	Data 0.00106 (0.00098)	Tok/s 48343 (52273)	Loss/tok 4.7981 (6.9199)	Learning Rate [0.00125]
7: TRAIN [0][510/3416]	Time 0.049 (0.057)	Data 0.00090 (0.00091)	Tok/s 48402 (52378)	Loss/tok 4.9923 (6.9264)	Learning Rate [0.00125]
1: TRAIN [0][510/3416]	Time 0.049 (0.057)	Data 0.00172 (0.00093)	Tok/s 48274 (51752)	Loss/tok 4.7001 (6.9254)	Learning Rate [0.00125]
8: Upscaling, new scale: 256.0
9: Upscaling, new scale: 256.0
7: Upscaling, new scale: 256.0
10: Upscaling, new scale: 256.0
11: Upscaling, new scale: 256.0
3: Upscaling, new scale: 256.0
12: Upscaling, new scale: 256.0
6: Upscaling, new scale: 256.0
5: Upscaling, new scale: 256.0
13: Upscaling, new scale: 256.0
2: Upscaling, new scale: 256.0
4: Upscaling, new scale: 256.0
0: Upscaling, new scale: 256.0
14: Upscaling, new scale: 256.0
1: Upscaling, new scale: 256.0
15: Upscaling, new scale: 256.0
2: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00106 (0.00101)	Tok/s 57799 (51861)	Loss/tok 5.1410 (6.8850)	Learning Rate [0.00125]
1: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00110 (0.00093)	Tok/s 57830 (51748)	Loss/tok 4.6979 (6.8850)	Learning Rate [0.00125]
3: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00099 (0.00100)	Tok/s 57796 (51956)	Loss/tok 5.0909 (6.8843)	Learning Rate [0.00125]
0: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00098 (0.00092)	Tok/s 57822 (51624)	Loss/tok 5.1368 (6.8806)	Learning Rate [0.00125]
4: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00105 (0.00095)	Tok/s 57807 (52064)	Loss/tok 5.0124 (6.8838)	Learning Rate [0.00125]
15: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00098 (0.00094)	Tok/s 58808 (53104)	Loss/tok 5.2230 (6.8912)	Learning Rate [0.00125]
5: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00093 (0.00097)	Tok/s 57814 (52172)	Loss/tok 5.1672 (6.8966)	Learning Rate [0.00125]
14: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00092 (0.00098)	Tok/s 58749 (52990)	Loss/tok 5.0058 (6.8899)	Learning Rate [0.00125]
13: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00098 (0.00101)	Tok/s 58755 (52879)	Loss/tok 5.2515 (6.8885)	Learning Rate [0.00125]
6: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00109 (0.00098)	Tok/s 57827 (52263)	Loss/tok 5.0959 (6.8810)	Learning Rate [0.00125]
12: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00098 (0.00100)	Tok/s 58746 (52770)	Loss/tok 4.9440 (6.8852)	Learning Rate [0.00125]
8: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00105 (0.00102)	Tok/s 57815 (52455)	Loss/tok 5.0327 (6.8812)	Learning Rate [0.00125]
7: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00102 (0.00091)	Tok/s 57840 (52367)	Loss/tok 5.0783 (6.8869)	Learning Rate [0.00125]
11: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00107 (0.00100)	Tok/s 58761 (52663)	Loss/tok 5.1024 (6.8835)	Learning Rate [0.00125]
10: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00110 (0.00100)	Tok/s 58748 (52597)	Loss/tok 5.3912 (6.8873)	Learning Rate [0.00125]
9: TRAIN [0][520/3416]	Time 0.069 (0.057)	Data 0.00095 (0.00097)	Tok/s 58342 (52513)	Loss/tok 5.0180 (6.8870)	Learning Rate [0.00125]
12: TRAIN [0][530/3416]	Time 0.050 (0.057)	Data 0.00113 (0.00100)	Tok/s 36790 (52664)	Loss/tok 4.4480 (6.8514)	Learning Rate [0.00125]
11: TRAIN [0][530/3416]	Time 0.050 (0.057)	Data 0.00110 (0.00100)	Tok/s 36794 (52556)	Loss/tok 4.2808 (6.8489)	Learning Rate [0.00125]
13: TRAIN [0][530/3416]	Time 0.050 (0.057)	Data 0.00097 (0.00101)	Tok/s 36761 (52771)	Loss/tok 4.0922 (6.8550)	Learning Rate [0.00125]
10: TRAIN [0][530/3416]	Time 0.051 (0.057)	Data 0.00095 (0.00100)	Tok/s 36751 (52489)	Loss/tok 4.5063 (6.8535)	Learning Rate [0.00125]
14: TRAIN [0][530/3416]	Time 0.051 (0.057)	Data 0.00091 (0.00098)	Tok/s 36716 (52883)	Loss/tok 4.6444 (6.8573)	Learning Rate [0.00125]
9: TRAIN [0][530/3416]	Time 0.051 (0.057)	Data 0.00094 (0.00096)	Tok/s 36695 (52406)	Loss/tok 4.3988 (6.8535)	Learning Rate [0.00125]
15: TRAIN [0][530/3416]	Time 0.051 (0.057)	Data 0.00088 (0.00094)	Tok/s 36751 (52997)	Loss/tok 4.4030 (6.8578)	Learning Rate [0.00125]
8: TRAIN [0][530/3416]	Time 0.051 (0.057)	Data 0.00099 (0.00101)	Tok/s 36631 (52348)	Loss/tok 4.6879 (6.8466)	Learning Rate [0.00125]
0: TRAIN [0][530/3416]	Time 0.051 (0.057)	Data 0.00092 (0.00092)	Tok/s 36584 (51503)	Loss/tok 4.3418 (6.8469)	Learning Rate [0.00125]
7: TRAIN [0][530/3416]	Time 0.051 (0.057)	Data 0.00089 (0.00091)	Tok/s 36606 (52259)	Loss/tok 4.3416 (6.8543)	Learning Rate [0.00125]
2: TRAIN [0][530/3416]	Time 0.051 (0.057)	Data 0.00098 (0.00100)	Tok/s 36552 (51748)	Loss/tok 4.5270 (6.8490)	Learning Rate [0.00125]
6: TRAIN [0][530/3416]	Time 0.051 (0.057)	Data 0.00104 (0.00098)	Tok/s 36608 (52155)	Loss/tok 4.1234 (6.8459)	Learning Rate [0.00125]
5: TRAIN [0][530/3416]	Time 0.051 (0.057)	Data 0.00093 (0.00097)	Tok/s 36595 (52063)	Loss/tok 4.4957 (6.8629)	Learning Rate [0.00125]
1: TRAIN [0][530/3416]	Time 0.051 (0.057)	Data 0.00101 (0.00093)	Tok/s 36623 (51629)	Loss/tok 4.2825 (6.8524)	Learning Rate [0.00125]
3: TRAIN [0][530/3416]	Time 0.051 (0.057)	Data 0.00099 (0.00100)	Tok/s 36540 (51843)	Loss/tok 4.2678 (6.8492)	Learning Rate [0.00125]
4: TRAIN [0][530/3416]	Time 0.051 (0.057)	Data 0.00083 (0.00095)	Tok/s 36579 (51951)	Loss/tok 4.6089 (6.8513)	Learning Rate [0.00125]
11: TRAIN [0][540/3416]	Time 0.068 (0.057)	Data 0.00107 (0.00100)	Tok/s 63690 (52478)	Loss/tok 5.3176 (6.8172)	Learning Rate [0.00125]
10: TRAIN [0][540/3416]	Time 0.068 (0.057)	Data 0.00109 (0.00100)	Tok/s 63563 (52410)	Loss/tok 5.0121 (6.8198)	Learning Rate [0.00125]
12: TRAIN [0][540/3416]	Time 0.068 (0.057)	Data 0.00114 (0.00100)	Tok/s 63714 (52585)	Loss/tok 5.3356 (6.8187)	Learning Rate [0.00125]
9: TRAIN [0][540/3416]	Time 0.069 (0.057)	Data 0.00093 (0.00096)	Tok/s 63417 (52328)	Loss/tok 4.9674 (6.8197)	Learning Rate [0.00125]
13: TRAIN [0][540/3416]	Time 0.068 (0.057)	Data 0.00092 (0.00101)	Tok/s 63551 (52691)	Loss/tok 5.1039 (6.8232)	Learning Rate [0.00125]
8: TRAIN [0][540/3416]	Time 0.069 (0.057)	Data 0.00091 (0.00101)	Tok/s 63340 (52271)	Loss/tok 4.7800 (6.8134)	Learning Rate [0.00125]
15: TRAIN [0][540/3416]	Time 0.069 (0.057)	Data 0.00089 (0.00094)	Tok/s 63423 (52916)	Loss/tok 5.0418 (6.8253)	Learning Rate [0.00125]
14: TRAIN [0][540/3416]	Time 0.069 (0.057)	Data 0.00090 (0.00097)	Tok/s 63445 (52803)	Loss/tok 5.0738 (6.8245)	Learning Rate [0.00125]
7: TRAIN [0][540/3416]	Time 0.069 (0.057)	Data 0.00086 (0.00091)	Tok/s 63149 (52182)	Loss/tok 4.8177 (6.8199)	Learning Rate [0.00125]
0: TRAIN [0][540/3416]	Time 0.069 (0.057)	Data 0.00095 (0.00092)	Tok/s 62389 (51423)	Loss/tok 4.9594 (6.8143)	Learning Rate [0.00125]
6: TRAIN [0][540/3416]	Time 0.069 (0.057)	Data 0.00104 (0.00098)	Tok/s 63085 (52078)	Loss/tok 4.8802 (6.8130)	Learning Rate [0.00125]
5: TRAIN [0][540/3416]	Time 0.069 (0.057)	Data 0.00095 (0.00097)	Tok/s 62945 (51988)	Loss/tok 5.1658 (6.8312)	Learning Rate [0.00125]
2: TRAIN [0][540/3416]	Time 0.069 (0.057)	Data 0.00088 (0.00100)	Tok/s 62455 (51665)	Loss/tok 4.9954 (6.8164)	Learning Rate [0.00125]
4: TRAIN [0][540/3416]	Time 0.069 (0.057)	Data 0.00090 (0.00095)	Tok/s 62971 (51876)	Loss/tok 5.1926 (6.8175)	Learning Rate [0.00125]
1: TRAIN [0][540/3416]	Time 0.069 (0.057)	Data 0.00089 (0.00093)	Tok/s 62233 (51548)	Loss/tok 5.2172 (6.8192)	Learning Rate [0.00125]
3: TRAIN [0][540/3416]	Time 0.069 (0.057)	Data 0.00102 (0.00100)	Tok/s 63042 (51767)	Loss/tok 5.1176 (6.8160)	Learning Rate [0.00125]
11: Gradient norm: inf
10: Gradient norm: inf
12: Gradient norm: inf
13: Gradient norm: inf
11: Skipped batch, new scale: 128.0
10: Skipped batch, new scale: 128.0
12: Skipped batch, new scale: 128.0
13: Skipped batch, new scale: 128.0
15: Gradient norm: inf
9: Gradient norm: inf
14: Gradient norm: inf
8: Gradient norm: inf
0: Gradient norm: inf
15: Skipped batch, new scale: 128.0
9: Skipped batch, new scale: 128.0
8: Skipped batch, new scale: 128.0
7: Gradient norm: inf
14: Skipped batch, new scale: 128.0
0: Skipped batch, new scale: 128.0
1: Gradient norm: inf
7: Skipped batch, new scale: 128.0
6: Gradient norm: inf
1: Skipped batch, new scale: 128.0
2: Gradient norm: inf
6: Skipped batch, new scale: 128.0
2: Skipped batch, new scale: 128.0
5: Gradient norm: inf
4: Gradient norm: inf
3: Gradient norm: inf
4: Skipped batch, new scale: 128.0
5: Skipped batch, new scale: 128.0
3: Skipped batch, new scale: 128.0
5: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00086 (0.00097)	Tok/s 58980 (52194)	Loss/tok 4.8844 (6.7844)	Learning Rate [0.00125]
4: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00080 (0.00094)	Tok/s 58980 (52084)	Loss/tok 5.2828 (6.7711)	Learning Rate [0.00125]
6: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00104 (0.00098)	Tok/s 58900 (52283)	Loss/tok 4.9536 (6.7685)	Learning Rate [0.00125]
2: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00082 (0.00100)	Tok/s 59034 (51867)	Loss/tok 4.9000 (6.7711)	Learning Rate [0.00125]
3: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00084 (0.00100)	Tok/s 58994 (51974)	Loss/tok 5.0367 (6.7711)	Learning Rate [0.00125]
7: TRAIN [0][550/3416]	Time 0.069 (0.057)	Data 0.00085 (0.00091)	Tok/s 58845 (52387)	Loss/tok 5.0751 (6.7756)	Learning Rate [0.00125]
8: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00091 (0.00101)	Tok/s 58868 (52475)	Loss/tok 5.2882 (6.7703)	Learning Rate [0.00125]
1: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00085 (0.00093)	Tok/s 58977 (51750)	Loss/tok 4.9566 (6.7746)	Learning Rate [0.00125]
10: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00100 (0.00101)	Tok/s 58917 (52614)	Loss/tok 5.0934 (6.7745)	Learning Rate [0.00125]
9: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00102 (0.00097)	Tok/s 58881 (52531)	Loss/tok 5.0415 (6.7752)	Learning Rate [0.00125]
11: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00107 (0.00100)	Tok/s 58893 (52681)	Loss/tok 4.9003 (6.7702)	Learning Rate [0.00125]
15: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00084 (0.00094)	Tok/s 58932 (53123)	Loss/tok 5.0088 (6.7808)	Learning Rate [0.00125]
13: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00098 (0.00101)	Tok/s 58957 (52893)	Loss/tok 4.9270 (6.7778)	Learning Rate [0.00125]
12: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00094 (0.00100)	Tok/s 58876 (52788)	Loss/tok 4.9595 (6.7722)	Learning Rate [0.00125]
0: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00098 (0.00092)	Tok/s 58992 (51627)	Loss/tok 5.2983 (6.7697)	Learning Rate [0.00125]
14: TRAIN [0][550/3416]	Time 0.068 (0.057)	Data 0.00098 (0.00097)	Tok/s 58864 (53007)	Loss/tok 5.1245 (6.7806)	Learning Rate [0.00125]
15: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00083 (0.00094)	Tok/s 85062 (53109)	Loss/tok 4.7356 (6.7448)	Learning Rate [0.00125]
0: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00086 (0.00092)	Tok/s 82318 (51618)	Loss/tok 4.8501 (6.7349)	Learning Rate [0.00125]
14: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00098 (0.00097)	Tok/s 84640 (52994)	Loss/tok 4.8241 (6.7442)	Learning Rate [0.00125]
12: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00102 (0.00100)	Tok/s 84360 (52775)	Loss/tok 4.5988 (6.7366)	Learning Rate [0.00125]
11: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00107 (0.00100)	Tok/s 84404 (52668)	Loss/tok 4.7084 (6.7347)	Learning Rate [0.00125]
10: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00095 (0.00101)	Tok/s 83771 (52601)	Loss/tok 4.5615 (6.7384)	Learning Rate [0.00125]
2: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00095 (0.00100)	Tok/s 82289 (51853)	Loss/tok 4.7176 (6.7340)	Learning Rate [0.00125]
1: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00084 (0.00093)	Tok/s 82275 (51738)	Loss/tok 4.8884 (6.7394)	Learning Rate [0.00125]
13: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00097 (0.00101)	Tok/s 84293 (52879)	Loss/tok 4.7130 (6.7417)	Learning Rate [0.00125]
8: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00099 (0.00101)	Tok/s 83445 (52464)	Loss/tok 4.9935 (6.7347)	Learning Rate [0.00125]
3: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00092 (0.00100)	Tok/s 82316 (51960)	Loss/tok 4.7512 (6.7350)	Learning Rate [0.00125]
7: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00086 (0.00091)	Tok/s 83403 (52375)	Loss/tok 4.7149 (6.7390)	Learning Rate [0.00125]
4: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00090 (0.00094)	Tok/s 82311 (52070)	Loss/tok 4.7315 (6.7352)	Learning Rate [0.00125]
5: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00090 (0.00097)	Tok/s 83142 (52180)	Loss/tok 4.5994 (6.7475)	Learning Rate [0.00125]
9: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00095 (0.00097)	Tok/s 83626 (52520)	Loss/tok 4.9134 (6.7387)	Learning Rate [0.00125]
6: TRAIN [0][560/3416]	Time 0.070 (0.057)	Data 0.00099 (0.00098)	Tok/s 83325 (52270)	Loss/tok 4.6456 (6.7318)	Learning Rate [0.00125]
10: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00101)	Tok/s 49761 (52667)	Loss/tok 4.4288 (6.6981)	Learning Rate [0.00125]
8: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00101)	Tok/s 49854 (52530)	Loss/tok 4.3074 (6.6971)	Learning Rate [0.00125]
9: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00097)	Tok/s 49820 (52584)	Loss/tok 4.4836 (6.7011)	Learning Rate [0.00125]
11: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00100)	Tok/s 49657 (52734)	Loss/tok 4.4853 (6.6965)	Learning Rate [0.00125]
7: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00091)	Tok/s 49806 (52443)	Loss/tok 4.4797 (6.6996)	Learning Rate [0.00125]
12: TRAIN [0][570/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00100)	Tok/s 49530 (52843)	Loss/tok 4.3599 (6.6987)	Learning Rate [0.00125]
5: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00097)	Tok/s 49895 (52249)	Loss/tok 4.6225 (6.7096)	Learning Rate [0.00125]
13: TRAIN [0][570/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00101)	Tok/s 49537 (52948)	Loss/tok 4.4231 (6.7031)	Learning Rate [0.00125]
2: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00100)	Tok/s 49825 (51926)	Loss/tok 4.7555 (6.6976)	Learning Rate [0.00125]
4: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00094)	Tok/s 49920 (52139)	Loss/tok 4.6451 (6.6961)	Learning Rate [0.00125]
6: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00113 (0.00098)	Tok/s 50012 (52339)	Loss/tok 4.6035 (6.6933)	Learning Rate [0.00125]
3: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00100)	Tok/s 49834 (52031)	Loss/tok 4.7645 (6.6958)	Learning Rate [0.00125]
1: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00093)	Tok/s 49701 (51813)	Loss/tok 4.5748 (6.7007)	Learning Rate [0.00125]
0: TRAIN [0][570/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00092)	Tok/s 49623 (51693)	Loss/tok 4.7194 (6.6961)	Learning Rate [0.00125]
14: TRAIN [0][570/3416]	Time 0.047 (0.058)	Data 0.00113 (0.00098)	Tok/s 49538 (53061)	Loss/tok 4.3337 (6.7063)	Learning Rate [0.00125]
15: TRAIN [0][570/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00094)	Tok/s 49703 (53175)	Loss/tok 4.2195 (6.7065)	Learning Rate [0.00125]
7: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00091)	Tok/s 54488 (52446)	Loss/tok 4.8680 (6.6648)	Learning Rate [0.00125]
8: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00101)	Tok/s 54468 (52532)	Loss/tok 4.6939 (6.6630)	Learning Rate [0.00125]
5: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00096)	Tok/s 54313 (52254)	Loss/tok 4.6411 (6.6737)	Learning Rate [0.00125]
6: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00099)	Tok/s 54434 (52343)	Loss/tok 4.9852 (6.6587)	Learning Rate [0.00125]
9: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00097)	Tok/s 54345 (52587)	Loss/tok 4.4978 (6.6658)	Learning Rate [0.00125]
4: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00094)	Tok/s 54180 (52147)	Loss/tok 4.7567 (6.6623)	Learning Rate [0.00125]
3: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00100)	Tok/s 54061 (52041)	Loss/tok 4.9156 (6.6606)	Learning Rate [0.00125]
11: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00100)	Tok/s 55268 (52738)	Loss/tok 4.9706 (6.6613)	Learning Rate [0.00125]
2: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00100)	Tok/s 53955 (51937)	Loss/tok 4.4608 (6.6619)	Learning Rate [0.00125]
12: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00100)	Tok/s 55159 (52847)	Loss/tok 4.8256 (6.6642)	Learning Rate [0.00125]
10: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00101)	Tok/s 54999 (52670)	Loss/tok 4.6898 (6.6631)	Learning Rate [0.00125]
0: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00092)	Tok/s 53791 (51703)	Loss/tok 4.5598 (6.6605)	Learning Rate [0.00125]
13: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00101)	Tok/s 55042 (52951)	Loss/tok 4.7582 (6.6691)	Learning Rate [0.00125]
1: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00083 (0.00093)	Tok/s 53853 (51822)	Loss/tok 4.7017 (6.6651)	Learning Rate [0.00125]
15: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00094)	Tok/s 54861 (53178)	Loss/tok 4.8521 (6.6721)	Learning Rate [0.00125]
14: TRAIN [0][580/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00097)	Tok/s 54937 (53063)	Loss/tok 4.4513 (6.6703)	Learning Rate [0.00125]
1: TRAIN [0][590/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 70148 (51875)	Loss/tok 4.6708 (6.6282)	Learning Rate [0.00125]
2: TRAIN [0][590/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00100)	Tok/s 70165 (51990)	Loss/tok 4.7057 (6.6249)	Learning Rate [0.00125]
0: TRAIN [0][590/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 70040 (51757)	Loss/tok 4.8940 (6.6246)	Learning Rate [0.00125]
3: TRAIN [0][590/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00101)	Tok/s 70153 (52094)	Loss/tok 4.8002 (6.6244)	Learning Rate [0.00125]
4: TRAIN [0][590/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00094)	Tok/s 70089 (52201)	Loss/tok 4.8354 (6.6263)	Learning Rate [0.00125]
13: TRAIN [0][590/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00100)	Tok/s 70606 (53007)	Loss/tok 4.8203 (6.6335)	Learning Rate [0.00125]
5: TRAIN [0][590/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 70013 (52309)	Loss/tok 4.6440 (6.6370)	Learning Rate [0.00125]
6: TRAIN [0][590/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00099)	Tok/s 70088 (52398)	Loss/tok 4.8391 (6.6223)	Learning Rate [0.00125]
15: TRAIN [0][590/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00094)	Tok/s 70852 (53231)	Loss/tok 4.7434 (6.6356)	Learning Rate [0.00125]
12: TRAIN [0][590/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00100)	Tok/s 70491 (52903)	Loss/tok 5.0840 (6.6282)	Learning Rate [0.00125]
10: TRAIN [0][590/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00101)	Tok/s 69635 (52723)	Loss/tok 4.6527 (6.6272)	Learning Rate [0.00125]
14: TRAIN [0][590/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 70733 (53117)	Loss/tok 4.9375 (6.6345)	Learning Rate [0.00125]
7: TRAIN [0][590/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00091)	Tok/s 69790 (52500)	Loss/tok 4.9331 (6.6283)	Learning Rate [0.00125]
11: TRAIN [0][590/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00100)	Tok/s 70268 (52793)	Loss/tok 4.9011 (6.6239)	Learning Rate [0.00125]
8: TRAIN [0][590/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00101)	Tok/s 69703 (52585)	Loss/tok 4.8624 (6.6264)	Learning Rate [0.00125]
9: TRAIN [0][590/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00097)	Tok/s 69632 (52640)	Loss/tok 4.8414 (6.6314)	Learning Rate [0.00125]
10: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00101)	Tok/s 34495 (52715)	Loss/tok 4.4485 (6.5943)	Learning Rate [0.00125]
11: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00100)	Tok/s 34530 (52787)	Loss/tok 4.2275 (6.5915)	Learning Rate [0.00125]
12: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00100)	Tok/s 34525 (52897)	Loss/tok 4.2166 (6.5953)	Learning Rate [0.00125]
9: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00097)	Tok/s 34445 (52633)	Loss/tok 3.7570 (6.5981)	Learning Rate [0.00125]
13: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00100)	Tok/s 34967 (53000)	Loss/tok 4.1919 (6.6009)	Learning Rate [0.00125]
8: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00101)	Tok/s 34447 (52579)	Loss/tok 4.3464 (6.5937)	Learning Rate [0.00125]
14: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00080 (0.00097)	Tok/s 35769 (53110)	Loss/tok 4.2098 (6.6026)	Learning Rate [0.00125]
7: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00091)	Tok/s 34450 (52495)	Loss/tok 4.2049 (6.5953)	Learning Rate [0.00125]
15: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00094)	Tok/s 35753 (53223)	Loss/tok 4.1867 (6.6029)	Learning Rate [0.00125]
0: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 34490 (51757)	Loss/tok 4.2734 (6.5920)	Learning Rate [0.00125]
5: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00096)	Tok/s 34433 (52305)	Loss/tok 4.1148 (6.6044)	Learning Rate [0.00125]
6: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00099)	Tok/s 34487 (52394)	Loss/tok 4.1637 (6.5902)	Learning Rate [0.00125]
4: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00094)	Tok/s 34459 (52197)	Loss/tok 4.1708 (6.5946)	Learning Rate [0.00125]
1: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00093)	Tok/s 34514 (51873)	Loss/tok 4.2066 (6.5957)	Learning Rate [0.00125]
2: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00100)	Tok/s 34475 (51988)	Loss/tok 3.8947 (6.5904)	Learning Rate [0.00125]
3: TRAIN [0][600/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00100)	Tok/s 34463 (52091)	Loss/tok 4.1441 (6.5923)	Learning Rate [0.00125]
13: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00102 (0.00100)	Tok/s 44992 (53038)	Loss/tok 4.2273 (6.5670)	Learning Rate [0.00125]
12: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00100)	Tok/s 44887 (52935)	Loss/tok 4.5071 (6.5617)	Learning Rate [0.00125]
14: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00097)	Tok/s 44808 (53147)	Loss/tok 4.3444 (6.5680)	Learning Rate [0.00125]
11: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00100)	Tok/s 44830 (52819)	Loss/tok 4.6431 (6.5563)	Learning Rate [0.00125]
10: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00101)	Tok/s 44739 (52747)	Loss/tok 4.4837 (6.5602)	Learning Rate [0.00125]
15: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00094)	Tok/s 44845 (53260)	Loss/tok 4.3189 (6.5690)	Learning Rate [0.00125]
9: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00097)	Tok/s 44588 (52665)	Loss/tok 4.3002 (6.5639)	Learning Rate [0.00125]
0: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00092)	Tok/s 44744 (51790)	Loss/tok 4.3420 (6.5575)	Learning Rate [0.00125]
1: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00093)	Tok/s 44663 (51905)	Loss/tok 4.2913 (6.5618)	Learning Rate [0.00125]
2: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00100)	Tok/s 44517 (52018)	Loss/tok 4.4107 (6.5571)	Learning Rate [0.00125]
8: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00101)	Tok/s 44482 (52610)	Loss/tok 4.2213 (6.5596)	Learning Rate [0.00125]
5: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00096)	Tok/s 44262 (52339)	Loss/tok 4.3292 (6.5693)	Learning Rate [0.00125]
3: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00101)	Tok/s 44403 (52122)	Loss/tok 4.3439 (6.5581)	Learning Rate [0.00125]
7: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00091)	Tok/s 44415 (52528)	Loss/tok 4.2014 (6.5606)	Learning Rate [0.00125]
4: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00094)	Tok/s 44337 (52230)	Loss/tok 4.2389 (6.5612)	Learning Rate [0.00125]
6: TRAIN [0][610/3416]	Time 0.046 (0.058)	Data 0.00111 (0.00099)	Tok/s 44247 (52428)	Loss/tok 4.4426 (6.5554)	Learning Rate [0.00125]
12: TRAIN [0][620/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00100)	Tok/s 55570 (52982)	Loss/tok 4.6661 (6.5272)	Learning Rate [0.00125]
13: TRAIN [0][620/3416]	Time 0.064 (0.058)	Data 0.00097 (0.00100)	Tok/s 55669 (53088)	Loss/tok 4.5260 (6.5331)	Learning Rate [0.00125]
14: TRAIN [0][620/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00097)	Tok/s 55678 (53198)	Loss/tok 4.6476 (6.5345)	Learning Rate [0.00125]
11: TRAIN [0][620/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00100)	Tok/s 55448 (52866)	Loss/tok 4.8046 (6.5222)	Learning Rate [0.00125]
15: TRAIN [0][620/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00094)	Tok/s 55618 (53310)	Loss/tok 4.6125 (6.5347)	Learning Rate [0.00125]
10: TRAIN [0][620/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00101)	Tok/s 55394 (52796)	Loss/tok 4.3859 (6.5263)	Learning Rate [0.00125]
0: TRAIN [0][620/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00092)	Tok/s 54645 (51839)	Loss/tok 4.7730 (6.5235)	Learning Rate [0.00125]
9: TRAIN [0][620/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00097)	Tok/s 55390 (52712)	Loss/tok 4.7695 (6.5301)	Learning Rate [0.00125]
1: TRAIN [0][620/3416]	Time 0.064 (0.058)	Data 0.00084 (0.00093)	Tok/s 54646 (51953)	Loss/tok 4.8596 (6.5287)	Learning Rate [0.00125]
8: TRAIN [0][620/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00101)	Tok/s 55317 (52658)	Loss/tok 4.5468 (6.5250)	Learning Rate [0.00125]
2: TRAIN [0][620/3416]	Time 0.064 (0.058)	Data 0.00106 (0.00100)	Tok/s 54635 (52065)	Loss/tok 4.8285 (6.5240)	Learning Rate [0.00125]
7: TRAIN [0][620/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00091)	Tok/s 55405 (52577)	Loss/tok 4.8436 (6.5278)	Learning Rate [0.00125]
5: TRAIN [0][620/3416]	Time 0.065 (0.058)	Data 0.00107 (0.00096)	Tok/s 55399 (52387)	Loss/tok 4.8268 (6.5359)	Learning Rate [0.00125]
4: TRAIN [0][620/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00094)	Tok/s 55437 (52279)	Loss/tok 4.9198 (6.5281)	Learning Rate [0.00125]
3: TRAIN [0][620/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00101)	Tok/s 54804 (52171)	Loss/tok 4.6633 (6.5223)	Learning Rate [0.00125]
6: TRAIN [0][620/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00099)	Tok/s 55351 (52476)	Loss/tok 4.8628 (6.5213)	Learning Rate [0.00125]
9: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00097)	Tok/s 51466 (52796)	Loss/tok 4.4995 (6.4957)	Learning Rate [0.00125]
8: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00101)	Tok/s 51298 (52740)	Loss/tok 4.6079 (6.4906)	Learning Rate [0.00125]
4: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00094)	Tok/s 51356 (52364)	Loss/tok 4.4515 (6.4943)	Learning Rate [0.00125]
7: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00091)	Tok/s 51405 (52658)	Loss/tok 4.0611 (6.4928)	Learning Rate [0.00125]
6: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00099)	Tok/s 51301 (52558)	Loss/tok 4.4403 (6.4876)	Learning Rate [0.00125]
5: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00096)	Tok/s 51287 (52471)	Loss/tok 4.7704 (6.5023)	Learning Rate [0.00125]
2: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00099)	Tok/s 51107 (52152)	Loss/tok 4.5615 (6.4900)	Learning Rate [0.00125]
12: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00100)	Tok/s 51300 (53065)	Loss/tok 4.1350 (6.4927)	Learning Rate [0.00125]
15: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00094)	Tok/s 51254 (53390)	Loss/tok 4.3551 (6.5004)	Learning Rate [0.00125]
14: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00097)	Tok/s 51340 (53280)	Loss/tok 4.3101 (6.5005)	Learning Rate [0.00125]
1: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00093)	Tok/s 51134 (52039)	Loss/tok 4.6309 (6.4940)	Learning Rate [0.00125]
13: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00100)	Tok/s 51313 (53170)	Loss/tok 4.5949 (6.4974)	Learning Rate [0.00125]
3: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00101)	Tok/s 51339 (52256)	Loss/tok 4.4797 (6.4882)	Learning Rate [0.00125]
11: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00101)	Tok/s 51309 (52951)	Loss/tok 4.3661 (6.4877)	Learning Rate [0.00125]
10: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00101)	Tok/s 51303 (52879)	Loss/tok 4.2866 (6.4924)	Learning Rate [0.00125]
0: TRAIN [0][630/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00092)	Tok/s 51137 (51927)	Loss/tok 4.4613 (6.4892)	Learning Rate [0.00125]
5: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00096)	Tok/s 39440 (52485)	Loss/tok 4.3045 (6.4708)	Learning Rate [0.00125]
4: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00094)	Tok/s 38244 (52377)	Loss/tok 4.1856 (6.4611)	Learning Rate [0.00125]
6: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00099)	Tok/s 39453 (52571)	Loss/tok 4.3984 (6.4564)	Learning Rate [0.00125]
3: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00101)	Tok/s 37930 (52270)	Loss/tok 3.9487 (6.4555)	Learning Rate [0.00125]
7: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00091)	Tok/s 39372 (52671)	Loss/tok 3.9695 (6.4615)	Learning Rate [0.00125]
8: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00106 (0.00101)	Tok/s 39304 (52754)	Loss/tok 4.2243 (6.4592)	Learning Rate [0.00125]
0: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00092)	Tok/s 37710 (51944)	Loss/tok 3.8661 (6.4570)	Learning Rate [0.00125]
10: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00116 (0.00101)	Tok/s 39137 (52894)	Loss/tok 3.9479 (6.4615)	Learning Rate [0.00125]
9: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00109 (0.00097)	Tok/s 39230 (52810)	Loss/tok 4.0020 (6.4628)	Learning Rate [0.00125]
1: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00093)	Tok/s 37754 (52055)	Loss/tok 3.9268 (6.4625)	Learning Rate [0.00125]
12: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00100)	Tok/s 38987 (53078)	Loss/tok 4.2393 (6.4603)	Learning Rate [0.00125]
11: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00101)	Tok/s 39088 (52965)	Loss/tok 4.2643 (6.4551)	Learning Rate [0.00125]
15: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00094)	Tok/s 38879 (53401)	Loss/tok 4.3760 (6.4688)	Learning Rate [0.00125]
14: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00097)	Tok/s 38898 (53292)	Loss/tok 4.4266 (6.4687)	Learning Rate [0.00125]
13: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00109 (0.00100)	Tok/s 38896 (53181)	Loss/tok 4.3630 (6.4661)	Learning Rate [0.00125]
2: TRAIN [0][640/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00099)	Tok/s 37686 (52166)	Loss/tok 3.9254 (6.4583)	Learning Rate [0.00125]
12: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00100)	Tok/s 50700 (53100)	Loss/tok 4.5029 (6.4300)	Learning Rate [0.00125]
11: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00101)	Tok/s 50784 (52988)	Loss/tok 4.3439 (6.4230)	Learning Rate [0.00125]
13: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00100)	Tok/s 50643 (53202)	Loss/tok 4.3606 (6.4358)	Learning Rate [0.00125]
14: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00097)	Tok/s 50475 (53311)	Loss/tok 4.1939 (6.4373)	Learning Rate [0.00125]
10: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00101)	Tok/s 50693 (52917)	Loss/tok 4.4440 (6.4306)	Learning Rate [0.00125]
15: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00094)	Tok/s 50388 (53420)	Loss/tok 4.1215 (6.4368)	Learning Rate [0.00125]
7: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00092)	Tok/s 50451 (52690)	Loss/tok 4.3753 (6.4293)	Learning Rate [0.00125]
8: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00125 (0.00101)	Tok/s 50771 (52774)	Loss/tok 4.3448 (6.4289)	Learning Rate [0.00125]
0: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 50261 (51965)	Loss/tok 4.4185 (6.4245)	Learning Rate [0.00125]
2: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00099)	Tok/s 50095 (52186)	Loss/tok 4.2700 (6.4276)	Learning Rate [0.00125]
5: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00096)	Tok/s 50271 (52503)	Loss/tok 4.2168 (6.4397)	Learning Rate [0.00125]
6: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00099)	Tok/s 50347 (52589)	Loss/tok 4.2099 (6.4262)	Learning Rate [0.00125]
1: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00093)	Tok/s 50125 (52075)	Loss/tok 4.2875 (6.4316)	Learning Rate [0.00125]
4: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00094)	Tok/s 50149 (52396)	Loss/tok 4.4974 (6.4310)	Learning Rate [0.00125]
3: TRAIN [0][650/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00101)	Tok/s 50090 (52290)	Loss/tok 4.1738 (6.4239)	Learning Rate [0.00125]
9: TRAIN [0][650/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00096)	Tok/s 49470 (52829)	Loss/tok 4.2898 (6.4318)	Learning Rate [0.00125]
1: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00093)	Tok/s 50384 (52023)	Loss/tok 4.0748 (6.4044)	Learning Rate [0.00125]
14: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00097)	Tok/s 51905 (53254)	Loss/tok 4.3125 (6.4113)	Learning Rate [0.00125]
2: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00099)	Tok/s 50273 (52132)	Loss/tok 4.2093 (6.3997)	Learning Rate [0.00125]
0: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00092)	Tok/s 50392 (51914)	Loss/tok 4.1741 (6.3963)	Learning Rate [0.00125]
15: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00094)	Tok/s 51749 (53362)	Loss/tok 4.6254 (6.4098)	Learning Rate [0.00125]
3: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00100)	Tok/s 50254 (52238)	Loss/tok 4.2407 (6.3966)	Learning Rate [0.00125]
4: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00130 (0.00094)	Tok/s 50229 (52345)	Loss/tok 4.3885 (6.4028)	Learning Rate [0.00125]
5: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00096)	Tok/s 50582 (52451)	Loss/tok 4.3454 (6.4114)	Learning Rate [0.00125]
13: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00100)	Tok/s 51752 (53146)	Loss/tok 4.3819 (6.4079)	Learning Rate [0.00125]
12: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00100)	Tok/s 51730 (53044)	Loss/tok 4.1041 (6.4025)	Learning Rate [0.00125]
6: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00099)	Tok/s 51623 (52537)	Loss/tok 4.2638 (6.3995)	Learning Rate [0.00125]
11: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00101)	Tok/s 51680 (52932)	Loss/tok 4.0804 (6.3966)	Learning Rate [0.00125]
10: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00101)	Tok/s 51592 (52861)	Loss/tok 4.1784 (6.4029)	Learning Rate [0.00125]
8: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00101)	Tok/s 51535 (52720)	Loss/tok 4.1257 (6.4008)	Learning Rate [0.00125]
7: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00092)	Tok/s 51532 (52637)	Loss/tok 4.3294 (6.4018)	Learning Rate [0.00125]
9: TRAIN [0][660/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00096)	Tok/s 51461 (52776)	Loss/tok 4.0999 (6.4035)	Learning Rate [0.00125]
5: TRAIN [0][670/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00096)	Tok/s 51962 (52519)	Loss/tok 4.2119 (6.3802)	Learning Rate [0.00125]
4: TRAIN [0][670/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00094)	Tok/s 51918 (52413)	Loss/tok 4.2671 (6.3717)	Learning Rate [0.00125]
6: TRAIN [0][670/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00099)	Tok/s 51793 (52603)	Loss/tok 4.2294 (6.3668)	Learning Rate [0.00125]
3: TRAIN [0][670/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00100)	Tok/s 51977 (52308)	Loss/tok 4.2030 (6.3658)	Learning Rate [0.00125]
7: TRAIN [0][670/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00092)	Tok/s 51724 (52703)	Loss/tok 4.3132 (6.3698)	Learning Rate [0.00125]
8: TRAIN [0][670/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00101)	Tok/s 51660 (52785)	Loss/tok 4.3977 (6.3704)	Learning Rate [0.00125]
10: TRAIN [0][670/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00101)	Tok/s 51444 (52927)	Loss/tok 4.5160 (6.3724)	Learning Rate [0.00125]
2: TRAIN [0][670/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00099)	Tok/s 51934 (52202)	Loss/tok 4.4811 (6.3685)	Learning Rate [0.00125]
12: TRAIN [0][670/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00100)	Tok/s 51638 (53110)	Loss/tok 4.1038 (6.3710)	Learning Rate [0.00125]
11: TRAIN [0][670/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00101)	Tok/s 51586 (52998)	Loss/tok 4.3823 (6.3656)	Learning Rate [0.00125]
9: TRAIN [0][670/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00096)	Tok/s 51501 (52841)	Loss/tok 4.0040 (6.3716)	Learning Rate [0.00125]
1: TRAIN [0][670/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00092)	Tok/s 51818 (52093)	Loss/tok 4.3454 (6.3731)	Learning Rate [0.00125]
0: TRAIN [0][670/3416]	Time 0.049 (0.058)	Data 0.00082 (0.00092)	Tok/s 51731 (51985)	Loss/tok 4.3434 (6.3646)	Learning Rate [0.00125]
13: TRAIN [0][670/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00100)	Tok/s 51577 (53210)	Loss/tok 4.3864 (6.3771)	Learning Rate [0.00125]
14: TRAIN [0][670/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00097)	Tok/s 51620 (53320)	Loss/tok 4.0906 (6.3789)	Learning Rate [0.00125]
15: TRAIN [0][670/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00094)	Tok/s 51628 (53428)	Loss/tok 4.3776 (6.3791)	Learning Rate [0.00125]
12: Upscaling, new scale: 256.0
13: Upscaling, new scale: 256.0
14: Upscaling, new scale: 256.0
11: Upscaling, new scale: 256.0
10: Upscaling, new scale: 256.0
15: Upscaling, new scale: 256.0
0: Upscaling, new scale: 256.0
2: Upscaling, new scale: 256.0
8: Upscaling, new scale: 256.0
1: Upscaling, new scale: 256.0
9: Upscaling, new scale: 256.0
7: Upscaling, new scale: 256.0
3: Upscaling, new scale: 256.0
5: Upscaling, new scale: 256.0
6: Upscaling, new scale: 256.0
4: Upscaling, new scale: 256.0
14: TRAIN [0][680/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00097)	Tok/s 38498 (53328)	Loss/tok 3.9311 (6.3494)	Learning Rate [0.00125]
2: TRAIN [0][680/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00099)	Tok/s 37122 (52213)	Loss/tok 4.2338 (6.3402)	Learning Rate [0.00125]
0: TRAIN [0][680/3416]	Time 0.050 (0.058)	Data 0.00108 (0.00092)	Tok/s 37228 (51997)	Loss/tok 3.9797 (6.3363)	Learning Rate [0.00125]
15: TRAIN [0][680/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00094)	Tok/s 38497 (53436)	Loss/tok 4.1840 (6.3495)	Learning Rate [0.00125]
1: TRAIN [0][680/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00092)	Tok/s 37188 (52105)	Loss/tok 3.9549 (6.3448)	Learning Rate [0.00125]
13: TRAIN [0][680/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00100)	Tok/s 38321 (53218)	Loss/tok 3.8662 (6.3487)	Learning Rate [0.00125]
3: TRAIN [0][680/3416]	Time 0.050 (0.058)	Data 0.00111 (0.00100)	Tok/s 37039 (52318)	Loss/tok 3.9447 (6.3353)	Learning Rate [0.00125]
4: TRAIN [0][680/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00094)	Tok/s 36938 (52423)	Loss/tok 4.3212 (6.3430)	Learning Rate [0.00125]
11: TRAIN [0][680/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00101)	Tok/s 38157 (53005)	Loss/tok 4.1153 (6.3368)	Learning Rate [0.00125]
5: TRAIN [0][680/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00096)	Tok/s 37655 (52528)	Loss/tok 4.0335 (6.3515)	Learning Rate [0.00125]
10: TRAIN [0][680/3416]	Time 0.050 (0.058)	Data 0.00118 (0.00101)	Tok/s 38359 (52933)	Loss/tok 4.4136 (6.3449)	Learning Rate [0.00125]
12: TRAIN [0][680/3416]	Time 0.050 (0.058)	Data 0.00129 (0.00100)	Tok/s 38297 (53119)	Loss/tok 3.9071 (6.3418)	Learning Rate [0.00125]
8: TRAIN [0][680/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00101)	Tok/s 37940 (52791)	Loss/tok 4.2093 (6.3413)	Learning Rate [0.00125]
9: TRAIN [0][680/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00096)	Tok/s 37998 (52846)	Loss/tok 4.1456 (6.3423)	Learning Rate [0.00125]
6: TRAIN [0][680/3416]	Time 0.050 (0.058)	Data 0.00117 (0.00099)	Tok/s 38045 (52612)	Loss/tok 4.2313 (6.3373)	Learning Rate [0.00125]
7: TRAIN [0][680/3416]	Time 0.051 (0.058)	Data 0.00113 (0.00092)	Tok/s 37963 (52711)	Loss/tok 4.1303 (6.3421)	Learning Rate [0.00125]
5: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00096)	Tok/s 51083 (52526)	Loss/tok 4.1283 (6.3234)	Learning Rate [0.00125]
6: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00099)	Tok/s 51146 (52611)	Loss/tok 4.3635 (6.3099)	Learning Rate [0.00125]
4: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00105 (0.00094)	Tok/s 50964 (52421)	Loss/tok 4.3280 (6.3155)	Learning Rate [0.00125]
7: TRAIN [0][690/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00092)	Tok/s 51316 (52708)	Loss/tok 4.4169 (6.3148)	Learning Rate [0.00125]
8: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00101)	Tok/s 51122 (52787)	Loss/tok 4.4733 (6.3145)	Learning Rate [0.00125]
3: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00100)	Tok/s 50895 (52317)	Loss/tok 4.1796 (6.3084)	Learning Rate [0.00125]
2: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00099)	Tok/s 50808 (52212)	Loss/tok 4.0695 (6.3130)	Learning Rate [0.00125]
9: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00096)	Tok/s 51007 (52842)	Loss/tok 4.3416 (6.3156)	Learning Rate [0.00125]
10: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00100)	Tok/s 50867 (52927)	Loss/tok 4.4477 (6.3174)	Learning Rate [0.00125]
1: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00092)	Tok/s 50620 (52106)	Loss/tok 4.1962 (6.3174)	Learning Rate [0.00125]
12: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00100)	Tok/s 51381 (53115)	Loss/tok 4.2910 (6.3137)	Learning Rate [0.00125]
11: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00101)	Tok/s 50772 (53000)	Loss/tok 3.9734 (6.3094)	Learning Rate [0.00125]
0: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00092)	Tok/s 50509 (51999)	Loss/tok 4.1298 (6.3083)	Learning Rate [0.00125]
13: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00101)	Tok/s 51839 (53214)	Loss/tok 4.2000 (6.3209)	Learning Rate [0.00125]
15: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00082 (0.00094)	Tok/s 51692 (53429)	Loss/tok 4.5157 (6.3228)	Learning Rate [0.00125]
14: TRAIN [0][690/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00097)	Tok/s 51675 (53322)	Loss/tok 4.3639 (6.3217)	Learning Rate [0.00125]
10: TRAIN [0][700/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00101)	Tok/s 61052 (52892)	Loss/tok 4.7036 (6.2905)	Learning Rate [0.00125]
11: TRAIN [0][700/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00101)	Tok/s 61041 (52964)	Loss/tok 4.8379 (6.2825)	Learning Rate [0.00125]
12: TRAIN [0][700/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00100)	Tok/s 61032 (53080)	Loss/tok 4.8059 (6.2872)	Learning Rate [0.00125]
8: TRAIN [0][700/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00101)	Tok/s 60786 (52750)	Loss/tok 4.5681 (6.2882)	Learning Rate [0.00125]
9: TRAIN [0][700/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 60861 (52805)	Loss/tok 4.6311 (6.2891)	Learning Rate [0.00125]
13: TRAIN [0][700/3416]	Time 0.069 (0.058)	Data 0.00113 (0.00101)	Tok/s 61076 (53179)	Loss/tok 4.8031 (6.2934)	Learning Rate [0.00125]
7: TRAIN [0][700/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 60760 (52672)	Loss/tok 4.6419 (6.2866)	Learning Rate [0.00125]
14: TRAIN [0][700/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00097)	Tok/s 60942 (53287)	Loss/tok 4.6833 (6.2951)	Learning Rate [0.00125]
6: TRAIN [0][700/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00099)	Tok/s 60772 (52576)	Loss/tok 4.8629 (6.2846)	Learning Rate [0.00125]
15: TRAIN [0][700/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00094)	Tok/s 60974 (53394)	Loss/tok 4.6163 (6.2955)	Learning Rate [0.00125]
5: TRAIN [0][700/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 60770 (52493)	Loss/tok 4.8721 (6.2962)	Learning Rate [0.00125]
0: TRAIN [0][700/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 59900 (51967)	Loss/tok 4.6032 (6.2813)	Learning Rate [0.00125]
2: TRAIN [0][700/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00099)	Tok/s 60202 (52180)	Loss/tok 4.6501 (6.2866)	Learning Rate [0.00125]
4: TRAIN [0][700/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00094)	Tok/s 60742 (52389)	Loss/tok 4.7685 (6.2886)	Learning Rate [0.00125]
3: TRAIN [0][700/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00100)	Tok/s 60703 (52286)	Loss/tok 4.6147 (6.2817)	Learning Rate [0.00125]
1: TRAIN [0][700/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 59904 (52074)	Loss/tok 4.5293 (6.2907)	Learning Rate [0.00125]
5: TRAIN [0][710/3416]	Time 0.054 (0.058)	Data 0.00101 (0.00096)	Tok/s 50956 (52399)	Loss/tok 4.3068 (6.2727)	Learning Rate [0.00125]
4: TRAIN [0][710/3416]	Time 0.054 (0.058)	Data 0.00111 (0.00094)	Tok/s 50839 (52293)	Loss/tok 4.2287 (6.2651)	Learning Rate [0.00125]
3: TRAIN [0][710/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00100)	Tok/s 50792 (52187)	Loss/tok 4.3844 (6.2582)	Learning Rate [0.00125]
2: TRAIN [0][710/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00099)	Tok/s 50800 (52080)	Loss/tok 4.4881 (6.2633)	Learning Rate [0.00125]
15: TRAIN [0][710/3416]	Time 0.054 (0.058)	Data 0.00103 (0.00094)	Tok/s 50684 (53307)	Loss/tok 4.3667 (6.2705)	Learning Rate [0.00125]
6: TRAIN [0][710/3416]	Time 0.054 (0.058)	Data 0.00107 (0.00099)	Tok/s 50832 (52484)	Loss/tok 4.1644 (6.2611)	Learning Rate [0.00125]
1: TRAIN [0][710/3416]	Time 0.054 (0.058)	Data 0.00103 (0.00092)	Tok/s 50775 (51971)	Loss/tok 4.4710 (6.2670)	Learning Rate [0.00125]
7: TRAIN [0][710/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00092)	Tok/s 50798 (52580)	Loss/tok 4.5044 (6.2624)	Learning Rate [0.00125]
0: TRAIN [0][710/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00092)	Tok/s 50673 (51858)	Loss/tok 4.3484 (6.2580)	Learning Rate [0.00125]
14: TRAIN [0][710/3416]	Time 0.054 (0.058)	Data 0.00102 (0.00097)	Tok/s 50584 (53199)	Loss/tok 4.2739 (6.2710)	Learning Rate [0.00125]
8: TRAIN [0][710/3416]	Time 0.054 (0.058)	Data 0.00102 (0.00101)	Tok/s 50692 (52658)	Loss/tok 4.1636 (6.2643)	Learning Rate [0.00125]
10: TRAIN [0][710/3416]	Time 0.054 (0.058)	Data 0.00116 (0.00101)	Tok/s 50530 (52800)	Loss/tok 4.3263 (6.2668)	Learning Rate [0.00125]
13: TRAIN [0][710/3416]	Time 0.055 (0.058)	Data 0.00118 (0.00101)	Tok/s 50392 (53088)	Loss/tok 4.6633 (6.2701)	Learning Rate [0.00125]
12: TRAIN [0][710/3416]	Time 0.055 (0.058)	Data 0.00109 (0.00100)	Tok/s 50376 (52989)	Loss/tok 4.4007 (6.2630)	Learning Rate [0.00125]
9: TRAIN [0][710/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00096)	Tok/s 50619 (52714)	Loss/tok 4.0315 (6.2639)	Learning Rate [0.00125]
11: TRAIN [0][710/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00101)	Tok/s 50424 (52874)	Loss/tok 4.0882 (6.2588)	Learning Rate [0.00125]
0: TRAIN [0][720/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00092)	Tok/s 34334 (51760)	Loss/tok 3.8693 (6.2350)	Learning Rate [0.00125]
14: TRAIN [0][720/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00097)	Tok/s 34277 (53101)	Loss/tok 3.7793 (6.2482)	Learning Rate [0.00125]
13: TRAIN [0][720/3416]	Time 0.052 (0.058)	Data 0.00116 (0.00101)	Tok/s 34315 (52988)	Loss/tok 3.9133 (6.2484)	Learning Rate [0.00125]
10: TRAIN [0][720/3416]	Time 0.052 (0.058)	Data 0.00108 (0.00101)	Tok/s 34411 (52696)	Loss/tok 3.9981 (6.2443)	Learning Rate [0.00125]
12: TRAIN [0][720/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00100)	Tok/s 34312 (52890)	Loss/tok 3.8041 (6.2413)	Learning Rate [0.00125]
2: TRAIN [0][720/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00099)	Tok/s 34332 (51979)	Loss/tok 3.9455 (6.2411)	Learning Rate [0.00125]
11: TRAIN [0][720/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00101)	Tok/s 34334 (52774)	Loss/tok 3.7065 (6.2365)	Learning Rate [0.00125]
4: TRAIN [0][720/3416]	Time 0.052 (0.058)	Data 0.00109 (0.00094)	Tok/s 34279 (52191)	Loss/tok 4.0921 (6.2438)	Learning Rate [0.00125]
1: TRAIN [0][720/3416]	Time 0.052 (0.057)	Data 0.00097 (0.00092)	Tok/s 34259 (51871)	Loss/tok 3.7661 (6.2443)	Learning Rate [0.00125]
3: TRAIN [0][720/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00100)	Tok/s 34317 (52086)	Loss/tok 3.9936 (6.2358)	Learning Rate [0.00125]
5: TRAIN [0][720/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00096)	Tok/s 34326 (52297)	Loss/tok 3.8324 (6.2512)	Learning Rate [0.00125]
8: TRAIN [0][720/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00101)	Tok/s 34325 (52555)	Loss/tok 4.0267 (6.2412)	Learning Rate [0.00125]
9: TRAIN [0][720/3416]	Time 0.052 (0.057)	Data 0.00090 (0.00096)	Tok/s 34240 (52611)	Loss/tok 3.9691 (6.2412)	Learning Rate [0.00125]
6: TRAIN [0][720/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00099)	Tok/s 34341 (52381)	Loss/tok 3.7929 (6.2387)	Learning Rate [0.00125]
15: TRAIN [0][720/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00094)	Tok/s 33750 (53208)	Loss/tok 3.7387 (6.2480)	Learning Rate [0.00125]
7: TRAIN [0][720/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00092)	Tok/s 33733 (52475)	Loss/tok 3.5171 (6.2400)	Learning Rate [0.00125]
5: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00106 (0.00096)	Tok/s 54084 (52363)	Loss/tok 4.6157 (6.2226)	Learning Rate [0.00125]
7: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00117 (0.00092)	Tok/s 54145 (52540)	Loss/tok 4.4424 (6.2098)	Learning Rate [0.00125]
4: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00109 (0.00094)	Tok/s 54115 (52258)	Loss/tok 4.6014 (6.2140)	Learning Rate [0.00125]
8: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00101)	Tok/s 55029 (52618)	Loss/tok 4.3755 (6.2115)	Learning Rate [0.00125]
14: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00097)	Tok/s 55364 (53162)	Loss/tok 4.5549 (6.2187)	Learning Rate [0.00125]
0: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00092)	Tok/s 54259 (51831)	Loss/tok 4.1705 (6.2054)	Learning Rate [0.00125]
9: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00096)	Tok/s 55161 (52676)	Loss/tok 4.5153 (6.2101)	Learning Rate [0.00125]
3: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00100)	Tok/s 54109 (52153)	Loss/tok 4.6518 (6.2043)	Learning Rate [0.00125]
1: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00092)	Tok/s 54181 (51940)	Loss/tok 4.5567 (6.2159)	Learning Rate [0.00125]
6: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00099)	Tok/s 54103 (52446)	Loss/tok 4.3269 (6.2097)	Learning Rate [0.00125]
10: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00110 (0.00101)	Tok/s 55123 (52759)	Loss/tok 4.2293 (6.2158)	Learning Rate [0.00125]
15: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00094)	Tok/s 55370 (53272)	Loss/tok 4.5319 (6.2188)	Learning Rate [0.00125]
13: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00110 (0.00101)	Tok/s 55269 (53050)	Loss/tok 4.3996 (6.2182)	Learning Rate [0.00125]
12: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00105 (0.00100)	Tok/s 55186 (52953)	Loss/tok 4.4751 (6.2109)	Learning Rate [0.00125]
11: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00101)	Tok/s 55148 (52837)	Loss/tok 4.4029 (6.2069)	Learning Rate [0.00125]
2: TRAIN [0][730/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00099)	Tok/s 54021 (52047)	Loss/tok 4.4627 (6.2109)	Learning Rate [0.00125]
10: TRAIN [0][740/3416]	Time 0.053 (0.058)	Data 0.00105 (0.00101)	Tok/s 34113 (52790)	Loss/tok 4.0764 (6.1887)	Learning Rate [0.00125]
11: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00101)	Tok/s 34162 (52869)	Loss/tok 3.8698 (6.1797)	Learning Rate [0.00125]
12: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00100)	Tok/s 34158 (52984)	Loss/tok 3.8708 (6.1843)	Learning Rate [0.00125]
13: TRAIN [0][740/3416]	Time 0.052 (0.058)	Data 0.00122 (0.00101)	Tok/s 34298 (53079)	Loss/tok 4.0918 (6.1900)	Learning Rate [0.00125]
9: TRAIN [0][740/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00096)	Tok/s 34081 (52704)	Loss/tok 3.9520 (6.1829)	Learning Rate [0.00125]
8: TRAIN [0][740/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00101)	Tok/s 34034 (52646)	Loss/tok 3.7371 (6.1847)	Learning Rate [0.00125]
14: TRAIN [0][740/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00097)	Tok/s 34119 (53189)	Loss/tok 3.8902 (6.1914)	Learning Rate [0.00125]
15: TRAIN [0][740/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00094)	Tok/s 34876 (53299)	Loss/tok 4.0002 (6.1915)	Learning Rate [0.00125]
7: TRAIN [0][740/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00092)	Tok/s 33895 (52568)	Loss/tok 3.5854 (6.1824)	Learning Rate [0.00125]
6: TRAIN [0][740/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00099)	Tok/s 33889 (52474)	Loss/tok 4.0779 (6.1831)	Learning Rate [0.00125]
0: TRAIN [0][740/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00092)	Tok/s 34081 (51865)	Loss/tok 4.3095 (6.1783)	Learning Rate [0.00125]
5: TRAIN [0][740/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00096)	Tok/s 33864 (52392)	Loss/tok 3.9856 (6.1946)	Learning Rate [0.00125]
1: TRAIN [0][740/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00092)	Tok/s 34012 (51974)	Loss/tok 4.0128 (6.1877)	Learning Rate [0.00125]
2: TRAIN [0][740/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00099)	Tok/s 33966 (52080)	Loss/tok 4.0655 (6.1827)	Learning Rate [0.00125]
4: TRAIN [0][740/3416]	Time 0.053 (0.058)	Data 0.00105 (0.00094)	Tok/s 33861 (52288)	Loss/tok 3.9051 (6.1859)	Learning Rate [0.00125]
3: TRAIN [0][740/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00100)	Tok/s 33911 (52185)	Loss/tok 3.5639 (6.1760)	Learning Rate [0.00125]
9: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00086 (0.00096)	Tok/s 53941 (52756)	Loss/tok 4.3797 (6.1554)	Learning Rate [0.00125]
8: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00101)	Tok/s 53900 (52698)	Loss/tok 4.3519 (6.1576)	Learning Rate [0.00125]
10: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00104 (0.00101)	Tok/s 53969 (52842)	Loss/tok 4.2899 (6.1608)	Learning Rate [0.00125]
7: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00092)	Tok/s 53867 (52619)	Loss/tok 4.3565 (6.1550)	Learning Rate [0.00125]
11: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00101)	Tok/s 53968 (52921)	Loss/tok 4.9905 (6.1544)	Learning Rate [0.00125]
5: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00096)	Tok/s 53915 (52445)	Loss/tok 4.2220 (6.1682)	Learning Rate [0.00125]
6: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00099)	Tok/s 53842 (52526)	Loss/tok 4.5341 (6.1560)	Learning Rate [0.00125]
12: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00100)	Tok/s 53895 (53036)	Loss/tok 4.4172 (6.1557)	Learning Rate [0.00125]
4: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00094)	Tok/s 53880 (52343)	Loss/tok 4.6001 (6.1583)	Learning Rate [0.00125]
14: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00097)	Tok/s 53877 (53242)	Loss/tok 4.5209 (6.1642)	Learning Rate [0.00125]
3: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00100)	Tok/s 53894 (52241)	Loss/tok 4.5465 (6.1492)	Learning Rate [0.00125]
2: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00099)	Tok/s 53871 (52135)	Loss/tok 4.4878 (6.1546)	Learning Rate [0.00125]
15: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00094)	Tok/s 53825 (53351)	Loss/tok 4.4850 (6.1644)	Learning Rate [0.00125]
13: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00101)	Tok/s 53950 (53133)	Loss/tok 4.2952 (6.1621)	Learning Rate [0.00125]
1: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00092)	Tok/s 53819 (52031)	Loss/tok 4.5384 (6.1600)	Learning Rate [0.00125]
0: TRAIN [0][750/3416]	Time 0.065 (0.058)	Data 0.00083 (0.00092)	Tok/s 53779 (51924)	Loss/tok 4.4779 (6.1517)	Learning Rate [0.00125]
12: Gradient norm: inf
13: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 128.0
13: Skipped batch, new scale: 128.0
14: Gradient norm: inf
11: Skipped batch, new scale: 128.0
10: Gradient norm: inf
15: Gradient norm: inf
9: Gradient norm: inf
14: Skipped batch, new scale: 128.0
10: Skipped batch, new scale: 128.0
15: Skipped batch, new scale: 128.0
0: Gradient norm: inf
9: Skipped batch, new scale: 128.0
8: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
0: Skipped batch, new scale: 128.0
8: Skipped batch, new scale: 128.0
7: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 128.0
6: Gradient norm: inf
2: Skipped batch, new scale: 128.0
7: Skipped batch, new scale: 128.0
4: Gradient norm: inf
5: Gradient norm: inf
3: Skipped batch, new scale: 128.0
6: Skipped batch, new scale: 128.0
5: Skipped batch, new scale: 128.0
4: Skipped batch, new scale: 128.0
15: TRAIN [0][760/3416]	Time 0.055 (0.058)	Data 0.00105 (0.00094)	Tok/s 51951 (53468)	Loss/tok 4.2400 (6.1350)	Learning Rate [0.00125]
14: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00104 (0.00097)	Tok/s 51881 (53358)	Loss/tok 4.3395 (6.1349)	Learning Rate [0.00125]
0: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00099 (0.00092)	Tok/s 51849 (52039)	Loss/tok 4.5088 (6.1228)	Learning Rate [0.00125]
13: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00109 (0.00101)	Tok/s 51762 (53246)	Loss/tok 4.3195 (6.1338)	Learning Rate [0.00125]
1: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00107 (0.00092)	Tok/s 51704 (52147)	Loss/tok 4.0609 (6.1299)	Learning Rate [0.00125]
12: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00100 (0.00100)	Tok/s 51536 (53149)	Loss/tok 4.5616 (6.1274)	Learning Rate [0.00125]
2: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00111 (0.00099)	Tok/s 51612 (52251)	Loss/tok 4.4232 (6.1263)	Learning Rate [0.00125]
11: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00101)	Tok/s 51556 (53035)	Loss/tok 4.0784 (6.1249)	Learning Rate [0.00125]
3: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00096 (0.00100)	Tok/s 51496 (52356)	Loss/tok 4.3219 (6.1194)	Learning Rate [0.00125]
10: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00114 (0.00101)	Tok/s 51409 (52956)	Loss/tok 4.3184 (6.1306)	Learning Rate [0.00125]
4: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00103 (0.00094)	Tok/s 51380 (52457)	Loss/tok 4.3038 (6.1292)	Learning Rate [0.00125]
9: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00096)	Tok/s 51342 (52869)	Loss/tok 4.1209 (6.1259)	Learning Rate [0.00125]
8: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00115 (0.00101)	Tok/s 51224 (52811)	Loss/tok 4.3950 (6.1268)	Learning Rate [0.00125]
7: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00092)	Tok/s 51138 (52733)	Loss/tok 4.6048 (6.1261)	Learning Rate [0.00125]
6: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00099)	Tok/s 51167 (52640)	Loss/tok 4.3193 (6.1260)	Learning Rate [0.00125]
5: TRAIN [0][760/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00096)	Tok/s 51247 (52559)	Loss/tok 4.2844 (6.1389)	Learning Rate [0.00125]
15: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00094)	Tok/s 71630 (53469)	Loss/tok 4.4356 (6.1106)	Learning Rate [0.00125]
14: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 71649 (53360)	Loss/tok 4.5982 (6.1105)	Learning Rate [0.00125]
12: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00100)	Tok/s 71775 (53154)	Loss/tok 4.3860 (6.1026)	Learning Rate [0.00125]
0: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 70597 (52049)	Loss/tok 4.4034 (6.0987)	Learning Rate [0.00125]
13: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00101)	Tok/s 71737 (53250)	Loss/tok 4.4388 (6.1101)	Learning Rate [0.00125]
1: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 70468 (52156)	Loss/tok 4.5657 (6.1062)	Learning Rate [0.00125]
2: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 70361 (52259)	Loss/tok 4.5799 (6.1029)	Learning Rate [0.00125]
11: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00101)	Tok/s 71322 (53039)	Loss/tok 4.5249 (6.1019)	Learning Rate [0.00125]
10: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00101)	Tok/s 70498 (52960)	Loss/tok 4.4297 (6.1065)	Learning Rate [0.00125]
3: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 70250 (52363)	Loss/tok 4.5142 (6.0946)	Learning Rate [0.00125]
8: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00101)	Tok/s 70380 (52817)	Loss/tok 4.3400 (6.1022)	Learning Rate [0.00125]
9: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00096)	Tok/s 70450 (52874)	Loss/tok 4.2907 (6.1005)	Learning Rate [0.00125]
5: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00096)	Tok/s 70163 (52564)	Loss/tok 4.5932 (6.1142)	Learning Rate [0.00125]
6: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 70200 (52646)	Loss/tok 4.4289 (6.1008)	Learning Rate [0.00125]
7: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 70293 (52740)	Loss/tok 4.3990 (6.1023)	Learning Rate [0.00125]
4: TRAIN [0][770/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00094)	Tok/s 70135 (52462)	Loss/tok 4.3486 (6.1051)	Learning Rate [0.00125]
4: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00103 (0.00094)	Tok/s 32289 (52494)	Loss/tok 3.6273 (6.0800)	Learning Rate [0.00125]
10: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00117 (0.00101)	Tok/s 32308 (52989)	Loss/tok 3.6395 (6.0817)	Learning Rate [0.00125]
5: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00096)	Tok/s 32297 (52595)	Loss/tok 3.2912 (6.0902)	Learning Rate [0.00125]
6: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00098)	Tok/s 32363 (52675)	Loss/tok 3.4678 (6.0766)	Learning Rate [0.00125]
9: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00096)	Tok/s 32335 (52902)	Loss/tok 3.2811 (6.0759)	Learning Rate [0.00125]
2: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00099)	Tok/s 30662 (52289)	Loss/tok 3.3037 (6.0779)	Learning Rate [0.00125]
8: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00101)	Tok/s 32347 (52844)	Loss/tok 3.7537 (6.0784)	Learning Rate [0.00125]
7: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00092)	Tok/s 32357 (52768)	Loss/tok 3.5257 (6.0774)	Learning Rate [0.00125]
11: TRAIN [0][780/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00101)	Tok/s 32545 (53067)	Loss/tok 3.2119 (6.0763)	Learning Rate [0.00125]
12: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00100)	Tok/s 32161 (53182)	Loss/tok 3.2630 (6.0769)	Learning Rate [0.00125]
3: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00100)	Tok/s 31984 (52394)	Loss/tok 3.4430 (6.0704)	Learning Rate [0.00125]
15: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00094)	Tok/s 32497 (53495)	Loss/tok 3.5578 (6.0856)	Learning Rate [0.00125]
13: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00106 (0.00101)	Tok/s 32081 (53278)	Loss/tok 3.5186 (6.0855)	Learning Rate [0.00125]
1: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00102 (0.00093)	Tok/s 30564 (52187)	Loss/tok 3.2055 (6.0816)	Learning Rate [0.00125]
14: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00097)	Tok/s 32023 (53387)	Loss/tok 3.5147 (6.0857)	Learning Rate [0.00125]
0: TRAIN [0][780/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00092)	Tok/s 30505 (52081)	Loss/tok 3.3131 (6.0739)	Learning Rate [0.00125]
3: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 63142 (52471)	Loss/tok 4.2765 (6.0434)	Learning Rate [0.00125]
4: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00094)	Tok/s 63179 (52574)	Loss/tok 4.3122 (6.0533)	Learning Rate [0.00125]
2: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00099)	Tok/s 63037 (52365)	Loss/tok 4.2334 (6.0519)	Learning Rate [0.00125]
1: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 63080 (52264)	Loss/tok 4.3717 (6.0540)	Learning Rate [0.00125]
5: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 63155 (52673)	Loss/tok 4.3512 (6.0624)	Learning Rate [0.00125]
0: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 62216 (52159)	Loss/tok 4.4219 (6.0473)	Learning Rate [0.00125]
15: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00094)	Tok/s 63052 (53576)	Loss/tok 4.4564 (6.0591)	Learning Rate [0.00125]
7: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 63140 (52846)	Loss/tok 4.2826 (6.0500)	Learning Rate [0.00125]
6: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 63135 (52752)	Loss/tok 4.2383 (6.0494)	Learning Rate [0.00125]
12: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 63149 (53264)	Loss/tok 4.2163 (6.0502)	Learning Rate [0.00125]
11: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00101)	Tok/s 63267 (53149)	Loss/tok 4.4132 (6.0493)	Learning Rate [0.00125]
14: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 63069 (53469)	Loss/tok 4.2883 (6.0599)	Learning Rate [0.00125]
10: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00101)	Tok/s 63062 (53069)	Loss/tok 4.3700 (6.0554)	Learning Rate [0.00125]
8: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00101)	Tok/s 63002 (52923)	Loss/tok 4.4114 (6.0510)	Learning Rate [0.00125]
13: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00101)	Tok/s 63055 (53359)	Loss/tok 4.3014 (6.0588)	Learning Rate [0.00125]
9: TRAIN [0][790/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 63016 (52982)	Loss/tok 4.2183 (6.0481)	Learning Rate [0.00125]
8: TRAIN [0][800/3416]	Time 0.033 (0.058)	Data 0.00102 (0.00101)	Tok/s 24983 (52895)	Loss/tok 2.0467 (6.0300)	Learning Rate [0.00125]
5: TRAIN [0][800/3416]	Time 0.033 (0.058)	Data 0.00092 (0.00096)	Tok/s 21103 (52640)	Loss/tok 2.5203 (6.0403)	Learning Rate [0.00125]
6: TRAIN [0][800/3416]	Time 0.033 (0.058)	Data 0.00092 (0.00098)	Tok/s 22891 (52722)	Loss/tok 2.7190 (6.0280)	Learning Rate [0.00125]
9: TRAIN [0][800/3416]	Time 0.033 (0.058)	Data 0.00090 (0.00096)	Tok/s 24897 (52953)	Loss/tok 2.3379 (6.0261)	Learning Rate [0.00125]
4: TRAIN [0][800/3416]	Time 0.033 (0.058)	Data 0.00096 (0.00094)	Tok/s 19480 (52540)	Loss/tok 2.8892 (6.0310)	Learning Rate [0.00125]
10: TRAIN [0][800/3416]	Time 0.034 (0.058)	Data 0.00105 (0.00101)	Tok/s 24812 (53039)	Loss/tok 2.2656 (6.0327)	Learning Rate [0.00125]
3: TRAIN [0][800/3416]	Time 0.034 (0.058)	Data 0.00091 (0.00100)	Tok/s 17159 (52435)	Loss/tok 1.8422 (6.0206)	Learning Rate [0.00125]
11: TRAIN [0][800/3416]	Time 0.034 (0.058)	Data 0.00096 (0.00101)	Tok/s 24872 (53118)	Loss/tok 2.3458 (6.0268)	Learning Rate [0.00125]
2: TRAIN [0][800/3416]	Time 0.034 (0.058)	Data 0.00085 (0.00099)	Tok/s 15848 (52327)	Loss/tok 2.4254 (6.0313)	Learning Rate [0.00125]
12: TRAIN [0][800/3416]	Time 0.034 (0.058)	Data 0.00091 (0.00100)	Tok/s 26563 (53235)	Loss/tok 3.1776 (6.0279)	Learning Rate [0.00125]
13: TRAIN [0][800/3416]	Time 0.034 (0.058)	Data 0.00094 (0.00101)	Tok/s 26506 (53331)	Loss/tok 3.2029 (6.0361)	Learning Rate [0.00125]
0: TRAIN [0][800/3416]	Time 0.034 (0.058)	Data 0.00086 (0.00092)	Tok/s 9451 (52113)	Loss/tok 1.5254 (6.0263)	Learning Rate [0.00125]
1: TRAIN [0][800/3416]	Time 0.034 (0.058)	Data 0.00088 (0.00093)	Tok/s 12190 (52222)	Loss/tok 2.0853 (6.0325)	Learning Rate [0.00125]
15: TRAIN [0][800/3416]	Time 0.034 (0.058)	Data 0.00089 (0.00094)	Tok/s 28223 (53550)	Loss/tok 2.7390 (6.0372)	Learning Rate [0.00125]
14: TRAIN [0][800/3416]	Time 0.034 (0.058)	Data 0.00087 (0.00097)	Tok/s 27019 (53440)	Loss/tok 2.8069 (6.0382)	Learning Rate [0.00125]
7: TRAIN [0][800/3416]	Time 0.033 (0.058)	Data 0.00110 (0.00092)	Tok/s 23774 (52817)	Loss/tok 2.8577 (6.0276)	Learning Rate [0.00125]
6: TRAIN [0][810/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00098)	Tok/s 58187 (52698)	Loss/tok 4.2240 (6.0062)	Learning Rate [0.00125]
5: TRAIN [0][810/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00096)	Tok/s 58119 (52617)	Loss/tok 4.5074 (6.0188)	Learning Rate [0.00125]
4: TRAIN [0][810/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00094)	Tok/s 57970 (52515)	Loss/tok 4.3670 (6.0083)	Learning Rate [0.00125]
7: TRAIN [0][810/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00093)	Tok/s 58457 (52792)	Loss/tok 4.3200 (6.0052)	Learning Rate [0.00125]
10: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00102)	Tok/s 57912 (53014)	Loss/tok 4.3982 (6.0108)	Learning Rate [0.00125]
9: TRAIN [0][810/3416]	Time 0.068 (0.058)	Data 0.00076 (0.00095)	Tok/s 58022 (52929)	Loss/tok 4.4739 (6.0042)	Learning Rate [0.00125]
2: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 57778 (52303)	Loss/tok 4.2571 (6.0098)	Learning Rate [0.00125]
8: TRAIN [0][810/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00101)	Tok/s 58110 (52870)	Loss/tok 4.3604 (6.0087)	Learning Rate [0.00125]
11: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00101)	Tok/s 57835 (53094)	Loss/tok 4.6454 (6.0060)	Learning Rate [0.00125]
15: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00094)	Tok/s 58632 (53522)	Loss/tok 4.2779 (6.0151)	Learning Rate [0.00125]
12: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00100)	Tok/s 57740 (53210)	Loss/tok 4.3272 (6.0056)	Learning Rate [0.00125]
1: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 57735 (52199)	Loss/tok 4.2869 (6.0114)	Learning Rate [0.00125]
14: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 58021 (53413)	Loss/tok 4.7485 (6.0168)	Learning Rate [0.00125]
0: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 57675 (52091)	Loss/tok 4.1797 (6.0047)	Learning Rate [0.00125]
3: TRAIN [0][810/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 57113 (52409)	Loss/tok 4.4707 (5.9979)	Learning Rate [0.00125]
13: TRAIN [0][810/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00101)	Tok/s 56890 (53304)	Loss/tok 4.2411 (6.0137)	Learning Rate [0.00125]
4: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00094)	Tok/s 73187 (52485)	Loss/tok 4.2109 (5.9875)	Learning Rate [0.00125]
5: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00096)	Tok/s 73854 (52587)	Loss/tok 4.4762 (5.9991)	Learning Rate [0.00125]
6: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 73976 (52668)	Loss/tok 4.2419 (5.9858)	Learning Rate [0.00125]
7: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 73819 (52761)	Loss/tok 4.1397 (5.9840)	Learning Rate [0.00125]
3: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00100)	Tok/s 73168 (52381)	Loss/tok 3.9771 (5.9772)	Learning Rate [0.00125]
2: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00098)	Tok/s 73139 (52275)	Loss/tok 4.2914 (5.9892)	Learning Rate [0.00125]
8: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00101)	Tok/s 73833 (52838)	Loss/tok 4.0628 (5.9873)	Learning Rate [0.00125]
1: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 73191 (52172)	Loss/tok 4.5830 (5.9913)	Learning Rate [0.00125]
0: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 73188 (52065)	Loss/tok 4.3032 (5.9841)	Learning Rate [0.00125]
9: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00095)	Tok/s 73847 (52898)	Loss/tok 4.3165 (5.9834)	Learning Rate [0.00125]
10: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00101)	Tok/s 73918 (52982)	Loss/tok 4.3944 (5.9911)	Learning Rate [0.00125]
15: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00094)	Tok/s 74952 (53491)	Loss/tok 4.4428 (5.9945)	Learning Rate [0.00125]
11: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00101)	Tok/s 73901 (53062)	Loss/tok 4.2474 (5.9848)	Learning Rate [0.00125]
12: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00100)	Tok/s 73914 (53179)	Loss/tok 4.4861 (5.9857)	Learning Rate [0.00125]
14: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 74466 (53384)	Loss/tok 4.2839 (5.9959)	Learning Rate [0.00125]
13: TRAIN [0][820/3416]	Time 0.070 (0.058)	Data 0.00415 (0.00101)	Tok/s 74058 (53275)	Loss/tok 4.2866 (5.9935)	Learning Rate [0.00125]
7: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00099 (0.00092)	Tok/s 30736 (52680)	Loss/tok 3.2105 (5.9656)	Learning Rate [0.00125]
8: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00104 (0.00101)	Tok/s 30667 (52758)	Loss/tok 3.3915 (5.9692)	Learning Rate [0.00125]
11: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00098 (0.00101)	Tok/s 30625 (52981)	Loss/tok 3.3755 (5.9663)	Learning Rate [0.00125]
3: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00101 (0.00100)	Tok/s 29096 (52299)	Loss/tok 2.9443 (5.9588)	Learning Rate [0.00125]
10: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00098 (0.00101)	Tok/s 30663 (52901)	Loss/tok 3.3459 (5.9729)	Learning Rate [0.00125]
4: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00104 (0.00094)	Tok/s 29108 (52401)	Loss/tok 3.1809 (5.9686)	Learning Rate [0.00125]
5: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00102 (0.00096)	Tok/s 29674 (52502)	Loss/tok 3.2227 (5.9813)	Learning Rate [0.00125]
9: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00098 (0.00095)	Tok/s 30628 (52818)	Loss/tok 3.2532 (5.9655)	Learning Rate [0.00125]
6: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00099 (0.00098)	Tok/s 30693 (52585)	Loss/tok 3.3776 (5.9678)	Learning Rate [0.00125]
2: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00097 (0.00098)	Tok/s 29092 (52194)	Loss/tok 3.3019 (5.9717)	Learning Rate [0.00125]
12: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00103 (0.00100)	Tok/s 30641 (53099)	Loss/tok 3.1626 (5.9676)	Learning Rate [0.00125]
13: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00098 (0.00101)	Tok/s 30644 (53195)	Loss/tok 2.9024 (5.9755)	Learning Rate [0.00125]
1: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00096 (0.00093)	Tok/s 29125 (52092)	Loss/tok 3.4055 (5.9725)	Learning Rate [0.00125]
15: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00112 (0.00094)	Tok/s 32339 (53411)	Loss/tok 3.1440 (5.9762)	Learning Rate [0.00125]
14: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00105 (0.00097)	Tok/s 31183 (53303)	Loss/tok 3.3279 (5.9775)	Learning Rate [0.00125]
0: TRAIN [0][830/3416]	Time 0.040 (0.058)	Data 0.00099 (0.00092)	Tok/s 29116 (51987)	Loss/tok 3.0793 (5.9657)	Learning Rate [0.00125]
7: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00091 (0.00093)	Tok/s 21928 (52611)	Loss/tok 2.8360 (5.9458)	Learning Rate [0.00125]
8: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00097 (0.00101)	Tok/s 23332 (52692)	Loss/tok 2.4136 (5.9504)	Learning Rate [0.00125]
6: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00095 (0.00098)	Tok/s 21182 (52516)	Loss/tok 2.7834 (5.9487)	Learning Rate [0.00125]
5: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00101 (0.00096)	Tok/s 19631 (52430)	Loss/tok 2.5747 (5.9621)	Learning Rate [0.00125]
10: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00098 (0.00101)	Tok/s 23211 (52834)	Loss/tok 2.4413 (5.9539)	Learning Rate [0.00125]
4: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00088 (0.00094)	Tok/s 17883 (52326)	Loss/tok 2.5365 (5.9505)	Learning Rate [0.00125]
9: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00110 (0.00095)	Tok/s 23279 (52751)	Loss/tok 2.3355 (5.9471)	Learning Rate [0.00125]
2: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00099 (0.00098)	Tok/s 15083 (52113)	Loss/tok 2.1010 (5.9524)	Learning Rate [0.00125]
11: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00097 (0.00101)	Tok/s 23171 (52914)	Loss/tok 2.4624 (5.9467)	Learning Rate [0.00125]
3: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00093 (0.00100)	Tok/s 15977 (52219)	Loss/tok 1.8126 (5.9397)	Learning Rate [0.00125]
12: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00105 (0.00099)	Tok/s 24577 (53036)	Loss/tok 2.7375 (5.9490)	Learning Rate [0.00125]
13: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00097 (0.00101)	Tok/s 24801 (53131)	Loss/tok 2.7546 (5.9573)	Learning Rate [0.00125]
14: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00091 (0.00097)	Tok/s 25028 (53239)	Loss/tok 2.7968 (5.9582)	Learning Rate [0.00125]
1: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00089 (0.00093)	Tok/s 11519 (52004)	Loss/tok 2.5941 (5.9542)	Learning Rate [0.00125]
0: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00091 (0.00092)	Tok/s 8818 (51892)	Loss/tok 1.5017 (5.9475)	Learning Rate [0.00125]
15: TRAIN [0][840/3416]	Time 0.036 (0.058)	Data 0.00108 (0.00094)	Tok/s 26424 (53349)	Loss/tok 2.8164 (5.9567)	Learning Rate [0.00125]
12: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00099)	Tok/s 52496 (53021)	Loss/tok 3.8947 (5.9293)	Learning Rate [0.00125]
11: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00101)	Tok/s 52352 (52901)	Loss/tok 4.0283 (5.9270)	Learning Rate [0.00125]
13: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00101)	Tok/s 52459 (53115)	Loss/tok 4.1137 (5.9384)	Learning Rate [0.00125]
10: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00101)	Tok/s 52268 (52821)	Loss/tok 4.0818 (5.9345)	Learning Rate [0.00125]
14: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00097)	Tok/s 52501 (53222)	Loss/tok 4.0681 (5.9382)	Learning Rate [0.00125]
15: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00101 (0.00095)	Tok/s 52510 (53332)	Loss/tok 4.2258 (5.9378)	Learning Rate [0.00125]
8: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00101)	Tok/s 52251 (52679)	Loss/tok 4.2060 (5.9312)	Learning Rate [0.00125]
9: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00081 (0.00095)	Tok/s 52213 (52738)	Loss/tok 3.9484 (5.9277)	Learning Rate [0.00125]
0: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00092)	Tok/s 51176 (51880)	Loss/tok 4.0387 (5.9287)	Learning Rate [0.00125]
7: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00093)	Tok/s 52254 (52599)	Loss/tok 4.2062 (5.9267)	Learning Rate [0.00125]
1: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00082 (0.00093)	Tok/s 51158 (51992)	Loss/tok 4.2368 (5.9340)	Learning Rate [0.00125]
2: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00098)	Tok/s 51050 (52100)	Loss/tok 4.3530 (5.9328)	Learning Rate [0.00125]
5: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00096)	Tok/s 52260 (52418)	Loss/tok 4.0748 (5.9417)	Learning Rate [0.00125]
6: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00098)	Tok/s 52235 (52505)	Loss/tok 3.9939 (5.9286)	Learning Rate [0.00125]
4: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00094)	Tok/s 52276 (52315)	Loss/tok 4.1245 (5.9308)	Learning Rate [0.00125]
3: TRAIN [0][850/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00100)	Tok/s 52089 (52208)	Loss/tok 4.0927 (5.9202)	Learning Rate [0.00125]
15: TRAIN [0][860/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00095)	Tok/s 55346 (53307)	Loss/tok 4.3548 (5.9181)	Learning Rate [0.00125]
14: TRAIN [0][860/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00097)	Tok/s 55363 (53197)	Loss/tok 4.3288 (5.9198)	Learning Rate [0.00125]
0: TRAIN [0][860/3416]	Time 0.063 (0.058)	Data 0.00083 (0.00092)	Tok/s 54224 (51856)	Loss/tok 4.0758 (5.9090)	Learning Rate [0.00125]
1: TRAIN [0][860/3416]	Time 0.063 (0.058)	Data 0.00076 (0.00092)	Tok/s 54181 (51967)	Loss/tok 3.9670 (5.9147)	Learning Rate [0.00125]
13: TRAIN [0][860/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00101)	Tok/s 55417 (53085)	Loss/tok 4.4743 (5.9192)	Learning Rate [0.00125]
2: TRAIN [0][860/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00098)	Tok/s 54055 (52073)	Loss/tok 4.2077 (5.9139)	Learning Rate [0.00125]
12: TRAIN [0][860/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00099)	Tok/s 55370 (52991)	Loss/tok 4.3636 (5.9116)	Learning Rate [0.00125]
11: TRAIN [0][860/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00101)	Tok/s 55367 (52872)	Loss/tok 4.3976 (5.9083)	Learning Rate [0.00125]
10: TRAIN [0][860/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00101)	Tok/s 55328 (52793)	Loss/tok 4.1039 (5.9152)	Learning Rate [0.00125]
4: TRAIN [0][860/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00094)	Tok/s 54000 (52288)	Loss/tok 4.4109 (5.9126)	Learning Rate [0.00125]
3: TRAIN [0][860/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00100)	Tok/s 53970 (52180)	Loss/tok 4.2558 (5.9020)	Learning Rate [0.00125]
9: TRAIN [0][860/3416]	Time 0.063 (0.058)	Data 0.00081 (0.00095)	Tok/s 54566 (52710)	Loss/tok 4.4845 (5.9089)	Learning Rate [0.00125]
5: TRAIN [0][860/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00096)	Tok/s 53973 (52391)	Loss/tok 4.0198 (5.9227)	Learning Rate [0.00125]
8: TRAIN [0][860/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00101)	Tok/s 54085 (52651)	Loss/tok 4.3884 (5.9127)	Learning Rate [0.00125]
7: TRAIN [0][860/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00093)	Tok/s 54052 (52570)	Loss/tok 4.4028 (5.9084)	Learning Rate [0.00125]
6: TRAIN [0][860/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00098)	Tok/s 53929 (52477)	Loss/tok 4.0649 (5.9104)	Learning Rate [0.00125]
0: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00092)	Tok/s 51636 (51802)	Loss/tok 3.8937 (5.8895)	Learning Rate [0.00125]
15: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00095)	Tok/s 52915 (53270)	Loss/tok 3.9819 (5.8995)	Learning Rate [0.00125]
1: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00092)	Tok/s 51466 (51915)	Loss/tok 4.0714 (5.8972)	Learning Rate [0.00125]
14: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00097)	Tok/s 52838 (53160)	Loss/tok 4.0051 (5.9007)	Learning Rate [0.00125]
2: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00098)	Tok/s 51373 (52024)	Loss/tok 4.2512 (5.8950)	Learning Rate [0.00125]
13: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00101)	Tok/s 52861 (53050)	Loss/tok 4.1044 (5.9002)	Learning Rate [0.00125]
12: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00099)	Tok/s 52812 (52953)	Loss/tok 3.7785 (5.8918)	Learning Rate [0.00125]
4: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00094)	Tok/s 51198 (52241)	Loss/tok 3.9885 (5.8932)	Learning Rate [0.00125]
3: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00100)	Tok/s 51306 (52132)	Loss/tok 4.1686 (5.8835)	Learning Rate [0.00125]
11: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00101)	Tok/s 52650 (52831)	Loss/tok 3.7946 (5.8893)	Learning Rate [0.00125]
5: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00096)	Tok/s 51108 (52347)	Loss/tok 4.1844 (5.9041)	Learning Rate [0.00125]
6: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00098)	Tok/s 51039 (52434)	Loss/tok 4.0496 (5.8915)	Learning Rate [0.00125]
8: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00101)	Tok/s 51120 (52609)	Loss/tok 4.3711 (5.8943)	Learning Rate [0.00125]
9: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00095)	Tok/s 51186 (52669)	Loss/tok 4.2765 (5.8901)	Learning Rate [0.00125]
7: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00093)	Tok/s 51078 (52528)	Loss/tok 4.3029 (5.8898)	Learning Rate [0.00125]
10: TRAIN [0][870/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00101)	Tok/s 52005 (52752)	Loss/tok 4.3122 (5.8964)	Learning Rate [0.00125]
5: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00094 (0.00096)	Tok/s 52334 (52391)	Loss/tok 4.0622 (5.8825)	Learning Rate [0.00125]
6: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00098)	Tok/s 52419 (52478)	Loss/tok 4.1885 (5.8684)	Learning Rate [0.00125]
4: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00083 (0.00094)	Tok/s 52259 (52285)	Loss/tok 4.1663 (5.8718)	Learning Rate [0.00125]
8: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00094 (0.00101)	Tok/s 52274 (52653)	Loss/tok 4.2103 (5.8719)	Learning Rate [0.00125]
7: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00093)	Tok/s 52395 (52572)	Loss/tok 4.0289 (5.8668)	Learning Rate [0.00125]
2: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00098)	Tok/s 52021 (52069)	Loss/tok 4.0883 (5.8728)	Learning Rate [0.00125]
3: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00100)	Tok/s 52141 (52177)	Loss/tok 3.9471 (5.8615)	Learning Rate [0.00125]
10: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00102 (0.00101)	Tok/s 52131 (52797)	Loss/tok 3.9587 (5.8734)	Learning Rate [0.00125]
0: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00092)	Tok/s 51995 (51848)	Loss/tok 3.7869 (5.8667)	Learning Rate [0.00125]
1: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00092)	Tok/s 51953 (51960)	Loss/tok 4.0032 (5.8742)	Learning Rate [0.00125]
9: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00082 (0.00095)	Tok/s 52234 (52713)	Loss/tok 4.2298 (5.8676)	Learning Rate [0.00125]
11: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00101)	Tok/s 52064 (52878)	Loss/tok 4.0555 (5.8671)	Learning Rate [0.00125]
15: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00099 (0.00095)	Tok/s 53129 (53319)	Loss/tok 4.0107 (5.8769)	Learning Rate [0.00125]
14: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00097)	Tok/s 52389 (53207)	Loss/tok 4.1505 (5.8787)	Learning Rate [0.00125]
12: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00099)	Tok/s 51958 (53000)	Loss/tok 3.7702 (5.8692)	Learning Rate [0.00125]
13: TRAIN [0][880/3416]	Time 0.054 (0.058)	Data 0.00094 (0.00101)	Tok/s 51916 (53097)	Loss/tok 3.9023 (5.8775)	Learning Rate [0.00125]
5: Upscaling, new scale: 256.0
6: Upscaling, new scale: 256.0
7: Upscaling, new scale: 256.0
4: Upscaling, new scale: 256.0
8: Upscaling, new scale: 256.0
2: Upscaling, new scale: 256.0
10: Upscaling, new scale: 256.0
9: Upscaling, new scale: 256.0
11: Upscaling, new scale: 256.0
1: Upscaling, new scale: 256.0
3: Upscaling, new scale: 256.0
13: Upscaling, new scale: 256.0
12: Upscaling, new scale: 256.0
0: Upscaling, new scale: 256.0
15: Upscaling, new scale: 256.0
14: Upscaling, new scale: 256.0
8: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00101)	Tok/s 72620 (52675)	Loss/tok 4.1906 (5.8519)	Learning Rate [0.00125]
7: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00093)	Tok/s 72639 (52594)	Loss/tok 4.3455 (5.8471)	Learning Rate [0.00125]
10: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00101)	Tok/s 72390 (52819)	Loss/tok 4.0734 (5.8529)	Learning Rate [0.00125]
6: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 72624 (52501)	Loss/tok 4.4361 (5.8488)	Learning Rate [0.00125]
9: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00095)	Tok/s 72511 (52736)	Loss/tok 4.2587 (5.8482)	Learning Rate [0.00125]
11: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00100)	Tok/s 72259 (52899)	Loss/tok 4.1262 (5.8476)	Learning Rate [0.00125]
4: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00094)	Tok/s 72630 (52309)	Loss/tok 4.4553 (5.8527)	Learning Rate [0.00125]
12: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00100)	Tok/s 72141 (53020)	Loss/tok 4.3973 (5.8507)	Learning Rate [0.00125]
5: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00096)	Tok/s 72637 (52415)	Loss/tok 4.3494 (5.8627)	Learning Rate [0.00125]
3: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 71847 (52201)	Loss/tok 4.2330 (5.8416)	Learning Rate [0.00125]
13: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00101)	Tok/s 72219 (53117)	Loss/tok 4.2393 (5.8584)	Learning Rate [0.00125]
15: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00095)	Tok/s 73204 (53341)	Loss/tok 4.0194 (5.8568)	Learning Rate [0.00125]
2: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 71541 (52094)	Loss/tok 4.3520 (5.8540)	Learning Rate [0.00125]
1: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 71463 (51986)	Loss/tok 4.3199 (5.8539)	Learning Rate [0.00125]
0: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 71389 (51876)	Loss/tok 4.1609 (5.8471)	Learning Rate [0.00125]
14: TRAIN [0][890/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00097)	Tok/s 73127 (53230)	Loss/tok 4.3083 (5.8593)	Learning Rate [0.00125]
10: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00113 (0.00101)	Tok/s 48919 (52772)	Loss/tok 4.0469 (5.8357)	Learning Rate [0.00125]
13: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00106 (0.00101)	Tok/s 48924 (53071)	Loss/tok 3.8873 (5.8408)	Learning Rate [0.00125]
14: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00106 (0.00097)	Tok/s 48859 (53183)	Loss/tok 3.7651 (5.8419)	Learning Rate [0.00125]
12: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00114 (0.00100)	Tok/s 48888 (52974)	Loss/tok 3.9901 (5.8339)	Learning Rate [0.00125]
9: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00095)	Tok/s 48692 (52689)	Loss/tok 3.8883 (5.8296)	Learning Rate [0.00125]
0: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00092)	Tok/s 48632 (51832)	Loss/tok 4.0823 (5.8297)	Learning Rate [0.00125]
8: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00109 (0.00101)	Tok/s 48528 (52628)	Loss/tok 3.9774 (5.8344)	Learning Rate [0.00125]
1: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00092)	Tok/s 48383 (51942)	Loss/tok 4.1807 (5.8361)	Learning Rate [0.00125]
2: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00108 (0.00098)	Tok/s 48311 (52049)	Loss/tok 3.9377 (5.8357)	Learning Rate [0.00125]
5: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00096)	Tok/s 48208 (52370)	Loss/tok 4.0924 (5.8454)	Learning Rate [0.00125]
15: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00111 (0.00095)	Tok/s 48600 (53293)	Loss/tok 3.6874 (5.8393)	Learning Rate [0.00125]
6: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00106 (0.00098)	Tok/s 48261 (52456)	Loss/tok 3.7992 (5.8303)	Learning Rate [0.00125]
7: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00102 (0.00093)	Tok/s 48380 (52548)	Loss/tok 3.9550 (5.8289)	Learning Rate [0.00125]
11: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00105 (0.00100)	Tok/s 48738 (52853)	Loss/tok 3.8187 (5.8303)	Learning Rate [0.00125]
3: TRAIN [0][900/3416]	Time 0.046 (0.058)	Data 0.00108 (0.00100)	Tok/s 48196 (52156)	Loss/tok 3.9747 (5.8242)	Learning Rate [0.00125]
4: TRAIN [0][900/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00094)	Tok/s 48129 (52264)	Loss/tok 4.0640 (5.8344)	Learning Rate [0.00125]
7: TRAIN [0][910/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00093)	Tok/s 32535 (52629)	Loss/tok 3.8056 (5.8051)	Learning Rate [0.00125]
8: TRAIN [0][910/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00101)	Tok/s 32536 (52709)	Loss/tok 3.6897 (5.8129)	Learning Rate [0.00125]
5: TRAIN [0][910/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00096)	Tok/s 32447 (52451)	Loss/tok 3.6429 (5.8216)	Learning Rate [0.00125]
6: TRAIN [0][910/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00098)	Tok/s 32480 (52537)	Loss/tok 3.4667 (5.8069)	Learning Rate [0.00125]
3: TRAIN [0][910/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00100)	Tok/s 32453 (52236)	Loss/tok 3.5518 (5.8017)	Learning Rate [0.00125]
9: TRAIN [0][910/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00095)	Tok/s 32498 (52771)	Loss/tok 3.6365 (5.8062)	Learning Rate [0.00125]
4: TRAIN [0][910/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00094)	Tok/s 32424 (52345)	Loss/tok 3.3562 (5.8105)	Learning Rate [0.00125]
10: TRAIN [0][910/3416]	Time 0.051 (0.058)	Data 0.00109 (0.00101)	Tok/s 32438 (52855)	Loss/tok 3.6655 (5.8126)	Learning Rate [0.00125]
2: TRAIN [0][910/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00098)	Tok/s 32352 (52129)	Loss/tok 3.5887 (5.8127)	Learning Rate [0.00125]
11: TRAIN [0][910/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00101)	Tok/s 32766 (52936)	Loss/tok 3.6887 (5.8075)	Learning Rate [0.00125]
12: TRAIN [0][910/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00100)	Tok/s 33562 (53058)	Loss/tok 3.4061 (5.8099)	Learning Rate [0.00125]
1: TRAIN [0][910/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00092)	Tok/s 32246 (52022)	Loss/tok 3.8067 (5.8141)	Learning Rate [0.00125]
14: TRAIN [0][910/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00097)	Tok/s 33416 (53267)	Loss/tok 3.2142 (5.8187)	Learning Rate [0.00125]
13: TRAIN [0][910/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00101)	Tok/s 33442 (53154)	Loss/tok 3.8045 (5.8179)	Learning Rate [0.00125]
0: TRAIN [0][910/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 32171 (51913)	Loss/tok 3.7638 (5.8068)	Learning Rate [0.00125]
15: TRAIN [0][910/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00095)	Tok/s 33372 (53378)	Loss/tok 3.5433 (5.8165)	Learning Rate [0.00125]
0: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00092)	Tok/s 50429 (51962)	Loss/tok 3.9247 (5.7877)	Learning Rate [0.00125]
15: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00095)	Tok/s 51707 (53418)	Loss/tok 4.0740 (5.7967)	Learning Rate [0.00125]
14: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00097)	Tok/s 51552 (53306)	Loss/tok 3.8577 (5.7990)	Learning Rate [0.00125]
1: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00093)	Tok/s 50367 (52069)	Loss/tok 3.8743 (5.7939)	Learning Rate [0.00125]
2: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00098)	Tok/s 50350 (52175)	Loss/tok 3.9244 (5.7933)	Learning Rate [0.00125]
13: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00101)	Tok/s 51344 (53195)	Loss/tok 3.9896 (5.7987)	Learning Rate [0.00125]
3: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00100)	Tok/s 50304 (52282)	Loss/tok 4.0791 (5.7832)	Learning Rate [0.00125]
12: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00100)	Tok/s 51233 (53099)	Loss/tok 3.7297 (5.7902)	Learning Rate [0.00125]
4: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00094)	Tok/s 51612 (52390)	Loss/tok 4.0387 (5.7914)	Learning Rate [0.00125]
5: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00096)	Tok/s 51579 (52496)	Loss/tok 4.0984 (5.8027)	Learning Rate [0.00125]
11: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00100)	Tok/s 51251 (52977)	Loss/tok 3.9067 (5.7870)	Learning Rate [0.00125]
10: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00101)	Tok/s 51311 (52896)	Loss/tok 3.8234 (5.7936)	Learning Rate [0.00125]
8: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00100)	Tok/s 51308 (52751)	Loss/tok 4.1267 (5.7937)	Learning Rate [0.00125]
9: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00095)	Tok/s 51295 (52813)	Loss/tok 3.8809 (5.7867)	Learning Rate [0.00125]
7: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00093)	Tok/s 51345 (52672)	Loss/tok 3.8600 (5.7866)	Learning Rate [0.00125]
6: TRAIN [0][920/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00098)	Tok/s 51407 (52581)	Loss/tok 4.1438 (5.7875)	Learning Rate [0.00125]
1: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00092)	Tok/s 51908 (52049)	Loss/tok 4.0236 (5.7765)	Learning Rate [0.00125]
0: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00092)	Tok/s 51898 (51941)	Loss/tok 4.2654 (5.7706)	Learning Rate [0.00125]
15: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00094)	Tok/s 51887 (53397)	Loss/tok 4.1531 (5.7792)	Learning Rate [0.00125]
3: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00100)	Tok/s 51632 (52263)	Loss/tok 4.1271 (5.7665)	Learning Rate [0.00125]
4: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00094)	Tok/s 51552 (52371)	Loss/tok 3.9450 (5.7745)	Learning Rate [0.00125]
14: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00097)	Tok/s 52010 (53285)	Loss/tok 4.0548 (5.7817)	Learning Rate [0.00125]
2: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00098)	Tok/s 51768 (52156)	Loss/tok 3.7536 (5.7766)	Learning Rate [0.00125]
5: TRAIN [0][930/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00096)	Tok/s 51435 (52475)	Loss/tok 3.8351 (5.7861)	Learning Rate [0.00125]
13: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00101)	Tok/s 51870 (53174)	Loss/tok 4.3401 (5.7814)	Learning Rate [0.00125]
12: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00103 (0.00100)	Tok/s 51877 (53079)	Loss/tok 4.0115 (5.7726)	Learning Rate [0.00125]
6: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00098)	Tok/s 51519 (52560)	Loss/tok 3.8089 (5.7708)	Learning Rate [0.00125]
11: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00100)	Tok/s 51695 (52958)	Loss/tok 3.9717 (5.7700)	Learning Rate [0.00125]
10: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00101)	Tok/s 51632 (52877)	Loss/tok 4.2423 (5.7765)	Learning Rate [0.00125]
8: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00100)	Tok/s 51489 (52733)	Loss/tok 4.0767 (5.7768)	Learning Rate [0.00125]
7: TRAIN [0][930/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00093)	Tok/s 51436 (52653)	Loss/tok 4.1317 (5.7700)	Learning Rate [0.00125]
9: TRAIN [0][930/3416]	Time 0.053 (0.058)	Data 0.00080 (0.00095)	Tok/s 51508 (52795)	Loss/tok 3.7955 (5.7696)	Learning Rate [0.00125]
5: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00096)	Tok/s 36535 (52459)	Loss/tok 3.7726 (5.7692)	Learning Rate [0.00125]
6: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00098)	Tok/s 36581 (52543)	Loss/tok 3.9629 (5.7544)	Learning Rate [0.00125]
7: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00079 (0.00093)	Tok/s 36538 (52635)	Loss/tok 3.9239 (5.7530)	Learning Rate [0.00125]
8: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00100)	Tok/s 36376 (52714)	Loss/tok 3.6900 (5.7607)	Learning Rate [0.00125]
3: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00100)	Tok/s 36391 (52246)	Loss/tok 3.5648 (5.7493)	Learning Rate [0.00125]
9: TRAIN [0][940/3416]	Time 0.051 (0.057)	Data 0.00089 (0.00095)	Tok/s 36358 (52776)	Loss/tok 3.7873 (5.7529)	Learning Rate [0.00125]
1: TRAIN [0][940/3416]	Time 0.051 (0.057)	Data 0.00094 (0.00092)	Tok/s 36391 (52034)	Loss/tok 3.4271 (5.7597)	Learning Rate [0.00125]
10: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00101)	Tok/s 36309 (52857)	Loss/tok 3.4910 (5.7600)	Learning Rate [0.00125]
4: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00094)	Tok/s 36458 (52355)	Loss/tok 3.7955 (5.7576)	Learning Rate [0.00125]
0: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00092)	Tok/s 36365 (51926)	Loss/tok 3.5214 (5.7542)	Learning Rate [0.00125]
2: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00098)	Tok/s 36356 (52140)	Loss/tok 3.7837 (5.7602)	Learning Rate [0.00125]
11: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00100)	Tok/s 36234 (52937)	Loss/tok 3.7237 (5.7533)	Learning Rate [0.00125]
12: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00100)	Tok/s 36181 (53059)	Loss/tok 3.6729 (5.7563)	Learning Rate [0.00125]
15: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00094)	Tok/s 36254 (53377)	Loss/tok 3.7461 (5.7624)	Learning Rate [0.00125]
13: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00101)	Tok/s 36174 (53155)	Loss/tok 3.7204 (5.7648)	Learning Rate [0.00125]
14: TRAIN [0][940/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 36095 (53266)	Loss/tok 4.0218 (5.7654)	Learning Rate [0.00125]
5: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00096)	Tok/s 57879 (52566)	Loss/tok 4.3484 (5.7463)	Learning Rate [0.00125]
4: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 57862 (52463)	Loss/tok 4.1440 (5.7344)	Learning Rate [0.00125]
6: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00098)	Tok/s 57798 (52651)	Loss/tok 4.4326 (5.7331)	Learning Rate [0.00125]
2: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 57910 (52250)	Loss/tok 4.4313 (5.7385)	Learning Rate [0.00125]
3: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 57899 (52354)	Loss/tok 4.1974 (5.7272)	Learning Rate [0.00125]
1: TRAIN [0][950/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00092)	Tok/s 57945 (52143)	Loss/tok 4.0756 (5.7376)	Learning Rate [0.00125]
8: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00100)	Tok/s 57718 (52823)	Loss/tok 4.4020 (5.7392)	Learning Rate [0.00125]
0: TRAIN [0][950/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00092)	Tok/s 57937 (52035)	Loss/tok 4.1525 (5.7319)	Learning Rate [0.00125]
15: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00094)	Tok/s 58860 (53485)	Loss/tok 4.2462 (5.7401)	Learning Rate [0.00125]
9: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00094)	Tok/s 57698 (52883)	Loss/tok 4.2907 (5.7314)	Learning Rate [0.00125]
10: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00101)	Tok/s 57701 (52965)	Loss/tok 4.3807 (5.7368)	Learning Rate [0.00125]
7: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 57692 (52742)	Loss/tok 4.1677 (5.7309)	Learning Rate [0.00125]
13: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00101)	Tok/s 58492 (53263)	Loss/tok 4.4356 (5.7434)	Learning Rate [0.00125]
14: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 58821 (53375)	Loss/tok 4.3455 (5.7425)	Learning Rate [0.00125]
12: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00100)	Tok/s 57758 (53167)	Loss/tok 4.3717 (5.7341)	Learning Rate [0.00125]
11: TRAIN [0][950/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00100)	Tok/s 57692 (53046)	Loss/tok 4.1445 (5.7322)	Learning Rate [0.00125]
10: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00101)	Tok/s 51247 (52970)	Loss/tok 4.1120 (5.7198)	Learning Rate [0.00125]
9: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00094)	Tok/s 51312 (52889)	Loss/tok 4.1830 (5.7141)	Learning Rate [0.00125]
8: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00100)	Tok/s 51294 (52828)	Loss/tok 4.0386 (5.7220)	Learning Rate [0.00125]
11: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00100)	Tok/s 51144 (53050)	Loss/tok 4.1395 (5.7154)	Learning Rate [0.00125]
12: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00100)	Tok/s 51101 (53170)	Loss/tok 3.8440 (5.7172)	Learning Rate [0.00125]
7: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00093)	Tok/s 51315 (52749)	Loss/tok 3.9947 (5.7133)	Learning Rate [0.00125]
13: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00101)	Tok/s 51100 (53267)	Loss/tok 3.7949 (5.7261)	Learning Rate [0.00125]
6: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00098)	Tok/s 51289 (52658)	Loss/tok 4.0288 (5.7154)	Learning Rate [0.00125]
14: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00097)	Tok/s 51127 (53380)	Loss/tok 3.7645 (5.7263)	Learning Rate [0.00125]
5: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00096)	Tok/s 51229 (52573)	Loss/tok 3.7343 (5.7288)	Learning Rate [0.00125]
4: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00094)	Tok/s 51231 (52471)	Loss/tok 3.8051 (5.7169)	Learning Rate [0.00125]
15: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00094)	Tok/s 51059 (53491)	Loss/tok 3.7529 (5.7229)	Learning Rate [0.00125]
0: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00092)	Tok/s 51142 (52047)	Loss/tok 4.1103 (5.7156)	Learning Rate [0.00125]
2: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00098)	Tok/s 51079 (52258)	Loss/tok 3.9876 (5.7214)	Learning Rate [0.00125]
3: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00100)	Tok/s 51188 (52363)	Loss/tok 3.9495 (5.7090)	Learning Rate [0.00125]
1: TRAIN [0][960/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00093)	Tok/s 51121 (52153)	Loss/tok 4.0288 (5.7204)	Learning Rate [0.00125]
10: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00101)	Tok/s 59466 (52923)	Loss/tok 4.5139 (5.7057)	Learning Rate [0.00125]
14: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 60578 (53332)	Loss/tok 4.3105 (5.7124)	Learning Rate [0.00125]
12: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00100)	Tok/s 59546 (53122)	Loss/tok 4.1059 (5.7019)	Learning Rate [0.00125]
0: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 59530 (52005)	Loss/tok 4.1724 (5.7004)	Learning Rate [0.00125]
11: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 59482 (53002)	Loss/tok 4.4444 (5.7008)	Learning Rate [0.00125]
15: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00094)	Tok/s 60475 (53443)	Loss/tok 4.1983 (5.7089)	Learning Rate [0.00125]
13: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00101)	Tok/s 60161 (53220)	Loss/tok 4.1197 (5.7113)	Learning Rate [0.00125]
2: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00098)	Tok/s 59293 (52215)	Loss/tok 4.0635 (5.7064)	Learning Rate [0.00125]
9: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00094)	Tok/s 59276 (52842)	Loss/tok 4.0006 (5.6987)	Learning Rate [0.00125]
1: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 59298 (52111)	Loss/tok 3.9729 (5.7053)	Learning Rate [0.00125]
8: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00100)	Tok/s 59135 (52781)	Loss/tok 4.3099 (5.7069)	Learning Rate [0.00125]
5: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00116 (0.00096)	Tok/s 58963 (52527)	Loss/tok 4.4390 (5.7144)	Learning Rate [0.00125]
4: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00094)	Tok/s 59018 (52426)	Loss/tok 4.5103 (5.7018)	Learning Rate [0.00125]
3: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 59101 (52318)	Loss/tok 4.4298 (5.6941)	Learning Rate [0.00125]
6: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 58954 (52611)	Loss/tok 4.2440 (5.7011)	Learning Rate [0.00125]
7: TRAIN [0][970/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 59040 (52702)	Loss/tok 4.4738 (5.6986)	Learning Rate [0.00125]
5: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00098 (0.00096)	Tok/s 20362 (52517)	Loss/tok 2.4960 (5.6991)	Learning Rate [0.00125]
6: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00086 (0.00097)	Tok/s 21690 (52603)	Loss/tok 2.8792 (5.6847)	Learning Rate [0.00125]
4: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00091 (0.00094)	Tok/s 19031 (52414)	Loss/tok 3.0817 (5.6853)	Learning Rate [0.00125]
8: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00092 (0.00100)	Tok/s 23868 (52774)	Loss/tok 2.4138 (5.6915)	Learning Rate [0.00125]
7: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00082 (0.00093)	Tok/s 22273 (52694)	Loss/tok 3.0782 (5.6822)	Learning Rate [0.00125]
2: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00096 (0.00098)	Tok/s 15566 (52201)	Loss/tok 2.2345 (5.6901)	Learning Rate [0.00125]
10: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00083 (0.00101)	Tok/s 23681 (52917)	Loss/tok 2.1485 (5.6898)	Learning Rate [0.00125]
3: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00092 (0.00099)	Tok/s 16613 (52305)	Loss/tok 1.6672 (5.6777)	Learning Rate [0.00125]
11: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00084 (0.00100)	Tok/s 25384 (52998)	Loss/tok 2.8965 (5.6855)	Learning Rate [0.00125]
1: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00080 (0.00092)	Tok/s 13000 (52095)	Loss/tok 2.5134 (5.6888)	Learning Rate [0.00125]
9: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00084 (0.00094)	Tok/s 23702 (52835)	Loss/tok 2.3333 (5.6822)	Learning Rate [0.00125]
12: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00092 (0.00100)	Tok/s 25409 (53117)	Loss/tok 2.9677 (5.6864)	Learning Rate [0.00125]
15: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00077 (0.00094)	Tok/s 27441 (53437)	Loss/tok 2.4257 (5.6931)	Learning Rate [0.00125]
0: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00085 (0.00092)	Tok/s 9159 (51987)	Loss/tok 1.6066 (5.6849)	Learning Rate [0.00125]
13: TRAIN [0][980/3416]	Time 0.035 (0.058)	Data 0.00085 (0.00101)	Tok/s 25874 (53214)	Loss/tok 2.9143 (5.6954)	Learning Rate [0.00125]
14: TRAIN [0][980/3416]	Time 0.036 (0.058)	Data 0.00082 (0.00097)	Tok/s 27020 (53327)	Loss/tok 2.5984 (5.6963)	Learning Rate [0.00125]
4: TRAIN [0][990/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00094)	Tok/s 48801 (52420)	Loss/tok 3.9042 (5.6697)	Learning Rate [0.00125]
3: TRAIN [0][990/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00099)	Tok/s 48882 (52312)	Loss/tok 3.8669 (5.6616)	Learning Rate [0.00125]
2: TRAIN [0][990/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00098)	Tok/s 48726 (52208)	Loss/tok 4.0188 (5.6737)	Learning Rate [0.00125]
0: TRAIN [0][990/3416]	Time 0.046 (0.058)	Data 0.00082 (0.00092)	Tok/s 48585 (51995)	Loss/tok 3.6903 (5.6687)	Learning Rate [0.00125]
1: TRAIN [0][990/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00092)	Tok/s 48684 (52104)	Loss/tok 4.0132 (5.6716)	Learning Rate [0.00125]
5: TRAIN [0][990/3416]	Time 0.046 (0.058)	Data 0.00106 (0.00096)	Tok/s 49418 (52523)	Loss/tok 3.8939 (5.6830)	Learning Rate [0.00125]
15: TRAIN [0][990/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00094)	Tok/s 49753 (53438)	Loss/tok 3.9001 (5.6762)	Learning Rate [0.00125]
12: TRAIN [0][990/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00100)	Tok/s 49535 (53118)	Loss/tok 3.9250 (5.6696)	Learning Rate [0.00125]
6: TRAIN [0][990/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00097)	Tok/s 49951 (52608)	Loss/tok 3.8904 (5.6692)	Learning Rate [0.00125]
7: TRAIN [0][990/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00093)	Tok/s 49828 (52699)	Loss/tok 3.9663 (5.6658)	Learning Rate [0.00125]
14: TRAIN [0][990/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00097)	Tok/s 49614 (53327)	Loss/tok 3.8602 (5.6801)	Learning Rate [0.00125]
8: TRAIN [0][990/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00100)	Tok/s 49698 (52778)	Loss/tok 3.8839 (5.6751)	Learning Rate [0.00125]
13: TRAIN [0][990/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00101)	Tok/s 49504 (53215)	Loss/tok 4.3014 (5.6796)	Learning Rate [0.00125]
9: TRAIN [0][990/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00094)	Tok/s 49592 (52838)	Loss/tok 3.9430 (5.6660)	Learning Rate [0.00125]
10: TRAIN [0][990/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00101)	Tok/s 49487 (52920)	Loss/tok 3.6631 (5.6732)	Learning Rate [0.00125]
11: TRAIN [0][990/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00100)	Tok/s 49390 (53000)	Loss/tok 3.8902 (5.6693)	Learning Rate [0.00125]
13: TRAIN [0][1000/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00100)	Tok/s 57887 (53282)	Loss/tok 4.4293 (5.6615)	Learning Rate [0.00125]
12: TRAIN [0][1000/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00100)	Tok/s 57741 (53185)	Loss/tok 4.1470 (5.6506)	Learning Rate [0.00125]
11: TRAIN [0][1000/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00100)	Tok/s 57650 (53068)	Loss/tok 4.1448 (5.6503)	Learning Rate [0.00125]
14: TRAIN [0][1000/3416]	Time 0.066 (0.058)	Data 0.00087 (0.00097)	Tok/s 57802 (53393)	Loss/tok 4.4304 (5.6621)	Learning Rate [0.00125]
10: TRAIN [0][1000/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00101)	Tok/s 57537 (52988)	Loss/tok 4.0950 (5.6539)	Learning Rate [0.00125]
15: TRAIN [0][1000/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00094)	Tok/s 57847 (53502)	Loss/tok 4.0836 (5.6579)	Learning Rate [0.00125]
0: TRAIN [0][1000/3416]	Time 0.066 (0.058)	Data 0.00075 (0.00092)	Tok/s 57826 (52068)	Loss/tok 4.4168 (5.6501)	Learning Rate [0.00125]
9: TRAIN [0][1000/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00094)	Tok/s 57519 (52908)	Loss/tok 3.9957 (5.6473)	Learning Rate [0.00125]
8: TRAIN [0][1000/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00100)	Tok/s 57534 (52848)	Loss/tok 4.1081 (5.6568)	Learning Rate [0.00125]
1: TRAIN [0][1000/3416]	Time 0.066 (0.058)	Data 0.00079 (0.00092)	Tok/s 57792 (52177)	Loss/tok 4.2929 (5.6525)	Learning Rate [0.00125]
2: TRAIN [0][1000/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00098)	Tok/s 57764 (52281)	Loss/tok 4.1055 (5.6542)	Learning Rate [0.00125]
5: TRAIN [0][1000/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00096)	Tok/s 57603 (52593)	Loss/tok 4.2547 (5.6632)	Learning Rate [0.00125]
6: TRAIN [0][1000/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00097)	Tok/s 57574 (52678)	Loss/tok 4.2573 (5.6506)	Learning Rate [0.00125]
7: TRAIN [0][1000/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00093)	Tok/s 57540 (52769)	Loss/tok 4.1594 (5.6479)	Learning Rate [0.00125]
3: TRAIN [0][1000/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00099)	Tok/s 57697 (52383)	Loss/tok 3.9437 (5.6429)	Learning Rate [0.00125]
4: TRAIN [0][1000/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00094)	Tok/s 57606 (52491)	Loss/tok 4.1052 (5.6509)	Learning Rate [0.00125]
11: TRAIN [0][1010/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00100)	Tok/s 49372 (53105)	Loss/tok 3.8428 (5.6332)	Learning Rate [0.00125]
12: TRAIN [0][1010/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00100)	Tok/s 49272 (53222)	Loss/tok 3.6589 (5.6333)	Learning Rate [0.00125]
13: TRAIN [0][1010/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00100)	Tok/s 49270 (53318)	Loss/tok 3.9220 (5.6447)	Learning Rate [0.00125]
14: TRAIN [0][1010/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00097)	Tok/s 49283 (53429)	Loss/tok 3.6774 (5.6448)	Learning Rate [0.00125]
10: TRAIN [0][1010/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00101)	Tok/s 49143 (53026)	Loss/tok 3.8372 (5.6369)	Learning Rate [0.00125]
15: TRAIN [0][1010/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00094)	Tok/s 49048 (53538)	Loss/tok 3.7123 (5.6413)	Learning Rate [0.00125]
9: TRAIN [0][1010/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00094)	Tok/s 49035 (52946)	Loss/tok 3.7661 (5.6302)	Learning Rate [0.00125]
8: TRAIN [0][1010/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00100)	Tok/s 48911 (52887)	Loss/tok 3.6618 (5.6403)	Learning Rate [0.00125]
0: TRAIN [0][1010/3416]	Time 0.044 (0.058)	Data 0.00084 (0.00092)	Tok/s 47555 (52108)	Loss/tok 3.6445 (5.6330)	Learning Rate [0.00125]
1: TRAIN [0][1010/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00092)	Tok/s 47423 (52216)	Loss/tok 3.9879 (5.6356)	Learning Rate [0.00125]
2: TRAIN [0][1010/3416]	Time 0.045 (0.058)	Data 0.00103 (0.00098)	Tok/s 47301 (52319)	Loss/tok 3.7287 (5.6377)	Learning Rate [0.00125]
7: TRAIN [0][1010/3416]	Time 0.045 (0.058)	Data 0.00083 (0.00093)	Tok/s 48757 (52808)	Loss/tok 3.8643 (5.6311)	Learning Rate [0.00125]
6: TRAIN [0][1010/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00097)	Tok/s 48705 (52716)	Loss/tok 3.7436 (5.6339)	Learning Rate [0.00125]
4: TRAIN [0][1010/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00094)	Tok/s 47117 (52529)	Loss/tok 3.5138 (5.6335)	Learning Rate [0.00125]
5: TRAIN [0][1010/3416]	Time 0.045 (0.058)	Data 0.00107 (0.00096)	Tok/s 47364 (52632)	Loss/tok 3.9479 (5.6474)	Learning Rate [0.00125]
3: TRAIN [0][1010/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00099)	Tok/s 47205 (52421)	Loss/tok 4.1977 (5.6257)	Learning Rate [0.00125]
8: Upscaling, new scale: 512.0
7: Upscaling, new scale: 512.0
9: Upscaling, new scale: 512.0
10: Upscaling, new scale: 512.0
5: Upscaling, new scale: 512.0
6: Upscaling, new scale: 512.0
11: Upscaling, new scale: 512.0
4: Upscaling, new scale: 512.0
12: Upscaling, new scale: 512.0
15: Upscaling, new scale: 512.0
13: Upscaling, new scale: 512.0
3: Upscaling, new scale: 512.0
2: Upscaling, new scale: 512.0
14: Upscaling, new scale: 512.0
1: Upscaling, new scale: 512.0
0: Upscaling, new scale: 512.0
2: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00115 (0.00098)	Tok/s 49851 (52386)	Loss/tok 3.8011 (5.6193)	Learning Rate [0.00125]
0: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00092)	Tok/s 49268 (52176)	Loss/tok 3.7265 (5.6142)	Learning Rate [0.00125]
10: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00101)	Tok/s 50672 (53091)	Loss/tok 3.6475 (5.6189)	Learning Rate [0.00125]
12: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00100)	Tok/s 50753 (53287)	Loss/tok 3.7969 (5.6140)	Learning Rate [0.00125]
11: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00106 (0.00100)	Tok/s 50665 (53171)	Loss/tok 3.6490 (5.6147)	Learning Rate [0.00125]
1: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00092)	Tok/s 49157 (52283)	Loss/tok 3.8082 (5.6168)	Learning Rate [0.00125]
4: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00094)	Tok/s 50533 (52595)	Loss/tok 3.7628 (5.6155)	Learning Rate [0.00125]
3: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00099)	Tok/s 50508 (52488)	Loss/tok 3.6839 (5.6077)	Learning Rate [0.00125]
5: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00113 (0.00096)	Tok/s 50536 (52697)	Loss/tok 3.7666 (5.6287)	Learning Rate [0.00125]
14: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00097)	Tok/s 50607 (53494)	Loss/tok 3.7215 (5.6252)	Learning Rate [0.00125]
8: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00100)	Tok/s 50625 (52952)	Loss/tok 3.9344 (5.6223)	Learning Rate [0.00125]
15: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00094)	Tok/s 50496 (53603)	Loss/tok 4.0304 (5.6229)	Learning Rate [0.00125]
7: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00093)	Tok/s 50617 (52873)	Loss/tok 3.8895 (5.6129)	Learning Rate [0.00125]
13: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00107 (0.00100)	Tok/s 50963 (53383)	Loss/tok 3.6858 (5.6254)	Learning Rate [0.00125]
9: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00094)	Tok/s 50620 (53011)	Loss/tok 3.7028 (5.6126)	Learning Rate [0.00125]
6: TRAIN [0][1020/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00097)	Tok/s 50453 (52781)	Loss/tok 3.7483 (5.6155)	Learning Rate [0.00125]
9: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00094)	Tok/s 54881 (53040)	Loss/tok 3.9074 (5.5964)	Learning Rate [0.00125]
8: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00100)	Tok/s 54777 (52981)	Loss/tok 4.1590 (5.6060)	Learning Rate [0.00125]
10: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00101)	Tok/s 54860 (53119)	Loss/tok 4.0751 (5.6031)	Learning Rate [0.00125]
14: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00097)	Tok/s 55892 (53524)	Loss/tok 4.2831 (5.6091)	Learning Rate [0.00125]
13: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00100)	Tok/s 55910 (53413)	Loss/tok 4.0784 (5.6086)	Learning Rate [0.00125]
11: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00100)	Tok/s 54982 (53198)	Loss/tok 3.9511 (5.5983)	Learning Rate [0.00125]
12: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00100)	Tok/s 55595 (53316)	Loss/tok 4.0276 (5.5992)	Learning Rate [0.00125]
7: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00093)	Tok/s 54684 (52902)	Loss/tok 4.0459 (5.5963)	Learning Rate [0.00125]
15: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00094)	Tok/s 55748 (53632)	Loss/tok 4.1039 (5.6065)	Learning Rate [0.00125]
0: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00092)	Tok/s 54638 (52209)	Loss/tok 4.0773 (5.5980)	Learning Rate [0.00125]
5: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00107 (0.00096)	Tok/s 54599 (52727)	Loss/tok 4.2999 (5.6121)	Learning Rate [0.00125]
6: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00097)	Tok/s 54640 (52810)	Loss/tok 4.2177 (5.5992)	Learning Rate [0.00125]
4: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00083 (0.00094)	Tok/s 54616 (52627)	Loss/tok 4.1637 (5.5996)	Learning Rate [0.00125]
1: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00092)	Tok/s 54543 (52316)	Loss/tok 4.2232 (5.6005)	Learning Rate [0.00125]
2: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00105 (0.00098)	Tok/s 54553 (52418)	Loss/tok 4.2539 (5.6024)	Learning Rate [0.00125]
3: TRAIN [0][1030/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00099)	Tok/s 54597 (52519)	Loss/tok 4.3104 (5.5916)	Learning Rate [0.00125]
14: TRAIN [0][1040/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00097)	Tok/s 31910 (53422)	Loss/tok 3.2513 (5.5978)	Learning Rate [0.00125]
0: TRAIN [0][1040/3416]	Time 0.040 (0.058)	Data 0.00090 (0.00092)	Tok/s 28736 (52100)	Loss/tok 3.0708 (5.5870)	Learning Rate [0.00125]
15: TRAIN [0][1040/3416]	Time 0.040 (0.058)	Data 0.00080 (0.00094)	Tok/s 31906 (53530)	Loss/tok 3.3150 (5.5949)	Learning Rate [0.00125]
2: TRAIN [0][1040/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00098)	Tok/s 28559 (52309)	Loss/tok 2.9512 (5.5913)	Learning Rate [0.00125]
13: TRAIN [0][1040/3416]	Time 0.040 (0.058)	Data 0.00102 (0.00100)	Tok/s 31879 (53310)	Loss/tok 3.3411 (5.5970)	Learning Rate [0.00125]
1: TRAIN [0][1040/3416]	Time 0.040 (0.058)	Data 0.00100 (0.00092)	Tok/s 28569 (52208)	Loss/tok 3.0433 (5.5889)	Learning Rate [0.00125]
12: TRAIN [0][1040/3416]	Time 0.040 (0.058)	Data 0.00108 (0.00100)	Tok/s 30602 (53210)	Loss/tok 3.1626 (5.5870)	Learning Rate [0.00125]
11: TRAIN [0][1040/3416]	Time 0.040 (0.058)	Data 0.00101 (0.00100)	Tok/s 30160 (53092)	Loss/tok 3.1569 (5.5871)	Learning Rate [0.00125]
10: TRAIN [0][1040/3416]	Time 0.041 (0.058)	Data 0.00092 (0.00101)	Tok/s 29989 (53015)	Loss/tok 3.1701 (5.5920)	Learning Rate [0.00125]
3: TRAIN [0][1040/3416]	Time 0.041 (0.058)	Data 0.00095 (0.00099)	Tok/s 28433 (52409)	Loss/tok 3.0039 (5.5797)	Learning Rate [0.00125]
4: TRAIN [0][1040/3416]	Time 0.041 (0.058)	Data 0.00108 (0.00094)	Tok/s 28782 (52517)	Loss/tok 3.1068 (5.5885)	Learning Rate [0.00125]
5: TRAIN [0][1040/3416]	Time 0.041 (0.058)	Data 0.00127 (0.00096)	Tok/s 29834 (52624)	Loss/tok 3.2190 (5.6001)	Learning Rate [0.00125]
8: TRAIN [0][1040/3416]	Time 0.041 (0.058)	Data 0.00088 (0.00100)	Tok/s 29957 (52876)	Loss/tok 3.0529 (5.5943)	Learning Rate [0.00125]
6: TRAIN [0][1040/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00097)	Tok/s 29804 (52706)	Loss/tok 3.0143 (5.5875)	Learning Rate [0.00125]
9: TRAIN [0][1040/3416]	Time 0.040 (0.058)	Data 0.00096 (0.00094)	Tok/s 30034 (52936)	Loss/tok 2.9932 (5.5849)	Learning Rate [0.00125]
7: TRAIN [0][1040/3416]	Time 0.041 (0.058)	Data 0.00090 (0.00093)	Tok/s 29719 (52798)	Loss/tok 3.1004 (5.5853)	Learning Rate [0.00125]
9: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00094)	Tok/s 56027 (52918)	Loss/tok 4.0169 (5.5709)	Learning Rate [0.00125]
8: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00100)	Tok/s 55299 (52859)	Loss/tok 4.0369 (5.5805)	Learning Rate [0.00125]
10: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00101)	Tok/s 55995 (52996)	Loss/tok 3.9424 (5.5782)	Learning Rate [0.00125]
7: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00093)	Tok/s 54942 (52781)	Loss/tok 4.2885 (5.5714)	Learning Rate [0.00125]
6: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00097)	Tok/s 54982 (52689)	Loss/tok 4.2637 (5.5736)	Learning Rate [0.00125]
11: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00100)	Tok/s 56026 (53073)	Loss/tok 3.8670 (5.5729)	Learning Rate [0.00125]
12: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00100)	Tok/s 55946 (53190)	Loss/tok 4.2229 (5.5730)	Learning Rate [0.00125]
5: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00112 (0.00096)	Tok/s 54930 (52608)	Loss/tok 4.3263 (5.5869)	Learning Rate [0.00125]
4: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00093)	Tok/s 54900 (52501)	Loss/tok 4.0137 (5.5745)	Learning Rate [0.00125]
13: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00100)	Tok/s 56031 (53290)	Loss/tok 3.9406 (5.5834)	Learning Rate [0.00125]
14: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00097)	Tok/s 55951 (53402)	Loss/tok 4.0122 (5.5837)	Learning Rate [0.00125]
3: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00104 (0.00099)	Tok/s 54939 (52393)	Loss/tok 3.9485 (5.5660)	Learning Rate [0.00125]
15: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00094)	Tok/s 56002 (53510)	Loss/tok 3.9976 (5.5812)	Learning Rate [0.00125]
0: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00092)	Tok/s 54973 (52086)	Loss/tok 4.1953 (5.5734)	Learning Rate [0.00125]
2: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00110 (0.00098)	Tok/s 54855 (52293)	Loss/tok 4.3445 (5.5769)	Learning Rate [0.00125]
1: TRAIN [0][1050/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00092)	Tok/s 54888 (52192)	Loss/tok 4.3365 (5.5750)	Learning Rate [0.00125]
0: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00092)	Tok/s 52531 (52137)	Loss/tok 4.1641 (5.5569)	Learning Rate [0.00125]
15: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00094)	Tok/s 53581 (53554)	Loss/tok 4.2114 (5.5645)	Learning Rate [0.00125]
1: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00116 (0.00092)	Tok/s 52460 (52243)	Loss/tok 4.0974 (5.5587)	Learning Rate [0.00125]
2: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00111 (0.00098)	Tok/s 52425 (52343)	Loss/tok 3.7431 (5.5608)	Learning Rate [0.00125]
14: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00097)	Tok/s 53584 (53445)	Loss/tok 4.0057 (5.5674)	Learning Rate [0.00125]
12: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00100)	Tok/s 53586 (53234)	Loss/tok 3.9938 (5.5562)	Learning Rate [0.00125]
4: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00093)	Tok/s 52372 (52549)	Loss/tok 4.1063 (5.5577)	Learning Rate [0.00125]
5: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00103 (0.00096)	Tok/s 52309 (52655)	Loss/tok 4.0916 (5.5705)	Learning Rate [0.00125]
3: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00100)	Tok/s 52376 (52442)	Loss/tok 3.8665 (5.5492)	Learning Rate [0.00125]
11: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00102 (0.00100)	Tok/s 53560 (53118)	Loss/tok 4.0051 (5.5569)	Learning Rate [0.00125]
10: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00100)	Tok/s 53490 (53041)	Loss/tok 4.1661 (5.5624)	Learning Rate [0.00125]
6: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00104 (0.00097)	Tok/s 52288 (52736)	Loss/tok 3.8974 (5.5572)	Learning Rate [0.00125]
8: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00100)	Tok/s 52414 (52903)	Loss/tok 4.2386 (5.5641)	Learning Rate [0.00125]
9: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00094)	Tok/s 53442 (52964)	Loss/tok 4.0294 (5.5543)	Learning Rate [0.00125]
7: TRAIN [0][1060/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00093)	Tok/s 52226 (52826)	Loss/tok 4.0431 (5.5565)	Learning Rate [0.00125]
13: TRAIN [0][1060/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00100)	Tok/s 51783 (53333)	Loss/tok 4.0575 (5.5678)	Learning Rate [0.00125]
14: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00097)	Tok/s 42559 (53413)	Loss/tok 3.7857 (5.5532)	Learning Rate [0.00125]
15: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00082 (0.00094)	Tok/s 42517 (53522)	Loss/tok 3.4936 (5.5511)	Learning Rate [0.00125]
13: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00100)	Tok/s 42427 (53303)	Loss/tok 3.8350 (5.5541)	Learning Rate [0.00125]
12: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00100)	Tok/s 42411 (53201)	Loss/tok 3.7307 (5.5432)	Learning Rate [0.00125]
0: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00091)	Tok/s 42514 (52092)	Loss/tok 3.8112 (5.5444)	Learning Rate [0.00125]
11: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00100)	Tok/s 42401 (53084)	Loss/tok 3.9063 (5.5431)	Learning Rate [0.00125]
1: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00092)	Tok/s 42533 (52202)	Loss/tok 3.6318 (5.5454)	Learning Rate [0.00125]
2: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00112 (0.00098)	Tok/s 42495 (52304)	Loss/tok 3.8177 (5.5477)	Learning Rate [0.00125]
10: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00125 (0.00100)	Tok/s 42400 (53008)	Loss/tok 3.5957 (5.5488)	Learning Rate [0.00125]
3: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00100)	Tok/s 42488 (52404)	Loss/tok 3.4857 (5.5353)	Learning Rate [0.00125]
8: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00100)	Tok/s 42416 (52870)	Loss/tok 3.6467 (5.5501)	Learning Rate [0.00125]
4: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00093)	Tok/s 42522 (52511)	Loss/tok 3.9860 (5.5448)	Learning Rate [0.00125]
5: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00096)	Tok/s 42463 (52618)	Loss/tok 3.6538 (5.5569)	Learning Rate [0.00125]
6: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00097)	Tok/s 42466 (52699)	Loss/tok 3.7264 (5.5438)	Learning Rate [0.00125]
7: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00093)	Tok/s 42388 (52791)	Loss/tok 3.6763 (5.5430)	Learning Rate [0.00125]
9: TRAIN [0][1070/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00094)	Tok/s 42430 (52930)	Loss/tok 3.4886 (5.5403)	Learning Rate [0.00125]
1: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00092)	Tok/s 30926 (52154)	Loss/tok 3.4430 (5.5331)	Learning Rate [0.00125]
2: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00098)	Tok/s 30908 (52255)	Loss/tok 3.3480 (5.5349)	Learning Rate [0.00125]
0: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00091)	Tok/s 30244 (52043)	Loss/tok 3.2452 (5.5321)	Learning Rate [0.00125]
15: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00094)	Tok/s 32145 (53469)	Loss/tok 3.2673 (5.5389)	Learning Rate [0.00125]
3: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00100)	Tok/s 30847 (52355)	Loss/tok 3.4831 (5.5230)	Learning Rate [0.00125]
14: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00097)	Tok/s 31745 (53359)	Loss/tok 3.5008 (5.5402)	Learning Rate [0.00125]
4: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00093)	Tok/s 30771 (52462)	Loss/tok 3.3388 (5.5323)	Learning Rate [0.00125]
13: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00100)	Tok/s 30663 (53248)	Loss/tok 3.1900 (5.5417)	Learning Rate [0.00125]
5: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00096)	Tok/s 30697 (52568)	Loss/tok 3.2522 (5.5444)	Learning Rate [0.00125]
12: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00100)	Tok/s 30608 (53148)	Loss/tok 3.4314 (5.5305)	Learning Rate [0.00125]
6: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00097)	Tok/s 30610 (52648)	Loss/tok 3.5624 (5.5325)	Learning Rate [0.00125]
11: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00100)	Tok/s 30525 (53031)	Loss/tok 3.1994 (5.5308)	Learning Rate [0.00125]
10: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00100)	Tok/s 30464 (52955)	Loss/tok 3.5278 (5.5366)	Learning Rate [0.00125]
8: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00100)	Tok/s 30495 (52817)	Loss/tok 3.3327 (5.5379)	Learning Rate [0.00125]
7: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00080 (0.00093)	Tok/s 30564 (52739)	Loss/tok 3.5603 (5.5309)	Learning Rate [0.00125]
9: TRAIN [0][1080/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00094)	Tok/s 30371 (52877)	Loss/tok 3.3253 (5.5282)	Learning Rate [0.00125]
14: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 80132 (53315)	Loss/tok 4.0073 (5.5272)	Learning Rate [0.00125]
15: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00094)	Tok/s 80175 (53425)	Loss/tok 3.7839 (5.5251)	Learning Rate [0.00125]
0: TRAIN [0][1090/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00091)	Tok/s 78330 (52002)	Loss/tok 4.2503 (5.5194)	Learning Rate [0.00125]
13: TRAIN [0][1090/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00100)	Tok/s 79962 (53205)	Loss/tok 3.9311 (5.5280)	Learning Rate [0.00125]
1: TRAIN [0][1090/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 78243 (52112)	Loss/tok 4.0599 (5.5193)	Learning Rate [0.00125]
12: TRAIN [0][1090/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00100)	Tok/s 79906 (53104)	Loss/tok 4.1727 (5.5175)	Learning Rate [0.00125]
2: TRAIN [0][1090/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00098)	Tok/s 78125 (52212)	Loss/tok 4.1435 (5.5217)	Learning Rate [0.00125]
11: TRAIN [0][1090/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00100)	Tok/s 79742 (52986)	Loss/tok 4.0951 (5.5180)	Learning Rate [0.00125]
10: TRAIN [0][1090/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00100)	Tok/s 78790 (52909)	Loss/tok 4.1297 (5.5228)	Learning Rate [0.00125]
3: TRAIN [0][1090/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00099)	Tok/s 78401 (52312)	Loss/tok 4.0660 (5.5102)	Learning Rate [0.00125]
5: TRAIN [0][1090/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 78759 (52524)	Loss/tok 4.1421 (5.5305)	Learning Rate [0.00125]
8: TRAIN [0][1090/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 78560 (52771)	Loss/tok 4.1637 (5.5251)	Learning Rate [0.00125]
4: TRAIN [0][1090/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 78782 (52418)	Loss/tok 4.2624 (5.5194)	Learning Rate [0.00125]
6: TRAIN [0][1090/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 78742 (52603)	Loss/tok 3.9722 (5.5187)	Learning Rate [0.00125]
7: TRAIN [0][1090/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 78685 (52694)	Loss/tok 4.0349 (5.5176)	Learning Rate [0.00125]
9: TRAIN [0][1090/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00094)	Tok/s 78604 (52831)	Loss/tok 4.1011 (5.5153)	Learning Rate [0.00125]
4: TRAIN [0][1100/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00093)	Tok/s 47243 (52397)	Loss/tok 3.9068 (5.5056)	Learning Rate [0.00125]
5: TRAIN [0][1100/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00096)	Tok/s 47149 (52503)	Loss/tok 3.8067 (5.5171)	Learning Rate [0.00125]
3: TRAIN [0][1100/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00100)	Tok/s 47328 (52292)	Loss/tok 3.9942 (5.4970)	Learning Rate [0.00125]
2: TRAIN [0][1100/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00098)	Tok/s 47188 (52193)	Loss/tok 3.7875 (5.5087)	Learning Rate [0.00125]
6: TRAIN [0][1100/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00097)	Tok/s 47043 (52582)	Loss/tok 3.9569 (5.5051)	Learning Rate [0.00125]
1: TRAIN [0][1100/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00092)	Tok/s 47027 (52093)	Loss/tok 3.9577 (5.5059)	Learning Rate [0.00125]
7: TRAIN [0][1100/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00093)	Tok/s 46908 (52672)	Loss/tok 3.8119 (5.5047)	Learning Rate [0.00125]
0: TRAIN [0][1100/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00091)	Tok/s 46951 (51983)	Loss/tok 3.7947 (5.5067)	Learning Rate [0.00125]
8: TRAIN [0][1100/3416]	Time 0.047 (0.058)	Data 0.00110 (0.00100)	Tok/s 46779 (52749)	Loss/tok 3.7473 (5.5116)	Learning Rate [0.00125]
15: TRAIN [0][1100/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00094)	Tok/s 47172 (53401)	Loss/tok 3.7388 (5.5120)	Learning Rate [0.00125]
14: TRAIN [0][1100/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00096)	Tok/s 46747 (53290)	Loss/tok 3.6599 (5.5138)	Learning Rate [0.00125]
10: TRAIN [0][1100/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00100)	Tok/s 46649 (52886)	Loss/tok 3.9330 (5.5097)	Learning Rate [0.00125]
11: TRAIN [0][1100/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00100)	Tok/s 46581 (52963)	Loss/tok 3.7095 (5.5047)	Learning Rate [0.00125]
12: TRAIN [0][1100/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00100)	Tok/s 46610 (53080)	Loss/tok 3.8253 (5.5050)	Learning Rate [0.00125]
13: TRAIN [0][1100/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00100)	Tok/s 46553 (53180)	Loss/tok 3.7786 (5.5147)	Learning Rate [0.00125]
9: TRAIN [0][1100/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00094)	Tok/s 46687 (52808)	Loss/tok 3.7232 (5.5026)	Learning Rate [0.00125]
12: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00107 (0.00100)	Tok/s 69494 (53127)	Loss/tok 4.1576 (5.4899)	Learning Rate [0.00125]
11: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00100)	Tok/s 68922 (53009)	Loss/tok 4.3037 (5.4896)	Learning Rate [0.00125]
10: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00100)	Tok/s 68423 (52931)	Loss/tok 4.1795 (5.4949)	Learning Rate [0.00125]
13: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00099 (0.00100)	Tok/s 69442 (53227)	Loss/tok 4.3498 (5.4990)	Learning Rate [0.00125]
14: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00088 (0.00096)	Tok/s 69374 (53336)	Loss/tok 4.1035 (5.4977)	Learning Rate [0.00125]
9: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00122 (0.00094)	Tok/s 68671 (52854)	Loss/tok 4.1954 (5.4873)	Learning Rate [0.00125]
8: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00100 (0.00100)	Tok/s 68243 (52793)	Loss/tok 4.0327 (5.4959)	Learning Rate [0.00125]
15: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00088 (0.00094)	Tok/s 69244 (53446)	Loss/tok 4.1320 (5.4964)	Learning Rate [0.00125]
0: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00091)	Tok/s 68267 (52032)	Loss/tok 4.2314 (5.4914)	Learning Rate [0.00125]
7: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00099 (0.00093)	Tok/s 68265 (52716)	Loss/tok 4.3163 (5.4894)	Learning Rate [0.00125]
1: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00092)	Tok/s 68166 (52141)	Loss/tok 4.1316 (5.4910)	Learning Rate [0.00125]
2: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00098)	Tok/s 68150 (52241)	Loss/tok 4.2356 (5.4939)	Learning Rate [0.00125]
5: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00096)	Tok/s 68216 (52549)	Loss/tok 4.0796 (5.5015)	Learning Rate [0.00125]
6: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00097)	Tok/s 68243 (52627)	Loss/tok 4.1701 (5.4904)	Learning Rate [0.00125]
3: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00105 (0.00100)	Tok/s 68155 (52339)	Loss/tok 4.1773 (5.4816)	Learning Rate [0.00125]
4: TRAIN [0][1110/3416]	Time 0.071 (0.058)	Data 0.00088 (0.00093)	Tok/s 68111 (52443)	Loss/tok 4.1434 (5.4904)	Learning Rate [0.00125]
15: TRAIN [0][1120/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00094)	Tok/s 71859 (53420)	Loss/tok 3.9999 (5.4839)	Learning Rate [0.00125]
14: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00096)	Tok/s 71788 (53311)	Loss/tok 3.9581 (5.4848)	Learning Rate [0.00125]
0: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 70857 (51995)	Loss/tok 4.1079 (5.4787)	Learning Rate [0.00125]
13: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 71535 (53201)	Loss/tok 4.0968 (5.4860)	Learning Rate [0.00125]
12: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00100)	Tok/s 71407 (53100)	Loss/tok 4.2112 (5.4775)	Learning Rate [0.00125]
3: TRAIN [0][1120/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00100)	Tok/s 71000 (52307)	Loss/tok 4.0149 (5.4683)	Learning Rate [0.00125]
1: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 70858 (52107)	Loss/tok 4.1953 (5.4784)	Learning Rate [0.00125]
2: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00098)	Tok/s 70842 (52209)	Loss/tok 4.2904 (5.4813)	Learning Rate [0.00125]
11: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00100)	Tok/s 71394 (52982)	Loss/tok 3.8818 (5.4764)	Learning Rate [0.00125]
10: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00100)	Tok/s 71420 (52904)	Loss/tok 4.1989 (5.4819)	Learning Rate [0.00125]
5: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 70687 (52520)	Loss/tok 4.0604 (5.4897)	Learning Rate [0.00125]
9: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00094)	Tok/s 70784 (52826)	Loss/tok 4.1662 (5.4751)	Learning Rate [0.00125]
4: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 70743 (52413)	Loss/tok 4.0429 (5.4775)	Learning Rate [0.00125]
8: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00100)	Tok/s 70493 (52765)	Loss/tok 4.0024 (5.4831)	Learning Rate [0.00125]
7: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 70497 (52688)	Loss/tok 4.2423 (5.4770)	Learning Rate [0.00125]
6: TRAIN [0][1120/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00097)	Tok/s 70547 (52599)	Loss/tok 4.2873 (5.4774)	Learning Rate [0.00125]
5: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00096)	Tok/s 49904 (52537)	Loss/tok 3.5632 (5.4763)	Learning Rate [0.00125]
4: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00093)	Tok/s 49891 (52429)	Loss/tok 3.8431 (5.4638)	Learning Rate [0.00125]
6: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00097)	Tok/s 49799 (52615)	Loss/tok 3.7181 (5.4638)	Learning Rate [0.00125]
7: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00093)	Tok/s 49734 (52704)	Loss/tok 3.9210 (5.4640)	Learning Rate [0.00125]
2: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00098)	Tok/s 49887 (52226)	Loss/tok 3.8336 (5.4681)	Learning Rate [0.00125]
8: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00100)	Tok/s 49714 (52781)	Loss/tok 3.8258 (5.4684)	Learning Rate [0.00125]
0: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00091)	Tok/s 49874 (52013)	Loss/tok 3.6981 (5.4651)	Learning Rate [0.00125]
1: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00092)	Tok/s 49883 (52125)	Loss/tok 3.8444 (5.4645)	Learning Rate [0.00125]
9: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00094)	Tok/s 49706 (52842)	Loss/tok 3.8326 (5.4606)	Learning Rate [0.00125]
15: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00094)	Tok/s 49709 (53434)	Loss/tok 3.9494 (5.4708)	Learning Rate [0.00125]
11: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00100)	Tok/s 49673 (52998)	Loss/tok 3.9544 (5.4627)	Learning Rate [0.00125]
3: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00112 (0.00100)	Tok/s 49831 (52324)	Loss/tok 4.0550 (5.4555)	Learning Rate [0.00125]
14: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00096)	Tok/s 49689 (53325)	Loss/tok 4.3373 (5.4713)	Learning Rate [0.00125]
12: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00106 (0.00100)	Tok/s 49698 (53116)	Loss/tok 3.8989 (5.4643)	Learning Rate [0.00125]
10: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00111 (0.00100)	Tok/s 49473 (52919)	Loss/tok 3.6284 (5.4687)	Learning Rate [0.00125]
13: TRAIN [0][1130/3416]	Time 0.050 (0.058)	Data 0.00123 (0.00100)	Tok/s 49473 (53216)	Loss/tok 3.8035 (5.4728)	Learning Rate [0.00125]
14: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
9: Upscaling, new scale: 1024.0
14: TRAIN [0][1140/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00096)	Tok/s 53244 (53336)	Loss/tok 3.8885 (5.4574)	Learning Rate [0.00125]
1: TRAIN [0][1140/3416]	Time 0.062 (0.058)	Data 0.00081 (0.00092)	Tok/s 53170 (52143)	Loss/tok 3.8781 (5.4503)	Learning Rate [0.00125]
2: TRAIN [0][1140/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00098)	Tok/s 53309 (52243)	Loss/tok 3.8131 (5.4543)	Learning Rate [0.00125]
0: TRAIN [0][1140/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00091)	Tok/s 52206 (52030)	Loss/tok 4.0314 (5.4511)	Learning Rate [0.00125]
15: TRAIN [0][1140/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00094)	Tok/s 53289 (53445)	Loss/tok 3.8980 (5.4564)	Learning Rate [0.00125]
4: TRAIN [0][1140/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00093)	Tok/s 53195 (52444)	Loss/tok 3.8290 (5.4497)	Learning Rate [0.00125]
3: TRAIN [0][1140/3416]	Time 0.062 (0.058)	Data 0.00108 (0.00100)	Tok/s 53278 (52341)	Loss/tok 3.9921 (5.4415)	Learning Rate [0.00125]
13: TRAIN [0][1140/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00100)	Tok/s 53173 (53229)	Loss/tok 3.9540 (5.4590)	Learning Rate [0.00125]
5: TRAIN [0][1140/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00096)	Tok/s 53128 (52551)	Loss/tok 3.8319 (5.4618)	Learning Rate [0.00125]
12: TRAIN [0][1140/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00100)	Tok/s 53171 (53128)	Loss/tok 3.9511 (5.4504)	Learning Rate [0.00125]
6: TRAIN [0][1140/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00097)	Tok/s 53129 (52630)	Loss/tok 4.0049 (5.4501)	Learning Rate [0.00125]
11: TRAIN [0][1140/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00100)	Tok/s 53144 (53012)	Loss/tok 4.1211 (5.4492)	Learning Rate [0.00125]
10: TRAIN [0][1140/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00100)	Tok/s 53152 (52933)	Loss/tok 3.9101 (5.4539)	Learning Rate [0.00125]
8: TRAIN [0][1140/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00099)	Tok/s 53111 (52795)	Loss/tok 3.9881 (5.4545)	Learning Rate [0.00125]
7: TRAIN [0][1140/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00093)	Tok/s 53079 (52719)	Loss/tok 4.1817 (5.4502)	Learning Rate [0.00125]
9: TRAIN [0][1140/3416]	Time 0.063 (0.058)	Data 0.00084 (0.00094)	Tok/s 53164 (52856)	Loss/tok 4.1142 (5.4474)	Learning Rate [0.00125]
12: TRAIN [0][1150/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00100)	Tok/s 61810 (53091)	Loss/tok 3.7955 (5.4383)	Learning Rate [0.00125]
13: TRAIN [0][1150/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00100)	Tok/s 61769 (53191)	Loss/tok 4.1790 (5.4479)	Learning Rate [0.00125]
10: TRAIN [0][1150/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00100)	Tok/s 61802 (52897)	Loss/tok 4.1222 (5.4421)	Learning Rate [0.00125]
15: TRAIN [0][1150/3416]	Time 0.069 (0.057)	Data 0.00081 (0.00094)	Tok/s 62355 (53406)	Loss/tok 4.0824 (5.4449)	Learning Rate [0.00125]
14: TRAIN [0][1150/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00096)	Tok/s 61725 (53297)	Loss/tok 4.0381 (5.4460)	Learning Rate [0.00125]
11: TRAIN [0][1150/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00100)	Tok/s 61806 (52975)	Loss/tok 4.2748 (5.4382)	Learning Rate [0.00125]
0: TRAIN [0][1150/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00091)	Tok/s 61479 (51997)	Loss/tok 4.0945 (5.4396)	Learning Rate [0.00125]
9: TRAIN [0][1150/3416]	Time 0.068 (0.057)	Data 0.00084 (0.00094)	Tok/s 61726 (52820)	Loss/tok 4.4460 (5.4364)	Learning Rate [0.00125]
1: TRAIN [0][1150/3416]	Time 0.069 (0.057)	Data 0.00087 (0.00092)	Tok/s 61513 (52108)	Loss/tok 4.1647 (5.4386)	Learning Rate [0.00125]
8: TRAIN [0][1150/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00099)	Tok/s 61686 (52759)	Loss/tok 4.0382 (5.4430)	Learning Rate [0.00125]
2: TRAIN [0][1150/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 61508 (52208)	Loss/tok 4.1498 (5.4432)	Learning Rate [0.00125]
7: TRAIN [0][1150/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00093)	Tok/s 61691 (52683)	Loss/tok 4.1422 (5.4391)	Learning Rate [0.00125]
6: TRAIN [0][1150/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00098)	Tok/s 61715 (52595)	Loss/tok 4.3071 (5.4386)	Learning Rate [0.00125]
5: TRAIN [0][1150/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 61548 (52516)	Loss/tok 4.2810 (5.4504)	Learning Rate [0.00125]
4: TRAIN [0][1150/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00093)	Tok/s 61525 (52410)	Loss/tok 4.0617 (5.4379)	Learning Rate [0.00125]
3: TRAIN [0][1150/3416]	Time 0.069 (0.058)	Data 0.00113 (0.00100)	Tok/s 61481 (52305)	Loss/tok 4.0361 (5.4295)	Learning Rate [0.00125]
11: TRAIN [0][1160/3416]	Time 0.047 (0.057)	Data 0.00096 (0.00100)	Tok/s 51214 (52936)	Loss/tok 3.8479 (5.4269)	Learning Rate [0.00125]
12: TRAIN [0][1160/3416]	Time 0.047 (0.057)	Data 0.00097 (0.00100)	Tok/s 51237 (53054)	Loss/tok 3.7631 (5.4266)	Learning Rate [0.00125]
10: TRAIN [0][1160/3416]	Time 0.048 (0.057)	Data 0.00088 (0.00100)	Tok/s 51069 (52858)	Loss/tok 3.8153 (5.4301)	Learning Rate [0.00125]
13: TRAIN [0][1160/3416]	Time 0.047 (0.057)	Data 0.00102 (0.00100)	Tok/s 51433 (53153)	Loss/tok 3.5841 (5.4358)	Learning Rate [0.00125]
9: TRAIN [0][1160/3416]	Time 0.048 (0.057)	Data 0.00093 (0.00094)	Tok/s 50880 (52780)	Loss/tok 3.6900 (5.4249)	Learning Rate [0.00125]
14: TRAIN [0][1160/3416]	Time 0.047 (0.057)	Data 0.00090 (0.00096)	Tok/s 52658 (53261)	Loss/tok 3.9887 (5.4344)	Learning Rate [0.00125]
15: TRAIN [0][1160/3416]	Time 0.048 (0.057)	Data 0.00077 (0.00094)	Tok/s 52456 (53371)	Loss/tok 3.7537 (5.4337)	Learning Rate [0.00125]
8: TRAIN [0][1160/3416]	Time 0.048 (0.057)	Data 0.00098 (0.00099)	Tok/s 50812 (52720)	Loss/tok 3.6544 (5.4317)	Learning Rate [0.00125]
0: TRAIN [0][1160/3416]	Time 0.048 (0.057)	Data 0.00082 (0.00091)	Tok/s 51161 (51938)	Loss/tok 4.1781 (5.4284)	Learning Rate [0.00125]
7: TRAIN [0][1160/3416]	Time 0.048 (0.057)	Data 0.00089 (0.00093)	Tok/s 50752 (52642)	Loss/tok 4.1788 (5.4275)	Learning Rate [0.00125]
1: TRAIN [0][1160/3416]	Time 0.048 (0.057)	Data 0.00087 (0.00092)	Tok/s 51056 (52053)	Loss/tok 3.5740 (5.4266)	Learning Rate [0.00125]
5: TRAIN [0][1160/3416]	Time 0.048 (0.057)	Data 0.00096 (0.00096)	Tok/s 50681 (52472)	Loss/tok 3.7507 (5.4390)	Learning Rate [0.00125]
2: TRAIN [0][1160/3416]	Time 0.048 (0.057)	Data 0.00103 (0.00099)	Tok/s 50885 (52158)	Loss/tok 4.0218 (5.4325)	Learning Rate [0.00125]
4: TRAIN [0][1160/3416]	Time 0.048 (0.057)	Data 0.00082 (0.00093)	Tok/s 50767 (52364)	Loss/tok 3.7383 (5.4266)	Learning Rate [0.00125]
6: TRAIN [0][1160/3416]	Time 0.048 (0.057)	Data 0.00096 (0.00098)	Tok/s 50653 (52553)	Loss/tok 3.7614 (5.4274)	Learning Rate [0.00125]
3: TRAIN [0][1160/3416]	Time 0.048 (0.057)	Data 0.00112 (0.00100)	Tok/s 50664 (52256)	Loss/tok 3.5721 (5.4175)	Learning Rate [0.00125]
0: Gradient norm: inf
2: Gradient norm: inf
0: Skipped batch, new scale: 512.0
2: Skipped batch, new scale: 512.0
15: Gradient norm: inf
3: Gradient norm: inf
14: Gradient norm: inf
1: Gradient norm: inf
15: Skipped batch, new scale: 512.0
4: Gradient norm: inf
3: Skipped batch, new scale: 512.0
14: Skipped batch, new scale: 512.0
13: Gradient norm: inf
1: Skipped batch, new scale: 512.0
4: Skipped batch, new scale: 512.0
5: Gradient norm: inf
13: Skipped batch, new scale: 512.0
5: Skipped batch, new scale: 512.0
6: Gradient norm: inf
11: Gradient norm: inf
6: Skipped batch, new scale: 512.0
11: Skipped batch, new scale: 512.0
10: Gradient norm: inf
7: Gradient norm: inf
12: Gradient norm: inf
8: Gradient norm: inf
10: Skipped batch, new scale: 512.0
9: Gradient norm: inf
7: Skipped batch, new scale: 512.0
12: Skipped batch, new scale: 512.0
8: Skipped batch, new scale: 512.0
9: Skipped batch, new scale: 512.0
14: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00097 (0.00096)	Tok/s 53635 (53286)	Loss/tok 4.1173 (5.4211)	Learning Rate [0.00125]
15: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00091 (0.00094)	Tok/s 53491 (53397)	Loss/tok 3.6706 (5.4193)	Learning Rate [0.00125]
13: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00099 (0.00100)	Tok/s 53608 (53178)	Loss/tok 4.0561 (5.4223)	Learning Rate [0.00125]
0: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00092 (0.00091)	Tok/s 52388 (51964)	Loss/tok 3.9175 (5.4147)	Learning Rate [0.00125]
12: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00097 (0.00100)	Tok/s 53608 (53078)	Loss/tok 4.1729 (5.4136)	Learning Rate [0.00125]
11: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00108 (0.00100)	Tok/s 52804 (52959)	Loss/tok 3.7688 (5.4129)	Learning Rate [0.00125]
2: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00103 (0.00099)	Tok/s 52428 (52184)	Loss/tok 3.9483 (5.4186)	Learning Rate [0.00125]
1: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00097 (0.00092)	Tok/s 52433 (52080)	Loss/tok 4.1398 (5.4127)	Learning Rate [0.00125]
10: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00089 (0.00100)	Tok/s 52437 (52881)	Loss/tok 3.9157 (5.4175)	Learning Rate [0.00125]
3: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00108 (0.00100)	Tok/s 52459 (52281)	Loss/tok 3.5466 (5.4037)	Learning Rate [0.00125]
4: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00090 (0.00093)	Tok/s 52482 (52388)	Loss/tok 3.7147 (5.4132)	Learning Rate [0.00125]
5: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00107 (0.00096)	Tok/s 52466 (52497)	Loss/tok 3.7782 (5.4252)	Learning Rate [0.00125]
8: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00095 (0.00099)	Tok/s 52448 (52743)	Loss/tok 3.8436 (5.4175)	Learning Rate [0.00125]
9: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00096 (0.00094)	Tok/s 52461 (52803)	Loss/tok 4.1442 (5.4118)	Learning Rate [0.00125]
6: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00100 (0.00098)	Tok/s 52455 (52577)	Loss/tok 4.0369 (5.4132)	Learning Rate [0.00125]
7: TRAIN [0][1170/3416]	Time 0.056 (0.057)	Data 0.00095 (0.00093)	Tok/s 52444 (52665)	Loss/tok 3.8302 (5.4140)	Learning Rate [0.00125]
15: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00087 (0.00093)	Tok/s 44799 (53411)	Loss/tok 3.5753 (5.4059)	Learning Rate [0.00125]
1: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00096 (0.00092)	Tok/s 44446 (52098)	Loss/tok 3.7221 (5.4000)	Learning Rate [0.00125]
2: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00110 (0.00099)	Tok/s 44552 (52202)	Loss/tok 3.6655 (5.4057)	Learning Rate [0.00125]
0: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00093 (0.00091)	Tok/s 43288 (51982)	Loss/tok 3.7829 (5.4018)	Learning Rate [0.00125]
14: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00091 (0.00096)	Tok/s 44735 (53300)	Loss/tok 3.6636 (5.4075)	Learning Rate [0.00125]
4: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00098 (0.00093)	Tok/s 44382 (52406)	Loss/tok 3.6764 (5.3999)	Learning Rate [0.00125]
13: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00104 (0.00100)	Tok/s 44716 (53191)	Loss/tok 3.6209 (5.4097)	Learning Rate [0.00125]
5: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00106 (0.00096)	Tok/s 44386 (52515)	Loss/tok 3.4286 (5.4117)	Learning Rate [0.00125]
3: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00117 (0.00100)	Tok/s 44442 (52299)	Loss/tok 3.7301 (5.3913)	Learning Rate [0.00125]
12: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00117 (0.00100)	Tok/s 44682 (53092)	Loss/tok 3.5035 (5.4008)	Learning Rate [0.00125]
6: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00110 (0.00098)	Tok/s 44383 (52595)	Loss/tok 3.5501 (5.3997)	Learning Rate [0.00125]
11: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00088 (0.00100)	Tok/s 44654 (52974)	Loss/tok 3.6708 (5.3995)	Learning Rate [0.00125]
10: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00087 (0.00100)	Tok/s 44539 (52896)	Loss/tok 3.7034 (5.4041)	Learning Rate [0.00125]
8: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00101 (0.00099)	Tok/s 44399 (52760)	Loss/tok 3.6005 (5.4050)	Learning Rate [0.00125]
9: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00087 (0.00094)	Tok/s 44503 (52819)	Loss/tok 3.5254 (5.3987)	Learning Rate [0.00125]
7: TRAIN [0][1180/3416]	Time 0.046 (0.057)	Data 0.00092 (0.00093)	Tok/s 44389 (52682)	Loss/tok 3.5597 (5.4014)	Learning Rate [0.00125]
8: Gradient norm: inf
9: Gradient norm: inf
7: Gradient norm: inf
8: Skipped batch, new scale: 256.0
9: Skipped batch, new scale: 256.0
10: Gradient norm: inf
6: Gradient norm: inf
7: Skipped batch, new scale: 256.0
15: Gradient norm: inf
11: Gradient norm: inf
0: Gradient norm: inf
10: Skipped batch, new scale: 256.0
6: Skipped batch, new scale: 256.0
15: Skipped batch, new scale: 256.0
5: Gradient norm: inf
14: Gradient norm: inf
11: Skipped batch, new scale: 256.0
12: Gradient norm: inf
0: Skipped batch, new scale: 256.0
13: Gradient norm: inf
1: Gradient norm: inf
4: Gradient norm: inf
5: Skipped batch, new scale: 256.0
14: Skipped batch, new scale: 256.0
2: Gradient norm: inf
12: Skipped batch, new scale: 256.0
1: Skipped batch, new scale: 256.0
13: Skipped batch, new scale: 256.0
4: Skipped batch, new scale: 256.0
2: Skipped batch, new scale: 256.0
3: Gradient norm: inf
3: Skipped batch, new scale: 256.0
10: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00092 (0.00100)	Tok/s 36383 (52880)	Loss/tok 3.7391 (5.3927)	Learning Rate [0.00125]
11: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00094 (0.00100)	Tok/s 36398 (52958)	Loss/tok 3.3711 (5.3876)	Learning Rate [0.00125]
12: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00101 (0.00100)	Tok/s 36464 (53077)	Loss/tok 3.6503 (5.3892)	Learning Rate [0.00125]
13: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00097 (0.00100)	Tok/s 36435 (53175)	Loss/tok 3.4613 (5.3982)	Learning Rate [0.00125]
9: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00085 (0.00094)	Tok/s 36303 (52803)	Loss/tok 3.5962 (5.3871)	Learning Rate [0.00125]
8: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00091 (0.00099)	Tok/s 36259 (52742)	Loss/tok 3.3664 (5.3937)	Learning Rate [0.00125]
14: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00084 (0.00096)	Tok/s 36363 (53283)	Loss/tok 3.5068 (5.3960)	Learning Rate [0.00125]
15: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00089 (0.00093)	Tok/s 36815 (53394)	Loss/tok 3.2916 (5.3941)	Learning Rate [0.00125]
7: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00089 (0.00093)	Tok/s 36231 (52664)	Loss/tok 3.6310 (5.3908)	Learning Rate [0.00125]
5: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00099 (0.00096)	Tok/s 36265 (52498)	Loss/tok 3.3563 (5.4000)	Learning Rate [0.00125]
0: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00100 (0.00091)	Tok/s 36257 (51966)	Loss/tok 3.6552 (5.3899)	Learning Rate [0.00125]
6: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00104 (0.00098)	Tok/s 36204 (52578)	Loss/tok 3.6080 (5.3879)	Learning Rate [0.00125]
4: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00091 (0.00093)	Tok/s 36259 (52389)	Loss/tok 3.5691 (5.3886)	Learning Rate [0.00125]
1: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00088 (0.00092)	Tok/s 36247 (52082)	Loss/tok 3.6110 (5.3882)	Learning Rate [0.00125]
2: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00098 (0.00099)	Tok/s 36243 (52185)	Loss/tok 3.5096 (5.3938)	Learning Rate [0.00125]
3: TRAIN [0][1190/3416]	Time 0.049 (0.057)	Data 0.00114 (0.00100)	Tok/s 36325 (52282)	Loss/tok 3.4035 (5.3800)	Learning Rate [0.00125]
1: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00097 (0.00092)	Tok/s 56592 (52036)	Loss/tok 4.0912 (5.3781)	Learning Rate [0.00125]
0: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00088 (0.00091)	Tok/s 56584 (51920)	Loss/tok 4.0474 (5.3789)	Learning Rate [0.00125]
2: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00108 (0.00099)	Tok/s 56407 (52139)	Loss/tok 4.1141 (5.3828)	Learning Rate [0.00125]
15: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00090 (0.00093)	Tok/s 56603 (53342)	Loss/tok 3.7347 (5.3832)	Learning Rate [0.00125]
4: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00093 (0.00093)	Tok/s 56366 (52342)	Loss/tok 3.8124 (5.3776)	Learning Rate [0.00125]
14: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00092 (0.00096)	Tok/s 56573 (53230)	Loss/tok 4.1940 (5.3848)	Learning Rate [0.00125]
3: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00110 (0.00100)	Tok/s 56389 (52235)	Loss/tok 3.8781 (5.3692)	Learning Rate [0.00125]
5: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00103 (0.00096)	Tok/s 56296 (52450)	Loss/tok 4.2199 (5.3894)	Learning Rate [0.00125]
13: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00105 (0.00100)	Tok/s 56498 (53123)	Loss/tok 3.9304 (5.3877)	Learning Rate [0.00125]
7: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00090 (0.00093)	Tok/s 56326 (52615)	Loss/tok 3.9294 (5.3802)	Learning Rate [0.00125]
6: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00098 (0.00098)	Tok/s 56179 (52529)	Loss/tok 4.2113 (5.3778)	Learning Rate [0.00125]
12: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00106 (0.00100)	Tok/s 56452 (53024)	Loss/tok 4.1385 (5.3788)	Learning Rate [0.00125]
9: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00092 (0.00094)	Tok/s 56322 (52752)	Loss/tok 4.0302 (5.3763)	Learning Rate [0.00125]
8: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00097 (0.00099)	Tok/s 56245 (52692)	Loss/tok 4.0472 (5.3834)	Learning Rate [0.00125]
10: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00094 (0.00100)	Tok/s 56303 (52829)	Loss/tok 4.2802 (5.3827)	Learning Rate [0.00125]
11: TRAIN [0][1200/3416]	Time 0.067 (0.057)	Data 0.00094 (0.00100)	Tok/s 56372 (52907)	Loss/tok 4.1696 (5.3774)	Learning Rate [0.00125]
11: TRAIN [0][1210/3416]	Time 0.068 (0.057)	Data 0.00094 (0.00100)	Tok/s 57227 (52974)	Loss/tok 4.0948 (5.3620)	Learning Rate [0.00125]
12: TRAIN [0][1210/3416]	Time 0.068 (0.057)	Data 0.00097 (0.00100)	Tok/s 57183 (53091)	Loss/tok 4.0391 (5.3638)	Learning Rate [0.00125]
13: TRAIN [0][1210/3416]	Time 0.068 (0.057)	Data 0.00107 (0.00100)	Tok/s 57094 (53189)	Loss/tok 4.3329 (5.3733)	Learning Rate [0.00125]
10: TRAIN [0][1210/3416]	Time 0.068 (0.057)	Data 0.00085 (0.00100)	Tok/s 57065 (52896)	Loss/tok 4.2251 (5.3684)	Learning Rate [0.00125]
14: TRAIN [0][1210/3416]	Time 0.069 (0.057)	Data 0.00089 (0.00096)	Tok/s 56967 (53295)	Loss/tok 3.8981 (5.3699)	Learning Rate [0.00125]
15: TRAIN [0][1210/3416]	Time 0.069 (0.057)	Data 0.00086 (0.00093)	Tok/s 56878 (53406)	Loss/tok 4.0078 (5.3683)	Learning Rate [0.00125]
9: TRAIN [0][1210/3416]	Time 0.068 (0.057)	Data 0.00093 (0.00094)	Tok/s 57080 (52817)	Loss/tok 3.9115 (5.3610)	Learning Rate [0.00125]
0: TRAIN [0][1210/3416]	Time 0.069 (0.057)	Data 0.00090 (0.00091)	Tok/s 55882 (51985)	Loss/tok 4.2279 (5.3642)	Learning Rate [0.00125]
7: TRAIN [0][1210/3416]	Time 0.068 (0.057)	Data 0.00091 (0.00092)	Tok/s 56539 (52678)	Loss/tok 4.1626 (5.3663)	Learning Rate [0.00125]
1: TRAIN [0][1210/3416]	Time 0.069 (0.057)	Data 0.00087 (0.00092)	Tok/s 55840 (52101)	Loss/tok 4.2076 (5.3638)	Learning Rate [0.00125]
2: TRAIN [0][1210/3416]	Time 0.069 (0.057)	Data 0.00106 (0.00099)	Tok/s 55918 (52203)	Loss/tok 3.8327 (5.3674)	Learning Rate [0.00125]
8: TRAIN [0][1210/3416]	Time 0.068 (0.057)	Data 0.00094 (0.00099)	Tok/s 57112 (52756)	Loss/tok 4.0330 (5.3689)	Learning Rate [0.00125]
4: TRAIN [0][1210/3416]	Time 0.069 (0.057)	Data 0.00087 (0.00093)	Tok/s 55919 (52406)	Loss/tok 4.2207 (5.3634)	Learning Rate [0.00125]
6: TRAIN [0][1210/3416]	Time 0.068 (0.057)	Data 0.00116 (0.00098)	Tok/s 56136 (52592)	Loss/tok 4.3621 (5.3638)	Learning Rate [0.00125]
3: TRAIN [0][1210/3416]	Time 0.069 (0.057)	Data 0.00101 (0.00100)	Tok/s 55872 (52299)	Loss/tok 3.9502 (5.3548)	Learning Rate [0.00125]
5: TRAIN [0][1210/3416]	Time 0.069 (0.057)	Data 0.00093 (0.00096)	Tok/s 55993 (52514)	Loss/tok 4.2233 (5.3755)	Learning Rate [0.00125]
15: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 63227 (53452)	Loss/tok 3.9052 (5.3543)	Learning Rate [0.00125]
14: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 63226 (53341)	Loss/tok 4.1719 (5.3562)	Learning Rate [0.00125]
0: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 62163 (52034)	Loss/tok 4.0188 (5.3502)	Learning Rate [0.00125]
13: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00100)	Tok/s 63206 (53235)	Loss/tok 4.3005 (5.3596)	Learning Rate [0.00125]
1: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 62064 (52149)	Loss/tok 4.1493 (5.3505)	Learning Rate [0.00125]
2: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 62427 (52250)	Loss/tok 3.9168 (5.3536)	Learning Rate [0.00125]
12: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 63141 (53138)	Loss/tok 3.9611 (5.3498)	Learning Rate [0.00125]
11: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 63099 (53021)	Loss/tok 4.0708 (5.3489)	Learning Rate [0.00125]
10: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00100)	Tok/s 63022 (52942)	Loss/tok 4.0819 (5.3551)	Learning Rate [0.00125]
3: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00100)	Tok/s 62717 (52348)	Loss/tok 3.7531 (5.3406)	Learning Rate [0.00125]
4: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 62678 (52454)	Loss/tok 4.2615 (5.3501)	Learning Rate [0.00125]
9: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00094)	Tok/s 62914 (52863)	Loss/tok 3.7719 (5.3477)	Learning Rate [0.00125]
8: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00099)	Tok/s 62831 (52802)	Loss/tok 4.0677 (5.3549)	Learning Rate [0.00125]
5: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00096)	Tok/s 62725 (52561)	Loss/tok 4.0160 (5.3615)	Learning Rate [0.00125]
7: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 62752 (52724)	Loss/tok 4.1777 (5.3526)	Learning Rate [0.00125]
6: TRAIN [0][1220/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00098)	Tok/s 62697 (52639)	Loss/tok 4.2104 (5.3502)	Learning Rate [0.00125]
6: TRAIN [0][1230/3416]	Time 0.046 (0.058)	Data 0.00108 (0.00098)	Tok/s 31680 (52590)	Loss/tok 3.5610 (5.3390)	Learning Rate [0.00125]
7: TRAIN [0][1230/3416]	Time 0.047 (0.058)	Data 0.00083 (0.00092)	Tok/s 31626 (52675)	Loss/tok 3.3429 (5.3425)	Learning Rate [0.00125]
5: TRAIN [0][1230/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00096)	Tok/s 31653 (52512)	Loss/tok 3.3179 (5.3509)	Learning Rate [0.00125]
8: TRAIN [0][1230/3416]	Time 0.047 (0.058)	Data 0.00082 (0.00099)	Tok/s 31547 (52753)	Loss/tok 3.1104 (5.3447)	Learning Rate [0.00125]
4: TRAIN [0][1230/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00093)	Tok/s 31529 (52406)	Loss/tok 3.1579 (5.3397)	Learning Rate [0.00125]
10: TRAIN [0][1230/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00100)	Tok/s 31421 (52893)	Loss/tok 3.4010 (5.3445)	Learning Rate [0.00125]
9: TRAIN [0][1230/3416]	Time 0.047 (0.057)	Data 0.00091 (0.00094)	Tok/s 31493 (52814)	Loss/tok 3.3599 (5.3372)	Learning Rate [0.00125]
3: TRAIN [0][1230/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00100)	Tok/s 31499 (52301)	Loss/tok 3.6194 (5.3298)	Learning Rate [0.00125]
11: TRAIN [0][1230/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00099)	Tok/s 31351 (52971)	Loss/tok 3.0767 (5.3379)	Learning Rate [0.00125]
2: TRAIN [0][1230/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00099)	Tok/s 31406 (52202)	Loss/tok 3.3091 (5.3434)	Learning Rate [0.00125]
12: TRAIN [0][1230/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00100)	Tok/s 32443 (53088)	Loss/tok 3.3334 (5.3393)	Learning Rate [0.00125]
13: TRAIN [0][1230/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00100)	Tok/s 32733 (53185)	Loss/tok 3.2440 (5.3483)	Learning Rate [0.00125]
1: TRAIN [0][1230/3416]	Time 0.047 (0.057)	Data 0.00087 (0.00093)	Tok/s 31425 (52101)	Loss/tok 3.2194 (5.3404)	Learning Rate [0.00125]
0: TRAIN [0][1230/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00091)	Tok/s 31397 (51986)	Loss/tok 3.1263 (5.3398)	Learning Rate [0.00125]
15: TRAIN [0][1230/3416]	Time 0.047 (0.058)	Data 0.00080 (0.00093)	Tok/s 32748 (53401)	Loss/tok 3.3189 (5.3434)	Learning Rate [0.00125]
14: TRAIN [0][1230/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00096)	Tok/s 32733 (53291)	Loss/tok 3.2685 (5.3456)	Learning Rate [0.00125]
1: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00081 (0.00093)	Tok/s 46969 (52097)	Loss/tok 3.7230 (5.3285)	Learning Rate [0.00125]
15: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00080 (0.00093)	Tok/s 48313 (53400)	Loss/tok 3.7237 (5.3314)	Learning Rate [0.00125]
2: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00092 (0.00099)	Tok/s 46839 (52198)	Loss/tok 3.8014 (5.3317)	Learning Rate [0.00125]
14: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00082 (0.00096)	Tok/s 48294 (53290)	Loss/tok 3.6249 (5.3335)	Learning Rate [0.00125]
3: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00100 (0.00100)	Tok/s 46652 (52298)	Loss/tok 3.8187 (5.3178)	Learning Rate [0.00125]
4: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00089 (0.00093)	Tok/s 46570 (52404)	Loss/tok 3.6283 (5.3277)	Learning Rate [0.00125]
13: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00102 (0.00100)	Tok/s 48290 (53184)	Loss/tok 3.8086 (5.3356)	Learning Rate [0.00125]
12: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00099 (0.00100)	Tok/s 48045 (53087)	Loss/tok 3.9634 (5.3278)	Learning Rate [0.00125]
10: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00096 (0.00100)	Tok/s 47909 (52891)	Loss/tok 3.8370 (5.3320)	Learning Rate [0.00125]
5: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00090 (0.00096)	Tok/s 46406 (52509)	Loss/tok 3.6314 (5.3389)	Learning Rate [0.00125]
0: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00087 (0.00092)	Tok/s 46837 (51983)	Loss/tok 3.5063 (5.3279)	Learning Rate [0.00125]
9: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00092 (0.00094)	Tok/s 47823 (52811)	Loss/tok 3.8431 (5.3258)	Learning Rate [0.00125]
6: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00107 (0.00098)	Tok/s 46325 (52586)	Loss/tok 3.7287 (5.3266)	Learning Rate [0.00125]
11: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00095 (0.00099)	Tok/s 47887 (52970)	Loss/tok 3.6206 (5.3248)	Learning Rate [0.00125]
8: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00086 (0.00099)	Tok/s 47687 (52750)	Loss/tok 3.5875 (5.3327)	Learning Rate [0.00125]
7: TRAIN [0][1240/3416]	Time 0.048 (0.057)	Data 0.00092 (0.00092)	Tok/s 47386 (52671)	Loss/tok 3.5997 (5.3304)	Learning Rate [0.00125]
13: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00115 (0.00100)	Tok/s 58436 (53136)	Loss/tok 4.4034 (5.3263)	Learning Rate [0.00125]
12: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00092 (0.00100)	Tok/s 58445 (53039)	Loss/tok 3.7928 (5.3182)	Learning Rate [0.00125]
14: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00093 (0.00096)	Tok/s 58291 (53242)	Loss/tok 3.8278 (5.3236)	Learning Rate [0.00125]
0: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00095 (0.00092)	Tok/s 57348 (51941)	Loss/tok 3.9878 (5.3176)	Learning Rate [0.00125]
11: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00090 (0.00099)	Tok/s 58440 (52922)	Loss/tok 3.9297 (5.3152)	Learning Rate [0.00125]
15: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00084 (0.00093)	Tok/s 58127 (53352)	Loss/tok 4.0609 (5.3216)	Learning Rate [0.00125]
10: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00092 (0.00100)	Tok/s 58347 (52844)	Loss/tok 4.0509 (5.3224)	Learning Rate [0.00125]
8: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00091 (0.00099)	Tok/s 58423 (52703)	Loss/tok 4.1343 (5.3228)	Learning Rate [0.00125]
1: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00091 (0.00093)	Tok/s 57262 (52053)	Loss/tok 4.0613 (5.3188)	Learning Rate [0.00125]
9: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00104 (0.00094)	Tok/s 58362 (52763)	Loss/tok 3.9812 (5.3157)	Learning Rate [0.00125]
2: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00104 (0.00099)	Tok/s 57282 (52154)	Loss/tok 3.8494 (5.3221)	Learning Rate [0.00125]
4: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00086 (0.00093)	Tok/s 57254 (52357)	Loss/tok 3.9863 (5.3185)	Learning Rate [0.00125]
7: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00086 (0.00092)	Tok/s 58324 (52624)	Loss/tok 3.8783 (5.3203)	Learning Rate [0.00125]
5: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00092 (0.00096)	Tok/s 57301 (52462)	Loss/tok 3.9318 (5.3293)	Learning Rate [0.00125]
3: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00105 (0.00100)	Tok/s 57217 (52253)	Loss/tok 3.9375 (5.3076)	Learning Rate [0.00125]
6: TRAIN [0][1250/3416]	Time 0.068 (0.057)	Data 0.00111 (0.00098)	Tok/s 57713 (52538)	Loss/tok 4.2311 (5.3170)	Learning Rate [0.00125]
1: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00087 (0.00093)	Tok/s 85285 (52057)	Loss/tok 3.9207 (5.3064)	Learning Rate [0.00125]
0: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00097 (0.00092)	Tok/s 85297 (51941)	Loss/tok 3.8539 (5.3059)	Learning Rate [0.00125]
4: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00085 (0.00093)	Tok/s 85963 (52362)	Loss/tok 3.8481 (5.3063)	Learning Rate [0.00125]
3: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00096 (0.00100)	Tok/s 86096 (52258)	Loss/tok 3.6619 (5.2952)	Learning Rate [0.00125]
2: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00101 (0.00099)	Tok/s 85262 (52158)	Loss/tok 3.8452 (5.3102)	Learning Rate [0.00125]
5: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00092 (0.00096)	Tok/s 85954 (52468)	Loss/tok 4.0686 (5.3173)	Learning Rate [0.00125]
15: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00093 (0.00093)	Tok/s 90250 (53365)	Loss/tok 3.7046 (5.3083)	Learning Rate [0.00125]
14: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00090 (0.00096)	Tok/s 89409 (53254)	Loss/tok 3.9146 (5.3117)	Learning Rate [0.00125]
13: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00107 (0.00100)	Tok/s 88979 (53147)	Loss/tok 3.8845 (5.3135)	Learning Rate [0.00125]
6: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00107 (0.00098)	Tok/s 86316 (52545)	Loss/tok 3.8157 (5.3047)	Learning Rate [0.00125]
12: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00088 (0.00100)	Tok/s 88633 (53050)	Loss/tok 3.7654 (5.3059)	Learning Rate [0.00125]
11: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00090 (0.00099)	Tok/s 87980 (52933)	Loss/tok 3.9715 (5.3035)	Learning Rate [0.00125]
10: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00094 (0.00100)	Tok/s 87854 (52854)	Loss/tok 3.9592 (5.3111)	Learning Rate [0.00125]
8: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00087 (0.00099)	Tok/s 86873 (52712)	Loss/tok 3.7540 (5.3105)	Learning Rate [0.00125]
7: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00087 (0.00092)	Tok/s 86882 (52632)	Loss/tok 3.8044 (5.3079)	Learning Rate [0.00125]
9: TRAIN [0][1260/3416]	Time 0.070 (0.057)	Data 0.00092 (0.00094)	Tok/s 87144 (52773)	Loss/tok 3.6673 (5.3031)	Learning Rate [0.00125]
4: TRAIN [0][1270/3416]	Time 0.049 (0.057)	Data 0.00087 (0.00093)	Tok/s 38691 (52362)	Loss/tok 3.7416 (5.2952)	Learning Rate [0.00125]
5: TRAIN [0][1270/3416]	Time 0.049 (0.057)	Data 0.00087 (0.00096)	Tok/s 38867 (52467)	Loss/tok 3.3958 (5.3065)	Learning Rate [0.00125]
2: TRAIN [0][1270/3416]	Time 0.050 (0.057)	Data 0.00101 (0.00099)	Tok/s 37381 (52156)	Loss/tok 3.4315 (5.2980)	Learning Rate [0.00125]
1: TRAIN [0][1270/3416]	Time 0.050 (0.057)	Data 0.00093 (0.00093)	Tok/s 37336 (52054)	Loss/tok 3.7275 (5.2963)	Learning Rate [0.00125]
6: TRAIN [0][1270/3416]	Time 0.049 (0.057)	Data 0.00106 (0.00098)	Tok/s 38853 (52544)	Loss/tok 3.5835 (5.2928)	Learning Rate [0.00125]
3: TRAIN [0][1270/3416]	Time 0.050 (0.057)	Data 0.00095 (0.00100)	Tok/s 37448 (52255)	Loss/tok 3.6007 (5.2836)	Learning Rate [0.00125]
7: TRAIN [0][1270/3416]	Time 0.049 (0.057)	Data 0.00092 (0.00092)	Tok/s 38879 (52630)	Loss/tok 3.5556 (5.2972)	Learning Rate [0.00125]
15: TRAIN [0][1270/3416]	Time 0.050 (0.057)	Data 0.00093 (0.00093)	Tok/s 38635 (53360)	Loss/tok 4.0009 (5.2969)	Learning Rate [0.00125]
0: TRAIN [0][1270/3416]	Time 0.050 (0.057)	Data 0.00092 (0.00092)	Tok/s 37312 (51939)	Loss/tok 3.4490 (5.2954)	Learning Rate [0.00125]
8: TRAIN [0][1270/3416]	Time 0.049 (0.057)	Data 0.00092 (0.00099)	Tok/s 38844 (52710)	Loss/tok 3.5249 (5.3000)	Learning Rate [0.00125]
9: TRAIN [0][1270/3416]	Time 0.049 (0.057)	Data 0.00098 (0.00094)	Tok/s 38815 (52770)	Loss/tok 3.3974 (5.2921)	Learning Rate [0.00125]
14: TRAIN [0][1270/3416]	Time 0.050 (0.057)	Data 0.00085 (0.00096)	Tok/s 38611 (53249)	Loss/tok 3.6931 (5.3005)	Learning Rate [0.00125]
10: TRAIN [0][1270/3416]	Time 0.050 (0.057)	Data 0.00091 (0.00100)	Tok/s 38766 (52850)	Loss/tok 3.3386 (5.3001)	Learning Rate [0.00125]
12: TRAIN [0][1270/3416]	Time 0.050 (0.057)	Data 0.00095 (0.00100)	Tok/s 38653 (53046)	Loss/tok 3.5277 (5.2946)	Learning Rate [0.00125]
13: TRAIN [0][1270/3416]	Time 0.050 (0.057)	Data 0.00107 (0.00100)	Tok/s 38588 (53143)	Loss/tok 3.7842 (5.3026)	Learning Rate [0.00125]
11: TRAIN [0][1270/3416]	Time 0.050 (0.057)	Data 0.00089 (0.00099)	Tok/s 38650 (52929)	Loss/tok 3.8606 (5.2923)	Learning Rate [0.00125]
2: TRAIN [0][1280/3416]	Time 0.069 (0.057)	Data 0.00104 (0.00099)	Tok/s 65509 (52152)	Loss/tok 3.8679 (5.2874)	Learning Rate [0.00125]
1: TRAIN [0][1280/3416]	Time 0.069 (0.057)	Data 0.00094 (0.00093)	Tok/s 65535 (52050)	Loss/tok 3.8391 (5.2858)	Learning Rate [0.00125]
3: TRAIN [0][1280/3416]	Time 0.069 (0.057)	Data 0.00109 (0.00100)	Tok/s 65430 (52252)	Loss/tok 3.9301 (5.2731)	Learning Rate [0.00125]
0: TRAIN [0][1280/3416]	Time 0.069 (0.057)	Data 0.00092 (0.00092)	Tok/s 65538 (51934)	Loss/tok 3.8702 (5.2838)	Learning Rate [0.00125]
4: TRAIN [0][1280/3416]	Time 0.070 (0.057)	Data 0.00084 (0.00093)	Tok/s 65284 (52357)	Loss/tok 4.1927 (5.2843)	Learning Rate [0.00125]
15: TRAIN [0][1280/3416]	Time 0.069 (0.057)	Data 0.00087 (0.00093)	Tok/s 66536 (53355)	Loss/tok 3.8193 (5.2857)	Learning Rate [0.00125]
14: TRAIN [0][1280/3416]	Time 0.069 (0.057)	Data 0.00093 (0.00096)	Tok/s 66420 (53245)	Loss/tok 4.0420 (5.2898)	Learning Rate [0.00125]
13: TRAIN [0][1280/3416]	Time 0.070 (0.057)	Data 0.00104 (0.00100)	Tok/s 66286 (53138)	Loss/tok 4.1558 (5.2918)	Learning Rate [0.00125]
6: TRAIN [0][1280/3416]	Time 0.070 (0.057)	Data 0.00095 (0.00098)	Tok/s 65031 (52541)	Loss/tok 4.1514 (5.2816)	Learning Rate [0.00125]
5: TRAIN [0][1280/3416]	Time 0.070 (0.057)	Data 0.00091 (0.00096)	Tok/s 65191 (52463)	Loss/tok 3.9636 (5.2950)	Learning Rate [0.00125]
12: TRAIN [0][1280/3416]	Time 0.070 (0.057)	Data 0.00094 (0.00100)	Tok/s 66128 (53041)	Loss/tok 4.1287 (5.2837)	Learning Rate [0.00125]
7: TRAIN [0][1280/3416]	Time 0.070 (0.057)	Data 0.00088 (0.00092)	Tok/s 64979 (52626)	Loss/tok 3.8595 (5.2862)	Learning Rate [0.00125]
8: TRAIN [0][1280/3416]	Time 0.070 (0.057)	Data 0.00088 (0.00099)	Tok/s 64978 (52705)	Loss/tok 4.1272 (5.2892)	Learning Rate [0.00125]
11: TRAIN [0][1280/3416]	Time 0.070 (0.057)	Data 0.00096 (0.00099)	Tok/s 65415 (52925)	Loss/tok 4.3357 (5.2819)	Learning Rate [0.00125]
10: TRAIN [0][1280/3416]	Time 0.070 (0.057)	Data 0.00088 (0.00100)	Tok/s 65054 (52846)	Loss/tok 3.8081 (5.2887)	Learning Rate [0.00125]
9: TRAIN [0][1280/3416]	Time 0.070 (0.057)	Data 0.00089 (0.00094)	Tok/s 64969 (52765)	Loss/tok 4.1522 (5.2816)	Learning Rate [0.00125]
10: TRAIN [0][1290/3416]	Time 0.063 (0.057)	Data 0.00096 (0.00100)	Tok/s 54710 (52893)	Loss/tok 4.0318 (5.2759)	Learning Rate [0.00125]
9: TRAIN [0][1290/3416]	Time 0.063 (0.057)	Data 0.00096 (0.00094)	Tok/s 54820 (52812)	Loss/tok 3.9837 (5.2689)	Learning Rate [0.00125]
8: TRAIN [0][1290/3416]	Time 0.063 (0.057)	Data 0.00099 (0.00099)	Tok/s 54794 (52752)	Loss/tok 3.8787 (5.2772)	Learning Rate [0.00125]
7: TRAIN [0][1290/3416]	Time 0.063 (0.057)	Data 0.00092 (0.00092)	Tok/s 54789 (52674)	Loss/tok 3.8720 (5.2738)	Learning Rate [0.00125]
11: TRAIN [0][1290/3416]	Time 0.063 (0.057)	Data 0.00093 (0.00099)	Tok/s 54593 (52972)	Loss/tok 3.9269 (5.2699)	Learning Rate [0.00125]
12: TRAIN [0][1290/3416]	Time 0.063 (0.057)	Data 0.00096 (0.00100)	Tok/s 54492 (53088)	Loss/tok 3.9227 (5.2710)	Learning Rate [0.00125]
5: TRAIN [0][1290/3416]	Time 0.063 (0.057)	Data 0.00097 (0.00096)	Tok/s 54567 (52509)	Loss/tok 3.8932 (5.2824)	Learning Rate [0.00125]
4: TRAIN [0][1290/3416]	Time 0.063 (0.057)	Data 0.00106 (0.00093)	Tok/s 54567 (52403)	Loss/tok 4.2820 (5.2718)	Learning Rate [0.00125]
13: TRAIN [0][1290/3416]	Time 0.064 (0.057)	Data 0.00110 (0.00100)	Tok/s 54395 (53185)	Loss/tok 3.9093 (5.2794)	Learning Rate [0.00125]
15: TRAIN [0][1290/3416]	Time 0.064 (0.057)	Data 0.00092 (0.00093)	Tok/s 54214 (53402)	Loss/tok 3.9161 (5.2731)	Learning Rate [0.00125]
14: TRAIN [0][1290/3416]	Time 0.064 (0.057)	Data 0.00096 (0.00096)	Tok/s 54266 (53292)	Loss/tok 3.9895 (5.2770)	Learning Rate [0.00125]
6: TRAIN [0][1290/3416]	Time 0.063 (0.057)	Data 0.00133 (0.00098)	Tok/s 54908 (52587)	Loss/tok 3.9755 (5.2693)	Learning Rate [0.00125]
3: TRAIN [0][1290/3416]	Time 0.063 (0.057)	Data 0.00097 (0.00100)	Tok/s 54463 (52298)	Loss/tok 4.0822 (5.2602)	Learning Rate [0.00125]
0: TRAIN [0][1290/3416]	Time 0.064 (0.057)	Data 0.00087 (0.00092)	Tok/s 54280 (51982)	Loss/tok 3.9903 (5.2717)	Learning Rate [0.00125]
2: TRAIN [0][1290/3416]	Time 0.064 (0.057)	Data 0.00095 (0.00099)	Tok/s 54352 (52199)	Loss/tok 4.0726 (5.2747)	Learning Rate [0.00125]
1: TRAIN [0][1290/3416]	Time 0.064 (0.057)	Data 0.00089 (0.00093)	Tok/s 54310 (52098)	Loss/tok 4.2540 (5.2737)	Learning Rate [0.00125]
5: TRAIN [0][1300/3416]	Time 0.044 (0.057)	Data 0.00092 (0.00096)	Tok/s 28805 (52498)	Loss/tok 3.4274 (5.2714)	Learning Rate [0.00125]
3: TRAIN [0][1300/3416]	Time 0.044 (0.057)	Data 0.00105 (0.00100)	Tok/s 28897 (52289)	Loss/tok 3.1223 (5.2494)	Learning Rate [0.00125]
2: TRAIN [0][1300/3416]	Time 0.044 (0.057)	Data 0.00096 (0.00099)	Tok/s 28905 (52190)	Loss/tok 3.2718 (5.2646)	Learning Rate [0.00125]
4: TRAIN [0][1300/3416]	Time 0.044 (0.057)	Data 0.00084 (0.00093)	Tok/s 28902 (52393)	Loss/tok 3.1018 (5.2619)	Learning Rate [0.00125]
6: TRAIN [0][1300/3416]	Time 0.045 (0.057)	Data 0.00100 (0.00098)	Tok/s 28745 (52576)	Loss/tok 3.0932 (5.2596)	Learning Rate [0.00125]
1: TRAIN [0][1300/3416]	Time 0.044 (0.057)	Data 0.00094 (0.00093)	Tok/s 28885 (52089)	Loss/tok 3.0545 (5.2628)	Learning Rate [0.00125]
8: TRAIN [0][1300/3416]	Time 0.045 (0.057)	Data 0.00104 (0.00099)	Tok/s 29679 (52743)	Loss/tok 3.0058 (5.2668)	Learning Rate [0.00125]
0: TRAIN [0][1300/3416]	Time 0.044 (0.057)	Data 0.00099 (0.00092)	Tok/s 28865 (51974)	Loss/tok 3.1902 (5.2614)	Learning Rate [0.00125]
15: TRAIN [0][1300/3416]	Time 0.044 (0.057)	Data 0.00097 (0.00093)	Tok/s 30236 (53392)	Loss/tok 3.1531 (5.2624)	Learning Rate [0.00125]
7: TRAIN [0][1300/3416]	Time 0.045 (0.057)	Data 0.00089 (0.00092)	Tok/s 28664 (52664)	Loss/tok 3.1243 (5.2629)	Learning Rate [0.00125]
14: TRAIN [0][1300/3416]	Time 0.045 (0.057)	Data 0.00104 (0.00096)	Tok/s 30182 (53283)	Loss/tok 2.9767 (5.2666)	Learning Rate [0.00125]
10: TRAIN [0][1300/3416]	Time 0.045 (0.057)	Data 0.00093 (0.00100)	Tok/s 30096 (52884)	Loss/tok 3.2801 (5.2655)	Learning Rate [0.00125]
13: TRAIN [0][1300/3416]	Time 0.045 (0.057)	Data 0.00111 (0.00100)	Tok/s 30176 (53176)	Loss/tok 3.1651 (5.2685)	Learning Rate [0.00125]
12: TRAIN [0][1300/3416]	Time 0.045 (0.057)	Data 0.00098 (0.00100)	Tok/s 30146 (53079)	Loss/tok 3.1446 (5.2604)	Learning Rate [0.00125]
11: TRAIN [0][1300/3416]	Time 0.045 (0.057)	Data 0.00097 (0.00099)	Tok/s 30107 (52964)	Loss/tok 2.9045 (5.2597)	Learning Rate [0.00125]
9: TRAIN [0][1300/3416]	Time 0.045 (0.057)	Data 0.00091 (0.00094)	Tok/s 30019 (52803)	Loss/tok 3.3086 (5.2577)	Learning Rate [0.00125]
15: TRAIN [0][1310/3416]	Time 0.070 (0.057)	Data 0.00085 (0.00093)	Tok/s 75985 (53448)	Loss/tok 4.2113 (5.2500)	Learning Rate [0.00125]
14: TRAIN [0][1310/3416]	Time 0.070 (0.057)	Data 0.00092 (0.00096)	Tok/s 76082 (53339)	Loss/tok 3.7358 (5.2536)	Learning Rate [0.00125]
0: TRAIN [0][1310/3416]	Time 0.070 (0.057)	Data 0.00085 (0.00092)	Tok/s 75126 (52031)	Loss/tok 4.1312 (5.2487)	Learning Rate [0.00125]
2: TRAIN [0][1310/3416]	Time 0.070 (0.057)	Data 0.00089 (0.00099)	Tok/s 75180 (52246)	Loss/tok 4.1720 (5.2524)	Learning Rate [0.00125]
13: TRAIN [0][1310/3416]	Time 0.070 (0.057)	Data 0.00114 (0.00100)	Tok/s 76023 (53232)	Loss/tok 3.8272 (5.2551)	Learning Rate [0.00125]
1: TRAIN [0][1310/3416]	Time 0.070 (0.057)	Data 0.00092 (0.00093)	Tok/s 75137 (52146)	Loss/tok 3.9436 (5.2500)	Learning Rate [0.00125]
12: TRAIN [0][1310/3416]	Time 0.070 (0.057)	Data 0.00105 (0.00100)	Tok/s 76030 (53136)	Loss/tok 3.7590 (5.2473)	Learning Rate [0.00125]
11: TRAIN [0][1310/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00099)	Tok/s 75993 (53020)	Loss/tok 3.9171 (5.2475)	Learning Rate [0.00125]
10: TRAIN [0][1310/3416]	Time 0.070 (0.057)	Data 0.00100 (0.00100)	Tok/s 76057 (52940)	Loss/tok 4.1184 (5.2528)	Learning Rate [0.00125]
4: TRAIN [0][1310/3416]	Time 0.070 (0.057)	Data 0.00093 (0.00093)	Tok/s 75142 (52449)	Loss/tok 3.8628 (5.2499)	Learning Rate [0.00125]
5: TRAIN [0][1310/3416]	Time 0.070 (0.057)	Data 0.00103 (0.00096)	Tok/s 75167 (52553)	Loss/tok 4.0693 (5.2590)	Learning Rate [0.00125]
8: TRAIN [0][1310/3416]	Time 0.070 (0.057)	Data 0.00099 (0.00099)	Tok/s 75999 (52799)	Loss/tok 3.8649 (5.2533)	Learning Rate [0.00125]
9: TRAIN [0][1310/3416]	Time 0.069 (0.057)	Data 0.00104 (0.00094)	Tok/s 77098 (52858)	Loss/tok 3.9717 (5.2447)	Learning Rate [0.00125]
3: TRAIN [0][1310/3416]	Time 0.070 (0.057)	Data 0.00123 (0.00100)	Tok/s 75169 (52345)	Loss/tok 3.7725 (5.2366)	Learning Rate [0.00125]
6: TRAIN [0][1310/3416]	Time 0.070 (0.057)	Data 0.00104 (0.00098)	Tok/s 75292 (52631)	Loss/tok 3.9537 (5.2478)	Learning Rate [0.00125]
7: TRAIN [0][1310/3416]	Time 0.069 (0.057)	Data 0.00106 (0.00093)	Tok/s 76218 (52719)	Loss/tok 3.8679 (5.2505)	Learning Rate [0.00125]
4: Upscaling, new scale: 512.0
5: Upscaling, new scale: 512.0
3: Upscaling, new scale: 512.0
2: Upscaling, new scale: 512.0
6: Upscaling, new scale: 512.0
1: Upscaling, new scale: 512.0
0: Upscaling, new scale: 512.0
8: Upscaling, new scale: 512.0
15: Upscaling, new scale: 512.0
14: Upscaling, new scale: 512.0
7: Upscaling, new scale: 512.0
10: Upscaling, new scale: 512.0
13: Upscaling, new scale: 512.0
12: Upscaling, new scale: 512.0
11: Upscaling, new scale: 512.0
9: Upscaling, new scale: 512.0
14: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00099 (0.00096)	Tok/s 62814 (53322)	Loss/tok 3.9022 (5.2441)	Learning Rate [0.00125]
15: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00094 (0.00093)	Tok/s 63453 (53431)	Loss/tok 4.0640 (5.2405)	Learning Rate [0.00125]
13: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00118 (0.00100)	Tok/s 62845 (53216)	Loss/tok 3.9460 (5.2450)	Learning Rate [0.00125]
0: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00088 (0.00092)	Tok/s 62699 (52018)	Loss/tok 4.0678 (5.2389)	Learning Rate [0.00125]
12: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00103 (0.00100)	Tok/s 62836 (53119)	Loss/tok 4.1341 (5.2378)	Learning Rate [0.00125]
11: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00100 (0.00099)	Tok/s 62820 (53004)	Loss/tok 3.8160 (5.2375)	Learning Rate [0.00125]
1: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00100 (0.00093)	Tok/s 62661 (52131)	Loss/tok 4.0939 (5.2407)	Learning Rate [0.00125]
10: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00109 (0.00100)	Tok/s 62825 (52924)	Loss/tok 4.0277 (5.2429)	Learning Rate [0.00125]
2: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00099 (0.00099)	Tok/s 62650 (52230)	Loss/tok 4.1001 (5.2429)	Learning Rate [0.00125]
3: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00101 (0.00100)	Tok/s 62666 (52329)	Loss/tok 3.8944 (5.2270)	Learning Rate [0.00125]
5: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00103 (0.00096)	Tok/s 62711 (52539)	Loss/tok 3.8948 (5.2491)	Learning Rate [0.00125]
4: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00091 (0.00093)	Tok/s 62658 (52434)	Loss/tok 4.0740 (5.2406)	Learning Rate [0.00125]
9: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00092 (0.00094)	Tok/s 62786 (52842)	Loss/tok 4.1466 (5.2351)	Learning Rate [0.00125]
8: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00105 (0.00099)	Tok/s 62809 (52783)	Loss/tok 3.9417 (5.2432)	Learning Rate [0.00125]
6: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00106 (0.00098)	Tok/s 62747 (52617)	Loss/tok 4.2225 (5.2381)	Learning Rate [0.00125]
7: TRAIN [0][1320/3416]	Time 0.069 (0.057)	Data 0.00098 (0.00093)	Tok/s 62747 (52704)	Loss/tok 4.1205 (5.2408)	Learning Rate [0.00125]
4: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00091 (0.00093)	Tok/s 57485 (52437)	Loss/tok 3.8206 (5.2292)	Learning Rate [0.00125]
5: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00103 (0.00096)	Tok/s 57384 (52541)	Loss/tok 3.8892 (5.2383)	Learning Rate [0.00125]
3: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00095 (0.00100)	Tok/s 57485 (52332)	Loss/tok 4.0775 (5.2161)	Learning Rate [0.00125]
2: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00095 (0.00099)	Tok/s 57477 (52233)	Loss/tok 4.2140 (5.2320)	Learning Rate [0.00125]
6: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00094 (0.00098)	Tok/s 57381 (52618)	Loss/tok 4.1788 (5.2274)	Learning Rate [0.00125]
1: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00096 (0.00093)	Tok/s 57479 (52134)	Loss/tok 3.8227 (5.2299)	Learning Rate [0.00125]
8: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00104 (0.00099)	Tok/s 57376 (52783)	Loss/tok 4.0815 (5.2329)	Learning Rate [0.00125]
7: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00096 (0.00093)	Tok/s 57378 (52705)	Loss/tok 4.0303 (5.2298)	Learning Rate [0.00125]
0: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00092 (0.00092)	Tok/s 56678 (52020)	Loss/tok 4.0386 (5.2281)	Learning Rate [0.00125]
9: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00086 (0.00094)	Tok/s 57393 (52842)	Loss/tok 4.2636 (5.2250)	Learning Rate [0.00125]
15: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00086 (0.00094)	Tok/s 57459 (53433)	Loss/tok 3.8964 (5.2298)	Learning Rate [0.00125]
14: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00092 (0.00096)	Tok/s 57498 (53324)	Loss/tok 4.2192 (5.2333)	Learning Rate [0.00125]
10: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00105 (0.00100)	Tok/s 57355 (52924)	Loss/tok 3.7777 (5.2326)	Learning Rate [0.00125]
13: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00108 (0.00100)	Tok/s 57609 (53219)	Loss/tok 4.0362 (5.2350)	Learning Rate [0.00125]
11: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00105 (0.00099)	Tok/s 57407 (53005)	Loss/tok 3.8247 (5.2272)	Learning Rate [0.00125]
12: TRAIN [0][1330/3416]	Time 0.068 (0.057)	Data 0.00102 (0.00100)	Tok/s 57445 (53122)	Loss/tok 3.9319 (5.2272)	Learning Rate [0.00125]
10: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00094 (0.00100)	Tok/s 51734 (52922)	Loss/tok 3.7265 (5.2232)	Learning Rate [0.00125]
9: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00091 (0.00094)	Tok/s 51732 (52841)	Loss/tok 3.9008 (5.2153)	Learning Rate [0.00125]
8: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00102 (0.00099)	Tok/s 51635 (52783)	Loss/tok 3.7758 (5.2231)	Learning Rate [0.00125]
11: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00101 (0.00099)	Tok/s 51660 (53003)	Loss/tok 3.9562 (5.2170)	Learning Rate [0.00125]
12: TRAIN [0][1340/3416]	Time 0.050 (0.057)	Data 0.00127 (0.00100)	Tok/s 52700 (53120)	Loss/tok 3.7657 (5.2177)	Learning Rate [0.00125]
7: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00083 (0.00093)	Tok/s 51472 (52705)	Loss/tok 3.9320 (5.2203)	Learning Rate [0.00125]
6: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00095 (0.00098)	Tok/s 51513 (52619)	Loss/tok 3.8933 (5.2176)	Learning Rate [0.00125]
5: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00137 (0.00096)	Tok/s 51510 (52542)	Loss/tok 3.7705 (5.2287)	Learning Rate [0.00125]
13: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00093 (0.00100)	Tok/s 51621 (53217)	Loss/tok 3.4422 (5.2244)	Learning Rate [0.00125]
14: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00092 (0.00096)	Tok/s 51613 (53322)	Loss/tok 3.9292 (5.2234)	Learning Rate [0.00125]
4: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00091 (0.00093)	Tok/s 51474 (52438)	Loss/tok 3.6196 (5.2193)	Learning Rate [0.00125]
15: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00093 (0.00094)	Tok/s 51579 (53430)	Loss/tok 3.8889 (5.2197)	Learning Rate [0.00125]
2: TRAIN [0][1340/3416]	Time 0.050 (0.057)	Data 0.00116 (0.00099)	Tok/s 52576 (52236)	Loss/tok 3.7254 (5.2221)	Learning Rate [0.00125]
1: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00099 (0.00093)	Tok/s 51500 (52137)	Loss/tok 3.8805 (5.2201)	Learning Rate [0.00125]
0: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00095 (0.00092)	Tok/s 51511 (52022)	Loss/tok 3.8908 (5.2182)	Learning Rate [0.00125]
3: TRAIN [0][1340/3416]	Time 0.051 (0.057)	Data 0.00092 (0.00100)	Tok/s 51295 (52334)	Loss/tok 3.6136 (5.2063)	Learning Rate [0.00125]
5: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00104 (0.00096)	Tok/s 31530 (52542)	Loss/tok 3.1386 (5.2184)	Learning Rate [0.00125]
6: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00086 (0.00098)	Tok/s 31451 (52619)	Loss/tok 3.2350 (5.2076)	Learning Rate [0.00125]
7: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00089 (0.00092)	Tok/s 31513 (52704)	Loss/tok 3.0970 (5.2102)	Learning Rate [0.00125]
4: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00093 (0.00093)	Tok/s 31495 (52440)	Loss/tok 3.2782 (5.2097)	Learning Rate [0.00125]
8: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00107 (0.00099)	Tok/s 31444 (52781)	Loss/tok 3.4524 (5.2138)	Learning Rate [0.00125]
10: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00090 (0.00100)	Tok/s 31265 (52922)	Loss/tok 3.4573 (5.2134)	Learning Rate [0.00125]
3: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00095 (0.00100)	Tok/s 31384 (52336)	Loss/tok 3.2783 (5.1964)	Learning Rate [0.00125]
2: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00101 (0.00099)	Tok/s 31410 (52239)	Loss/tok 3.1080 (5.2119)	Learning Rate [0.00125]
9: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00090 (0.00094)	Tok/s 31361 (52840)	Loss/tok 3.1561 (5.2055)	Learning Rate [0.00125]
1: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00097 (0.00093)	Tok/s 31332 (52139)	Loss/tok 3.3266 (5.2101)	Learning Rate [0.00125]
11: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00101 (0.00100)	Tok/s 31891 (53004)	Loss/tok 3.2477 (5.2067)	Learning Rate [0.00125]
0: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00086 (0.00092)	Tok/s 31256 (52025)	Loss/tok 3.3325 (5.2081)	Learning Rate [0.00125]
12: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00096 (0.00100)	Tok/s 32515 (53121)	Loss/tok 3.5411 (5.2075)	Learning Rate [0.00125]
13: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00094 (0.00100)	Tok/s 32448 (53218)	Loss/tok 3.1988 (5.2142)	Learning Rate [0.00125]
14: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00093 (0.00096)	Tok/s 32462 (53323)	Loss/tok 3.4144 (5.2139)	Learning Rate [0.00125]
15: TRAIN [0][1350/3416]	Time 0.047 (0.057)	Data 0.00092 (0.00094)	Tok/s 32518 (53431)	Loss/tok 3.0863 (5.2091)	Learning Rate [0.00125]
5: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00104 (0.00097)	Tok/s 58576 (52530)	Loss/tok 4.4109 (5.2091)	Learning Rate [0.00125]
4: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00086 (0.00093)	Tok/s 58566 (52428)	Loss/tok 3.8589 (5.1996)	Learning Rate [0.00125]
2: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00095 (0.00099)	Tok/s 58433 (52227)	Loss/tok 3.9356 (5.2021)	Learning Rate [0.00125]
7: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00088 (0.00092)	Tok/s 58651 (52691)	Loss/tok 3.8297 (5.2002)	Learning Rate [0.00125]
3: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00085 (0.00100)	Tok/s 58366 (52324)	Loss/tok 4.1467 (5.1863)	Learning Rate [0.00125]
6: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00091 (0.00098)	Tok/s 58572 (52606)	Loss/tok 4.2206 (5.1980)	Learning Rate [0.00125]
1: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00099 (0.00093)	Tok/s 58375 (52128)	Loss/tok 3.9428 (5.2001)	Learning Rate [0.00125]
9: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00086 (0.00094)	Tok/s 58657 (52826)	Loss/tok 4.1896 (5.1959)	Learning Rate [0.00125]
8: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00120 (0.00099)	Tok/s 58631 (52768)	Loss/tok 4.2533 (5.2040)	Learning Rate [0.00125]
0: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00083 (0.00092)	Tok/s 58378 (52014)	Loss/tok 4.1375 (5.1983)	Learning Rate [0.00125]
15: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00084 (0.00094)	Tok/s 59281 (53416)	Loss/tok 4.0454 (5.1994)	Learning Rate [0.00125]
12: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00096 (0.00100)	Tok/s 59341 (53108)	Loss/tok 4.1307 (5.1978)	Learning Rate [0.00125]
11: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00110 (0.00100)	Tok/s 58727 (52991)	Loss/tok 4.0659 (5.1969)	Learning Rate [0.00125]
10: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00092 (0.00100)	Tok/s 58515 (52908)	Loss/tok 4.0426 (5.2035)	Learning Rate [0.00125]
14: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00082 (0.00096)	Tok/s 59282 (53309)	Loss/tok 4.1441 (5.2041)	Learning Rate [0.00125]
13: TRAIN [0][1360/3416]	Time 0.069 (0.057)	Data 0.00093 (0.00100)	Tok/s 59237 (53205)	Loss/tok 3.8892 (5.2040)	Learning Rate [0.00125]
6: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00116 (0.00098)	Tok/s 27263 (52592)	Loss/tok 2.9076 (5.1885)	Learning Rate [0.00125]
5: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00112 (0.00097)	Tok/s 27191 (52516)	Loss/tok 2.8325 (5.1996)	Learning Rate [0.00125]
8: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00102 (0.00099)	Tok/s 28939 (52755)	Loss/tok 2.8758 (5.1943)	Learning Rate [0.00125]
7: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00101 (0.00092)	Tok/s 28357 (52678)	Loss/tok 2.8576 (5.1910)	Learning Rate [0.00125]
4: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00112 (0.00093)	Tok/s 27098 (52414)	Loss/tok 2.8880 (5.1898)	Learning Rate [0.00125]
10: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00118 (0.00100)	Tok/s 28978 (52895)	Loss/tok 2.8940 (5.1936)	Learning Rate [0.00125]
3: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00098 (0.00099)	Tok/s 26686 (52311)	Loss/tok 2.9044 (5.1769)	Learning Rate [0.00125]
9: TRAIN [0][1370/3416]	Time 0.038 (0.057)	Data 0.00097 (0.00094)	Tok/s 28960 (52813)	Loss/tok 2.8441 (5.1868)	Learning Rate [0.00125]
2: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00106 (0.00099)	Tok/s 25331 (52214)	Loss/tok 2.5441 (5.1918)	Learning Rate [0.00125]
1: TRAIN [0][1370/3416]	Time 0.038 (0.057)	Data 0.00116 (0.00093)	Tok/s 25308 (52114)	Loss/tok 2.5187 (5.1904)	Learning Rate [0.00125]
11: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00109 (0.00100)	Tok/s 28878 (52977)	Loss/tok 2.7287 (5.1870)	Learning Rate [0.00125]
12: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00111 (0.00100)	Tok/s 28813 (53094)	Loss/tok 2.8215 (5.1880)	Learning Rate [0.00125]
13: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00098 (0.00100)	Tok/s 29143 (53191)	Loss/tok 2.9541 (5.1946)	Learning Rate [0.00125]
14: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00104 (0.00096)	Tok/s 30405 (53297)	Loss/tok 2.9801 (5.1941)	Learning Rate [0.00125]
0: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00093 (0.00092)	Tok/s 25300 (52001)	Loss/tok 2.4720 (5.1883)	Learning Rate [0.00125]
15: TRAIN [0][1370/3416]	Time 0.038 (0.058)	Data 0.00098 (0.00094)	Tok/s 30354 (53403)	Loss/tok 2.8651 (5.1900)	Learning Rate [0.00125]
2: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00100 (0.00099)	Tok/s 48992 (52195)	Loss/tok 3.7616 (5.1828)	Learning Rate [0.00125]
10: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00095 (0.00100)	Tok/s 50599 (52876)	Loss/tok 3.5809 (5.1850)	Learning Rate [0.00125]
3: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00095 (0.00099)	Tok/s 48911 (52292)	Loss/tok 3.6254 (5.1685)	Learning Rate [0.00125]
1: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00102 (0.00093)	Tok/s 49002 (52096)	Loss/tok 3.5988 (5.1816)	Learning Rate [0.00125]
4: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00098 (0.00093)	Tok/s 48821 (52394)	Loss/tok 3.9161 (5.1809)	Learning Rate [0.00125]
11: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00101 (0.00100)	Tok/s 50602 (52958)	Loss/tok 3.5464 (5.1780)	Learning Rate [0.00125]
0: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00082 (0.00092)	Tok/s 49010 (51984)	Loss/tok 3.6207 (5.1792)	Learning Rate [0.00125]
9: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00087 (0.00094)	Tok/s 50509 (52795)	Loss/tok 3.6832 (5.1776)	Learning Rate [0.00125]
5: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00100 (0.00097)	Tok/s 48812 (52495)	Loss/tok 3.7885 (5.1906)	Learning Rate [0.00125]
15: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00084 (0.00094)	Tok/s 50425 (53382)	Loss/tok 3.6381 (5.1809)	Learning Rate [0.00125]
12: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00106 (0.00100)	Tok/s 50548 (53074)	Loss/tok 3.8636 (5.1791)	Learning Rate [0.00125]
14: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00086 (0.00096)	Tok/s 50425 (53276)	Loss/tok 3.8023 (5.1849)	Learning Rate [0.00125]
6: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00089 (0.00098)	Tok/s 49673 (52572)	Loss/tok 3.8271 (5.1800)	Learning Rate [0.00125]
8: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00091 (0.00099)	Tok/s 50376 (52736)	Loss/tok 3.8985 (5.1848)	Learning Rate [0.00125]
13: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00095 (0.00100)	Tok/s 50418 (53170)	Loss/tok 3.8086 (5.1855)	Learning Rate [0.00125]
7: TRAIN [0][1380/3416]	Time 0.046 (0.057)	Data 0.00082 (0.00092)	Tok/s 50278 (52660)	Loss/tok 3.5570 (5.1823)	Learning Rate [0.00125]
15: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00094 (0.00094)	Tok/s 89279 (53398)	Loss/tok 3.6240 (5.1706)	Learning Rate [0.00125]
14: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00094 (0.00096)	Tok/s 88723 (53292)	Loss/tok 3.6385 (5.1745)	Learning Rate [0.00125]
13: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00112 (0.00100)	Tok/s 87853 (53186)	Loss/tok 3.8028 (5.1759)	Learning Rate [0.00125]
0: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00091 (0.00092)	Tok/s 83857 (52000)	Loss/tok 3.6538 (5.1691)	Learning Rate [0.00125]
12: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00104 (0.00100)	Tok/s 87380 (53089)	Loss/tok 3.8864 (5.1692)	Learning Rate [0.00125]
11: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00103 (0.00100)	Tok/s 86693 (52973)	Loss/tok 3.8927 (5.1685)	Learning Rate [0.00125]
10: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00098 (0.00100)	Tok/s 86451 (52892)	Loss/tok 3.5883 (5.1749)	Learning Rate [0.00125]
1: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00111 (0.00093)	Tok/s 83837 (52111)	Loss/tok 3.8487 (5.1725)	Learning Rate [0.00125]
2: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00113 (0.00099)	Tok/s 83704 (52210)	Loss/tok 3.7355 (5.1727)	Learning Rate [0.00125]
8: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00100 (0.00099)	Tok/s 85459 (52752)	Loss/tok 3.6053 (5.1744)	Learning Rate [0.00125]
4: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00105 (0.00093)	Tok/s 84367 (52409)	Loss/tok 3.7339 (5.1712)	Learning Rate [0.00125]
3: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00108 (0.00099)	Tok/s 83639 (52307)	Loss/tok 3.8028 (5.1582)	Learning Rate [0.00125]
9: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00091 (0.00094)	Tok/s 85469 (52810)	Loss/tok 3.8573 (5.1671)	Learning Rate [0.00125]
5: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00090 (0.00097)	Tok/s 84314 (52510)	Loss/tok 3.6804 (5.1813)	Learning Rate [0.00125]
7: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00089 (0.00092)	Tok/s 84922 (52675)	Loss/tok 3.7714 (5.1722)	Learning Rate [0.00125]
6: TRAIN [0][1390/3416]	Time 0.071 (0.057)	Data 0.00095 (0.00098)	Tok/s 84370 (52588)	Loss/tok 3.7943 (5.1710)	Learning Rate [0.00125]
10: TRAIN [0][1400/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00100)	Tok/s 35867 (52930)	Loss/tok 3.8592 (5.1638)	Learning Rate [0.00125]
12: TRAIN [0][1400/3416]	Time 0.052 (0.058)	Data 0.00106 (0.00100)	Tok/s 35755 (53127)	Loss/tok 3.5488 (5.1588)	Learning Rate [0.00125]
9: TRAIN [0][1400/3416]	Time 0.052 (0.057)	Data 0.00085 (0.00094)	Tok/s 35686 (52849)	Loss/tok 3.4829 (5.1564)	Learning Rate [0.00125]
11: TRAIN [0][1400/3416]	Time 0.052 (0.058)	Data 0.00133 (0.00100)	Tok/s 35883 (53010)	Loss/tok 3.5769 (5.1578)	Learning Rate [0.00125]
13: TRAIN [0][1400/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00100)	Tok/s 35664 (53222)	Loss/tok 3.5241 (5.1650)	Learning Rate [0.00125]
14: TRAIN [0][1400/3416]	Time 0.052 (0.058)	Data 0.00081 (0.00095)	Tok/s 35541 (53328)	Loss/tok 3.4370 (5.1628)	Learning Rate [0.00125]
8: TRAIN [0][1400/3416]	Time 0.052 (0.058)	Data 0.00106 (0.00099)	Tok/s 35679 (52790)	Loss/tok 3.5606 (5.1635)	Learning Rate [0.00125]
15: TRAIN [0][1400/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00094)	Tok/s 35520 (53433)	Loss/tok 3.5982 (5.1603)	Learning Rate [0.00125]
7: TRAIN [0][1400/3416]	Time 0.052 (0.058)	Data 0.00081 (0.00092)	Tok/s 35549 (52713)	Loss/tok 3.4802 (5.1613)	Learning Rate [0.00125]
0: TRAIN [0][1400/3416]	Time 0.052 (0.058)	Data 0.00079 (0.00092)	Tok/s 34151 (52037)	Loss/tok 3.3430 (5.1584)	Learning Rate [0.00125]
6: TRAIN [0][1400/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00098)	Tok/s 35456 (52626)	Loss/tok 3.3162 (5.1596)	Learning Rate [0.00125]
4: TRAIN [0][1400/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00093)	Tok/s 35294 (52447)	Loss/tok 3.3309 (5.1605)	Learning Rate [0.00125]
1: TRAIN [0][1400/3416]	Time 0.053 (0.057)	Data 0.00099 (0.00093)	Tok/s 34127 (52149)	Loss/tok 3.5332 (5.1613)	Learning Rate [0.00125]
5: TRAIN [0][1400/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00097)	Tok/s 35359 (52549)	Loss/tok 3.7024 (5.1702)	Learning Rate [0.00125]
3: TRAIN [0][1400/3416]	Time 0.053 (0.058)	Data 0.00107 (0.00099)	Tok/s 35251 (52346)	Loss/tok 3.6886 (5.1471)	Learning Rate [0.00125]
2: TRAIN [0][1400/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00099)	Tok/s 34670 (52248)	Loss/tok 3.5883 (5.1618)	Learning Rate [0.00125]
0: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00107 (0.00092)	Tok/s 70835 (52023)	Loss/tok 3.9217 (5.1495)	Learning Rate [0.00125]
1: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00095 (0.00093)	Tok/s 70726 (52137)	Loss/tok 3.8744 (5.1525)	Learning Rate [0.00125]
3: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00101 (0.00099)	Tok/s 70590 (52335)	Loss/tok 4.0260 (5.1386)	Learning Rate [0.00125]
4: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00098 (0.00093)	Tok/s 70935 (52437)	Loss/tok 3.8917 (5.1516)	Learning Rate [0.00125]
15: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00086 (0.00094)	Tok/s 72008 (53429)	Loss/tok 4.1287 (5.1512)	Learning Rate [0.00125]
5: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00100 (0.00097)	Tok/s 71485 (52540)	Loss/tok 3.9209 (5.1614)	Learning Rate [0.00125]
14: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00086 (0.00095)	Tok/s 71583 (53323)	Loss/tok 3.7968 (5.1536)	Learning Rate [0.00125]
12: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00102 (0.00100)	Tok/s 71609 (53120)	Loss/tok 3.9444 (5.1501)	Learning Rate [0.00125]
6: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00100 (0.00098)	Tok/s 71458 (52618)	Loss/tok 3.8769 (5.1502)	Learning Rate [0.00125]
7: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00094 (0.00092)	Tok/s 71509 (52706)	Loss/tok 3.9384 (5.1525)	Learning Rate [0.00125]
2: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00094 (0.00099)	Tok/s 70403 (52237)	Loss/tok 3.8821 (5.1527)	Learning Rate [0.00125]
8: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00100 (0.00099)	Tok/s 71561 (52784)	Loss/tok 4.0280 (5.1541)	Learning Rate [0.00125]
9: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00093 (0.00094)	Tok/s 71507 (52843)	Loss/tok 3.9079 (5.1478)	Learning Rate [0.00125]
10: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00106 (0.00100)	Tok/s 71548 (52923)	Loss/tok 4.1585 (5.1548)	Learning Rate [0.00125]
11: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00109 (0.00100)	Tok/s 71550 (53003)	Loss/tok 3.8512 (5.1483)	Learning Rate [0.00125]
13: TRAIN [0][1410/3416]	Time 0.070 (0.057)	Data 0.00155 (0.00100)	Tok/s 71705 (53218)	Loss/tok 4.1699 (5.1560)	Learning Rate [0.00125]
8: TRAIN [0][1420/3416]	Time 0.069 (0.058)	Data 0.00117 (0.00099)	Tok/s 62632 (52846)	Loss/tok 4.0354 (5.1437)	Learning Rate [0.00125]
9: TRAIN [0][1420/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00094)	Tok/s 62602 (52905)	Loss/tok 3.8928 (5.1364)	Learning Rate [0.00125]
7: TRAIN [0][1420/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 62656 (52769)	Loss/tok 3.9144 (5.1410)	Learning Rate [0.00125]
10: TRAIN [0][1420/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00100)	Tok/s 62477 (52985)	Loss/tok 4.1618 (5.1433)	Learning Rate [0.00125]
6: TRAIN [0][1420/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 62599 (52681)	Loss/tok 3.7526 (5.1386)	Learning Rate [0.00125]
5: TRAIN [0][1420/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 62578 (52604)	Loss/tok 4.0089 (5.1499)	Learning Rate [0.00125]
11: TRAIN [0][1420/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00100)	Tok/s 62404 (53065)	Loss/tok 3.9158 (5.1373)	Learning Rate [0.00125]
4: TRAIN [0][1420/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 62550 (52500)	Loss/tok 3.9772 (5.1408)	Learning Rate [0.00125]
12: TRAIN [0][1420/3416]	Time 0.069 (0.058)	Data 0.00132 (0.00100)	Tok/s 63128 (53181)	Loss/tok 3.7351 (5.1384)	Learning Rate [0.00125]
2: TRAIN [0][1420/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00099)	Tok/s 62553 (52299)	Loss/tok 4.0166 (5.1412)	Learning Rate [0.00125]
3: TRAIN [0][1420/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00100)	Tok/s 62561 (52399)	Loss/tok 3.9710 (5.1267)	Learning Rate [0.00125]
13: TRAIN [0][1420/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00100)	Tok/s 62396 (53278)	Loss/tok 3.9960 (5.1449)	Learning Rate [0.00125]
14: TRAIN [0][1420/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00095)	Tok/s 62421 (53383)	Loss/tok 4.1000 (5.1421)	Learning Rate [0.00125]
1: TRAIN [0][1420/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 62493 (52199)	Loss/tok 3.7228 (5.1403)	Learning Rate [0.00125]
15: TRAIN [0][1420/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00094)	Tok/s 63225 (53489)	Loss/tok 4.0022 (5.1408)	Learning Rate [0.00125]
0: TRAIN [0][1420/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 62441 (52086)	Loss/tok 3.9482 (5.1385)	Learning Rate [0.00125]
11: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00100)	Tok/s 32299 (53099)	Loss/tok 3.2736 (5.1273)	Learning Rate [0.00125]
15: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00094)	Tok/s 33553 (53522)	Loss/tok 3.4565 (5.1305)	Learning Rate [0.00125]
12: TRAIN [0][1430/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00100)	Tok/s 33193 (53215)	Loss/tok 3.3908 (5.1281)	Learning Rate [0.00125]
0: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00092)	Tok/s 32215 (52121)	Loss/tok 3.5189 (5.1283)	Learning Rate [0.00125]
14: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00095)	Tok/s 33475 (53417)	Loss/tok 3.3817 (5.1313)	Learning Rate [0.00125]
13: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00100)	Tok/s 33550 (53313)	Loss/tok 3.2845 (5.1348)	Learning Rate [0.00125]
10: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00100)	Tok/s 32240 (53018)	Loss/tok 3.1562 (5.1337)	Learning Rate [0.00125]
9: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00094)	Tok/s 32275 (52937)	Loss/tok 3.0724 (5.1264)	Learning Rate [0.00125]
1: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00093)	Tok/s 32210 (52235)	Loss/tok 3.7133 (5.1294)	Learning Rate [0.00125]
8: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00110 (0.00099)	Tok/s 32294 (52879)	Loss/tok 3.3137 (5.1335)	Learning Rate [0.00125]
2: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00099)	Tok/s 32228 (52335)	Loss/tok 3.3019 (5.1309)	Learning Rate [0.00125]
6: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00098)	Tok/s 32327 (52715)	Loss/tok 2.8557 (5.1287)	Learning Rate [0.00125]
5: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00097)	Tok/s 32254 (52637)	Loss/tok 3.4270 (5.1397)	Learning Rate [0.00125]
3: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00111 (0.00100)	Tok/s 32230 (52434)	Loss/tok 3.2207 (5.1162)	Learning Rate [0.00125]
4: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00093)	Tok/s 32233 (52535)	Loss/tok 3.4011 (5.1308)	Learning Rate [0.00125]
7: TRAIN [0][1430/3416]	Time 0.048 (0.058)	Data 0.00107 (0.00092)	Tok/s 32258 (52801)	Loss/tok 3.3464 (5.1309)	Learning Rate [0.00125]
8: TRAIN [0][1440/3416]	Time 0.048 (0.058)	Data 0.00114 (0.00099)	Tok/s 42380 (52829)	Loss/tok 3.5132 (5.1255)	Learning Rate [0.00125]
9: TRAIN [0][1440/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00094)	Tok/s 42421 (52889)	Loss/tok 3.4853 (5.1184)	Learning Rate [0.00125]
10: TRAIN [0][1440/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00100)	Tok/s 42422 (52969)	Loss/tok 3.4223 (5.1256)	Learning Rate [0.00125]
6: TRAIN [0][1440/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00098)	Tok/s 42188 (52666)	Loss/tok 3.4503 (5.1202)	Learning Rate [0.00125]
5: TRAIN [0][1440/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00097)	Tok/s 42177 (52589)	Loss/tok 3.6662 (5.1319)	Learning Rate [0.00125]
11: TRAIN [0][1440/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00100)	Tok/s 42421 (53049)	Loss/tok 3.7875 (5.1195)	Learning Rate [0.00125]
12: TRAIN [0][1440/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00100)	Tok/s 42429 (53164)	Loss/tok 3.6722 (5.1202)	Learning Rate [0.00125]
4: TRAIN [0][1440/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00093)	Tok/s 42220 (52486)	Loss/tok 3.6392 (5.1233)	Learning Rate [0.00125]
13: TRAIN [0][1440/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00100)	Tok/s 42393 (53262)	Loss/tok 3.6298 (5.1272)	Learning Rate [0.00125]
2: TRAIN [0][1440/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00099)	Tok/s 42126 (52286)	Loss/tok 3.4078 (5.1224)	Learning Rate [0.00125]
14: TRAIN [0][1440/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00095)	Tok/s 42352 (53366)	Loss/tok 3.6640 (5.1236)	Learning Rate [0.00125]
1: TRAIN [0][1440/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00093)	Tok/s 42175 (52186)	Loss/tok 3.4389 (5.1216)	Learning Rate [0.00125]
15: TRAIN [0][1440/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00094)	Tok/s 42287 (53470)	Loss/tok 3.8964 (5.1228)	Learning Rate [0.00125]
3: TRAIN [0][1440/3416]	Time 0.049 (0.058)	Data 0.00115 (0.00100)	Tok/s 42154 (52385)	Loss/tok 3.6888 (5.1086)	Learning Rate [0.00125]
0: TRAIN [0][1440/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00092)	Tok/s 42265 (52071)	Loss/tok 3.6803 (5.1201)	Learning Rate [0.00125]
7: TRAIN [0][1440/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00092)	Tok/s 42142 (52752)	Loss/tok 3.5536 (5.1225)	Learning Rate [0.00125]
9: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
9: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00094)	Tok/s 75902 (52883)	Loss/tok 3.9049 (5.1096)	Learning Rate [0.00125]
5: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 74706 (52583)	Loss/tok 4.0586 (5.1232)	Learning Rate [0.00125]
10: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00100)	Tok/s 75855 (52962)	Loss/tok 3.7982 (5.1170)	Learning Rate [0.00125]
11: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00100)	Tok/s 75923 (53043)	Loss/tok 3.7635 (5.1106)	Learning Rate [0.00125]
8: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00099)	Tok/s 74878 (52823)	Loss/tok 3.8553 (5.1169)	Learning Rate [0.00125]
12: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00100)	Tok/s 75921 (53159)	Loss/tok 4.0141 (5.1117)	Learning Rate [0.00125]
6: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00098)	Tok/s 74586 (52659)	Loss/tok 3.9720 (5.1116)	Learning Rate [0.00125]
13: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00100)	Tok/s 75903 (53256)	Loss/tok 3.9560 (5.1187)	Learning Rate [0.00125]
0: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 74838 (52067)	Loss/tok 3.9680 (5.1118)	Learning Rate [0.00125]
4: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 74599 (52480)	Loss/tok 3.8381 (5.1144)	Learning Rate [0.00125]
14: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00095)	Tok/s 75841 (53360)	Loss/tok 3.8412 (5.1143)	Learning Rate [0.00125]
1: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 74773 (52181)	Loss/tok 3.9896 (5.1130)	Learning Rate [0.00125]
2: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00099)	Tok/s 74654 (52280)	Loss/tok 3.8262 (5.1138)	Learning Rate [0.00125]
15: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00094)	Tok/s 75872 (53463)	Loss/tok 4.0403 (5.1146)	Learning Rate [0.00125]
3: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00100)	Tok/s 74622 (52379)	Loss/tok 3.8054 (5.0996)	Learning Rate [0.00125]
7: TRAIN [0][1450/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 74817 (52745)	Loss/tok 3.7670 (5.1135)	Learning Rate [0.00125]
2: TRAIN [0][1460/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00099)	Tok/s 31154 (52240)	Loss/tok 3.4010 (5.1059)	Learning Rate [0.00125]
11: TRAIN [0][1460/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00100)	Tok/s 31109 (53001)	Loss/tok 3.0570 (5.1028)	Learning Rate [0.00125]
3: TRAIN [0][1460/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00100)	Tok/s 31122 (52339)	Loss/tok 3.2569 (5.0920)	Learning Rate [0.00125]
10: TRAIN [0][1460/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00100)	Tok/s 31050 (52921)	Loss/tok 3.0115 (5.1091)	Learning Rate [0.00125]
4: TRAIN [0][1460/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00093)	Tok/s 31055 (52439)	Loss/tok 3.0700 (5.1066)	Learning Rate [0.00125]
5: TRAIN [0][1460/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00097)	Tok/s 30991 (52541)	Loss/tok 3.2165 (5.1153)	Learning Rate [0.00125]
8: TRAIN [0][1460/3416]	Time 0.045 (0.058)	Data 0.00107 (0.00099)	Tok/s 30958 (52782)	Loss/tok 3.2009 (5.1094)	Learning Rate [0.00125]
9: TRAIN [0][1460/3416]	Time 0.045 (0.057)	Data 0.00087 (0.00094)	Tok/s 31002 (52842)	Loss/tok 3.0197 (5.1019)	Learning Rate [0.00125]
0: TRAIN [0][1460/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00092)	Tok/s 29772 (52027)	Loss/tok 3.2566 (5.1039)	Learning Rate [0.00125]
1: TRAIN [0][1460/3416]	Time 0.045 (0.057)	Data 0.00101 (0.00093)	Tok/s 29758 (52141)	Loss/tok 3.0932 (5.1050)	Learning Rate [0.00125]
14: TRAIN [0][1460/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00095)	Tok/s 31339 (53318)	Loss/tok 3.2287 (5.1065)	Learning Rate [0.00125]
12: TRAIN [0][1460/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00100)	Tok/s 31072 (53116)	Loss/tok 3.2045 (5.1041)	Learning Rate [0.00125]
6: TRAIN [0][1460/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00098)	Tok/s 30936 (52617)	Loss/tok 3.1493 (5.1038)	Learning Rate [0.00125]
7: TRAIN [0][1460/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00092)	Tok/s 31151 (52704)	Loss/tok 3.2032 (5.1061)	Learning Rate [0.00125]
13: TRAIN [0][1460/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00100)	Tok/s 31064 (53214)	Loss/tok 3.2419 (5.1111)	Learning Rate [0.00125]
15: TRAIN [0][1460/3416]	Time 0.045 (0.058)	Data 0.00100 (0.00094)	Tok/s 32507 (53423)	Loss/tok 3.2373 (5.1071)	Learning Rate [0.00125]
2: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
2: Skipped batch, new scale: 512.0
1: Skipped batch, new scale: 512.0
3: Skipped batch, new scale: 512.0
4: Gradient norm: inf
0: Gradient norm: inf
15: Gradient norm: inf
4: Skipped batch, new scale: 512.0
5: Gradient norm: inf
15: Skipped batch, new scale: 512.0
0: Skipped batch, new scale: 512.0
14: Gradient norm: inf
5: Skipped batch, new scale: 512.0
6: Gradient norm: inf
14: Skipped batch, new scale: 512.0
13: Gradient norm: inf
6: Skipped batch, new scale: 512.0
7: Gradient norm: inf
12: Gradient norm: inf
13: Skipped batch, new scale: 512.0
8: Gradient norm: inf
7: Skipped batch, new scale: 512.0
11: Gradient norm: inf
12: Skipped batch, new scale: 512.0
10: Gradient norm: inf
9: Gradient norm: inf
8: Skipped batch, new scale: 512.0
11: Skipped batch, new scale: 512.0
9: Skipped batch, new scale: 512.0
10: Skipped batch, new scale: 512.0
7: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00092)	Tok/s 55321 (52735)	Loss/tok 4.0065 (5.0964)	Learning Rate [0.00125]
9: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00094)	Tok/s 55475 (52872)	Loss/tok 3.7092 (5.0918)	Learning Rate [0.00125]
10: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00100)	Tok/s 55419 (52952)	Loss/tok 3.8893 (5.0996)	Learning Rate [0.00125]
12: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00100)	Tok/s 55474 (53145)	Loss/tok 3.8894 (5.0942)	Learning Rate [0.00125]
11: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00100)	Tok/s 55449 (53031)	Loss/tok 3.9303 (5.0935)	Learning Rate [0.00125]
6: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00098)	Tok/s 55182 (52648)	Loss/tok 3.8340 (5.0945)	Learning Rate [0.00125]
5: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00097)	Tok/s 55169 (52571)	Loss/tok 3.8549 (5.1053)	Learning Rate [0.00125]
13: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00100)	Tok/s 55475 (53243)	Loss/tok 3.7618 (5.1012)	Learning Rate [0.00125]
4: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00093)	Tok/s 55174 (52469)	Loss/tok 3.6942 (5.0966)	Learning Rate [0.00125]
14: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00104 (0.00095)	Tok/s 55489 (53347)	Loss/tok 3.6460 (5.0967)	Learning Rate [0.00125]
15: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00094)	Tok/s 55346 (53452)	Loss/tok 3.7422 (5.0975)	Learning Rate [0.00125]
3: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00100)	Tok/s 55186 (52370)	Loss/tok 3.8581 (5.0827)	Learning Rate [0.00125]
1: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00093)	Tok/s 54925 (52171)	Loss/tok 3.8634 (5.0956)	Learning Rate [0.00125]
0: TRAIN [0][1470/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00092)	Tok/s 54116 (52058)	Loss/tok 3.6938 (5.0940)	Learning Rate [0.00125]
8: TRAIN [0][1470/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00099)	Tok/s 54736 (52812)	Loss/tok 3.7616 (5.0992)	Learning Rate [0.00125]
2: TRAIN [0][1470/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00099)	Tok/s 54516 (52270)	Loss/tok 3.6088 (5.0961)	Learning Rate [0.00125]
13: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00100)	Tok/s 88403 (53296)	Loss/tok 3.5983 (5.0902)	Learning Rate [0.00125]
12: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 88206 (53200)	Loss/tok 3.6332 (5.0832)	Learning Rate [0.00125]
15: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 89550 (53506)	Loss/tok 3.6878 (5.0865)	Learning Rate [0.00125]
5: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 85671 (52624)	Loss/tok 3.6634 (5.0943)	Learning Rate [0.00125]
11: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 87359 (53085)	Loss/tok 3.5863 (5.0829)	Learning Rate [0.00125]
10: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 87465 (53006)	Loss/tok 3.8310 (5.0890)	Learning Rate [0.00125]
0: TRAIN [0][1480/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00092)	Tok/s 84418 (52112)	Loss/tok 3.8796 (5.0834)	Learning Rate [0.00125]
4: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 85503 (52523)	Loss/tok 3.6873 (5.0865)	Learning Rate [0.00125]
1: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 84459 (52225)	Loss/tok 3.6492 (5.0843)	Learning Rate [0.00125]
2: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00099)	Tok/s 84608 (52325)	Loss/tok 3.6516 (5.0863)	Learning Rate [0.00125]
7: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 86473 (52789)	Loss/tok 3.7045 (5.0858)	Learning Rate [0.00125]
9: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00094)	Tok/s 86761 (52926)	Loss/tok 3.4057 (5.0802)	Learning Rate [0.00125]
6: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 86027 (52702)	Loss/tok 3.6915 (5.0838)	Learning Rate [0.00125]
14: TRAIN [0][1480/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00095)	Tok/s 88784 (53401)	Loss/tok 3.8647 (5.0860)	Learning Rate [0.00125]
8: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00099)	Tok/s 86491 (52866)	Loss/tok 3.4261 (5.0879)	Learning Rate [0.00125]
3: TRAIN [0][1480/3416]	Time 0.070 (0.058)	Data 0.00117 (0.00100)	Tok/s 85441 (52423)	Loss/tok 3.8140 (5.0728)	Learning Rate [0.00125]
15: TRAIN [0][1490/3416]	Time 0.046 (0.058)	Data 0.00076 (0.00093)	Tok/s 51185 (53506)	Loss/tok 3.9053 (5.0782)	Learning Rate [0.00125]
14: TRAIN [0][1490/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00095)	Tok/s 51163 (53401)	Loss/tok 3.3860 (5.0778)	Learning Rate [0.00125]
0: TRAIN [0][1490/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00092)	Tok/s 49680 (52115)	Loss/tok 3.6011 (5.0746)	Learning Rate [0.00125]
1: TRAIN [0][1490/3416]	Time 0.046 (0.058)	Data 0.00079 (0.00093)	Tok/s 49553 (52227)	Loss/tok 3.5385 (5.0755)	Learning Rate [0.00125]
12: TRAIN [0][1490/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00100)	Tok/s 51139 (53199)	Loss/tok 3.8848 (5.0751)	Learning Rate [0.00125]
13: TRAIN [0][1490/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00100)	Tok/s 51176 (53296)	Loss/tok 3.7370 (5.0816)	Learning Rate [0.00125]
11: TRAIN [0][1490/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00100)	Tok/s 51126 (53085)	Loss/tok 3.6900 (5.0743)	Learning Rate [0.00125]
2: TRAIN [0][1490/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00099)	Tok/s 49410 (52326)	Loss/tok 3.3232 (5.0777)	Learning Rate [0.00125]
10: TRAIN [0][1490/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00100)	Tok/s 51060 (53006)	Loss/tok 3.3997 (5.0806)	Learning Rate [0.00125]
3: TRAIN [0][1490/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00100)	Tok/s 49258 (52425)	Loss/tok 3.8130 (5.0643)	Learning Rate [0.00125]
4: TRAIN [0][1490/3416]	Time 0.047 (0.058)	Data 0.00077 (0.00093)	Tok/s 49172 (52523)	Loss/tok 3.8385 (5.0785)	Learning Rate [0.00125]
9: TRAIN [0][1490/3416]	Time 0.047 (0.058)	Data 0.00083 (0.00094)	Tok/s 50882 (52926)	Loss/tok 3.3006 (5.0722)	Learning Rate [0.00125]
5: TRAIN [0][1490/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00096)	Tok/s 49160 (52624)	Loss/tok 3.5409 (5.0860)	Learning Rate [0.00125]
8: TRAIN [0][1490/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00099)	Tok/s 50607 (52866)	Loss/tok 3.5252 (5.0793)	Learning Rate [0.00125]
6: TRAIN [0][1490/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00098)	Tok/s 49626 (52701)	Loss/tok 3.5329 (5.0753)	Learning Rate [0.00125]
7: TRAIN [0][1490/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00092)	Tok/s 49214 (52787)	Loss/tok 3.7574 (5.0775)	Learning Rate [0.00125]
13: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00100)	Tok/s 88558 (53361)	Loss/tok 3.6699 (5.0705)	Learning Rate [0.00125]
12: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00100)	Tok/s 88275 (53264)	Loss/tok 3.5271 (5.0635)	Learning Rate [0.00125]
14: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00095)	Tok/s 89126 (53465)	Loss/tok 3.6846 (5.0661)	Learning Rate [0.00125]
15: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 89893 (53571)	Loss/tok 3.6064 (5.0663)	Learning Rate [0.00125]
0: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 84836 (52178)	Loss/tok 3.5606 (5.0637)	Learning Rate [0.00125]
11: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00100)	Tok/s 87652 (53150)	Loss/tok 3.6026 (5.0631)	Learning Rate [0.00125]
10: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00100)	Tok/s 87628 (53070)	Loss/tok 3.7429 (5.0700)	Learning Rate [0.00125]
9: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00094)	Tok/s 86857 (52989)	Loss/tok 3.7196 (5.0612)	Learning Rate [0.00125]
8: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00099)	Tok/s 86732 (52929)	Loss/tok 3.6025 (5.0680)	Learning Rate [0.00125]
2: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00099)	Tok/s 84784 (52388)	Loss/tok 3.6825 (5.0669)	Learning Rate [0.00125]
7: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 86749 (52850)	Loss/tok 3.6218 (5.0663)	Learning Rate [0.00125]
1: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 84807 (52289)	Loss/tok 3.6596 (5.0645)	Learning Rate [0.00125]
3: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00100)	Tok/s 85426 (52487)	Loss/tok 3.7447 (5.0534)	Learning Rate [0.00125]
4: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 85704 (52585)	Loss/tok 3.6537 (5.0673)	Learning Rate [0.00125]
5: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 85743 (52686)	Loss/tok 3.6418 (5.0756)	Learning Rate [0.00125]
6: TRAIN [0][1500/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00098)	Tok/s 85885 (52763)	Loss/tok 3.7948 (5.0642)	Learning Rate [0.00125]
11: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 59704 (53132)	Loss/tok 3.9488 (5.0549)	Learning Rate [0.00125]
10: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 59473 (53052)	Loss/tok 3.9430 (5.0614)	Learning Rate [0.00125]
12: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00100)	Tok/s 59721 (53247)	Loss/tok 3.8932 (5.0549)	Learning Rate [0.00125]
13: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 59664 (53344)	Loss/tok 3.8022 (5.0620)	Learning Rate [0.00125]
9: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00094)	Tok/s 58618 (52970)	Loss/tok 3.8172 (5.0527)	Learning Rate [0.00125]
8: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00099)	Tok/s 58494 (52910)	Loss/tok 4.1089 (5.0599)	Learning Rate [0.00125]
14: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00095)	Tok/s 59512 (53447)	Loss/tok 3.9850 (5.0577)	Learning Rate [0.00125]
7: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 58717 (52831)	Loss/tok 3.8945 (5.0577)	Learning Rate [0.00125]
15: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00093)	Tok/s 59494 (53552)	Loss/tok 3.8981 (5.0576)	Learning Rate [0.00125]
5: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 58245 (52668)	Loss/tok 3.9758 (5.0669)	Learning Rate [0.00125]
0: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 58493 (52161)	Loss/tok 3.7572 (5.0551)	Learning Rate [0.00125]
6: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 58315 (52745)	Loss/tok 3.8245 (5.0554)	Learning Rate [0.00125]
1: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00093)	Tok/s 58387 (52271)	Loss/tok 4.1082 (5.0562)	Learning Rate [0.00125]
2: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 58301 (52370)	Loss/tok 4.0558 (5.0581)	Learning Rate [0.00125]
4: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 58247 (52567)	Loss/tok 3.8414 (5.0588)	Learning Rate [0.00125]
3: TRAIN [0][1510/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00100)	Tok/s 58168 (52469)	Loss/tok 3.9764 (5.0447)	Learning Rate [0.00125]
15: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00093)	Tok/s 76393 (53575)	Loss/tok 3.8391 (5.0480)	Learning Rate [0.00125]
14: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00095)	Tok/s 76476 (53470)	Loss/tok 3.7502 (5.0486)	Learning Rate [0.00125]
0: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 74966 (52185)	Loss/tok 3.8241 (5.0463)	Learning Rate [0.00125]
2: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00099)	Tok/s 75254 (52394)	Loss/tok 3.9242 (5.0493)	Learning Rate [0.00125]
1: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 75288 (52296)	Loss/tok 3.9078 (5.0475)	Learning Rate [0.00125]
13: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 76420 (53366)	Loss/tok 3.8552 (5.0531)	Learning Rate [0.00125]
12: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00100)	Tok/s 76423 (53270)	Loss/tok 4.0126 (5.0462)	Learning Rate [0.00125]
8: TRAIN [0][1520/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 75546 (52932)	Loss/tok 3.7399 (5.0507)	Learning Rate [0.00125]
11: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00100)	Tok/s 76392 (53155)	Loss/tok 3.8683 (5.0460)	Learning Rate [0.00125]
10: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00099)	Tok/s 76344 (53075)	Loss/tok 3.9695 (5.0526)	Learning Rate [0.00125]
3: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00100)	Tok/s 75217 (52492)	Loss/tok 3.8092 (5.0357)	Learning Rate [0.00125]
4: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00093)	Tok/s 75174 (52590)	Loss/tok 3.6449 (5.0498)	Learning Rate [0.00125]
6: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 75263 (52767)	Loss/tok 4.0527 (5.0467)	Learning Rate [0.00125]
9: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00094)	Tok/s 76058 (52993)	Loss/tok 3.6541 (5.0436)	Learning Rate [0.00125]
5: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 75187 (52690)	Loss/tok 4.0394 (5.0578)	Learning Rate [0.00125]
7: TRAIN [0][1520/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 75333 (52853)	Loss/tok 3.6483 (5.0485)	Learning Rate [0.00125]
12: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00104 (0.00100)	Tok/s 80574 (53310)	Loss/tok 3.8327 (5.0366)	Learning Rate [0.00125]
11: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00121 (0.00100)	Tok/s 80537 (53196)	Loss/tok 3.7629 (5.0363)	Learning Rate [0.00125]
13: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00106 (0.00100)	Tok/s 80436 (53405)	Loss/tok 3.6505 (5.0430)	Learning Rate [0.00125]
10: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00099 (0.00099)	Tok/s 80501 (53116)	Loss/tok 3.8145 (5.0433)	Learning Rate [0.00125]
15: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00093)	Tok/s 81091 (53614)	Loss/tok 3.6215 (5.0382)	Learning Rate [0.00125]
14: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00087 (0.00095)	Tok/s 80266 (53509)	Loss/tok 3.6305 (5.0393)	Learning Rate [0.00125]
9: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00112 (0.00094)	Tok/s 80337 (53033)	Loss/tok 3.8567 (5.0340)	Learning Rate [0.00125]
8: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00102 (0.00099)	Tok/s 79383 (52971)	Loss/tok 3.7640 (5.0412)	Learning Rate [0.00125]
0: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00092)	Tok/s 78254 (52225)	Loss/tok 3.6409 (5.0370)	Learning Rate [0.00125]
7: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00093)	Tok/s 79195 (52891)	Loss/tok 3.8206 (5.0392)	Learning Rate [0.00125]
1: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00093)	Tok/s 78451 (52335)	Loss/tok 3.7562 (5.0377)	Learning Rate [0.00125]
5: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00096)	Tok/s 78951 (52729)	Loss/tok 3.7974 (5.0483)	Learning Rate [0.00125]
2: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00099)	Tok/s 78943 (52434)	Loss/tok 3.6781 (5.0399)	Learning Rate [0.00125]
6: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00099 (0.00098)	Tok/s 79036 (52805)	Loss/tok 3.7925 (5.0377)	Learning Rate [0.00125]
4: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00093)	Tok/s 78789 (52629)	Loss/tok 3.8204 (5.0406)	Learning Rate [0.00125]
3: TRAIN [0][1530/3416]	Time 0.071 (0.058)	Data 0.00103 (0.00100)	Tok/s 78845 (52532)	Loss/tok 3.7174 (5.0270)	Learning Rate [0.00125]
8: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00099)	Tok/s 36442 (52958)	Loss/tok 3.3531 (5.0332)	Learning Rate [0.00125]
9: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00094)	Tok/s 36393 (53020)	Loss/tok 3.7982 (5.0261)	Learning Rate [0.00125]
10: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00099)	Tok/s 36301 (53102)	Loss/tok 3.6910 (5.0353)	Learning Rate [0.00125]
7: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00079 (0.00092)	Tok/s 36412 (52878)	Loss/tok 3.4237 (5.0318)	Learning Rate [0.00125]
5: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00096)	Tok/s 36447 (52716)	Loss/tok 3.5072 (5.0401)	Learning Rate [0.00125]
6: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00098)	Tok/s 36419 (52792)	Loss/tok 3.6957 (5.0299)	Learning Rate [0.00125]
11: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00100)	Tok/s 36201 (53182)	Loss/tok 3.4399 (5.0288)	Learning Rate [0.00125]
12: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00100)	Tok/s 36129 (53296)	Loss/tok 3.2290 (5.0287)	Learning Rate [0.00125]
4: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00093)	Tok/s 36424 (52616)	Loss/tok 3.4532 (5.0329)	Learning Rate [0.00125]
13: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00100)	Tok/s 36126 (53391)	Loss/tok 3.3577 (5.0347)	Learning Rate [0.00125]
2: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00099)	Tok/s 36279 (52423)	Loss/tok 3.5674 (5.0321)	Learning Rate [0.00125]
3: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00107 (0.00100)	Tok/s 36367 (52520)	Loss/tok 3.5447 (5.0192)	Learning Rate [0.00125]
15: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 36157 (53601)	Loss/tok 3.6450 (5.0294)	Learning Rate [0.00125]
1: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00093)	Tok/s 35053 (52324)	Loss/tok 3.8432 (5.0295)	Learning Rate [0.00125]
14: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00095)	Tok/s 36114 (53495)	Loss/tok 3.7810 (5.0317)	Learning Rate [0.00125]
0: TRAIN [0][1540/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00092)	Tok/s 34884 (52214)	Loss/tok 3.3463 (5.0289)	Learning Rate [0.00125]
12: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00100)	Tok/s 66902 (53251)	Loss/tok 3.6794 (5.0218)	Learning Rate [0.00125]
11: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 66636 (53136)	Loss/tok 4.1783 (5.0220)	Learning Rate [0.00125]
13: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00100)	Tok/s 66840 (53348)	Loss/tok 3.9489 (5.0275)	Learning Rate [0.00125]
10: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00099)	Tok/s 65689 (53056)	Loss/tok 4.1313 (5.0286)	Learning Rate [0.00125]
15: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 66725 (53556)	Loss/tok 3.6230 (5.0219)	Learning Rate [0.00125]
8: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 65508 (52912)	Loss/tok 4.0589 (5.0264)	Learning Rate [0.00125]
9: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00094)	Tok/s 65528 (52974)	Loss/tok 4.1959 (5.0199)	Learning Rate [0.00125]
7: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 65389 (52833)	Loss/tok 3.9665 (5.0247)	Learning Rate [0.00125]
14: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00095)	Tok/s 66886 (53451)	Loss/tok 3.8745 (5.0248)	Learning Rate [0.00125]
1: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00093)	Tok/s 65646 (52279)	Loss/tok 3.8124 (5.0223)	Learning Rate [0.00125]
2: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00099)	Tok/s 65561 (52378)	Loss/tok 3.9912 (5.0251)	Learning Rate [0.00125]
5: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 65383 (52670)	Loss/tok 3.9609 (5.0329)	Learning Rate [0.00125]
6: TRAIN [0][1550/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 65381 (52747)	Loss/tok 4.1035 (5.0231)	Learning Rate [0.00125]
0: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 65754 (52170)	Loss/tok 3.9270 (5.0218)	Learning Rate [0.00125]
3: TRAIN [0][1550/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 65440 (52475)	Loss/tok 3.7950 (5.0122)	Learning Rate [0.00125]
4: TRAIN [0][1550/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 65273 (52571)	Loss/tok 3.9646 (5.0259)	Learning Rate [0.00125]
0: TRAIN [0][1560/3416]	Time 0.038 (0.058)	Data 0.00086 (0.00092)	Tok/s 25192 (52114)	Loss/tok 2.3951 (5.0151)	Learning Rate [0.00125]
15: TRAIN [0][1560/3416]	Time 0.038 (0.058)	Data 0.00093 (0.00093)	Tok/s 30230 (53511)	Loss/tok 2.8899 (5.0156)	Learning Rate [0.00125]
2: TRAIN [0][1560/3416]	Time 0.038 (0.058)	Data 0.00085 (0.00099)	Tok/s 26416 (52326)	Loss/tok 2.7517 (5.0184)	Learning Rate [0.00125]
14: TRAIN [0][1560/3416]	Time 0.038 (0.058)	Data 0.00093 (0.00095)	Tok/s 30191 (53406)	Loss/tok 2.7538 (5.0178)	Learning Rate [0.00125]
13: TRAIN [0][1560/3416]	Time 0.038 (0.058)	Data 0.00088 (0.00100)	Tok/s 30250 (53302)	Loss/tok 2.8773 (5.0209)	Learning Rate [0.00125]
1: TRAIN [0][1560/3416]	Time 0.038 (0.058)	Data 0.00089 (0.00093)	Tok/s 25096 (52225)	Loss/tok 2.6469 (5.0157)	Learning Rate [0.00125]
12: TRAIN [0][1560/3416]	Time 0.038 (0.058)	Data 0.00091 (0.00100)	Tok/s 29490 (53205)	Loss/tok 2.7957 (5.0151)	Learning Rate [0.00125]
3: TRAIN [0][1560/3416]	Time 0.038 (0.058)	Data 0.00094 (0.00100)	Tok/s 26619 (52425)	Loss/tok 2.7337 (5.0051)	Learning Rate [0.00125]
10: TRAIN [0][1560/3416]	Time 0.038 (0.058)	Data 0.00087 (0.00099)	Tok/s 28405 (53009)	Loss/tok 2.5802 (5.0217)	Learning Rate [0.00125]
11: TRAIN [0][1560/3416]	Time 0.038 (0.058)	Data 0.00084 (0.00100)	Tok/s 28440 (53089)	Loss/tok 2.6005 (5.0150)	Learning Rate [0.00125]
5: TRAIN [0][1560/3416]	Time 0.039 (0.058)	Data 0.00091 (0.00096)	Tok/s 26506 (52621)	Loss/tok 2.8263 (5.0266)	Learning Rate [0.00125]
4: TRAIN [0][1560/3416]	Time 0.039 (0.058)	Data 0.00088 (0.00093)	Tok/s 26500 (52522)	Loss/tok 2.5625 (5.0195)	Learning Rate [0.00125]
6: TRAIN [0][1560/3416]	Time 0.039 (0.058)	Data 0.00086 (0.00098)	Tok/s 26918 (52698)	Loss/tok 2.7313 (5.0158)	Learning Rate [0.00125]
8: TRAIN [0][1560/3416]	Time 0.039 (0.058)	Data 0.00092 (0.00099)	Tok/s 28206 (52867)	Loss/tok 2.7576 (5.0198)	Learning Rate [0.00125]
9: TRAIN [0][1560/3416]	Time 0.039 (0.058)	Data 0.00092 (0.00094)	Tok/s 28235 (52928)	Loss/tok 3.0583 (5.0130)	Learning Rate [0.00125]
7: TRAIN [0][1560/3416]	Time 0.039 (0.058)	Data 0.00088 (0.00092)	Tok/s 28110 (52786)	Loss/tok 2.8219 (5.0177)	Learning Rate [0.00125]
13: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00091 (0.00100)	Tok/s 37919 (53270)	Loss/tok 3.5174 (5.0144)	Learning Rate [0.00125]
14: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00090 (0.00095)	Tok/s 37920 (53374)	Loss/tok 3.5923 (5.0111)	Learning Rate [0.00125]
12: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00093 (0.00100)	Tok/s 37926 (53173)	Loss/tok 3.4220 (5.0083)	Learning Rate [0.00125]
15: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00088 (0.00093)	Tok/s 37882 (53478)	Loss/tok 3.4545 (5.0090)	Learning Rate [0.00125]
10: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00089 (0.00099)	Tok/s 37984 (52978)	Loss/tok 3.2774 (5.0144)	Learning Rate [0.00125]
11: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00090 (0.00100)	Tok/s 37927 (53058)	Loss/tok 3.4701 (5.0083)	Learning Rate [0.00125]
0: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00100 (0.00092)	Tok/s 36651 (52083)	Loss/tok 3.3772 (5.0081)	Learning Rate [0.00125]
9: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00098 (0.00094)	Tok/s 38009 (52898)	Loss/tok 3.4288 (5.0058)	Learning Rate [0.00125]
1: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00079 (0.00093)	Tok/s 36632 (52193)	Loss/tok 3.5960 (5.0090)	Learning Rate [0.00125]
8: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00090 (0.00099)	Tok/s 37921 (52837)	Loss/tok 3.6367 (5.0128)	Learning Rate [0.00125]
2: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00090 (0.00099)	Tok/s 36603 (52294)	Loss/tok 3.3931 (5.0114)	Learning Rate [0.00125]
7: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00084 (0.00092)	Tok/s 37986 (52755)	Loss/tok 3.2436 (5.0110)	Learning Rate [0.00125]
4: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00093 (0.00093)	Tok/s 36728 (52490)	Loss/tok 3.6260 (5.0125)	Learning Rate [0.00125]
3: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00083 (0.00100)	Tok/s 36570 (52392)	Loss/tok 3.2767 (4.9985)	Learning Rate [0.00125]
5: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00082 (0.00096)	Tok/s 37900 (52590)	Loss/tok 3.3707 (5.0196)	Learning Rate [0.00125]
6: TRAIN [0][1570/3416]	Time 0.051 (0.057)	Data 0.00097 (0.00098)	Tok/s 37892 (52667)	Loss/tok 3.5898 (5.0092)	Learning Rate [0.00125]
3: TRAIN [0][1580/3416]	Time 0.049 (0.058)	Data 0.00103 (0.00100)	Tok/s 40141 (52451)	Loss/tok 3.8255 (4.9889)	Learning Rate [0.00125]
4: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00093)	Tok/s 40067 (52548)	Loss/tok 3.2916 (5.0030)	Learning Rate [0.00125]
2: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00099)	Tok/s 39990 (52353)	Loss/tok 3.4637 (5.0020)	Learning Rate [0.00125]
5: TRAIN [0][1580/3416]	Time 0.049 (0.058)	Data 0.00122 (0.00096)	Tok/s 40103 (52648)	Loss/tok 3.5473 (5.0098)	Learning Rate [0.00125]
14: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00113 (0.00095)	Tok/s 39960 (53432)	Loss/tok 3.5455 (5.0012)	Learning Rate [0.00125]
10: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00110 (0.00099)	Tok/s 39929 (53036)	Loss/tok 3.3225 (5.0047)	Learning Rate [0.00125]
6: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00098)	Tok/s 40079 (52725)	Loss/tok 3.3570 (4.9996)	Learning Rate [0.00125]
0: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00107 (0.00092)	Tok/s 39794 (52141)	Loss/tok 3.5828 (4.9987)	Learning Rate [0.00125]
12: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00100)	Tok/s 39799 (53231)	Loss/tok 3.5510 (4.9989)	Learning Rate [0.00125]
15: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00093)	Tok/s 41020 (53537)	Loss/tok 3.3757 (4.9991)	Learning Rate [0.00125]
11: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00100)	Tok/s 39851 (53115)	Loss/tok 3.2887 (4.9982)	Learning Rate [0.00125]
13: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00100)	Tok/s 39737 (53328)	Loss/tok 3.4930 (5.0044)	Learning Rate [0.00125]
8: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00099)	Tok/s 39952 (52895)	Loss/tok 3.3103 (5.0030)	Learning Rate [0.00125]
7: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00092)	Tok/s 40006 (52813)	Loss/tok 3.4294 (5.0015)	Learning Rate [0.00125]
9: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00115 (0.00094)	Tok/s 39895 (52955)	Loss/tok 3.5527 (4.9962)	Learning Rate [0.00125]
1: TRAIN [0][1580/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00093)	Tok/s 39903 (52252)	Loss/tok 3.6220 (4.9992)	Learning Rate [0.00125]
0: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00092)	Tok/s 45783 (52140)	Loss/tok 3.4930 (4.9910)	Learning Rate [0.00125]
15: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00093)	Tok/s 47230 (53535)	Loss/tok 3.5966 (4.9911)	Learning Rate [0.00125]
1: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00093)	Tok/s 45649 (52250)	Loss/tok 3.5814 (4.9914)	Learning Rate [0.00125]
14: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00095)	Tok/s 47190 (53430)	Loss/tok 3.3455 (4.9935)	Learning Rate [0.00125]
2: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00079 (0.00099)	Tok/s 45494 (52350)	Loss/tok 3.4783 (4.9944)	Learning Rate [0.00125]
13: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00100)	Tok/s 47141 (53325)	Loss/tok 3.5789 (4.9960)	Learning Rate [0.00125]
3: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00100)	Tok/s 45326 (52448)	Loss/tok 3.6570 (4.9814)	Learning Rate [0.00125]
4: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00093)	Tok/s 46107 (52545)	Loss/tok 3.6906 (4.9952)	Learning Rate [0.00125]
12: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00100)	Tok/s 47097 (53228)	Loss/tok 3.6857 (4.9912)	Learning Rate [0.00125]
11: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00099)	Tok/s 47043 (53113)	Loss/tok 3.4655 (4.9901)	Learning Rate [0.00125]
5: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00096)	Tok/s 46611 (52646)	Loss/tok 3.5120 (5.0013)	Learning Rate [0.00125]
10: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00103 (0.00099)	Tok/s 46954 (53033)	Loss/tok 3.5304 (4.9969)	Learning Rate [0.00125]
6: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00098)	Tok/s 46626 (52723)	Loss/tok 3.9531 (4.9917)	Learning Rate [0.00125]
7: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00092)	Tok/s 46699 (52811)	Loss/tok 3.9014 (4.9939)	Learning Rate [0.00125]
9: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00094)	Tok/s 46858 (52953)	Loss/tok 3.6518 (4.9886)	Learning Rate [0.00125]
8: TRAIN [0][1590/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00099)	Tok/s 46634 (52892)	Loss/tok 3.4267 (4.9950)	Learning Rate [0.00125]
15: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
9: Upscaling, new scale: 1024.0
5: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 56988 (52623)	Loss/tok 4.1797 (4.9941)	Learning Rate [0.00125]
4: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00093)	Tok/s 56806 (52523)	Loss/tok 3.7575 (4.9877)	Learning Rate [0.00125]
6: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00098)	Tok/s 57821 (52701)	Loss/tok 3.9977 (4.9841)	Learning Rate [0.00125]
2: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00099)	Tok/s 56615 (52328)	Loss/tok 3.4933 (4.9869)	Learning Rate [0.00125]
3: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00100)	Tok/s 56690 (52427)	Loss/tok 3.7077 (4.9741)	Learning Rate [0.00125]
7: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00093)	Tok/s 57856 (52789)	Loss/tok 3.7929 (4.9869)	Learning Rate [0.00125]
0: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 56575 (52118)	Loss/tok 3.9454 (4.9837)	Learning Rate [0.00125]
8: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00099)	Tok/s 57820 (52871)	Loss/tok 3.7964 (4.9876)	Learning Rate [0.00125]
1: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 56517 (52228)	Loss/tok 3.7726 (4.9836)	Learning Rate [0.00125]
9: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00094)	Tok/s 57851 (52931)	Loss/tok 3.7302 (4.9814)	Learning Rate [0.00125]
10: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 57715 (53011)	Loss/tok 3.8660 (4.9890)	Learning Rate [0.00125]
15: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 57407 (53511)	Loss/tok 4.1525 (4.9842)	Learning Rate [0.00125]
11: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00099)	Tok/s 57593 (53091)	Loss/tok 3.7788 (4.9826)	Learning Rate [0.00125]
13: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 57425 (53303)	Loss/tok 3.8527 (4.9884)	Learning Rate [0.00125]
12: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 57424 (53206)	Loss/tok 3.7301 (4.9836)	Learning Rate [0.00125]
14: TRAIN [0][1600/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00095)	Tok/s 57491 (53406)	Loss/tok 3.8536 (4.9860)	Learning Rate [0.00125]
3: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00100)	Tok/s 50074 (52419)	Loss/tok 3.5280 (4.9666)	Learning Rate [0.00125]
5: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00096)	Tok/s 49941 (52616)	Loss/tok 3.2675 (4.9871)	Learning Rate [0.00125]
4: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00081 (0.00093)	Tok/s 50031 (52516)	Loss/tok 3.3295 (4.9798)	Learning Rate [0.00125]
2: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00099)	Tok/s 49707 (52321)	Loss/tok 3.6294 (4.9793)	Learning Rate [0.00125]
6: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00098)	Tok/s 49960 (52693)	Loss/tok 3.3694 (4.9771)	Learning Rate [0.00125]
7: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00080 (0.00092)	Tok/s 49973 (52781)	Loss/tok 3.4176 (4.9798)	Learning Rate [0.00125]
1: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00093)	Tok/s 48612 (52221)	Loss/tok 3.5890 (4.9764)	Learning Rate [0.00125]
15: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00093)	Tok/s 50153 (53501)	Loss/tok 3.4687 (4.9764)	Learning Rate [0.00125]
0: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00092)	Tok/s 48661 (52112)	Loss/tok 3.7907 (4.9764)	Learning Rate [0.00125]
8: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00099)	Tok/s 49973 (52863)	Loss/tok 3.5280 (4.9799)	Learning Rate [0.00125]
13: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00100)	Tok/s 50179 (53294)	Loss/tok 3.5961 (4.9811)	Learning Rate [0.00125]
12: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00100)	Tok/s 50124 (53197)	Loss/tok 3.3791 (4.9760)	Learning Rate [0.00125]
9: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00094)	Tok/s 49964 (52923)	Loss/tok 3.9164 (4.9744)	Learning Rate [0.00125]
10: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00099)	Tok/s 49966 (53003)	Loss/tok 3.4243 (4.9817)	Learning Rate [0.00125]
11: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00099)	Tok/s 50022 (53083)	Loss/tok 3.7660 (4.9755)	Learning Rate [0.00125]
14: TRAIN [0][1610/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00095)	Tok/s 49980 (53397)	Loss/tok 3.5612 (4.9787)	Learning Rate [0.00125]
8: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00099)	Tok/s 58680 (52845)	Loss/tok 3.7799 (4.9726)	Learning Rate [0.00125]
9: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00094)	Tok/s 58616 (52905)	Loss/tok 4.0321 (4.9674)	Learning Rate [0.00125]
10: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00099)	Tok/s 58465 (52984)	Loss/tok 3.7325 (4.9748)	Learning Rate [0.00125]
7: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00093)	Tok/s 58714 (52763)	Loss/tok 3.8536 (4.9733)	Learning Rate [0.00125]
11: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00099)	Tok/s 58543 (53064)	Loss/tok 3.6832 (4.9683)	Learning Rate [0.00125]
6: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00098)	Tok/s 58577 (52674)	Loss/tok 3.8619 (4.9701)	Learning Rate [0.00125]
12: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00100)	Tok/s 58518 (53178)	Loss/tok 3.8632 (4.9685)	Learning Rate [0.00125]
5: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00096)	Tok/s 58578 (52597)	Loss/tok 3.9786 (4.9798)	Learning Rate [0.00125]
4: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00093)	Tok/s 58687 (52498)	Loss/tok 3.8811 (4.9729)	Learning Rate [0.00125]
13: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00100)	Tok/s 58529 (53274)	Loss/tok 4.1988 (4.9744)	Learning Rate [0.00125]
2: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00099)	Tok/s 58658 (52304)	Loss/tok 3.8175 (4.9722)	Learning Rate [0.00125]
15: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00093)	Tok/s 58518 (53481)	Loss/tok 3.9988 (4.9695)	Learning Rate [0.00125]
0: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00092)	Tok/s 58584 (52095)	Loss/tok 3.8792 (4.9686)	Learning Rate [0.00125]
1: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00083 (0.00093)	Tok/s 58622 (52204)	Loss/tok 4.1570 (4.9698)	Learning Rate [0.00125]
3: TRAIN [0][1620/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00100)	Tok/s 58666 (52402)	Loss/tok 3.7996 (4.9598)	Learning Rate [0.00125]
14: TRAIN [0][1620/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00095)	Tok/s 57410 (53377)	Loss/tok 3.9440 (4.9715)	Learning Rate [0.00125]
8: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00091 (0.00099)	Tok/s 31258 (52843)	Loss/tok 3.0352 (4.9652)	Learning Rate [0.00125]
9: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00101 (0.00094)	Tok/s 31278 (52904)	Loss/tok 2.9610 (4.9598)	Learning Rate [0.00125]
7: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00093)	Tok/s 30748 (52761)	Loss/tok 3.0659 (4.9656)	Learning Rate [0.00125]
10: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00107 (0.00099)	Tok/s 31249 (52983)	Loss/tok 2.8404 (4.9670)	Learning Rate [0.00125]
6: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00098)	Tok/s 29691 (52672)	Loss/tok 3.0657 (4.9629)	Learning Rate [0.00125]
5: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00098 (0.00096)	Tok/s 29703 (52596)	Loss/tok 2.9071 (4.9726)	Learning Rate [0.00125]
11: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00099)	Tok/s 31187 (53063)	Loss/tok 3.0023 (4.9613)	Learning Rate [0.00125]
4: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00090 (0.00093)	Tok/s 29653 (52497)	Loss/tok 3.0242 (4.9658)	Learning Rate [0.00125]
12: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00091 (0.00100)	Tok/s 31143 (53176)	Loss/tok 3.1963 (4.9606)	Learning Rate [0.00125]
3: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00100)	Tok/s 29572 (52402)	Loss/tok 3.0502 (4.9525)	Learning Rate [0.00125]
2: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00099)	Tok/s 29495 (52305)	Loss/tok 3.0271 (4.9653)	Learning Rate [0.00125]
13: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00099 (0.00100)	Tok/s 30988 (53272)	Loss/tok 3.0018 (4.9669)	Learning Rate [0.00125]
15: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00093)	Tok/s 30905 (53479)	Loss/tok 3.0911 (4.9622)	Learning Rate [0.00125]
0: TRAIN [0][1630/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00092)	Tok/s 29369 (52097)	Loss/tok 3.0636 (4.9609)	Learning Rate [0.00125]
1: TRAIN [0][1630/3416]	Time 0.044 (0.058)	Data 0.00085 (0.00093)	Tok/s 29378 (52205)	Loss/tok 3.1785 (4.9621)	Learning Rate [0.00125]
14: TRAIN [0][1630/3416]	Time 0.043 (0.058)	Data 0.00096 (0.00095)	Tok/s 30998 (53375)	Loss/tok 2.9404 (4.9642)	Learning Rate [0.00125]
14: Gradient norm: inf
13: Gradient norm: inf
15: Gradient norm: inf
14: Skipped batch, new scale: 512.0
12: Gradient norm: inf
13: Skipped batch, new scale: 512.0
15: Skipped batch, new scale: 512.0
0: Gradient norm: inf
12: Skipped batch, new scale: 512.0
11: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 512.0
10: Gradient norm: inf
11: Skipped batch, new scale: 512.0
2: Gradient norm: inf
1: Skipped batch, new scale: 512.0
14: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00095)	Tok/s 90848 (53373)	Loss/tok 3.5778 (4.9564)	Learning Rate [0.00125]
9: Gradient norm: inf
15: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 91381 (53477)	Loss/tok 3.3866 (4.9541)	Learning Rate [0.00125]
13: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 90104 (53269)	Loss/tok 3.8388 (4.9595)	Learning Rate [0.00125]
10: Skipped batch, new scale: 512.0
2: Skipped batch, new scale: 512.0
3: Gradient norm: inf
8: Gradient norm: inf
5: Gradient norm: inf
9: Skipped batch, new scale: 512.0
12: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 89651 (53173)	Loss/tok 3.6444 (4.9531)	Learning Rate [0.00125]
4: Gradient norm: inf
3: Skipped batch, new scale: 512.0
6: Gradient norm: inf
5: Skipped batch, new scale: 512.0
8: Skipped batch, new scale: 512.0
0: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 86136 (52094)	Loss/tok 3.7360 (4.9536)	Learning Rate [0.00125]
11: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00099)	Tok/s 89147 (53060)	Loss/tok 3.7720 (4.9536)	Learning Rate [0.00125]
4: Skipped batch, new scale: 512.0
1: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 86184 (52203)	Loss/tok 3.5132 (4.9543)	Learning Rate [0.00125]
10: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 89136 (52981)	Loss/tok 3.6653 (4.9594)	Learning Rate [0.00125]
6: Skipped batch, new scale: 512.0
9: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00094)	Tok/s 88405 (52901)	Loss/tok 3.6080 (4.9519)	Learning Rate [0.00125]
2: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00099)	Tok/s 86196 (52302)	Loss/tok 3.6429 (4.9578)	Learning Rate [0.00125]
7: Gradient norm: inf
3: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00100)	Tok/s 86440 (52399)	Loss/tok 3.8057 (4.9449)	Learning Rate [0.00125]
5: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 87230 (52593)	Loss/tok 3.5980 (4.9648)	Learning Rate [0.00125]
7: Skipped batch, new scale: 512.0
4: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 87151 (52495)	Loss/tok 3.6337 (4.9581)	Learning Rate [0.00125]
6: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 87344 (52668)	Loss/tok 3.5952 (4.9548)	Learning Rate [0.00125]
8: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 88204 (52839)	Loss/tok 3.5633 (4.9575)	Learning Rate [0.00125]
7: TRAIN [0][1640/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00093)	Tok/s 88017 (52758)	Loss/tok 3.4464 (4.9577)	Learning Rate [0.00125]
5: TRAIN [0][1650/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00096)	Tok/s 53979 (52608)	Loss/tok 3.6506 (4.9576)	Learning Rate [0.00125]
4: TRAIN [0][1650/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00093)	Tok/s 54006 (52510)	Loss/tok 3.9379 (4.9502)	Learning Rate [0.00125]
6: TRAIN [0][1650/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00098)	Tok/s 53879 (52683)	Loss/tok 3.9645 (4.9474)	Learning Rate [0.00125]
2: TRAIN [0][1650/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00099)	Tok/s 54043 (52318)	Loss/tok 3.6887 (4.9504)	Learning Rate [0.00125]
3: TRAIN [0][1650/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00100)	Tok/s 54007 (52414)	Loss/tok 3.7962 (4.9373)	Learning Rate [0.00125]
8: TRAIN [0][1650/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00099)	Tok/s 53875 (52853)	Loss/tok 3.7038 (4.9497)	Learning Rate [0.00125]
7: TRAIN [0][1650/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00093)	Tok/s 53879 (52772)	Loss/tok 3.6500 (4.9502)	Learning Rate [0.00125]
0: TRAIN [0][1650/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00092)	Tok/s 54048 (52109)	Loss/tok 3.6495 (4.9459)	Learning Rate [0.00125]
1: TRAIN [0][1650/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00093)	Tok/s 53991 (52218)	Loss/tok 3.7692 (4.9468)	Learning Rate [0.00125]
10: TRAIN [0][1650/3416]	Time 0.061 (0.058)	Data 0.00109 (0.00099)	Tok/s 53898 (52994)	Loss/tok 3.7794 (4.9517)	Learning Rate [0.00125]
15: TRAIN [0][1650/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00093)	Tok/s 55085 (53489)	Loss/tok 3.9518 (4.9466)	Learning Rate [0.00125]
11: TRAIN [0][1650/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00099)	Tok/s 53897 (53073)	Loss/tok 3.8258 (4.9456)	Learning Rate [0.00125]
12: TRAIN [0][1650/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00100)	Tok/s 53914 (53186)	Loss/tok 3.8750 (4.9456)	Learning Rate [0.00125]
13: TRAIN [0][1650/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00100)	Tok/s 53974 (53281)	Loss/tok 3.7805 (4.9517)	Learning Rate [0.00125]
9: TRAIN [0][1650/3416]	Time 0.061 (0.058)	Data 0.00105 (0.00094)	Tok/s 53827 (52913)	Loss/tok 3.6934 (4.9447)	Learning Rate [0.00125]
14: TRAIN [0][1650/3416]	Time 0.061 (0.058)	Data 0.00116 (0.00095)	Tok/s 53972 (53384)	Loss/tok 3.5764 (4.9487)	Learning Rate [0.00125]
5: TRAIN [0][1660/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00096)	Tok/s 31924 (52584)	Loss/tok 3.0645 (4.9512)	Learning Rate [0.00125]
4: TRAIN [0][1660/3416]	Time 0.044 (0.058)	Data 0.00080 (0.00093)	Tok/s 31851 (52485)	Loss/tok 3.1421 (4.9431)	Learning Rate [0.00125]
6: TRAIN [0][1660/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00098)	Tok/s 31959 (52659)	Loss/tok 3.1712 (4.9403)	Learning Rate [0.00125]
2: TRAIN [0][1660/3416]	Time 0.044 (0.058)	Data 0.00108 (0.00099)	Tok/s 31690 (52294)	Loss/tok 3.0953 (4.9436)	Learning Rate [0.00125]
7: TRAIN [0][1660/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00093)	Tok/s 32002 (52747)	Loss/tok 3.0711 (4.9438)	Learning Rate [0.00125]
3: TRAIN [0][1660/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00100)	Tok/s 31768 (52390)	Loss/tok 3.1815 (4.9301)	Learning Rate [0.00125]
8: TRAIN [0][1660/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00099)	Tok/s 31896 (52828)	Loss/tok 3.1351 (4.9433)	Learning Rate [0.00125]
1: TRAIN [0][1660/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00093)	Tok/s 31593 (52195)	Loss/tok 2.9691 (4.9401)	Learning Rate [0.00125]
0: TRAIN [0][1660/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00092)	Tok/s 30674 (52086)	Loss/tok 3.0569 (4.9390)	Learning Rate [0.00125]
10: TRAIN [0][1660/3416]	Time 0.044 (0.058)	Data 0.00129 (0.00099)	Tok/s 31768 (52969)	Loss/tok 3.2017 (4.9447)	Learning Rate [0.00125]
15: TRAIN [0][1660/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00093)	Tok/s 33006 (53464)	Loss/tok 3.3646 (4.9394)	Learning Rate [0.00125]
11: TRAIN [0][1660/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00099)	Tok/s 31713 (53048)	Loss/tok 3.1547 (4.9383)	Learning Rate [0.00125]
13: TRAIN [0][1660/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00100)	Tok/s 32551 (53257)	Loss/tok 2.8998 (4.9448)	Learning Rate [0.00125]
12: TRAIN [0][1660/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00100)	Tok/s 31628 (53161)	Loss/tok 3.2958 (4.9389)	Learning Rate [0.00125]
9: TRAIN [0][1660/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00094)	Tok/s 31798 (52888)	Loss/tok 3.2931 (4.9385)	Learning Rate [0.00125]
14: TRAIN [0][1660/3416]	Time 0.045 (0.058)	Data 0.00112 (0.00095)	Tok/s 32986 (53360)	Loss/tok 3.3009 (4.9416)	Learning Rate [0.00125]
7: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00093)	Tok/s 35569 (52776)	Loss/tok 3.4469 (4.9352)	Learning Rate [0.00125]
4: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00093)	Tok/s 35685 (52513)	Loss/tok 3.1806 (4.9342)	Learning Rate [0.00125]
5: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00096)	Tok/s 35738 (52612)	Loss/tok 3.3291 (4.9430)	Learning Rate [0.00125]
6: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00098)	Tok/s 35708 (52687)	Loss/tok 3.5495 (4.9315)	Learning Rate [0.00125]
0: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00092)	Tok/s 35126 (52115)	Loss/tok 3.4114 (4.9306)	Learning Rate [0.00125]
9: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00094)	Tok/s 35463 (52917)	Loss/tok 3.4189 (4.9306)	Learning Rate [0.00125]
8: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00099)	Tok/s 35517 (52856)	Loss/tok 3.2450 (4.9349)	Learning Rate [0.00125]
2: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00108 (0.00099)	Tok/s 35716 (52323)	Loss/tok 3.5081 (4.9354)	Learning Rate [0.00125]
3: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00100)	Tok/s 35732 (52418)	Loss/tok 3.2195 (4.9214)	Learning Rate [0.00125]
1: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00093)	Tok/s 35677 (52224)	Loss/tok 3.4231 (4.9311)	Learning Rate [0.00125]
15: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00093)	Tok/s 35627 (53492)	Loss/tok 3.4984 (4.9311)	Learning Rate [0.00125]
11: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00099)	Tok/s 35566 (53076)	Loss/tok 3.2057 (4.9295)	Learning Rate [0.00125]
12: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00100)	Tok/s 35573 (53189)	Loss/tok 3.2409 (4.9306)	Learning Rate [0.00125]
13: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00100)	Tok/s 35569 (53285)	Loss/tok 3.5459 (4.9372)	Learning Rate [0.00125]
14: TRAIN [0][1670/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00095)	Tok/s 35586 (53388)	Loss/tok 3.3263 (4.9336)	Learning Rate [0.00125]
10: TRAIN [0][1670/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00099)	Tok/s 35325 (52997)	Loss/tok 3.4514 (4.9362)	Learning Rate [0.00125]
1: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00087 (0.00093)	Tok/s 29701 (52225)	Loss/tok 3.2767 (4.9240)	Learning Rate [0.00125]
0: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00088 (0.00092)	Tok/s 29629 (52117)	Loss/tok 3.1008 (4.9231)	Learning Rate [0.00125]
2: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00098 (0.00099)	Tok/s 29730 (52324)	Loss/tok 3.4845 (4.9285)	Learning Rate [0.00125]
15: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00081 (0.00093)	Tok/s 31018 (53490)	Loss/tok 3.0447 (4.9241)	Learning Rate [0.00125]
3: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00120 (0.00100)	Tok/s 29712 (52419)	Loss/tok 3.1731 (4.9146)	Learning Rate [0.00125]
4: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00093)	Tok/s 29697 (52514)	Loss/tok 3.2475 (4.9268)	Learning Rate [0.00125]
14: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00083 (0.00095)	Tok/s 30995 (53387)	Loss/tok 2.9284 (4.9263)	Learning Rate [0.00125]
5: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00105 (0.00096)	Tok/s 30479 (52613)	Loss/tok 3.3082 (4.9363)	Learning Rate [0.00125]
12: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00105 (0.00100)	Tok/s 31025 (53189)	Loss/tok 3.0010 (4.9234)	Learning Rate [0.00125]
13: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00105 (0.00100)	Tok/s 31004 (53285)	Loss/tok 2.9355 (4.9302)	Learning Rate [0.00125]
6: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00104 (0.00098)	Tok/s 31166 (52689)	Loss/tok 3.2967 (4.9243)	Learning Rate [0.00125]
11: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00103 (0.00099)	Tok/s 31013 (53077)	Loss/tok 3.2158 (4.9220)	Learning Rate [0.00125]
10: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00099)	Tok/s 30987 (52998)	Loss/tok 2.8810 (4.9291)	Learning Rate [0.00125]
9: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00094)	Tok/s 30990 (52917)	Loss/tok 2.9870 (4.9230)	Learning Rate [0.00125]
8: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00098 (0.00099)	Tok/s 31040 (52857)	Loss/tok 2.9534 (4.9276)	Learning Rate [0.00125]
7: TRAIN [0][1680/3416]	Time 0.043 (0.058)	Data 0.00100 (0.00093)	Tok/s 31081 (52777)	Loss/tok 3.1634 (4.9283)	Learning Rate [0.00125]
5: TRAIN [0][1690/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 72881 (52581)	Loss/tok 3.9762 (4.9298)	Learning Rate [0.00125]
4: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 72725 (52482)	Loss/tok 3.8940 (4.9203)	Learning Rate [0.00125]
6: TRAIN [0][1690/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 72929 (52656)	Loss/tok 3.9052 (4.9184)	Learning Rate [0.00125]
7: TRAIN [0][1690/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00093)	Tok/s 72880 (52743)	Loss/tok 3.9346 (4.9223)	Learning Rate [0.00125]
3: TRAIN [0][1690/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 72404 (52386)	Loss/tok 3.9211 (4.9085)	Learning Rate [0.00125]
8: TRAIN [0][1690/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00099)	Tok/s 72968 (52823)	Loss/tok 3.8640 (4.9214)	Learning Rate [0.00125]
2: TRAIN [0][1690/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 71853 (52291)	Loss/tok 4.0381 (4.9223)	Learning Rate [0.00125]
9: TRAIN [0][1690/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 72927 (52883)	Loss/tok 3.6435 (4.9171)	Learning Rate [0.00125]
0: TRAIN [0][1690/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 71887 (52084)	Loss/tok 3.7986 (4.9165)	Learning Rate [0.00125]
10: TRAIN [0][1690/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 72944 (52964)	Loss/tok 3.7987 (4.9226)	Learning Rate [0.00125]
1: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 71808 (52193)	Loss/tok 3.8769 (4.9180)	Learning Rate [0.00125]
15: TRAIN [0][1690/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 73759 (53457)	Loss/tok 3.9012 (4.9180)	Learning Rate [0.00125]
13: TRAIN [0][1690/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00100)	Tok/s 73016 (53250)	Loss/tok 4.0635 (4.9245)	Learning Rate [0.00125]
14: TRAIN [0][1690/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00095)	Tok/s 73586 (53355)	Loss/tok 3.7250 (4.9203)	Learning Rate [0.00125]
11: TRAIN [0][1690/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00099)	Tok/s 73306 (53043)	Loss/tok 4.0342 (4.9157)	Learning Rate [0.00125]
12: TRAIN [0][1690/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00100)	Tok/s 72904 (53155)	Loss/tok 3.8015 (4.9172)	Learning Rate [0.00125]
8: TRAIN [0][1700/3416]	Time 0.055 (0.058)	Data 0.00107 (0.00099)	Tok/s 53074 (52813)	Loss/tok 3.5533 (4.9146)	Learning Rate [0.00125]
5: TRAIN [0][1700/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00096)	Tok/s 52654 (52570)	Loss/tok 3.8901 (4.9234)	Learning Rate [0.00125]
11: TRAIN [0][1700/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00099)	Tok/s 52753 (53032)	Loss/tok 4.0031 (4.9098)	Learning Rate [0.00125]
12: TRAIN [0][1700/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00100)	Tok/s 52702 (53143)	Loss/tok 3.6874 (4.9106)	Learning Rate [0.00125]
7: TRAIN [0][1700/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00093)	Tok/s 53188 (52733)	Loss/tok 3.5700 (4.9156)	Learning Rate [0.00125]
15: TRAIN [0][1700/3416]	Time 0.056 (0.058)	Data 0.00128 (0.00093)	Tok/s 52955 (53446)	Loss/tok 3.5828 (4.9111)	Learning Rate [0.00125]
14: TRAIN [0][1700/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00095)	Tok/s 52954 (53344)	Loss/tok 3.7267 (4.9141)	Learning Rate [0.00125]
13: TRAIN [0][1700/3416]	Time 0.056 (0.058)	Data 0.00115 (0.00100)	Tok/s 52758 (53239)	Loss/tok 3.7334 (4.9180)	Learning Rate [0.00125]
0: TRAIN [0][1700/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00092)	Tok/s 51889 (52074)	Loss/tok 3.9330 (4.9104)	Learning Rate [0.00125]
4: TRAIN [0][1700/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00093)	Tok/s 52218 (52471)	Loss/tok 3.9355 (4.9138)	Learning Rate [0.00125]
1: TRAIN [0][1700/3416]	Time 0.055 (0.058)	Data 0.00109 (0.00093)	Tok/s 51980 (52183)	Loss/tok 3.7437 (4.9117)	Learning Rate [0.00125]
10: TRAIN [0][1700/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00099)	Tok/s 52896 (52953)	Loss/tok 3.7154 (4.9160)	Learning Rate [0.00125]
9: TRAIN [0][1700/3416]	Time 0.056 (0.058)	Data 0.00101 (0.00094)	Tok/s 52975 (52873)	Loss/tok 3.7369 (4.9108)	Learning Rate [0.00125]
2: TRAIN [0][1700/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00099)	Tok/s 52219 (52281)	Loss/tok 3.9594 (4.9161)	Learning Rate [0.00125]
3: TRAIN [0][1700/3416]	Time 0.055 (0.058)	Data 0.00116 (0.00100)	Tok/s 52188 (52376)	Loss/tok 3.7614 (4.9023)	Learning Rate [0.00125]
6: TRAIN [0][1700/3416]	Time 0.055 (0.058)	Data 0.00102 (0.00098)	Tok/s 53335 (52645)	Loss/tok 3.7746 (4.9121)	Learning Rate [0.00125]
4: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00093)	Tok/s 54124 (52488)	Loss/tok 3.7892 (4.9062)	Learning Rate [0.00125]
5: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00096)	Tok/s 54120 (52587)	Loss/tok 3.6393 (4.9157)	Learning Rate [0.00125]
2: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00097 (0.00099)	Tok/s 53974 (52299)	Loss/tok 3.8755 (4.9093)	Learning Rate [0.00125]
3: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00100)	Tok/s 54092 (52394)	Loss/tok 3.5579 (4.8952)	Learning Rate [0.00125]
6: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00098)	Tok/s 54133 (52662)	Loss/tok 3.8159 (4.9050)	Learning Rate [0.00125]
1: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00093)	Tok/s 53969 (52201)	Loss/tok 4.0205 (4.9043)	Learning Rate [0.00125]
0: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00092)	Tok/s 53979 (52092)	Loss/tok 3.7152 (4.9030)	Learning Rate [0.00125]
10: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00099 (0.00099)	Tok/s 54194 (52971)	Loss/tok 3.8270 (4.9089)	Learning Rate [0.00125]
8: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00099)	Tok/s 54140 (52829)	Loss/tok 3.6308 (4.9072)	Learning Rate [0.00125]
15: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00093)	Tok/s 54849 (53464)	Loss/tok 3.7805 (4.9036)	Learning Rate [0.00125]
9: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00094)	Tok/s 54142 (52889)	Loss/tok 3.9218 (4.9035)	Learning Rate [0.00125]
14: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00108 (0.00095)	Tok/s 53900 (53362)	Loss/tok 3.8033 (4.9075)	Learning Rate [0.00125]
7: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00116 (0.00093)	Tok/s 54231 (52750)	Loss/tok 4.0536 (4.9082)	Learning Rate [0.00125]
13: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00101 (0.00100)	Tok/s 54040 (53257)	Loss/tok 3.6222 (4.9103)	Learning Rate [0.00125]
12: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00097 (0.00100)	Tok/s 53999 (53160)	Loss/tok 3.6411 (4.9035)	Learning Rate [0.00125]
11: TRAIN [0][1710/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00099)	Tok/s 54270 (53049)	Loss/tok 3.8747 (4.9023)	Learning Rate [0.00125]
2: TRAIN [0][1720/3416]	Time 0.054 (0.058)	Data 0.00105 (0.00099)	Tok/s 50746 (52300)	Loss/tok 3.4686 (4.9023)	Learning Rate [0.00125]
4: TRAIN [0][1720/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00093)	Tok/s 50763 (52489)	Loss/tok 3.9244 (4.9001)	Learning Rate [0.00125]
5: TRAIN [0][1720/3416]	Time 0.054 (0.058)	Data 0.00103 (0.00096)	Tok/s 50687 (52587)	Loss/tok 3.7485 (4.9091)	Learning Rate [0.00125]
3: TRAIN [0][1720/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00100)	Tok/s 50739 (52395)	Loss/tok 3.4842 (4.8888)	Learning Rate [0.00125]
6: TRAIN [0][1720/3416]	Time 0.054 (0.058)	Data 0.00102 (0.00098)	Tok/s 50605 (52661)	Loss/tok 3.6785 (4.8982)	Learning Rate [0.00125]
15: TRAIN [0][1720/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00093)	Tok/s 50426 (53462)	Loss/tok 3.7490 (4.8972)	Learning Rate [0.00125]
1: TRAIN [0][1720/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00093)	Tok/s 49398 (52200)	Loss/tok 3.6469 (4.8976)	Learning Rate [0.00125]
7: TRAIN [0][1720/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00093)	Tok/s 50493 (52750)	Loss/tok 3.5451 (4.9018)	Learning Rate [0.00125]
0: TRAIN [0][1720/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00092)	Tok/s 49235 (52092)	Loss/tok 3.4860 (4.8961)	Learning Rate [0.00125]
10: TRAIN [0][1720/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00099)	Tok/s 50294 (52970)	Loss/tok 3.5286 (4.9027)	Learning Rate [0.00125]
8: TRAIN [0][1720/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00099)	Tok/s 50381 (52829)	Loss/tok 3.5905 (4.9007)	Learning Rate [0.00125]
14: TRAIN [0][1720/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00095)	Tok/s 50321 (53361)	Loss/tok 3.7379 (4.9008)	Learning Rate [0.00125]
12: TRAIN [0][1720/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00100)	Tok/s 50158 (53159)	Loss/tok 3.8004 (4.8966)	Learning Rate [0.00125]
9: TRAIN [0][1720/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00094)	Tok/s 50309 (52889)	Loss/tok 3.8150 (4.8966)	Learning Rate [0.00125]
11: TRAIN [0][1720/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00099)	Tok/s 50156 (53049)	Loss/tok 3.6388 (4.8964)	Learning Rate [0.00125]
13: TRAIN [0][1720/3416]	Time 0.055 (0.058)	Data 0.00110 (0.00100)	Tok/s 50162 (53256)	Loss/tok 3.7321 (4.9037)	Learning Rate [0.00125]
12: TRAIN [0][1730/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00100)	Tok/s 62720 (53172)	Loss/tok 3.6127 (4.8896)	Learning Rate [0.00125]
11: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00099)	Tok/s 62552 (53061)	Loss/tok 3.7025 (4.8890)	Learning Rate [0.00125]
13: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00115 (0.00100)	Tok/s 62584 (53269)	Loss/tok 3.7831 (4.8965)	Learning Rate [0.00125]
10: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00099)	Tok/s 62464 (52982)	Loss/tok 3.7912 (4.8950)	Learning Rate [0.00125]
15: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00093)	Tok/s 63483 (53475)	Loss/tok 3.9183 (4.8900)	Learning Rate [0.00125]
0: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 62558 (52105)	Loss/tok 4.0661 (4.8890)	Learning Rate [0.00125]
14: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00095)	Tok/s 62854 (53373)	Loss/tok 4.1808 (4.8936)	Learning Rate [0.00125]
2: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00099)	Tok/s 62587 (52313)	Loss/tok 3.5532 (4.8944)	Learning Rate [0.00125]
9: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00094)	Tok/s 62343 (52900)	Loss/tok 3.8722 (4.8897)	Learning Rate [0.00125]
8: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00099)	Tok/s 62356 (52841)	Loss/tok 3.9090 (4.8934)	Learning Rate [0.00125]
7: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00093)	Tok/s 62362 (52762)	Loss/tok 3.8677 (4.8946)	Learning Rate [0.00125]
1: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 62464 (52214)	Loss/tok 4.0385 (4.8905)	Learning Rate [0.00125]
5: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00096)	Tok/s 62369 (52600)	Loss/tok 3.9419 (4.9021)	Learning Rate [0.00125]
4: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00093)	Tok/s 62366 (52502)	Loss/tok 4.0217 (4.8929)	Learning Rate [0.00125]
6: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00098)	Tok/s 62323 (52674)	Loss/tok 3.9294 (4.8910)	Learning Rate [0.00125]
3: TRAIN [0][1730/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00100)	Tok/s 62362 (52408)	Loss/tok 3.9001 (4.8817)	Learning Rate [0.00125]
2: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00099)	Tok/s 55344 (52355)	Loss/tok 3.8596 (4.8866)	Learning Rate [0.00125]
4: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00093)	Tok/s 55456 (52543)	Loss/tok 3.8177 (4.8850)	Learning Rate [0.00125]
5: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00096)	Tok/s 55434 (52641)	Loss/tok 3.9293 (4.8945)	Learning Rate [0.00125]
3: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00100)	Tok/s 55400 (52450)	Loss/tok 3.9449 (4.8742)	Learning Rate [0.00125]
1: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 55350 (52255)	Loss/tok 3.9147 (4.8819)	Learning Rate [0.00125]
0: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 55378 (52147)	Loss/tok 3.7978 (4.8806)	Learning Rate [0.00125]
15: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00093)	Tok/s 55342 (53514)	Loss/tok 3.9670 (4.8822)	Learning Rate [0.00125]
7: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00093)	Tok/s 55432 (52803)	Loss/tok 3.7694 (4.8869)	Learning Rate [0.00125]
6: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00098)	Tok/s 55440 (52715)	Loss/tok 3.8765 (4.8826)	Learning Rate [0.00125]
14: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00095)	Tok/s 55402 (53412)	Loss/tok 3.6135 (4.8861)	Learning Rate [0.00125]
8: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00099)	Tok/s 55421 (52881)	Loss/tok 3.8718 (4.8854)	Learning Rate [0.00125]
13: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00100)	Tok/s 55399 (53308)	Loss/tok 3.9148 (4.8886)	Learning Rate [0.00125]
9: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00094)	Tok/s 55425 (52941)	Loss/tok 3.9778 (4.8821)	Learning Rate [0.00125]
12: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00100)	Tok/s 55348 (53211)	Loss/tok 3.7028 (4.8809)	Learning Rate [0.00125]
10: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00099)	Tok/s 55375 (53022)	Loss/tok 3.8239 (4.8869)	Learning Rate [0.00125]
11: TRAIN [0][1740/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00099)	Tok/s 55315 (53101)	Loss/tok 3.9748 (4.8815)	Learning Rate [0.00125]
11: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00107 (0.00099)	Tok/s 55490 (53115)	Loss/tok 3.8011 (4.8749)	Learning Rate [0.00125]
12: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00100)	Tok/s 55574 (53225)	Loss/tok 3.8369 (4.8740)	Learning Rate [0.00125]
13: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00100)	Tok/s 55602 (53322)	Loss/tok 3.7562 (4.8813)	Learning Rate [0.00125]
10: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00099)	Tok/s 55415 (53036)	Loss/tok 3.7066 (4.8799)	Learning Rate [0.00125]
14: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00108 (0.00095)	Tok/s 55607 (53425)	Loss/tok 3.9007 (4.8791)	Learning Rate [0.00125]
9: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00094)	Tok/s 55353 (52955)	Loss/tok 4.0073 (4.8754)	Learning Rate [0.00125]
15: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00093)	Tok/s 55557 (53527)	Loss/tok 3.7668 (4.8753)	Learning Rate [0.00125]
8: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00099)	Tok/s 55224 (52896)	Loss/tok 3.9724 (4.8789)	Learning Rate [0.00125]
7: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00093)	Tok/s 55256 (52818)	Loss/tok 3.7006 (4.8795)	Learning Rate [0.00125]
0: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00102 (0.00092)	Tok/s 55542 (52165)	Loss/tok 3.7883 (4.8735)	Learning Rate [0.00125]
1: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00093)	Tok/s 55475 (52273)	Loss/tok 3.8889 (4.8751)	Learning Rate [0.00125]
5: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00096)	Tok/s 55225 (52657)	Loss/tok 3.6058 (4.8873)	Learning Rate [0.00125]
4: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00093)	Tok/s 55262 (52559)	Loss/tok 4.0380 (4.8780)	Learning Rate [0.00125]
2: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00099)	Tok/s 55383 (52372)	Loss/tok 3.8948 (4.8795)	Learning Rate [0.00125]
6: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00098)	Tok/s 55210 (52730)	Loss/tok 3.9517 (4.8757)	Learning Rate [0.00125]
3: TRAIN [0][1750/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00099)	Tok/s 55259 (52467)	Loss/tok 3.7078 (4.8670)	Learning Rate [0.00125]
8: TRAIN [0][1760/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00099)	Tok/s 56833 (52894)	Loss/tok 3.9109 (4.8729)	Learning Rate [0.00125]
9: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00094)	Tok/s 56746 (52953)	Loss/tok 3.6336 (4.8689)	Learning Rate [0.00125]
7: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00093)	Tok/s 56768 (52817)	Loss/tok 3.7705 (4.8730)	Learning Rate [0.00125]
10: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00099)	Tok/s 56682 (53033)	Loss/tok 3.9264 (4.8742)	Learning Rate [0.00125]
5: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00096)	Tok/s 56600 (52657)	Loss/tok 3.8390 (4.8810)	Learning Rate [0.00125]
6: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00098)	Tok/s 56703 (52729)	Loss/tok 3.9225 (4.8697)	Learning Rate [0.00125]
11: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00099)	Tok/s 56537 (53112)	Loss/tok 3.9570 (4.8691)	Learning Rate [0.00125]
4: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00092)	Tok/s 56498 (52559)	Loss/tok 3.6910 (4.8717)	Learning Rate [0.00125]
12: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00100)	Tok/s 56482 (53222)	Loss/tok 3.8453 (4.8676)	Learning Rate [0.00125]
14: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00095)	Tok/s 56290 (53423)	Loss/tok 3.6661 (4.8727)	Learning Rate [0.00125]
2: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00099)	Tok/s 56334 (52373)	Loss/tok 3.5924 (4.8731)	Learning Rate [0.00125]
13: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00104 (0.00100)	Tok/s 56379 (53319)	Loss/tok 3.9434 (4.8752)	Learning Rate [0.00125]
3: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00099)	Tok/s 56406 (52467)	Loss/tok 3.8586 (4.8609)	Learning Rate [0.00125]
15: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00093)	Tok/s 56172 (53524)	Loss/tok 3.5798 (4.8688)	Learning Rate [0.00125]
1: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00093)	Tok/s 56228 (52273)	Loss/tok 3.8473 (4.8684)	Learning Rate [0.00125]
0: TRAIN [0][1760/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00092)	Tok/s 56014 (52165)	Loss/tok 3.8689 (4.8672)	Learning Rate [0.00125]
0: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
9: Upscaling, new scale: 1024.0
4: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00085 (0.00092)	Tok/s 27707 (52587)	Loss/tok 2.7712 (4.8637)	Learning Rate [0.00125]
3: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00099 (0.00099)	Tok/s 27719 (52495)	Loss/tok 2.7878 (4.8527)	Learning Rate [0.00125]
2: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00104 (0.00099)	Tok/s 27561 (52402)	Loss/tok 2.7793 (4.8648)	Learning Rate [0.00125]
5: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00092 (0.00096)	Tok/s 28981 (52686)	Loss/tok 2.9170 (4.8726)	Learning Rate [0.00125]
1: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00092 (0.00093)	Tok/s 27543 (52302)	Loss/tok 2.9877 (4.8604)	Learning Rate [0.00125]
6: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00095 (0.00098)	Tok/s 29162 (52759)	Loss/tok 2.9252 (4.8620)	Learning Rate [0.00125]
15: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00098 (0.00093)	Tok/s 30400 (53554)	Loss/tok 3.0287 (4.8608)	Learning Rate [0.00125]
0: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00092 (0.00092)	Tok/s 27446 (52194)	Loss/tok 2.7974 (4.8594)	Learning Rate [0.00125]
7: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00092 (0.00093)	Tok/s 29100 (52845)	Loss/tok 2.9975 (4.8646)	Learning Rate [0.00125]
8: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00097 (0.00099)	Tok/s 29027 (52922)	Loss/tok 2.8000 (4.8644)	Learning Rate [0.00125]
13: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00104 (0.00100)	Tok/s 29214 (53349)	Loss/tok 2.9985 (4.8668)	Learning Rate [0.00125]
14: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00090 (0.00095)	Tok/s 30315 (53453)	Loss/tok 2.8682 (4.8645)	Learning Rate [0.00125]
9: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00095 (0.00094)	Tok/s 28960 (52981)	Loss/tok 3.2223 (4.8613)	Learning Rate [0.00125]
10: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00094 (0.00099)	Tok/s 28878 (53062)	Loss/tok 2.7845 (4.8665)	Learning Rate [0.00125]
12: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00090 (0.00100)	Tok/s 28798 (53251)	Loss/tok 3.0540 (4.8599)	Learning Rate [0.00125]
11: TRAIN [0][1770/3416]	Time 0.042 (0.058)	Data 0.00107 (0.00099)	Tok/s 28824 (53141)	Loss/tok 3.0664 (4.8612)	Learning Rate [0.00125]
4: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00092)	Tok/s 78779 (52599)	Loss/tok 3.7876 (4.8571)	Learning Rate [0.00125]
2: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 78670 (52413)	Loss/tok 3.6390 (4.8574)	Learning Rate [0.00125]
5: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 78761 (52698)	Loss/tok 3.7297 (4.8661)	Learning Rate [0.00125]
6: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 78827 (52769)	Loss/tok 3.6603 (4.8555)	Learning Rate [0.00125]
3: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00099)	Tok/s 78647 (52507)	Loss/tok 3.9718 (4.8462)	Learning Rate [0.00125]
1: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00093)	Tok/s 77959 (52313)	Loss/tok 3.7184 (4.8535)	Learning Rate [0.00125]
0: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 77742 (52206)	Loss/tok 3.7829 (4.8520)	Learning Rate [0.00125]
7: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 78802 (52856)	Loss/tok 3.7302 (4.8580)	Learning Rate [0.00125]
15: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 79560 (53566)	Loss/tok 3.9444 (4.8542)	Learning Rate [0.00125]
8: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 78742 (52934)	Loss/tok 3.6860 (4.8568)	Learning Rate [0.00125]
9: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00094)	Tok/s 79156 (52993)	Loss/tok 3.8321 (4.8542)	Learning Rate [0.00125]
14: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00095)	Tok/s 79567 (53465)	Loss/tok 3.6285 (4.8572)	Learning Rate [0.00125]
10: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00099)	Tok/s 79612 (53074)	Loss/tok 3.4733 (4.8591)	Learning Rate [0.00125]
13: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 79546 (53361)	Loss/tok 3.6658 (4.8602)	Learning Rate [0.00125]
12: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 79567 (53263)	Loss/tok 3.8439 (4.8530)	Learning Rate [0.00125]
11: TRAIN [0][1780/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 79728 (53152)	Loss/tok 3.7486 (4.8540)	Learning Rate [0.00125]
15: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00093)	Tok/s 51324 (53553)	Loss/tok 3.4265 (4.8477)	Learning Rate [0.00125]
14: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00096)	Tok/s 51291 (53452)	Loss/tok 3.6575 (4.8511)	Learning Rate [0.00125]
0: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00092)	Tok/s 50045 (52193)	Loss/tok 3.5830 (4.8457)	Learning Rate [0.00125]
13: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00108 (0.00100)	Tok/s 51171 (53348)	Loss/tok 3.3011 (4.8539)	Learning Rate [0.00125]
12: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00100)	Tok/s 51083 (53249)	Loss/tok 3.3787 (4.8467)	Learning Rate [0.00125]
1: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00093)	Tok/s 49970 (52300)	Loss/tok 3.8518 (4.8471)	Learning Rate [0.00125]
11: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00099)	Tok/s 50955 (53138)	Loss/tok 3.8422 (4.8482)	Learning Rate [0.00125]
10: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00099)	Tok/s 50919 (53060)	Loss/tok 3.8783 (4.8526)	Learning Rate [0.00125]
2: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00099)	Tok/s 51186 (52400)	Loss/tok 3.7453 (4.8514)	Learning Rate [0.00125]
9: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00094)	Tok/s 50946 (52979)	Loss/tok 3.5969 (4.8480)	Learning Rate [0.00125]
4: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00093)	Tok/s 51083 (52586)	Loss/tok 3.6645 (4.8509)	Learning Rate [0.00125]
5: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00096)	Tok/s 51015 (52684)	Loss/tok 3.6813 (4.8601)	Learning Rate [0.00125]
7: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00093)	Tok/s 50929 (52843)	Loss/tok 3.7126 (4.8519)	Learning Rate [0.00125]
6: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00098)	Tok/s 50932 (52756)	Loss/tok 3.7869 (4.8499)	Learning Rate [0.00125]
8: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00099)	Tok/s 50952 (52920)	Loss/tok 3.4159 (4.8505)	Learning Rate [0.00125]
3: TRAIN [0][1790/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00099)	Tok/s 51206 (52494)	Loss/tok 3.8647 (4.8406)	Learning Rate [0.00125]
0: TRAIN [0][1800/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00092)	Tok/s 51038 (52210)	Loss/tok 3.8044 (4.8387)	Learning Rate [0.00125]
2: TRAIN [0][1800/3416]	Time 0.056 (0.058)	Data 0.00122 (0.00099)	Tok/s 51853 (52418)	Loss/tok 3.7568 (4.8443)	Learning Rate [0.00125]
15: TRAIN [0][1800/3416]	Time 0.057 (0.058)	Data 0.00089 (0.00093)	Tok/s 52047 (53570)	Loss/tok 3.6028 (4.8413)	Learning Rate [0.00125]
1: TRAIN [0][1800/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00093)	Tok/s 51010 (52316)	Loss/tok 3.7969 (4.8401)	Learning Rate [0.00125]
4: TRAIN [0][1800/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00093)	Tok/s 51925 (52603)	Loss/tok 3.6937 (4.8440)	Learning Rate [0.00125]
3: TRAIN [0][1800/3416]	Time 0.057 (0.058)	Data 0.00109 (0.00099)	Tok/s 52040 (52512)	Loss/tok 3.9969 (4.8334)	Learning Rate [0.00125]
5: TRAIN [0][1800/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00096)	Tok/s 51813 (52701)	Loss/tok 3.9393 (4.8529)	Learning Rate [0.00125]
13: TRAIN [0][1800/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00100)	Tok/s 51643 (53365)	Loss/tok 3.4943 (4.8463)	Learning Rate [0.00125]
12: TRAIN [0][1800/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00100)	Tok/s 51641 (53266)	Loss/tok 3.7297 (4.8391)	Learning Rate [0.00125]
14: TRAIN [0][1800/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00096)	Tok/s 51874 (53468)	Loss/tok 3.5962 (4.8439)	Learning Rate [0.00125]
7: TRAIN [0][1800/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00093)	Tok/s 51616 (52860)	Loss/tok 3.4188 (4.8446)	Learning Rate [0.00125]
6: TRAIN [0][1800/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00098)	Tok/s 51710 (52773)	Loss/tok 3.7040 (4.8426)	Learning Rate [0.00125]
11: TRAIN [0][1800/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00099)	Tok/s 51555 (53155)	Loss/tok 3.6386 (4.8410)	Learning Rate [0.00125]
10: TRAIN [0][1800/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00099)	Tok/s 51433 (53078)	Loss/tok 3.8120 (4.8456)	Learning Rate [0.00125]
9: TRAIN [0][1800/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00093)	Tok/s 51448 (52997)	Loss/tok 3.8703 (4.8409)	Learning Rate [0.00125]
8: TRAIN [0][1800/3416]	Time 0.056 (0.058)	Data 0.00124 (0.00099)	Tok/s 52285 (52938)	Loss/tok 3.8801 (4.8433)	Learning Rate [0.00125]
5: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00108 (0.00096)	Tok/s 49775 (52720)	Loss/tok 3.4084 (4.8462)	Learning Rate [0.00125]
6: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00098)	Tok/s 49792 (52792)	Loss/tok 3.5783 (4.8363)	Learning Rate [0.00125]
8: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00102 (0.00099)	Tok/s 49798 (52957)	Loss/tok 3.2838 (4.8366)	Learning Rate [0.00125]
7: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00102 (0.00093)	Tok/s 49776 (52879)	Loss/tok 3.5462 (4.8380)	Learning Rate [0.00125]
3: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00099)	Tok/s 48425 (52531)	Loss/tok 3.5059 (4.8265)	Learning Rate [0.00125]
10: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00099)	Tok/s 49794 (53098)	Loss/tok 3.5971 (4.8391)	Learning Rate [0.00125]
2: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00099)	Tok/s 48414 (52437)	Loss/tok 3.5196 (4.8376)	Learning Rate [0.00125]
9: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00094)	Tok/s 49771 (53016)	Loss/tok 3.5792 (4.8342)	Learning Rate [0.00125]
1: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00111 (0.00093)	Tok/s 48366 (52337)	Loss/tok 3.3631 (4.8330)	Learning Rate [0.00125]
11: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00099)	Tok/s 49728 (53175)	Loss/tok 3.6995 (4.8341)	Learning Rate [0.00125]
0: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00112 (0.00092)	Tok/s 48389 (52230)	Loss/tok 3.6364 (4.8321)	Learning Rate [0.00125]
15: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00106 (0.00093)	Tok/s 49744 (53588)	Loss/tok 3.3179 (4.8345)	Learning Rate [0.00125]
13: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00118 (0.00100)	Tok/s 49752 (53384)	Loss/tok 3.4245 (4.8396)	Learning Rate [0.00125]
14: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00109 (0.00096)	Tok/s 49762 (53487)	Loss/tok 3.5756 (4.8376)	Learning Rate [0.00125]
4: TRAIN [0][1810/3416]	Time 0.047 (0.058)	Data 0.00131 (0.00093)	Tok/s 48093 (52621)	Loss/tok 3.4526 (4.8371)	Learning Rate [0.00125]
12: TRAIN [0][1810/3416]	Time 0.046 (0.058)	Data 0.00115 (0.00100)	Tok/s 49784 (53285)	Loss/tok 3.6338 (4.8322)	Learning Rate [0.00125]
12: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00100)	Tok/s 49945 (53342)	Loss/tok 3.8188 (4.8243)	Learning Rate [0.00125]
13: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00100)	Tok/s 50886 (53441)	Loss/tok 3.6629 (4.8313)	Learning Rate [0.00125]
11: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00099)	Tok/s 49957 (53231)	Loss/tok 3.7502 (4.8261)	Learning Rate [0.00125]
10: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00099)	Tok/s 49887 (53154)	Loss/tok 3.4551 (4.8305)	Learning Rate [0.00125]
14: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00096)	Tok/s 51383 (53544)	Loss/tok 3.6266 (4.8299)	Learning Rate [0.00125]
9: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00094)	Tok/s 49941 (53072)	Loss/tok 3.6942 (4.8266)	Learning Rate [0.00125]
8: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00099)	Tok/s 49972 (53012)	Loss/tok 3.3329 (4.8283)	Learning Rate [0.00125]
0: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00092)	Tok/s 49974 (52286)	Loss/tok 3.7128 (4.8246)	Learning Rate [0.00125]
15: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00082 (0.00093)	Tok/s 51363 (53646)	Loss/tok 3.4307 (4.8266)	Learning Rate [0.00125]
1: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00093)	Tok/s 49971 (52393)	Loss/tok 3.6456 (4.8252)	Learning Rate [0.00125]
7: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00080 (0.00093)	Tok/s 49962 (52934)	Loss/tok 3.3298 (4.8303)	Learning Rate [0.00125]
2: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00099)	Tok/s 50116 (52493)	Loss/tok 3.4493 (4.8298)	Learning Rate [0.00125]
6: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00098)	Tok/s 50007 (52848)	Loss/tok 3.9575 (4.8286)	Learning Rate [0.00125]
4: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00105 (0.00093)	Tok/s 49975 (52678)	Loss/tok 3.5082 (4.8292)	Learning Rate [0.00125]
3: TRAIN [0][1820/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00099)	Tok/s 49980 (52587)	Loss/tok 3.2556 (4.8187)	Learning Rate [0.00125]
5: TRAIN [0][1820/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00096)	Tok/s 49518 (52776)	Loss/tok 3.2775 (4.8379)	Learning Rate [0.00125]
13: Gradient norm: inf
12: Gradient norm: inf
14: Gradient norm: inf
13: Skipped batch, new scale: 512.0
12: Skipped batch, new scale: 512.0
11: Gradient norm: inf
15: Gradient norm: inf
14: Skipped batch, new scale: 512.0
11: Skipped batch, new scale: 512.0
10: Gradient norm: inf
15: Skipped batch, new scale: 512.0
0: Gradient norm: inf
9: Gradient norm: inf
10: Skipped batch, new scale: 512.0
0: Skipped batch, new scale: 512.0
1: Gradient norm: inf
9: Skipped batch, new scale: 512.0
8: Gradient norm: inf
1: Skipped batch, new scale: 512.0
2: Gradient norm: inf
8: Skipped batch, new scale: 512.0
2: Skipped batch, new scale: 512.0
3: Gradient norm: inf
6: Gradient norm: inf
4: Gradient norm: inf
5: Gradient norm: inf
3: Skipped batch, new scale: 512.0
6: Skipped batch, new scale: 512.0
7: Gradient norm: inf
4: Skipped batch, new scale: 512.0
5: Skipped batch, new scale: 512.0
7: Skipped batch, new scale: 512.0
2: TRAIN [0][1830/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00099)	Tok/s 39092 (52506)	Loss/tok 3.4949 (4.8233)	Learning Rate [0.00125]
1: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00093)	Tok/s 38312 (52406)	Loss/tok 3.2324 (4.8192)	Learning Rate [0.00125]
0: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 37605 (52299)	Loss/tok 3.1918 (4.8178)	Learning Rate [0.00125]
3: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00107 (0.00099)	Tok/s 39063 (52600)	Loss/tok 3.6530 (4.8122)	Learning Rate [0.00125]
4: TRAIN [0][1830/3416]	Time 0.047 (0.058)	Data 0.00137 (0.00093)	Tok/s 39103 (52691)	Loss/tok 3.5652 (4.8226)	Learning Rate [0.00125]
15: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00093)	Tok/s 38815 (53659)	Loss/tok 3.5384 (4.8197)	Learning Rate [0.00125]
5: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00096)	Tok/s 39060 (52789)	Loss/tok 3.3835 (4.8311)	Learning Rate [0.00125]
14: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00109 (0.00096)	Tok/s 38760 (53557)	Loss/tok 3.3185 (4.8235)	Learning Rate [0.00125]
13: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00100)	Tok/s 38678 (53453)	Loss/tok 3.6292 (4.8251)	Learning Rate [0.00125]
7: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00093)	Tok/s 38969 (52947)	Loss/tok 3.3514 (4.8243)	Learning Rate [0.00125]
6: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00107 (0.00098)	Tok/s 38902 (52861)	Loss/tok 3.3091 (4.8217)	Learning Rate [0.00125]
12: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00109 (0.00100)	Tok/s 38656 (53355)	Loss/tok 3.4798 (4.8180)	Learning Rate [0.00125]
8: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00099)	Tok/s 38800 (53026)	Loss/tok 3.5190 (4.8214)	Learning Rate [0.00125]
10: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00099)	Tok/s 38693 (53168)	Loss/tok 3.1769 (4.8235)	Learning Rate [0.00125]
11: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00110 (0.00099)	Tok/s 38623 (53245)	Loss/tok 3.2187 (4.8194)	Learning Rate [0.00125]
9: TRAIN [0][1830/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00094)	Tok/s 38688 (53086)	Loss/tok 3.4183 (4.8196)	Learning Rate [0.00125]
0: TRAIN [0][1840/3416]	Time 0.043 (0.058)	Data 0.00087 (0.00092)	Tok/s 47486 (52334)	Loss/tok 3.3543 (4.8108)	Learning Rate [0.00125]
14: TRAIN [0][1840/3416]	Time 0.043 (0.058)	Data 0.00089 (0.00096)	Tok/s 48937 (53592)	Loss/tok 3.6159 (4.8157)	Learning Rate [0.00125]
5: TRAIN [0][1840/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00096)	Tok/s 48591 (52823)	Loss/tok 3.4499 (4.8238)	Learning Rate [0.00125]
3: TRAIN [0][1840/3416]	Time 0.043 (0.058)	Data 0.00091 (0.00099)	Tok/s 48671 (52634)	Loss/tok 3.5262 (4.8053)	Learning Rate [0.00125]
15: TRAIN [0][1840/3416]	Time 0.043 (0.058)	Data 0.00086 (0.00093)	Tok/s 48820 (53694)	Loss/tok 3.4820 (4.8126)	Learning Rate [0.00125]
1: TRAIN [0][1840/3416]	Time 0.043 (0.058)	Data 0.00086 (0.00093)	Tok/s 47282 (52440)	Loss/tok 3.4952 (4.8122)	Learning Rate [0.00125]
4: TRAIN [0][1840/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00093)	Tok/s 48640 (52725)	Loss/tok 3.3816 (4.8151)	Learning Rate [0.00125]
2: TRAIN [0][1840/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00099)	Tok/s 48498 (52541)	Loss/tok 3.3707 (4.8156)	Learning Rate [0.00125]
13: TRAIN [0][1840/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00100)	Tok/s 48813 (53488)	Loss/tok 3.4712 (4.8178)	Learning Rate [0.00125]
6: TRAIN [0][1840/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00098)	Tok/s 48466 (52894)	Loss/tok 3.4275 (4.8143)	Learning Rate [0.00125]
7: TRAIN [0][1840/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00093)	Tok/s 48398 (52980)	Loss/tok 3.6163 (4.8170)	Learning Rate [0.00125]
8: TRAIN [0][1840/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00099)	Tok/s 48426 (53059)	Loss/tok 3.4094 (4.8144)	Learning Rate [0.00125]
12: TRAIN [0][1840/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00100)	Tok/s 48679 (53390)	Loss/tok 3.2055 (4.8098)	Learning Rate [0.00125]
11: TRAIN [0][1840/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00099)	Tok/s 48603 (53279)	Loss/tok 3.2638 (4.8120)	Learning Rate [0.00125]
10: TRAIN [0][1840/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00099)	Tok/s 48465 (53202)	Loss/tok 3.4487 (4.8163)	Learning Rate [0.00125]
9: TRAIN [0][1840/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00094)	Tok/s 48414 (53119)	Loss/tok 3.5357 (4.8124)	Learning Rate [0.00125]
7: TRAIN [0][1850/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00093)	Tok/s 33066 (52985)	Loss/tok 3.2762 (4.8106)	Learning Rate [0.00125]
8: TRAIN [0][1850/3416]	Time 0.050 (0.058)	Data 0.00112 (0.00099)	Tok/s 32997 (53063)	Loss/tok 3.3004 (4.8080)	Learning Rate [0.00125]
6: TRAIN [0][1850/3416]	Time 0.050 (0.058)	Data 0.00111 (0.00098)	Tok/s 33094 (52899)	Loss/tok 3.4041 (4.8082)	Learning Rate [0.00125]
5: TRAIN [0][1850/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00096)	Tok/s 33045 (52828)	Loss/tok 3.4921 (4.8175)	Learning Rate [0.00125]
9: TRAIN [0][1850/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00094)	Tok/s 32912 (53123)	Loss/tok 3.3267 (4.8067)	Learning Rate [0.00125]
4: TRAIN [0][1850/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00093)	Tok/s 32947 (52730)	Loss/tok 3.3568 (4.8090)	Learning Rate [0.00125]
3: TRAIN [0][1850/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00099)	Tok/s 32816 (52640)	Loss/tok 3.2164 (4.7989)	Learning Rate [0.00125]
11: TRAIN [0][1850/3416]	Time 0.051 (0.058)	Data 0.00119 (0.00099)	Tok/s 32784 (53283)	Loss/tok 3.3011 (4.8057)	Learning Rate [0.00125]
2: TRAIN [0][1850/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00099)	Tok/s 32810 (52546)	Loss/tok 3.1718 (4.8096)	Learning Rate [0.00125]
12: TRAIN [0][1850/3416]	Time 0.051 (0.058)	Data 0.00109 (0.00100)	Tok/s 33714 (53394)	Loss/tok 3.2631 (4.8039)	Learning Rate [0.00125]
1: TRAIN [0][1850/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00093)	Tok/s 32742 (52445)	Loss/tok 3.1373 (4.8058)	Learning Rate [0.00125]
13: TRAIN [0][1850/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00100)	Tok/s 33882 (53492)	Loss/tok 3.2166 (4.8119)	Learning Rate [0.00125]
0: TRAIN [0][1850/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00092)	Tok/s 32856 (52340)	Loss/tok 3.2611 (4.8049)	Learning Rate [0.00125]
14: TRAIN [0][1850/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00095)	Tok/s 33781 (53597)	Loss/tok 3.1598 (4.8097)	Learning Rate [0.00125]
10: TRAIN [0][1850/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00099)	Tok/s 32809 (53206)	Loss/tok 3.4147 (4.8101)	Learning Rate [0.00125]
15: TRAIN [0][1850/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00093)	Tok/s 33839 (53699)	Loss/tok 3.1280 (4.8066)	Learning Rate [0.00125]
14: TRAIN [0][1860/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00095)	Tok/s 52503 (53582)	Loss/tok 3.5107 (4.8033)	Learning Rate [0.00125]
13: TRAIN [0][1860/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00100)	Tok/s 52463 (53477)	Loss/tok 3.5205 (4.8061)	Learning Rate [0.00125]
15: TRAIN [0][1860/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00093)	Tok/s 52839 (53684)	Loss/tok 3.5797 (4.8003)	Learning Rate [0.00125]
12: TRAIN [0][1860/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00100)	Tok/s 52275 (53378)	Loss/tok 3.6449 (4.7980)	Learning Rate [0.00125]
0: TRAIN [0][1860/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00092)	Tok/s 52450 (52323)	Loss/tok 3.8031 (4.7990)	Learning Rate [0.00125]
11: TRAIN [0][1860/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00099)	Tok/s 52221 (53267)	Loss/tok 3.6277 (4.7994)	Learning Rate [0.00125]
10: TRAIN [0][1860/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00099)	Tok/s 52105 (53190)	Loss/tok 3.4579 (4.8039)	Learning Rate [0.00125]
2: TRAIN [0][1860/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00099)	Tok/s 52310 (52531)	Loss/tok 3.8223 (4.8040)	Learning Rate [0.00125]
1: TRAIN [0][1860/3416]	Time 0.051 (0.058)	Data 0.00112 (0.00093)	Tok/s 52518 (52429)	Loss/tok 3.1896 (4.7997)	Learning Rate [0.00125]
9: TRAIN [0][1860/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00094)	Tok/s 51990 (53107)	Loss/tok 3.6474 (4.8014)	Learning Rate [0.00125]
8: TRAIN [0][1860/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00099)	Tok/s 51977 (53047)	Loss/tok 3.7066 (4.8018)	Learning Rate [0.00125]
3: TRAIN [0][1860/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00099)	Tok/s 52249 (52623)	Loss/tok 3.6877 (4.7927)	Learning Rate [0.00125]
4: TRAIN [0][1860/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00093)	Tok/s 52146 (52714)	Loss/tok 3.7942 (4.8028)	Learning Rate [0.00125]
7: TRAIN [0][1860/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00093)	Tok/s 51988 (52968)	Loss/tok 3.6262 (4.8046)	Learning Rate [0.00125]
5: TRAIN [0][1860/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00096)	Tok/s 52061 (52812)	Loss/tok 3.5335 (4.8111)	Learning Rate [0.00125]
6: TRAIN [0][1860/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00098)	Tok/s 52006 (52883)	Loss/tok 3.3575 (4.8021)	Learning Rate [0.00125]
3: TRAIN [0][1870/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00099)	Tok/s 65054 (52619)	Loss/tok 3.7402 (4.7868)	Learning Rate [0.00125]
5: TRAIN [0][1870/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 64905 (52809)	Loss/tok 3.8869 (4.8054)	Learning Rate [0.00125]
2: TRAIN [0][1870/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 64976 (52526)	Loss/tok 4.0017 (4.7987)	Learning Rate [0.00125]
4: TRAIN [0][1870/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 64967 (52710)	Loss/tok 4.1385 (4.7970)	Learning Rate [0.00125]
6: TRAIN [0][1870/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 64833 (52880)	Loss/tok 3.8235 (4.7957)	Learning Rate [0.00125]
1: TRAIN [0][1870/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00093)	Tok/s 64340 (52422)	Loss/tok 3.7588 (4.7937)	Learning Rate [0.00125]
7: TRAIN [0][1870/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00093)	Tok/s 64716 (52965)	Loss/tok 3.7737 (4.7983)	Learning Rate [0.00125]
0: TRAIN [0][1870/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 63834 (52314)	Loss/tok 3.7854 (4.7934)	Learning Rate [0.00125]
8: TRAIN [0][1870/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00099)	Tok/s 64611 (53045)	Loss/tok 3.9840 (4.7966)	Learning Rate [0.00125]
15: TRAIN [0][1870/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 64689 (53681)	Loss/tok 3.7326 (4.7946)	Learning Rate [0.00125]
14: TRAIN [0][1870/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00095)	Tok/s 64491 (53579)	Loss/tok 4.0968 (4.7980)	Learning Rate [0.00125]
9: TRAIN [0][1870/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00094)	Tok/s 64533 (53104)	Loss/tok 3.5447 (4.7957)	Learning Rate [0.00125]
10: TRAIN [0][1870/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00099)	Tok/s 64425 (53187)	Loss/tok 3.8456 (4.7980)	Learning Rate [0.00125]
12: TRAIN [0][1870/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00100)	Tok/s 64419 (53376)	Loss/tok 4.0500 (4.7929)	Learning Rate [0.00125]
13: TRAIN [0][1870/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 64481 (53474)	Loss/tok 3.7281 (4.8003)	Learning Rate [0.00125]
11: TRAIN [0][1870/3416]	Time 0.070 (0.058)	Data 0.00117 (0.00099)	Tok/s 64327 (53264)	Loss/tok 3.8257 (4.7934)	Learning Rate [0.00125]
3: TRAIN [0][1880/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00099)	Tok/s 70956 (52667)	Loss/tok 3.6741 (4.7796)	Learning Rate [0.00125]
4: TRAIN [0][1880/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00093)	Tok/s 71083 (52758)	Loss/tok 3.8552 (4.7896)	Learning Rate [0.00125]
2: TRAIN [0][1880/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 70976 (52574)	Loss/tok 3.8539 (4.7913)	Learning Rate [0.00125]
11: TRAIN [0][1880/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00099)	Tok/s 71870 (53314)	Loss/tok 3.6261 (4.7861)	Learning Rate [0.00125]
12: TRAIN [0][1880/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 71904 (53425)	Loss/tok 3.8453 (4.7856)	Learning Rate [0.00125]
5: TRAIN [0][1880/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 70770 (52856)	Loss/tok 3.9441 (4.7986)	Learning Rate [0.00125]
10: TRAIN [0][1880/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00099)	Tok/s 71748 (53237)	Loss/tok 3.7833 (4.7906)	Learning Rate [0.00125]
1: TRAIN [0][1880/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 70982 (52471)	Loss/tok 3.8853 (4.7869)	Learning Rate [0.00125]
13: TRAIN [0][1880/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 71901 (53523)	Loss/tok 3.6929 (4.7928)	Learning Rate [0.00125]
0: TRAIN [0][1880/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 71003 (52364)	Loss/tok 3.8339 (4.7866)	Learning Rate [0.00125]
14: TRAIN [0][1880/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00095)	Tok/s 71857 (53628)	Loss/tok 4.0009 (4.7911)	Learning Rate [0.00125]
6: TRAIN [0][1880/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 71146 (52928)	Loss/tok 3.9894 (4.7890)	Learning Rate [0.00125]
9: TRAIN [0][1880/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00094)	Tok/s 71632 (53152)	Loss/tok 3.8325 (4.7886)	Learning Rate [0.00125]
15: TRAIN [0][1880/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 71922 (53730)	Loss/tok 3.8332 (4.7872)	Learning Rate [0.00125]
8: TRAIN [0][1880/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00099)	Tok/s 71537 (53093)	Loss/tok 3.9767 (4.7898)	Learning Rate [0.00125]
7: TRAIN [0][1880/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00093)	Tok/s 71467 (53013)	Loss/tok 3.7371 (4.7912)	Learning Rate [0.00125]
12: TRAIN [0][1890/3416]	Time 0.064 (0.058)	Data 0.00118 (0.00100)	Tok/s 54736 (53412)	Loss/tok 3.7227 (4.7803)	Learning Rate [0.00125]
11: TRAIN [0][1890/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00099)	Tok/s 54795 (53299)	Loss/tok 3.7105 (4.7804)	Learning Rate [0.00125]
13: TRAIN [0][1890/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00100)	Tok/s 54612 (53509)	Loss/tok 3.7584 (4.7872)	Learning Rate [0.00125]
10: TRAIN [0][1890/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00099)	Tok/s 54680 (53222)	Loss/tok 3.6566 (4.7852)	Learning Rate [0.00125]
8: TRAIN [0][1890/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00099)	Tok/s 54560 (53079)	Loss/tok 3.7027 (4.7839)	Learning Rate [0.00125]
14: TRAIN [0][1890/3416]	Time 0.065 (0.058)	Data 0.00104 (0.00095)	Tok/s 54483 (53614)	Loss/tok 3.9227 (4.7855)	Learning Rate [0.00125]
0: TRAIN [0][1890/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00092)	Tok/s 54502 (52344)	Loss/tok 3.7977 (4.7814)	Learning Rate [0.00125]
15: TRAIN [0][1890/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00093)	Tok/s 54468 (53716)	Loss/tok 3.6136 (4.7814)	Learning Rate [0.00125]
5: TRAIN [0][1890/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00096)	Tok/s 54292 (52841)	Loss/tok 3.6151 (4.7928)	Learning Rate [0.00125]
2: TRAIN [0][1890/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00099)	Tok/s 54170 (52557)	Loss/tok 3.7088 (4.7859)	Learning Rate [0.00125]
6: TRAIN [0][1890/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00098)	Tok/s 54411 (52913)	Loss/tok 3.5495 (4.7834)	Learning Rate [0.00125]
7: TRAIN [0][1890/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00093)	Tok/s 54443 (52999)	Loss/tok 3.8268 (4.7860)	Learning Rate [0.00125]
9: TRAIN [0][1890/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00094)	Tok/s 54562 (53138)	Loss/tok 3.8773 (4.7830)	Learning Rate [0.00125]
1: TRAIN [0][1890/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00093)	Tok/s 54289 (52453)	Loss/tok 3.7707 (4.7813)	Learning Rate [0.00125]
3: TRAIN [0][1890/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00099)	Tok/s 54160 (52650)	Loss/tok 3.8027 (4.7748)	Learning Rate [0.00125]
4: TRAIN [0][1890/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00093)	Tok/s 54168 (52741)	Loss/tok 3.6177 (4.7839)	Learning Rate [0.00125]
14: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00095)	Tok/s 62619 (53616)	Loss/tok 3.9039 (4.7796)	Learning Rate [0.00125]
15: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 63459 (53718)	Loss/tok 3.7736 (4.7756)	Learning Rate [0.00125]
11: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 62760 (53301)	Loss/tok 3.7069 (4.7744)	Learning Rate [0.00125]
12: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00115 (0.00100)	Tok/s 62600 (53414)	Loss/tok 3.6216 (4.7743)	Learning Rate [0.00125]
10: TRAIN [0][1900/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00099)	Tok/s 62700 (53224)	Loss/tok 3.9067 (4.7794)	Learning Rate [0.00125]
0: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 62442 (52347)	Loss/tok 3.4756 (4.7756)	Learning Rate [0.00125]
13: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00100)	Tok/s 62591 (53512)	Loss/tok 4.1708 (4.7814)	Learning Rate [0.00125]
9: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00094)	Tok/s 62609 (53140)	Loss/tok 3.8277 (4.7773)	Learning Rate [0.00125]
8: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00099)	Tok/s 62472 (53081)	Loss/tok 4.1474 (4.7786)	Learning Rate [0.00125]
1: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 62323 (52455)	Loss/tok 3.8754 (4.7757)	Learning Rate [0.00125]
2: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00099)	Tok/s 62223 (52559)	Loss/tok 3.9383 (4.7800)	Learning Rate [0.00125]
7: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 62537 (53000)	Loss/tok 3.9930 (4.7801)	Learning Rate [0.00125]
4: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 62152 (52743)	Loss/tok 4.0581 (4.7785)	Learning Rate [0.00125]
5: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00096)	Tok/s 62201 (52842)	Loss/tok 3.9533 (4.7870)	Learning Rate [0.00125]
3: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00099)	Tok/s 62131 (52652)	Loss/tok 3.7310 (4.7693)	Learning Rate [0.00125]
6: TRAIN [0][1900/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 62265 (52914)	Loss/tok 3.9536 (4.7777)	Learning Rate [0.00125]
7: TRAIN [0][1910/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00093)	Tok/s 51925 (53003)	Loss/tok 3.6378 (4.7746)	Learning Rate [0.00125]
5: TRAIN [0][1910/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00096)	Tok/s 51962 (52845)	Loss/tok 3.3791 (4.7811)	Learning Rate [0.00125]
6: TRAIN [0][1910/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00098)	Tok/s 51975 (52917)	Loss/tok 3.5643 (4.7721)	Learning Rate [0.00125]
4: TRAIN [0][1910/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00093)	Tok/s 51910 (52746)	Loss/tok 3.5535 (4.7731)	Learning Rate [0.00125]
8: TRAIN [0][1910/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00099)	Tok/s 51801 (53083)	Loss/tok 3.6257 (4.7729)	Learning Rate [0.00125]
2: TRAIN [0][1910/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00099)	Tok/s 51690 (52562)	Loss/tok 3.8732 (4.7742)	Learning Rate [0.00125]
10: TRAIN [0][1910/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00099)	Tok/s 51586 (53225)	Loss/tok 3.5786 (4.7737)	Learning Rate [0.00125]
1: TRAIN [0][1910/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00093)	Tok/s 51653 (52458)	Loss/tok 3.7331 (4.7700)	Learning Rate [0.00125]
11: TRAIN [0][1910/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00099)	Tok/s 51519 (53301)	Loss/tok 3.8780 (4.7688)	Learning Rate [0.00125]
9: TRAIN [0][1910/3416]	Time 0.058 (0.058)	Data 0.00119 (0.00094)	Tok/s 51739 (53142)	Loss/tok 3.6381 (4.7723)	Learning Rate [0.00125]
3: TRAIN [0][1910/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00099)	Tok/s 51823 (52655)	Loss/tok 3.8742 (4.7638)	Learning Rate [0.00125]
0: TRAIN [0][1910/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00092)	Tok/s 51518 (52350)	Loss/tok 3.6808 (4.7698)	Learning Rate [0.00125]
15: TRAIN [0][1910/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00093)	Tok/s 51468 (53718)	Loss/tok 3.6980 (4.7704)	Learning Rate [0.00125]
12: TRAIN [0][1910/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00100)	Tok/s 51398 (53414)	Loss/tok 3.6271 (4.7682)	Learning Rate [0.00125]
13: TRAIN [0][1910/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00100)	Tok/s 51309 (53512)	Loss/tok 3.6900 (4.7761)	Learning Rate [0.00125]
14: TRAIN [0][1910/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00095)	Tok/s 51318 (53616)	Loss/tok 3.7568 (4.7738)	Learning Rate [0.00125]
5: TRAIN [0][1920/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00096)	Tok/s 69920 (52863)	Loss/tok 3.7238 (4.7746)	Learning Rate [0.00125]
3: TRAIN [0][1920/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00099)	Tok/s 70037 (52674)	Loss/tok 3.6445 (4.7577)	Learning Rate [0.00125]
6: TRAIN [0][1920/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 70002 (52935)	Loss/tok 3.5941 (4.7658)	Learning Rate [0.00125]
7: TRAIN [0][1920/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 69963 (53021)	Loss/tok 4.0485 (4.7687)	Learning Rate [0.00125]
4: TRAIN [0][1920/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 69902 (52764)	Loss/tok 3.9914 (4.7668)	Learning Rate [0.00125]
8: TRAIN [0][1920/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00098)	Tok/s 69962 (53101)	Loss/tok 3.8111 (4.7665)	Learning Rate [0.00125]
2: TRAIN [0][1920/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00099)	Tok/s 69922 (52581)	Loss/tok 3.8080 (4.7684)	Learning Rate [0.00125]
10: TRAIN [0][1920/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00099)	Tok/s 70020 (53244)	Loss/tok 4.0159 (4.7678)	Learning Rate [0.00125]
12: TRAIN [0][1920/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00100)	Tok/s 70989 (53434)	Loss/tok 3.7878 (4.7619)	Learning Rate [0.00125]
9: TRAIN [0][1920/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00094)	Tok/s 69961 (53161)	Loss/tok 4.0833 (4.7663)	Learning Rate [0.00125]
11: TRAIN [0][1920/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00099)	Tok/s 70225 (53320)	Loss/tok 3.9116 (4.7624)	Learning Rate [0.00125]
1: TRAIN [0][1920/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00093)	Tok/s 69917 (52478)	Loss/tok 3.8901 (4.7644)	Learning Rate [0.00125]
0: TRAIN [0][1920/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 69891 (52370)	Loss/tok 3.9357 (4.7638)	Learning Rate [0.00125]
13: TRAIN [0][1920/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00100)	Tok/s 70981 (53531)	Loss/tok 3.5820 (4.7694)	Learning Rate [0.00125]
15: TRAIN [0][1920/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 70838 (53737)	Loss/tok 3.7173 (4.7642)	Learning Rate [0.00125]
14: TRAIN [0][1920/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00095)	Tok/s 70871 (53635)	Loss/tok 3.9146 (4.7681)	Learning Rate [0.00125]
8: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 64633 (53089)	Loss/tok 3.7949 (4.7612)	Learning Rate [0.00125]
7: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00093)	Tok/s 64577 (53008)	Loss/tok 3.8158 (4.7631)	Learning Rate [0.00125]
2: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00099)	Tok/s 64854 (52565)	Loss/tok 3.5511 (4.7627)	Learning Rate [0.00125]
9: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00074 (0.00094)	Tok/s 64580 (53149)	Loss/tok 4.0732 (4.7613)	Learning Rate [0.00125]
10: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00099)	Tok/s 64577 (53231)	Loss/tok 3.8953 (4.7629)	Learning Rate [0.00125]
5: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 64651 (52849)	Loss/tok 3.8191 (4.7691)	Learning Rate [0.00125]
6: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 64628 (52922)	Loss/tok 3.8023 (4.7606)	Learning Rate [0.00125]
1: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 64831 (52461)	Loss/tok 3.8874 (4.7592)	Learning Rate [0.00125]
11: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00099)	Tok/s 64645 (53307)	Loss/tok 3.9050 (4.7571)	Learning Rate [0.00125]
4: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00079 (0.00092)	Tok/s 64631 (52750)	Loss/tok 3.8299 (4.7612)	Learning Rate [0.00125]
0: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 64219 (52352)	Loss/tok 3.5907 (4.7587)	Learning Rate [0.00125]
3: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00099)	Tok/s 64637 (52658)	Loss/tok 4.0246 (4.7526)	Learning Rate [0.00125]
12: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 64624 (53421)	Loss/tok 3.8577 (4.7566)	Learning Rate [0.00125]
15: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00093)	Tok/s 65173 (53724)	Loss/tok 3.9576 (4.7592)	Learning Rate [0.00125]
13: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 64636 (53518)	Loss/tok 3.7742 (4.7641)	Learning Rate [0.00125]
14: TRAIN [0][1930/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00095)	Tok/s 64697 (53622)	Loss/tok 3.8865 (4.7630)	Learning Rate [0.00125]
4: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00092)	Tok/s 56820 (52763)	Loss/tok 3.7528 (4.7550)	Learning Rate [0.00125]
5: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00096)	Tok/s 56738 (52863)	Loss/tok 3.4558 (4.7627)	Learning Rate [0.00125]
3: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00099)	Tok/s 56856 (52673)	Loss/tok 4.1442 (4.7468)	Learning Rate [0.00125]
2: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00099 (0.00099)	Tok/s 56858 (52579)	Loss/tok 3.5022 (4.7562)	Learning Rate [0.00125]
15: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00093)	Tok/s 56930 (53736)	Loss/tok 3.6891 (4.7530)	Learning Rate [0.00125]
7: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00093)	Tok/s 56758 (53022)	Loss/tok 3.8538 (4.7568)	Learning Rate [0.00125]
1: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00093)	Tok/s 56843 (52473)	Loss/tok 3.9855 (4.7532)	Learning Rate [0.00125]
8: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00098)	Tok/s 56781 (53103)	Loss/tok 3.8296 (4.7546)	Learning Rate [0.00125]
0: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00092)	Tok/s 56834 (52365)	Loss/tok 3.8251 (4.7531)	Learning Rate [0.00125]
10: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00099)	Tok/s 56775 (53243)	Loss/tok 3.7313 (4.7570)	Learning Rate [0.00125]
9: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00094)	Tok/s 56761 (53162)	Loss/tok 3.9172 (4.7550)	Learning Rate [0.00125]
14: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00095)	Tok/s 56851 (53635)	Loss/tok 3.8350 (4.7567)	Learning Rate [0.00125]
13: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00100)	Tok/s 56866 (53531)	Loss/tok 3.7131 (4.7578)	Learning Rate [0.00125]
12: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00099 (0.00099)	Tok/s 56840 (53433)	Loss/tok 3.8248 (4.7506)	Learning Rate [0.00125]
6: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00098)	Tok/s 56708 (52935)	Loss/tok 3.6243 (4.7542)	Learning Rate [0.00125]
11: TRAIN [0][1940/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00099)	Tok/s 56784 (53320)	Loss/tok 3.9680 (4.7511)	Learning Rate [0.00125]
15: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 62182 (53766)	Loss/tok 3.7461 (4.7465)	Learning Rate [0.00125]
14: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00095)	Tok/s 62113 (53665)	Loss/tok 3.7673 (4.7503)	Learning Rate [0.00125]
1: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 61960 (52503)	Loss/tok 3.8207 (4.7469)	Learning Rate [0.00125]
0: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 61189 (52394)	Loss/tok 3.7427 (4.7470)	Learning Rate [0.00125]
2: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00099)	Tok/s 61916 (52608)	Loss/tok 4.1231 (4.7504)	Learning Rate [0.00125]
13: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00100)	Tok/s 61974 (53561)	Loss/tok 3.9851 (4.7515)	Learning Rate [0.00125]
12: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 61848 (53463)	Loss/tok 3.9547 (4.7444)	Learning Rate [0.00125]
3: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00099)	Tok/s 61799 (52703)	Loss/tok 3.3909 (4.7404)	Learning Rate [0.00125]
4: TRAIN [0][1950/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 61686 (52793)	Loss/tok 3.6253 (4.7485)	Learning Rate [0.00125]
5: TRAIN [0][1950/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 61590 (52892)	Loss/tok 3.7202 (4.7565)	Learning Rate [0.00125]
11: TRAIN [0][1950/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00099)	Tok/s 61735 (53350)	Loss/tok 3.8983 (4.7448)	Learning Rate [0.00125]
10: TRAIN [0][1950/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00099)	Tok/s 61654 (53273)	Loss/tok 3.7707 (4.7504)	Learning Rate [0.00125]
8: TRAIN [0][1950/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 61478 (53132)	Loss/tok 3.8267 (4.7483)	Learning Rate [0.00125]
6: TRAIN [0][1950/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00098)	Tok/s 61438 (52964)	Loss/tok 3.6542 (4.7474)	Learning Rate [0.00125]
7: TRAIN [0][1950/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 61404 (53051)	Loss/tok 3.8136 (4.7503)	Learning Rate [0.00125]
9: TRAIN [0][1950/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00094)	Tok/s 61494 (53191)	Loss/tok 4.0672 (4.7488)	Learning Rate [0.00125]
14: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
9: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
2: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00099)	Tok/s 62889 (52578)	Loss/tok 3.9364 (4.7458)	Learning Rate [0.00125]
3: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 62801 (52673)	Loss/tok 3.6683 (4.7355)	Learning Rate [0.00125]
1: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 62925 (52471)	Loss/tok 3.9225 (4.7420)	Learning Rate [0.00125]
12: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00099)	Tok/s 63256 (53437)	Loss/tok 3.8395 (4.7392)	Learning Rate [0.00125]
0: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 62932 (52361)	Loss/tok 3.7500 (4.7421)	Learning Rate [0.00125]
11: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00099)	Tok/s 63125 (53323)	Loss/tok 3.7843 (4.7396)	Learning Rate [0.00125]
14: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00095)	Tok/s 63632 (53638)	Loss/tok 3.5358 (4.7452)	Learning Rate [0.00125]
13: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00100)	Tok/s 63047 (53534)	Loss/tok 3.7007 (4.7466)	Learning Rate [0.00125]
4: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 62678 (52764)	Loss/tok 3.8489 (4.7439)	Learning Rate [0.00125]
10: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 62994 (53246)	Loss/tok 4.0070 (4.7457)	Learning Rate [0.00125]
9: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 62913 (53164)	Loss/tok 4.0151 (4.7441)	Learning Rate [0.00125]
5: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 62659 (52864)	Loss/tok 3.9423 (4.7516)	Learning Rate [0.00125]
8: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 62836 (53105)	Loss/tok 4.0462 (4.7435)	Learning Rate [0.00125]
6: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 62622 (52937)	Loss/tok 3.8271 (4.7424)	Learning Rate [0.00125]
7: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 62741 (53023)	Loss/tok 3.9602 (4.7453)	Learning Rate [0.00125]
15: TRAIN [0][1960/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 63873 (53740)	Loss/tok 3.9253 (4.7420)	Learning Rate [0.00125]
0: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00092)	Tok/s 53238 (52353)	Loss/tok 3.9528 (4.7373)	Learning Rate [0.00125]
15: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00078 (0.00093)	Tok/s 54319 (53731)	Loss/tok 3.9361 (4.7369)	Learning Rate [0.00125]
2: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00099)	Tok/s 53040 (52570)	Loss/tok 3.6584 (4.7403)	Learning Rate [0.00125]
14: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00095)	Tok/s 54338 (53630)	Loss/tok 3.7078 (4.7401)	Learning Rate [0.00125]
13: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00100)	Tok/s 54325 (53525)	Loss/tok 3.7834 (4.7416)	Learning Rate [0.00125]
3: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00099)	Tok/s 53034 (52665)	Loss/tok 3.7665 (4.7304)	Learning Rate [0.00125]
12: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00102 (0.00099)	Tok/s 54365 (53428)	Loss/tok 3.7908 (4.7341)	Learning Rate [0.00125]
4: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00081 (0.00092)	Tok/s 53050 (52756)	Loss/tok 3.6484 (4.7388)	Learning Rate [0.00125]
10: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00099)	Tok/s 53220 (53237)	Loss/tok 3.6002 (4.7406)	Learning Rate [0.00125]
11: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00099)	Tok/s 54285 (53315)	Loss/tok 3.7840 (4.7344)	Learning Rate [0.00125]
5: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00096)	Tok/s 52946 (52855)	Loss/tok 3.9250 (4.7465)	Learning Rate [0.00125]
9: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00094)	Tok/s 53185 (53155)	Loss/tok 3.5471 (4.7387)	Learning Rate [0.00125]
6: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00098)	Tok/s 53067 (52928)	Loss/tok 3.6364 (4.7379)	Learning Rate [0.00125]
8: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00098)	Tok/s 53125 (53096)	Loss/tok 3.8635 (4.7386)	Learning Rate [0.00125]
1: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00080 (0.00093)	Tok/s 52773 (52463)	Loss/tok 3.9570 (4.7370)	Learning Rate [0.00125]
7: TRAIN [0][1970/3416]	Time 0.058 (0.058)	Data 0.00081 (0.00093)	Tok/s 53061 (53015)	Loss/tok 3.5454 (4.7402)	Learning Rate [0.00125]
2: TRAIN [0][1980/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 60373 (52562)	Loss/tok 4.1908 (4.7357)	Learning Rate [0.00125]
3: TRAIN [0][1980/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00099)	Tok/s 60244 (52657)	Loss/tok 3.9134 (4.7255)	Learning Rate [0.00125]
0: TRAIN [0][1980/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 59837 (52346)	Loss/tok 3.6227 (4.7322)	Learning Rate [0.00125]
15: TRAIN [0][1980/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 60287 (53720)	Loss/tok 3.7745 (4.7318)	Learning Rate [0.00125]
4: TRAIN [0][1980/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 60146 (52747)	Loss/tok 3.7465 (4.7336)	Learning Rate [0.00125]
5: TRAIN [0][1980/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00096)	Tok/s 60063 (52846)	Loss/tok 3.7882 (4.7415)	Learning Rate [0.00125]
14: TRAIN [0][1980/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00095)	Tok/s 60193 (53618)	Loss/tok 3.6524 (4.7351)	Learning Rate [0.00125]
6: TRAIN [0][1980/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00098)	Tok/s 59999 (52919)	Loss/tok 3.7241 (4.7330)	Learning Rate [0.00125]
13: TRAIN [0][1980/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 60099 (53514)	Loss/tok 4.0509 (4.7368)	Learning Rate [0.00125]
12: TRAIN [0][1980/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00099)	Tok/s 59946 (53417)	Loss/tok 3.4857 (4.7288)	Learning Rate [0.00125]
7: TRAIN [0][1980/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 59863 (53005)	Loss/tok 3.6900 (4.7350)	Learning Rate [0.00125]
8: TRAIN [0][1980/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00098)	Tok/s 59768 (53086)	Loss/tok 3.6423 (4.7337)	Learning Rate [0.00125]
11: TRAIN [0][1980/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00099)	Tok/s 59901 (53304)	Loss/tok 3.9192 (4.7296)	Learning Rate [0.00125]
10: TRAIN [0][1980/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00099)	Tok/s 59780 (53227)	Loss/tok 4.0453 (4.7356)	Learning Rate [0.00125]
1: TRAIN [0][1980/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 60344 (52455)	Loss/tok 3.7021 (4.7318)	Learning Rate [0.00125]
9: TRAIN [0][1980/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00094)	Tok/s 59732 (53145)	Loss/tok 3.8119 (4.7334)	Learning Rate [0.00125]
7: Gradient norm: inf
4: Gradient norm: inf
8: Gradient norm: inf
5: Gradient norm: inf
6: Gradient norm: inf
7: Skipped batch, new scale: 512.0
3: Gradient norm: inf
8: Skipped batch, new scale: 512.0
5: Skipped batch, new scale: 512.0
4: Skipped batch, new scale: 512.0
9: Gradient norm: inf
6: Skipped batch, new scale: 512.0
3: Skipped batch, new scale: 512.0
10: Gradient norm: inf
9: Skipped batch, new scale: 512.0
2: Gradient norm: inf
10: Skipped batch, new scale: 512.0
1: Gradient norm: inf
11: Gradient norm: inf
0: Gradient norm: inf
11: Skipped batch, new scale: 512.0
1: Skipped batch, new scale: 512.0
2: Skipped batch, new scale: 512.0
12: Gradient norm: inf
15: Gradient norm: inf
0: Skipped batch, new scale: 512.0
12: Skipped batch, new scale: 512.0
14: Gradient norm: inf
13: Gradient norm: inf
15: Skipped batch, new scale: 512.0
14: Skipped batch, new scale: 512.0
13: Skipped batch, new scale: 512.0
4: TRAIN [0][1990/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 58944 (52727)	Loss/tok 3.8512 (4.7283)	Learning Rate [0.00125]
5: TRAIN [0][1990/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00096)	Tok/s 58963 (52827)	Loss/tok 4.0185 (4.7365)	Learning Rate [0.00125]
3: TRAIN [0][1990/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 58971 (52637)	Loss/tok 3.5879 (4.7204)	Learning Rate [0.00125]
2: TRAIN [0][1990/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00099)	Tok/s 58966 (52541)	Loss/tok 3.4909 (4.7305)	Learning Rate [0.00125]
6: TRAIN [0][1990/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 58942 (52900)	Loss/tok 3.5768 (4.7277)	Learning Rate [0.00125]
7: TRAIN [0][1990/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 58957 (52987)	Loss/tok 3.9791 (4.7297)	Learning Rate [0.00125]
0: TRAIN [0][1990/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 58938 (52323)	Loss/tok 3.7386 (4.7273)	Learning Rate [0.00125]
8: TRAIN [0][1990/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 58950 (53068)	Loss/tok 4.0584 (4.7290)	Learning Rate [0.00125]
14: TRAIN [0][1990/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00095)	Tok/s 58989 (53602)	Loss/tok 3.7342 (4.7297)	Learning Rate [0.00125]
15: TRAIN [0][1990/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 58924 (53704)	Loss/tok 4.0411 (4.7270)	Learning Rate [0.00125]
9: TRAIN [0][1990/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00094)	Tok/s 58928 (53126)	Loss/tok 3.6248 (4.7280)	Learning Rate [0.00125]
10: TRAIN [0][1990/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 58924 (53209)	Loss/tok 3.8674 (4.7303)	Learning Rate [0.00125]
13: TRAIN [0][1990/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 58927 (53497)	Loss/tok 3.9196 (4.7317)	Learning Rate [0.00125]
11: TRAIN [0][1990/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00099)	Tok/s 58919 (53287)	Loss/tok 3.8659 (4.7247)	Learning Rate [0.00125]
12: TRAIN [0][1990/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00100)	Tok/s 58984 (53400)	Loss/tok 4.1640 (4.7235)	Learning Rate [0.00125]
1: TRAIN [0][1990/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00093)	Tok/s 58969 (52433)	Loss/tok 3.8000 (4.7265)	Learning Rate [0.00125]
14: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00095)	Tok/s 56687 (53626)	Loss/tok 3.6812 (4.7239)	Learning Rate [0.00125]
15: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00093)	Tok/s 56674 (53727)	Loss/tok 3.8937 (4.7217)	Learning Rate [0.00125]
13: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00100)	Tok/s 56582 (53522)	Loss/tok 3.8250 (4.7264)	Learning Rate [0.00125]
0: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00073 (0.00092)	Tok/s 55725 (52349)	Loss/tok 3.7206 (4.7212)	Learning Rate [0.00125]
12: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00107 (0.00100)	Tok/s 56508 (53424)	Loss/tok 3.6917 (4.7176)	Learning Rate [0.00125]
11: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00099)	Tok/s 56525 (53311)	Loss/tok 3.8340 (4.7193)	Learning Rate [0.00125]
10: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00098)	Tok/s 56494 (53234)	Loss/tok 3.5723 (4.7243)	Learning Rate [0.00125]
2: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00099)	Tok/s 55651 (52566)	Loss/tok 3.7336 (4.7251)	Learning Rate [0.00125]
3: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00099)	Tok/s 55659 (52661)	Loss/tok 3.6085 (4.7146)	Learning Rate [0.00125]
8: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00098)	Tok/s 56500 (53092)	Loss/tok 3.9128 (4.7233)	Learning Rate [0.00125]
4: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 55638 (52751)	Loss/tok 3.7670 (4.7225)	Learning Rate [0.00125]
9: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00094)	Tok/s 56469 (53151)	Loss/tok 3.7917 (4.7221)	Learning Rate [0.00125]
5: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00096)	Tok/s 55601 (52851)	Loss/tok 3.5566 (4.7307)	Learning Rate [0.00125]
6: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00098)	Tok/s 56361 (52925)	Loss/tok 3.7641 (4.7222)	Learning Rate [0.00125]
7: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00092)	Tok/s 56496 (53011)	Loss/tok 3.6289 (4.7240)	Learning Rate [0.00125]
1: TRAIN [0][2000/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00093)	Tok/s 55710 (52459)	Loss/tok 3.8563 (4.7212)	Learning Rate [0.00125]
10: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00098)	Tok/s 65812 (53235)	Loss/tok 3.8430 (4.7196)	Learning Rate [0.00125]
9: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00094)	Tok/s 64881 (53153)	Loss/tok 4.0384 (4.7170)	Learning Rate [0.00125]
8: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 64719 (53094)	Loss/tok 3.7450 (4.7180)	Learning Rate [0.00125]
11: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00099)	Tok/s 65805 (53312)	Loss/tok 3.6289 (4.7145)	Learning Rate [0.00125]
12: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00100)	Tok/s 65796 (53425)	Loss/tok 3.9816 (4.7124)	Learning Rate [0.00125]
6: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00098)	Tok/s 64610 (52927)	Loss/tok 3.7149 (4.7169)	Learning Rate [0.00125]
5: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 64613 (52853)	Loss/tok 3.7121 (4.7254)	Learning Rate [0.00125]
13: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00100)	Tok/s 65677 (53523)	Loss/tok 3.8493 (4.7210)	Learning Rate [0.00125]
4: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 64625 (52754)	Loss/tok 3.7848 (4.7175)	Learning Rate [0.00125]
14: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00095)	Tok/s 65822 (53627)	Loss/tok 3.7692 (4.7189)	Learning Rate [0.00125]
3: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00099)	Tok/s 64679 (52663)	Loss/tok 3.9135 (4.7095)	Learning Rate [0.00125]
7: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 64639 (53013)	Loss/tok 3.6745 (4.7187)	Learning Rate [0.00125]
15: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 65734 (53728)	Loss/tok 3.5679 (4.7164)	Learning Rate [0.00125]
2: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00099)	Tok/s 64698 (52568)	Loss/tok 3.8347 (4.7205)	Learning Rate [0.00125]
0: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 64839 (52352)	Loss/tok 3.9392 (4.7160)	Learning Rate [0.00125]
1: TRAIN [0][2010/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 64678 (52462)	Loss/tok 3.5646 (4.7160)	Learning Rate [0.00125]
15: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00093)	Tok/s 39588 (53687)	Loss/tok 3.4892 (4.7121)	Learning Rate [0.00125]
14: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00095)	Tok/s 39566 (53586)	Loss/tok 3.3565 (4.7148)	Learning Rate [0.00125]
13: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00100)	Tok/s 39512 (53482)	Loss/tok 3.2373 (4.7170)	Learning Rate [0.00125]
12: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00100)	Tok/s 39372 (53384)	Loss/tok 3.7051 (4.7086)	Learning Rate [0.00125]
0: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00092)	Tok/s 38269 (52313)	Loss/tok 3.4182 (4.7119)	Learning Rate [0.00125]
11: TRAIN [0][2020/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00099)	Tok/s 39271 (53272)	Loss/tok 3.6333 (4.7105)	Learning Rate [0.00125]
10: TRAIN [0][2020/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00098)	Tok/s 38884 (53195)	Loss/tok 3.3049 (4.7155)	Learning Rate [0.00125]
2: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00099)	Tok/s 38266 (52529)	Loss/tok 3.2887 (4.7163)	Learning Rate [0.00125]
9: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00079 (0.00094)	Tok/s 38050 (53112)	Loss/tok 3.3979 (4.7128)	Learning Rate [0.00125]
3: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00099)	Tok/s 38216 (52623)	Loss/tok 3.2361 (4.7054)	Learning Rate [0.00125]
4: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 38177 (52714)	Loss/tok 3.3354 (4.7132)	Learning Rate [0.00125]
8: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00098)	Tok/s 38025 (53054)	Loss/tok 3.2696 (4.7138)	Learning Rate [0.00125]
7: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00075 (0.00092)	Tok/s 38046 (52973)	Loss/tok 3.4379 (4.7142)	Learning Rate [0.00125]
5: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00081 (0.00096)	Tok/s 38107 (52813)	Loss/tok 3.3900 (4.7210)	Learning Rate [0.00125]
6: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00098)	Tok/s 38054 (52887)	Loss/tok 3.5277 (4.7127)	Learning Rate [0.00125]
1: TRAIN [0][2020/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00093)	Tok/s 38290 (52422)	Loss/tok 3.1353 (4.7118)	Learning Rate [0.00125]
11: TRAIN [0][2030/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00099)	Tok/s 58842 (53314)	Loss/tok 3.8453 (4.7042)	Learning Rate [0.00125]
10: TRAIN [0][2030/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00098)	Tok/s 58267 (53236)	Loss/tok 4.0878 (4.7097)	Learning Rate [0.00125]
12: TRAIN [0][2030/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 59398 (53426)	Loss/tok 3.7033 (4.7024)	Learning Rate [0.00125]
9: TRAIN [0][2030/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00094)	Tok/s 58260 (53154)	Loss/tok 3.8925 (4.7071)	Learning Rate [0.00125]
13: TRAIN [0][2030/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 59230 (53524)	Loss/tok 3.8248 (4.7107)	Learning Rate [0.00125]
8: TRAIN [0][2030/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00098)	Tok/s 58148 (53095)	Loss/tok 3.9373 (4.7077)	Learning Rate [0.00125]
7: TRAIN [0][2030/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 58040 (53015)	Loss/tok 3.8942 (4.7080)	Learning Rate [0.00125]
15: TRAIN [0][2030/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 59056 (53729)	Loss/tok 3.6120 (4.7062)	Learning Rate [0.00125]
6: TRAIN [0][2030/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 57976 (52929)	Loss/tok 3.6910 (4.7063)	Learning Rate [0.00125]
14: TRAIN [0][2030/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00095)	Tok/s 59056 (53628)	Loss/tok 3.6615 (4.7083)	Learning Rate [0.00125]
5: TRAIN [0][2030/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00096)	Tok/s 57857 (52855)	Loss/tok 4.0314 (4.7152)	Learning Rate [0.00125]
0: TRAIN [0][2030/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 58005 (52356)	Loss/tok 3.9480 (4.7057)	Learning Rate [0.00125]
4: TRAIN [0][2030/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 57745 (52756)	Loss/tok 3.6534 (4.7071)	Learning Rate [0.00125]
1: TRAIN [0][2030/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 57902 (52465)	Loss/tok 3.6754 (4.7055)	Learning Rate [0.00125]
2: TRAIN [0][2030/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 57721 (52572)	Loss/tok 3.8254 (4.7100)	Learning Rate [0.00125]
3: TRAIN [0][2030/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00099)	Tok/s 57784 (52666)	Loss/tok 3.8042 (4.6994)	Learning Rate [0.00125]
11: TRAIN [0][2040/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 71784 (53339)	Loss/tok 3.7799 (4.6983)	Learning Rate [0.00125]
12: TRAIN [0][2040/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00100)	Tok/s 71796 (53452)	Loss/tok 3.7711 (4.6962)	Learning Rate [0.00125]
13: TRAIN [0][2040/3416]	Time 0.069 (0.058)	Data 0.00116 (0.00100)	Tok/s 71914 (53549)	Loss/tok 3.9002 (4.7048)	Learning Rate [0.00125]
14: TRAIN [0][2040/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00095)	Tok/s 71996 (53653)	Loss/tok 3.6879 (4.7024)	Learning Rate [0.00125]
15: TRAIN [0][2040/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00093)	Tok/s 71948 (53753)	Loss/tok 3.8661 (4.7005)	Learning Rate [0.00125]
10: TRAIN [0][2040/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00098)	Tok/s 71667 (53262)	Loss/tok 3.8591 (4.7037)	Learning Rate [0.00125]
9: TRAIN [0][2040/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00094)	Tok/s 71593 (53179)	Loss/tok 3.7606 (4.7013)	Learning Rate [0.00125]
0: TRAIN [0][2040/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00092)	Tok/s 70919 (52381)	Loss/tok 3.7247 (4.7002)	Learning Rate [0.00125]
8: TRAIN [0][2040/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 71448 (53119)	Loss/tok 3.7155 (4.7019)	Learning Rate [0.00125]
1: TRAIN [0][2040/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 70796 (52490)	Loss/tok 3.6732 (4.6996)	Learning Rate [0.00125]
2: TRAIN [0][2040/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00098)	Tok/s 70674 (52597)	Loss/tok 3.7411 (4.7043)	Learning Rate [0.00125]
7: TRAIN [0][2040/3416]	Time 0.070 (0.058)	Data 0.00116 (0.00092)	Tok/s 71335 (53039)	Loss/tok 3.5893 (4.7019)	Learning Rate [0.00125]
3: TRAIN [0][2040/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00099)	Tok/s 70552 (52690)	Loss/tok 3.6580 (4.6937)	Learning Rate [0.00125]
5: TRAIN [0][2040/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 70984 (52879)	Loss/tok 3.9567 (4.7099)	Learning Rate [0.00125]
4: TRAIN [0][2040/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 70471 (52780)	Loss/tok 3.8881 (4.7010)	Learning Rate [0.00125]
6: TRAIN [0][2040/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00098)	Tok/s 71001 (52953)	Loss/tok 3.6427 (4.7004)	Learning Rate [0.00125]
5: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00096)	Tok/s 52049 (52896)	Loss/tok 3.7652 (4.7043)	Learning Rate [0.00125]
6: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00098)	Tok/s 52080 (52970)	Loss/tok 3.7522 (4.6945)	Learning Rate [0.00125]
7: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00086 (0.00092)	Tok/s 52033 (53057)	Loss/tok 3.5635 (4.6961)	Learning Rate [0.00125]
4: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00080 (0.00092)	Tok/s 52005 (52797)	Loss/tok 3.7048 (4.6951)	Learning Rate [0.00125]
8: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00102 (0.00098)	Tok/s 52020 (53137)	Loss/tok 3.7777 (4.6967)	Learning Rate [0.00125]
3: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00099)	Tok/s 51927 (52707)	Loss/tok 3.5989 (4.6880)	Learning Rate [0.00125]
2: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00098)	Tok/s 51868 (52614)	Loss/tok 3.4743 (4.6988)	Learning Rate [0.00125]
9: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00094)	Tok/s 52071 (53196)	Loss/tok 3.5830 (4.6957)	Learning Rate [0.00125]
10: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00098)	Tok/s 52444 (53280)	Loss/tok 3.9219 (4.6979)	Learning Rate [0.00125]
1: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00093)	Tok/s 51849 (52507)	Loss/tok 3.5949 (4.6940)	Learning Rate [0.00125]
11: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00099)	Tok/s 53001 (53357)	Loss/tok 3.6863 (4.6927)	Learning Rate [0.00125]
0: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00083 (0.00092)	Tok/s 51822 (52398)	Loss/tok 3.7586 (4.6948)	Learning Rate [0.00125]
15: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00093)	Tok/s 52813 (53771)	Loss/tok 3.8772 (4.6949)	Learning Rate [0.00125]
13: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00100)	Tok/s 52889 (53566)	Loss/tok 3.8921 (4.6998)	Learning Rate [0.00125]
14: TRAIN [0][2050/3416]	Time 0.064 (0.058)	Data 0.00106 (0.00095)	Tok/s 54053 (53670)	Loss/tok 3.7323 (4.6972)	Learning Rate [0.00125]
12: TRAIN [0][2050/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00100)	Tok/s 52969 (53469)	Loss/tok 3.8073 (4.6909)	Learning Rate [0.00125]
12: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00116 (0.00100)	Tok/s 54592 (53483)	Loss/tok 3.6131 (4.6863)	Learning Rate [0.00125]
11: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00099)	Tok/s 54503 (53371)	Loss/tok 3.7334 (4.6876)	Learning Rate [0.00125]
13: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00099)	Tok/s 54599 (53579)	Loss/tok 3.4610 (4.6951)	Learning Rate [0.00125]
15: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00093)	Tok/s 55254 (53784)	Loss/tok 3.7741 (4.6896)	Learning Rate [0.00125]
0: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00092)	Tok/s 54508 (52415)	Loss/tok 3.7680 (4.6890)	Learning Rate [0.00125]
14: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00096)	Tok/s 54564 (53683)	Loss/tok 3.6360 (4.6922)	Learning Rate [0.00125]
2: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00098)	Tok/s 54307 (52630)	Loss/tok 3.6627 (4.6935)	Learning Rate [0.00125]
1: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00093)	Tok/s 54413 (52523)	Loss/tok 3.5812 (4.6890)	Learning Rate [0.00125]
10: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00098)	Tok/s 54331 (53294)	Loss/tok 3.4829 (4.6927)	Learning Rate [0.00125]
9: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00094)	Tok/s 54273 (53210)	Loss/tok 3.8023 (4.6908)	Learning Rate [0.00125]
3: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00099)	Tok/s 54228 (52723)	Loss/tok 3.5326 (4.6829)	Learning Rate [0.00125]
8: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00098)	Tok/s 54153 (53150)	Loss/tok 3.9737 (4.6916)	Learning Rate [0.00125]
4: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00084 (0.00092)	Tok/s 54111 (52812)	Loss/tok 3.4509 (4.6896)	Learning Rate [0.00125]
7: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00092)	Tok/s 54012 (53070)	Loss/tok 3.6894 (4.6907)	Learning Rate [0.00125]
5: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00096)	Tok/s 54020 (52911)	Loss/tok 3.5565 (4.6988)	Learning Rate [0.00125]
6: TRAIN [0][2060/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00098)	Tok/s 53979 (52984)	Loss/tok 3.9497 (4.6894)	Learning Rate [0.00125]
1: TRAIN [0][2070/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00093)	Tok/s 53252 (52523)	Loss/tok 3.8327 (4.6836)	Learning Rate [0.00125]
2: TRAIN [0][2070/3416]	Time 0.067 (0.058)	Data 0.00106 (0.00098)	Tok/s 53174 (52629)	Loss/tok 4.0004 (4.6888)	Learning Rate [0.00125]
0: TRAIN [0][2070/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00092)	Tok/s 53263 (52415)	Loss/tok 3.6008 (4.6837)	Learning Rate [0.00125]
15: TRAIN [0][2070/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00092)	Tok/s 54201 (53783)	Loss/tok 3.6231 (4.6844)	Learning Rate [0.00125]
3: TRAIN [0][2070/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00099)	Tok/s 53012 (52722)	Loss/tok 3.7137 (4.6782)	Learning Rate [0.00125]
14: TRAIN [0][2070/3416]	Time 0.067 (0.058)	Data 0.00104 (0.00096)	Tok/s 54150 (53681)	Loss/tok 3.8654 (4.6872)	Learning Rate [0.00125]
4: TRAIN [0][2070/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00092)	Tok/s 52979 (52811)	Loss/tok 3.6452 (4.6845)	Learning Rate [0.00125]
5: TRAIN [0][2070/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00096)	Tok/s 52879 (52910)	Loss/tok 3.8921 (4.6934)	Learning Rate [0.00125]
13: TRAIN [0][2070/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00099)	Tok/s 54014 (53578)	Loss/tok 3.5985 (4.6899)	Learning Rate [0.00125]
12: TRAIN [0][2070/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00100)	Tok/s 53947 (53481)	Loss/tok 3.9737 (4.6812)	Learning Rate [0.00125]
11: TRAIN [0][2070/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00099)	Tok/s 53887 (53370)	Loss/tok 3.8312 (4.6821)	Learning Rate [0.00125]
6: TRAIN [0][2070/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00098)	Tok/s 53385 (52983)	Loss/tok 3.8986 (4.6843)	Learning Rate [0.00125]
10: TRAIN [0][2070/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00098)	Tok/s 53764 (53292)	Loss/tok 3.5933 (4.6877)	Learning Rate [0.00125]
7: TRAIN [0][2070/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 53639 (53069)	Loss/tok 3.8678 (4.6854)	Learning Rate [0.00125]
8: TRAIN [0][2070/3416]	Time 0.068 (0.058)	Data 0.00107 (0.00098)	Tok/s 53667 (53149)	Loss/tok 4.2635 (4.6866)	Learning Rate [0.00125]
9: TRAIN [0][2070/3416]	Time 0.068 (0.058)	Data 0.00081 (0.00094)	Tok/s 53687 (53208)	Loss/tok 3.8940 (4.6858)	Learning Rate [0.00125]
4: TRAIN [0][2080/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00092)	Tok/s 77078 (52846)	Loss/tok 3.7345 (4.6783)	Learning Rate [0.00125]
5: TRAIN [0][2080/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00096)	Tok/s 77073 (52945)	Loss/tok 3.8897 (4.6876)	Learning Rate [0.00125]
6: TRAIN [0][2080/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00098)	Tok/s 76996 (53018)	Loss/tok 3.5423 (4.6782)	Learning Rate [0.00125]
7: TRAIN [0][2080/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00092)	Tok/s 76999 (53104)	Loss/tok 3.4389 (4.6795)	Learning Rate [0.00125]
3: TRAIN [0][2080/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00099)	Tok/s 77072 (52758)	Loss/tok 3.8981 (4.6726)	Learning Rate [0.00125]
2: TRAIN [0][2080/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00098)	Tok/s 76946 (52664)	Loss/tok 3.8254 (4.6830)	Learning Rate [0.00125]
8: TRAIN [0][2080/3416]	Time 0.072 (0.058)	Data 0.00104 (0.00098)	Tok/s 76934 (53183)	Loss/tok 3.4249 (4.6809)	Learning Rate [0.00125]
9: TRAIN [0][2080/3416]	Time 0.072 (0.058)	Data 0.00095 (0.00094)	Tok/s 76960 (53242)	Loss/tok 3.6026 (4.6796)	Learning Rate [0.00125]
10: TRAIN [0][2080/3416]	Time 0.072 (0.058)	Data 0.00091 (0.00098)	Tok/s 77620 (53327)	Loss/tok 3.7220 (4.6816)	Learning Rate [0.00125]
0: TRAIN [0][2080/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00092)	Tok/s 76122 (52450)	Loss/tok 3.7589 (4.6777)	Learning Rate [0.00125]
15: TRAIN [0][2080/3416]	Time 0.072 (0.058)	Data 0.00091 (0.00092)	Tok/s 77807 (53816)	Loss/tok 3.5237 (4.6783)	Learning Rate [0.00125]
11: TRAIN [0][2080/3416]	Time 0.072 (0.058)	Data 0.00092 (0.00099)	Tok/s 77521 (53404)	Loss/tok 3.6250 (4.6761)	Learning Rate [0.00125]
1: TRAIN [0][2080/3416]	Time 0.071 (0.058)	Data 0.00099 (0.00093)	Tok/s 76167 (52558)	Loss/tok 3.6639 (4.6777)	Learning Rate [0.00125]
12: TRAIN [0][2080/3416]	Time 0.072 (0.058)	Data 0.00094 (0.00100)	Tok/s 77525 (53515)	Loss/tok 3.4548 (4.6754)	Learning Rate [0.00125]
14: TRAIN [0][2080/3416]	Time 0.072 (0.058)	Data 0.00095 (0.00096)	Tok/s 77651 (53714)	Loss/tok 3.6968 (4.6815)	Learning Rate [0.00125]
13: TRAIN [0][2080/3416]	Time 0.072 (0.058)	Data 0.00097 (0.00099)	Tok/s 77556 (53611)	Loss/tok 3.6567 (4.6840)	Learning Rate [0.00125]
12: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00100)	Tok/s 52431 (53519)	Loss/tok 3.8066 (4.6708)	Learning Rate [0.00125]
11: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00099)	Tok/s 52068 (53408)	Loss/tok 3.9085 (4.6713)	Learning Rate [0.00125]
13: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00099)	Tok/s 53228 (53615)	Loss/tok 3.5954 (4.6789)	Learning Rate [0.00125]
10: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00098)	Tok/s 52081 (53331)	Loss/tok 3.8691 (4.6765)	Learning Rate [0.00125]
14: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00096)	Tok/s 53204 (53718)	Loss/tok 3.6930 (4.6768)	Learning Rate [0.00125]
15: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00092)	Tok/s 53225 (53820)	Loss/tok 3.5991 (4.6736)	Learning Rate [0.00125]
9: TRAIN [0][2090/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00094)	Tok/s 52534 (53246)	Loss/tok 3.5220 (4.6745)	Learning Rate [0.00125]
0: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00092)	Tok/s 51938 (52457)	Loss/tok 3.8127 (4.6727)	Learning Rate [0.00125]
8: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00098)	Tok/s 52050 (53187)	Loss/tok 3.5498 (4.6761)	Learning Rate [0.00125]
7: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00092)	Tok/s 51973 (53108)	Loss/tok 3.3621 (4.6748)	Learning Rate [0.00125]
1: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00093)	Tok/s 51889 (52564)	Loss/tok 3.4163 (4.6730)	Learning Rate [0.00125]
6: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00106 (0.00098)	Tok/s 51891 (53023)	Loss/tok 3.3614 (4.6733)	Learning Rate [0.00125]
5: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00096)	Tok/s 51797 (52949)	Loss/tok 3.4193 (4.6827)	Learning Rate [0.00125]
3: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00099)	Tok/s 51707 (52763)	Loss/tok 3.5983 (4.6679)	Learning Rate [0.00125]
2: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00098)	Tok/s 51869 (52670)	Loss/tok 3.7413 (4.6782)	Learning Rate [0.00125]
4: TRAIN [0][2090/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00092)	Tok/s 51664 (52852)	Loss/tok 3.6531 (4.6732)	Learning Rate [0.00125]
4: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00092)	Tok/s 49857 (52862)	Loss/tok 3.5939 (4.6683)	Learning Rate [0.00125]
6: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00098)	Tok/s 49738 (53033)	Loss/tok 3.5660 (4.6686)	Learning Rate [0.00125]
2: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00098)	Tok/s 49910 (52680)	Loss/tok 3.7620 (4.6732)	Learning Rate [0.00125]
5: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00101 (0.00096)	Tok/s 49840 (52960)	Loss/tok 3.6720 (4.6776)	Learning Rate [0.00125]
7: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00092)	Tok/s 49622 (53118)	Loss/tok 3.4297 (4.6696)	Learning Rate [0.00125]
3: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00099)	Tok/s 49873 (52773)	Loss/tok 3.5358 (4.6631)	Learning Rate [0.00125]
8: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00098)	Tok/s 49515 (53196)	Loss/tok 3.5322 (4.6709)	Learning Rate [0.00125]
1: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00093)	Tok/s 49862 (52575)	Loss/tok 3.5310 (4.6679)	Learning Rate [0.00125]
9: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00094)	Tok/s 49490 (53256)	Loss/tok 3.4873 (4.6696)	Learning Rate [0.00125]
10: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00098)	Tok/s 49523 (53341)	Loss/tok 3.4952 (4.6719)	Learning Rate [0.00125]
0: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00092)	Tok/s 49820 (52468)	Loss/tok 3.1070 (4.6678)	Learning Rate [0.00125]
15: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00081 (0.00092)	Tok/s 51072 (53829)	Loss/tok 3.5441 (4.6686)	Learning Rate [0.00125]
11: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00099)	Tok/s 50680 (53418)	Loss/tok 3.7256 (4.6666)	Learning Rate [0.00125]
14: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00096)	Tok/s 51003 (53728)	Loss/tok 3.5249 (4.6720)	Learning Rate [0.00125]
12: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00100)	Tok/s 50824 (53528)	Loss/tok 3.7223 (4.6662)	Learning Rate [0.00125]
13: TRAIN [0][2100/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00099)	Tok/s 50887 (53625)	Loss/tok 3.6884 (4.6742)	Learning Rate [0.00125]
12: TRAIN [0][2110/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00100)	Tok/s 69092 (53535)	Loss/tok 3.7800 (4.6619)	Learning Rate [0.00125]
11: TRAIN [0][2110/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 69121 (53424)	Loss/tok 3.6157 (4.6617)	Learning Rate [0.00125]
10: TRAIN [0][2110/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 69144 (53347)	Loss/tok 3.8669 (4.6670)	Learning Rate [0.00125]
13: TRAIN [0][2110/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00099)	Tok/s 68978 (53631)	Loss/tok 3.7259 (4.6692)	Learning Rate [0.00125]
8: TRAIN [0][2110/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00098)	Tok/s 69157 (53203)	Loss/tok 3.6481 (4.6658)	Learning Rate [0.00125]
9: TRAIN [0][2110/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00094)	Tok/s 69152 (53263)	Loss/tok 3.8400 (4.6651)	Learning Rate [0.00125]
14: TRAIN [0][2110/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 69743 (53734)	Loss/tok 3.9768 (4.6670)	Learning Rate [0.00125]
6: TRAIN [0][2110/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00098)	Tok/s 69137 (53040)	Loss/tok 3.9053 (4.6639)	Learning Rate [0.00125]
2: TRAIN [0][2110/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00098)	Tok/s 68886 (52689)	Loss/tok 3.7676 (4.6685)	Learning Rate [0.00125]
3: TRAIN [0][2110/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00099)	Tok/s 69043 (52782)	Loss/tok 3.8249 (4.6588)	Learning Rate [0.00125]
0: TRAIN [0][2110/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 67887 (52477)	Loss/tok 3.8147 (4.6636)	Learning Rate [0.00125]
1: TRAIN [0][2110/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 68163 (52584)	Loss/tok 4.0502 (4.6632)	Learning Rate [0.00125]
7: TRAIN [0][2110/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 69113 (53125)	Loss/tok 3.9650 (4.6649)	Learning Rate [0.00125]
5: TRAIN [0][2110/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00096)	Tok/s 68946 (52967)	Loss/tok 3.8531 (4.6727)	Learning Rate [0.00125]
4: TRAIN [0][2110/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 68908 (52870)	Loss/tok 3.9134 (4.6635)	Learning Rate [0.00125]
15: TRAIN [0][2110/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 69804 (53835)	Loss/tok 3.8337 (4.6637)	Learning Rate [0.00125]
5: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
9: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
8: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 62044 (53204)	Loss/tok 3.4232 (4.6610)	Learning Rate [0.00125]
7: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 62001 (53126)	Loss/tok 3.6572 (4.6605)	Learning Rate [0.00125]
14: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 62143 (53735)	Loss/tok 4.1865 (4.6624)	Learning Rate [0.00125]
9: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00094)	Tok/s 62059 (53263)	Loss/tok 3.6243 (4.6603)	Learning Rate [0.00125]
10: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 62033 (53348)	Loss/tok 3.7653 (4.6622)	Learning Rate [0.00125]
5: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 61782 (52967)	Loss/tok 3.8890 (4.6683)	Learning Rate [0.00125]
6: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 61876 (53040)	Loss/tok 3.7706 (4.6595)	Learning Rate [0.00125]
13: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00099)	Tok/s 62120 (53632)	Loss/tok 3.8809 (4.6644)	Learning Rate [0.00125]
12: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00100)	Tok/s 62119 (53536)	Loss/tok 3.6839 (4.6572)	Learning Rate [0.00125]
4: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 61783 (52870)	Loss/tok 4.0541 (4.6590)	Learning Rate [0.00125]
11: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00099)	Tok/s 62034 (53425)	Loss/tok 3.8103 (4.6570)	Learning Rate [0.00125]
0: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 61923 (52479)	Loss/tok 3.7296 (4.6588)	Learning Rate [0.00125]
2: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 61824 (52689)	Loss/tok 3.7799 (4.6634)	Learning Rate [0.00125]
3: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00099)	Tok/s 61793 (52782)	Loss/tok 3.8218 (4.6540)	Learning Rate [0.00125]
1: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 61867 (52585)	Loss/tok 3.8543 (4.6584)	Learning Rate [0.00125]
15: TRAIN [0][2120/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 62127 (53835)	Loss/tok 3.9577 (4.6591)	Learning Rate [0.00125]
12: Gradient norm: inf
11: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
12: Skipped batch, new scale: 512.0
10: Gradient norm: inf
13: Gradient norm: inf
2: Skipped batch, new scale: 512.0
1: Skipped batch, new scale: 512.0
11: Skipped batch, new scale: 512.0
0: Gradient norm: inf
3: Skipped batch, new scale: 512.0
4: Gradient norm: inf
14: Gradient norm: inf
15: Gradient norm: inf
10: Skipped batch, new scale: 512.0
13: Skipped batch, new scale: 512.0
9: Gradient norm: inf
4: Skipped batch, new scale: 512.0
0: Skipped batch, new scale: 512.0
5: Gradient norm: inf
15: Skipped batch, new scale: 512.0
8: Gradient norm: inf
14: Skipped batch, new scale: 512.0
9: Skipped batch, new scale: 512.0
6: Gradient norm: inf
5: Skipped batch, new scale: 512.0
8: Skipped batch, new scale: 512.0
7: Gradient norm: inf
6: Skipped batch, new scale: 512.0
7: Skipped batch, new scale: 512.0
2: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00098)	Tok/s 55465 (52718)	Loss/tok 3.6319 (4.6578)	Learning Rate [0.00125]
1: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00093)	Tok/s 55359 (52613)	Loss/tok 3.8747 (4.6531)	Learning Rate [0.00125]
0: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00092)	Tok/s 55345 (52507)	Loss/tok 3.8016 (4.6534)	Learning Rate [0.00125]
3: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00099)	Tok/s 55414 (52810)	Loss/tok 3.6327 (4.6482)	Learning Rate [0.00125]
4: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00081 (0.00092)	Tok/s 55422 (52899)	Loss/tok 3.5361 (4.6535)	Learning Rate [0.00125]
5: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00096)	Tok/s 55391 (52995)	Loss/tok 3.8508 (4.6631)	Learning Rate [0.00125]
14: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00095)	Tok/s 56281 (53763)	Loss/tok 3.7060 (4.6568)	Learning Rate [0.00125]
13: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00099)	Tok/s 56184 (53660)	Loss/tok 3.6470 (4.6589)	Learning Rate [0.00125]
6: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00098)	Tok/s 55319 (53068)	Loss/tok 3.7562 (4.6539)	Learning Rate [0.00125]
12: TRAIN [0][2130/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00100)	Tok/s 55850 (53563)	Loss/tok 3.8648 (4.6518)	Learning Rate [0.00125]
8: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00098)	Tok/s 55145 (53231)	Loss/tok 3.7850 (4.6553)	Learning Rate [0.00125]
7: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00092)	Tok/s 55221 (53153)	Loss/tok 3.5760 (4.6550)	Learning Rate [0.00125]
10: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00098)	Tok/s 54998 (53375)	Loss/tok 3.7546 (4.6563)	Learning Rate [0.00125]
11: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00099)	Tok/s 55099 (53453)	Loss/tok 3.8770 (4.6518)	Learning Rate [0.00125]
9: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00094)	Tok/s 55049 (53290)	Loss/tok 3.6043 (4.6546)	Learning Rate [0.00125]
15: TRAIN [0][2130/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00092)	Tok/s 56313 (53862)	Loss/tok 3.8429 (4.6541)	Learning Rate [0.00125]
10: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 57660 (53373)	Loss/tok 3.6965 (4.6514)	Learning Rate [0.00125]
11: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 57591 (53450)	Loss/tok 3.8662 (4.6468)	Learning Rate [0.00125]
9: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00094)	Tok/s 57702 (53288)	Loss/tok 3.7540 (4.6494)	Learning Rate [0.00125]
8: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00098)	Tok/s 57669 (53228)	Loss/tok 3.7724 (4.6507)	Learning Rate [0.00125]
12: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00100)	Tok/s 57669 (53561)	Loss/tok 3.7695 (4.6469)	Learning Rate [0.00125]
7: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 57624 (53150)	Loss/tok 3.7775 (4.6503)	Learning Rate [0.00125]
13: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 58337 (53658)	Loss/tok 3.9198 (4.6541)	Learning Rate [0.00125]
14: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00095)	Tok/s 58266 (53761)	Loss/tok 3.9208 (4.6521)	Learning Rate [0.00125]
5: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 57467 (52993)	Loss/tok 3.8560 (4.6587)	Learning Rate [0.00125]
6: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00098)	Tok/s 57540 (53066)	Loss/tok 3.7343 (4.6491)	Learning Rate [0.00125]
4: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 57347 (52896)	Loss/tok 3.9666 (4.6490)	Learning Rate [0.00125]
3: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00099)	Tok/s 57235 (52808)	Loss/tok 3.8569 (4.6432)	Learning Rate [0.00125]
2: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 57197 (52715)	Loss/tok 3.7688 (4.6528)	Learning Rate [0.00125]
0: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 57142 (52506)	Loss/tok 4.1917 (4.6486)	Learning Rate [0.00125]
1: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 57134 (52612)	Loss/tok 3.7799 (4.6481)	Learning Rate [0.00125]
15: TRAIN [0][2140/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 58136 (53860)	Loss/tok 3.7034 (4.6494)	Learning Rate [0.00125]
7: TRAIN [0][2150/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 32544 (53134)	Loss/tok 3.3608 (4.6462)	Learning Rate [0.00125]
8: TRAIN [0][2150/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00098)	Tok/s 32493 (53212)	Loss/tok 3.5304 (4.6460)	Learning Rate [0.00125]
5: TRAIN [0][2150/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00096)	Tok/s 32591 (52977)	Loss/tok 3.2112 (4.6543)	Learning Rate [0.00125]
6: TRAIN [0][2150/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00098)	Tok/s 32579 (53049)	Loss/tok 3.1474 (4.6446)	Learning Rate [0.00125]
4: TRAIN [0][2150/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00092)	Tok/s 32562 (52881)	Loss/tok 3.1026 (4.6441)	Learning Rate [0.00125]
9: TRAIN [0][2150/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00094)	Tok/s 32384 (53272)	Loss/tok 3.4205 (4.6448)	Learning Rate [0.00125]
10: TRAIN [0][2150/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00098)	Tok/s 32334 (53358)	Loss/tok 3.2638 (4.6466)	Learning Rate [0.00125]
3: TRAIN [0][2150/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00099)	Tok/s 32563 (52793)	Loss/tok 3.2544 (4.6388)	Learning Rate [0.00125]
12: TRAIN [0][2150/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00100)	Tok/s 32998 (53545)	Loss/tok 3.0726 (4.6421)	Learning Rate [0.00125]
2: TRAIN [0][2150/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00098)	Tok/s 32532 (52701)	Loss/tok 3.1715 (4.6481)	Learning Rate [0.00125]
11: TRAIN [0][2150/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00099)	Tok/s 32219 (53435)	Loss/tok 3.1588 (4.6424)	Learning Rate [0.00125]
1: TRAIN [0][2150/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00093)	Tok/s 32431 (52598)	Loss/tok 3.4439 (4.6440)	Learning Rate [0.00125]
14: TRAIN [0][2150/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00095)	Tok/s 33549 (53745)	Loss/tok 3.2708 (4.6474)	Learning Rate [0.00125]
13: TRAIN [0][2150/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00099)	Tok/s 33529 (53642)	Loss/tok 3.2101 (4.6496)	Learning Rate [0.00125]
0: TRAIN [0][2150/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 32315 (52492)	Loss/tok 3.0987 (4.6441)	Learning Rate [0.00125]
15: TRAIN [0][2150/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00092)	Tok/s 33558 (53844)	Loss/tok 3.3515 (4.6448)	Learning Rate [0.00125]
0: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 65030 (52488)	Loss/tok 3.6794 (4.6392)	Learning Rate [0.00125]
1: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 65053 (52594)	Loss/tok 3.6316 (4.6393)	Learning Rate [0.00125]
14: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00095)	Tok/s 65490 (53740)	Loss/tok 3.6023 (4.6430)	Learning Rate [0.00125]
2: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 65014 (52697)	Loss/tok 3.8880 (4.6432)	Learning Rate [0.00125]
4: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 65040 (52876)	Loss/tok 3.8365 (4.6393)	Learning Rate [0.00125]
3: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00099)	Tok/s 64999 (52789)	Loss/tok 3.7270 (4.6339)	Learning Rate [0.00125]
13: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00099)	Tok/s 64606 (53637)	Loss/tok 3.8709 (4.6450)	Learning Rate [0.00125]
5: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00096)	Tok/s 64923 (52972)	Loss/tok 3.8172 (4.6495)	Learning Rate [0.00125]
12: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00100)	Tok/s 64576 (53540)	Loss/tok 3.7479 (4.6373)	Learning Rate [0.00125]
6: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00098)	Tok/s 64846 (53044)	Loss/tok 3.9063 (4.6399)	Learning Rate [0.00125]
10: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 64579 (53352)	Loss/tok 3.8137 (4.6419)	Learning Rate [0.00125]
7: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 64785 (53128)	Loss/tok 3.6291 (4.6418)	Learning Rate [0.00125]
15: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 65823 (53839)	Loss/tok 3.8770 (4.6405)	Learning Rate [0.00125]
11: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00099)	Tok/s 64530 (53430)	Loss/tok 3.4189 (4.6374)	Learning Rate [0.00125]
9: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00094)	Tok/s 64652 (53266)	Loss/tok 3.7647 (4.6402)	Learning Rate [0.00125]
8: TRAIN [0][2160/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 64659 (53206)	Loss/tok 3.9224 (4.6413)	Learning Rate [0.00125]
10: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 81678 (53356)	Loss/tok 3.5344 (4.6370)	Learning Rate [0.00125]
12: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 81521 (53544)	Loss/tok 3.7422 (4.6328)	Learning Rate [0.00125]
9: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00094)	Tok/s 81716 (53270)	Loss/tok 3.6440 (4.6351)	Learning Rate [0.00125]
11: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00099)	Tok/s 81666 (53435)	Loss/tok 3.7560 (4.6329)	Learning Rate [0.00125]
8: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 80964 (53211)	Loss/tok 3.5735 (4.6360)	Learning Rate [0.00125]
13: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00099)	Tok/s 81360 (53641)	Loss/tok 3.6219 (4.6398)	Learning Rate [0.00125]
14: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00095)	Tok/s 81320 (53744)	Loss/tok 3.5612 (4.6380)	Learning Rate [0.00125]
7: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00092)	Tok/s 80758 (53133)	Loss/tok 3.7045 (4.6367)	Learning Rate [0.00125]
1: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 79865 (52600)	Loss/tok 3.5305 (4.6347)	Learning Rate [0.00125]
2: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 80604 (52703)	Loss/tok 3.8800 (4.6383)	Learning Rate [0.00125]
0: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 79572 (52495)	Loss/tok 3.6791 (4.6342)	Learning Rate [0.00125]
5: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 80605 (52977)	Loss/tok 3.6496 (4.6445)	Learning Rate [0.00125]
4: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 80589 (52881)	Loss/tok 3.5422 (4.6345)	Learning Rate [0.00125]
6: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00098)	Tok/s 80712 (53049)	Loss/tok 3.5793 (4.6347)	Learning Rate [0.00125]
3: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 80632 (52794)	Loss/tok 3.6960 (4.6291)	Learning Rate [0.00125]
15: TRAIN [0][2170/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 81878 (53842)	Loss/tok 3.5308 (4.6352)	Learning Rate [0.00125]
12: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00109 (0.00100)	Tok/s 58024 (53557)	Loss/tok 3.7914 (4.6282)	Learning Rate [0.00125]
10: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00098)	Tok/s 58012 (53369)	Loss/tok 3.7503 (4.6323)	Learning Rate [0.00125]
13: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00099)	Tok/s 57903 (53654)	Loss/tok 3.7487 (4.6350)	Learning Rate [0.00125]
14: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00086 (0.00095)	Tok/s 57850 (53756)	Loss/tok 4.0571 (4.6335)	Learning Rate [0.00125]
11: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00105 (0.00099)	Tok/s 57925 (53448)	Loss/tok 3.7388 (4.6277)	Learning Rate [0.00125]
9: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00094)	Tok/s 57998 (53284)	Loss/tok 3.6432 (4.6301)	Learning Rate [0.00125]
8: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00098)	Tok/s 57997 (53224)	Loss/tok 3.6512 (4.6313)	Learning Rate [0.00125]
0: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00092)	Tok/s 57156 (52511)	Loss/tok 3.8157 (4.6293)	Learning Rate [0.00125]
15: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00092)	Tok/s 57751 (53855)	Loss/tok 3.4818 (4.6307)	Learning Rate [0.00125]
1: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00093)	Tok/s 57718 (52616)	Loss/tok 3.8818 (4.6299)	Learning Rate [0.00125]
7: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00083 (0.00092)	Tok/s 58024 (53147)	Loss/tok 3.5584 (4.6322)	Learning Rate [0.00125]
2: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00098)	Tok/s 57687 (52719)	Loss/tok 3.6446 (4.6334)	Learning Rate [0.00125]
4: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00092)	Tok/s 57793 (52896)	Loss/tok 3.9085 (4.6300)	Learning Rate [0.00125]
5: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00096)	Tok/s 57799 (52992)	Loss/tok 3.8758 (4.6401)	Learning Rate [0.00125]
3: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00099)	Tok/s 57721 (52810)	Loss/tok 3.9040 (4.6247)	Learning Rate [0.00125]
6: TRAIN [0][2180/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00098)	Tok/s 57900 (53063)	Loss/tok 3.7848 (4.6299)	Learning Rate [0.00125]
12: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00100 (0.00100)	Tok/s 57179 (53565)	Loss/tok 3.9823 (4.6231)	Learning Rate [0.00125]
13: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00099)	Tok/s 57142 (53663)	Loss/tok 3.9440 (4.6297)	Learning Rate [0.00125]
11: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00099)	Tok/s 57225 (53456)	Loss/tok 3.8474 (4.6225)	Learning Rate [0.00125]
10: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00098)	Tok/s 56573 (53377)	Loss/tok 3.8975 (4.6276)	Learning Rate [0.00125]
14: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00095)	Tok/s 57017 (53766)	Loss/tok 3.9024 (4.6285)	Learning Rate [0.00125]
15: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00092)	Tok/s 56923 (53864)	Loss/tok 3.7838 (4.6254)	Learning Rate [0.00125]
0: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00092)	Tok/s 55890 (52518)	Loss/tok 3.9630 (4.6244)	Learning Rate [0.00125]
9: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00094)	Tok/s 56175 (53291)	Loss/tok 3.7202 (4.6247)	Learning Rate [0.00125]
1: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00100 (0.00093)	Tok/s 55827 (52623)	Loss/tok 4.0056 (4.6254)	Learning Rate [0.00125]
8: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00098)	Tok/s 56180 (53232)	Loss/tok 3.9950 (4.6259)	Learning Rate [0.00125]
2: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00098)	Tok/s 55837 (52725)	Loss/tok 3.5389 (4.6281)	Learning Rate [0.00125]
3: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00104 (0.00099)	Tok/s 55830 (52817)	Loss/tok 3.7261 (4.6195)	Learning Rate [0.00125]
5: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00096)	Tok/s 55894 (52999)	Loss/tok 3.9608 (4.6354)	Learning Rate [0.00125]
4: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00092)	Tok/s 55834 (52904)	Loss/tok 3.7811 (4.6252)	Learning Rate [0.00125]
6: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00098)	Tok/s 56019 (53070)	Loss/tok 3.9051 (4.6249)	Learning Rate [0.00125]
7: TRAIN [0][2190/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00092)	Tok/s 56028 (53154)	Loss/tok 3.6933 (4.6270)	Learning Rate [0.00125]
12: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00100)	Tok/s 48605 (53569)	Loss/tok 3.3171 (4.6179)	Learning Rate [0.00125]
11: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00099)	Tok/s 48704 (53460)	Loss/tok 3.5155 (4.6179)	Learning Rate [0.00125]
13: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00099)	Tok/s 48590 (53667)	Loss/tok 3.5804 (4.6248)	Learning Rate [0.00125]
10: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00098)	Tok/s 48563 (53380)	Loss/tok 3.3716 (4.6225)	Learning Rate [0.00125]
14: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00095)	Tok/s 48519 (53770)	Loss/tok 3.4695 (4.6239)	Learning Rate [0.00125]
15: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00079 (0.00092)	Tok/s 48560 (53869)	Loss/tok 3.2795 (4.6206)	Learning Rate [0.00125]
9: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00079 (0.00094)	Tok/s 48597 (53295)	Loss/tok 3.3877 (4.6197)	Learning Rate [0.00125]
0: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00092)	Tok/s 47158 (52523)	Loss/tok 3.6971 (4.6197)	Learning Rate [0.00125]
8: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00098)	Tok/s 48592 (53236)	Loss/tok 3.7535 (4.6215)	Learning Rate [0.00125]
7: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00078 (0.00092)	Tok/s 47653 (53158)	Loss/tok 3.3036 (4.6220)	Learning Rate [0.00125]
1: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00093)	Tok/s 47114 (52627)	Loss/tok 3.3557 (4.6206)	Learning Rate [0.00125]
2: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00098)	Tok/s 47175 (52729)	Loss/tok 3.5865 (4.6235)	Learning Rate [0.00125]
5: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00096)	Tok/s 47030 (53002)	Loss/tok 3.1543 (4.6303)	Learning Rate [0.00125]
4: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00092)	Tok/s 47044 (52907)	Loss/tok 3.3609 (4.6202)	Learning Rate [0.00125]
6: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00098)	Tok/s 47019 (53073)	Loss/tok 3.2959 (4.6199)	Learning Rate [0.00125]
3: TRAIN [0][2200/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00099)	Tok/s 47068 (52821)	Loss/tok 3.4596 (4.6145)	Learning Rate [0.00125]
5: TRAIN [0][2210/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00096)	Tok/s 82558 (53014)	Loss/tok 3.5417 (4.6255)	Learning Rate [0.00125]
6: TRAIN [0][2210/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00098)	Tok/s 82576 (53086)	Loss/tok 3.5414 (4.6149)	Learning Rate [0.00125]
10: TRAIN [0][2210/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00098)	Tok/s 83645 (53392)	Loss/tok 3.5064 (4.6178)	Learning Rate [0.00125]
3: TRAIN [0][2210/3416]	Time 0.071 (0.058)	Data 0.00098 (0.00099)	Tok/s 81547 (52833)	Loss/tok 3.5136 (4.6095)	Learning Rate [0.00125]
2: TRAIN [0][2210/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00098)	Tok/s 81515 (52742)	Loss/tok 3.6664 (4.6188)	Learning Rate [0.00125]
7: TRAIN [0][2210/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00092)	Tok/s 82578 (53169)	Loss/tok 3.4638 (4.6171)	Learning Rate [0.00125]
8: TRAIN [0][2210/3416]	Time 0.071 (0.058)	Data 0.00101 (0.00098)	Tok/s 82588 (53247)	Loss/tok 3.4271 (4.6168)	Learning Rate [0.00125]
11: TRAIN [0][2210/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00099)	Tok/s 83744 (53472)	Loss/tok 3.3318 (4.6128)	Learning Rate [0.00125]
12: TRAIN [0][2210/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00100)	Tok/s 83664 (53580)	Loss/tok 3.5395 (4.6130)	Learning Rate [0.00125]
4: TRAIN [0][2210/3416]	Time 0.071 (0.058)	Data 0.00114 (0.00092)	Tok/s 82196 (52920)	Loss/tok 3.6736 (4.6156)	Learning Rate [0.00125]
9: TRAIN [0][2210/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00094)	Tok/s 82604 (53306)	Loss/tok 3.4428 (4.6149)	Learning Rate [0.00125]
1: TRAIN [0][2210/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00093)	Tok/s 81547 (52640)	Loss/tok 3.5092 (4.6158)	Learning Rate [0.00125]
13: TRAIN [0][2210/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00099)	Tok/s 83566 (53678)	Loss/tok 3.3844 (4.6196)	Learning Rate [0.00125]
15: TRAIN [0][2210/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00092)	Tok/s 84253 (53881)	Loss/tok 3.6383 (4.6158)	Learning Rate [0.00125]
14: TRAIN [0][2210/3416]	Time 0.071 (0.058)	Data 0.00093 (0.00095)	Tok/s 83702 (53782)	Loss/tok 3.4965 (4.6192)	Learning Rate [0.00125]
0: TRAIN [0][2210/3416]	Time 0.071 (0.058)	Data 0.00091 (0.00092)	Tok/s 81517 (52536)	Loss/tok 3.4193 (4.6146)	Learning Rate [0.00125]
8: TRAIN [0][2220/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00098)	Tok/s 53826 (53258)	Loss/tok 3.8394 (4.6123)	Learning Rate [0.00125]
10: TRAIN [0][2220/3416]	Time 0.057 (0.058)	Data 0.00103 (0.00098)	Tok/s 53846 (53403)	Loss/tok 3.8663 (4.6135)	Learning Rate [0.00125]
9: TRAIN [0][2220/3416]	Time 0.057 (0.058)	Data 0.00106 (0.00094)	Tok/s 53807 (53317)	Loss/tok 3.5093 (4.6100)	Learning Rate [0.00125]
7: TRAIN [0][2220/3416]	Time 0.057 (0.058)	Data 0.00086 (0.00092)	Tok/s 53693 (53180)	Loss/tok 3.8438 (4.6124)	Learning Rate [0.00125]
5: TRAIN [0][2220/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00096)	Tok/s 53514 (53023)	Loss/tok 3.8894 (4.6206)	Learning Rate [0.00125]
6: TRAIN [0][2220/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00098)	Tok/s 53594 (53095)	Loss/tok 3.9400 (4.6100)	Learning Rate [0.00125]
11: TRAIN [0][2220/3416]	Time 0.057 (0.058)	Data 0.00116 (0.00099)	Tok/s 54056 (53483)	Loss/tok 3.4816 (4.6081)	Learning Rate [0.00125]
4: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00083 (0.00092)	Tok/s 53384 (52928)	Loss/tok 3.8934 (4.6111)	Learning Rate [0.00125]
12: TRAIN [0][2220/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00100)	Tok/s 54718 (53591)	Loss/tok 3.5097 (4.6081)	Learning Rate [0.00125]
3: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00102 (0.00099)	Tok/s 53273 (52841)	Loss/tok 3.6117 (4.6052)	Learning Rate [0.00125]
14: TRAIN [0][2220/3416]	Time 0.057 (0.058)	Data 0.00105 (0.00095)	Tok/s 54560 (53794)	Loss/tok 3.7064 (4.6147)	Learning Rate [0.00125]
2: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00083 (0.00098)	Tok/s 53235 (52749)	Loss/tok 3.5542 (4.6141)	Learning Rate [0.00125]
13: TRAIN [0][2220/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00099)	Tok/s 54639 (53690)	Loss/tok 3.6703 (4.6149)	Learning Rate [0.00125]
15: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00084 (0.00092)	Tok/s 54383 (53893)	Loss/tok 3.4635 (4.6110)	Learning Rate [0.00125]
1: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00080 (0.00093)	Tok/s 53213 (52646)	Loss/tok 3.6654 (4.6109)	Learning Rate [0.00125]
0: TRAIN [0][2220/3416]	Time 0.058 (0.058)	Data 0.00081 (0.00092)	Tok/s 53170 (52541)	Loss/tok 3.6296 (4.6097)	Learning Rate [0.00125]
15: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00077 (0.00092)	Tok/s 54133 (53894)	Loss/tok 3.5795 (4.6066)	Learning Rate [0.00125]
14: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00079 (0.00095)	Tok/s 54186 (53794)	Loss/tok 3.9378 (4.6103)	Learning Rate [0.00125]
0: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00078 (0.00092)	Tok/s 54017 (52543)	Loss/tok 3.6317 (4.6056)	Learning Rate [0.00125]
2: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00098)	Tok/s 53882 (52751)	Loss/tok 3.8161 (4.6098)	Learning Rate [0.00125]
12: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00101 (0.00100)	Tok/s 54193 (53592)	Loss/tok 3.5908 (4.6035)	Learning Rate [0.00125]
1: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00082 (0.00093)	Tok/s 53883 (52648)	Loss/tok 3.7277 (4.6064)	Learning Rate [0.00125]
4: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00074 (0.00092)	Tok/s 53984 (52931)	Loss/tok 3.6053 (4.6066)	Learning Rate [0.00125]
13: TRAIN [0][2230/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00099)	Tok/s 54224 (53691)	Loss/tok 3.5267 (4.6099)	Learning Rate [0.00125]
3: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00099)	Tok/s 53937 (52844)	Loss/tok 3.5362 (4.6009)	Learning Rate [0.00125]
5: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00096)	Tok/s 53946 (53025)	Loss/tok 3.6429 (4.6159)	Learning Rate [0.00125]
11: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00099)	Tok/s 54088 (53484)	Loss/tok 3.5450 (4.6038)	Learning Rate [0.00125]
10: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00109 (0.00098)	Tok/s 54158 (53405)	Loss/tok 3.4447 (4.6088)	Learning Rate [0.00125]
6: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00098)	Tok/s 53934 (53098)	Loss/tok 3.7179 (4.6058)	Learning Rate [0.00125]
8: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00100 (0.00098)	Tok/s 53993 (53261)	Loss/tok 3.5653 (4.6082)	Learning Rate [0.00125]
7: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00092)	Tok/s 53941 (53182)	Loss/tok 3.4970 (4.6081)	Learning Rate [0.00125]
9: TRAIN [0][2230/3416]	Time 0.056 (0.058)	Data 0.00086 (0.00094)	Tok/s 54083 (53319)	Loss/tok 3.3785 (4.6053)	Learning Rate [0.00125]
2: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 58311 (52763)	Loss/tok 3.9392 (4.6053)	Learning Rate [0.00125]
3: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00099)	Tok/s 58316 (52855)	Loss/tok 3.6528 (4.5958)	Learning Rate [0.00125]
1: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00093)	Tok/s 58241 (52659)	Loss/tok 3.9495 (4.6014)	Learning Rate [0.00125]
4: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00092)	Tok/s 58323 (52941)	Loss/tok 3.7639 (4.6017)	Learning Rate [0.00125]
15: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 59058 (53904)	Loss/tok 3.6126 (4.6019)	Learning Rate [0.00125]
5: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 58340 (53036)	Loss/tok 3.7605 (4.6109)	Learning Rate [0.00125]
14: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00095)	Tok/s 59057 (53804)	Loss/tok 3.7725 (4.6057)	Learning Rate [0.00125]
13: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00099)	Tok/s 59078 (53701)	Loss/tok 3.8706 (4.6056)	Learning Rate [0.00125]
0: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 58099 (52555)	Loss/tok 3.7518 (4.6009)	Learning Rate [0.00125]
6: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00191 (0.00098)	Tok/s 58400 (53108)	Loss/tok 3.6567 (4.6010)	Learning Rate [0.00125]
12: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00100)	Tok/s 58493 (53603)	Loss/tok 3.6183 (4.5989)	Learning Rate [0.00125]
8: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00098)	Tok/s 58294 (53271)	Loss/tok 3.5657 (4.6036)	Learning Rate [0.00125]
7: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00113 (0.00092)	Tok/s 58325 (53192)	Loss/tok 3.7002 (4.6034)	Learning Rate [0.00125]
11: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00099)	Tok/s 58162 (53495)	Loss/tok 3.6631 (4.5993)	Learning Rate [0.00125]
10: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 58149 (53415)	Loss/tok 3.8804 (4.6041)	Learning Rate [0.00125]
9: TRAIN [0][2240/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00094)	Tok/s 58256 (53329)	Loss/tok 3.7641 (4.6007)	Learning Rate [0.00125]
4: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
9: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
14: TRAIN [0][2250/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00095)	Tok/s 52925 (53805)	Loss/tok 3.4804 (4.6011)	Learning Rate [0.00125]
15: TRAIN [0][2250/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00092)	Tok/s 53010 (53905)	Loss/tok 3.7158 (4.5973)	Learning Rate [0.00125]
13: TRAIN [0][2250/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00099)	Tok/s 52962 (53702)	Loss/tok 3.5136 (4.6013)	Learning Rate [0.00125]
0: TRAIN [0][2250/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00092)	Tok/s 52960 (52558)	Loss/tok 3.5511 (4.5961)	Learning Rate [0.00125]
2: TRAIN [0][2250/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00098)	Tok/s 52743 (52765)	Loss/tok 3.5585 (4.6010)	Learning Rate [0.00125]
1: TRAIN [0][2250/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00093)	Tok/s 52763 (52662)	Loss/tok 3.8266 (4.5969)	Learning Rate [0.00125]
12: TRAIN [0][2250/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00100)	Tok/s 52880 (53604)	Loss/tok 3.5947 (4.5943)	Learning Rate [0.00125]
3: TRAIN [0][2250/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00099)	Tok/s 52618 (52857)	Loss/tok 3.3013 (4.5910)	Learning Rate [0.00125]
11: TRAIN [0][2250/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00099)	Tok/s 53020 (53496)	Loss/tok 3.8630 (4.5952)	Learning Rate [0.00125]
4: TRAIN [0][2250/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00092)	Tok/s 52515 (52943)	Loss/tok 3.6524 (4.5974)	Learning Rate [0.00125]
10: TRAIN [0][2250/3416]	Time 0.047 (0.058)	Data 0.00114 (0.00098)	Tok/s 52882 (53416)	Loss/tok 3.5067 (4.5995)	Learning Rate [0.00125]
8: TRAIN [0][2250/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00098)	Tok/s 52707 (53272)	Loss/tok 3.6240 (4.5993)	Learning Rate [0.00125]
5: TRAIN [0][2250/3416]	Time 0.048 (0.058)	Data 0.00110 (0.00096)	Tok/s 52527 (53038)	Loss/tok 3.5037 (4.6060)	Learning Rate [0.00125]
7: TRAIN [0][2250/3416]	Time 0.048 (0.058)	Data 0.00120 (0.00092)	Tok/s 52496 (53194)	Loss/tok 3.3828 (4.5988)	Learning Rate [0.00125]
9: TRAIN [0][2250/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00094)	Tok/s 52578 (53330)	Loss/tok 3.5854 (4.5965)	Learning Rate [0.00125]
6: TRAIN [0][2250/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00098)	Tok/s 52554 (53109)	Loss/tok 3.6910 (4.5969)	Learning Rate [0.00125]
4: TRAIN [0][2260/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00092)	Tok/s 54298 (52944)	Loss/tok 3.6224 (4.5930)	Learning Rate [0.00125]
5: TRAIN [0][2260/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00096)	Tok/s 54248 (53038)	Loss/tok 3.6500 (4.6019)	Learning Rate [0.00125]
6: TRAIN [0][2260/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00098)	Tok/s 54175 (53110)	Loss/tok 3.4868 (4.5921)	Learning Rate [0.00125]
3: TRAIN [0][2260/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00099)	Tok/s 54282 (52858)	Loss/tok 3.7708 (4.5867)	Learning Rate [0.00125]
7: TRAIN [0][2260/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00092)	Tok/s 54122 (53195)	Loss/tok 3.6250 (4.5946)	Learning Rate [0.00125]
2: TRAIN [0][2260/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00098)	Tok/s 54199 (52765)	Loss/tok 3.5523 (4.5964)	Learning Rate [0.00125]
8: TRAIN [0][2260/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00098)	Tok/s 53998 (53273)	Loss/tok 3.8759 (4.5950)	Learning Rate [0.00125]
1: TRAIN [0][2260/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00093)	Tok/s 54137 (52663)	Loss/tok 3.5662 (4.5923)	Learning Rate [0.00125]
10: TRAIN [0][2260/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00098)	Tok/s 53995 (53418)	Loss/tok 3.5974 (4.5952)	Learning Rate [0.00125]
9: TRAIN [0][2260/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00094)	Tok/s 53950 (53332)	Loss/tok 3.6591 (4.5922)	Learning Rate [0.00125]
0: TRAIN [0][2260/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00092)	Tok/s 54083 (52558)	Loss/tok 3.6280 (4.5916)	Learning Rate [0.00125]
15: TRAIN [0][2260/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00092)	Tok/s 55063 (53906)	Loss/tok 3.6072 (4.5929)	Learning Rate [0.00125]
11: TRAIN [0][2260/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00099)	Tok/s 54866 (53498)	Loss/tok 3.7522 (4.5910)	Learning Rate [0.00125]
14: TRAIN [0][2260/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00095)	Tok/s 55012 (53806)	Loss/tok 3.7041 (4.5970)	Learning Rate [0.00125]
12: TRAIN [0][2260/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00100)	Tok/s 54901 (53605)	Loss/tok 3.6116 (4.5901)	Learning Rate [0.00125]
13: TRAIN [0][2260/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00099)	Tok/s 55223 (53704)	Loss/tok 3.8076 (4.5968)	Learning Rate [0.00125]
3: TRAIN [0][2270/3416]	Time 0.061 (0.058)	Data 0.00101 (0.00099)	Tok/s 57309 (52868)	Loss/tok 3.5982 (4.5820)	Learning Rate [0.00125]
2: TRAIN [0][2270/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00098)	Tok/s 57174 (52776)	Loss/tok 3.6403 (4.5919)	Learning Rate [0.00125]
4: TRAIN [0][2270/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00092)	Tok/s 57257 (52954)	Loss/tok 3.9591 (4.5889)	Learning Rate [0.00125]
1: TRAIN [0][2270/3416]	Time 0.062 (0.058)	Data 0.00085 (0.00093)	Tok/s 57151 (52674)	Loss/tok 3.6152 (4.5877)	Learning Rate [0.00125]
0: TRAIN [0][2270/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00092)	Tok/s 57145 (52569)	Loss/tok 3.8081 (4.5875)	Learning Rate [0.00125]
15: TRAIN [0][2270/3416]	Time 0.062 (0.058)	Data 0.00081 (0.00092)	Tok/s 57159 (53915)	Loss/tok 3.8070 (4.5887)	Learning Rate [0.00125]
6: TRAIN [0][2270/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00098)	Tok/s 57276 (53119)	Loss/tok 3.2755 (4.5876)	Learning Rate [0.00125]
5: TRAIN [0][2270/3416]	Time 0.061 (0.058)	Data 0.00104 (0.00096)	Tok/s 57299 (53048)	Loss/tok 3.7940 (4.5970)	Learning Rate [0.00125]
14: TRAIN [0][2270/3416]	Time 0.062 (0.058)	Data 0.00082 (0.00095)	Tok/s 57127 (53815)	Loss/tok 3.4904 (4.5923)	Learning Rate [0.00125]
7: TRAIN [0][2270/3416]	Time 0.061 (0.058)	Data 0.00082 (0.00092)	Tok/s 57283 (53204)	Loss/tok 3.7581 (4.5899)	Learning Rate [0.00125]
8: TRAIN [0][2270/3416]	Time 0.061 (0.058)	Data 0.00101 (0.00098)	Tok/s 57292 (53282)	Loss/tok 3.9437 (4.5907)	Learning Rate [0.00125]
13: TRAIN [0][2270/3416]	Time 0.062 (0.058)	Data 0.00107 (0.00099)	Tok/s 57198 (53713)	Loss/tok 3.7535 (4.5922)	Learning Rate [0.00125]
9: TRAIN [0][2270/3416]	Time 0.061 (0.058)	Data 0.00082 (0.00094)	Tok/s 57312 (53341)	Loss/tok 3.5921 (4.5877)	Learning Rate [0.00125]
12: TRAIN [0][2270/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00100)	Tok/s 57195 (53614)	Loss/tok 3.7609 (4.5856)	Learning Rate [0.00125]
10: TRAIN [0][2270/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00098)	Tok/s 57228 (53427)	Loss/tok 3.5494 (4.5904)	Learning Rate [0.00125]
11: TRAIN [0][2270/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00099)	Tok/s 57218 (53507)	Loss/tok 3.9111 (4.5868)	Learning Rate [0.00125]
3: TRAIN [0][2280/3416]	Time 0.057 (0.058)	Data 0.00106 (0.00099)	Tok/s 55925 (52904)	Loss/tok 3.6648 (4.5776)	Learning Rate [0.00125]
2: TRAIN [0][2280/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00098)	Tok/s 55906 (52812)	Loss/tok 3.5107 (4.5869)	Learning Rate [0.00125]
4: TRAIN [0][2280/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00092)	Tok/s 55792 (52989)	Loss/tok 3.6918 (4.5841)	Learning Rate [0.00125]
0: TRAIN [0][2280/3416]	Time 0.057 (0.058)	Data 0.00089 (0.00092)	Tok/s 55669 (52605)	Loss/tok 3.5356 (4.5822)	Learning Rate [0.00125]
5: TRAIN [0][2280/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00096)	Tok/s 55644 (53083)	Loss/tok 3.8784 (4.5917)	Learning Rate [0.00125]
1: TRAIN [0][2280/3416]	Time 0.057 (0.058)	Data 0.00089 (0.00093)	Tok/s 55911 (52709)	Loss/tok 3.6997 (4.5829)	Learning Rate [0.00125]
15: TRAIN [0][2280/3416]	Time 0.057 (0.058)	Data 0.00085 (0.00092)	Tok/s 55894 (53950)	Loss/tok 3.7408 (4.5838)	Learning Rate [0.00125]
7: TRAIN [0][2280/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00092)	Tok/s 55522 (53239)	Loss/tok 3.7278 (4.5848)	Learning Rate [0.00125]
14: TRAIN [0][2280/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00095)	Tok/s 55807 (53850)	Loss/tok 3.6270 (4.5871)	Learning Rate [0.00125]
13: TRAIN [0][2280/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00099)	Tok/s 55701 (53748)	Loss/tok 3.6208 (4.5871)	Learning Rate [0.00125]
8: TRAIN [0][2280/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00098)	Tok/s 55502 (53318)	Loss/tok 3.6211 (4.5857)	Learning Rate [0.00125]
10: TRAIN [0][2280/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00098)	Tok/s 55477 (53462)	Loss/tok 3.4188 (4.5855)	Learning Rate [0.00125]
12: TRAIN [0][2280/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00100)	Tok/s 55542 (53649)	Loss/tok 3.8754 (4.5810)	Learning Rate [0.00125]
9: TRAIN [0][2280/3416]	Time 0.058 (0.058)	Data 0.00083 (0.00094)	Tok/s 55505 (53376)	Loss/tok 3.4452 (4.5830)	Learning Rate [0.00125]
11: TRAIN [0][2280/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00099)	Tok/s 55520 (53542)	Loss/tok 3.4166 (4.5816)	Learning Rate [0.00125]
6: TRAIN [0][2280/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00098)	Tok/s 55296 (53155)	Loss/tok 3.7563 (4.5827)	Learning Rate [0.00125]
0: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 67702 (52614)	Loss/tok 3.4750 (4.5778)	Learning Rate [0.00125]
15: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 68415 (53957)	Loss/tok 3.6876 (4.5793)	Learning Rate [0.00125]
14: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00095)	Tok/s 68428 (53857)	Loss/tok 3.7171 (4.5829)	Learning Rate [0.00125]
11: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 68360 (53549)	Loss/tok 3.8070 (4.5776)	Learning Rate [0.00125]
13: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00099)	Tok/s 68432 (53755)	Loss/tok 4.0003 (4.5832)	Learning Rate [0.00125]
12: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00120 (0.00100)	Tok/s 68433 (53656)	Loss/tok 3.7957 (4.5771)	Learning Rate [0.00125]
3: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00099)	Tok/s 67621 (52911)	Loss/tok 3.4512 (4.5731)	Learning Rate [0.00125]
2: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 67836 (52820)	Loss/tok 3.8138 (4.5825)	Learning Rate [0.00125]
4: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 67553 (52997)	Loss/tok 3.9141 (4.5796)	Learning Rate [0.00125]
8: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00098)	Tok/s 67449 (53325)	Loss/tok 3.6059 (4.5813)	Learning Rate [0.00125]
1: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 67666 (52718)	Loss/tok 3.7880 (4.5783)	Learning Rate [0.00125]
6: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00098)	Tok/s 67500 (53163)	Loss/tok 3.9136 (4.5787)	Learning Rate [0.00125]
5: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00096)	Tok/s 67555 (53091)	Loss/tok 3.4806 (4.5869)	Learning Rate [0.00125]
7: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 67349 (53247)	Loss/tok 3.7632 (4.5804)	Learning Rate [0.00125]
9: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00094)	Tok/s 67417 (53383)	Loss/tok 3.8372 (4.5789)	Learning Rate [0.00125]
10: TRAIN [0][2290/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 68126 (53469)	Loss/tok 3.5682 (4.5816)	Learning Rate [0.00125]
10: TRAIN [0][2300/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00098)	Tok/s 46495 (53491)	Loss/tok 3.3074 (4.5769)	Learning Rate [0.00125]
12: TRAIN [0][2300/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00100)	Tok/s 46535 (53679)	Loss/tok 3.3088 (4.5724)	Learning Rate [0.00125]
11: TRAIN [0][2300/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00099)	Tok/s 46599 (53572)	Loss/tok 3.4495 (4.5729)	Learning Rate [0.00125]
13: TRAIN [0][2300/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00099)	Tok/s 46474 (53778)	Loss/tok 3.3386 (4.5785)	Learning Rate [0.00125]
8: TRAIN [0][2300/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00098)	Tok/s 46238 (53347)	Loss/tok 3.3405 (4.5765)	Learning Rate [0.00125]
9: TRAIN [0][2300/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00094)	Tok/s 46337 (53406)	Loss/tok 3.1953 (4.5741)	Learning Rate [0.00125]
14: TRAIN [0][2300/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00095)	Tok/s 46383 (53881)	Loss/tok 3.2970 (4.5785)	Learning Rate [0.00125]
7: TRAIN [0][2300/3416]	Time 0.046 (0.058)	Data 0.00081 (0.00092)	Tok/s 46133 (53269)	Loss/tok 3.0145 (4.5757)	Learning Rate [0.00125]
15: TRAIN [0][2300/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00092)	Tok/s 46251 (53980)	Loss/tok 3.3308 (4.5746)	Learning Rate [0.00125]
0: TRAIN [0][2300/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00092)	Tok/s 44692 (52638)	Loss/tok 3.5197 (4.5734)	Learning Rate [0.00125]
6: TRAIN [0][2300/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00098)	Tok/s 45097 (53185)	Loss/tok 3.2393 (4.5742)	Learning Rate [0.00125]
5: TRAIN [0][2300/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00096)	Tok/s 44536 (53113)	Loss/tok 3.3355 (4.5825)	Learning Rate [0.00125]
4: TRAIN [0][2300/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00092)	Tok/s 44483 (53020)	Loss/tok 3.2198 (4.5751)	Learning Rate [0.00125]
2: TRAIN [0][2300/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00098)	Tok/s 44561 (52843)	Loss/tok 3.3466 (4.5776)	Learning Rate [0.00125]
1: TRAIN [0][2300/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00093)	Tok/s 44647 (52741)	Loss/tok 3.1813 (4.5737)	Learning Rate [0.00125]
3: TRAIN [0][2300/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00099)	Tok/s 44382 (52934)	Loss/tok 3.0844 (4.5685)	Learning Rate [0.00125]
2: TRAIN [0][2310/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00098)	Tok/s 53259 (52852)	Loss/tok 3.5828 (4.5731)	Learning Rate [0.00125]
3: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00099)	Tok/s 53083 (52943)	Loss/tok 3.6061 (4.5646)	Learning Rate [0.00125]
1: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00093)	Tok/s 53064 (52748)	Loss/tok 3.6727 (4.5691)	Learning Rate [0.00125]
4: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00092)	Tok/s 53021 (53029)	Loss/tok 3.5930 (4.5705)	Learning Rate [0.00125]
0: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00092)	Tok/s 52972 (52644)	Loss/tok 3.6623 (4.5687)	Learning Rate [0.00125]
14: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00095)	Tok/s 53944 (53892)	Loss/tok 3.7022 (4.5741)	Learning Rate [0.00125]
15: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00084 (0.00092)	Tok/s 53884 (53993)	Loss/tok 3.4568 (4.5697)	Learning Rate [0.00125]
5: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00096)	Tok/s 53022 (53124)	Loss/tok 3.3487 (4.5783)	Learning Rate [0.00125]
13: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00099)	Tok/s 53876 (53790)	Loss/tok 3.6328 (4.5740)	Learning Rate [0.00125]
6: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00098)	Tok/s 53683 (53196)	Loss/tok 3.8852 (4.5702)	Learning Rate [0.00125]
11: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00099)	Tok/s 53928 (53583)	Loss/tok 3.8487 (4.5680)	Learning Rate [0.00125]
12: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00100)	Tok/s 53868 (53691)	Loss/tok 3.6122 (4.5682)	Learning Rate [0.00125]
8: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00098)	Tok/s 53987 (53359)	Loss/tok 3.8165 (4.5721)	Learning Rate [0.00125]
10: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00098)	Tok/s 53886 (53503)	Loss/tok 3.5102 (4.5724)	Learning Rate [0.00125]
9: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00094)	Tok/s 53902 (53418)	Loss/tok 3.9163 (4.5698)	Learning Rate [0.00125]
7: TRAIN [0][2310/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00092)	Tok/s 53942 (53280)	Loss/tok 3.4705 (4.5707)	Learning Rate [0.00125]
3: TRAIN [0][2320/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00099)	Tok/s 58871 (52949)	Loss/tok 3.7969 (4.5608)	Learning Rate [0.00125]
5: TRAIN [0][2320/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00096)	Tok/s 58988 (53128)	Loss/tok 3.8725 (4.5743)	Learning Rate [0.00125]
4: TRAIN [0][2320/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00092)	Tok/s 58896 (53034)	Loss/tok 3.4188 (4.5661)	Learning Rate [0.00125]
6: TRAIN [0][2320/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00098)	Tok/s 58990 (53200)	Loss/tok 3.6008 (4.5659)	Learning Rate [0.00125]
7: TRAIN [0][2320/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00092)	Tok/s 58994 (53285)	Loss/tok 3.6098 (4.5667)	Learning Rate [0.00125]
2: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 58787 (52857)	Loss/tok 3.8256 (4.5689)	Learning Rate [0.00125]
8: TRAIN [0][2320/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00098)	Tok/s 59846 (53364)	Loss/tok 3.7077 (4.5681)	Learning Rate [0.00125]
10: TRAIN [0][2320/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00098)	Tok/s 60000 (53508)	Loss/tok 3.5998 (4.5678)	Learning Rate [0.00125]
0: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 58793 (52650)	Loss/tok 3.8583 (4.5647)	Learning Rate [0.00125]
15: TRAIN [0][2320/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00092)	Tok/s 59826 (53996)	Loss/tok 3.5101 (4.5657)	Learning Rate [0.00125]
1: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 58821 (52754)	Loss/tok 3.9268 (4.5653)	Learning Rate [0.00125]
12: TRAIN [0][2320/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00100)	Tok/s 59923 (53696)	Loss/tok 3.4603 (4.5639)	Learning Rate [0.00125]
14: TRAIN [0][2320/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00095)	Tok/s 59842 (53896)	Loss/tok 3.8019 (4.5701)	Learning Rate [0.00125]
11: TRAIN [0][2320/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00099)	Tok/s 59932 (53588)	Loss/tok 3.5684 (4.5640)	Learning Rate [0.00125]
9: TRAIN [0][2320/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00094)	Tok/s 59936 (53423)	Loss/tok 3.6207 (4.5654)	Learning Rate [0.00125]
13: TRAIN [0][2320/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00099)	Tok/s 59753 (53794)	Loss/tok 3.5981 (4.5696)	Learning Rate [0.00125]
14: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00095)	Tok/s 52872 (53887)	Loss/tok 3.6901 (4.5664)	Learning Rate [0.00125]
13: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00099)	Tok/s 52855 (53785)	Loss/tok 3.8191 (4.5659)	Learning Rate [0.00125]
15: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00079 (0.00092)	Tok/s 52750 (53987)	Loss/tok 3.8601 (4.5613)	Learning Rate [0.00125]
0: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00092)	Tok/s 51641 (52634)	Loss/tok 3.7629 (4.5609)	Learning Rate [0.00125]
12: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00100)	Tok/s 52841 (53686)	Loss/tok 3.7997 (4.5602)	Learning Rate [0.00125]
2: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00098)	Tok/s 51760 (52844)	Loss/tok 3.5486 (4.5651)	Learning Rate [0.00125]
11: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00099)	Tok/s 52850 (53578)	Loss/tok 3.9342 (4.5600)	Learning Rate [0.00125]
1: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00093)	Tok/s 51750 (52739)	Loss/tok 3.7146 (4.5612)	Learning Rate [0.00125]
10: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00083 (0.00098)	Tok/s 52843 (53498)	Loss/tok 3.8578 (4.5640)	Learning Rate [0.00125]
9: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00080 (0.00094)	Tok/s 52891 (53413)	Loss/tok 4.0021 (4.5612)	Learning Rate [0.00125]
8: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00098)	Tok/s 52850 (53354)	Loss/tok 3.9001 (4.5641)	Learning Rate [0.00125]
4: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00102 (0.00092)	Tok/s 51757 (53022)	Loss/tok 3.5539 (4.5620)	Learning Rate [0.00125]
3: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00099)	Tok/s 51749 (52936)	Loss/tok 3.5653 (4.5571)	Learning Rate [0.00125]
7: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00086 (0.00092)	Tok/s 52186 (53274)	Loss/tok 3.6542 (4.5627)	Learning Rate [0.00125]
5: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00096)	Tok/s 51709 (53117)	Loss/tok 3.6283 (4.5704)	Learning Rate [0.00125]
6: TRAIN [0][2330/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00098)	Tok/s 51762 (53189)	Loss/tok 3.7967 (4.5617)	Learning Rate [0.00125]
1: TRAIN [0][2340/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00093)	Tok/s 58228 (52734)	Loss/tok 3.7589 (4.5575)	Learning Rate [0.00125]
0: TRAIN [0][2340/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 58243 (52630)	Loss/tok 3.4115 (4.5570)	Learning Rate [0.00125]
15: TRAIN [0][2340/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 59152 (53981)	Loss/tok 3.9663 (4.5576)	Learning Rate [0.00125]
2: TRAIN [0][2340/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00098)	Tok/s 58092 (52838)	Loss/tok 3.8265 (4.5612)	Learning Rate [0.00125]
14: TRAIN [0][2340/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00095)	Tok/s 59063 (53881)	Loss/tok 4.0418 (4.5628)	Learning Rate [0.00125]
4: TRAIN [0][2340/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00092)	Tok/s 57957 (53016)	Loss/tok 3.7157 (4.5578)	Learning Rate [0.00125]
13: TRAIN [0][2340/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00099)	Tok/s 58978 (53779)	Loss/tok 3.6839 (4.5621)	Learning Rate [0.00125]
5: TRAIN [0][2340/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 57845 (53110)	Loss/tok 3.7196 (4.5666)	Learning Rate [0.00125]
12: TRAIN [0][2340/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00100)	Tok/s 58905 (53681)	Loss/tok 3.7035 (4.5562)	Learning Rate [0.00125]
3: TRAIN [0][2340/3416]	Time 0.068 (0.058)	Data 0.00129 (0.00099)	Tok/s 58096 (52930)	Loss/tok 3.7073 (4.5532)	Learning Rate [0.00125]
7: TRAIN [0][2340/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 57711 (53268)	Loss/tok 3.9120 (4.5590)	Learning Rate [0.00125]
6: TRAIN [0][2340/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 57760 (53183)	Loss/tok 3.6091 (4.5580)	Learning Rate [0.00125]
10: TRAIN [0][2340/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00098)	Tok/s 58764 (53493)	Loss/tok 3.6868 (4.5600)	Learning Rate [0.00125]
11: TRAIN [0][2340/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00099)	Tok/s 58830 (53573)	Loss/tok 3.5832 (4.5561)	Learning Rate [0.00125]
9: TRAIN [0][2340/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00094)	Tok/s 57961 (53408)	Loss/tok 3.8487 (4.5574)	Learning Rate [0.00125]
8: TRAIN [0][2340/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 57689 (53348)	Loss/tok 3.7344 (4.5603)	Learning Rate [0.00125]
5: TRAIN [0][2350/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00096)	Tok/s 61287 (53124)	Loss/tok 3.8110 (4.5620)	Learning Rate [0.00125]
4: TRAIN [0][2350/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00092)	Tok/s 61195 (53030)	Loss/tok 3.6555 (4.5531)	Learning Rate [0.00125]
2: TRAIN [0][2350/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00098)	Tok/s 61068 (52852)	Loss/tok 3.5800 (4.5566)	Learning Rate [0.00125]
3: TRAIN [0][2350/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00099)	Tok/s 61176 (52943)	Loss/tok 3.8439 (4.5485)	Learning Rate [0.00125]
6: TRAIN [0][2350/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00098)	Tok/s 61158 (53196)	Loss/tok 3.7226 (4.5534)	Learning Rate [0.00125]
7: TRAIN [0][2350/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00092)	Tok/s 61119 (53281)	Loss/tok 3.8649 (4.5543)	Learning Rate [0.00125]
8: TRAIN [0][2350/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00098)	Tok/s 60991 (53362)	Loss/tok 3.6622 (4.5559)	Learning Rate [0.00125]
1: TRAIN [0][2350/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00093)	Tok/s 60889 (52748)	Loss/tok 3.5333 (4.5531)	Learning Rate [0.00125]
9: TRAIN [0][2350/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00094)	Tok/s 60939 (53421)	Loss/tok 3.8481 (4.5525)	Learning Rate [0.00125]
10: TRAIN [0][2350/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00098)	Tok/s 60861 (53507)	Loss/tok 3.8206 (4.5555)	Learning Rate [0.00125]
11: TRAIN [0][2350/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00099)	Tok/s 60762 (53587)	Loss/tok 3.6899 (4.5516)	Learning Rate [0.00125]
14: TRAIN [0][2350/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00095)	Tok/s 60598 (53896)	Loss/tok 3.8263 (4.5582)	Learning Rate [0.00125]
15: TRAIN [0][2350/3416]	Time 0.069 (0.058)	Data 0.00078 (0.00092)	Tok/s 61533 (53997)	Loss/tok 3.6109 (4.5531)	Learning Rate [0.00125]
12: TRAIN [0][2350/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 60684 (53695)	Loss/tok 3.8181 (4.5516)	Learning Rate [0.00125]
13: TRAIN [0][2350/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00099)	Tok/s 60572 (53794)	Loss/tok 3.7967 (4.5577)	Learning Rate [0.00125]
0: TRAIN [0][2350/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00092)	Tok/s 60749 (52644)	Loss/tok 3.8454 (4.5523)	Learning Rate [0.00125]
2: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00098)	Tok/s 36322 (52827)	Loss/tok 3.1012 (4.5525)	Learning Rate [0.00125]
0: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00092)	Tok/s 35435 (52618)	Loss/tok 3.2530 (4.5485)	Learning Rate [0.00125]
3: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00112 (0.00099)	Tok/s 36239 (52918)	Loss/tok 3.2630 (4.5446)	Learning Rate [0.00125]
14: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00095)	Tok/s 36323 (53871)	Loss/tok 3.3711 (4.5544)	Learning Rate [0.00125]
5: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00096)	Tok/s 36133 (53098)	Loss/tok 3.5257 (4.5583)	Learning Rate [0.00125]
4: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00092)	Tok/s 36165 (53005)	Loss/tok 3.3162 (4.5496)	Learning Rate [0.00125]
13: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00099)	Tok/s 36303 (53768)	Loss/tok 3.1488 (4.5542)	Learning Rate [0.00125]
6: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00098)	Tok/s 36168 (53171)	Loss/tok 3.3899 (4.5497)	Learning Rate [0.00125]
7: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00081 (0.00092)	Tok/s 36165 (53255)	Loss/tok 3.2388 (4.5505)	Learning Rate [0.00125]
12: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00112 (0.00100)	Tok/s 36306 (53668)	Loss/tok 3.2882 (4.5479)	Learning Rate [0.00125]
8: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00098)	Tok/s 36185 (53336)	Loss/tok 3.3421 (4.5521)	Learning Rate [0.00125]
10: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00098)	Tok/s 36237 (53481)	Loss/tok 3.1737 (4.5517)	Learning Rate [0.00125]
11: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00099)	Tok/s 36276 (53561)	Loss/tok 3.3371 (4.5484)	Learning Rate [0.00125]
9: TRAIN [0][2360/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00094)	Tok/s 36171 (53395)	Loss/tok 3.2252 (4.5487)	Learning Rate [0.00125]
1: TRAIN [0][2360/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00093)	Tok/s 35710 (52723)	Loss/tok 3.0596 (4.5492)	Learning Rate [0.00125]
15: TRAIN [0][2360/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 35703 (53971)	Loss/tok 3.3405 (4.5494)	Learning Rate [0.00125]
12: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00100)	Tok/s 81714 (53682)	Loss/tok 3.6162 (4.5435)	Learning Rate [0.00125]
2: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 80622 (52842)	Loss/tok 3.4033 (4.5478)	Learning Rate [0.00125]
1: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 80527 (52738)	Loss/tok 3.7635 (4.5450)	Learning Rate [0.00125]
0: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 79809 (52634)	Loss/tok 3.4612 (4.5440)	Learning Rate [0.00125]
13: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00099)	Tok/s 81682 (53782)	Loss/tok 3.6501 (4.5498)	Learning Rate [0.00125]
14: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00095)	Tok/s 81671 (53885)	Loss/tok 3.7189 (4.5498)	Learning Rate [0.00125]
10: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00098)	Tok/s 81580 (53495)	Loss/tok 3.5261 (4.5475)	Learning Rate [0.00125]
11: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00099)	Tok/s 81583 (53575)	Loss/tok 3.6280 (4.5442)	Learning Rate [0.00125]
15: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 82492 (53986)	Loss/tok 3.6109 (4.5449)	Learning Rate [0.00125]
3: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00099)	Tok/s 80629 (52934)	Loss/tok 3.5315 (4.5405)	Learning Rate [0.00125]
4: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00092)	Tok/s 80568 (53020)	Loss/tok 3.5373 (4.5451)	Learning Rate [0.00125]
9: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00094)	Tok/s 81482 (53410)	Loss/tok 3.7056 (4.5444)	Learning Rate [0.00125]
5: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 80617 (53113)	Loss/tok 3.4565 (4.5535)	Learning Rate [0.00125]
8: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00098)	Tok/s 81156 (53351)	Loss/tok 3.3634 (4.5478)	Learning Rate [0.00125]
6: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 80583 (53185)	Loss/tok 3.4494 (4.5454)	Learning Rate [0.00125]
7: TRAIN [0][2370/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00092)	Tok/s 80531 (53269)	Loss/tok 3.5420 (4.5464)	Learning Rate [0.00125]
6: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
6: TRAIN [0][2380/3416]	Time 0.039 (0.058)	Data 0.00102 (0.00098)	Tok/s 26165 (53180)	Loss/tok 2.7281 (4.5414)	Learning Rate [0.00125]
5: TRAIN [0][2380/3416]	Time 0.039 (0.058)	Data 0.00097 (0.00096)	Tok/s 26099 (53109)	Loss/tok 2.6807 (4.5496)	Learning Rate [0.00125]
8: TRAIN [0][2380/3416]	Time 0.039 (0.058)	Data 0.00100 (0.00098)	Tok/s 27712 (53346)	Loss/tok 2.6603 (4.5436)	Learning Rate [0.00125]
7: TRAIN [0][2380/3416]	Time 0.039 (0.058)	Data 0.00090 (0.00092)	Tok/s 26516 (53264)	Loss/tok 2.6468 (4.5424)	Learning Rate [0.00125]
4: TRAIN [0][2380/3416]	Time 0.039 (0.058)	Data 0.00105 (0.00092)	Tok/s 26015 (53015)	Loss/tok 2.6525 (4.5412)	Learning Rate [0.00125]
9: TRAIN [0][2380/3416]	Time 0.039 (0.058)	Data 0.00094 (0.00094)	Tok/s 27617 (53405)	Loss/tok 2.4774 (4.5403)	Learning Rate [0.00125]
2: TRAIN [0][2380/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00098)	Tok/s 24297 (52837)	Loss/tok 2.5739 (4.5440)	Learning Rate [0.00125]
3: TRAIN [0][2380/3416]	Time 0.039 (0.058)	Data 0.00107 (0.00099)	Tok/s 24849 (52929)	Loss/tok 2.6689 (4.5365)	Learning Rate [0.00125]
10: TRAIN [0][2380/3416]	Time 0.039 (0.058)	Data 0.00098 (0.00098)	Tok/s 27570 (53490)	Loss/tok 2.7638 (4.5440)	Learning Rate [0.00125]
1: TRAIN [0][2380/3416]	Time 0.040 (0.058)	Data 0.00097 (0.00093)	Tok/s 24283 (52734)	Loss/tok 2.3661 (4.5415)	Learning Rate [0.00125]
11: TRAIN [0][2380/3416]	Time 0.039 (0.058)	Data 0.00097 (0.00099)	Tok/s 27545 (53570)	Loss/tok 2.6518 (4.5405)	Learning Rate [0.00125]
12: TRAIN [0][2380/3416]	Time 0.039 (0.058)	Data 0.00099 (0.00100)	Tok/s 27546 (53678)	Loss/tok 2.5890 (4.5400)	Learning Rate [0.00125]
0: TRAIN [0][2380/3416]	Time 0.040 (0.058)	Data 0.00099 (0.00092)	Tok/s 24252 (52630)	Loss/tok 2.3294 (4.5403)	Learning Rate [0.00125]
15: TRAIN [0][2380/3416]	Time 0.040 (0.058)	Data 0.00101 (0.00092)	Tok/s 29056 (53982)	Loss/tok 2.7045 (4.5412)	Learning Rate [0.00125]
13: TRAIN [0][2380/3416]	Time 0.040 (0.058)	Data 0.00106 (0.00099)	Tok/s 28126 (53778)	Loss/tok 2.6531 (4.5462)	Learning Rate [0.00125]
14: TRAIN [0][2380/3416]	Time 0.040 (0.058)	Data 0.00099 (0.00095)	Tok/s 29036 (53881)	Loss/tok 2.7642 (4.5460)	Learning Rate [0.00125]
7: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00083 (0.00092)	Tok/s 51207 (53249)	Loss/tok 3.4536 (4.5388)	Learning Rate [0.00125]
8: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00098)	Tok/s 51196 (53331)	Loss/tok 3.6236 (4.5401)	Learning Rate [0.00125]
5: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00096)	Tok/s 50992 (53094)	Loss/tok 3.6232 (4.5458)	Learning Rate [0.00125]
6: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00098)	Tok/s 51096 (53165)	Loss/tok 3.5058 (4.5379)	Learning Rate [0.00125]
10: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00098)	Tok/s 51228 (53475)	Loss/tok 3.6777 (4.5404)	Learning Rate [0.00125]
9: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00080 (0.00094)	Tok/s 51191 (53390)	Loss/tok 3.6279 (4.5366)	Learning Rate [0.00125]
4: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00092)	Tok/s 50879 (53001)	Loss/tok 3.3227 (4.5375)	Learning Rate [0.00125]
11: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00099)	Tok/s 51163 (53555)	Loss/tok 3.6189 (4.5374)	Learning Rate [0.00125]
2: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00098)	Tok/s 50796 (52822)	Loss/tok 3.4271 (4.5409)	Learning Rate [0.00125]
3: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00099)	Tok/s 50821 (52914)	Loss/tok 3.2827 (4.5327)	Learning Rate [0.00125]
12: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00099)	Tok/s 51023 (53661)	Loss/tok 3.4695 (4.5368)	Learning Rate [0.00125]
13: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00099)	Tok/s 50989 (53762)	Loss/tok 3.7328 (4.5426)	Learning Rate [0.00125]
0: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00092)	Tok/s 50847 (52615)	Loss/tok 3.5720 (4.5368)	Learning Rate [0.00125]
1: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00093)	Tok/s 50776 (52719)	Loss/tok 3.5996 (4.5382)	Learning Rate [0.00125]
15: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00084 (0.00092)	Tok/s 51954 (53966)	Loss/tok 3.5790 (4.5373)	Learning Rate [0.00125]
14: TRAIN [0][2390/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00095)	Tok/s 51423 (53865)	Loss/tok 3.8296 (4.5429)	Learning Rate [0.00125]
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
15: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
3: Gradient norm: inf
4: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
6: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
15: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00092)	Tok/s 53959 (53991)	Loss/tok 3.7029 (4.5328)	Learning Rate [0.00125]
0: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00092)	Tok/s 52902 (52641)	Loss/tok 3.4970 (4.5321)	Learning Rate [0.00125]
14: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00095)	Tok/s 53882 (53890)	Loss/tok 3.7653 (4.5382)	Learning Rate [0.00125]
13: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00099)	Tok/s 53863 (53786)	Loss/tok 3.4258 (4.5380)	Learning Rate [0.00125]
1: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00093)	Tok/s 52902 (52745)	Loss/tok 3.6880 (4.5337)	Learning Rate [0.00125]
2: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00098)	Tok/s 53908 (52848)	Loss/tok 3.7463 (4.5365)	Learning Rate [0.00125]
12: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00099)	Tok/s 53899 (53686)	Loss/tok 3.5339 (4.5322)	Learning Rate [0.00125]
11: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00099)	Tok/s 53895 (53579)	Loss/tok 3.4253 (4.5327)	Learning Rate [0.00125]
10: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00098)	Tok/s 53920 (53499)	Loss/tok 3.8135 (4.5357)	Learning Rate [0.00125]
3: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00107 (0.00099)	Tok/s 53903 (52940)	Loss/tok 3.7859 (4.5285)	Learning Rate [0.00125]
4: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00104 (0.00092)	Tok/s 53928 (53027)	Loss/tok 3.5187 (4.5327)	Learning Rate [0.00125]
9: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00094)	Tok/s 53913 (53415)	Loss/tok 3.9120 (4.5322)	Learning Rate [0.00125]
5: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00096)	Tok/s 53914 (53120)	Loss/tok 3.4569 (4.5410)	Learning Rate [0.00125]
8: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00098)	Tok/s 53913 (53356)	Loss/tok 3.7317 (4.5355)	Learning Rate [0.00125]
7: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00092)	Tok/s 53936 (53274)	Loss/tok 3.6566 (4.5346)	Learning Rate [0.00125]
6: TRAIN [0][2400/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00098)	Tok/s 53947 (53191)	Loss/tok 3.4978 (4.5334)	Learning Rate [0.00125]
11: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00099)	Tok/s 59609 (53596)	Loss/tok 3.7943 (4.5286)	Learning Rate [0.00125]
12: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00115 (0.00099)	Tok/s 59580 (53702)	Loss/tok 3.8131 (4.5279)	Learning Rate [0.00125]
10: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00098)	Tok/s 59588 (53516)	Loss/tok 3.7696 (4.5313)	Learning Rate [0.00125]
13: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00099)	Tok/s 59552 (53802)	Loss/tok 3.5641 (4.5335)	Learning Rate [0.00125]
9: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00094)	Tok/s 59577 (53432)	Loss/tok 3.8336 (4.5278)	Learning Rate [0.00125]
8: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00098)	Tok/s 59535 (53373)	Loss/tok 3.8767 (4.5312)	Learning Rate [0.00125]
15: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 59582 (54006)	Loss/tok 3.8968 (4.5285)	Learning Rate [0.00125]
14: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00095)	Tok/s 59547 (53906)	Loss/tok 3.8184 (4.5336)	Learning Rate [0.00125]
6: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00115 (0.00098)	Tok/s 59528 (53207)	Loss/tok 4.0156 (4.5289)	Learning Rate [0.00125]
7: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00092)	Tok/s 59551 (53290)	Loss/tok 3.7239 (4.5302)	Learning Rate [0.00125]
5: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 59568 (53136)	Loss/tok 3.7002 (4.5365)	Learning Rate [0.00125]
0: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 58639 (52657)	Loss/tok 3.7583 (4.5276)	Learning Rate [0.00125]
2: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00098)	Tok/s 59018 (52864)	Loss/tok 3.7511 (4.5323)	Learning Rate [0.00125]
1: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00093)	Tok/s 58637 (52761)	Loss/tok 3.3912 (4.5290)	Learning Rate [0.00125]
3: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00099)	Tok/s 59548 (52956)	Loss/tok 3.8491 (4.5244)	Learning Rate [0.00125]
4: TRAIN [0][2410/3416]	Time 0.070 (0.058)	Data 0.00114 (0.00092)	Tok/s 59543 (53043)	Loss/tok 3.6908 (4.5281)	Learning Rate [0.00125]
8: Gradient norm: inf
10: Gradient norm: inf
9: Gradient norm: inf
7: Gradient norm: inf
11: Gradient norm: inf
9: Skipped batch, new scale: 512.0
10: Skipped batch, new scale: 512.0
8: Skipped batch, new scale: 512.0
13: Gradient norm: inf
0: Gradient norm: inf
15: Gradient norm: inf
14: Gradient norm: inf
12: Gradient norm: inf
6: Gradient norm: inf
2: Gradient norm: inf
7: Skipped batch, new scale: 512.0
11: Skipped batch, new scale: 512.0
13: Skipped batch, new scale: 512.0
0: Skipped batch, new scale: 512.0
15: Skipped batch, new scale: 512.0
14: Skipped batch, new scale: 512.0
12: Skipped batch, new scale: 512.0
4: Gradient norm: inf
6: Skipped batch, new scale: 512.0
2: Skipped batch, new scale: 512.0
1: Gradient norm: inf
5: Gradient norm: inf
3: Gradient norm: inf
4: Skipped batch, new scale: 512.0
1: Skipped batch, new scale: 512.0
5: Skipped batch, new scale: 512.0
3: Skipped batch, new scale: 512.0
0: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 68060 (52685)	Loss/tok 3.8318 (4.5231)	Learning Rate [0.00125]
15: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 69017 (54034)	Loss/tok 3.8331 (4.5245)	Learning Rate [0.00125]
1: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 68007 (52789)	Loss/tok 3.6623 (4.5246)	Learning Rate [0.00125]
14: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00095)	Tok/s 68925 (53932)	Loss/tok 3.6274 (4.5290)	Learning Rate [0.00125]
2: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00098)	Tok/s 67967 (52892)	Loss/tok 3.8878 (4.5278)	Learning Rate [0.00125]
13: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00099)	Tok/s 68941 (53829)	Loss/tok 3.8483 (4.5292)	Learning Rate [0.00125]
3: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00099)	Tok/s 67924 (52983)	Loss/tok 3.6208 (4.5200)	Learning Rate [0.00125]
12: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 68926 (53729)	Loss/tok 3.5573 (4.5234)	Learning Rate [0.00125]
11: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 68996 (53623)	Loss/tok 3.5638 (4.5240)	Learning Rate [0.00125]
4: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00092)	Tok/s 67979 (53070)	Loss/tok 3.6495 (4.5239)	Learning Rate [0.00125]
10: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 68956 (53543)	Loss/tok 3.6923 (4.5271)	Learning Rate [0.00125]
5: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 68057 (53163)	Loss/tok 3.6361 (4.5319)	Learning Rate [0.00125]
6: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00098)	Tok/s 68850 (53234)	Loss/tok 3.6371 (4.5244)	Learning Rate [0.00125]
9: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00094)	Tok/s 68753 (53459)	Loss/tok 3.7652 (4.5234)	Learning Rate [0.00125]
8: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 68647 (53399)	Loss/tok 3.6005 (4.5269)	Learning Rate [0.00125]
7: TRAIN [0][2420/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 68719 (53317)	Loss/tok 3.7988 (4.5256)	Learning Rate [0.00125]
6: TRAIN [0][2430/3416]	Time 0.040 (0.058)	Data 0.00104 (0.00098)	Tok/s 30211 (53223)	Loss/tok 2.8691 (4.5203)	Learning Rate [0.00125]
7: TRAIN [0][2430/3416]	Time 0.040 (0.058)	Data 0.00084 (0.00092)	Tok/s 30251 (53306)	Loss/tok 2.8079 (4.5219)	Learning Rate [0.00125]
5: TRAIN [0][2430/3416]	Time 0.040 (0.058)	Data 0.00095 (0.00096)	Tok/s 29730 (53152)	Loss/tok 2.9039 (4.5285)	Learning Rate [0.00125]
8: TRAIN [0][2430/3416]	Time 0.040 (0.058)	Data 0.00110 (0.00098)	Tok/s 30227 (53388)	Loss/tok 3.0328 (4.5231)	Learning Rate [0.00125]
4: TRAIN [0][2430/3416]	Time 0.040 (0.058)	Data 0.00098 (0.00092)	Tok/s 28511 (53058)	Loss/tok 2.7580 (4.5202)	Learning Rate [0.00125]
3: TRAIN [0][2430/3416]	Time 0.041 (0.058)	Data 0.00108 (0.00099)	Tok/s 28400 (52972)	Loss/tok 2.7368 (4.5163)	Learning Rate [0.00125]
9: TRAIN [0][2430/3416]	Time 0.040 (0.058)	Data 0.00088 (0.00094)	Tok/s 30181 (53448)	Loss/tok 2.8509 (4.5195)	Learning Rate [0.00125]
10: TRAIN [0][2430/3416]	Time 0.040 (0.058)	Data 0.00091 (0.00098)	Tok/s 30119 (53532)	Loss/tok 2.8291 (4.5232)	Learning Rate [0.00125]
2: TRAIN [0][2430/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00098)	Tok/s 28306 (52881)	Loss/tok 2.9089 (4.5241)	Learning Rate [0.00125]
1: TRAIN [0][2430/3416]	Time 0.041 (0.058)	Data 0.00097 (0.00093)	Tok/s 28216 (52778)	Loss/tok 2.6387 (4.5210)	Learning Rate [0.00125]
14: TRAIN [0][2430/3416]	Time 0.041 (0.058)	Data 0.00078 (0.00095)	Tok/s 31182 (53921)	Loss/tok 3.0216 (4.5251)	Learning Rate [0.00125]
11: TRAIN [0][2430/3416]	Time 0.041 (0.058)	Data 0.00100 (0.00099)	Tok/s 29964 (53611)	Loss/tok 2.8463 (4.5200)	Learning Rate [0.00125]
12: TRAIN [0][2430/3416]	Time 0.041 (0.058)	Data 0.00094 (0.00099)	Tok/s 29958 (53717)	Loss/tok 2.7460 (4.5197)	Learning Rate [0.00125]
0: TRAIN [0][2430/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00092)	Tok/s 28222 (52675)	Loss/tok 2.6212 (4.5197)	Learning Rate [0.00125]
15: TRAIN [0][2430/3416]	Time 0.041 (0.058)	Data 0.00082 (0.00092)	Tok/s 31318 (54023)	Loss/tok 3.0123 (4.5205)	Learning Rate [0.00125]
13: TRAIN [0][2430/3416]	Time 0.041 (0.058)	Data 0.00100 (0.00099)	Tok/s 29899 (53817)	Loss/tok 2.7363 (4.5254)	Learning Rate [0.00125]
2: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00098)	Tok/s 49427 (52886)	Loss/tok 3.3553 (4.5203)	Learning Rate [0.00125]
0: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00092)	Tok/s 49257 (52680)	Loss/tok 3.4710 (4.5157)	Learning Rate [0.00125]
3: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00112 (0.00099)	Tok/s 50540 (52977)	Loss/tok 3.3103 (4.5122)	Learning Rate [0.00125]
1: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00093)	Tok/s 49298 (52783)	Loss/tok 3.3203 (4.5171)	Learning Rate [0.00125]
4: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00092)	Tok/s 50755 (53064)	Loss/tok 3.0361 (4.5164)	Learning Rate [0.00125]
5: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00096)	Tok/s 50749 (53157)	Loss/tok 3.3555 (4.5244)	Learning Rate [0.00125]
15: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00075 (0.00092)	Tok/s 50440 (54027)	Loss/tok 3.4307 (4.5165)	Learning Rate [0.00125]
14: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00095)	Tok/s 50391 (53925)	Loss/tok 3.5375 (4.5215)	Learning Rate [0.00125]
8: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00098)	Tok/s 50574 (53392)	Loss/tok 3.3926 (4.5194)	Learning Rate [0.00125]
6: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00098)	Tok/s 50814 (53227)	Loss/tok 3.5968 (4.5169)	Learning Rate [0.00125]
9: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00094)	Tok/s 50524 (53451)	Loss/tok 3.4466 (4.5159)	Learning Rate [0.00125]
13: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00099)	Tok/s 50303 (53821)	Loss/tok 3.3802 (4.5216)	Learning Rate [0.00125]
12: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00099)	Tok/s 50295 (53721)	Loss/tok 3.3464 (4.5160)	Learning Rate [0.00125]
10: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00098)	Tok/s 50292 (53535)	Loss/tok 3.7556 (4.5194)	Learning Rate [0.00125]
11: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00099)	Tok/s 50272 (53615)	Loss/tok 3.5924 (4.5162)	Learning Rate [0.00125]
7: TRAIN [0][2440/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00092)	Tok/s 50596 (53310)	Loss/tok 3.4711 (4.5181)	Learning Rate [0.00125]
13: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 59540 (53825)	Loss/tok 3.7371 (4.5178)	Learning Rate [0.00125]
12: TRAIN [0][2450/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00099)	Tok/s 59034 (53724)	Loss/tok 3.6872 (4.5121)	Learning Rate [0.00125]
11: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00099)	Tok/s 58614 (53618)	Loss/tok 3.4518 (4.5118)	Learning Rate [0.00125]
14: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00095)	Tok/s 59534 (53929)	Loss/tok 3.9133 (4.5176)	Learning Rate [0.00125]
15: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 59538 (54031)	Loss/tok 3.9915 (4.5124)	Learning Rate [0.00125]
0: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 58588 (52679)	Loss/tok 3.7125 (4.5123)	Learning Rate [0.00125]
10: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 58597 (53539)	Loss/tok 3.6654 (4.5157)	Learning Rate [0.00125]
9: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00094)	Tok/s 58611 (53455)	Loss/tok 3.7000 (4.5122)	Learning Rate [0.00125]
8: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 58603 (53395)	Loss/tok 3.6026 (4.5153)	Learning Rate [0.00125]
2: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 58620 (52887)	Loss/tok 3.7206 (4.5168)	Learning Rate [0.00125]
1: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 58600 (52783)	Loss/tok 3.8525 (4.5133)	Learning Rate [0.00125]
7: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 58620 (53313)	Loss/tok 3.7434 (4.5146)	Learning Rate [0.00125]
6: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 58700 (53230)	Loss/tok 3.9634 (4.5130)	Learning Rate [0.00125]
4: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00092)	Tok/s 58582 (53066)	Loss/tok 3.7941 (4.5126)	Learning Rate [0.00125]
5: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00096)	Tok/s 58581 (53159)	Loss/tok 3.7514 (4.5206)	Learning Rate [0.00125]
3: TRAIN [0][2450/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 58531 (52979)	Loss/tok 3.7308 (4.5079)	Learning Rate [0.00125]
14: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00095)	Tok/s 37895 (53919)	Loss/tok 3.2779 (4.5142)	Learning Rate [0.00125]
15: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00092)	Tok/s 37895 (54021)	Loss/tok 3.3016 (4.5090)	Learning Rate [0.00125]
13: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00099)	Tok/s 37817 (53815)	Loss/tok 3.4555 (4.5142)	Learning Rate [0.00125]
12: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00099)	Tok/s 37744 (53715)	Loss/tok 3.4014 (4.5090)	Learning Rate [0.00125]
0: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00092)	Tok/s 36640 (52670)	Loss/tok 3.5592 (4.5086)	Learning Rate [0.00125]
11: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00099)	Tok/s 37647 (53609)	Loss/tok 3.5663 (4.5086)	Learning Rate [0.00125]
10: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00098)	Tok/s 37651 (53530)	Loss/tok 3.4628 (4.5123)	Learning Rate [0.00125]
2: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00098)	Tok/s 36608 (52877)	Loss/tok 3.6660 (4.5130)	Learning Rate [0.00125]
1: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00093)	Tok/s 36633 (52773)	Loss/tok 3.2479 (4.5099)	Learning Rate [0.00125]
9: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00094)	Tok/s 37620 (53446)	Loss/tok 3.2385 (4.5084)	Learning Rate [0.00125]
3: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00099)	Tok/s 36606 (52969)	Loss/tok 3.3708 (4.5046)	Learning Rate [0.00125]
8: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00098)	Tok/s 37660 (53385)	Loss/tok 3.5464 (4.5119)	Learning Rate [0.00125]
5: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00096)	Tok/s 36452 (53148)	Loss/tok 3.4255 (4.5169)	Learning Rate [0.00125]
4: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00092)	Tok/s 36506 (53055)	Loss/tok 3.4242 (4.5093)	Learning Rate [0.00125]
6: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00098)	Tok/s 36433 (53220)	Loss/tok 3.1145 (4.5093)	Learning Rate [0.00125]
7: TRAIN [0][2460/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 37386 (53303)	Loss/tok 3.1850 (4.5110)	Learning Rate [0.00125]
15: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 90049 (54051)	Loss/tok 3.4054 (4.5044)	Learning Rate [0.00125]
0: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 84770 (52698)	Loss/tok 3.3956 (4.5039)	Learning Rate [0.00125]
13: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00099)	Tok/s 88542 (53844)	Loss/tok 3.2661 (4.5094)	Learning Rate [0.00125]
1: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 84727 (52802)	Loss/tok 3.3581 (4.5053)	Learning Rate [0.00125]
12: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00099)	Tok/s 88342 (53744)	Loss/tok 3.2756 (4.5047)	Learning Rate [0.00125]
14: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00095)	Tok/s 89236 (53948)	Loss/tok 3.3519 (4.5099)	Learning Rate [0.00125]
2: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00098)	Tok/s 84705 (52905)	Loss/tok 3.7257 (4.5087)	Learning Rate [0.00125]
11: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00099)	Tok/s 87537 (53638)	Loss/tok 3.5392 (4.5040)	Learning Rate [0.00125]
10: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 87427 (53559)	Loss/tok 3.5069 (4.5079)	Learning Rate [0.00125]
3: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 85565 (52998)	Loss/tok 3.4142 (4.4998)	Learning Rate [0.00125]
4: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 85631 (53084)	Loss/tok 3.3291 (4.5046)	Learning Rate [0.00125]
5: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 85599 (53177)	Loss/tok 3.4133 (4.5121)	Learning Rate [0.00125]
9: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00094)	Tok/s 86973 (53475)	Loss/tok 3.4299 (4.5035)	Learning Rate [0.00125]
8: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 86402 (53414)	Loss/tok 3.3337 (4.5073)	Learning Rate [0.00125]
7: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 86296 (53332)	Loss/tok 3.3627 (4.5064)	Learning Rate [0.00125]
6: TRAIN [0][2470/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00098)	Tok/s 85875 (53249)	Loss/tok 3.3878 (4.5048)	Learning Rate [0.00125]
4: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00116 (0.00092)	Tok/s 52097 (53064)	Loss/tok 3.6812 (4.5014)	Learning Rate [0.00125]
5: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00096)	Tok/s 52112 (53158)	Loss/tok 3.5736 (4.5088)	Learning Rate [0.00125]
0: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00109 (0.00092)	Tok/s 52070 (52676)	Loss/tok 3.4681 (4.5011)	Learning Rate [0.00125]
2: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00098)	Tok/s 52158 (52885)	Loss/tok 3.6601 (4.5055)	Learning Rate [0.00125]
3: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00107 (0.00099)	Tok/s 52119 (52978)	Loss/tok 3.6723 (4.4965)	Learning Rate [0.00125]
8: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00108 (0.00098)	Tok/s 52991 (53396)	Loss/tok 3.5043 (4.5037)	Learning Rate [0.00125]
6: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00119 (0.00098)	Tok/s 52752 (53230)	Loss/tok 3.4488 (4.5014)	Learning Rate [0.00125]
1: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00109 (0.00093)	Tok/s 52048 (52780)	Loss/tok 3.7347 (4.5020)	Learning Rate [0.00125]
14: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00115 (0.00095)	Tok/s 52982 (53930)	Loss/tok 3.5887 (4.5067)	Learning Rate [0.00125]
7: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00092)	Tok/s 52916 (53313)	Loss/tok 3.5656 (4.5033)	Learning Rate [0.00125]
10: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00098)	Tok/s 52855 (53540)	Loss/tok 3.6783 (4.5047)	Learning Rate [0.00125]
13: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00108 (0.00099)	Tok/s 52839 (53826)	Loss/tok 3.8775 (4.5064)	Learning Rate [0.00125]
12: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00111 (0.00099)	Tok/s 52758 (53726)	Loss/tok 3.8789 (4.5019)	Learning Rate [0.00125]
11: TRAIN [0][2480/3416]	Time 0.058 (0.058)	Data 0.00115 (0.00099)	Tok/s 52856 (53619)	Loss/tok 3.7269 (4.5010)	Learning Rate [0.00125]
15: TRAIN [0][2480/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00092)	Tok/s 52118 (54032)	Loss/tok 3.6966 (4.5013)	Learning Rate [0.00125]
9: TRAIN [0][2480/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00094)	Tok/s 51947 (53456)	Loss/tok 3.7141 (4.5002)	Learning Rate [0.00125]
6: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00112 (0.00098)	Tok/s 56703 (53214)	Loss/tok 3.6645 (4.4980)	Learning Rate [0.00125]
5: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00118 (0.00096)	Tok/s 56465 (53142)	Loss/tok 3.8049 (4.5057)	Learning Rate [0.00125]
7: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00092)	Tok/s 56562 (53298)	Loss/tok 3.4447 (4.5000)	Learning Rate [0.00125]
3: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00109 (0.00099)	Tok/s 56509 (52963)	Loss/tok 3.5573 (4.4932)	Learning Rate [0.00125]
4: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00092)	Tok/s 56451 (53049)	Loss/tok 4.0502 (4.4984)	Learning Rate [0.00125]
8: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00106 (0.00098)	Tok/s 56495 (53380)	Loss/tok 3.5782 (4.5001)	Learning Rate [0.00125]
9: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00110 (0.00094)	Tok/s 56508 (53440)	Loss/tok 3.7627 (4.4967)	Learning Rate [0.00125]
2: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00104 (0.00098)	Tok/s 56449 (52871)	Loss/tok 3.7786 (4.5019)	Learning Rate [0.00125]
10: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00107 (0.00098)	Tok/s 56421 (53524)	Loss/tok 3.7083 (4.5015)	Learning Rate [0.00125]
0: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00092)	Tok/s 56316 (52662)	Loss/tok 3.6981 (4.4975)	Learning Rate [0.00125]
11: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00110 (0.00099)	Tok/s 56519 (53603)	Loss/tok 3.6965 (4.4977)	Learning Rate [0.00125]
1: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00093)	Tok/s 56403 (52766)	Loss/tok 3.7421 (4.4987)	Learning Rate [0.00125]
14: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00095)	Tok/s 57138 (53913)	Loss/tok 3.7272 (4.5034)	Learning Rate [0.00125]
12: TRAIN [0][2490/3416]	Time 0.066 (0.058)	Data 0.00129 (0.00099)	Tok/s 57228 (53710)	Loss/tok 3.5531 (4.4984)	Learning Rate [0.00125]
15: TRAIN [0][2490/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00092)	Tok/s 57354 (54016)	Loss/tok 3.8112 (4.4982)	Learning Rate [0.00125]
13: TRAIN [0][2490/3416]	Time 0.066 (0.058)	Data 0.00126 (0.00099)	Tok/s 57183 (53810)	Loss/tok 3.5944 (4.5028)	Learning Rate [0.00125]
7: TRAIN [0][2500/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00092)	Tok/s 50426 (53321)	Loss/tok 3.5184 (4.4960)	Learning Rate [0.00125]
6: TRAIN [0][2500/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00098)	Tok/s 50469 (53237)	Loss/tok 3.6189 (4.4939)	Learning Rate [0.00125]
9: TRAIN [0][2500/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00094)	Tok/s 50265 (53464)	Loss/tok 3.7869 (4.4923)	Learning Rate [0.00125]
8: TRAIN [0][2500/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00098)	Tok/s 50311 (53403)	Loss/tok 3.4799 (4.4955)	Learning Rate [0.00125]
3: TRAIN [0][2500/3416]	Time 0.049 (0.058)	Data 0.00103 (0.00099)	Tok/s 50756 (52987)	Loss/tok 3.4110 (4.4889)	Learning Rate [0.00125]
5: TRAIN [0][2500/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00096)	Tok/s 50294 (53165)	Loss/tok 3.4485 (4.5014)	Learning Rate [0.00125]
10: TRAIN [0][2500/3416]	Time 0.050 (0.058)	Data 0.00109 (0.00098)	Tok/s 50108 (53547)	Loss/tok 3.3446 (4.4975)	Learning Rate [0.00125]
12: TRAIN [0][2500/3416]	Time 0.050 (0.058)	Data 0.00115 (0.00099)	Tok/s 49986 (53732)	Loss/tok 3.7036 (4.4942)	Learning Rate [0.00125]
4: TRAIN [0][2500/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00092)	Tok/s 50314 (53072)	Loss/tok 3.3756 (4.4938)	Learning Rate [0.00125]
11: TRAIN [0][2500/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00099)	Tok/s 49988 (53626)	Loss/tok 3.3360 (4.4937)	Learning Rate [0.00125]
15: TRAIN [0][2500/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00092)	Tok/s 49873 (54039)	Loss/tok 3.7425 (4.4938)	Learning Rate [0.00125]
1: TRAIN [0][2500/3416]	Time 0.050 (0.058)	Data 0.00109 (0.00093)	Tok/s 50007 (52791)	Loss/tok 3.6702 (4.4948)	Learning Rate [0.00125]
0: TRAIN [0][2500/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00092)	Tok/s 49925 (52687)	Loss/tok 3.3197 (4.4931)	Learning Rate [0.00125]
14: TRAIN [0][2500/3416]	Time 0.050 (0.058)	Data 0.00108 (0.00095)	Tok/s 49851 (53936)	Loss/tok 3.4625 (4.4993)	Learning Rate [0.00125]
13: TRAIN [0][2500/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00099)	Tok/s 49824 (53832)	Loss/tok 3.5900 (4.4981)	Learning Rate [0.00125]
2: TRAIN [0][2500/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00098)	Tok/s 49708 (52895)	Loss/tok 3.3423 (4.4976)	Learning Rate [0.00125]
12: TRAIN [0][2510/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00099)	Tok/s 62966 (53748)	Loss/tok 3.4831 (4.4900)	Learning Rate [0.00125]
10: TRAIN [0][2510/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00098)	Tok/s 62978 (53563)	Loss/tok 3.8379 (4.4933)	Learning Rate [0.00125]
13: TRAIN [0][2510/3416]	Time 0.068 (0.058)	Data 0.00113 (0.00099)	Tok/s 63662 (53849)	Loss/tok 3.6915 (4.4943)	Learning Rate [0.00125]
14: TRAIN [0][2510/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00095)	Tok/s 62725 (53952)	Loss/tok 3.6498 (4.4955)	Learning Rate [0.00125]
15: TRAIN [0][2510/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 63043 (54056)	Loss/tok 3.5592 (4.4897)	Learning Rate [0.00125]
9: TRAIN [0][2510/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00094)	Tok/s 62981 (53479)	Loss/tok 3.6417 (4.4882)	Learning Rate [0.00125]
0: TRAIN [0][2510/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 62279 (52698)	Loss/tok 3.6395 (4.4896)	Learning Rate [0.00125]
8: TRAIN [0][2510/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 62986 (53418)	Loss/tok 3.7888 (4.4916)	Learning Rate [0.00125]
1: TRAIN [0][2510/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 62748 (52803)	Loss/tok 3.7714 (4.4908)	Learning Rate [0.00125]
7: TRAIN [0][2510/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 62969 (53336)	Loss/tok 4.0631 (4.4922)	Learning Rate [0.00125]
2: TRAIN [0][2510/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 62789 (52908)	Loss/tok 3.7449 (4.4940)	Learning Rate [0.00125]
5: TRAIN [0][2510/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 62935 (53180)	Loss/tok 3.6772 (4.4976)	Learning Rate [0.00125]
6: TRAIN [0][2510/3416]	Time 0.068 (0.058)	Data 0.00116 (0.00098)	Tok/s 63677 (53252)	Loss/tok 3.4801 (4.4901)	Learning Rate [0.00125]
4: TRAIN [0][2510/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 62824 (53086)	Loss/tok 3.6853 (4.4899)	Learning Rate [0.00125]
11: TRAIN [0][2510/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 62306 (53641)	Loss/tok 3.8390 (4.4897)	Learning Rate [0.00125]
3: TRAIN [0][2510/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00099)	Tok/s 62101 (53000)	Loss/tok 3.6356 (4.4847)	Learning Rate [0.00125]
9: TRAIN [0][2520/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00094)	Tok/s 52042 (53503)	Loss/tok 3.4143 (4.4839)	Learning Rate [0.00125]
8: TRAIN [0][2520/3416]	Time 0.059 (0.058)	Data 0.00116 (0.00098)	Tok/s 51993 (53442)	Loss/tok 3.8678 (4.4875)	Learning Rate [0.00125]
10: TRAIN [0][2520/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00098)	Tok/s 51981 (53587)	Loss/tok 3.5598 (4.4891)	Learning Rate [0.00125]
7: TRAIN [0][2520/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00092)	Tok/s 51913 (53360)	Loss/tok 3.5188 (4.4883)	Learning Rate [0.00125]
11: TRAIN [0][2520/3416]	Time 0.059 (0.058)	Data 0.00106 (0.00099)	Tok/s 51957 (53666)	Loss/tok 3.3495 (4.4857)	Learning Rate [0.00125]
14: TRAIN [0][2520/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00095)	Tok/s 51711 (53976)	Loss/tok 3.4912 (4.4914)	Learning Rate [0.00125]
5: TRAIN [0][2520/3416]	Time 0.059 (0.058)	Data 0.00115 (0.00096)	Tok/s 51720 (53204)	Loss/tok 3.7831 (4.4934)	Learning Rate [0.00125]
6: TRAIN [0][2520/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00098)	Tok/s 51820 (53276)	Loss/tok 3.4783 (4.4860)	Learning Rate [0.00125]
12: TRAIN [0][2520/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00099)	Tok/s 51889 (53772)	Loss/tok 3.8495 (4.4863)	Learning Rate [0.00125]
2: TRAIN [0][2520/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00098)	Tok/s 51767 (52933)	Loss/tok 3.5917 (4.4900)	Learning Rate [0.00125]
4: TRAIN [0][2520/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00093)	Tok/s 51704 (53111)	Loss/tok 3.5148 (4.4858)	Learning Rate [0.00125]
13: TRAIN [0][2520/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00099)	Tok/s 51762 (53873)	Loss/tok 3.8681 (4.4903)	Learning Rate [0.00125]
15: TRAIN [0][2520/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00092)	Tok/s 51609 (54080)	Loss/tok 3.5184 (4.4855)	Learning Rate [0.00125]
3: TRAIN [0][2520/3416]	Time 0.059 (0.058)	Data 0.00129 (0.00099)	Tok/s 51800 (53025)	Loss/tok 3.5386 (4.4805)	Learning Rate [0.00125]
1: TRAIN [0][2520/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00093)	Tok/s 51412 (52828)	Loss/tok 3.8144 (4.4869)	Learning Rate [0.00125]
0: TRAIN [0][2520/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00092)	Tok/s 50466 (52723)	Loss/tok 3.5580 (4.4853)	Learning Rate [0.00125]
0: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 73004 (52716)	Loss/tok 3.6356 (4.4817)	Learning Rate [0.00125]
14: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00125 (0.00095)	Tok/s 73844 (53968)	Loss/tok 3.6735 (4.4877)	Learning Rate [0.00125]
15: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 73798 (54072)	Loss/tok 3.5626 (4.4821)	Learning Rate [0.00125]
1: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00093)	Tok/s 72870 (52821)	Loss/tok 3.7403 (4.4831)	Learning Rate [0.00125]
13: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00099)	Tok/s 73738 (53865)	Loss/tok 3.7798 (4.4868)	Learning Rate [0.00125]
12: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00099)	Tok/s 73763 (53765)	Loss/tok 3.6521 (4.4832)	Learning Rate [0.00125]
2: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00098)	Tok/s 72871 (52926)	Loss/tok 3.6289 (4.4865)	Learning Rate [0.00125]
11: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00099)	Tok/s 73766 (53658)	Loss/tok 3.6101 (4.4823)	Learning Rate [0.00125]
10: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00098)	Tok/s 73779 (53579)	Loss/tok 3.4639 (4.4857)	Learning Rate [0.00125]
4: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 72879 (53103)	Loss/tok 3.6307 (4.4820)	Learning Rate [0.00125]
3: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00114 (0.00099)	Tok/s 72879 (53018)	Loss/tok 3.6574 (4.4771)	Learning Rate [0.00125]
9: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00094)	Tok/s 73858 (53496)	Loss/tok 3.5707 (4.4804)	Learning Rate [0.00125]
6: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 72981 (53267)	Loss/tok 3.8758 (4.4825)	Learning Rate [0.00125]
5: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00096)	Tok/s 72866 (53196)	Loss/tok 3.5344 (4.4897)	Learning Rate [0.00125]
7: TRAIN [0][2530/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00092)	Tok/s 73106 (53351)	Loss/tok 3.4930 (4.4847)	Learning Rate [0.00125]
8: TRAIN [0][2530/3416]	Time 0.071 (0.058)	Data 0.00113 (0.00098)	Tok/s 73515 (53434)	Loss/tok 3.7114 (4.4840)	Learning Rate [0.00125]
4: TRAIN [0][2540/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00093)	Tok/s 53921 (53102)	Loss/tok 3.5983 (4.4782)	Learning Rate [0.00125]
2: TRAIN [0][2540/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00098)	Tok/s 53794 (52925)	Loss/tok 3.2898 (4.4827)	Learning Rate [0.00125]
3: TRAIN [0][2540/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00099)	Tok/s 53897 (53017)	Loss/tok 3.5870 (4.4732)	Learning Rate [0.00125]
1: TRAIN [0][2540/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00093)	Tok/s 53703 (52821)	Loss/tok 3.5983 (4.4796)	Learning Rate [0.00125]
0: TRAIN [0][2540/3416]	Time 0.066 (0.058)	Data 0.00087 (0.00092)	Tok/s 53725 (52716)	Loss/tok 3.4809 (4.4780)	Learning Rate [0.00125]
5: TRAIN [0][2540/3416]	Time 0.065 (0.058)	Data 0.00111 (0.00096)	Tok/s 54294 (53194)	Loss/tok 3.8903 (4.4860)	Learning Rate [0.00125]
15: TRAIN [0][2540/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00092)	Tok/s 53694 (54070)	Loss/tok 3.6707 (4.4788)	Learning Rate [0.00125]
7: TRAIN [0][2540/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00092)	Tok/s 53889 (53349)	Loss/tok 3.7551 (4.4810)	Learning Rate [0.00125]
6: TRAIN [0][2540/3416]	Time 0.065 (0.058)	Data 0.00099 (0.00098)	Tok/s 53834 (53265)	Loss/tok 3.5323 (4.4791)	Learning Rate [0.00125]
14: TRAIN [0][2540/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00095)	Tok/s 53695 (53966)	Loss/tok 4.0004 (4.4841)	Learning Rate [0.00125]
8: TRAIN [0][2540/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00098)	Tok/s 53845 (53432)	Loss/tok 3.6829 (4.4805)	Learning Rate [0.00125]
13: TRAIN [0][2540/3416]	Time 0.066 (0.058)	Data 0.00112 (0.00099)	Tok/s 53661 (53863)	Loss/tok 3.5739 (4.4833)	Learning Rate [0.00125]
9: TRAIN [0][2540/3416]	Time 0.065 (0.058)	Data 0.00097 (0.00094)	Tok/s 53922 (53494)	Loss/tok 3.8731 (4.4766)	Learning Rate [0.00125]
12: TRAIN [0][2540/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00100)	Tok/s 53660 (53762)	Loss/tok 3.6406 (4.4793)	Learning Rate [0.00125]
10: TRAIN [0][2540/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00098)	Tok/s 53712 (53577)	Loss/tok 3.5810 (4.4820)	Learning Rate [0.00125]
11: TRAIN [0][2540/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00099)	Tok/s 53630 (53656)	Loss/tok 3.5779 (4.4788)	Learning Rate [0.00125]
0: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
9: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
7: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
15: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 65606 (54094)	Loss/tok 3.6659 (4.4750)	Learning Rate [0.00125]
2: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 64465 (52950)	Loss/tok 3.5863 (4.4785)	Learning Rate [0.00125]
1: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 64491 (52846)	Loss/tok 3.4121 (4.4755)	Learning Rate [0.00125]
0: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 64556 (52741)	Loss/tok 3.5921 (4.4738)	Learning Rate [0.00125]
14: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00095)	Tok/s 65540 (53990)	Loss/tok 3.5925 (4.4799)	Learning Rate [0.00125]
4: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 64482 (53126)	Loss/tok 3.6935 (4.4742)	Learning Rate [0.00125]
5: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00096)	Tok/s 64515 (53219)	Loss/tok 3.5451 (4.4819)	Learning Rate [0.00125]
12: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00100)	Tok/s 65225 (53787)	Loss/tok 3.6082 (4.4752)	Learning Rate [0.00125]
13: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00099)	Tok/s 65488 (53887)	Loss/tok 3.6299 (4.4791)	Learning Rate [0.00125]
6: TRAIN [0][2550/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00098)	Tok/s 64438 (53290)	Loss/tok 3.6845 (4.4747)	Learning Rate [0.00125]
11: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00099)	Tok/s 64581 (53681)	Loss/tok 3.3553 (4.4749)	Learning Rate [0.00125]
7: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00092)	Tok/s 64525 (53374)	Loss/tok 3.6544 (4.4770)	Learning Rate [0.00125]
10: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 64524 (53602)	Loss/tok 3.8990 (4.4781)	Learning Rate [0.00125]
8: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00098)	Tok/s 64508 (53457)	Loss/tok 3.8015 (4.4764)	Learning Rate [0.00125]
3: TRAIN [0][2550/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00099)	Tok/s 64381 (53041)	Loss/tok 3.6254 (4.4690)	Learning Rate [0.00125]
9: TRAIN [0][2550/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00094)	Tok/s 64687 (53518)	Loss/tok 3.5781 (4.4723)	Learning Rate [0.00125]
0: TRAIN [0][2560/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 71805 (52764)	Loss/tok 3.6445 (4.4698)	Learning Rate [0.00125]
14: TRAIN [0][2560/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00095)	Tok/s 73692 (54012)	Loss/tok 3.6787 (4.4761)	Learning Rate [0.00125]
15: TRAIN [0][2560/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 73611 (54116)	Loss/tok 3.6329 (4.4713)	Learning Rate [0.00125]
1: TRAIN [0][2560/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00093)	Tok/s 71700 (52868)	Loss/tok 3.7419 (4.4716)	Learning Rate [0.00125]
2: TRAIN [0][2560/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00098)	Tok/s 71609 (52972)	Loss/tok 3.8597 (4.4745)	Learning Rate [0.00125]
3: TRAIN [0][2560/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00099)	Tok/s 72124 (53064)	Loss/tok 3.8308 (4.4653)	Learning Rate [0.00125]
13: TRAIN [0][2560/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00099)	Tok/s 72737 (53909)	Loss/tok 3.6202 (4.4752)	Learning Rate [0.00125]
11: TRAIN [0][2560/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00099)	Tok/s 72843 (53703)	Loss/tok 3.4357 (4.4709)	Learning Rate [0.00125]
12: TRAIN [0][2560/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 72797 (53809)	Loss/tok 3.9041 (4.4714)	Learning Rate [0.00125]
4: TRAIN [0][2560/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 72529 (53149)	Loss/tok 3.5729 (4.4703)	Learning Rate [0.00125]
10: TRAIN [0][2560/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00098)	Tok/s 72777 (53625)	Loss/tok 3.5298 (4.4742)	Learning Rate [0.00125]
6: TRAIN [0][2560/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 72553 (53313)	Loss/tok 3.4461 (4.4708)	Learning Rate [0.00125]
9: TRAIN [0][2560/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00094)	Tok/s 72819 (53541)	Loss/tok 3.4610 (4.4682)	Learning Rate [0.00125]
8: TRAIN [0][2560/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 72582 (53479)	Loss/tok 3.7752 (4.4725)	Learning Rate [0.00125]
5: TRAIN [0][2560/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 72447 (53242)	Loss/tok 3.8207 (4.4784)	Learning Rate [0.00125]
7: TRAIN [0][2560/3416]	Time 0.070 (0.058)	Data 0.00078 (0.00092)	Tok/s 72552 (53397)	Loss/tok 3.8677 (4.4729)	Learning Rate [0.00125]
2: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00098)	Tok/s 49027 (52970)	Loss/tok 3.1677 (4.4711)	Learning Rate [0.00125]
3: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00099)	Tok/s 49074 (53061)	Loss/tok 3.4851 (4.4617)	Learning Rate [0.00125]
1: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00093)	Tok/s 48897 (52866)	Loss/tok 3.5624 (4.4680)	Learning Rate [0.00125]
0: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00092)	Tok/s 48548 (52762)	Loss/tok 3.4518 (4.4666)	Learning Rate [0.00125]
4: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00093)	Tok/s 49008 (53147)	Loss/tok 3.4722 (4.4673)	Learning Rate [0.00125]
5: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00096)	Tok/s 49045 (53240)	Loss/tok 3.4404 (4.4752)	Learning Rate [0.00125]
15: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00082 (0.00092)	Tok/s 48711 (54113)	Loss/tok 3.2177 (4.4677)	Learning Rate [0.00125]
10: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00098)	Tok/s 49016 (53622)	Loss/tok 3.1942 (4.4708)	Learning Rate [0.00125]
14: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00095)	Tok/s 48719 (54009)	Loss/tok 3.3706 (4.4729)	Learning Rate [0.00125]
9: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00094)	Tok/s 49140 (53538)	Loss/tok 3.3914 (4.4644)	Learning Rate [0.00125]
7: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00092)	Tok/s 49035 (53395)	Loss/tok 3.4411 (4.4694)	Learning Rate [0.00125]
11: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00099)	Tok/s 48852 (53700)	Loss/tok 3.2726 (4.4677)	Learning Rate [0.00125]
8: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00098)	Tok/s 49043 (53477)	Loss/tok 3.4550 (4.4692)	Learning Rate [0.00125]
13: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00099)	Tok/s 48796 (53906)	Loss/tok 3.1285 (4.4717)	Learning Rate [0.00125]
6: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00098)	Tok/s 49049 (53311)	Loss/tok 3.2598 (4.4673)	Learning Rate [0.00125]
12: TRAIN [0][2570/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00099)	Tok/s 48822 (53806)	Loss/tok 3.3502 (4.4677)	Learning Rate [0.00125]
2: TRAIN [0][2580/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00098)	Tok/s 54283 (52970)	Loss/tok 3.6579 (4.4676)	Learning Rate [0.00125]
3: TRAIN [0][2580/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00099)	Tok/s 54354 (53061)	Loss/tok 3.6824 (4.4583)	Learning Rate [0.00125]
4: TRAIN [0][2580/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00093)	Tok/s 54360 (53147)	Loss/tok 3.5230 (4.4639)	Learning Rate [0.00125]
5: TRAIN [0][2580/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00096)	Tok/s 54330 (53240)	Loss/tok 3.6387 (4.4712)	Learning Rate [0.00125]
1: TRAIN [0][2580/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00093)	Tok/s 54127 (52866)	Loss/tok 3.3905 (4.4644)	Learning Rate [0.00125]
0: TRAIN [0][2580/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00092)	Tok/s 54069 (52762)	Loss/tok 3.7538 (4.4633)	Learning Rate [0.00125]
6: TRAIN [0][2580/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00098)	Tok/s 54319 (53311)	Loss/tok 3.5982 (4.4638)	Learning Rate [0.00125]
14: TRAIN [0][2580/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00095)	Tok/s 54061 (54009)	Loss/tok 3.7598 (4.4692)	Learning Rate [0.00125]
8: TRAIN [0][2580/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00098)	Tok/s 54254 (53477)	Loss/tok 3.7170 (4.4654)	Learning Rate [0.00125]
13: TRAIN [0][2580/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00099)	Tok/s 54065 (53906)	Loss/tok 3.5164 (4.4681)	Learning Rate [0.00125]
10: TRAIN [0][2580/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00098)	Tok/s 54120 (53622)	Loss/tok 3.7424 (4.4672)	Learning Rate [0.00125]
9: TRAIN [0][2580/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00094)	Tok/s 54161 (53538)	Loss/tok 3.8138 (4.4609)	Learning Rate [0.00125]
15: TRAIN [0][2580/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00092)	Tok/s 53844 (54112)	Loss/tok 3.6731 (4.4640)	Learning Rate [0.00125]
7: TRAIN [0][2580/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00092)	Tok/s 54017 (53395)	Loss/tok 3.6999 (4.4659)	Learning Rate [0.00125]
12: TRAIN [0][2580/3416]	Time 0.068 (0.058)	Data 0.00108 (0.00100)	Tok/s 53963 (53805)	Loss/tok 3.8415 (4.4645)	Learning Rate [0.00125]
11: TRAIN [0][2580/3416]	Time 0.068 (0.058)	Data 0.00106 (0.00099)	Tok/s 53958 (53699)	Loss/tok 3.9546 (4.4644)	Learning Rate [0.00125]
1: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00093)	Tok/s 50133 (52854)	Loss/tok 3.3701 (4.4612)	Learning Rate [0.00125]
3: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00099)	Tok/s 50925 (53049)	Loss/tok 3.5945 (4.4549)	Learning Rate [0.00125]
2: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00098)	Tok/s 50805 (52958)	Loss/tok 3.2262 (4.4643)	Learning Rate [0.00125]
0: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00092)	Tok/s 49663 (52750)	Loss/tok 3.4434 (4.4600)	Learning Rate [0.00125]
14: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00095)	Tok/s 50871 (53995)	Loss/tok 3.6215 (4.4663)	Learning Rate [0.00125]
15: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00092)	Tok/s 50801 (54098)	Loss/tok 3.7570 (4.4609)	Learning Rate [0.00125]
4: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00093)	Tok/s 50838 (53134)	Loss/tok 3.4482 (4.4604)	Learning Rate [0.00125]
13: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00099)	Tok/s 50773 (53893)	Loss/tok 3.6897 (4.4649)	Learning Rate [0.00125]
5: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00096)	Tok/s 50835 (53227)	Loss/tok 3.6405 (4.4676)	Learning Rate [0.00125]
12: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00100)	Tok/s 50749 (53793)	Loss/tok 3.7842 (4.4617)	Learning Rate [0.00125]
11: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00099)	Tok/s 50759 (53687)	Loss/tok 3.1884 (4.4611)	Learning Rate [0.00125]
7: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00082 (0.00092)	Tok/s 50858 (53382)	Loss/tok 3.3153 (4.4626)	Learning Rate [0.00125]
6: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00098)	Tok/s 50847 (53298)	Loss/tok 3.5803 (4.4605)	Learning Rate [0.00125]
8: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00098)	Tok/s 50818 (53464)	Loss/tok 3.6772 (4.4620)	Learning Rate [0.00125]
10: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00098)	Tok/s 50827 (53608)	Loss/tok 3.3830 (4.4640)	Learning Rate [0.00125]
9: TRAIN [0][2590/3416]	Time 0.055 (0.058)	Data 0.00087 (0.00094)	Tok/s 50753 (53525)	Loss/tok 3.6059 (4.4576)	Learning Rate [0.00125]
4: TRAIN [0][2600/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00093)	Tok/s 34917 (53126)	Loss/tok 3.3186 (4.4570)	Learning Rate [0.00125]
3: TRAIN [0][2600/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00099)	Tok/s 34910 (53040)	Loss/tok 3.0643 (4.4514)	Learning Rate [0.00125]
5: TRAIN [0][2600/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00096)	Tok/s 34821 (53219)	Loss/tok 3.0472 (4.4639)	Learning Rate [0.00125]
2: TRAIN [0][2600/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00098)	Tok/s 34905 (52949)	Loss/tok 3.3036 (4.4606)	Learning Rate [0.00125]
7: TRAIN [0][2600/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00092)	Tok/s 34649 (53374)	Loss/tok 3.2303 (4.4593)	Learning Rate [0.00125]
6: TRAIN [0][2600/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00098)	Tok/s 34728 (53291)	Loss/tok 3.3097 (4.4568)	Learning Rate [0.00125]
1: TRAIN [0][2600/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00093)	Tok/s 34947 (52843)	Loss/tok 3.2451 (4.4576)	Learning Rate [0.00125]
0: TRAIN [0][2600/3416]	Time 0.051 (0.058)	Data 0.00109 (0.00092)	Tok/s 35145 (52739)	Loss/tok 3.3533 (4.4566)	Learning Rate [0.00125]
8: TRAIN [0][2600/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00098)	Tok/s 34514 (53457)	Loss/tok 3.2630 (4.4585)	Learning Rate [0.00125]
14: TRAIN [0][2600/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00095)	Tok/s 34680 (53989)	Loss/tok 2.9979 (4.4624)	Learning Rate [0.00125]
15: TRAIN [0][2600/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00092)	Tok/s 35831 (54093)	Loss/tok 3.1008 (4.4574)	Learning Rate [0.00125]
10: TRAIN [0][2600/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00098)	Tok/s 34425 (53601)	Loss/tok 3.1608 (4.4604)	Learning Rate [0.00125]
9: TRAIN [0][2600/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00094)	Tok/s 34476 (53518)	Loss/tok 2.9361 (4.4540)	Learning Rate [0.00125]
13: TRAIN [0][2600/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00099)	Tok/s 34561 (53887)	Loss/tok 3.1808 (4.4616)	Learning Rate [0.00125]
12: TRAIN [0][2600/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00099)	Tok/s 34481 (53786)	Loss/tok 3.3151 (4.4587)	Learning Rate [0.00125]
11: TRAIN [0][2600/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00099)	Tok/s 34425 (53680)	Loss/tok 3.2055 (4.4575)	Learning Rate [0.00125]
2: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00079 (0.00098)	Tok/s 57458 (52936)	Loss/tok 3.8425 (4.4576)	Learning Rate [0.00125]
3: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00080 (0.00099)	Tok/s 57481 (53028)	Loss/tok 3.6211 (4.4485)	Learning Rate [0.00125]
4: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00093)	Tok/s 57301 (53114)	Loss/tok 3.7833 (4.4542)	Learning Rate [0.00125]
1: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00093)	Tok/s 57440 (52831)	Loss/tok 3.6959 (4.4546)	Learning Rate [0.00125]
5: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00096)	Tok/s 57233 (53207)	Loss/tok 3.6547 (4.4607)	Learning Rate [0.00125]
15: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00092)	Tok/s 58343 (54082)	Loss/tok 3.5731 (4.4543)	Learning Rate [0.00125]
6: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00098)	Tok/s 57556 (53280)	Loss/tok 3.7386 (4.4536)	Learning Rate [0.00125]
14: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00095)	Tok/s 58253 (53979)	Loss/tok 3.7226 (4.4592)	Learning Rate [0.00125]
8: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00098)	Tok/s 57942 (53447)	Loss/tok 3.4992 (4.4552)	Learning Rate [0.00125]
13: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00099)	Tok/s 58148 (53876)	Loss/tok 3.6185 (4.4583)	Learning Rate [0.00125]
12: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00099)	Tok/s 58147 (53775)	Loss/tok 3.4780 (4.4552)	Learning Rate [0.00125]
7: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00092)	Tok/s 57897 (53364)	Loss/tok 3.5863 (4.4558)	Learning Rate [0.00125]
10: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00098)	Tok/s 57972 (53591)	Loss/tok 3.7646 (4.4572)	Learning Rate [0.00125]
11: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00099)	Tok/s 58044 (53669)	Loss/tok 3.6288 (4.4543)	Learning Rate [0.00125]
9: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00094)	Tok/s 57920 (53508)	Loss/tok 3.5732 (4.4507)	Learning Rate [0.00125]
0: TRAIN [0][2610/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00092)	Tok/s 57607 (52727)	Loss/tok 3.7591 (4.4536)	Learning Rate [0.00125]
2: TRAIN [0][2620/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 61785 (52943)	Loss/tok 3.5842 (4.4543)	Learning Rate [0.00125]
1: TRAIN [0][2620/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 61816 (52837)	Loss/tok 3.7192 (4.4510)	Learning Rate [0.00125]
3: TRAIN [0][2620/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00099)	Tok/s 61686 (53034)	Loss/tok 3.6562 (4.4449)	Learning Rate [0.00125]
4: TRAIN [0][2620/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 61612 (53120)	Loss/tok 3.7612 (4.4507)	Learning Rate [0.00125]
0: TRAIN [0][2620/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 61437 (52733)	Loss/tok 3.7270 (4.4503)	Learning Rate [0.00125]
15: TRAIN [0][2620/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 61840 (54086)	Loss/tok 3.7031 (4.4509)	Learning Rate [0.00125]
14: TRAIN [0][2620/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00095)	Tok/s 61856 (53983)	Loss/tok 3.7112 (4.4557)	Learning Rate [0.00125]
5: TRAIN [0][2620/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 61560 (53213)	Loss/tok 3.7500 (4.4575)	Learning Rate [0.00125]
6: TRAIN [0][2620/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00098)	Tok/s 61555 (53285)	Loss/tok 3.8834 (4.4501)	Learning Rate [0.00125]
13: TRAIN [0][2620/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00099)	Tok/s 61750 (53880)	Loss/tok 3.7472 (4.4547)	Learning Rate [0.00125]
7: TRAIN [0][2620/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 61610 (53369)	Loss/tok 3.6508 (4.4524)	Learning Rate [0.00125]
12: TRAIN [0][2620/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00099)	Tok/s 61762 (53780)	Loss/tok 3.7162 (4.4517)	Learning Rate [0.00125]
8: TRAIN [0][2620/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 61557 (53452)	Loss/tok 3.4235 (4.4516)	Learning Rate [0.00125]
11: TRAIN [0][2620/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 61712 (53673)	Loss/tok 3.8418 (4.4509)	Learning Rate [0.00125]
10: TRAIN [0][2620/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00098)	Tok/s 61710 (53595)	Loss/tok 3.8008 (4.4537)	Learning Rate [0.00125]
9: TRAIN [0][2620/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00094)	Tok/s 61604 (53512)	Loss/tok 3.6079 (4.4472)	Learning Rate [0.00125]
8: TRAIN [0][2630/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00098)	Tok/s 55016 (53434)	Loss/tok 3.9843 (4.4487)	Learning Rate [0.00125]
10: TRAIN [0][2630/3416]	Time 0.065 (0.058)	Data 0.00104 (0.00098)	Tok/s 54908 (53578)	Loss/tok 3.8886 (4.4507)	Learning Rate [0.00125]
7: TRAIN [0][2630/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00092)	Tok/s 55012 (53352)	Loss/tok 3.5364 (4.4494)	Learning Rate [0.00125]
9: TRAIN [0][2630/3416]	Time 0.065 (0.058)	Data 0.00102 (0.00094)	Tok/s 54918 (53494)	Loss/tok 3.8924 (4.4445)	Learning Rate [0.00125]
6: TRAIN [0][2630/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00098)	Tok/s 55035 (53268)	Loss/tok 3.6143 (4.4475)	Learning Rate [0.00125]
5: TRAIN [0][2630/3416]	Time 0.065 (0.058)	Data 0.00105 (0.00096)	Tok/s 55007 (53195)	Loss/tok 3.3982 (4.4545)	Learning Rate [0.00125]
11: TRAIN [0][2630/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00099)	Tok/s 54724 (53655)	Loss/tok 3.7233 (4.4479)	Learning Rate [0.00125]
4: TRAIN [0][2630/3416]	Time 0.065 (0.058)	Data 0.00107 (0.00093)	Tok/s 54942 (53103)	Loss/tok 3.6583 (4.4477)	Learning Rate [0.00125]
12: TRAIN [0][2630/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00099)	Tok/s 54712 (53762)	Loss/tok 3.5379 (4.4485)	Learning Rate [0.00125]
2: TRAIN [0][2630/3416]	Time 0.065 (0.058)	Data 0.00107 (0.00097)	Tok/s 53860 (52925)	Loss/tok 3.6079 (4.4515)	Learning Rate [0.00125]
3: TRAIN [0][2630/3416]	Time 0.065 (0.058)	Data 0.00107 (0.00099)	Tok/s 53889 (53016)	Loss/tok 3.7064 (4.4421)	Learning Rate [0.00125]
13: TRAIN [0][2630/3416]	Time 0.066 (0.058)	Data 0.00104 (0.00099)	Tok/s 54656 (53862)	Loss/tok 3.6501 (4.4515)	Learning Rate [0.00125]
14: TRAIN [0][2630/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00095)	Tok/s 54656 (53965)	Loss/tok 3.7769 (4.4529)	Learning Rate [0.00125]
1: TRAIN [0][2630/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00093)	Tok/s 53714 (52820)	Loss/tok 3.5851 (4.4481)	Learning Rate [0.00125]
0: TRAIN [0][2630/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00092)	Tok/s 53646 (52716)	Loss/tok 3.5447 (4.4475)	Learning Rate [0.00125]
15: TRAIN [0][2630/3416]	Time 0.066 (0.058)	Data 0.00105 (0.00092)	Tok/s 54518 (54068)	Loss/tok 3.6773 (4.4481)	Learning Rate [0.00125]
2: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00097)	Tok/s 32246 (52928)	Loss/tok 3.1321 (4.4482)	Learning Rate [0.00125]
5: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00096)	Tok/s 32141 (53198)	Loss/tok 3.2250 (4.4514)	Learning Rate [0.00125]
4: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00093)	Tok/s 32136 (53106)	Loss/tok 3.3376 (4.4445)	Learning Rate [0.00125]
1: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00082 (0.00093)	Tok/s 32138 (52824)	Loss/tok 3.1393 (4.4449)	Learning Rate [0.00125]
3: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00122 (0.00099)	Tok/s 32228 (53020)	Loss/tok 3.1485 (4.4392)	Learning Rate [0.00125]
0: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 32056 (52720)	Loss/tok 3.0433 (4.4444)	Learning Rate [0.00125]
14: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00082 (0.00095)	Tok/s 33196 (53967)	Loss/tok 3.3937 (4.4497)	Learning Rate [0.00125]
6: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00098)	Tok/s 32067 (53271)	Loss/tok 3.2827 (4.4445)	Learning Rate [0.00125]
15: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 33211 (54070)	Loss/tok 3.1168 (4.4447)	Learning Rate [0.00125]
7: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 31947 (53354)	Loss/tok 3.3181 (4.4461)	Learning Rate [0.00125]
13: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00099)	Tok/s 33179 (53864)	Loss/tok 2.9771 (4.4481)	Learning Rate [0.00125]
8: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00098)	Tok/s 31938 (53437)	Loss/tok 2.9312 (4.4456)	Learning Rate [0.00125]
12: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00099)	Tok/s 33011 (53764)	Loss/tok 3.1846 (4.4454)	Learning Rate [0.00125]
10: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00098)	Tok/s 31874 (53580)	Loss/tok 3.2437 (4.4473)	Learning Rate [0.00125]
9: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00094)	Tok/s 31825 (53497)	Loss/tok 3.2779 (4.4415)	Learning Rate [0.00125]
11: TRAIN [0][2640/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00099)	Tok/s 33047 (53658)	Loss/tok 3.1822 (4.4444)	Learning Rate [0.00125]
1: TRAIN [0][2650/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00093)	Tok/s 48275 (52817)	Loss/tok 3.5193 (4.4420)	Learning Rate [0.00125]
0: TRAIN [0][2650/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00092)	Tok/s 48162 (52714)	Loss/tok 3.4356 (4.4413)	Learning Rate [0.00125]
2: TRAIN [0][2650/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00097)	Tok/s 48231 (52921)	Loss/tok 3.3472 (4.4451)	Learning Rate [0.00125]
15: TRAIN [0][2650/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00092)	Tok/s 49431 (54061)	Loss/tok 3.2774 (4.4416)	Learning Rate [0.00125]
3: TRAIN [0][2650/3416]	Time 0.046 (0.058)	Data 0.00111 (0.00099)	Tok/s 48181 (53012)	Loss/tok 3.6088 (4.4363)	Learning Rate [0.00125]
14: TRAIN [0][2650/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00095)	Tok/s 49300 (53958)	Loss/tok 3.6775 (4.4466)	Learning Rate [0.00125]
13: TRAIN [0][2650/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00099)	Tok/s 49190 (53856)	Loss/tok 3.6963 (4.4448)	Learning Rate [0.00125]
5: TRAIN [0][2650/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00096)	Tok/s 47989 (53190)	Loss/tok 3.4136 (4.4486)	Learning Rate [0.00125]
4: TRAIN [0][2650/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00093)	Tok/s 48069 (53098)	Loss/tok 3.3632 (4.4414)	Learning Rate [0.00125]
12: TRAIN [0][2650/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00099)	Tok/s 49017 (53756)	Loss/tok 3.6039 (4.4424)	Learning Rate [0.00125]
11: TRAIN [0][2650/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00099)	Tok/s 48929 (53650)	Loss/tok 3.3959 (4.4413)	Learning Rate [0.00125]
6: TRAIN [0][2650/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00098)	Tok/s 47867 (53263)	Loss/tok 3.3101 (4.4414)	Learning Rate [0.00125]
7: TRAIN [0][2650/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00092)	Tok/s 48179 (53346)	Loss/tok 3.3087 (4.4429)	Learning Rate [0.00125]
10: TRAIN [0][2650/3416]	Time 0.047 (0.058)	Data 0.00110 (0.00098)	Tok/s 48922 (53572)	Loss/tok 3.6889 (4.4443)	Learning Rate [0.00125]
8: TRAIN [0][2650/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00098)	Tok/s 49029 (53429)	Loss/tok 3.4972 (4.4425)	Learning Rate [0.00125]
9: TRAIN [0][2650/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00094)	Tok/s 48934 (53489)	Loss/tok 3.2838 (4.4384)	Learning Rate [0.00125]
10: Gradient norm: inf
11: Gradient norm: inf
9: Gradient norm: inf
10: Skipped batch, new scale: 512.0
11: Skipped batch, new scale: 512.0
12: Gradient norm: inf
9: Skipped batch, new scale: 512.0
8: Gradient norm: inf
12: Skipped batch, new scale: 512.0
8: Skipped batch, new scale: 512.0
7: Gradient norm: inf
14: Gradient norm: inf
6: Gradient norm: inf
15: Gradient norm: inf
7: Skipped batch, new scale: 512.0
14: Skipped batch, new scale: 512.0
0: Gradient norm: inf
6: Skipped batch, new scale: 512.0
15: Skipped batch, new scale: 512.0
5: Gradient norm: inf
0: Skipped batch, new scale: 512.0
1: Gradient norm: inf
4: Gradient norm: inf
5: Skipped batch, new scale: 512.0
2: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 512.0
4: Skipped batch, new scale: 512.0
2: Skipped batch, new scale: 512.0
3: Skipped batch, new scale: 512.0
13: Gradient norm: inf
13: Skipped batch, new scale: 512.0
15: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00079 (0.00092)	Tok/s 63825 (54071)	Loss/tok 4.0199 (4.4382)	Learning Rate [0.00125]
0: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 62906 (52725)	Loss/tok 3.5953 (4.4377)	Learning Rate [0.00125]
14: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00095)	Tok/s 63732 (53969)	Loss/tok 3.3198 (4.4429)	Learning Rate [0.00125]
1: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 62940 (52828)	Loss/tok 3.7566 (4.4385)	Learning Rate [0.00125]
2: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 63413 (52932)	Loss/tok 3.7603 (4.4415)	Learning Rate [0.00125]
13: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00099)	Tok/s 63841 (53866)	Loss/tok 3.6725 (4.4413)	Learning Rate [0.00125]
3: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00099)	Tok/s 63925 (53023)	Loss/tok 3.7284 (4.4330)	Learning Rate [0.00125]
12: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00099)	Tok/s 63880 (53766)	Loss/tok 4.0908 (4.4393)	Learning Rate [0.00125]
11: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00098)	Tok/s 63867 (53660)	Loss/tok 3.5708 (4.4374)	Learning Rate [0.00125]
4: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00093)	Tok/s 63892 (53108)	Loss/tok 3.5687 (4.4381)	Learning Rate [0.00125]
5: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 63906 (53200)	Loss/tok 3.3559 (4.4446)	Learning Rate [0.00125]
10: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 63828 (53582)	Loss/tok 3.8013 (4.4409)	Learning Rate [0.00125]
8: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00098)	Tok/s 63826 (53439)	Loss/tok 3.7186 (4.4390)	Learning Rate [0.00125]
6: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 63824 (53273)	Loss/tok 3.9329 (4.4382)	Learning Rate [0.00125]
7: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 63817 (53357)	Loss/tok 3.7163 (4.4396)	Learning Rate [0.00125]
9: TRAIN [0][2660/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00094)	Tok/s 63778 (53499)	Loss/tok 3.7899 (4.4349)	Learning Rate [0.00125]
9: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00094)	Tok/s 48947 (53516)	Loss/tok 3.3944 (4.4314)	Learning Rate [0.00125]
10: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00112 (0.00098)	Tok/s 49015 (53599)	Loss/tok 3.5626 (4.4374)	Learning Rate [0.00125]
8: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00098)	Tok/s 48844 (53456)	Loss/tok 3.3317 (4.4355)	Learning Rate [0.00125]
11: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00098)	Tok/s 48995 (53677)	Loss/tok 3.2877 (4.4334)	Learning Rate [0.00125]
7: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00092)	Tok/s 48720 (53374)	Loss/tok 3.1943 (4.4359)	Learning Rate [0.00125]
12: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00099)	Tok/s 48874 (53783)	Loss/tok 3.4763 (4.4356)	Learning Rate [0.00125]
6: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00098)	Tok/s 48598 (53291)	Loss/tok 3.4262 (4.4345)	Learning Rate [0.00125]
5: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00096)	Tok/s 48506 (53218)	Loss/tok 3.4278 (4.4409)	Learning Rate [0.00125]
13: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00099)	Tok/s 48781 (53883)	Loss/tok 3.2723 (4.4375)	Learning Rate [0.00125]
3: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00107 (0.00099)	Tok/s 48418 (53041)	Loss/tok 3.3589 (4.4295)	Learning Rate [0.00125]
4: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00093)	Tok/s 48325 (53126)	Loss/tok 3.5440 (4.4346)	Learning Rate [0.00125]
14: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00095)	Tok/s 48605 (53985)	Loss/tok 3.5332 (4.4394)	Learning Rate [0.00125]
2: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00097)	Tok/s 48320 (52951)	Loss/tok 3.4777 (4.4382)	Learning Rate [0.00125]
15: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00092)	Tok/s 48540 (54088)	Loss/tok 3.3409 (4.4348)	Learning Rate [0.00125]
0: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00092)	Tok/s 47179 (52743)	Loss/tok 3.4546 (4.4347)	Learning Rate [0.00125]
1: TRAIN [0][2670/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00093)	Tok/s 48366 (52847)	Loss/tok 3.2767 (4.4348)	Learning Rate [0.00125]
3: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00099)	Tok/s 29939 (53025)	Loss/tok 2.9960 (4.4264)	Learning Rate [0.00125]
2: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00097)	Tok/s 29870 (52935)	Loss/tok 3.0196 (4.4351)	Learning Rate [0.00125]
4: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00080 (0.00093)	Tok/s 29936 (53110)	Loss/tok 3.0981 (4.4319)	Learning Rate [0.00125]
5: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00096)	Tok/s 29958 (53202)	Loss/tok 2.9641 (4.4382)	Learning Rate [0.00125]
1: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00087 (0.00093)	Tok/s 29768 (52831)	Loss/tok 3.0267 (4.4320)	Learning Rate [0.00125]
0: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00086 (0.00092)	Tok/s 29690 (52727)	Loss/tok 2.9990 (4.4318)	Learning Rate [0.00125]
15: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00081 (0.00092)	Tok/s 31145 (54070)	Loss/tok 2.8813 (4.4318)	Learning Rate [0.00125]
6: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00098)	Tok/s 30202 (53274)	Loss/tok 3.1458 (4.4315)	Learning Rate [0.00125]
14: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00079 (0.00095)	Tok/s 31191 (53968)	Loss/tok 2.8635 (4.4363)	Learning Rate [0.00125]
8: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00098)	Tok/s 31410 (53439)	Loss/tok 2.7270 (4.4326)	Learning Rate [0.00125]
7: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00092)	Tok/s 31410 (53357)	Loss/tok 2.7542 (4.4328)	Learning Rate [0.00125]
13: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00099)	Tok/s 31186 (53866)	Loss/tok 3.1424 (4.4346)	Learning Rate [0.00125]
12: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00087 (0.00099)	Tok/s 31226 (53766)	Loss/tok 2.5408 (4.4324)	Learning Rate [0.00125]
9: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00098 (0.00094)	Tok/s 31317 (53499)	Loss/tok 3.0665 (4.4283)	Learning Rate [0.00125]
10: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00098)	Tok/s 31245 (53582)	Loss/tok 2.8515 (4.4343)	Learning Rate [0.00125]
11: TRAIN [0][2680/3416]	Time 0.043 (0.058)	Data 0.00081 (0.00098)	Tok/s 31223 (53659)	Loss/tok 2.6976 (4.4302)	Learning Rate [0.00125]
1: TRAIN [0][2690/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00093)	Tok/s 51549 (52827)	Loss/tok 3.7546 (4.4291)	Learning Rate [0.00125]
2: TRAIN [0][2690/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00097)	Tok/s 51456 (52931)	Loss/tok 3.5099 (4.4320)	Learning Rate [0.00125]
0: TRAIN [0][2690/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00092)	Tok/s 51439 (52724)	Loss/tok 3.5901 (4.4287)	Learning Rate [0.00125]
15: TRAIN [0][2690/3416]	Time 0.056 (0.058)	Data 0.00083 (0.00092)	Tok/s 52496 (54066)	Loss/tok 3.5446 (4.4289)	Learning Rate [0.00125]
3: TRAIN [0][2690/3416]	Time 0.056 (0.058)	Data 0.00105 (0.00099)	Tok/s 51412 (53021)	Loss/tok 3.6745 (4.4233)	Learning Rate [0.00125]
14: TRAIN [0][2690/3416]	Time 0.056 (0.058)	Data 0.00078 (0.00095)	Tok/s 52415 (53963)	Loss/tok 3.6665 (4.4334)	Learning Rate [0.00125]
4: TRAIN [0][2690/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00093)	Tok/s 51292 (53106)	Loss/tok 3.4107 (4.4288)	Learning Rate [0.00125]
13: TRAIN [0][2690/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00099)	Tok/s 52277 (53861)	Loss/tok 3.7845 (4.4316)	Learning Rate [0.00125]
12: TRAIN [0][2690/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00099)	Tok/s 52193 (53762)	Loss/tok 3.6612 (4.4293)	Learning Rate [0.00125]
11: TRAIN [0][2690/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00098)	Tok/s 52096 (53655)	Loss/tok 3.3908 (4.4269)	Learning Rate [0.00125]
6: TRAIN [0][2690/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00098)	Tok/s 51091 (53270)	Loss/tok 3.6702 (4.4285)	Learning Rate [0.00125]
10: TRAIN [0][2690/3416]	Time 0.057 (0.058)	Data 0.00100 (0.00098)	Tok/s 51767 (53578)	Loss/tok 3.6563 (4.4315)	Learning Rate [0.00125]
5: TRAIN [0][2690/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00096)	Tok/s 51210 (53198)	Loss/tok 3.4337 (4.4351)	Learning Rate [0.00125]
8: TRAIN [0][2690/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00098)	Tok/s 50923 (53435)	Loss/tok 3.6207 (4.4296)	Learning Rate [0.00125]
7: TRAIN [0][2690/3416]	Time 0.056 (0.058)	Data 0.00079 (0.00092)	Tok/s 50997 (53353)	Loss/tok 3.7036 (4.4299)	Learning Rate [0.00125]
9: TRAIN [0][2690/3416]	Time 0.057 (0.058)	Data 0.00086 (0.00094)	Tok/s 50828 (53495)	Loss/tok 3.8451 (4.4253)	Learning Rate [0.00125]
5: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00096)	Tok/s 50501 (53196)	Loss/tok 3.3623 (4.4320)	Learning Rate [0.00125]
4: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00093)	Tok/s 49262 (53103)	Loss/tok 3.5336 (4.4260)	Learning Rate [0.00125]
6: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00098)	Tok/s 50691 (53267)	Loss/tok 3.3715 (4.4252)	Learning Rate [0.00125]
2: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00097)	Tok/s 49153 (52928)	Loss/tok 3.4390 (4.4290)	Learning Rate [0.00125]
7: TRAIN [0][2700/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00092)	Tok/s 50716 (53351)	Loss/tok 3.7566 (4.4267)	Learning Rate [0.00125]
3: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00099)	Tok/s 49168 (53019)	Loss/tok 3.4802 (4.4204)	Learning Rate [0.00125]
1: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00093)	Tok/s 49177 (52825)	Loss/tok 3.3672 (4.4260)	Learning Rate [0.00125]
10: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00098)	Tok/s 50681 (53574)	Loss/tok 3.3718 (4.4281)	Learning Rate [0.00125]
0: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 49174 (52721)	Loss/tok 3.5419 (4.4256)	Learning Rate [0.00125]
9: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00094)	Tok/s 50647 (53492)	Loss/tok 3.4256 (4.4224)	Learning Rate [0.00125]
8: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00098)	Tok/s 50680 (53432)	Loss/tok 3.5781 (4.4268)	Learning Rate [0.00125]
15: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 50448 (54061)	Loss/tok 3.4254 (4.4261)	Learning Rate [0.00125]
14: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00095)	Tok/s 50417 (53959)	Loss/tok 3.6169 (4.4306)	Learning Rate [0.00125]
11: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00098)	Tok/s 50614 (53652)	Loss/tok 3.7134 (4.4237)	Learning Rate [0.00125]
13: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00099)	Tok/s 50397 (53857)	Loss/tok 3.6112 (4.4287)	Learning Rate [0.00125]
12: TRAIN [0][2700/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00099)	Tok/s 50502 (53758)	Loss/tok 3.6445 (4.4262)	Learning Rate [0.00125]
12: TRAIN [0][2710/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00099)	Tok/s 51234 (53760)	Loss/tok 3.3314 (4.4231)	Learning Rate [0.00125]
11: TRAIN [0][2710/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00098)	Tok/s 51236 (53654)	Loss/tok 3.3127 (4.4203)	Learning Rate [0.00125]
13: TRAIN [0][2710/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00099)	Tok/s 51139 (53860)	Loss/tok 3.6332 (4.4255)	Learning Rate [0.00125]
14: TRAIN [0][2710/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00095)	Tok/s 52077 (53962)	Loss/tok 3.3356 (4.4276)	Learning Rate [0.00125]
10: TRAIN [0][2710/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00098)	Tok/s 51212 (53577)	Loss/tok 3.3114 (4.4248)	Learning Rate [0.00125]
15: TRAIN [0][2710/3416]	Time 0.048 (0.058)	Data 0.00108 (0.00092)	Tok/s 52277 (54065)	Loss/tok 3.4277 (4.4228)	Learning Rate [0.00125]
0: TRAIN [0][2710/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 50865 (52725)	Loss/tok 3.3455 (4.4225)	Learning Rate [0.00125]
9: TRAIN [0][2710/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00094)	Tok/s 51259 (53495)	Loss/tok 3.5409 (4.4192)	Learning Rate [0.00125]
1: TRAIN [0][2710/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00093)	Tok/s 50910 (52829)	Loss/tok 3.4592 (4.4229)	Learning Rate [0.00125]
8: TRAIN [0][2710/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00098)	Tok/s 51219 (53435)	Loss/tok 3.6021 (4.4237)	Learning Rate [0.00125]
2: TRAIN [0][2710/3416]	Time 0.048 (0.058)	Data 0.00106 (0.00097)	Tok/s 50920 (52932)	Loss/tok 3.3018 (4.4257)	Learning Rate [0.00125]
7: TRAIN [0][2710/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00092)	Tok/s 51161 (53353)	Loss/tok 3.5439 (4.4237)	Learning Rate [0.00125]
3: TRAIN [0][2710/3416]	Time 0.048 (0.058)	Data 0.00118 (0.00099)	Tok/s 50936 (53022)	Loss/tok 3.2292 (4.4170)	Learning Rate [0.00125]
5: TRAIN [0][2710/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00096)	Tok/s 50931 (53198)	Loss/tok 3.6391 (4.4287)	Learning Rate [0.00125]
4: TRAIN [0][2710/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00093)	Tok/s 50911 (53106)	Loss/tok 3.1795 (4.4227)	Learning Rate [0.00125]
6: TRAIN [0][2710/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00098)	Tok/s 51036 (53270)	Loss/tok 3.5528 (4.4218)	Learning Rate [0.00125]
12: TRAIN [0][2720/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00099)	Tok/s 56303 (53748)	Loss/tok 3.7334 (4.4203)	Learning Rate [0.00125]
11: TRAIN [0][2720/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00098)	Tok/s 56289 (53642)	Loss/tok 3.6352 (4.4174)	Learning Rate [0.00125]
13: TRAIN [0][2720/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00099)	Tok/s 56182 (53848)	Loss/tok 3.2758 (4.4225)	Learning Rate [0.00125]
10: TRAIN [0][2720/3416]	Time 0.061 (0.058)	Data 0.00104 (0.00098)	Tok/s 56255 (53565)	Loss/tok 3.6790 (4.4220)	Learning Rate [0.00125]
9: TRAIN [0][2720/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00094)	Tok/s 56304 (53483)	Loss/tok 3.7923 (4.4166)	Learning Rate [0.00125]
14: TRAIN [0][2720/3416]	Time 0.062 (0.058)	Data 0.00104 (0.00095)	Tok/s 55988 (53950)	Loss/tok 3.8637 (4.4246)	Learning Rate [0.00125]
8: TRAIN [0][2720/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00098)	Tok/s 56242 (53423)	Loss/tok 3.7887 (4.4207)	Learning Rate [0.00125]
15: TRAIN [0][2720/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00092)	Tok/s 56057 (54053)	Loss/tok 3.5278 (4.4200)	Learning Rate [0.00125]
2: TRAIN [0][2720/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00097)	Tok/s 55909 (52921)	Loss/tok 3.8507 (4.4228)	Learning Rate [0.00125]
7: TRAIN [0][2720/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00092)	Tok/s 56229 (53342)	Loss/tok 3.4092 (4.4206)	Learning Rate [0.00125]
6: TRAIN [0][2720/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00098)	Tok/s 56119 (53259)	Loss/tok 3.5452 (4.4190)	Learning Rate [0.00125]
5: TRAIN [0][2720/3416]	Time 0.062 (0.058)	Data 0.00104 (0.00096)	Tok/s 56030 (53187)	Loss/tok 3.8376 (4.4257)	Learning Rate [0.00125]
1: TRAIN [0][2720/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00093)	Tok/s 55842 (52818)	Loss/tok 3.6415 (4.4200)	Learning Rate [0.00125]
3: TRAIN [0][2720/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00099)	Tok/s 55890 (53011)	Loss/tok 3.8681 (4.4142)	Learning Rate [0.00125]
0: TRAIN [0][2720/3416]	Time 0.062 (0.058)	Data 0.00112 (0.00092)	Tok/s 55857 (52715)	Loss/tok 3.6781 (4.4197)	Learning Rate [0.00125]
4: TRAIN [0][2720/3416]	Time 0.062 (0.058)	Data 0.00120 (0.00093)	Tok/s 55944 (53095)	Loss/tok 3.6484 (4.4199)	Learning Rate [0.00125]
3: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00099)	Tok/s 54167 (53021)	Loss/tok 3.4242 (4.4109)	Learning Rate [0.00125]
2: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00097)	Tok/s 53200 (52931)	Loss/tok 3.7074 (4.4199)	Learning Rate [0.00125]
4: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00093)	Tok/s 54236 (53105)	Loss/tok 3.5509 (4.4166)	Learning Rate [0.00125]
5: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00096)	Tok/s 54237 (53196)	Loss/tok 3.2697 (4.4223)	Learning Rate [0.00125]
1: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00103 (0.00093)	Tok/s 53203 (52828)	Loss/tok 3.6361 (4.4165)	Learning Rate [0.00125]
0: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00084 (0.00092)	Tok/s 53209 (52725)	Loss/tok 3.5636 (4.4167)	Learning Rate [0.00125]
15: TRAIN [0][2730/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00092)	Tok/s 54329 (54063)	Loss/tok 3.5566 (4.4169)	Learning Rate [0.00125]
6: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00098)	Tok/s 54255 (53267)	Loss/tok 3.5485 (4.4159)	Learning Rate [0.00125]
7: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00092)	Tok/s 54252 (53350)	Loss/tok 3.6047 (4.4174)	Learning Rate [0.00125]
14: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00095)	Tok/s 54267 (53960)	Loss/tok 3.4401 (4.4216)	Learning Rate [0.00125]
8: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00098)	Tok/s 54269 (53432)	Loss/tok 3.5851 (4.4174)	Learning Rate [0.00125]
10: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00108 (0.00098)	Tok/s 54172 (53573)	Loss/tok 3.6525 (4.4187)	Learning Rate [0.00125]
12: TRAIN [0][2730/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00099)	Tok/s 54308 (53757)	Loss/tok 3.4608 (4.4170)	Learning Rate [0.00125]
13: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00099)	Tok/s 54243 (53857)	Loss/tok 3.3465 (4.4194)	Learning Rate [0.00125]
11: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00098)	Tok/s 54250 (53650)	Loss/tok 3.6270 (4.4141)	Learning Rate [0.00125]
9: TRAIN [0][2730/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00094)	Tok/s 54242 (53491)	Loss/tok 3.6971 (4.4134)	Learning Rate [0.00125]
2: TRAIN [0][2740/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 63554 (52927)	Loss/tok 3.9222 (4.4173)	Learning Rate [0.00125]
8: TRAIN [0][2740/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 63909 (53429)	Loss/tok 3.8055 (4.4144)	Learning Rate [0.00125]
6: TRAIN [0][2740/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 63874 (53264)	Loss/tok 3.6368 (4.4126)	Learning Rate [0.00125]
7: TRAIN [0][2740/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 63900 (53347)	Loss/tok 3.6227 (4.4141)	Learning Rate [0.00125]
10: TRAIN [0][2740/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00098)	Tok/s 63818 (53569)	Loss/tok 3.6196 (4.4157)	Learning Rate [0.00125]
3: TRAIN [0][2740/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00099)	Tok/s 63619 (53018)	Loss/tok 3.6091 (4.4073)	Learning Rate [0.00125]
4: TRAIN [0][2740/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 63647 (53102)	Loss/tok 3.6563 (4.4136)	Learning Rate [0.00125]
1: TRAIN [0][2740/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 63495 (52825)	Loss/tok 3.8436 (4.4135)	Learning Rate [0.00125]
9: TRAIN [0][2740/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00094)	Tok/s 63851 (53488)	Loss/tok 3.5475 (4.4103)	Learning Rate [0.00125]
5: TRAIN [0][2740/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 63727 (53193)	Loss/tok 3.7580 (4.4193)	Learning Rate [0.00125]
0: TRAIN [0][2740/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 63480 (52722)	Loss/tok 3.6883 (4.4137)	Learning Rate [0.00125]
15: TRAIN [0][2740/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00092)	Tok/s 64200 (54058)	Loss/tok 3.7774 (4.4140)	Learning Rate [0.00125]
14: TRAIN [0][2740/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00095)	Tok/s 63463 (53955)	Loss/tok 3.8307 (4.4186)	Learning Rate [0.00125]
11: TRAIN [0][2740/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00098)	Tok/s 63616 (53646)	Loss/tok 3.5491 (4.4107)	Learning Rate [0.00125]
12: TRAIN [0][2740/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00099)	Tok/s 63567 (53752)	Loss/tok 3.7037 (4.4137)	Learning Rate [0.00125]
13: TRAIN [0][2740/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00099)	Tok/s 63497 (53853)	Loss/tok 3.7855 (4.4164)	Learning Rate [0.00125]
4: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 64949 (53110)	Loss/tok 3.7162 (4.4104)	Learning Rate [0.00125]
5: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 64952 (53201)	Loss/tok 3.6523 (4.4161)	Learning Rate [0.00125]
0: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 65021 (52731)	Loss/tok 3.4437 (4.4103)	Learning Rate [0.00125]
2: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 64937 (52936)	Loss/tok 3.7626 (4.4141)	Learning Rate [0.00125]
1: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00093)	Tok/s 64938 (52833)	Loss/tok 3.6164 (4.4100)	Learning Rate [0.00125]
3: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00099)	Tok/s 64946 (53027)	Loss/tok 3.7558 (4.4040)	Learning Rate [0.00125]
6: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 64897 (53272)	Loss/tok 3.6603 (4.4094)	Learning Rate [0.00125]
8: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 64938 (53437)	Loss/tok 3.6302 (4.4111)	Learning Rate [0.00125]
7: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 64925 (53355)	Loss/tok 3.5518 (4.4109)	Learning Rate [0.00125]
15: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 65927 (54066)	Loss/tok 3.5980 (4.4107)	Learning Rate [0.00125]
10: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 65872 (53578)	Loss/tok 3.6801 (4.4124)	Learning Rate [0.00125]
14: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00095)	Tok/s 65825 (53963)	Loss/tok 4.0301 (4.4156)	Learning Rate [0.00125]
13: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00099)	Tok/s 65838 (53861)	Loss/tok 3.5918 (4.4132)	Learning Rate [0.00125]
12: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00099)	Tok/s 65839 (53761)	Loss/tok 3.6338 (4.4107)	Learning Rate [0.00125]
9: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00094)	Tok/s 65061 (53496)	Loss/tok 3.5665 (4.4070)	Learning Rate [0.00125]
11: TRAIN [0][2750/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 65813 (53655)	Loss/tok 3.8683 (4.4076)	Learning Rate [0.00125]
10: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00098)	Tok/s 53901 (53599)	Loss/tok 3.4033 (4.4090)	Learning Rate [0.00125]
11: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00098)	Tok/s 53853 (53675)	Loss/tok 3.7451 (4.4041)	Learning Rate [0.00125]
9: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00081 (0.00094)	Tok/s 53781 (53517)	Loss/tok 3.5555 (4.4032)	Learning Rate [0.00125]
12: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00104 (0.00099)	Tok/s 53852 (53782)	Loss/tok 3.7603 (4.4071)	Learning Rate [0.00125]
8: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00098)	Tok/s 53626 (53457)	Loss/tok 3.1840 (4.4075)	Learning Rate [0.00125]
13: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00105 (0.00099)	Tok/s 53833 (53882)	Loss/tok 3.4598 (4.4096)	Learning Rate [0.00125]
7: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00082 (0.00092)	Tok/s 53556 (53375)	Loss/tok 3.8168 (4.4074)	Learning Rate [0.00125]
5: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00096)	Tok/s 53545 (53221)	Loss/tok 3.6434 (4.4126)	Learning Rate [0.00125]
14: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00095)	Tok/s 53838 (53984)	Loss/tok 3.6558 (4.4119)	Learning Rate [0.00125]
6: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00098)	Tok/s 53565 (53292)	Loss/tok 3.4294 (4.4057)	Learning Rate [0.00125]
3: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00099)	Tok/s 53608 (53048)	Loss/tok 3.5038 (4.4005)	Learning Rate [0.00125]
15: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00092)	Tok/s 53857 (54086)	Loss/tok 3.7051 (4.4073)	Learning Rate [0.00125]
4: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00093)	Tok/s 53559 (53131)	Loss/tok 3.3175 (4.4065)	Learning Rate [0.00125]
0: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00092)	Tok/s 53684 (52752)	Loss/tok 3.7051 (4.4068)	Learning Rate [0.00125]
2: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00097)	Tok/s 53561 (52956)	Loss/tok 3.6341 (4.4104)	Learning Rate [0.00125]
1: TRAIN [0][2760/3416]	Time 0.062 (0.058)	Data 0.00100 (0.00093)	Tok/s 53632 (52854)	Loss/tok 3.5878 (4.4066)	Learning Rate [0.00125]
14: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00095)	Tok/s 77983 (54018)	Loss/tok 3.5415 (4.4080)	Learning Rate [0.00125]
13: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00099)	Tok/s 77896 (53917)	Loss/tok 3.3912 (4.4057)	Learning Rate [0.00125]
10: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00098)	Tok/s 77038 (53632)	Loss/tok 3.5340 (4.4050)	Learning Rate [0.00125]
12: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00099)	Tok/s 77910 (53816)	Loss/tok 3.5862 (4.4034)	Learning Rate [0.00125]
11: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00098)	Tok/s 77463 (53709)	Loss/tok 3.5228 (4.4002)	Learning Rate [0.00125]
9: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00094)	Tok/s 77164 (53550)	Loss/tok 3.7841 (4.3994)	Learning Rate [0.00125]
8: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 77134 (53491)	Loss/tok 3.2979 (4.4034)	Learning Rate [0.00125]
0: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 76137 (52786)	Loss/tok 3.5779 (4.4024)	Learning Rate [0.00125]
15: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 77991 (54121)	Loss/tok 3.6943 (4.4033)	Learning Rate [0.00125]
2: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 76782 (52991)	Loss/tok 3.3856 (4.4065)	Learning Rate [0.00125]
5: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 77165 (53256)	Loss/tok 3.6125 (4.4087)	Learning Rate [0.00125]
1: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00093)	Tok/s 76160 (52888)	Loss/tok 3.4774 (4.4028)	Learning Rate [0.00125]
7: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 77149 (53409)	Loss/tok 3.5898 (4.4034)	Learning Rate [0.00125]
3: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 77114 (53082)	Loss/tok 3.4440 (4.3966)	Learning Rate [0.00125]
4: TRAIN [0][2770/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00093)	Tok/s 77112 (53165)	Loss/tok 3.6469 (4.4025)	Learning Rate [0.00125]
6: TRAIN [0][2770/3416]	Time 0.069 (0.058)	Data 0.00116 (0.00098)	Tok/s 77810 (53326)	Loss/tok 3.3666 (4.4016)	Learning Rate [0.00125]
3: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
3: TRAIN [0][2780/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00099)	Tok/s 48897 (53093)	Loss/tok 3.2372 (4.3937)	Learning Rate [0.00125]
0: Upscaling, new scale: 1024.0
2: TRAIN [0][2780/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00097)	Tok/s 48779 (53001)	Loss/tok 3.4351 (4.4033)	Learning Rate [0.00125]
4: TRAIN [0][2780/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00093)	Tok/s 48878 (53176)	Loss/tok 3.6841 (4.3994)	Learning Rate [0.00125]
15: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
5: TRAIN [0][2780/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00096)	Tok/s 48856 (53266)	Loss/tok 3.5780 (4.4057)	Learning Rate [0.00125]
14: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
1: TRAIN [0][2780/3416]	Time 0.051 (0.058)	Data 0.00118 (0.00093)	Tok/s 48656 (52899)	Loss/tok 3.4294 (4.3995)	Learning Rate [0.00125]
0: TRAIN [0][2780/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00092)	Tok/s 48562 (52797)	Loss/tok 3.4665 (4.3994)	Learning Rate [0.00125]
13: Upscaling, new scale: 1024.0
15: TRAIN [0][2780/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 49704 (54130)	Loss/tok 3.4626 (4.4002)	Learning Rate [0.00125]
12: Upscaling, new scale: 1024.0
9: Upscaling, new scale: 1024.0
6: TRAIN [0][2780/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00098)	Tok/s 49767 (53337)	Loss/tok 3.7464 (4.3986)	Learning Rate [0.00125]
10: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
14: TRAIN [0][2780/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00095)	Tok/s 49635 (54028)	Loss/tok 3.3382 (4.4047)	Learning Rate [0.00125]
8: TRAIN [0][2780/3416]	Time 0.051 (0.058)	Data 0.00111 (0.00098)	Tok/s 49949 (53502)	Loss/tok 3.5436 (4.4002)	Learning Rate [0.00125]
13: TRAIN [0][2780/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00099)	Tok/s 49639 (53927)	Loss/tok 3.3737 (4.4023)	Learning Rate [0.00125]
7: Upscaling, new scale: 1024.0
9: TRAIN [0][2780/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00094)	Tok/s 49811 (53562)	Loss/tok 3.3960 (4.3965)	Learning Rate [0.00125]
12: TRAIN [0][2780/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00099)	Tok/s 49621 (53826)	Loss/tok 3.4883 (4.4002)	Learning Rate [0.00125]
11: TRAIN [0][2780/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00098)	Tok/s 49650 (53720)	Loss/tok 3.4482 (4.3971)	Learning Rate [0.00125]
10: TRAIN [0][2780/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00098)	Tok/s 49611 (53643)	Loss/tok 3.3723 (4.4020)	Learning Rate [0.00125]
7: TRAIN [0][2780/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00092)	Tok/s 49688 (53420)	Loss/tok 3.2196 (4.4002)	Learning Rate [0.00125]
4: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00093)	Tok/s 36737 (53166)	Loss/tok 3.2754 (4.3964)	Learning Rate [0.00125]
5: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00096)	Tok/s 36749 (53256)	Loss/tok 3.3949 (4.4026)	Learning Rate [0.00125]
3: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00099)	Tok/s 36674 (53083)	Loss/tok 3.2279 (4.3906)	Learning Rate [0.00125]
2: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00097)	Tok/s 36587 (52991)	Loss/tok 3.1085 (4.4001)	Learning Rate [0.00125]
6: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00098)	Tok/s 36682 (53327)	Loss/tok 3.3064 (4.3957)	Learning Rate [0.00125]
7: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00092)	Tok/s 36635 (53410)	Loss/tok 3.1174 (4.3976)	Learning Rate [0.00125]
1: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00093)	Tok/s 36490 (52889)	Loss/tok 3.1895 (4.3965)	Learning Rate [0.00125]
8: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00098)	Tok/s 36545 (53492)	Loss/tok 3.4179 (4.3972)	Learning Rate [0.00125]
0: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00092)	Tok/s 36410 (52786)	Loss/tok 3.2276 (4.3962)	Learning Rate [0.00125]
15: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00092)	Tok/s 36297 (54120)	Loss/tok 3.1187 (4.3972)	Learning Rate [0.00125]
14: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00095)	Tok/s 36258 (54017)	Loss/tok 2.9647 (4.4016)	Learning Rate [0.00125]
10: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00098)	Tok/s 36402 (53633)	Loss/tok 3.4757 (4.3991)	Learning Rate [0.00125]
9: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00094)	Tok/s 36465 (53551)	Loss/tok 3.0130 (4.3934)	Learning Rate [0.00125]
11: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00098)	Tok/s 36354 (53709)	Loss/tok 3.2312 (4.3941)	Learning Rate [0.00125]
12: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00099)	Tok/s 36254 (53816)	Loss/tok 2.9990 (4.3973)	Learning Rate [0.00125]
13: TRAIN [0][2790/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00099)	Tok/s 36250 (53916)	Loss/tok 3.4687 (4.3996)	Learning Rate [0.00125]
14: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00095)	Tok/s 53716 (54044)	Loss/tok 3.5918 (4.3981)	Learning Rate [0.00125]
13: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00102 (0.00099)	Tok/s 53078 (53943)	Loss/tok 3.4816 (4.3960)	Learning Rate [0.00125]
15: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00114 (0.00092)	Tok/s 53968 (54147)	Loss/tok 3.5746 (4.3937)	Learning Rate [0.00125]
10: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00102 (0.00098)	Tok/s 52980 (53660)	Loss/tok 3.4034 (4.3953)	Learning Rate [0.00125]
12: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00115 (0.00099)	Tok/s 52977 (53843)	Loss/tok 3.5685 (4.3937)	Learning Rate [0.00125]
11: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00098)	Tok/s 52977 (53736)	Loss/tok 3.4398 (4.3907)	Learning Rate [0.00125]
8: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00109 (0.00098)	Tok/s 52933 (53519)	Loss/tok 3.5096 (4.3935)	Learning Rate [0.00125]
6: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00098)	Tok/s 52945 (53354)	Loss/tok 3.4472 (4.3922)	Learning Rate [0.00125]
7: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00092)	Tok/s 52883 (53437)	Loss/tok 3.7479 (4.3939)	Learning Rate [0.00125]
4: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00103 (0.00093)	Tok/s 52803 (53193)	Loss/tok 3.3912 (4.3928)	Learning Rate [0.00125]
9: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00094)	Tok/s 52908 (53579)	Loss/tok 3.7043 (4.3899)	Learning Rate [0.00125]
0: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00106 (0.00092)	Tok/s 52842 (52814)	Loss/tok 3.9081 (4.3928)	Learning Rate [0.00125]
1: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00107 (0.00093)	Tok/s 52792 (52916)	Loss/tok 3.5254 (4.3930)	Learning Rate [0.00125]
3: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00099)	Tok/s 52812 (53110)	Loss/tok 3.6702 (4.3870)	Learning Rate [0.00125]
5: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00124 (0.00096)	Tok/s 52778 (53283)	Loss/tok 3.7479 (4.3989)	Learning Rate [0.00125]
2: TRAIN [0][2800/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00097)	Tok/s 52715 (53018)	Loss/tok 3.4704 (4.3965)	Learning Rate [0.00125]
2: TRAIN [0][2810/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00097)	Tok/s 52972 (53016)	Loss/tok 3.3716 (4.3935)	Learning Rate [0.00125]
1: TRAIN [0][2810/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00093)	Tok/s 52896 (52914)	Loss/tok 3.5787 (4.3900)	Learning Rate [0.00125]
3: TRAIN [0][2810/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00099)	Tok/s 52919 (53108)	Loss/tok 3.5672 (4.3838)	Learning Rate [0.00125]
4: TRAIN [0][2810/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00093)	Tok/s 52846 (53192)	Loss/tok 3.5806 (4.3896)	Learning Rate [0.00125]
15: TRAIN [0][2810/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00092)	Tok/s 52642 (54144)	Loss/tok 3.5634 (4.3909)	Learning Rate [0.00125]
5: TRAIN [0][2810/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00096)	Tok/s 52727 (53282)	Loss/tok 3.4194 (4.3957)	Learning Rate [0.00125]
14: TRAIN [0][2810/3416]	Time 0.057 (0.058)	Data 0.00083 (0.00095)	Tok/s 52570 (54041)	Loss/tok 3.6959 (4.3952)	Learning Rate [0.00125]
0: TRAIN [0][2810/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00092)	Tok/s 52787 (52812)	Loss/tok 3.4801 (4.3897)	Learning Rate [0.00125]
6: TRAIN [0][2810/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00098)	Tok/s 52641 (53352)	Loss/tok 3.5178 (4.3890)	Learning Rate [0.00125]
7: TRAIN [0][2810/3416]	Time 0.057 (0.058)	Data 0.00083 (0.00092)	Tok/s 52536 (53435)	Loss/tok 3.5923 (4.3913)	Learning Rate [0.00125]
8: TRAIN [0][2810/3416]	Time 0.057 (0.058)	Data 0.00106 (0.00098)	Tok/s 52497 (53516)	Loss/tok 3.7423 (4.3905)	Learning Rate [0.00125]
11: TRAIN [0][2810/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00098)	Tok/s 52243 (53734)	Loss/tok 3.5555 (4.3878)	Learning Rate [0.00125]
10: TRAIN [0][2810/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00098)	Tok/s 52246 (53658)	Loss/tok 3.2275 (4.3925)	Learning Rate [0.00125]
9: TRAIN [0][2810/3416]	Time 0.058 (0.058)	Data 0.00083 (0.00094)	Tok/s 52306 (53576)	Loss/tok 3.5638 (4.3869)	Learning Rate [0.00125]
13: TRAIN [0][2810/3416]	Time 0.057 (0.058)	Data 0.00112 (0.00099)	Tok/s 52386 (53940)	Loss/tok 3.4259 (4.3928)	Learning Rate [0.00125]
12: TRAIN [0][2810/3416]	Time 0.058 (0.058)	Data 0.00119 (0.00100)	Tok/s 52247 (53840)	Loss/tok 3.3969 (4.3907)	Learning Rate [0.00125]
4: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00093)	Tok/s 53596 (53204)	Loss/tok 3.7529 (4.3863)	Learning Rate [0.00125]
3: TRAIN [0][2820/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00099)	Tok/s 52730 (53120)	Loss/tok 3.4402 (4.3808)	Learning Rate [0.00125]
5: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00096)	Tok/s 53662 (53294)	Loss/tok 3.6205 (4.3922)	Learning Rate [0.00125]
2: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00097)	Tok/s 52425 (53028)	Loss/tok 3.2997 (4.3901)	Learning Rate [0.00125]
0: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00092)	Tok/s 52309 (52825)	Loss/tok 3.5835 (4.3865)	Learning Rate [0.00125]
1: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00093)	Tok/s 52345 (52926)	Loss/tok 3.7121 (4.3867)	Learning Rate [0.00125]
7: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00092)	Tok/s 53569 (53447)	Loss/tok 3.6980 (4.3880)	Learning Rate [0.00125]
6: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00098)	Tok/s 53602 (53364)	Loss/tok 3.7576 (4.3857)	Learning Rate [0.00125]
14: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00095)	Tok/s 53139 (54052)	Loss/tok 3.4006 (4.3919)	Learning Rate [0.00125]
15: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00092)	Tok/s 53239 (54154)	Loss/tok 3.5699 (4.3878)	Learning Rate [0.00125]
8: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00106 (0.00098)	Tok/s 53469 (53528)	Loss/tok 3.4742 (4.3874)	Learning Rate [0.00125]
9: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00094)	Tok/s 53403 (53588)	Loss/tok 3.5118 (4.3839)	Learning Rate [0.00125]
13: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00099)	Tok/s 53071 (53951)	Loss/tok 3.4248 (4.3896)	Learning Rate [0.00125]
11: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00098)	Tok/s 53164 (53745)	Loss/tok 3.7406 (4.3849)	Learning Rate [0.00125]
12: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00100)	Tok/s 53101 (53851)	Loss/tok 3.5795 (4.3875)	Learning Rate [0.00125]
10: TRAIN [0][2820/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00098)	Tok/s 53176 (53669)	Loss/tok 3.6666 (4.3891)	Learning Rate [0.00125]
3: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00099)	Tok/s 50668 (53103)	Loss/tok 3.4405 (4.3781)	Learning Rate [0.00125]
2: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00097)	Tok/s 50522 (53011)	Loss/tok 3.6274 (4.3874)	Learning Rate [0.00125]
5: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00096)	Tok/s 50437 (53276)	Loss/tok 3.3174 (4.3898)	Learning Rate [0.00125]
6: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00098)	Tok/s 50439 (53347)	Loss/tok 3.4183 (4.3833)	Learning Rate [0.00125]
4: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00114 (0.00093)	Tok/s 50604 (53187)	Loss/tok 3.3788 (4.3836)	Learning Rate [0.00125]
1: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00093)	Tok/s 50575 (52910)	Loss/tok 3.1982 (4.3840)	Learning Rate [0.00125]
7: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00092)	Tok/s 50433 (53429)	Loss/tok 3.4474 (4.3850)	Learning Rate [0.00125]
0: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00092)	Tok/s 50548 (52808)	Loss/tok 3.6691 (4.3836)	Learning Rate [0.00125]
15: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00092)	Tok/s 50590 (54137)	Loss/tok 3.6384 (4.3850)	Learning Rate [0.00125]
14: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00095)	Tok/s 50623 (54035)	Loss/tok 3.5626 (4.3894)	Learning Rate [0.00125]
8: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00098)	Tok/s 50429 (53511)	Loss/tok 3.7116 (4.3848)	Learning Rate [0.00125]
9: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00094)	Tok/s 50455 (53571)	Loss/tok 3.5547 (4.3816)	Learning Rate [0.00125]
12: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00100)	Tok/s 50612 (53834)	Loss/tok 3.3958 (4.3848)	Learning Rate [0.00125]
10: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00098)	Tok/s 50455 (53652)	Loss/tok 3.3324 (4.3865)	Learning Rate [0.00125]
13: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00099)	Tok/s 50560 (53933)	Loss/tok 3.4581 (4.3868)	Learning Rate [0.00125]
11: TRAIN [0][2830/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00098)	Tok/s 50481 (53728)	Loss/tok 3.4868 (4.3821)	Learning Rate [0.00125]
10: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00105 (0.00098)	Tok/s 32024 (53667)	Loss/tok 3.3364 (4.3835)	Learning Rate [0.00125]
12: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00102 (0.00100)	Tok/s 32075 (53849)	Loss/tok 3.2745 (4.3816)	Learning Rate [0.00125]
13: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00099)	Tok/s 32077 (53948)	Loss/tok 3.2323 (4.3835)	Learning Rate [0.00125]
14: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00095)	Tok/s 32091 (54050)	Loss/tok 3.0917 (4.3861)	Learning Rate [0.00125]
8: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00112 (0.00098)	Tok/s 31947 (53526)	Loss/tok 3.2856 (4.3813)	Learning Rate [0.00125]
9: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00094)	Tok/s 31954 (53586)	Loss/tok 3.2252 (4.3781)	Learning Rate [0.00125]
11: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00104 (0.00098)	Tok/s 32015 (53744)	Loss/tok 3.3702 (4.3790)	Learning Rate [0.00125]
15: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00117 (0.00092)	Tok/s 32359 (54152)	Loss/tok 3.2667 (4.3816)	Learning Rate [0.00125]
7: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00099 (0.00092)	Tok/s 31947 (53445)	Loss/tok 3.3782 (4.3818)	Learning Rate [0.00125]
0: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00109 (0.00092)	Tok/s 31975 (52825)	Loss/tok 3.3203 (4.3805)	Learning Rate [0.00125]
5: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00112 (0.00096)	Tok/s 31920 (53291)	Loss/tok 3.1871 (4.3863)	Learning Rate [0.00125]
6: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00101 (0.00098)	Tok/s 31907 (53362)	Loss/tok 3.2992 (4.3797)	Learning Rate [0.00125]
4: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00099 (0.00093)	Tok/s 31934 (53201)	Loss/tok 3.1274 (4.3805)	Learning Rate [0.00125]
1: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00105 (0.00093)	Tok/s 31916 (52925)	Loss/tok 3.1590 (4.3807)	Learning Rate [0.00125]
2: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00097)	Tok/s 31910 (53026)	Loss/tok 3.0478 (4.3838)	Learning Rate [0.00125]
3: TRAIN [0][2840/3416]	Time 0.054 (0.058)	Data 0.00102 (0.00099)	Tok/s 31924 (53118)	Loss/tok 3.4007 (4.3748)	Learning Rate [0.00125]
10: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 77167 (53689)	Loss/tok 3.7616 (4.3802)	Learning Rate [0.00125]
11: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00098)	Tok/s 77867 (53765)	Loss/tok 3.4964 (4.3759)	Learning Rate [0.00125]
12: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00100)	Tok/s 77865 (53871)	Loss/tok 3.4656 (4.3784)	Learning Rate [0.00125]
9: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00094)	Tok/s 77140 (53608)	Loss/tok 3.6084 (4.3750)	Learning Rate [0.00125]
8: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 77071 (53547)	Loss/tok 3.4171 (4.3780)	Learning Rate [0.00125]
14: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00095)	Tok/s 77667 (54071)	Loss/tok 3.4236 (4.3826)	Learning Rate [0.00125]
15: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 77551 (54174)	Loss/tok 3.4996 (4.3781)	Learning Rate [0.00125]
7: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 76963 (53466)	Loss/tok 3.4407 (4.3783)	Learning Rate [0.00125]
6: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00113 (0.00098)	Tok/s 77302 (53384)	Loss/tok 3.4276 (4.3761)	Learning Rate [0.00125]
0: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00092)	Tok/s 75572 (52847)	Loss/tok 3.6177 (4.3775)	Learning Rate [0.00125]
4: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00093)	Tok/s 76628 (53223)	Loss/tok 3.5139 (4.3773)	Learning Rate [0.00125]
1: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00093)	Tok/s 75565 (52948)	Loss/tok 3.8263 (4.3774)	Learning Rate [0.00125]
2: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 75817 (53048)	Loss/tok 3.7567 (4.3811)	Learning Rate [0.00125]
13: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00118 (0.00099)	Tok/s 77462 (53970)	Loss/tok 3.5235 (4.3804)	Learning Rate [0.00125]
5: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00096)	Tok/s 76694 (53312)	Loss/tok 3.5320 (4.3832)	Learning Rate [0.00125]
3: TRAIN [0][2850/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00099)	Tok/s 76519 (53140)	Loss/tok 3.6770 (4.3715)	Learning Rate [0.00125]
1: TRAIN [0][2860/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00093)	Tok/s 47574 (52971)	Loss/tok 3.1379 (4.3741)	Learning Rate [0.00125]
0: TRAIN [0][2860/3416]	Time 0.043 (0.058)	Data 0.00113 (0.00092)	Tok/s 47592 (52871)	Loss/tok 3.3411 (4.3744)	Learning Rate [0.00125]
15: TRAIN [0][2860/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00092)	Tok/s 48211 (54197)	Loss/tok 3.1281 (4.3750)	Learning Rate [0.00125]
14: TRAIN [0][2860/3416]	Time 0.043 (0.058)	Data 0.00092 (0.00095)	Tok/s 47412 (54093)	Loss/tok 3.2455 (4.3797)	Learning Rate [0.00125]
2: TRAIN [0][2860/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00097)	Tok/s 47500 (53072)	Loss/tok 3.4239 (4.3778)	Learning Rate [0.00125]
4: TRAIN [0][2860/3416]	Time 0.043 (0.058)	Data 0.00091 (0.00093)	Tok/s 47216 (53246)	Loss/tok 3.0014 (4.3739)	Learning Rate [0.00125]
5: TRAIN [0][2860/3416]	Time 0.043 (0.058)	Data 0.00105 (0.00096)	Tok/s 47087 (53335)	Loss/tok 3.0443 (4.3799)	Learning Rate [0.00125]
3: TRAIN [0][2860/3416]	Time 0.043 (0.058)	Data 0.00101 (0.00099)	Tok/s 47402 (53163)	Loss/tok 3.2646 (4.3686)	Learning Rate [0.00125]
12: TRAIN [0][2860/3416]	Time 0.043 (0.058)	Data 0.00102 (0.00100)	Tok/s 47089 (53893)	Loss/tok 3.4544 (4.3751)	Learning Rate [0.00125]
10: TRAIN [0][2860/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00098)	Tok/s 46879 (53711)	Loss/tok 3.2969 (4.3771)	Learning Rate [0.00125]
11: TRAIN [0][2860/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00098)	Tok/s 46999 (53788)	Loss/tok 3.4634 (4.3731)	Learning Rate [0.00125]
6: TRAIN [0][2860/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00098)	Tok/s 46965 (53406)	Loss/tok 3.3051 (4.3725)	Learning Rate [0.00125]
7: TRAIN [0][2860/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00092)	Tok/s 46846 (53488)	Loss/tok 3.4407 (4.3748)	Learning Rate [0.00125]
8: TRAIN [0][2860/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00098)	Tok/s 46732 (53569)	Loss/tok 3.4426 (4.3751)	Learning Rate [0.00125]
9: TRAIN [0][2860/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00094)	Tok/s 46808 (53630)	Loss/tok 3.0959 (4.3717)	Learning Rate [0.00125]
13: TRAIN [0][2860/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00099)	Tok/s 47165 (53992)	Loss/tok 3.3926 (4.3771)	Learning Rate [0.00125]
11: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00098)	Tok/s 37500 (53780)	Loss/tok 3.2572 (4.3704)	Learning Rate [0.00125]
10: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00098)	Tok/s 37502 (53703)	Loss/tok 3.3610 (4.3741)	Learning Rate [0.00125]
12: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00100)	Tok/s 37380 (53885)	Loss/tok 3.0166 (4.3721)	Learning Rate [0.00125]
13: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00099)	Tok/s 37448 (53983)	Loss/tok 3.2667 (4.3742)	Learning Rate [0.00125]
8: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00098)	Tok/s 37515 (53561)	Loss/tok 3.4124 (4.3724)	Learning Rate [0.00125]
9: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00094)	Tok/s 37479 (53622)	Loss/tok 3.4420 (4.3687)	Learning Rate [0.00125]
14: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00095)	Tok/s 37433 (54084)	Loss/tok 3.5065 (4.3770)	Learning Rate [0.00125]
15: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00078 (0.00092)	Tok/s 37410 (54188)	Loss/tok 3.2127 (4.3723)	Learning Rate [0.00125]
7: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00092)	Tok/s 37486 (53480)	Loss/tok 3.2458 (4.3718)	Learning Rate [0.00125]
0: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 36157 (52862)	Loss/tok 3.1763 (4.3718)	Learning Rate [0.00125]
6: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00079 (0.00098)	Tok/s 36560 (53397)	Loss/tok 3.4814 (4.3697)	Learning Rate [0.00125]
5: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00096)	Tok/s 36259 (53326)	Loss/tok 3.0820 (4.3767)	Learning Rate [0.00125]
4: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 36231 (53237)	Loss/tok 3.1733 (4.3712)	Learning Rate [0.00125]
1: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00093)	Tok/s 36167 (52962)	Loss/tok 3.2716 (4.3711)	Learning Rate [0.00125]
2: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 36187 (53063)	Loss/tok 3.2691 (4.3752)	Learning Rate [0.00125]
3: TRAIN [0][2870/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00099)	Tok/s 36211 (53154)	Loss/tok 3.2444 (4.3657)	Learning Rate [0.00125]
2: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00104 (0.00097)	Tok/s 51692 (53048)	Loss/tok 3.3700 (4.3725)	Learning Rate [0.00125]
3: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00099)	Tok/s 51623 (53139)	Loss/tok 3.7269 (4.3635)	Learning Rate [0.00125]
4: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00093)	Tok/s 51595 (53222)	Loss/tok 3.3860 (4.3684)	Learning Rate [0.00125]
5: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00107 (0.00096)	Tok/s 51586 (53310)	Loss/tok 3.6964 (4.3740)	Learning Rate [0.00125]
15: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00079 (0.00092)	Tok/s 52415 (54172)	Loss/tok 3.8789 (4.3698)	Learning Rate [0.00125]
14: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00095)	Tok/s 52420 (54069)	Loss/tok 3.5971 (4.3747)	Learning Rate [0.00125]
6: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00098)	Tok/s 51620 (53382)	Loss/tok 3.6845 (4.3671)	Learning Rate [0.00125]
13: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00099)	Tok/s 52439 (53968)	Loss/tok 3.5768 (4.3715)	Learning Rate [0.00125]
12: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00109 (0.00100)	Tok/s 52463 (53870)	Loss/tok 3.4907 (4.3696)	Learning Rate [0.00125]
7: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00092)	Tok/s 52309 (53464)	Loss/tok 3.7604 (4.3693)	Learning Rate [0.00125]
8: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00098)	Tok/s 52514 (53545)	Loss/tok 3.5385 (4.3698)	Learning Rate [0.00125]
11: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00098)	Tok/s 52460 (53765)	Loss/tok 3.7056 (4.3676)	Learning Rate [0.00125]
9: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00094)	Tok/s 52500 (53606)	Loss/tok 3.5429 (4.3662)	Learning Rate [0.00125]
10: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00098)	Tok/s 52426 (53688)	Loss/tok 3.6193 (4.3713)	Learning Rate [0.00125]
1: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00103 (0.00093)	Tok/s 51640 (52947)	Loss/tok 3.8151 (4.3686)	Learning Rate [0.00125]
0: TRAIN [0][2880/3416]	Time 0.062 (0.058)	Data 0.00105 (0.00092)	Tok/s 51558 (52847)	Loss/tok 3.8111 (4.3693)	Learning Rate [0.00125]
4: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00093)	Tok/s 55601 (53234)	Loss/tok 3.7643 (4.3655)	Learning Rate [0.00125]
5: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00106 (0.00096)	Tok/s 55485 (53322)	Loss/tok 3.7754 (4.3711)	Learning Rate [0.00125]
3: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00099)	Tok/s 55621 (53151)	Loss/tok 3.9134 (4.3609)	Learning Rate [0.00125]
2: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00097)	Tok/s 55634 (53060)	Loss/tok 3.6437 (4.3696)	Learning Rate [0.00125]
6: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00098)	Tok/s 55452 (53393)	Loss/tok 3.6797 (4.3644)	Learning Rate [0.00125]
1: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00093)	Tok/s 55620 (52960)	Loss/tok 3.6306 (4.3657)	Learning Rate [0.00125]
0: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 55610 (52860)	Loss/tok 3.7052 (4.3665)	Learning Rate [0.00125]
7: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 55316 (53476)	Loss/tok 3.4322 (4.3659)	Learning Rate [0.00125]
15: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 55552 (54183)	Loss/tok 3.6126 (4.3668)	Learning Rate [0.00125]
8: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00120 (0.00098)	Tok/s 55196 (53557)	Loss/tok 3.3222 (4.3667)	Learning Rate [0.00125]
14: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00095)	Tok/s 55524 (54080)	Loss/tok 3.7021 (4.3715)	Learning Rate [0.00125]
9: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00094)	Tok/s 55237 (53618)	Loss/tok 3.6371 (4.3628)	Learning Rate [0.00125]
13: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00099)	Tok/s 55461 (53979)	Loss/tok 3.8866 (4.3685)	Learning Rate [0.00125]
12: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00112 (0.00100)	Tok/s 55268 (53881)	Loss/tok 3.7965 (4.3669)	Learning Rate [0.00125]
11: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00098)	Tok/s 55207 (53776)	Loss/tok 3.3404 (4.3646)	Learning Rate [0.00125]
10: TRAIN [0][2890/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00098)	Tok/s 55127 (53699)	Loss/tok 3.5349 (4.3678)	Learning Rate [0.00125]
2: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00097)	Tok/s 29397 (53021)	Loss/tok 2.8192 (4.3673)	Learning Rate [0.00125]
3: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00102 (0.00099)	Tok/s 29288 (53112)	Loss/tok 2.7410 (4.3586)	Learning Rate [0.00125]
1: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00107 (0.00093)	Tok/s 29370 (52921)	Loss/tok 2.8570 (4.3634)	Learning Rate [0.00125]
0: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00092)	Tok/s 29377 (52821)	Loss/tok 2.8408 (4.3639)	Learning Rate [0.00125]
4: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00093)	Tok/s 29209 (53194)	Loss/tok 2.9289 (4.3633)	Learning Rate [0.00125]
15: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00092)	Tok/s 30830 (54143)	Loss/tok 2.7530 (4.3646)	Learning Rate [0.00125]
5: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00096)	Tok/s 30326 (53283)	Loss/tok 2.8156 (4.3686)	Learning Rate [0.00125]
14: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00095)	Tok/s 30797 (54040)	Loss/tok 3.0391 (4.3691)	Learning Rate [0.00125]
10: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00098)	Tok/s 30591 (53660)	Loss/tok 2.9583 (4.3655)	Learning Rate [0.00125]
13: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00099)	Tok/s 30750 (53939)	Loss/tok 3.0763 (4.3662)	Learning Rate [0.00125]
6: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00098)	Tok/s 30511 (53354)	Loss/tok 2.9797 (4.3622)	Learning Rate [0.00125]
12: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00100)	Tok/s 30628 (53841)	Loss/tok 2.9820 (4.3645)	Learning Rate [0.00125]
8: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00098)	Tok/s 30441 (53516)	Loss/tok 2.7831 (4.3645)	Learning Rate [0.00125]
9: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00094)	Tok/s 30495 (53578)	Loss/tok 2.5698 (4.3603)	Learning Rate [0.00125]
11: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00098)	Tok/s 30497 (53736)	Loss/tok 2.8657 (4.3621)	Learning Rate [0.00125]
7: TRAIN [0][2900/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00092)	Tok/s 30429 (53436)	Loss/tok 2.8370 (4.3636)	Learning Rate [0.00125]
3: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
8: TRAIN [0][2910/3416]	Time 0.041 (0.058)	Data 0.00097 (0.00098)	Tok/s 29444 (53524)	Loss/tok 2.7753 (4.3614)	Learning Rate [0.00125]
5: TRAIN [0][2910/3416]	Time 0.041 (0.058)	Data 0.00096 (0.00096)	Tok/s 29301 (53289)	Loss/tok 2.8064 (4.3655)	Learning Rate [0.00125]
6: TRAIN [0][2910/3416]	Time 0.041 (0.058)	Data 0.00088 (0.00098)	Tok/s 29360 (53360)	Loss/tok 2.8157 (4.3592)	Learning Rate [0.00125]
7: TRAIN [0][2910/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00092)	Tok/s 29371 (53443)	Loss/tok 2.8747 (4.3603)	Learning Rate [0.00125]
4: TRAIN [0][2910/3416]	Time 0.042 (0.058)	Data 0.00080 (0.00093)	Tok/s 29224 (53200)	Loss/tok 2.7685 (4.3602)	Learning Rate [0.00125]
2: TRAIN [0][2910/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00097)	Tok/s 27621 (53025)	Loss/tok 2.8364 (4.3644)	Learning Rate [0.00125]
3: TRAIN [0][2910/3416]	Time 0.042 (0.058)	Data 0.00099 (0.00099)	Tok/s 27691 (53117)	Loss/tok 2.5401 (4.3554)	Learning Rate [0.00125]
9: TRAIN [0][2910/3416]	Time 0.041 (0.058)	Data 0.00096 (0.00094)	Tok/s 29361 (53585)	Loss/tok 2.9134 (4.3573)	Learning Rate [0.00125]
10: TRAIN [0][2910/3416]	Time 0.041 (0.058)	Data 0.00101 (0.00098)	Tok/s 29308 (53667)	Loss/tok 2.7662 (4.3625)	Learning Rate [0.00125]
0: TRAIN [0][2910/3416]	Time 0.042 (0.058)	Data 0.00082 (0.00092)	Tok/s 27596 (52823)	Loss/tok 2.6601 (4.3611)	Learning Rate [0.00125]
15: TRAIN [0][2910/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00092)	Tok/s 30673 (54151)	Loss/tok 2.8242 (4.3616)	Learning Rate [0.00125]
14: TRAIN [0][2910/3416]	Time 0.042 (0.058)	Data 0.00089 (0.00095)	Tok/s 30668 (54048)	Loss/tok 2.9381 (4.3662)	Learning Rate [0.00125]
11: TRAIN [0][2910/3416]	Time 0.042 (0.058)	Data 0.00100 (0.00098)	Tok/s 29234 (53743)	Loss/tok 2.6109 (4.3592)	Learning Rate [0.00125]
12: TRAIN [0][2910/3416]	Time 0.042 (0.058)	Data 0.00106 (0.00100)	Tok/s 29853 (53849)	Loss/tok 2.8918 (4.3612)	Learning Rate [0.00125]
13: TRAIN [0][2910/3416]	Time 0.042 (0.058)	Data 0.00110 (0.00099)	Tok/s 30620 (53947)	Loss/tok 2.8442 (4.3631)	Learning Rate [0.00125]
1: TRAIN [0][2910/3416]	Time 0.042 (0.058)	Data 0.00088 (0.00093)	Tok/s 27584 (52924)	Loss/tok 2.5842 (4.3604)	Learning Rate [0.00125]
13: Gradient norm: inf
12: Gradient norm: inf
14: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
0: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
2: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
6: Gradient norm: inf
4: Gradient norm: inf
5: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
15: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00092)	Tok/s 63201 (54162)	Loss/tok 3.7592 (4.3586)	Learning Rate [0.00125]
14: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00095)	Tok/s 63262 (54058)	Loss/tok 3.8625 (4.3635)	Learning Rate [0.00125]
9: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00094)	Tok/s 63374 (53595)	Loss/tok 3.5211 (4.3540)	Learning Rate [0.00125]
10: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 63306 (53677)	Loss/tok 3.5712 (4.3598)	Learning Rate [0.00125]
8: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 63281 (53534)	Loss/tok 3.6732 (4.3582)	Learning Rate [0.00125]
12: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00100)	Tok/s 63307 (53859)	Loss/tok 3.7367 (4.3581)	Learning Rate [0.00125]
13: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00099)	Tok/s 63265 (53957)	Loss/tok 3.6717 (4.3601)	Learning Rate [0.00125]
7: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 63184 (53453)	Loss/tok 3.5103 (4.3570)	Learning Rate [0.00125]
0: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 62257 (52834)	Loss/tok 4.0530 (4.3582)	Learning Rate [0.00125]
11: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 63310 (53753)	Loss/tok 3.7625 (4.3563)	Learning Rate [0.00125]
2: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 63157 (53037)	Loss/tok 3.7951 (4.3613)	Learning Rate [0.00125]
6: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00098)	Tok/s 63179 (53371)	Loss/tok 3.6367 (4.3562)	Learning Rate [0.00125]
5: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 63179 (53300)	Loss/tok 4.0470 (4.3625)	Learning Rate [0.00125]
4: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 63177 (53211)	Loss/tok 3.9175 (4.3572)	Learning Rate [0.00125]
3: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 63221 (53128)	Loss/tok 3.4849 (4.3524)	Learning Rate [0.00125]
1: TRAIN [0][2920/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 62932 (52935)	Loss/tok 3.7365 (4.3571)	Learning Rate [0.00125]
10: TRAIN [0][2930/3416]	Time 0.064 (0.058)	Data 0.00102 (0.00098)	Tok/s 54661 (53661)	Loss/tok 3.6988 (4.3574)	Learning Rate [0.00125]
9: TRAIN [0][2930/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00094)	Tok/s 54649 (53579)	Loss/tok 3.5033 (4.3514)	Learning Rate [0.00125]
11: TRAIN [0][2930/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00098)	Tok/s 54567 (53737)	Loss/tok 3.5758 (4.3536)	Learning Rate [0.00125]
12: TRAIN [0][2930/3416]	Time 0.065 (0.058)	Data 0.00109 (0.00100)	Tok/s 54496 (53843)	Loss/tok 3.6465 (4.3557)	Learning Rate [0.00125]
8: TRAIN [0][2930/3416]	Time 0.064 (0.058)	Data 0.00099 (0.00098)	Tok/s 54589 (53518)	Loss/tok 3.5615 (4.3558)	Learning Rate [0.00125]
7: TRAIN [0][2930/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00092)	Tok/s 54493 (53437)	Loss/tok 3.7656 (4.3547)	Learning Rate [0.00125]
13: TRAIN [0][2930/3416]	Time 0.065 (0.058)	Data 0.00108 (0.00099)	Tok/s 54359 (53941)	Loss/tok 3.5346 (4.3576)	Learning Rate [0.00125]
14: TRAIN [0][2930/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00095)	Tok/s 54277 (54042)	Loss/tok 3.5746 (4.3609)	Learning Rate [0.00125]
6: TRAIN [0][2930/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00098)	Tok/s 54409 (53355)	Loss/tok 3.4110 (4.3538)	Learning Rate [0.00125]
5: TRAIN [0][2930/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00096)	Tok/s 54296 (53284)	Loss/tok 3.6352 (4.3601)	Learning Rate [0.00125]
4: TRAIN [0][2930/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00093)	Tok/s 54188 (53196)	Loss/tok 3.6518 (4.3545)	Learning Rate [0.00125]
15: TRAIN [0][2930/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00092)	Tok/s 54167 (54146)	Loss/tok 3.5192 (4.3558)	Learning Rate [0.00125]
0: TRAIN [0][2930/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00092)	Tok/s 54025 (52820)	Loss/tok 3.8816 (4.3559)	Learning Rate [0.00125]
2: TRAIN [0][2930/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00097)	Tok/s 54026 (53022)	Loss/tok 3.8900 (4.3588)	Learning Rate [0.00125]
3: TRAIN [0][2930/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00099)	Tok/s 54087 (53113)	Loss/tok 3.8255 (4.3501)	Learning Rate [0.00125]
1: TRAIN [0][2930/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00093)	Tok/s 53986 (52921)	Loss/tok 4.0285 (4.3547)	Learning Rate [0.00125]
5: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00096)	Tok/s 52991 (53304)	Loss/tok 3.3672 (4.3568)	Learning Rate [0.00125]
4: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00084 (0.00093)	Tok/s 52944 (53216)	Loss/tok 3.6761 (4.3510)	Learning Rate [0.00125]
3: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00099)	Tok/s 53010 (53133)	Loss/tok 3.6612 (4.3467)	Learning Rate [0.00125]
6: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00098)	Tok/s 52847 (53375)	Loss/tok 3.7278 (4.3504)	Learning Rate [0.00125]
7: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00078 (0.00092)	Tok/s 52735 (53457)	Loss/tok 3.5397 (4.3516)	Learning Rate [0.00125]
2: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00097)	Tok/s 52952 (53042)	Loss/tok 3.4540 (4.3554)	Learning Rate [0.00125]
8: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00098)	Tok/s 52666 (53537)	Loss/tok 3.4895 (4.3523)	Learning Rate [0.00125]
0: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00092)	Tok/s 52909 (52840)	Loss/tok 3.6857 (4.3526)	Learning Rate [0.00125]
9: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00084 (0.00094)	Tok/s 52578 (53598)	Loss/tok 3.3956 (4.3484)	Learning Rate [0.00125]
10: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00098)	Tok/s 53109 (53680)	Loss/tok 3.4815 (4.3540)	Learning Rate [0.00125]
15: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00080 (0.00092)	Tok/s 53957 (54166)	Loss/tok 3.5818 (4.3525)	Learning Rate [0.00125]
11: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00098)	Tok/s 53758 (53756)	Loss/tok 3.7089 (4.3503)	Learning Rate [0.00125]
12: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00109 (0.00100)	Tok/s 53767 (53862)	Loss/tok 3.6457 (4.3525)	Learning Rate [0.00125]
13: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00105 (0.00099)	Tok/s 53923 (53960)	Loss/tok 3.6310 (4.3540)	Learning Rate [0.00125]
14: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00095)	Tok/s 53874 (54062)	Loss/tok 3.4491 (4.3578)	Learning Rate [0.00125]
1: TRAIN [0][2940/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00093)	Tok/s 52951 (52941)	Loss/tok 3.6718 (4.3516)	Learning Rate [0.00125]
10: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00106 (0.00098)	Tok/s 53150 (53683)	Loss/tok 3.7230 (4.3516)	Learning Rate [0.00125]
9: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00102 (0.00094)	Tok/s 53177 (53601)	Loss/tok 3.3963 (4.3456)	Learning Rate [0.00125]
11: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00098)	Tok/s 53216 (53759)	Loss/tok 3.3432 (4.3476)	Learning Rate [0.00125]
8: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00106 (0.00098)	Tok/s 53209 (53540)	Loss/tok 3.3043 (4.3493)	Learning Rate [0.00125]
12: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00111 (0.00100)	Tok/s 53907 (53866)	Loss/tok 3.5246 (4.3494)	Learning Rate [0.00125]
13: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00106 (0.00099)	Tok/s 54338 (53964)	Loss/tok 3.5626 (4.3515)	Learning Rate [0.00125]
7: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00092)	Tok/s 53159 (53460)	Loss/tok 3.4397 (4.3491)	Learning Rate [0.00125]
6: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00098)	Tok/s 53190 (53378)	Loss/tok 3.5516 (4.3478)	Learning Rate [0.00125]
14: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00095)	Tok/s 54298 (54065)	Loss/tok 3.5765 (4.3549)	Learning Rate [0.00125]
4: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00093)	Tok/s 53203 (53219)	Loss/tok 3.6072 (4.3481)	Learning Rate [0.00125]
0: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00092)	Tok/s 53236 (52844)	Loss/tok 3.6719 (4.3500)	Learning Rate [0.00125]
15: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00092)	Tok/s 54336 (54169)	Loss/tok 3.6774 (4.3498)	Learning Rate [0.00125]
5: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00096)	Tok/s 53193 (53308)	Loss/tok 3.6999 (4.3541)	Learning Rate [0.00125]
3: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00099)	Tok/s 53280 (53137)	Loss/tok 3.7434 (4.3439)	Learning Rate [0.00125]
2: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00097)	Tok/s 53236 (53046)	Loss/tok 3.5326 (4.3525)	Learning Rate [0.00125]
1: TRAIN [0][2950/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00093)	Tok/s 53206 (52945)	Loss/tok 3.6158 (4.3491)	Learning Rate [0.00125]
2: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00097)	Tok/s 50348 (53041)	Loss/tok 3.3291 (4.3499)	Learning Rate [0.00125]
3: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00099)	Tok/s 50346 (53132)	Loss/tok 3.3984 (4.3414)	Learning Rate [0.00125]
1: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00093)	Tok/s 50266 (52941)	Loss/tok 3.5221 (4.3464)	Learning Rate [0.00125]
0: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00092)	Tok/s 50202 (52840)	Loss/tok 3.2684 (4.3475)	Learning Rate [0.00125]
4: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00093)	Tok/s 50252 (53214)	Loss/tok 3.6490 (4.3454)	Learning Rate [0.00125]
15: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00092)	Tok/s 51372 (54164)	Loss/tok 3.4245 (4.3472)	Learning Rate [0.00125]
14: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00095)	Tok/s 51228 (54060)	Loss/tok 3.5282 (4.3522)	Learning Rate [0.00125]
5: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00096)	Tok/s 50826 (53303)	Loss/tok 3.2455 (4.3514)	Learning Rate [0.00125]
7: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00092)	Tok/s 51177 (53456)	Loss/tok 3.4468 (4.3464)	Learning Rate [0.00125]
6: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00098)	Tok/s 51267 (53374)	Loss/tok 3.5044 (4.3455)	Learning Rate [0.00125]
12: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00117 (0.00100)	Tok/s 50957 (53861)	Loss/tok 3.5143 (4.3469)	Learning Rate [0.00125]
11: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00119 (0.00098)	Tok/s 50891 (53755)	Loss/tok 3.6599 (4.3450)	Learning Rate [0.00125]
8: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00098)	Tok/s 51033 (53536)	Loss/tok 3.6830 (4.3469)	Learning Rate [0.00125]
10: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00098)	Tok/s 50850 (53679)	Loss/tok 3.9154 (4.3489)	Learning Rate [0.00125]
9: TRAIN [0][2960/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00094)	Tok/s 50909 (53597)	Loss/tok 3.3008 (4.3432)	Learning Rate [0.00125]
13: TRAIN [0][2960/3416]	Time 0.051 (0.058)	Data 0.00114 (0.00099)	Tok/s 50628 (53959)	Loss/tok 3.2867 (4.3487)	Learning Rate [0.00125]
8: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00098)	Tok/s 51159 (53536)	Loss/tok 3.7018 (4.3444)	Learning Rate [0.00125]
7: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00092)	Tok/s 51115 (53456)	Loss/tok 3.1023 (4.3437)	Learning Rate [0.00125]
9: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00094)	Tok/s 51185 (53598)	Loss/tok 3.2018 (4.3405)	Learning Rate [0.00125]
10: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00098)	Tok/s 51179 (53679)	Loss/tok 3.3412 (4.3460)	Learning Rate [0.00125]
6: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00098)	Tok/s 50881 (53375)	Loss/tok 3.6306 (4.3429)	Learning Rate [0.00125]
5: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00096)	Tok/s 50760 (53304)	Loss/tok 3.4098 (4.3486)	Learning Rate [0.00125]
12: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00100)	Tok/s 51173 (53861)	Loss/tok 3.3029 (4.3443)	Learning Rate [0.00125]
11: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00098)	Tok/s 51218 (53755)	Loss/tok 3.5651 (4.3426)	Learning Rate [0.00125]
4: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00093)	Tok/s 50813 (53216)	Loss/tok 3.6655 (4.3428)	Learning Rate [0.00125]
3: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00101 (0.00099)	Tok/s 50803 (53133)	Loss/tok 3.6330 (4.3386)	Learning Rate [0.00125]
13: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00099)	Tok/s 51158 (53959)	Loss/tok 3.3773 (4.3462)	Learning Rate [0.00125]
2: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00097)	Tok/s 50790 (53043)	Loss/tok 3.4387 (4.3470)	Learning Rate [0.00125]
1: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00093)	Tok/s 50832 (52942)	Loss/tok 3.5329 (4.3436)	Learning Rate [0.00125]
15: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00092)	Tok/s 50882 (54164)	Loss/tok 3.3337 (4.3447)	Learning Rate [0.00125]
0: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00092)	Tok/s 50742 (52842)	Loss/tok 3.3842 (4.3452)	Learning Rate [0.00125]
14: TRAIN [0][2970/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00095)	Tok/s 50916 (54060)	Loss/tok 3.3971 (4.3494)	Learning Rate [0.00125]
4: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00093)	Tok/s 65298 (53235)	Loss/tok 3.3898 (4.3399)	Learning Rate [0.00125]
10: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 64977 (53697)	Loss/tok 3.7036 (4.3433)	Learning Rate [0.00125]
3: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 65295 (53153)	Loss/tok 3.7373 (4.3354)	Learning Rate [0.00125]
2: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 65246 (53062)	Loss/tok 3.8029 (4.3438)	Learning Rate [0.00125]
5: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00096)	Tok/s 65265 (53323)	Loss/tok 3.6589 (4.3456)	Learning Rate [0.00125]
9: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00094)	Tok/s 65041 (53616)	Loss/tok 3.5867 (4.3375)	Learning Rate [0.00125]
8: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 65068 (53555)	Loss/tok 3.4807 (4.3413)	Learning Rate [0.00125]
7: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 65078 (53475)	Loss/tok 3.8149 (4.3408)	Learning Rate [0.00125]
11: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 64851 (53774)	Loss/tok 3.7616 (4.3399)	Learning Rate [0.00125]
1: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 64509 (52962)	Loss/tok 3.8087 (4.3405)	Learning Rate [0.00125]
0: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 64015 (52861)	Loss/tok 3.6958 (4.3421)	Learning Rate [0.00125]
6: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 65090 (53394)	Loss/tok 3.6734 (4.3401)	Learning Rate [0.00125]
12: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00100)	Tok/s 64738 (53880)	Loss/tok 3.4853 (4.3412)	Learning Rate [0.00125]
15: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 64898 (54182)	Loss/tok 3.6617 (4.3418)	Learning Rate [0.00125]
14: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00095)	Tok/s 64744 (54078)	Loss/tok 3.8394 (4.3465)	Learning Rate [0.00125]
13: TRAIN [0][2980/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00099)	Tok/s 64749 (53977)	Loss/tok 3.6499 (4.3431)	Learning Rate [0.00125]
4: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00093)	Tok/s 48586 (53241)	Loss/tok 3.3275 (4.3369)	Learning Rate [0.00125]
2: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00097)	Tok/s 48594 (53068)	Loss/tok 3.3093 (4.3410)	Learning Rate [0.00125]
5: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00110 (0.00096)	Tok/s 49020 (53329)	Loss/tok 3.2444 (4.3428)	Learning Rate [0.00125]
3: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00099)	Tok/s 48564 (53159)	Loss/tok 3.5438 (4.3328)	Learning Rate [0.00125]
6: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00098)	Tok/s 49717 (53399)	Loss/tok 3.6683 (4.3374)	Learning Rate [0.00125]
1: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00093)	Tok/s 48573 (52968)	Loss/tok 3.5219 (4.3377)	Learning Rate [0.00125]
7: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00091)	Tok/s 49732 (53480)	Loss/tok 3.3438 (4.3384)	Learning Rate [0.00125]
0: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00092)	Tok/s 48434 (52868)	Loss/tok 3.2741 (4.3394)	Learning Rate [0.00125]
15: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00092)	Tok/s 49938 (54187)	Loss/tok 3.3166 (4.3391)	Learning Rate [0.00125]
8: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00098)	Tok/s 49726 (53560)	Loss/tok 3.4274 (4.3383)	Learning Rate [0.00125]
9: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00094)	Tok/s 49732 (53622)	Loss/tok 3.1861 (4.3348)	Learning Rate [0.00125]
14: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00095)	Tok/s 49908 (54083)	Loss/tok 3.2169 (4.3435)	Learning Rate [0.00125]
12: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00100)	Tok/s 49832 (53885)	Loss/tok 3.5995 (4.3383)	Learning Rate [0.00125]
10: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00097 (0.00098)	Tok/s 49569 (53704)	Loss/tok 3.2364 (4.3406)	Learning Rate [0.00125]
13: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00105 (0.00099)	Tok/s 49916 (53983)	Loss/tok 3.4570 (4.3403)	Learning Rate [0.00125]
11: TRAIN [0][2990/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00098)	Tok/s 49559 (53780)	Loss/tok 3.5823 (4.3370)	Learning Rate [0.00125]
7: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00084 (0.00091)	Tok/s 55792 (53459)	Loss/tok 3.6388 (4.3362)	Learning Rate [0.00125]
8: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00098)	Tok/s 55769 (53539)	Loss/tok 3.6327 (4.3360)	Learning Rate [0.00125]
6: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00098)	Tok/s 55692 (53378)	Loss/tok 3.5173 (4.3351)	Learning Rate [0.00125]
5: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00104 (0.00096)	Tok/s 55630 (53308)	Loss/tok 3.2960 (4.3404)	Learning Rate [0.00125]
9: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00094)	Tok/s 55806 (53601)	Loss/tok 3.6015 (4.3324)	Learning Rate [0.00125]
4: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00085 (0.00093)	Tok/s 55555 (53220)	Loss/tok 3.6007 (4.3346)	Learning Rate [0.00125]
10: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00098)	Tok/s 55759 (53683)	Loss/tok 3.4101 (4.3381)	Learning Rate [0.00125]
11: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00098 (0.00098)	Tok/s 55787 (53760)	Loss/tok 3.4941 (4.3346)	Learning Rate [0.00125]
2: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00097)	Tok/s 54361 (53048)	Loss/tok 3.6064 (4.3386)	Learning Rate [0.00125]
3: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00099)	Tok/s 54421 (53138)	Loss/tok 3.5401 (4.3304)	Learning Rate [0.00125]
12: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00100)	Tok/s 55645 (53866)	Loss/tok 3.6427 (4.3361)	Learning Rate [0.00125]
0: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00092)	Tok/s 54398 (52848)	Loss/tok 3.5829 (4.3370)	Learning Rate [0.00125]
1: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00093)	Tok/s 54336 (52948)	Loss/tok 3.5025 (4.3354)	Learning Rate [0.00125]
14: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00095)	Tok/s 55450 (54064)	Loss/tok 3.6368 (4.3410)	Learning Rate [0.00125]
13: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00102 (0.00099)	Tok/s 55543 (53963)	Loss/tok 3.7501 (4.3378)	Learning Rate [0.00125]
15: TRAIN [0][3000/3416]	Time 0.061 (0.058)	Data 0.00086 (0.00092)	Tok/s 55417 (54167)	Loss/tok 3.6760 (4.3368)	Learning Rate [0.00125]
14: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00095)	Tok/s 53825 (54072)	Loss/tok 3.5188 (4.3382)	Learning Rate [0.00125]
13: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00101 (0.00099)	Tok/s 53885 (53971)	Loss/tok 3.6356 (4.3349)	Learning Rate [0.00125]
15: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00096 (0.00092)	Tok/s 53765 (54175)	Loss/tok 3.6667 (4.3338)	Learning Rate [0.00125]
12: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00099 (0.00100)	Tok/s 53721 (53874)	Loss/tok 3.4542 (4.3327)	Learning Rate [0.00125]
0: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00092)	Tok/s 52540 (52856)	Loss/tok 3.5376 (4.3342)	Learning Rate [0.00125]
11: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00098)	Tok/s 52721 (53767)	Loss/tok 3.4587 (4.3316)	Learning Rate [0.00125]
10: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00098)	Tok/s 52678 (53691)	Loss/tok 3.5918 (4.3353)	Learning Rate [0.00125]
2: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00097)	Tok/s 52317 (53055)	Loss/tok 3.6572 (4.3356)	Learning Rate [0.00125]
9: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00094)	Tok/s 52582 (53608)	Loss/tok 3.0376 (4.3292)	Learning Rate [0.00125]
1: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00093)	Tok/s 52342 (52956)	Loss/tok 3.4526 (4.3325)	Learning Rate [0.00125]
8: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00098)	Tok/s 52454 (53546)	Loss/tok 3.5285 (4.3330)	Learning Rate [0.00125]
4: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00093)	Tok/s 52237 (53227)	Loss/tok 3.5354 (4.3314)	Learning Rate [0.00125]
5: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00096)	Tok/s 52221 (53315)	Loss/tok 3.5564 (4.3374)	Learning Rate [0.00125]
7: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00118 (0.00091)	Tok/s 52379 (53466)	Loss/tok 3.5308 (4.3331)	Learning Rate [0.00125]
6: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00105 (0.00098)	Tok/s 52279 (53385)	Loss/tok 3.8501 (4.3321)	Learning Rate [0.00125]
3: TRAIN [0][3010/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00099)	Tok/s 52135 (53145)	Loss/tok 3.2048 (4.3273)	Learning Rate [0.00125]
2: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00097)	Tok/s 33617 (53062)	Loss/tok 3.1274 (4.3329)	Learning Rate [0.00125]
1: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00093)	Tok/s 33594 (52962)	Loss/tok 3.2281 (4.3297)	Learning Rate [0.00125]
3: TRAIN [0][3020/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00099)	Tok/s 33539 (53152)	Loss/tok 2.9415 (4.3241)	Learning Rate [0.00125]
0: TRAIN [0][3020/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00092)	Tok/s 33495 (52862)	Loss/tok 3.2997 (4.3311)	Learning Rate [0.00125]
4: TRAIN [0][3020/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00093)	Tok/s 33565 (53234)	Loss/tok 3.2575 (4.3287)	Learning Rate [0.00125]
12: TRAIN [0][3020/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00100)	Tok/s 33456 (53880)	Loss/tok 3.1508 (4.3296)	Learning Rate [0.00125]
15: TRAIN [0][3020/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00092)	Tok/s 34658 (54182)	Loss/tok 3.4974 (4.3312)	Learning Rate [0.00125]
5: TRAIN [0][3020/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00096)	Tok/s 33509 (53322)	Loss/tok 3.0906 (4.3345)	Learning Rate [0.00125]
11: TRAIN [0][3020/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00098)	Tok/s 33473 (53774)	Loss/tok 3.0680 (4.3285)	Learning Rate [0.00125]
14: TRAIN [0][3020/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00095)	Tok/s 34595 (54079)	Loss/tok 3.2305 (4.3353)	Learning Rate [0.00125]
13: TRAIN [0][3020/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00099)	Tok/s 33707 (53977)	Loss/tok 2.8077 (4.3322)	Learning Rate [0.00125]
8: TRAIN [0][3020/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00098)	Tok/s 33463 (53552)	Loss/tok 3.1757 (4.3305)	Learning Rate [0.00125]
9: TRAIN [0][3020/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00094)	Tok/s 33402 (53615)	Loss/tok 3.2851 (4.3264)	Learning Rate [0.00125]
10: TRAIN [0][3020/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00098)	Tok/s 33372 (53697)	Loss/tok 3.2434 (4.3327)	Learning Rate [0.00125]
6: TRAIN [0][3020/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00098)	Tok/s 33418 (53392)	Loss/tok 3.0218 (4.3292)	Learning Rate [0.00125]
7: TRAIN [0][3020/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00091)	Tok/s 33415 (53473)	Loss/tok 3.2383 (4.3304)	Learning Rate [0.00125]
8: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00098)	Tok/s 48828 (53531)	Loss/tok 3.5316 (4.3280)	Learning Rate [0.00125]
9: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00083 (0.00094)	Tok/s 48868 (53594)	Loss/tok 3.4015 (4.3242)	Learning Rate [0.00125]
7: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00091)	Tok/s 48721 (53452)	Loss/tok 3.3610 (4.3280)	Learning Rate [0.00125]
11: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00098)	Tok/s 48856 (53752)	Loss/tok 3.6664 (4.3263)	Learning Rate [0.00125]
6: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00098)	Tok/s 48118 (53371)	Loss/tok 3.1957 (4.3268)	Learning Rate [0.00125]
5: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00096)	Tok/s 47365 (53301)	Loss/tok 3.4536 (4.3322)	Learning Rate [0.00125]
4: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00081 (0.00093)	Tok/s 47366 (53213)	Loss/tok 3.5305 (4.3265)	Learning Rate [0.00125]
12: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00100)	Tok/s 48864 (53858)	Loss/tok 3.4331 (4.3273)	Learning Rate [0.00125]
3: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00099)	Tok/s 47413 (53130)	Loss/tok 3.5443 (4.3218)	Learning Rate [0.00125]
10: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00098)	Tok/s 48863 (53676)	Loss/tok 3.4303 (4.3304)	Learning Rate [0.00125]
13: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00099)	Tok/s 48897 (53956)	Loss/tok 3.1884 (4.3299)	Learning Rate [0.00125]
2: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00097)	Tok/s 47409 (53040)	Loss/tok 3.3102 (4.3306)	Learning Rate [0.00125]
14: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00095)	Tok/s 48876 (54057)	Loss/tok 3.2906 (4.3331)	Learning Rate [0.00125]
15: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 48810 (54160)	Loss/tok 3.4455 (4.3291)	Learning Rate [0.00125]
1: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00093)	Tok/s 47386 (52940)	Loss/tok 3.4126 (4.3277)	Learning Rate [0.00125]
0: TRAIN [0][3030/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00092)	Tok/s 47413 (52840)	Loss/tok 3.2436 (4.3290)	Learning Rate [0.00125]
4: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00093)	Tok/s 53573 (53204)	Loss/tok 3.4557 (4.3238)	Learning Rate [0.00125]
5: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00100 (0.00096)	Tok/s 54078 (53292)	Loss/tok 3.7284 (4.3295)	Learning Rate [0.00125]
6: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00107 (0.00098)	Tok/s 54487 (53363)	Loss/tok 3.6920 (4.3243)	Learning Rate [0.00125]
3: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00099)	Tok/s 53585 (53121)	Loss/tok 3.6696 (4.3189)	Learning Rate [0.00125]
2: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00106 (0.00097)	Tok/s 53636 (53031)	Loss/tok 3.7270 (4.3282)	Learning Rate [0.00125]
7: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00091)	Tok/s 54378 (53444)	Loss/tok 3.7851 (4.3256)	Learning Rate [0.00125]
15: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00092)	Tok/s 54529 (54153)	Loss/tok 3.7709 (4.3268)	Learning Rate [0.00125]
8: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00098)	Tok/s 54302 (53524)	Loss/tok 3.6122 (4.3253)	Learning Rate [0.00125]
9: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00094)	Tok/s 54227 (53586)	Loss/tok 3.7878 (4.3214)	Learning Rate [0.00125]
1: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00093)	Tok/s 53574 (52930)	Loss/tok 3.6990 (4.3253)	Learning Rate [0.00125]
11: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00098)	Tok/s 54374 (53745)	Loss/tok 3.6018 (4.3238)	Learning Rate [0.00125]
0: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00092)	Tok/s 53528 (52828)	Loss/tok 3.4783 (4.3264)	Learning Rate [0.00125]
10: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00098)	Tok/s 54238 (53668)	Loss/tok 3.7208 (4.3280)	Learning Rate [0.00125]
14: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00095)	Tok/s 54363 (54050)	Loss/tok 3.6957 (4.3306)	Learning Rate [0.00125]
12: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00100)	Tok/s 54210 (53851)	Loss/tok 3.5079 (4.3245)	Learning Rate [0.00125]
13: TRAIN [0][3040/3416]	Time 0.066 (0.058)	Data 0.00108 (0.00099)	Tok/s 54285 (53949)	Loss/tok 3.8463 (4.3274)	Learning Rate [0.00125]
10: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
13: Gradient norm: inf
12: Gradient norm: inf
14: Gradient norm: inf
11: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
7: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
3: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
2: TRAIN [0][3050/3416]	Time 0.066 (0.058)	Data 0.00084 (0.00097)	Tok/s 62140 (53053)	Loss/tok 3.3879 (4.3249)	Learning Rate [0.00125]
1: TRAIN [0][3050/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00093)	Tok/s 62009 (52952)	Loss/tok 3.5102 (4.3223)	Learning Rate [0.00125]
3: TRAIN [0][3050/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00099)	Tok/s 62123 (53143)	Loss/tok 3.9380 (4.3158)	Learning Rate [0.00125]
4: TRAIN [0][3050/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00093)	Tok/s 62108 (53226)	Loss/tok 3.8902 (4.3208)	Learning Rate [0.00125]
0: TRAIN [0][3050/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00092)	Tok/s 61893 (52851)	Loss/tok 3.4807 (4.3231)	Learning Rate [0.00125]
15: TRAIN [0][3050/3416]	Time 0.066 (0.058)	Data 0.00079 (0.00092)	Tok/s 62484 (54178)	Loss/tok 3.5108 (4.3230)	Learning Rate [0.00125]
14: TRAIN [0][3050/3416]	Time 0.066 (0.058)	Data 0.00104 (0.00095)	Tok/s 61736 (54075)	Loss/tok 3.7725 (4.3276)	Learning Rate [0.00125]
5: TRAIN [0][3050/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00096)	Tok/s 62065 (53315)	Loss/tok 3.5661 (4.3263)	Learning Rate [0.00125]
13: TRAIN [0][3050/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00099)	Tok/s 61632 (53972)	Loss/tok 3.6305 (4.3242)	Learning Rate [0.00125]
6: TRAIN [0][3050/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00098)	Tok/s 61900 (53386)	Loss/tok 3.7432 (4.3211)	Learning Rate [0.00125]
7: TRAIN [0][3050/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00091)	Tok/s 61846 (53467)	Loss/tok 3.7951 (4.3225)	Learning Rate [0.00125]
10: TRAIN [0][3050/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00098)	Tok/s 61598 (53691)	Loss/tok 3.8395 (4.3251)	Learning Rate [0.00125]
9: TRAIN [0][3050/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00094)	Tok/s 61616 (53609)	Loss/tok 3.5753 (4.3182)	Learning Rate [0.00125]
11: TRAIN [0][3050/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00098)	Tok/s 61438 (53768)	Loss/tok 3.6213 (4.3205)	Learning Rate [0.00125]
8: TRAIN [0][3050/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00098)	Tok/s 60895 (53546)	Loss/tok 3.4853 (4.3219)	Learning Rate [0.00125]
12: TRAIN [0][3050/3416]	Time 0.067 (0.058)	Data 0.00108 (0.00100)	Tok/s 60692 (53874)	Loss/tok 3.4069 (4.3212)	Learning Rate [0.00125]
4: TRAIN [0][3060/3416]	Time 0.037 (0.058)	Data 0.00094 (0.00093)	Tok/s 27352 (53211)	Loss/tok 2.7339 (4.3184)	Learning Rate [0.00125]
5: TRAIN [0][3060/3416]	Time 0.037 (0.058)	Data 0.00099 (0.00096)	Tok/s 27359 (53300)	Loss/tok 2.8131 (4.3241)	Learning Rate [0.00125]
7: TRAIN [0][3060/3416]	Time 0.038 (0.058)	Data 0.00099 (0.00091)	Tok/s 28527 (53451)	Loss/tok 2.4158 (4.3203)	Learning Rate [0.00125]
3: TRAIN [0][3060/3416]	Time 0.037 (0.058)	Data 0.00086 (0.00099)	Tok/s 27020 (53127)	Loss/tok 2.6781 (4.3134)	Learning Rate [0.00125]
6: TRAIN [0][3060/3416]	Time 0.038 (0.058)	Data 0.00083 (0.00098)	Tok/s 27274 (53370)	Loss/tok 2.6026 (4.3190)	Learning Rate [0.00125]
1: TRAIN [0][3060/3416]	Time 0.038 (0.058)	Data 0.00092 (0.00093)	Tok/s 25489 (52937)	Loss/tok 2.4480 (4.3199)	Learning Rate [0.00125]
8: TRAIN [0][3060/3416]	Time 0.038 (0.058)	Data 0.00087 (0.00098)	Tok/s 28840 (53531)	Loss/tok 2.5401 (4.3194)	Learning Rate [0.00125]
9: TRAIN [0][3060/3416]	Time 0.038 (0.058)	Data 0.00092 (0.00094)	Tok/s 28779 (53594)	Loss/tok 2.3743 (4.3159)	Learning Rate [0.00125]
0: TRAIN [0][3060/3416]	Time 0.038 (0.058)	Data 0.00095 (0.00092)	Tok/s 25390 (52835)	Loss/tok 2.5914 (4.3207)	Learning Rate [0.00125]
2: TRAIN [0][3060/3416]	Time 0.038 (0.058)	Data 0.00101 (0.00097)	Tok/s 25588 (53037)	Loss/tok 2.4412 (4.3226)	Learning Rate [0.00125]
15: TRAIN [0][3060/3416]	Time 0.038 (0.058)	Data 0.00094 (0.00092)	Tok/s 30412 (54161)	Loss/tok 2.7909 (4.3206)	Learning Rate [0.00125]
14: TRAIN [0][3060/3416]	Time 0.038 (0.058)	Data 0.00091 (0.00095)	Tok/s 30356 (54059)	Loss/tok 2.6674 (4.3254)	Learning Rate [0.00125]
12: TRAIN [0][3060/3416]	Time 0.038 (0.058)	Data 0.00099 (0.00100)	Tok/s 28550 (53859)	Loss/tok 2.6377 (4.3190)	Learning Rate [0.00125]
10: TRAIN [0][3060/3416]	Time 0.038 (0.058)	Data 0.00091 (0.00098)	Tok/s 28655 (53675)	Loss/tok 2.3953 (4.3229)	Learning Rate [0.00125]
13: TRAIN [0][3060/3416]	Time 0.038 (0.058)	Data 0.00102 (0.00099)	Tok/s 30258 (53957)	Loss/tok 2.9039 (4.3217)	Learning Rate [0.00125]
11: TRAIN [0][3060/3416]	Time 0.038 (0.058)	Data 0.00090 (0.00098)	Tok/s 28582 (53752)	Loss/tok 2.6442 (4.3182)	Learning Rate [0.00125]
7: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00091)	Tok/s 53100 (53449)	Loss/tok 3.6310 (4.3180)	Learning Rate [0.00125]
8: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00098)	Tok/s 52929 (53529)	Loss/tok 3.6119 (4.3171)	Learning Rate [0.00125]
6: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00098)	Tok/s 53110 (53367)	Loss/tok 3.5635 (4.3165)	Learning Rate [0.00125]
11: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00098)	Tok/s 52919 (53750)	Loss/tok 3.6011 (4.3159)	Learning Rate [0.00125]
5: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00096)	Tok/s 53150 (53297)	Loss/tok 3.6761 (4.3218)	Learning Rate [0.00125]
4: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00092)	Tok/s 53139 (53209)	Loss/tok 3.8668 (4.3157)	Learning Rate [0.00125]
9: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00094)	Tok/s 52871 (53592)	Loss/tok 3.6695 (4.3136)	Learning Rate [0.00125]
12: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00107 (0.00100)	Tok/s 52928 (53856)	Loss/tok 3.5686 (4.3168)	Learning Rate [0.00125]
10: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00134 (0.00098)	Tok/s 52785 (53673)	Loss/tok 3.6911 (4.3205)	Learning Rate [0.00125]
3: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00099)	Tok/s 53073 (53126)	Loss/tok 3.7701 (4.3111)	Learning Rate [0.00125]
2: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00097)	Tok/s 53151 (53035)	Loss/tok 3.5537 (4.3200)	Learning Rate [0.00125]
0: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00092)	Tok/s 53088 (52834)	Loss/tok 3.6537 (4.3183)	Learning Rate [0.00125]
1: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00093)	Tok/s 53123 (52936)	Loss/tok 3.6284 (4.3174)	Learning Rate [0.00125]
14: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00092 (0.00095)	Tok/s 52951 (54056)	Loss/tok 3.6185 (4.3229)	Learning Rate [0.00125]
13: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00103 (0.00099)	Tok/s 52801 (53954)	Loss/tok 3.5567 (4.3190)	Learning Rate [0.00125]
15: TRAIN [0][3070/3416]	Time 0.057 (0.058)	Data 0.00089 (0.00092)	Tok/s 52888 (54158)	Loss/tok 3.5985 (4.3183)	Learning Rate [0.00125]
15: TRAIN [0][3080/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 71351 (54166)	Loss/tok 3.6867 (4.3157)	Learning Rate [0.00125]
14: TRAIN [0][3080/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00095)	Tok/s 71087 (54063)	Loss/tok 3.4405 (4.3203)	Learning Rate [0.00125]
0: TRAIN [0][3080/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 69402 (52843)	Loss/tok 3.5212 (4.3156)	Learning Rate [0.00125]
12: TRAIN [0][3080/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00100)	Tok/s 70402 (53863)	Loss/tok 3.6094 (4.3141)	Learning Rate [0.00125]
1: TRAIN [0][3080/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 69261 (52944)	Loss/tok 3.6468 (4.3146)	Learning Rate [0.00125]
13: TRAIN [0][3080/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00099)	Tok/s 70662 (53961)	Loss/tok 3.6765 (4.3166)	Learning Rate [0.00125]
2: TRAIN [0][3080/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00097)	Tok/s 69525 (53044)	Loss/tok 3.7936 (4.3176)	Learning Rate [0.00125]
10: TRAIN [0][3080/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 70259 (53681)	Loss/tok 3.6672 (4.3181)	Learning Rate [0.00125]
11: TRAIN [0][3080/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 70326 (53757)	Loss/tok 3.4977 (4.3132)	Learning Rate [0.00125]
4: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 69884 (53217)	Loss/tok 3.8068 (4.3134)	Learning Rate [0.00125]
9: TRAIN [0][3080/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00094)	Tok/s 70125 (53599)	Loss/tok 3.5625 (4.3109)	Learning Rate [0.00125]
8: TRAIN [0][3080/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 70006 (53537)	Loss/tok 3.4508 (4.3144)	Learning Rate [0.00125]
5: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 69877 (53305)	Loss/tok 3.6780 (4.3192)	Learning Rate [0.00125]
3: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00099)	Tok/s 69952 (53134)	Loss/tok 3.4565 (4.3085)	Learning Rate [0.00125]
7: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 69906 (53457)	Loss/tok 3.9624 (4.3156)	Learning Rate [0.00125]
6: TRAIN [0][3080/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 69868 (53375)	Loss/tok 3.6884 (4.3142)	Learning Rate [0.00125]
9: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00094)	Tok/s 54438 (53594)	Loss/tok 3.5937 (4.3085)	Learning Rate [0.00125]
10: TRAIN [0][3090/3416]	Time 0.057 (0.058)	Data 0.00089 (0.00098)	Tok/s 54560 (53675)	Loss/tok 3.5984 (4.3159)	Learning Rate [0.00125]
8: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00098)	Tok/s 53277 (53531)	Loss/tok 3.6159 (4.3121)	Learning Rate [0.00125]
11: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00109 (0.00098)	Tok/s 54511 (53752)	Loss/tok 3.5104 (4.3108)	Learning Rate [0.00125]
7: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00091)	Tok/s 53198 (53451)	Loss/tok 3.4296 (4.3132)	Learning Rate [0.00125]
12: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00110 (0.00100)	Tok/s 54494 (53858)	Loss/tok 3.7552 (4.3118)	Learning Rate [0.00125]
6: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00098)	Tok/s 53083 (53370)	Loss/tok 3.4416 (4.3118)	Learning Rate [0.00125]
4: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00092)	Tok/s 53079 (53211)	Loss/tok 3.3699 (4.3106)	Learning Rate [0.00125]
13: TRAIN [0][3090/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00099)	Tok/s 54558 (53956)	Loss/tok 3.5277 (4.3143)	Learning Rate [0.00125]
14: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00095)	Tok/s 54412 (54058)	Loss/tok 3.5938 (4.3177)	Learning Rate [0.00125]
15: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00092)	Tok/s 54384 (54160)	Loss/tok 3.4244 (4.3133)	Learning Rate [0.00125]
3: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00099)	Tok/s 53072 (53129)	Loss/tok 3.4723 (4.3062)	Learning Rate [0.00125]
2: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00107 (0.00097)	Tok/s 53037 (53038)	Loss/tok 3.6307 (4.3152)	Learning Rate [0.00125]
0: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00092)	Tok/s 53153 (52837)	Loss/tok 3.7089 (4.3130)	Learning Rate [0.00125]
1: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00093)	Tok/s 53113 (52938)	Loss/tok 3.9080 (4.3122)	Learning Rate [0.00125]
5: TRAIN [0][3090/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00097)	Tok/s 53064 (53300)	Loss/tok 3.4610 (4.3167)	Learning Rate [0.00125]
11: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00098)	Tok/s 81547 (53773)	Loss/tok 3.5490 (4.3081)	Learning Rate [0.00125]
10: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 81624 (53696)	Loss/tok 3.2555 (4.3127)	Learning Rate [0.00125]
12: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00100)	Tok/s 81500 (53879)	Loss/tok 3.3611 (4.3087)	Learning Rate [0.00125]
13: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00099)	Tok/s 81341 (53977)	Loss/tok 3.4950 (4.3116)	Learning Rate [0.00125]
14: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00095)	Tok/s 81962 (54079)	Loss/tok 3.4817 (4.3150)	Learning Rate [0.00125]
9: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00094)	Tok/s 81588 (53615)	Loss/tok 3.5935 (4.3054)	Learning Rate [0.00125]
15: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00092)	Tok/s 82273 (54181)	Loss/tok 3.3370 (4.3102)	Learning Rate [0.00125]
8: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00098)	Tok/s 81402 (53553)	Loss/tok 3.5756 (4.3094)	Learning Rate [0.00125]
0: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00092)	Tok/s 79484 (52859)	Loss/tok 3.5838 (4.3102)	Learning Rate [0.00125]
7: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 80647 (53473)	Loss/tok 3.2391 (4.3099)	Learning Rate [0.00125]
1: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00093)	Tok/s 80172 (52960)	Loss/tok 3.3382 (4.3091)	Learning Rate [0.00125]
4: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00078 (0.00092)	Tok/s 80645 (53233)	Loss/tok 3.3085 (4.3076)	Learning Rate [0.00125]
2: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 80487 (53060)	Loss/tok 3.3817 (4.3125)	Learning Rate [0.00125]
3: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00099)	Tok/s 80550 (53150)	Loss/tok 3.4235 (4.3031)	Learning Rate [0.00125]
5: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 80631 (53322)	Loss/tok 3.4782 (4.3138)	Learning Rate [0.00125]
6: TRAIN [0][3100/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00098)	Tok/s 80633 (53391)	Loss/tok 3.6236 (4.3090)	Learning Rate [0.00125]
7: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00091)	Tok/s 51623 (53476)	Loss/tok 3.3518 (4.3070)	Learning Rate [0.00125]
8: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00098)	Tok/s 51572 (53556)	Loss/tok 3.2024 (4.3067)	Learning Rate [0.00125]
6: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00098)	Tok/s 51475 (53394)	Loss/tok 3.3714 (4.3063)	Learning Rate [0.00125]
9: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00094)	Tok/s 51595 (53618)	Loss/tok 3.2830 (4.3029)	Learning Rate [0.00125]
4: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00092)	Tok/s 51310 (53236)	Loss/tok 3.5139 (4.3050)	Learning Rate [0.00125]
3: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00099)	Tok/s 51367 (53154)	Loss/tok 3.4180 (4.3005)	Learning Rate [0.00125]
10: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00109 (0.00098)	Tok/s 51567 (53699)	Loss/tok 3.3965 (4.3104)	Learning Rate [0.00125]
5: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00097)	Tok/s 51390 (53325)	Loss/tok 3.2139 (4.3111)	Learning Rate [0.00125]
2: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00097)	Tok/s 51262 (53064)	Loss/tok 3.2383 (4.3097)	Learning Rate [0.00125]
11: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00098)	Tok/s 51907 (53776)	Loss/tok 3.4981 (4.3055)	Learning Rate [0.00125]
0: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00092)	Tok/s 51187 (52862)	Loss/tok 3.4588 (4.3078)	Learning Rate [0.00125]
12: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00100)	Tok/s 52676 (53882)	Loss/tok 3.3947 (4.3060)	Learning Rate [0.00125]
1: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00093)	Tok/s 51225 (52964)	Loss/tok 3.5317 (4.3064)	Learning Rate [0.00125]
14: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00095)	Tok/s 52544 (54082)	Loss/tok 3.4051 (4.3124)	Learning Rate [0.00125]
15: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00092)	Tok/s 52464 (54184)	Loss/tok 3.7195 (4.3075)	Learning Rate [0.00125]
13: TRAIN [0][3110/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00099)	Tok/s 52555 (53979)	Loss/tok 3.3942 (4.3089)	Learning Rate [0.00125]
14: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00095)	Tok/s 54770 (54091)	Loss/tok 3.8771 (4.3100)	Learning Rate [0.00125]
15: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00092)	Tok/s 54818 (54194)	Loss/tok 3.7107 (4.3049)	Learning Rate [0.00125]
0: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00092)	Tok/s 54828 (52873)	Loss/tok 3.7564 (4.3051)	Learning Rate [0.00125]
13: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 54672 (53989)	Loss/tok 3.4500 (4.3062)	Learning Rate [0.00125]
1: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 54815 (52975)	Loss/tok 3.4901 (4.3036)	Learning Rate [0.00125]
12: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00100)	Tok/s 54626 (53891)	Loss/tok 3.4873 (4.3033)	Learning Rate [0.00125]
11: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 54649 (53785)	Loss/tok 3.8982 (4.3034)	Learning Rate [0.00125]
2: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 54817 (53075)	Loss/tok 3.4367 (4.3070)	Learning Rate [0.00125]
10: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 54635 (53709)	Loss/tok 3.4687 (4.3080)	Learning Rate [0.00125]
3: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00099)	Tok/s 54784 (53164)	Loss/tok 3.6803 (4.2981)	Learning Rate [0.00125]
4: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 54818 (53246)	Loss/tok 3.4547 (4.3024)	Learning Rate [0.00125]
9: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00094)	Tok/s 54614 (53628)	Loss/tok 3.9247 (4.3006)	Learning Rate [0.00125]
8: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 54654 (53565)	Loss/tok 3.5243 (4.3040)	Learning Rate [0.00125]
5: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 54777 (53335)	Loss/tok 3.9750 (4.3088)	Learning Rate [0.00125]
7: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00091)	Tok/s 54652 (53486)	Loss/tok 3.6452 (4.3044)	Learning Rate [0.00125]
6: TRAIN [0][3120/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 54708 (53405)	Loss/tok 3.7437 (4.3040)	Learning Rate [0.00125]
2: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 63278 (53071)	Loss/tok 3.4008 (4.3044)	Learning Rate [0.00125]
1: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 63160 (52972)	Loss/tok 3.8132 (4.3010)	Learning Rate [0.00125]
3: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00099)	Tok/s 63277 (53161)	Loss/tok 3.8193 (4.2958)	Learning Rate [0.00125]
0: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 63120 (52870)	Loss/tok 3.7372 (4.3027)	Learning Rate [0.00125]
4: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 63272 (53243)	Loss/tok 3.4477 (4.2998)	Learning Rate [0.00125]
15: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 63625 (54190)	Loss/tok 3.7019 (4.3027)	Learning Rate [0.00125]
5: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 63245 (53332)	Loss/tok 3.6684 (4.3063)	Learning Rate [0.00125]
14: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00095)	Tok/s 63095 (54088)	Loss/tok 3.5227 (4.3075)	Learning Rate [0.00125]
13: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00099)	Tok/s 63095 (53985)	Loss/tok 3.7204 (4.3037)	Learning Rate [0.00125]
7: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 63284 (53482)	Loss/tok 3.7886 (4.3019)	Learning Rate [0.00125]
6: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 63257 (53401)	Loss/tok 3.6703 (4.3014)	Learning Rate [0.00125]
12: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 63067 (53888)	Loss/tok 3.6154 (4.3008)	Learning Rate [0.00125]
8: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 63163 (53561)	Loss/tok 3.6939 (4.3016)	Learning Rate [0.00125]
11: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00098)	Tok/s 63082 (53782)	Loss/tok 3.6737 (4.3010)	Learning Rate [0.00125]
9: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00094)	Tok/s 63147 (53624)	Loss/tok 3.4690 (4.2979)	Learning Rate [0.00125]
10: TRAIN [0][3130/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00098)	Tok/s 63089 (53705)	Loss/tok 3.6590 (4.3056)	Learning Rate [0.00125]
7: TRAIN [0][3140/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00091)	Tok/s 49524 (53468)	Loss/tok 3.4164 (4.2996)	Learning Rate [0.00125]
8: TRAIN [0][3140/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00098)	Tok/s 50321 (53548)	Loss/tok 3.1504 (4.2993)	Learning Rate [0.00125]
6: TRAIN [0][3140/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00098)	Tok/s 48907 (53387)	Loss/tok 3.2617 (4.2989)	Learning Rate [0.00125]
5: TRAIN [0][3140/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00097)	Tok/s 48790 (53318)	Loss/tok 3.6199 (4.3042)	Learning Rate [0.00125]
9: TRAIN [0][3140/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00094)	Tok/s 50331 (53610)	Loss/tok 3.2943 (4.2957)	Learning Rate [0.00125]
10: TRAIN [0][3140/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00098)	Tok/s 50331 (53691)	Loss/tok 3.2465 (4.3035)	Learning Rate [0.00125]
4: TRAIN [0][3140/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00092)	Tok/s 48665 (53229)	Loss/tok 3.4695 (4.2976)	Learning Rate [0.00125]
3: TRAIN [0][3140/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00099)	Tok/s 48560 (53147)	Loss/tok 3.5008 (4.2936)	Learning Rate [0.00125]
11: TRAIN [0][3140/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00098)	Tok/s 50259 (53767)	Loss/tok 3.2371 (4.2985)	Learning Rate [0.00125]
2: TRAIN [0][3140/3416]	Time 0.049 (0.058)	Data 0.00101 (0.00097)	Tok/s 48532 (53057)	Loss/tok 3.6375 (4.3022)	Learning Rate [0.00125]
1: TRAIN [0][3140/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00093)	Tok/s 48551 (52958)	Loss/tok 3.4958 (4.2988)	Learning Rate [0.00125]
12: TRAIN [0][3140/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00100)	Tok/s 50143 (53873)	Loss/tok 3.3069 (4.2985)	Learning Rate [0.00125]
0: TRAIN [0][3140/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00092)	Tok/s 48568 (52857)	Loss/tok 3.4000 (4.3006)	Learning Rate [0.00125]
15: TRAIN [0][3140/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00092)	Tok/s 49927 (54176)	Loss/tok 3.5207 (4.3002)	Learning Rate [0.00125]
14: TRAIN [0][3140/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00095)	Tok/s 49927 (54073)	Loss/tok 3.4657 (4.3052)	Learning Rate [0.00125]
13: TRAIN [0][3140/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00099)	Tok/s 49976 (53971)	Loss/tok 3.4578 (4.3014)	Learning Rate [0.00125]
15: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00092)	Tok/s 55177 (54182)	Loss/tok 3.5702 (4.2977)	Learning Rate [0.00125]
14: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00083 (0.00095)	Tok/s 55219 (54080)	Loss/tok 3.5735 (4.3027)	Learning Rate [0.00125]
0: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00092)	Tok/s 55094 (52865)	Loss/tok 3.6452 (4.2984)	Learning Rate [0.00125]
1: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00093)	Tok/s 54934 (52966)	Loss/tok 3.5618 (4.2961)	Learning Rate [0.00125]
13: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00099)	Tok/s 55173 (53978)	Loss/tok 3.3470 (4.2989)	Learning Rate [0.00125]
12: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00088 (0.00100)	Tok/s 55154 (53880)	Loss/tok 3.7136 (4.2960)	Learning Rate [0.00125]
2: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00097)	Tok/s 54949 (53065)	Loss/tok 3.7825 (4.2995)	Learning Rate [0.00125]
11: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00098)	Tok/s 54935 (53774)	Loss/tok 3.2093 (4.2959)	Learning Rate [0.00125]
4: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00083 (0.00092)	Tok/s 54698 (53237)	Loss/tok 3.4323 (4.2950)	Learning Rate [0.00125]
10: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00103 (0.00098)	Tok/s 54834 (53698)	Loss/tok 3.8499 (4.3009)	Learning Rate [0.00125]
9: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00093)	Tok/s 54788 (53617)	Loss/tok 3.6608 (4.2934)	Learning Rate [0.00125]
3: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00097 (0.00099)	Tok/s 54804 (53155)	Loss/tok 3.5526 (4.2912)	Learning Rate [0.00125]
7: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00091)	Tok/s 54709 (53475)	Loss/tok 3.6060 (4.2972)	Learning Rate [0.00125]
8: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00098)	Tok/s 54783 (53555)	Loss/tok 3.4367 (4.2967)	Learning Rate [0.00125]
5: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00106 (0.00097)	Tok/s 54702 (53326)	Loss/tok 3.4193 (4.3015)	Learning Rate [0.00125]
6: TRAIN [0][3150/3416]	Time 0.064 (0.058)	Data 0.00099 (0.00098)	Tok/s 54620 (53394)	Loss/tok 3.3602 (4.2963)	Learning Rate [0.00125]
4: TRAIN [0][3160/3416]	Time 0.050 (0.058)	Data 0.00080 (0.00092)	Tok/s 37109 (53230)	Loss/tok 3.2933 (4.2925)	Learning Rate [0.00125]
3: TRAIN [0][3160/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00099)	Tok/s 37127 (53148)	Loss/tok 3.2088 (4.2888)	Learning Rate [0.00125]
5: TRAIN [0][3160/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00097)	Tok/s 37047 (53318)	Loss/tok 3.2040 (4.2993)	Learning Rate [0.00125]
2: TRAIN [0][3160/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 36397 (53058)	Loss/tok 3.1235 (4.2972)	Learning Rate [0.00125]
6: TRAIN [0][3160/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00098)	Tok/s 36965 (53387)	Loss/tok 3.0538 (4.2937)	Learning Rate [0.00125]
1: TRAIN [0][3160/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00093)	Tok/s 35766 (52959)	Loss/tok 3.2875 (4.2936)	Learning Rate [0.00125]
7: TRAIN [0][3160/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00091)	Tok/s 36872 (53468)	Loss/tok 3.2958 (4.2947)	Learning Rate [0.00125]
0: TRAIN [0][3160/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00092)	Tok/s 35759 (52858)	Loss/tok 3.3811 (4.2961)	Learning Rate [0.00125]
8: TRAIN [0][3160/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00098)	Tok/s 36846 (53548)	Loss/tok 3.2488 (4.2943)	Learning Rate [0.00125]
15: TRAIN [0][3160/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00092)	Tok/s 36851 (54175)	Loss/tok 3.0559 (4.2950)	Learning Rate [0.00125]
9: TRAIN [0][3160/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 36732 (53610)	Loss/tok 3.1314 (4.2909)	Learning Rate [0.00125]
14: TRAIN [0][3160/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00095)	Tok/s 36743 (54073)	Loss/tok 2.9743 (4.3001)	Learning Rate [0.00125]
10: TRAIN [0][3160/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00098)	Tok/s 36779 (53691)	Loss/tok 3.3284 (4.2983)	Learning Rate [0.00125]
11: TRAIN [0][3160/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00098)	Tok/s 36759 (53767)	Loss/tok 3.2088 (4.2936)	Learning Rate [0.00125]
12: TRAIN [0][3160/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00100)	Tok/s 36741 (53873)	Loss/tok 3.1420 (4.2935)	Learning Rate [0.00125]
13: TRAIN [0][3160/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00099)	Tok/s 36724 (53970)	Loss/tok 3.1122 (4.2964)	Learning Rate [0.00125]
8: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00098)	Tok/s 51349 (53543)	Loss/tok 3.4168 (4.2918)	Learning Rate [0.00125]
6: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00098)	Tok/s 51433 (53383)	Loss/tok 3.6311 (4.2913)	Learning Rate [0.00125]
7: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00085 (0.00091)	Tok/s 51422 (53463)	Loss/tok 3.4080 (4.2922)	Learning Rate [0.00125]
5: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00097)	Tok/s 51428 (53314)	Loss/tok 3.4599 (4.2967)	Learning Rate [0.00125]
9: TRAIN [0][3170/3416]	Time 0.058 (0.058)	Data 0.00083 (0.00093)	Tok/s 51199 (53605)	Loss/tok 3.2441 (4.2884)	Learning Rate [0.00125]
4: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00084 (0.00092)	Tok/s 51420 (53226)	Loss/tok 3.3870 (4.2902)	Learning Rate [0.00125]
10: TRAIN [0][3170/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00098)	Tok/s 51117 (53686)	Loss/tok 3.5235 (4.2960)	Learning Rate [0.00125]
3: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00099)	Tok/s 51416 (53143)	Loss/tok 3.6900 (4.2864)	Learning Rate [0.00125]
11: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00107 (0.00098)	Tok/s 52206 (53763)	Loss/tok 3.4877 (4.2912)	Learning Rate [0.00125]
2: TRAIN [0][3170/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00097)	Tok/s 51278 (53054)	Loss/tok 3.3452 (4.2946)	Learning Rate [0.00125]
12: TRAIN [0][3170/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00100)	Tok/s 52171 (53869)	Loss/tok 3.7576 (4.2911)	Learning Rate [0.00125]
13: TRAIN [0][3170/3416]	Time 0.058 (0.058)	Data 0.00105 (0.00099)	Tok/s 52161 (53966)	Loss/tok 3.4606 (4.2941)	Learning Rate [0.00125]
1: TRAIN [0][3170/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00093)	Tok/s 51146 (52954)	Loss/tok 3.3794 (4.2912)	Learning Rate [0.00125]
14: TRAIN [0][3170/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00095)	Tok/s 52080 (54069)	Loss/tok 3.4150 (4.2975)	Learning Rate [0.00125]
0: TRAIN [0][3170/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00092)	Tok/s 51190 (52853)	Loss/tok 3.6617 (4.2940)	Learning Rate [0.00125]
15: TRAIN [0][3170/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00092)	Tok/s 52210 (54171)	Loss/tok 3.9381 (4.2931)	Learning Rate [0.00125]
14: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
4: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00092)	Tok/s 52565 (53237)	Loss/tok 3.3763 (4.2874)	Learning Rate [0.00125]
1: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00093)	Tok/s 52703 (52966)	Loss/tok 3.4311 (4.2886)	Learning Rate [0.00125]
0: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00092)	Tok/s 52603 (52865)	Loss/tok 3.5267 (4.2913)	Learning Rate [0.00125]
3: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00099)	Tok/s 52627 (53155)	Loss/tok 3.5504 (4.2836)	Learning Rate [0.00125]
2: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00097)	Tok/s 52663 (53066)	Loss/tok 3.7247 (4.2920)	Learning Rate [0.00125]
15: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 53544 (54182)	Loss/tok 3.3928 (4.2908)	Learning Rate [0.00125]
9: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 52208 (53617)	Loss/tok 3.3695 (4.2860)	Learning Rate [0.00125]
11: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00098)	Tok/s 52345 (53775)	Loss/tok 3.2590 (4.2887)	Learning Rate [0.00125]
14: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00095)	Tok/s 52437 (54080)	Loss/tok 3.4023 (4.2949)	Learning Rate [0.00125]
7: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00091)	Tok/s 52253 (53475)	Loss/tok 3.5753 (4.2896)	Learning Rate [0.00125]
5: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00097)	Tok/s 52401 (53326)	Loss/tok 3.4302 (4.2943)	Learning Rate [0.00125]
10: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00098)	Tok/s 52256 (53698)	Loss/tok 3.3323 (4.2938)	Learning Rate [0.00125]
12: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00100)	Tok/s 52300 (53881)	Loss/tok 3.6174 (4.2886)	Learning Rate [0.00125]
6: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00098)	Tok/s 52290 (53394)	Loss/tok 3.4251 (4.2888)	Learning Rate [0.00125]
8: TRAIN [0][3180/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00098)	Tok/s 52133 (53554)	Loss/tok 3.3141 (4.2889)	Learning Rate [0.00125]
13: TRAIN [0][3180/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00099)	Tok/s 52330 (53978)	Loss/tok 3.4949 (4.2914)	Learning Rate [0.00125]
13: Gradient norm: inf
12: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
11: Gradient norm: inf
15: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
10: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
1: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
7: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
5: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
13: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00099)	Tok/s 73261 (53984)	Loss/tok 3.4985 (4.2885)	Learning Rate [0.00125]
12: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00100)	Tok/s 72519 (53886)	Loss/tok 3.5574 (4.2862)	Learning Rate [0.00125]
14: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00095)	Tok/s 73311 (54086)	Loss/tok 3.6021 (4.2924)	Learning Rate [0.00125]
11: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 72548 (53781)	Loss/tok 3.6443 (4.2861)	Learning Rate [0.00125]
10: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 72546 (53704)	Loss/tok 3.6348 (4.2911)	Learning Rate [0.00125]
15: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00117 (0.00092)	Tok/s 73199 (54188)	Loss/tok 3.4775 (4.2883)	Learning Rate [0.00125]
0: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00092)	Tok/s 71184 (52872)	Loss/tok 3.5036 (4.2885)	Learning Rate [0.00125]
9: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00093)	Tok/s 72496 (53623)	Loss/tok 3.6780 (4.2833)	Learning Rate [0.00125]
1: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 71143 (52972)	Loss/tok 3.6325 (4.2860)	Learning Rate [0.00125]
8: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 72379 (53560)	Loss/tok 3.7690 (4.2865)	Learning Rate [0.00125]
2: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00097)	Tok/s 71805 (53072)	Loss/tok 3.4156 (4.2892)	Learning Rate [0.00125]
3: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 71912 (53162)	Loss/tok 3.5108 (4.2810)	Learning Rate [0.00125]
4: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 71985 (53244)	Loss/tok 3.7871 (4.2846)	Learning Rate [0.00125]
6: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00098)	Tok/s 72153 (53401)	Loss/tok 3.6948 (4.2865)	Learning Rate [0.00125]
7: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00115 (0.00091)	Tok/s 72377 (53481)	Loss/tok 3.6850 (4.2872)	Learning Rate [0.00125]
5: TRAIN [0][3190/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00097)	Tok/s 72069 (53333)	Loss/tok 3.5746 (4.2916)	Learning Rate [0.00125]
7: TRAIN [0][3200/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00091)	Tok/s 53953 (53466)	Loss/tok 3.5544 (4.2851)	Learning Rate [0.00125]
5: TRAIN [0][3200/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00097)	Tok/s 53842 (53317)	Loss/tok 3.5370 (4.2895)	Learning Rate [0.00125]
4: TRAIN [0][3200/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00092)	Tok/s 53226 (53228)	Loss/tok 3.7386 (4.2825)	Learning Rate [0.00125]
6: TRAIN [0][3200/3416]	Time 0.066 (0.058)	Data 0.00100 (0.00098)	Tok/s 53936 (53385)	Loss/tok 3.7124 (4.2844)	Learning Rate [0.00125]
8: TRAIN [0][3200/3416]	Time 0.066 (0.058)	Data 0.00087 (0.00098)	Tok/s 53958 (53545)	Loss/tok 3.4436 (4.2841)	Learning Rate [0.00125]
10: TRAIN [0][3200/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00098)	Tok/s 54025 (53689)	Loss/tok 3.3258 (4.2887)	Learning Rate [0.00125]
3: TRAIN [0][3200/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00099)	Tok/s 52815 (53145)	Loss/tok 3.5696 (4.2787)	Learning Rate [0.00125]
9: TRAIN [0][3200/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00093)	Tok/s 53969 (53607)	Loss/tok 3.6853 (4.2812)	Learning Rate [0.00125]
2: TRAIN [0][3200/3416]	Time 0.067 (0.058)	Data 0.00107 (0.00097)	Tok/s 52827 (53055)	Loss/tok 3.4920 (4.2870)	Learning Rate [0.00125]
1: TRAIN [0][3200/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00093)	Tok/s 52848 (52955)	Loss/tok 3.9358 (4.2841)	Learning Rate [0.00125]
0: TRAIN [0][3200/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00092)	Tok/s 52836 (52853)	Loss/tok 3.4970 (4.2863)	Learning Rate [0.00125]
15: TRAIN [0][3200/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00092)	Tok/s 54097 (54172)	Loss/tok 3.8601 (4.2863)	Learning Rate [0.00125]
11: TRAIN [0][3200/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00098)	Tok/s 53962 (53765)	Loss/tok 3.5077 (4.2839)	Learning Rate [0.00125]
12: TRAIN [0][3200/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00100)	Tok/s 53904 (53871)	Loss/tok 3.5749 (4.2841)	Learning Rate [0.00125]
14: TRAIN [0][3200/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00095)	Tok/s 53889 (54070)	Loss/tok 3.8772 (4.2905)	Learning Rate [0.00125]
13: TRAIN [0][3200/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00099)	Tok/s 53841 (53968)	Loss/tok 3.7843 (4.2865)	Learning Rate [0.00125]
11: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00091 (0.00098)	Tok/s 31541 (53746)	Loss/tok 2.7855 (4.2817)	Learning Rate [0.00125]
10: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00090 (0.00098)	Tok/s 31463 (53669)	Loss/tok 2.9627 (4.2867)	Learning Rate [0.00125]
12: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00102 (0.00100)	Tok/s 31478 (53852)	Loss/tok 2.7427 (4.2818)	Learning Rate [0.00125]
9: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00090 (0.00093)	Tok/s 31338 (53588)	Loss/tok 2.6495 (4.2791)	Learning Rate [0.00125]
7: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00082 (0.00091)	Tok/s 31213 (53446)	Loss/tok 3.0682 (4.2832)	Learning Rate [0.00125]
13: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00099)	Tok/s 31425 (53949)	Loss/tok 3.1419 (4.2845)	Learning Rate [0.00125]
8: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00098)	Tok/s 31227 (53525)	Loss/tok 2.6548 (4.2821)	Learning Rate [0.00125]
14: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00095)	Tok/s 31429 (54051)	Loss/tok 2.6261 (4.2882)	Learning Rate [0.00125]
15: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00079 (0.00092)	Tok/s 31355 (54153)	Loss/tok 2.8231 (4.2841)	Learning Rate [0.00125]
0: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00088 (0.00092)	Tok/s 29818 (52834)	Loss/tok 2.8190 (4.2839)	Learning Rate [0.00125]
1: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00087 (0.00093)	Tok/s 29713 (52935)	Loss/tok 2.9366 (4.2819)	Learning Rate [0.00125]
4: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00088 (0.00092)	Tok/s 29596 (53208)	Loss/tok 2.7552 (4.2804)	Learning Rate [0.00125]
6: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00098)	Tok/s 31019 (53366)	Loss/tok 2.7248 (4.2821)	Learning Rate [0.00125]
3: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00099)	Tok/s 29559 (53125)	Loss/tok 3.0177 (4.2768)	Learning Rate [0.00125]
2: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00090 (0.00097)	Tok/s 29580 (53035)	Loss/tok 2.7976 (4.2846)	Learning Rate [0.00125]
5: TRAIN [0][3210/3416]	Time 0.043 (0.058)	Data 0.00089 (0.00097)	Tok/s 29994 (53297)	Loss/tok 2.8698 (4.2873)	Learning Rate [0.00125]
12: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00100)	Tok/s 52828 (53841)	Loss/tok 3.4453 (4.2797)	Learning Rate [0.00125]
11: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00098)	Tok/s 52947 (53735)	Loss/tok 3.4405 (4.2793)	Learning Rate [0.00125]
13: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00099)	Tok/s 52892 (53938)	Loss/tok 3.4012 (4.2822)	Learning Rate [0.00125]
10: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00098)	Tok/s 52766 (53658)	Loss/tok 3.4268 (4.2842)	Learning Rate [0.00125]
14: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00096 (0.00095)	Tok/s 52821 (54041)	Loss/tok 3.3972 (4.2862)	Learning Rate [0.00125]
9: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00083 (0.00093)	Tok/s 52859 (53577)	Loss/tok 3.4087 (4.2768)	Learning Rate [0.00125]
0: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00092)	Tok/s 52962 (52824)	Loss/tok 3.6039 (4.2814)	Learning Rate [0.00125]
15: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00092)	Tok/s 52867 (54143)	Loss/tok 3.3536 (4.2816)	Learning Rate [0.00125]
8: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00086 (0.00098)	Tok/s 52852 (53515)	Loss/tok 3.5437 (4.2799)	Learning Rate [0.00125]
2: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00086 (0.00097)	Tok/s 52943 (53026)	Loss/tok 3.3107 (4.2823)	Learning Rate [0.00125]
7: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00084 (0.00091)	Tok/s 52861 (53435)	Loss/tok 3.3324 (4.2810)	Learning Rate [0.00125]
1: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00093)	Tok/s 52883 (52925)	Loss/tok 3.6543 (4.2795)	Learning Rate [0.00125]
6: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00098)	Tok/s 52918 (53355)	Loss/tok 3.4610 (4.2798)	Learning Rate [0.00125]
4: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00092)	Tok/s 52874 (53198)	Loss/tok 3.6161 (4.2781)	Learning Rate [0.00125]
5: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00096 (0.00097)	Tok/s 52874 (53286)	Loss/tok 3.3662 (4.2848)	Learning Rate [0.00125]
3: TRAIN [0][3220/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00099)	Tok/s 52856 (53115)	Loss/tok 3.4068 (4.2747)	Learning Rate [0.00125]
13: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00099)	Tok/s 53959 (53965)	Loss/tok 3.5145 (4.2791)	Learning Rate [0.00125]
12: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00100)	Tok/s 53915 (53868)	Loss/tok 3.3810 (4.2769)	Learning Rate [0.00125]
14: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00095)	Tok/s 53832 (54067)	Loss/tok 3.7837 (4.2836)	Learning Rate [0.00125]
15: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00092)	Tok/s 53722 (54169)	Loss/tok 3.3829 (4.2790)	Learning Rate [0.00125]
11: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00098)	Tok/s 53317 (53762)	Loss/tok 3.5663 (4.2765)	Learning Rate [0.00125]
10: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00098)	Tok/s 52493 (53685)	Loss/tok 3.5446 (4.2814)	Learning Rate [0.00125]
0: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00092)	Tok/s 52411 (52851)	Loss/tok 3.4542 (4.2786)	Learning Rate [0.00125]
1: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00093)	Tok/s 52242 (52953)	Loss/tok 3.4047 (4.2767)	Learning Rate [0.00125]
9: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00093)	Tok/s 52375 (53604)	Loss/tok 3.5397 (4.2737)	Learning Rate [0.00125]
8: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00098)	Tok/s 52287 (53542)	Loss/tok 3.5331 (4.2770)	Learning Rate [0.00125]
2: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00097)	Tok/s 52208 (53053)	Loss/tok 3.3869 (4.2796)	Learning Rate [0.00125]
7: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00091)	Tok/s 52221 (53462)	Loss/tok 3.5572 (4.2781)	Learning Rate [0.00125]
3: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00111 (0.00099)	Tok/s 52250 (53142)	Loss/tok 3.2399 (4.2714)	Learning Rate [0.00125]
4: TRAIN [0][3230/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00092)	Tok/s 52201 (53225)	Loss/tok 3.6032 (4.2754)	Learning Rate [0.00125]
6: TRAIN [0][3230/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00098)	Tok/s 52178 (53382)	Loss/tok 3.6022 (4.2773)	Learning Rate [0.00125]
5: TRAIN [0][3230/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00097)	Tok/s 52193 (53313)	Loss/tok 3.4501 (4.2816)	Learning Rate [0.00125]
6: TRAIN [0][3240/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00098)	Tok/s 52299 (53382)	Loss/tok 3.7334 (4.2750)	Learning Rate [0.00125]
5: TRAIN [0][3240/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00097)	Tok/s 52193 (53313)	Loss/tok 3.4718 (4.2790)	Learning Rate [0.00125]
7: TRAIN [0][3240/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00091)	Tok/s 52314 (53462)	Loss/tok 3.6059 (4.2757)	Learning Rate [0.00125]
4: TRAIN [0][3240/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00092)	Tok/s 52138 (53224)	Loss/tok 3.5661 (4.2729)	Learning Rate [0.00125]
8: TRAIN [0][3240/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00098)	Tok/s 52309 (53541)	Loss/tok 3.4685 (4.2746)	Learning Rate [0.00125]
3: TRAIN [0][3240/3416]	Time 0.063 (0.058)	Data 0.00105 (0.00098)	Tok/s 52164 (53141)	Loss/tok 3.5203 (4.2691)	Learning Rate [0.00125]
2: TRAIN [0][3240/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00097)	Tok/s 52143 (53051)	Loss/tok 3.6646 (4.2769)	Learning Rate [0.00125]
10: TRAIN [0][3240/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00098)	Tok/s 52287 (53684)	Loss/tok 3.4991 (4.2791)	Learning Rate [0.00125]
1: TRAIN [0][3240/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00093)	Tok/s 52150 (52951)	Loss/tok 3.5560 (4.2742)	Learning Rate [0.00125]
9: TRAIN [0][3240/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00093)	Tok/s 52311 (53603)	Loss/tok 3.7249 (4.2713)	Learning Rate [0.00125]
11: TRAIN [0][3240/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00098)	Tok/s 52301 (53761)	Loss/tok 3.7053 (4.2739)	Learning Rate [0.00125]
15: TRAIN [0][3240/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00092)	Tok/s 53209 (54168)	Loss/tok 3.5032 (4.2768)	Learning Rate [0.00125]
14: TRAIN [0][3240/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00095)	Tok/s 53152 (54066)	Loss/tok 3.7539 (4.2812)	Learning Rate [0.00125]
12: TRAIN [0][3240/3416]	Time 0.062 (0.058)	Data 0.00096 (0.00100)	Tok/s 52259 (53867)	Loss/tok 3.5217 (4.2746)	Learning Rate [0.00125]
13: TRAIN [0][3240/3416]	Time 0.063 (0.058)	Data 0.00094 (0.00099)	Tok/s 52218 (53964)	Loss/tok 3.4353 (4.2767)	Learning Rate [0.00125]
0: TRAIN [0][3240/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00092)	Tok/s 52173 (52850)	Loss/tok 3.5558 (4.2760)	Learning Rate [0.00125]
2: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 47427 (53040)	Loss/tok 3.3718 (4.2744)	Learning Rate [0.00125]
1: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00093)	Tok/s 47356 (52940)	Loss/tok 3.4267 (4.2717)	Learning Rate [0.00125]
3: TRAIN [0][3250/3416]	Time 0.044 (0.058)	Data 0.00126 (0.00099)	Tok/s 48392 (53130)	Loss/tok 3.2682 (4.2669)	Learning Rate [0.00125]
0: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00092)	Tok/s 47246 (52839)	Loss/tok 3.3184 (4.2738)	Learning Rate [0.00125]
4: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00092)	Tok/s 47461 (53214)	Loss/tok 3.2312 (4.2707)	Learning Rate [0.00125]
15: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00092)	Tok/s 48521 (54158)	Loss/tok 3.3599 (4.2743)	Learning Rate [0.00125]
5: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00097)	Tok/s 47459 (53302)	Loss/tok 3.2211 (4.2765)	Learning Rate [0.00125]
14: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00095)	Tok/s 48512 (54056)	Loss/tok 3.2219 (4.2788)	Learning Rate [0.00125]
13: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00099)	Tok/s 48524 (53954)	Loss/tok 3.3013 (4.2743)	Learning Rate [0.00125]
6: TRAIN [0][3250/3416]	Time 0.044 (0.058)	Data 0.00105 (0.00098)	Tok/s 48341 (53371)	Loss/tok 3.3806 (4.2726)	Learning Rate [0.00125]
12: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00100)	Tok/s 48518 (53857)	Loss/tok 3.2202 (4.2721)	Learning Rate [0.00125]
7: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00329 (0.00091)	Tok/s 47396 (53451)	Loss/tok 3.0994 (4.2732)	Learning Rate [0.00125]
8: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00098)	Tok/s 47273 (53530)	Loss/tok 3.3578 (4.2722)	Learning Rate [0.00125]
9: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00093)	Tok/s 47189 (53592)	Loss/tok 3.4186 (4.2690)	Learning Rate [0.00125]
10: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00098)	Tok/s 48477 (53673)	Loss/tok 3.3309 (4.2768)	Learning Rate [0.00125]
11: TRAIN [0][3250/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00098)	Tok/s 48485 (53750)	Loss/tok 3.2864 (4.2718)	Learning Rate [0.00125]
0: TRAIN [0][3260/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 71296 (52857)	Loss/tok 3.4608 (4.2713)	Learning Rate [0.00125]
1: TRAIN [0][3260/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 71275 (52958)	Loss/tok 3.6881 (4.2692)	Learning Rate [0.00125]
15: TRAIN [0][3260/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 72088 (54174)	Loss/tok 3.8046 (4.2720)	Learning Rate [0.00125]
6: TRAIN [0][3260/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 71053 (53389)	Loss/tok 3.5230 (4.2702)	Learning Rate [0.00125]
2: TRAIN [0][3260/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 71184 (53058)	Loss/tok 3.4141 (4.2718)	Learning Rate [0.00125]
14: TRAIN [0][3260/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00095)	Tok/s 71927 (54072)	Loss/tok 3.4932 (4.2762)	Learning Rate [0.00125]
7: TRAIN [0][3260/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00091)	Tok/s 71412 (53469)	Loss/tok 3.6478 (4.2703)	Learning Rate [0.00125]
4: TRAIN [0][3260/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00093)	Tok/s 71089 (53232)	Loss/tok 3.9248 (4.2681)	Learning Rate [0.00125]
3: TRAIN [0][3260/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00099)	Tok/s 71028 (53148)	Loss/tok 3.7084 (4.2644)	Learning Rate [0.00125]
9: TRAIN [0][3260/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 71610 (53609)	Loss/tok 3.7742 (4.2664)	Learning Rate [0.00125]
8: TRAIN [0][3260/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 71604 (53548)	Loss/tok 3.5876 (4.2698)	Learning Rate [0.00125]
13: TRAIN [0][3260/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00099)	Tok/s 71792 (53971)	Loss/tok 3.6791 (4.2719)	Learning Rate [0.00125]
12: TRAIN [0][3260/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00100)	Tok/s 71695 (53874)	Loss/tok 3.7781 (4.2696)	Learning Rate [0.00125]
10: TRAIN [0][3260/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00098)	Tok/s 71555 (53691)	Loss/tok 3.6253 (4.2741)	Learning Rate [0.00125]
11: TRAIN [0][3260/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00098)	Tok/s 71617 (53768)	Loss/tok 3.5315 (4.2691)	Learning Rate [0.00125]
5: TRAIN [0][3260/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00097)	Tok/s 70564 (53320)	Loss/tok 3.5695 (4.2740)	Learning Rate [0.00125]
2: TRAIN [0][3270/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00097)	Tok/s 41844 (53049)	Loss/tok 3.2405 (4.2693)	Learning Rate [0.00125]
1: TRAIN [0][3270/3416]	Time 0.047 (0.058)	Data 0.00081 (0.00093)	Tok/s 41775 (52949)	Loss/tok 3.2829 (4.2667)	Learning Rate [0.00125]
0: TRAIN [0][3270/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00092)	Tok/s 41683 (52848)	Loss/tok 3.4379 (4.2690)	Learning Rate [0.00125]
4: TRAIN [0][3270/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00093)	Tok/s 41829 (53223)	Loss/tok 3.2978 (4.2654)	Learning Rate [0.00125]
15: TRAIN [0][3270/3416]	Time 0.048 (0.058)	Data 0.00081 (0.00092)	Tok/s 42862 (54165)	Loss/tok 3.2133 (4.2694)	Learning Rate [0.00125]
3: TRAIN [0][3270/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00099)	Tok/s 41817 (53140)	Loss/tok 3.1815 (4.2621)	Learning Rate [0.00125]
5: TRAIN [0][3270/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00097)	Tok/s 41875 (53311)	Loss/tok 3.1775 (4.2716)	Learning Rate [0.00125]
14: TRAIN [0][3270/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00095)	Tok/s 42756 (54063)	Loss/tok 3.2543 (4.2737)	Learning Rate [0.00125]
6: TRAIN [0][3270/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00098)	Tok/s 41696 (53380)	Loss/tok 3.5640 (4.2680)	Learning Rate [0.00125]
13: TRAIN [0][3270/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00099)	Tok/s 42687 (53962)	Loss/tok 3.3975 (4.2693)	Learning Rate [0.00125]
7: TRAIN [0][3270/3416]	Time 0.048 (0.058)	Data 0.00079 (0.00091)	Tok/s 41591 (53460)	Loss/tok 3.1604 (4.2684)	Learning Rate [0.00125]
12: TRAIN [0][3270/3416]	Time 0.048 (0.058)	Data 0.00108 (0.00100)	Tok/s 42661 (53865)	Loss/tok 3.3240 (4.2672)	Learning Rate [0.00125]
8: TRAIN [0][3270/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00098)	Tok/s 41570 (53539)	Loss/tok 3.1700 (4.2672)	Learning Rate [0.00125]
10: TRAIN [0][3270/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00098)	Tok/s 41350 (53681)	Loss/tok 3.4065 (4.2717)	Learning Rate [0.00125]
11: TRAIN [0][3270/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00098)	Tok/s 42185 (53759)	Loss/tok 3.1653 (4.2665)	Learning Rate [0.00125]
9: TRAIN [0][3270/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00093)	Tok/s 41419 (53600)	Loss/tok 3.4173 (4.2639)	Learning Rate [0.00125]
15: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00084 (0.00092)	Tok/s 53962 (54165)	Loss/tok 3.5623 (4.2670)	Learning Rate [0.00125]
14: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00095)	Tok/s 53996 (54063)	Loss/tok 3.5522 (4.2713)	Learning Rate [0.00125]
0: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00092)	Tok/s 53878 (52849)	Loss/tok 3.2025 (4.2666)	Learning Rate [0.00125]
1: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00093)	Tok/s 53774 (52950)	Loss/tok 3.8030 (4.2643)	Learning Rate [0.00125]
13: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00099)	Tok/s 54026 (53962)	Loss/tok 3.5460 (4.2672)	Learning Rate [0.00125]
12: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00100)	Tok/s 54021 (53865)	Loss/tok 3.4761 (4.2651)	Learning Rate [0.00125]
2: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00097)	Tok/s 53749 (53050)	Loss/tok 3.4835 (4.2671)	Learning Rate [0.00125]
11: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00098)	Tok/s 54042 (53759)	Loss/tok 3.6389 (4.2642)	Learning Rate [0.00125]
10: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00098)	Tok/s 53956 (53681)	Loss/tok 3.5573 (4.2693)	Learning Rate [0.00125]
4: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00093)	Tok/s 53745 (53224)	Loss/tok 3.5283 (4.2634)	Learning Rate [0.00125]
3: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00099)	Tok/s 53741 (53141)	Loss/tok 3.3111 (4.2598)	Learning Rate [0.00125]
9: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00082 (0.00093)	Tok/s 53927 (53600)	Loss/tok 3.2352 (4.2615)	Learning Rate [0.00125]
5: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00097)	Tok/s 53688 (53312)	Loss/tok 3.4289 (4.2692)	Learning Rate [0.00125]
8: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00098)	Tok/s 53874 (53539)	Loss/tok 3.3568 (4.2647)	Learning Rate [0.00125]
7: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00091)	Tok/s 53788 (53460)	Loss/tok 3.5628 (4.2661)	Learning Rate [0.00125]
6: TRAIN [0][3280/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00098)	Tok/s 53722 (53380)	Loss/tok 3.4420 (4.2659)	Learning Rate [0.00125]
4: TRAIN [0][3290/3416]	Time 0.058 (0.058)	Data 0.00084 (0.00093)	Tok/s 51646 (53199)	Loss/tok 3.3491 (4.2615)	Learning Rate [0.00125]
5: TRAIN [0][3290/3416]	Time 0.058 (0.058)	Data 0.00106 (0.00097)	Tok/s 51604 (53288)	Loss/tok 3.4645 (4.2671)	Learning Rate [0.00125]
6: TRAIN [0][3290/3416]	Time 0.058 (0.058)	Data 0.00104 (0.00098)	Tok/s 51478 (53356)	Loss/tok 3.5524 (4.2638)	Learning Rate [0.00125]
7: TRAIN [0][3290/3416]	Time 0.058 (0.058)	Data 0.00082 (0.00091)	Tok/s 51428 (53436)	Loss/tok 3.3433 (4.2640)	Learning Rate [0.00125]
3: TRAIN [0][3290/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00098)	Tok/s 51589 (53116)	Loss/tok 3.5999 (4.2578)	Learning Rate [0.00125]
2: TRAIN [0][3290/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00097)	Tok/s 51610 (53025)	Loss/tok 3.6631 (4.2654)	Learning Rate [0.00125]
8: TRAIN [0][3290/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00098)	Tok/s 51406 (53515)	Loss/tok 3.6418 (4.2627)	Learning Rate [0.00125]
1: TRAIN [0][3290/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00093)	Tok/s 51361 (52924)	Loss/tok 3.4417 (4.2624)	Learning Rate [0.00125]
9: TRAIN [0][3290/3416]	Time 0.058 (0.058)	Data 0.00084 (0.00093)	Tok/s 51432 (53577)	Loss/tok 3.3057 (4.2595)	Learning Rate [0.00125]
0: TRAIN [0][3290/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00092)	Tok/s 50526 (52822)	Loss/tok 3.4594 (4.2645)	Learning Rate [0.00125]
14: TRAIN [0][3290/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00095)	Tok/s 51603 (54041)	Loss/tok 3.6088 (4.2693)	Learning Rate [0.00125]
12: TRAIN [0][3290/3416]	Time 0.058 (0.058)	Data 0.00106 (0.00100)	Tok/s 51475 (53842)	Loss/tok 3.5378 (4.2632)	Learning Rate [0.00125]
15: TRAIN [0][3290/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00092)	Tok/s 51613 (54143)	Loss/tok 3.4486 (4.2652)	Learning Rate [0.00125]
13: TRAIN [0][3290/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00099)	Tok/s 51472 (53939)	Loss/tok 3.6100 (4.2652)	Learning Rate [0.00125]
11: TRAIN [0][3290/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00098)	Tok/s 51398 (53736)	Loss/tok 3.4761 (4.2623)	Learning Rate [0.00125]
10: TRAIN [0][3290/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00098)	Tok/s 51401 (53658)	Loss/tok 3.4012 (4.2672)	Learning Rate [0.00125]
14: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00095)	Tok/s 52948 (54034)	Loss/tok 3.2619 (4.2669)	Learning Rate [0.00125]
10: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00081 (0.00098)	Tok/s 52565 (53652)	Loss/tok 3.5486 (4.2651)	Learning Rate [0.00125]
12: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00100)	Tok/s 52795 (53836)	Loss/tok 3.6149 (4.2610)	Learning Rate [0.00125]
13: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00099)	Tok/s 52892 (53932)	Loss/tok 3.2636 (4.2628)	Learning Rate [0.00125]
15: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00092)	Tok/s 52886 (54136)	Loss/tok 3.4362 (4.2629)	Learning Rate [0.00125]
0: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00092)	Tok/s 51672 (52815)	Loss/tok 3.6018 (4.2623)	Learning Rate [0.00125]
11: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00105 (0.00098)	Tok/s 52727 (53730)	Loss/tok 3.0584 (4.2599)	Learning Rate [0.00125]
9: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00091 (0.00093)	Tok/s 52549 (53570)	Loss/tok 3.4726 (4.2573)	Learning Rate [0.00125]
1: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00093)	Tok/s 51548 (52916)	Loss/tok 3.5533 (4.2604)	Learning Rate [0.00125]
8: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00098)	Tok/s 52353 (53508)	Loss/tok 3.6892 (4.2605)	Learning Rate [0.00125]
2: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00097)	Tok/s 51735 (53016)	Loss/tok 3.5596 (4.2631)	Learning Rate [0.00125]
7: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00086 (0.00091)	Tok/s 52189 (53429)	Loss/tok 3.3498 (4.2615)	Learning Rate [0.00125]
6: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00098)	Tok/s 52327 (53348)	Loss/tok 3.3350 (4.2613)	Learning Rate [0.00125]
4: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00093)	Tok/s 52379 (53191)	Loss/tok 3.4424 (4.2594)	Learning Rate [0.00125]
3: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00084 (0.00098)	Tok/s 52404 (53108)	Loss/tok 3.5416 (4.2556)	Learning Rate [0.00125]
5: TRAIN [0][3300/3416]	Time 0.056 (0.058)	Data 0.00104 (0.00097)	Tok/s 52185 (53280)	Loss/tok 3.6257 (4.2649)	Learning Rate [0.00125]
7: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00091)	Tok/s 33244 (53408)	Loss/tok 3.2475 (4.2595)	Learning Rate [0.00125]
8: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00097)	Tok/s 33135 (53487)	Loss/tok 3.1342 (4.2582)	Learning Rate [0.00125]
5: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00110 (0.00097)	Tok/s 33199 (53259)	Loss/tok 3.2208 (4.2627)	Learning Rate [0.00125]
6: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00098)	Tok/s 33187 (53327)	Loss/tok 3.0999 (4.2591)	Learning Rate [0.00125]
9: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00093)	Tok/s 33152 (53549)	Loss/tok 3.1281 (4.2551)	Learning Rate [0.00125]
4: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00093)	Tok/s 33184 (53169)	Loss/tok 3.1618 (4.2574)	Learning Rate [0.00125]
10: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00098)	Tok/s 33125 (53630)	Loss/tok 3.2425 (4.2630)	Learning Rate [0.00125]
3: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00098)	Tok/s 33104 (53086)	Loss/tok 3.1858 (4.2535)	Learning Rate [0.00125]
11: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00109 (0.00098)	Tok/s 33122 (53709)	Loss/tok 3.0836 (4.2579)	Learning Rate [0.00125]
2: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00097)	Tok/s 33035 (52994)	Loss/tok 3.2787 (4.2612)	Learning Rate [0.00125]
12: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00100)	Tok/s 33120 (53815)	Loss/tok 3.1306 (4.2591)	Learning Rate [0.00125]
1: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00093)	Tok/s 32994 (52893)	Loss/tok 3.4313 (4.2585)	Learning Rate [0.00125]
13: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00099)	Tok/s 33122 (53912)	Loss/tok 3.1574 (4.2608)	Learning Rate [0.00125]
0: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00092)	Tok/s 33005 (52790)	Loss/tok 3.1826 (4.2603)	Learning Rate [0.00125]
14: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00095)	Tok/s 34283 (54015)	Loss/tok 2.9705 (4.2647)	Learning Rate [0.00125]
15: TRAIN [0][3310/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00092)	Tok/s 34233 (54116)	Loss/tok 3.0094 (4.2608)	Learning Rate [0.00125]
8: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
13: Gradient norm: inf
12: Gradient norm: inf
14: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
7: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
6: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
4: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
2: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00097)	Tok/s 50881 (53011)	Loss/tok 3.4536 (4.2589)	Learning Rate [0.00125]
1: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00093)	Tok/s 50916 (52910)	Loss/tok 3.5840 (4.2560)	Learning Rate [0.00125]
0: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 50464 (52808)	Loss/tok 3.4805 (4.2578)	Learning Rate [0.00125]
3: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00098)	Tok/s 50788 (53103)	Loss/tok 3.7795 (4.2511)	Learning Rate [0.00125]
4: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00093)	Tok/s 50669 (53186)	Loss/tok 3.3625 (4.2547)	Learning Rate [0.00125]
15: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00115 (0.00092)	Tok/s 50863 (54133)	Loss/tok 3.4931 (4.2584)	Learning Rate [0.00125]
5: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00097)	Tok/s 50547 (53275)	Loss/tok 3.7344 (4.2602)	Learning Rate [0.00125]
14: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00115 (0.00095)	Tok/s 50823 (54031)	Loss/tok 3.5501 (4.2620)	Learning Rate [0.00125]
13: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00099)	Tok/s 50804 (53928)	Loss/tok 3.6948 (4.2585)	Learning Rate [0.00125]
6: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00098)	Tok/s 50472 (53343)	Loss/tok 3.6275 (4.2564)	Learning Rate [0.00125]
7: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00091)	Tok/s 50475 (53424)	Loss/tok 3.3279 (4.2571)	Learning Rate [0.00125]
12: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00100)	Tok/s 50671 (53831)	Loss/tok 3.2458 (4.2564)	Learning Rate [0.00125]
8: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00097)	Tok/s 50462 (53503)	Loss/tok 3.2590 (4.2556)	Learning Rate [0.00125]
10: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00098)	Tok/s 50521 (53646)	Loss/tok 3.4870 (4.2602)	Learning Rate [0.00125]
11: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00098)	Tok/s 50661 (53725)	Loss/tok 3.3946 (4.2555)	Learning Rate [0.00125]
9: TRAIN [0][3320/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00093)	Tok/s 50476 (53565)	Loss/tok 3.6465 (4.2526)	Learning Rate [0.00125]
8: TRAIN [0][3330/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00097)	Tok/s 54556 (53511)	Loss/tok 3.6946 (4.2535)	Learning Rate [0.00125]
9: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00093)	Tok/s 54475 (53572)	Loss/tok 3.6109 (4.2502)	Learning Rate [0.00125]
10: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00098)	Tok/s 54375 (53654)	Loss/tok 3.5065 (4.2579)	Learning Rate [0.00125]
5: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00104 (0.00097)	Tok/s 53177 (53282)	Loss/tok 3.5783 (4.2576)	Learning Rate [0.00125]
6: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00098)	Tok/s 53310 (53350)	Loss/tok 3.2816 (4.2540)	Learning Rate [0.00125]
11: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00108 (0.00098)	Tok/s 54180 (53732)	Loss/tok 3.8553 (4.2530)	Learning Rate [0.00125]
4: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00093)	Tok/s 53089 (53193)	Loss/tok 3.6794 (4.2525)	Learning Rate [0.00125]
12: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00103 (0.00100)	Tok/s 54033 (53839)	Loss/tok 3.4436 (4.2544)	Learning Rate [0.00125]
7: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00091)	Tok/s 53578 (53431)	Loss/tok 3.3296 (4.2548)	Learning Rate [0.00125]
3: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00098)	Tok/s 52994 (53110)	Loss/tok 3.6464 (4.2488)	Learning Rate [0.00125]
13: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00099)	Tok/s 54050 (53936)	Loss/tok 3.4319 (4.2560)	Learning Rate [0.00125]
14: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00095)	Tok/s 53991 (54039)	Loss/tok 3.6066 (4.2597)	Learning Rate [0.00125]
2: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00097)	Tok/s 52947 (53018)	Loss/tok 3.3154 (4.2563)	Learning Rate [0.00125]
1: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00105 (0.00093)	Tok/s 52786 (52917)	Loss/tok 3.5921 (4.2537)	Learning Rate [0.00125]
0: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00092)	Tok/s 52752 (52815)	Loss/tok 3.5679 (4.2556)	Learning Rate [0.00125]
15: TRAIN [0][3330/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00092)	Tok/s 53815 (54140)	Loss/tok 3.7445 (4.2560)	Learning Rate [0.00125]
10: TRAIN [0][3340/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00098)	Tok/s 58059 (53649)	Loss/tok 3.6241 (4.2558)	Learning Rate [0.00125]
9: TRAIN [0][3340/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00093)	Tok/s 58002 (53567)	Loss/tok 3.7180 (4.2482)	Learning Rate [0.00125]
0: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00092)	Tok/s 56751 (52807)	Loss/tok 3.7664 (4.2533)	Learning Rate [0.00125]
11: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00108 (0.00098)	Tok/s 57794 (53727)	Loss/tok 3.4898 (4.2509)	Learning Rate [0.00125]
8: TRAIN [0][3340/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00097)	Tok/s 58005 (53506)	Loss/tok 3.5734 (4.2512)	Learning Rate [0.00125]
15: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 57689 (54136)	Loss/tok 3.5925 (4.2540)	Learning Rate [0.00125]
2: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00097)	Tok/s 56760 (53011)	Loss/tok 3.5810 (4.2543)	Learning Rate [0.00125]
12: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00109 (0.00100)	Tok/s 57807 (53834)	Loss/tok 3.2256 (4.2519)	Learning Rate [0.00125]
1: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00093)	Tok/s 56802 (52909)	Loss/tok 3.2574 (4.2516)	Learning Rate [0.00125]
7: TRAIN [0][3340/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00091)	Tok/s 57797 (53426)	Loss/tok 3.5341 (4.2523)	Learning Rate [0.00125]
14: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00095)	Tok/s 57574 (54033)	Loss/tok 3.6669 (4.2579)	Learning Rate [0.00125]
5: TRAIN [0][3340/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00097)	Tok/s 56973 (53276)	Loss/tok 3.5043 (4.2555)	Learning Rate [0.00125]
6: TRAIN [0][3340/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00098)	Tok/s 56924 (53344)	Loss/tok 3.5232 (4.2518)	Learning Rate [0.00125]
4: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00093)	Tok/s 56819 (53187)	Loss/tok 3.4982 (4.2503)	Learning Rate [0.00125]
3: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00098)	Tok/s 56837 (53103)	Loss/tok 3.6573 (4.2466)	Learning Rate [0.00125]
13: TRAIN [0][3340/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00099)	Tok/s 57739 (53931)	Loss/tok 3.4244 (4.2539)	Learning Rate [0.00125]
10: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00098)	Tok/s 77178 (53645)	Loss/tok 3.3406 (4.2537)	Learning Rate [0.00125]
5: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00097)	Tok/s 76828 (53272)	Loss/tok 3.3451 (4.2533)	Learning Rate [0.00125]
6: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 76944 (53340)	Loss/tok 3.4595 (4.2493)	Learning Rate [0.00125]
8: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 77018 (53501)	Loss/tok 3.7826 (4.2489)	Learning Rate [0.00125]
9: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00093)	Tok/s 77080 (53563)	Loss/tok 3.6142 (4.2459)	Learning Rate [0.00125]
4: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 76720 (53182)	Loss/tok 3.5537 (4.2481)	Learning Rate [0.00125]
11: TRAIN [0][3350/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 77402 (53722)	Loss/tok 3.6401 (4.2485)	Learning Rate [0.00125]
12: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00100)	Tok/s 78172 (53829)	Loss/tok 3.5725 (4.2497)	Learning Rate [0.00125]
3: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00098)	Tok/s 75790 (53098)	Loss/tok 3.7709 (4.2446)	Learning Rate [0.00125]
13: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00099)	Tok/s 77960 (53926)	Loss/tok 3.4964 (4.2516)	Learning Rate [0.00125]
2: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 75759 (53007)	Loss/tok 3.5832 (4.2521)	Learning Rate [0.00125]
14: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00095)	Tok/s 77850 (54029)	Loss/tok 3.3529 (4.2555)	Learning Rate [0.00125]
1: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00093)	Tok/s 75783 (52904)	Loss/tok 3.6096 (4.2496)	Learning Rate [0.00125]
0: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 75764 (52802)	Loss/tok 3.6395 (4.2510)	Learning Rate [0.00125]
15: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 77704 (54131)	Loss/tok 3.4669 (4.2520)	Learning Rate [0.00125]
7: TRAIN [0][3350/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00091)	Tok/s 77182 (53422)	Loss/tok 3.4187 (4.2499)	Learning Rate [0.00125]
12: TRAIN [0][3360/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00100)	Tok/s 58944 (53829)	Loss/tok 3.6372 (4.2474)	Learning Rate [0.00125]
11: TRAIN [0][3360/3416]	Time 0.068 (0.058)	Data 0.00109 (0.00098)	Tok/s 58982 (53722)	Loss/tok 3.6796 (4.2461)	Learning Rate [0.00125]
10: TRAIN [0][3360/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00098)	Tok/s 58904 (53645)	Loss/tok 3.5361 (4.2514)	Learning Rate [0.00125]
9: TRAIN [0][3360/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00093)	Tok/s 58925 (53563)	Loss/tok 3.3026 (4.2438)	Learning Rate [0.00125]
13: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00099)	Tok/s 58798 (53926)	Loss/tok 3.8351 (4.2492)	Learning Rate [0.00125]
8: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 58828 (53501)	Loss/tok 3.6772 (4.2468)	Learning Rate [0.00125]
15: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 58596 (54131)	Loss/tok 3.7157 (4.2496)	Learning Rate [0.00125]
14: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00095)	Tok/s 58726 (54029)	Loss/tok 3.5939 (4.2532)	Learning Rate [0.00125]
0: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 58518 (52802)	Loss/tok 3.5124 (4.2489)	Learning Rate [0.00125]
6: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 58657 (53340)	Loss/tok 3.7914 (4.2473)	Learning Rate [0.00125]
1: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 58430 (52905)	Loss/tok 3.4562 (4.2470)	Learning Rate [0.00125]
5: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00097)	Tok/s 58565 (53272)	Loss/tok 3.5179 (4.2510)	Learning Rate [0.00125]
4: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 58468 (53182)	Loss/tok 3.6054 (4.2460)	Learning Rate [0.00125]
2: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 58345 (53007)	Loss/tok 3.8501 (4.2501)	Learning Rate [0.00125]
3: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 58391 (53098)	Loss/tok 3.5838 (4.2421)	Learning Rate [0.00125]
7: TRAIN [0][3360/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00091)	Tok/s 58747 (53421)	Loss/tok 3.6674 (4.2478)	Learning Rate [0.00125]
2: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00097)	Tok/s 53275 (53020)	Loss/tok 3.1730 (4.2476)	Learning Rate [0.00125]
0: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00080 (0.00092)	Tok/s 53119 (52815)	Loss/tok 3.2869 (4.2465)	Learning Rate [0.00125]
3: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00098)	Tok/s 53290 (53111)	Loss/tok 3.4653 (4.2398)	Learning Rate [0.00125]
4: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00093)	Tok/s 53220 (53195)	Loss/tok 3.3883 (4.2437)	Learning Rate [0.00125]
15: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00092)	Tok/s 53056 (54143)	Loss/tok 3.4817 (4.2472)	Learning Rate [0.00125]
5: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00109 (0.00097)	Tok/s 53135 (53284)	Loss/tok 3.6468 (4.2486)	Learning Rate [0.00125]
14: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00095)	Tok/s 53134 (54041)	Loss/tok 3.5035 (4.2507)	Learning Rate [0.00125]
1: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00093)	Tok/s 53189 (52918)	Loss/tok 3.5000 (4.2445)	Learning Rate [0.00125]
13: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00099)	Tok/s 53071 (53939)	Loss/tok 3.3899 (4.2466)	Learning Rate [0.00125]
12: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00104 (0.00100)	Tok/s 53090 (53842)	Loss/tok 3.3756 (4.2447)	Learning Rate [0.00125]
6: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00101 (0.00098)	Tok/s 53108 (53353)	Loss/tok 3.2133 (4.2450)	Learning Rate [0.00125]
11: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00099)	Tok/s 53096 (53735)	Loss/tok 3.2950 (4.2438)	Learning Rate [0.00125]
8: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00084 (0.00097)	Tok/s 53059 (53514)	Loss/tok 3.5384 (4.2442)	Learning Rate [0.00125]
10: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00098)	Tok/s 53037 (53657)	Loss/tok 3.2939 (4.2489)	Learning Rate [0.00125]
9: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00093)	Tok/s 53081 (53575)	Loss/tok 3.6101 (4.2413)	Learning Rate [0.00125]
7: TRAIN [0][3370/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00091)	Tok/s 53177 (53434)	Loss/tok 3.2946 (4.2454)	Learning Rate [0.00125]
15: TRAIN [0][3380/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00092)	Tok/s 51778 (54155)	Loss/tok 3.3573 (4.2447)	Learning Rate [0.00125]
14: TRAIN [0][3380/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00095)	Tok/s 51592 (54054)	Loss/tok 3.2594 (4.2481)	Learning Rate [0.00125]
0: TRAIN [0][3380/3416]	Time 0.054 (0.058)	Data 0.00088 (0.00092)	Tok/s 50570 (52828)	Loss/tok 3.4999 (4.2436)	Learning Rate [0.00125]
1: TRAIN [0][3380/3416]	Time 0.054 (0.058)	Data 0.00108 (0.00093)	Tok/s 50568 (52930)	Loss/tok 3.6284 (4.2419)	Learning Rate [0.00125]
13: TRAIN [0][3380/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00099)	Tok/s 51504 (53952)	Loss/tok 3.4515 (4.2440)	Learning Rate [0.00125]
12: TRAIN [0][3380/3416]	Time 0.055 (0.058)	Data 0.00106 (0.00100)	Tok/s 51507 (53855)	Loss/tok 3.3410 (4.2422)	Learning Rate [0.00125]
2: TRAIN [0][3380/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00097)	Tok/s 50571 (53032)	Loss/tok 3.5823 (4.2448)	Learning Rate [0.00125]
11: TRAIN [0][3380/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00099)	Tok/s 51515 (53748)	Loss/tok 3.4198 (4.2414)	Learning Rate [0.00125]
10: TRAIN [0][3380/3416]	Time 0.055 (0.058)	Data 0.00090 (0.00098)	Tok/s 51586 (53670)	Loss/tok 3.3717 (4.2461)	Learning Rate [0.00125]
4: TRAIN [0][3380/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00093)	Tok/s 51763 (53207)	Loss/tok 3.2356 (4.2412)	Learning Rate [0.00125]
5: TRAIN [0][3380/3416]	Time 0.054 (0.058)	Data 0.00104 (0.00097)	Tok/s 51733 (53296)	Loss/tok 3.4599 (4.2463)	Learning Rate [0.00125]
9: TRAIN [0][3380/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00093)	Tok/s 51563 (53587)	Loss/tok 3.5485 (4.2389)	Learning Rate [0.00125]
8: TRAIN [0][3380/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00097)	Tok/s 51568 (53526)	Loss/tok 3.4189 (4.2418)	Learning Rate [0.00125]
6: TRAIN [0][3380/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00098)	Tok/s 51690 (53365)	Loss/tok 3.4995 (4.2425)	Learning Rate [0.00125]
3: TRAIN [0][3380/3416]	Time 0.054 (0.058)	Data 0.00101 (0.00098)	Tok/s 51310 (53123)	Loss/tok 3.2907 (4.2373)	Learning Rate [0.00125]
7: TRAIN [0][3380/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00091)	Tok/s 51583 (53446)	Loss/tok 3.6338 (4.2428)	Learning Rate [0.00125]
8: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00097)	Tok/s 58319 (53537)	Loss/tok 3.6519 (4.2394)	Learning Rate [0.00125]
9: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00093)	Tok/s 59193 (53599)	Loss/tok 3.3077 (4.2363)	Learning Rate [0.00125]
10: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00098)	Tok/s 59154 (53681)	Loss/tok 3.8732 (4.2440)	Learning Rate [0.00125]
6: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00098)	Tok/s 58091 (53376)	Loss/tok 3.7451 (4.2401)	Learning Rate [0.00125]
5: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00097)	Tok/s 58071 (53308)	Loss/tok 3.5627 (4.2441)	Learning Rate [0.00125]
11: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00109 (0.00099)	Tok/s 59229 (53759)	Loss/tok 3.6371 (4.2390)	Learning Rate [0.00125]
12: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00100)	Tok/s 59300 (53865)	Loss/tok 3.5997 (4.2398)	Learning Rate [0.00125]
4: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00093)	Tok/s 58006 (53218)	Loss/tok 3.7577 (4.2389)	Learning Rate [0.00125]
2: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00097)	Tok/s 58009 (53043)	Loss/tok 3.5621 (4.2425)	Learning Rate [0.00125]
13: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00099)	Tok/s 59184 (53962)	Loss/tok 3.6107 (4.2418)	Learning Rate [0.00125]
3: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00098)	Tok/s 57995 (53134)	Loss/tok 3.4676 (4.2349)	Learning Rate [0.00125]
15: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00092)	Tok/s 59029 (54165)	Loss/tok 3.4907 (4.2424)	Learning Rate [0.00125]
14: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00095)	Tok/s 59108 (54064)	Loss/tok 3.7251 (4.2460)	Learning Rate [0.00125]
0: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00092)	Tok/s 57985 (52839)	Loss/tok 3.8192 (4.2413)	Learning Rate [0.00125]
1: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00093)	Tok/s 57961 (52942)	Loss/tok 4.0086 (4.2398)	Learning Rate [0.00125]
7: TRAIN [0][3390/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00091)	Tok/s 58085 (53457)	Loss/tok 3.5878 (4.2404)	Learning Rate [0.00125]
11: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00110 (0.00099)	Tok/s 53938 (53769)	Loss/tok 3.6604 (4.2368)	Learning Rate [0.00125]
10: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00098)	Tok/s 53791 (53691)	Loss/tok 3.4730 (4.2416)	Learning Rate [0.00125]
12: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00109 (0.00100)	Tok/s 53861 (53875)	Loss/tok 3.6788 (4.2375)	Learning Rate [0.00125]
9: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00093)	Tok/s 53676 (53609)	Loss/tok 3.4852 (4.2339)	Learning Rate [0.00125]
13: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00099)	Tok/s 53892 (53971)	Loss/tok 3.5296 (4.2394)	Learning Rate [0.00125]
8: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00097)	Tok/s 53606 (53548)	Loss/tok 3.5806 (4.2370)	Learning Rate [0.00125]
14: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00095)	Tok/s 53821 (54073)	Loss/tok 3.3280 (4.2438)	Learning Rate [0.00125]
15: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00092)	Tok/s 53780 (54174)	Loss/tok 3.8504 (4.2403)	Learning Rate [0.00125]
6: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00098)	Tok/s 53545 (53387)	Loss/tok 3.6868 (4.2377)	Learning Rate [0.00125]
0: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00092)	Tok/s 52749 (52850)	Loss/tok 3.3787 (4.2391)	Learning Rate [0.00125]
4: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00093)	Tok/s 53602 (53228)	Loss/tok 3.4307 (4.2363)	Learning Rate [0.00125]
1: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00093)	Tok/s 52698 (52952)	Loss/tok 3.4467 (4.2377)	Learning Rate [0.00125]
5: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00113 (0.00097)	Tok/s 53569 (53318)	Loss/tok 3.6384 (4.2417)	Learning Rate [0.00125]
2: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00097)	Tok/s 52661 (53054)	Loss/tok 3.5989 (4.2404)	Learning Rate [0.00125]
3: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00098)	Tok/s 53153 (53145)	Loss/tok 3.5476 (4.2326)	Learning Rate [0.00125]
7: TRAIN [0][3400/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00091)	Tok/s 53581 (53468)	Loss/tok 3.5944 (4.2382)	Learning Rate [0.00125]
12: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00100)	Tok/s 50324 (53892)	Loss/tok 3.1937 (4.2350)	Learning Rate [0.00125]
15: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00082 (0.00092)	Tok/s 50486 (54191)	Loss/tok 3.3004 (4.2378)	Learning Rate [0.00125]
11: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00099)	Tok/s 50240 (53786)	Loss/tok 3.2608 (4.2343)	Learning Rate [0.00125]
13: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00099)	Tok/s 50378 (53988)	Loss/tok 3.3990 (4.2372)	Learning Rate [0.00125]
14: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00095)	Tok/s 50372 (54090)	Loss/tok 3.4805 (4.2412)	Learning Rate [0.00125]
10: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00098)	Tok/s 49972 (53708)	Loss/tok 3.1561 (4.2393)	Learning Rate [0.00125]
0: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00083 (0.00092)	Tok/s 50363 (52868)	Loss/tok 3.3739 (4.2366)	Learning Rate [0.00125]
1: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00093)	Tok/s 50395 (52970)	Loss/tok 3.2508 (4.2353)	Learning Rate [0.00125]
9: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00093)	Tok/s 50019 (53627)	Loss/tok 3.1075 (4.2316)	Learning Rate [0.00125]
8: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00097)	Tok/s 50301 (53565)	Loss/tok 3.5286 (4.2345)	Learning Rate [0.00125]
2: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00097)	Tok/s 50305 (53071)	Loss/tok 3.4166 (4.2378)	Learning Rate [0.00125]
3: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00098)	Tok/s 50172 (53162)	Loss/tok 3.6101 (4.2302)	Learning Rate [0.00125]
4: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00078 (0.00093)	Tok/s 50126 (53246)	Loss/tok 3.4778 (4.2338)	Learning Rate [0.00125]
5: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00097)	Tok/s 50076 (53336)	Loss/tok 3.2851 (4.2391)	Learning Rate [0.00125]
6: TRAIN [0][3410/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00098)	Tok/s 49827 (53404)	Loss/tok 3.2799 (4.2351)	Learning Rate [0.00125]
7: TRAIN [0][3410/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00091)	Tok/s 50142 (53485)	Loss/tok 3.5430 (4.2357)	Learning Rate [0.00125]
15: Running validation on dev set
0: Running validation on dev set
13: Running validation on dev set
1: Running validation on dev set
14: Running validation on dev set
11: Running validation on dev set
6: Running validation on dev set
2: Running validation on dev set
9: Running validation on dev set
4: Running validation on dev set
3: Running validation on dev set
7: Running validation on dev set
8: Running validation on dev set
5: Running validation on dev set
12: Running validation on dev set
10: Running validation on dev set
15: VALIDATION [0][0/5]	Time 0.024 (0.000)	Data 0.00303 (0.00000)	Tok/s 208915 (0)	Loss/tok 3.3908 (0.0000)	Learning Rate [0.00125]
13: VALIDATION [0][0/5]	Time 0.025 (0.000)	Data 0.00216 (0.00000)	Tok/s 213629 (0)	Loss/tok 3.5377 (0.0000)	Learning Rate [0.00125]
1: VALIDATION [0][0/5]	Time 0.039 (0.000)	Data 0.00308 (0.00000)	Tok/s 215344 (0)	Loss/tok 3.6035 (0.0000)	Learning Rate [0.00125]
14: VALIDATION [0][0/5]	Time 0.023 (0.000)	Data 0.00210 (0.00000)	Tok/s 222174 (0)	Loss/tok 3.5667 (0.0000)	Learning Rate [0.00125]
0: VALIDATION [0][0/5]	Time 0.061 (0.000)	Data 0.00242 (0.00000)	Tok/s 165612 (0)	Loss/tok 3.7017 (0.0000)	Learning Rate [0.00125]
6: VALIDATION [0][0/5]	Time 0.028 (0.000)	Data 0.00212 (0.00000)	Tok/s 227116 (0)	Loss/tok 3.4122 (0.0000)	Learning Rate [0.00125]
11: VALIDATION [0][0/5]	Time 0.025 (0.000)	Data 0.00233 (0.00000)	Tok/s 223043 (0)	Loss/tok 3.4396 (0.0000)	Learning Rate [0.00125]
2: VALIDATION [0][0/5]	Time 0.035 (0.000)	Data 0.00215 (0.00000)	Tok/s 219500 (0)	Loss/tok 3.5690 (0.0000)	Learning Rate [0.00125]
9: VALIDATION [0][0/5]	Time 0.027 (0.000)	Data 0.00251 (0.00000)	Tok/s 217773 (0)	Loss/tok 3.5106 (0.0000)	Learning Rate [0.00125]
4: VALIDATION [0][0/5]	Time 0.031 (0.000)	Data 0.00225 (0.00000)	Tok/s 221450 (0)	Loss/tok 3.3697 (0.0000)	Learning Rate [0.00125]
3: VALIDATION [0][0/5]	Time 0.033 (0.000)	Data 0.00246 (0.00000)	Tok/s 221748 (0)	Loss/tok 3.4352 (0.0000)	Learning Rate [0.00125]
7: VALIDATION [0][0/5]	Time 0.031 (0.000)	Data 0.00562 (0.00000)	Tok/s 200584 (0)	Loss/tok 3.5298 (0.0000)	Learning Rate [0.00125]
8: VALIDATION [0][0/5]	Time 0.026 (0.000)	Data 0.00212 (0.00000)	Tok/s 230014 (0)	Loss/tok 3.5374 (0.0000)	Learning Rate [0.00125]
10: VALIDATION [0][0/5]	Time 0.026 (0.000)	Data 0.00222 (0.00000)	Tok/s 221810 (0)	Loss/tok 3.3572 (0.0000)	Learning Rate [0.00125]
12: VALIDATION [0][0/5]	Time 0.026 (0.000)	Data 0.00493 (0.00000)	Tok/s 204788 (0)	Loss/tok 3.4165 (0.0000)	Learning Rate [0.00125]
5: VALIDATION [0][0/5]	Time 0.029 (0.000)	Data 0.00245 (0.00000)	Tok/s 227307 (0)	Loss/tok 3.4288 (0.0000)	Learning Rate [0.00125]
8: Running evaluation on test set
10: Running evaluation on test set
2: Running evaluation on test set
9: Running evaluation on test set
12: Running evaluation on test set
11: Running evaluation on test set
7: Running evaluation on test set
14: Running evaluation on test set
1: Running evaluation on test set
6: Running evaluation on test set
15: Running evaluation on test set
4: Running evaluation on test set
3: Running evaluation on test set
13: Running evaluation on test set
5: Running evaluation on test set
:::MLPv0.5.0 gnmt 1541782455.134967804 (train.py:459) eval_start: 0
0: Running evaluation on test set
0: TEST [0][0/2]	Time 0.918 (0.918)	Decoder iters 65.0 (65.0)	Tok/s 7480 (7480)
2: TEST [0][0/2]	Time 0.919 (0.919)	Decoder iters 110.0 (110.0)	Tok/s 7922 (7922)
15: TEST [0][0/2]	Time 0.919 (0.919)	Decoder iters 69.0 (69.0)	Tok/s 8716 (8716)
3: TEST [0][0/2]	Time 0.919 (0.919)	Decoder iters 80.0 (80.0)	Tok/s 8154 (8154)
10: TEST [0][0/2]	Time 0.919 (0.919)	Decoder iters 56.0 (56.0)	Tok/s 7090 (7090)
6: TEST [0][0/2]	Time 0.919 (0.919)	Decoder iters 84.0 (84.0)	Tok/s 8377 (8377)
4: TEST [0][0/2]	Time 0.919 (0.919)	Decoder iters 68.0 (68.0)	Tok/s 8411 (8411)
13: TEST [0][0/2]	Time 0.919 (0.919)	Decoder iters 61.0 (61.0)	Tok/s 7450 (7450)
7: TEST [0][0/2]	Time 0.920 (0.920)	Decoder iters 65.0 (65.0)	Tok/s 7764 (7764)
11: TEST [0][0/2]	Time 0.920 (0.920)	Decoder iters 64.0 (64.0)	Tok/s 6829 (6829)
5: TEST [0][0/2]	Time 0.920 (0.920)	Decoder iters 58.0 (58.0)	Tok/s 7156 (7156)
12: TEST [0][0/2]	Time 0.921 (0.921)	Decoder iters 66.0 (66.0)	Tok/s 6866 (6866)
8: TEST [0][0/2]	Time 0.922 (0.922)	Decoder iters 64.0 (64.0)	Tok/s 7921 (7921)
1: TEST [0][0/2]	Time 0.922 (0.922)	Decoder iters 70.0 (70.0)	Tok/s 8123 (8123)
14: TEST [0][0/2]	Time 0.922 (0.922)	Decoder iters 73.0 (73.0)	Tok/s 8676 (8676)
9: TEST [0][0/2]	Time 0.926 (0.926)	Decoder iters 59.0 (59.0)	Tok/s 7074 (7074)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
4: Finished evaluation on test set
14: Finished evaluation on test set
1: Finished evaluation on test set
15: Finished evaluation on test set
9: Finished evaluation on test set
8: Finished evaluation on test set
3: Finished evaluation on test set
10: Finished evaluation on test set
13: Finished evaluation on test set
11: Finished evaluation on test set
6: Finished evaluation on test set
12: Finished evaluation on test set
2: Finished evaluation on test set
7: Finished evaluation on test set
5: Finished evaluation on test set
0: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1541782461.992266417 (train.py:464) eval_accuracy: {"epoch": 0, "value": 18.8799991607666}
:::MLPv0.5.0 gnmt 1541782461.992723465 (train.py:466) eval_target: 21.8
10: Summary: Epoch: 0	Training Loss 4.2349
4: Summary: Epoch: 0	Training Loss 4.2349
14: Summary: Epoch: 0	Training Loss 4.2349
12: Summary: Epoch: 0	Training Loss 4.2349
9: Summary: Epoch: 0	Training Loss 4.2349
3: Summary: Epoch: 0	Training Loss 4.2349
1: Summary: Epoch: 0	Training Loss 4.2349
15: Summary: Epoch: 0	Training Loss 4.2349
7: Summary: Epoch: 0	Training Loss 4.2349
2: Summary: Epoch: 0	Training Loss 4.2349
5: Summary: Epoch: 0	Training Loss 4.2349
8: Summary: Epoch: 0	Training Loss 4.2349
11: Summary: Epoch: 0	Training Loss 4.2349
13: Summary: Epoch: 0	Training Loss 4.2349
6: Summary: Epoch: 0	Training Loss 4.2349
10: Performance: Epoch: 0	Training: 856287 Tok/s
4: Performance: Epoch: 0	Training: 856287 Tok/s
14: Performance: Epoch: 0	Training: 856287 Tok/s
12: Performance: Epoch: 0	Training: 856287 Tok/s
9: Performance: Epoch: 0	Training: 856287 Tok/s
3: Performance: Epoch: 0	Training: 856287 Tok/s
15: Performance: Epoch: 0	Training: 856287 Tok/s
2: Performance: Epoch: 0	Training: 856287 Tok/s
11: Performance: Epoch: 0	Training: 856287 Tok/s
5: Performance: Epoch: 0	Training: 856287 Tok/s
8: Performance: Epoch: 0	Training: 856287 Tok/s
13: Performance: Epoch: 0	Training: 856287 Tok/s
10: Finished epoch 0
1: Performance: Epoch: 0	Training: 856287 Tok/s
4: Finished epoch 0
7: Performance: Epoch: 0	Training: 856287 Tok/s
14: Finished epoch 0
6: Performance: Epoch: 0	Training: 856287 Tok/s
12: Finished epoch 0
9: Finished epoch 0
15: Finished epoch 0
3: Finished epoch 0
2: Finished epoch 0
11: Finished epoch 0
8: Finished epoch 0
5: Finished epoch 0
13: Finished epoch 0
10: Starting epoch 1
4: Starting epoch 1
14: Starting epoch 1
6: Finished epoch 0
9: Starting epoch 1
12: Starting epoch 1
15: Starting epoch 1
3: Starting epoch 1
7: Finished epoch 0
1: Finished epoch 0
2: Starting epoch 1
11: Starting epoch 1
:::MLPv0.5.0 gnmt 1541782461.993382215 (train.py:467) eval_stop
13: Starting epoch 1
5: Starting epoch 1
8: Starting epoch 1
6: Starting epoch 1
1: Starting epoch 1
7: Starting epoch 1
0: Summary: Epoch: 0	Training Loss: 4.2349	Validation Loss: 3.2793	Test BLEU: 18.88
0: Performance: Epoch: 0	Training: 856287 Tok/s	Validation: 2782872 Tok/s
0: Finished epoch 0
0: Starting epoch 1
:::MLPv0.5.0 gnmt 1541782461.993925571 (train.py:443) train_epoch: 1
9: Sampler for epoch 1 uses seed 3386440794
4: Sampler for epoch 1 uses seed 3386440794
11: Sampler for epoch 1 uses seed 3386440794
6: Sampler for epoch 1 uses seed 3386440794
2: Sampler for epoch 1 uses seed 3386440794
5: Sampler for epoch 1 uses seed 3386440794
3: Sampler for epoch 1 uses seed 3386440794
15: Sampler for epoch 1 uses seed 3386440794
13: Sampler for epoch 1 uses seed 3386440794
1: Sampler for epoch 1 uses seed 3386440794
8: Sampler for epoch 1 uses seed 3386440794
10: Sampler for epoch 1 uses seed 3386440794
12: Sampler for epoch 1 uses seed 3386440794
7: Sampler for epoch 1 uses seed 3386440794
14: Sampler for epoch 1 uses seed 3386440794
:::MLPv0.5.0 gnmt 1541782462.341378927 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 1 uses seed 3386440794
:::MLPv0.5.0 gnmt 1541782462.505677462 (seq2seq/data/sampler.py:66) input_shard: 81920
8: TRAIN [1][0/3416]	Time 3.777 (0.000)	Data 3.49199 (0.00000)	Tok/s 881 (0)	Loss/tok 3.3895 (0.0000)	Learning Rate [0.00125]
5: TRAIN [1][0/3416]	Time 3.777 (0.000)	Data 2.94174 (0.00000)	Tok/s 881 (0)	Loss/tok 3.5885 (0.0000)	Learning Rate [0.00125]
10: TRAIN [1][0/3416]	Time 3.777 (0.000)	Data 3.64393 (0.00000)	Tok/s 881 (0)	Loss/tok 3.2693 (0.0000)	Learning Rate [0.00125]
12: TRAIN [1][0/3416]	Time 3.777 (0.000)	Data 2.56048 (0.00000)	Tok/s 881 (0)	Loss/tok 3.4465 (0.0000)	Learning Rate [0.00125]
4: TRAIN [1][0/3416]	Time 3.777 (0.000)	Data 2.96824 (0.00000)	Tok/s 881 (0)	Loss/tok 3.6572 (0.0000)	Learning Rate [0.00125]
14: TRAIN [1][0/3416]	Time 3.777 (0.000)	Data 2.19691 (0.00000)	Tok/s 881 (0)	Loss/tok 3.4421 (0.0000)	Learning Rate [0.00125]
1: TRAIN [1][0/3416]	Time 3.777 (0.000)	Data 3.66973 (0.00000)	Tok/s 881 (0)	Loss/tok 3.4678 (0.0000)	Learning Rate [0.00125]
11: TRAIN [1][0/3416]	Time 3.777 (0.000)	Data 2.99080 (0.00000)	Tok/s 881 (0)	Loss/tok 3.3887 (0.0000)	Learning Rate [0.00125]
15: TRAIN [1][0/3416]	Time 3.778 (0.000)	Data 3.50448 (0.00000)	Tok/s 881 (0)	Loss/tok 3.3494 (0.0000)	Learning Rate [0.00125]
0: TRAIN [1][0/3416]	Time 3.778 (0.000)	Data 3.71536 (0.00000)	Tok/s 881 (0)	Loss/tok 3.3775 (0.0000)	Learning Rate [0.00125]
2: TRAIN [1][0/3416]	Time 3.778 (0.000)	Data 3.71097 (0.00000)	Tok/s 881 (0)	Loss/tok 3.4686 (0.0000)	Learning Rate [0.00125]
6: TRAIN [1][0/3416]	Time 3.778 (0.000)	Data 3.55013 (0.00000)	Tok/s 881 (0)	Loss/tok 3.5249 (0.0000)	Learning Rate [0.00125]
3: TRAIN [1][0/3416]	Time 3.778 (0.000)	Data 3.20268 (0.00000)	Tok/s 881 (0)	Loss/tok 3.3511 (0.0000)	Learning Rate [0.00125]
13: TRAIN [1][0/3416]	Time 3.778 (0.000)	Data 3.34372 (0.00000)	Tok/s 881 (0)	Loss/tok 3.4101 (0.0000)	Learning Rate [0.00125]
7: TRAIN [1][0/3416]	Time 3.781 (0.000)	Data 3.09399 (0.00000)	Tok/s 880 (0)	Loss/tok 3.4415 (0.0000)	Learning Rate [0.00125]
9: TRAIN [1][0/3416]	Time 3.782 (0.000)	Data 3.07046 (0.00000)	Tok/s 880 (0)	Loss/tok 3.4623 (0.0000)	Learning Rate [0.00125]
5: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00103 (0.00103)	Tok/s 56931 (56876)	Loss/tok 3.4673 (3.4119)	Learning Rate [0.00125]
4: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00104 (0.00079)	Tok/s 56963 (56836)	Loss/tok 3.5308 (3.4349)	Learning Rate [0.00125]
9: TRAIN [1][10/3416]	Time 0.070 (0.065)	Data 0.00119 (0.00106)	Tok/s 57419 (57374)	Loss/tok 3.5322 (3.4463)	Learning Rate [0.00125]
10: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00107 (0.00088)	Tok/s 57751 (57160)	Loss/tok 3.5780 (3.4563)	Learning Rate [0.00125]
3: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00104 (0.00092)	Tok/s 56830 (56685)	Loss/tok 3.5754 (3.4657)	Learning Rate [0.00125]
11: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00125 (0.00094)	Tok/s 57814 (57198)	Loss/tok 3.5707 (3.4172)	Learning Rate [0.00125]
2: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00105 (0.00107)	Tok/s 56790 (56542)	Loss/tok 3.5201 (3.3571)	Learning Rate [0.00125]
14: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00112 (0.00097)	Tok/s 57584 (57611)	Loss/tok 3.5380 (3.3918)	Learning Rate [0.00125]
7: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00108 (0.00097)	Tok/s 57002 (57223)	Loss/tok 3.5300 (3.4485)	Learning Rate [0.00125]
12: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00109 (0.00111)	Tok/s 57635 (57250)	Loss/tok 3.4938 (3.4077)	Learning Rate [0.00125]
1: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00117 (0.00122)	Tok/s 56742 (56463)	Loss/tok 3.8254 (3.4232)	Learning Rate [0.00125]
13: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00108 (0.00109)	Tok/s 57577 (57444)	Loss/tok 3.5783 (3.4474)	Learning Rate [0.00125]
0: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00102 (0.00094)	Tok/s 56655 (56407)	Loss/tok 3.6334 (3.4401)	Learning Rate [0.00125]
15: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00103 (0.00101)	Tok/s 57508 (57785)	Loss/tok 3.4907 (3.4477)	Learning Rate [0.00125]
6: TRAIN [1][10/3416]	Time 0.070 (0.066)	Data 0.00109 (0.00090)	Tok/s 56307 (56935)	Loss/tok 3.6995 (3.4351)	Learning Rate [0.00125]
8: TRAIN [1][10/3416]	Time 0.071 (0.066)	Data 0.00112 (0.00107)	Tok/s 56254 (56912)	Loss/tok 3.4374 (3.4047)	Learning Rate [0.00125]
4: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00096 (0.00087)	Tok/s 53709 (54106)	Loss/tok 3.5004 (3.4150)	Learning Rate [0.00125]
3: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00101 (0.00095)	Tok/s 53717 (53975)	Loss/tok 3.4604 (3.4331)	Learning Rate [0.00125]
1: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00106 (0.00111)	Tok/s 53723 (53609)	Loss/tok 3.3587 (3.4011)	Learning Rate [0.00125]
6: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00096 (0.00102)	Tok/s 53563 (54408)	Loss/tok 3.4380 (3.3591)	Learning Rate [0.00125]
7: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00091 (0.00096)	Tok/s 53426 (54540)	Loss/tok 3.3752 (3.4003)	Learning Rate [0.00125]
0: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00095 (0.00094)	Tok/s 52827 (53427)	Loss/tok 3.6023 (3.4367)	Learning Rate [0.00125]
5: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00096 (0.00100)	Tok/s 53565 (54281)	Loss/tok 3.5884 (3.4125)	Learning Rate [0.00125]
2: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00097 (0.00105)	Tok/s 53741 (53778)	Loss/tok 3.4709 (3.3909)	Learning Rate [0.00125]
15: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00091 (0.00095)	Tok/s 53710 (55363)	Loss/tok 3.4354 (3.4163)	Learning Rate [0.00125]
8: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00105 (0.00108)	Tok/s 53440 (54498)	Loss/tok 3.1702 (3.4013)	Learning Rate [0.00125]
9: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00093 (0.00101)	Tok/s 53333 (54728)	Loss/tok 3.3167 (3.3846)	Learning Rate [0.00125]
14: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00098 (0.00097)	Tok/s 53658 (55184)	Loss/tok 3.4745 (3.3938)	Learning Rate [0.00125]
13: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00099 (0.00106)	Tok/s 53592 (55020)	Loss/tok 3.4330 (3.4278)	Learning Rate [0.00125]
11: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00111 (0.00100)	Tok/s 53765 (54726)	Loss/tok 3.3254 (3.3863)	Learning Rate [0.00125]
12: TRAIN [1][20/3416]	Time 0.062 (0.062)	Data 0.00107 (0.00108)	Tok/s 53544 (54812)	Loss/tok 3.3875 (3.3400)	Learning Rate [0.00125]
10: TRAIN [1][20/3416]	Time 0.063 (0.062)	Data 0.00101 (0.00094)	Tok/s 53206 (54670)	Loss/tok 3.5406 (3.3966)	Learning Rate [0.00125]
5: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
13: TRAIN [1][30/3416]	Time 0.053 (0.060)	Data 0.00097 (0.00105)	Tok/s 53192 (54243)	Loss/tok 3.1971 (3.3973)	Learning Rate [0.00125]
14: TRAIN [1][30/3416]	Time 0.053 (0.060)	Data 0.00106 (0.00097)	Tok/s 53155 (54429)	Loss/tok 3.0884 (3.3749)	Learning Rate [0.00125]
15: TRAIN [1][30/3416]	Time 0.053 (0.060)	Data 0.00090 (0.00093)	Tok/s 53043 (54592)	Loss/tok 3.1907 (3.3869)	Learning Rate [0.00125]
12: TRAIN [1][30/3416]	Time 0.053 (0.060)	Data 0.00101 (0.00104)	Tok/s 52919 (54090)	Loss/tok 3.4925 (3.3785)	Learning Rate [0.00125]
10: TRAIN [1][30/3416]	Time 0.053 (0.060)	Data 0.00090 (0.00096)	Tok/s 52879 (53910)	Loss/tok 3.7498 (3.3900)	Learning Rate [0.00125]
0: TRAIN [1][30/3416]	Time 0.053 (0.060)	Data 0.00101 (0.00093)	Tok/s 51721 (52384)	Loss/tok 3.6050 (3.4164)	Learning Rate [0.00125]
11: TRAIN [1][30/3416]	Time 0.053 (0.060)	Data 0.00099 (0.00099)	Tok/s 52838 (53940)	Loss/tok 3.3416 (3.3904)	Learning Rate [0.00125]
1: TRAIN [1][30/3416]	Time 0.053 (0.060)	Data 0.00111 (0.00106)	Tok/s 51590 (52577)	Loss/tok 3.2017 (3.3711)	Learning Rate [0.00125]
2: TRAIN [1][30/3416]	Time 0.053 (0.060)	Data 0.00098 (0.00102)	Tok/s 51499 (52805)	Loss/tok 3.3533 (3.4074)	Learning Rate [0.00125]
9: TRAIN [1][30/3416]	Time 0.054 (0.060)	Data 0.00094 (0.00098)	Tok/s 52617 (53901)	Loss/tok 3.2000 (3.3808)	Learning Rate [0.00125]
3: TRAIN [1][30/3416]	Time 0.054 (0.060)	Data 0.00106 (0.00096)	Tok/s 51356 (52983)	Loss/tok 3.1155 (3.3955)	Learning Rate [0.00125]
8: TRAIN [1][30/3416]	Time 0.054 (0.060)	Data 0.00100 (0.00107)	Tok/s 52517 (53686)	Loss/tok 3.5231 (3.4048)	Learning Rate [0.00125]
4: TRAIN [1][30/3416]	Time 0.054 (0.060)	Data 0.00100 (0.00089)	Tok/s 51793 (53154)	Loss/tok 3.5098 (3.3788)	Learning Rate [0.00125]
7: TRAIN [1][30/3416]	Time 0.054 (0.060)	Data 0.00098 (0.00095)	Tok/s 52428 (53622)	Loss/tok 3.3638 (3.3951)	Learning Rate [0.00125]
5: TRAIN [1][30/3416]	Time 0.054 (0.060)	Data 0.00095 (0.00100)	Tok/s 52382 (53381)	Loss/tok 3.3027 (3.4023)	Learning Rate [0.00125]
6: TRAIN [1][30/3416]	Time 0.054 (0.060)	Data 0.00110 (0.00105)	Tok/s 52326 (53505)	Loss/tok 3.2840 (3.3512)	Learning Rate [0.00125]
12: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00096 (0.00102)	Tok/s 62938 (55226)	Loss/tok 3.6372 (3.4142)	Learning Rate [0.00125]
13: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00098 (0.00103)	Tok/s 62930 (55372)	Loss/tok 3.3251 (3.4065)	Learning Rate [0.00125]
11: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00089 (0.00098)	Tok/s 62937 (55073)	Loss/tok 3.5490 (3.4272)	Learning Rate [0.00125]
14: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00089 (0.00096)	Tok/s 63535 (55548)	Loss/tok 3.5437 (3.4151)	Learning Rate [0.00125]
15: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00077 (0.00091)	Tok/s 63729 (55675)	Loss/tok 3.6532 (3.4297)	Learning Rate [0.00125]
10: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00097 (0.00096)	Tok/s 62939 (55047)	Loss/tok 3.5311 (3.4220)	Learning Rate [0.00125]
8: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00103 (0.00106)	Tok/s 62945 (54860)	Loss/tok 3.4072 (3.4234)	Learning Rate [0.00125]
1: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00091 (0.00103)	Tok/s 62873 (53957)	Loss/tok 3.4260 (3.3851)	Learning Rate [0.00125]
9: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00100 (0.00098)	Tok/s 62927 (55022)	Loss/tok 3.3950 (3.3882)	Learning Rate [0.00125]
0: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00084 (0.00092)	Tok/s 62780 (53781)	Loss/tok 3.5681 (3.4363)	Learning Rate [0.00125]
2: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00093 (0.00100)	Tok/s 62848 (54133)	Loss/tok 3.6139 (3.4085)	Learning Rate [0.00125]
7: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00093 (0.00094)	Tok/s 62924 (54788)	Loss/tok 3.4310 (3.4176)	Learning Rate [0.00125]
3: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00101 (0.00097)	Tok/s 62848 (54283)	Loss/tok 3.5955 (3.4173)	Learning Rate [0.00125]
4: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00089 (0.00089)	Tok/s 62846 (54424)	Loss/tok 3.4599 (3.3883)	Learning Rate [0.00125]
6: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00096 (0.00105)	Tok/s 62922 (54688)	Loss/tok 3.7335 (3.3632)	Learning Rate [0.00125]
5: TRAIN [1][40/3416]	Time 0.070 (0.061)	Data 0.00094 (0.00099)	Tok/s 62846 (54593)	Loss/tok 3.7136 (3.4421)	Learning Rate [0.00125]
6: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00101 (0.00105)	Tok/s 32537 (53108)	Loss/tok 2.7461 (3.3717)	Learning Rate [0.00125]
7: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00090 (0.00094)	Tok/s 32395 (53202)	Loss/tok 3.1394 (3.4086)	Learning Rate [0.00125]
4: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00084 (0.00088)	Tok/s 32489 (52851)	Loss/tok 3.1315 (3.3862)	Learning Rate [0.00125]
8: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00101 (0.00105)	Tok/s 32359 (53297)	Loss/tok 2.9919 (3.4074)	Learning Rate [0.00125]
9: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00088 (0.00096)	Tok/s 32337 (53424)	Loss/tok 2.9124 (3.3827)	Learning Rate [0.00125]
5: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00100 (0.00099)	Tok/s 32488 (52999)	Loss/tok 2.8072 (3.4339)	Learning Rate [0.00125]
2: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00094 (0.00099)	Tok/s 32522 (52558)	Loss/tok 3.0568 (3.4048)	Learning Rate [0.00125]
3: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00100 (0.00099)	Tok/s 32464 (52718)	Loss/tok 2.8121 (3.3876)	Learning Rate [0.00125]
10: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00091 (0.00096)	Tok/s 32361 (53441)	Loss/tok 2.9827 (3.4099)	Learning Rate [0.00125]
1: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00092 (0.00103)	Tok/s 32525 (52417)	Loss/tok 3.2072 (3.3720)	Learning Rate [0.00125]
11: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00096 (0.00098)	Tok/s 32368 (53477)	Loss/tok 2.8562 (3.4332)	Learning Rate [0.00125]
15: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00077 (0.00091)	Tok/s 33749 (54052)	Loss/tok 2.9888 (3.4132)	Learning Rate [0.00125]
12: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00094 (0.00101)	Tok/s 32465 (53633)	Loss/tok 2.9839 (3.3985)	Learning Rate [0.00125]
0: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00086 (0.00091)	Tok/s 32450 (52274)	Loss/tok 3.1639 (3.4237)	Learning Rate [0.00125]
14: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00095 (0.00096)	Tok/s 33660 (53948)	Loss/tok 3.0024 (3.3970)	Learning Rate [0.00125]
13: TRAIN [1][50/3416]	Time 0.049 (0.060)	Data 0.00093 (0.00102)	Tok/s 33641 (53804)	Loss/tok 2.7363 (3.3795)	Learning Rate [0.00125]
4: Gradient norm: inf
3: Gradient norm: inf
2: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
6: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
7: Gradient norm: inf
0: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
9: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
13: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
4: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00096 (0.00089)	Tok/s 67049 (54163)	Loss/tok 3.4125 (3.3929)	Learning Rate [0.00125]
5: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00096 (0.00098)	Tok/s 67101 (54287)	Loss/tok 3.4477 (3.4398)	Learning Rate [0.00125]
0: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00084 (0.00091)	Tok/s 66729 (53670)	Loss/tok 3.6068 (3.4084)	Learning Rate [0.00125]
6: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00101 (0.00105)	Tok/s 67039 (54389)	Loss/tok 3.6127 (3.3901)	Learning Rate [0.00125]
3: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00105 (0.00099)	Tok/s 66988 (54047)	Loss/tok 3.6401 (3.3963)	Learning Rate [0.00125]
2: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00100 (0.00098)	Tok/s 66885 (53905)	Loss/tok 3.7186 (3.4133)	Learning Rate [0.00125]
7: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00090 (0.00094)	Tok/s 67496 (54497)	Loss/tok 3.5999 (3.4091)	Learning Rate [0.00125]
1: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00099 (0.00102)	Tok/s 66787 (53787)	Loss/tok 3.5632 (3.3864)	Learning Rate [0.00125]
9: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00087 (0.00095)	Tok/s 67599 (54700)	Loss/tok 3.4720 (3.3846)	Learning Rate [0.00125]
8: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00119 (0.00105)	Tok/s 67708 (54593)	Loss/tok 3.7648 (3.4272)	Learning Rate [0.00125]
10: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00118 (0.00096)	Tok/s 67533 (54746)	Loss/tok 3.4715 (3.4388)	Learning Rate [0.00125]
15: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00089 (0.00090)	Tok/s 67421 (55324)	Loss/tok 3.4566 (3.4097)	Learning Rate [0.00125]
11: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00101 (0.00098)	Tok/s 67442 (54783)	Loss/tok 3.5091 (3.4413)	Learning Rate [0.00125]
14: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00090 (0.00095)	Tok/s 67356 (55205)	Loss/tok 3.4678 (3.3990)	Learning Rate [0.00125]
12: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00102 (0.00100)	Tok/s 67244 (54919)	Loss/tok 3.5290 (3.4053)	Learning Rate [0.00125]
13: TRAIN [1][60/3416]	Time 0.070 (0.060)	Data 0.00102 (0.00101)	Tok/s 67303 (55071)	Loss/tok 3.6184 (3.4040)	Learning Rate [0.00125]
1: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00100 (0.00102)	Tok/s 51360 (52941)	Loss/tok 3.2174 (3.3770)	Learning Rate [0.00125]
0: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00091 (0.00091)	Tok/s 51374 (52833)	Loss/tok 3.2063 (3.4023)	Learning Rate [0.00125]
2: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00095 (0.00098)	Tok/s 51236 (53053)	Loss/tok 3.3821 (3.4105)	Learning Rate [0.00125]
15: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00092 (0.00090)	Tok/s 52492 (54431)	Loss/tok 3.2816 (3.4058)	Learning Rate [0.00125]
3: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00098 (0.00100)	Tok/s 51098 (53178)	Loss/tok 3.2266 (3.3952)	Learning Rate [0.00125]
4: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00087 (0.00089)	Tok/s 51031 (53296)	Loss/tok 3.2571 (3.3891)	Learning Rate [0.00125]
5: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00093 (0.00098)	Tok/s 50925 (53415)	Loss/tok 3.3766 (3.4289)	Learning Rate [0.00125]
13: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00094 (0.00100)	Tok/s 52304 (54179)	Loss/tok 3.4470 (3.4011)	Learning Rate [0.00125]
12: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00090 (0.00099)	Tok/s 52243 (54045)	Loss/tok 3.3916 (3.4009)	Learning Rate [0.00125]
14: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00090 (0.00095)	Tok/s 52401 (54313)	Loss/tok 3.3380 (3.3953)	Learning Rate [0.00125]
10: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00092 (0.00096)	Tok/s 50933 (53853)	Loss/tok 3.5711 (3.4397)	Learning Rate [0.00125]
11: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00094 (0.00098)	Tok/s 51323 (53909)	Loss/tok 3.2029 (3.4256)	Learning Rate [0.00125]
6: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00103 (0.00105)	Tok/s 50822 (53505)	Loss/tok 3.3235 (3.3807)	Learning Rate [0.00125]
7: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00083 (0.00094)	Tok/s 50771 (53623)	Loss/tok 3.3098 (3.4014)	Learning Rate [0.00125]
8: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00102 (0.00104)	Tok/s 50774 (53708)	Loss/tok 3.5235 (3.4194)	Learning Rate [0.00125]
9: TRAIN [1][70/3416]	Time 0.055 (0.060)	Data 0.00090 (0.00095)	Tok/s 50816 (53800)	Loss/tok 3.3757 (3.3859)	Learning Rate [0.00125]
8: TRAIN [1][80/3416]	Time 0.046 (0.060)	Data 0.00097 (0.00103)	Tok/s 48496 (53633)	Loss/tok 3.2499 (3.4116)	Learning Rate [0.00125]
2: TRAIN [1][80/3416]	Time 0.046 (0.060)	Data 0.00091 (0.00097)	Tok/s 48471 (53025)	Loss/tok 3.2285 (3.4118)	Learning Rate [0.00125]
7: TRAIN [1][80/3416]	Time 0.046 (0.059)	Data 0.00084 (0.00093)	Tok/s 48525 (53553)	Loss/tok 3.4073 (3.4024)	Learning Rate [0.00125]
0: TRAIN [1][80/3416]	Time 0.046 (0.060)	Data 0.00083 (0.00090)	Tok/s 48295 (52832)	Loss/tok 3.3907 (3.4011)	Learning Rate [0.00125]
1: TRAIN [1][80/3416]	Time 0.046 (0.060)	Data 0.00100 (0.00102)	Tok/s 48435 (52926)	Loss/tok 3.2353 (3.3787)	Learning Rate [0.00125]
9: TRAIN [1][80/3416]	Time 0.046 (0.059)	Data 0.00088 (0.00094)	Tok/s 48345 (53714)	Loss/tok 3.4634 (3.3932)	Learning Rate [0.00125]
3: TRAIN [1][80/3416]	Time 0.046 (0.060)	Data 0.00090 (0.00100)	Tok/s 48497 (53135)	Loss/tok 3.2687 (3.3986)	Learning Rate [0.00125]
5: TRAIN [1][80/3416]	Time 0.046 (0.060)	Data 0.00089 (0.00098)	Tok/s 48478 (53359)	Loss/tok 3.1693 (3.4164)	Learning Rate [0.00125]
10: TRAIN [1][80/3416]	Time 0.046 (0.060)	Data 0.00089 (0.00095)	Tok/s 48358 (53760)	Loss/tok 3.4766 (3.4384)	Learning Rate [0.00125]
6: TRAIN [1][80/3416]	Time 0.046 (0.060)	Data 0.00095 (0.00106)	Tok/s 48533 (53439)	Loss/tok 3.1496 (3.3898)	Learning Rate [0.00125]
4: TRAIN [1][80/3416]	Time 0.046 (0.060)	Data 0.00086 (0.00089)	Tok/s 48492 (53248)	Loss/tok 3.0949 (3.3948)	Learning Rate [0.00125]
15: TRAIN [1][80/3416]	Time 0.047 (0.060)	Data 0.00096 (0.00091)	Tok/s 49512 (54316)	Loss/tok 3.2498 (3.4078)	Learning Rate [0.00125]
11: TRAIN [1][80/3416]	Time 0.047 (0.060)	Data 0.00088 (0.00097)	Tok/s 49489 (53838)	Loss/tok 3.1975 (3.4365)	Learning Rate [0.00125]
12: TRAIN [1][80/3416]	Time 0.047 (0.060)	Data 0.00094 (0.00098)	Tok/s 49332 (53966)	Loss/tok 3.3269 (3.4054)	Learning Rate [0.00125]
14: TRAIN [1][80/3416]	Time 0.047 (0.060)	Data 0.00095 (0.00094)	Tok/s 49394 (54202)	Loss/tok 3.2586 (3.3925)	Learning Rate [0.00125]
13: TRAIN [1][80/3416]	Time 0.047 (0.060)	Data 0.00096 (0.00100)	Tok/s 49268 (54081)	Loss/tok 3.4238 (3.3992)	Learning Rate [0.00125]
7: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00087 (0.00093)	Tok/s 53616 (53163)	Loss/tok 3.6008 (3.3960)	Learning Rate [0.00125]
8: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00099 (0.00102)	Tok/s 53588 (53233)	Loss/tok 3.3319 (3.3959)	Learning Rate [0.00125]
5: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00099 (0.00097)	Tok/s 53390 (52987)	Loss/tok 3.2915 (3.4106)	Learning Rate [0.00125]
6: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00095 (0.00106)	Tok/s 53470 (53060)	Loss/tok 3.3814 (3.3772)	Learning Rate [0.00125]
9: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00091 (0.00094)	Tok/s 53571 (53305)	Loss/tok 3.3971 (3.3896)	Learning Rate [0.00125]
10: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00098 (0.00095)	Tok/s 53553 (53355)	Loss/tok 3.2915 (3.4253)	Learning Rate [0.00125]
4: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00096 (0.00089)	Tok/s 53268 (52865)	Loss/tok 3.2153 (3.3824)	Learning Rate [0.00125]
11: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00097 (0.00097)	Tok/s 53427 (53442)	Loss/tok 3.4218 (3.4266)	Learning Rate [0.00125]
3: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00094 (0.00099)	Tok/s 53163 (52755)	Loss/tok 3.4640 (3.3846)	Learning Rate [0.00125]
12: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00101 (0.00098)	Tok/s 53334 (53570)	Loss/tok 3.1710 (3.3886)	Learning Rate [0.00125]
2: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00098 (0.00097)	Tok/s 53064 (52647)	Loss/tok 3.6668 (3.4078)	Learning Rate [0.00125]
0: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00086 (0.00090)	Tok/s 51984 (52441)	Loss/tok 3.4013 (3.3976)	Learning Rate [0.00125]
13: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00097 (0.00102)	Tok/s 53219 (53683)	Loss/tok 3.3668 (3.3864)	Learning Rate [0.00125]
1: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00100 (0.00101)	Tok/s 52655 (52536)	Loss/tok 3.6220 (3.3789)	Learning Rate [0.00125]
15: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00091 (0.00090)	Tok/s 53098 (53899)	Loss/tok 3.4800 (3.3941)	Learning Rate [0.00125]
14: TRAIN [1][90/3416]	Time 0.060 (0.059)	Data 0.00092 (0.00094)	Tok/s 53104 (53792)	Loss/tok 3.1759 (3.3826)	Learning Rate [0.00125]
0: TRAIN [1][100/3416]	Time 0.069 (0.059)	Data 0.00085 (0.00090)	Tok/s 63055 (52833)	Loss/tok 3.5784 (3.4135)	Learning Rate [0.00125]
4: TRAIN [1][100/3416]	Time 0.069 (0.059)	Data 0.00090 (0.00090)	Tok/s 63676 (53230)	Loss/tok 3.6838 (3.3919)	Learning Rate [0.00125]
2: TRAIN [1][100/3416]	Time 0.069 (0.059)	Data 0.00094 (0.00097)	Tok/s 63061 (53018)	Loss/tok 3.4270 (3.4096)	Learning Rate [0.00125]
1: TRAIN [1][100/3416]	Time 0.069 (0.059)	Data 0.00097 (0.00101)	Tok/s 62888 (52917)	Loss/tok 3.5386 (3.3826)	Learning Rate [0.00125]
5: TRAIN [1][100/3416]	Time 0.069 (0.059)	Data 0.00097 (0.00097)	Tok/s 63568 (53340)	Loss/tok 3.2918 (3.4096)	Learning Rate [0.00125]
3: TRAIN [1][100/3416]	Time 0.069 (0.059)	Data 0.00098 (0.00100)	Tok/s 63756 (53131)	Loss/tok 3.5607 (3.3900)	Learning Rate [0.00125]
9: TRAIN [1][100/3416]	Time 0.069 (0.059)	Data 0.00094 (0.00094)	Tok/s 63644 (53648)	Loss/tok 3.4500 (3.3950)	Learning Rate [0.00125]
15: TRAIN [1][100/3416]	Time 0.069 (0.059)	Data 0.00083 (0.00090)	Tok/s 63823 (54212)	Loss/tok 3.3584 (3.3947)	Learning Rate [0.00125]
10: TRAIN [1][100/3416]	Time 0.069 (0.059)	Data 0.00099 (0.00096)	Tok/s 63660 (53693)	Loss/tok 3.6036 (3.4231)	Learning Rate [0.00125]
14: TRAIN [1][100/3416]	Time 0.069 (0.059)	Data 0.00088 (0.00093)	Tok/s 63795 (54115)	Loss/tok 3.4570 (3.3936)	Learning Rate [0.00125]
8: TRAIN [1][100/3416]	Time 0.070 (0.059)	Data 0.00103 (0.00101)	Tok/s 63528 (53582)	Loss/tok 3.6097 (3.4040)	Learning Rate [0.00125]
7: TRAIN [1][100/3416]	Time 0.070 (0.059)	Data 0.00091 (0.00093)	Tok/s 63501 (53519)	Loss/tok 3.4217 (3.4033)	Learning Rate [0.00125]
12: TRAIN [1][100/3416]	Time 0.069 (0.059)	Data 0.00091 (0.00098)	Tok/s 63628 (53895)	Loss/tok 3.4236 (3.3922)	Learning Rate [0.00125]
6: TRAIN [1][100/3416]	Time 0.070 (0.059)	Data 0.00100 (0.00106)	Tok/s 63488 (53415)	Loss/tok 3.5512 (3.3829)	Learning Rate [0.00125]
11: TRAIN [1][100/3416]	Time 0.069 (0.059)	Data 0.00094 (0.00097)	Tok/s 63599 (53777)	Loss/tok 3.5214 (3.4273)	Learning Rate [0.00125]
13: TRAIN [1][100/3416]	Time 0.069 (0.059)	Data 0.00090 (0.00102)	Tok/s 63765 (54008)	Loss/tok 3.4164 (3.3917)	Learning Rate [0.00125]
2: TRAIN [1][110/3416]	Time 0.046 (0.059)	Data 0.00086 (0.00096)	Tok/s 47664 (52849)	Loss/tok 3.0121 (3.4097)	Learning Rate [0.00125]
5: TRAIN [1][110/3416]	Time 0.046 (0.059)	Data 0.00093 (0.00097)	Tok/s 47822 (53141)	Loss/tok 2.9724 (3.4059)	Learning Rate [0.00125]
3: TRAIN [1][110/3416]	Time 0.046 (0.059)	Data 0.00090 (0.00099)	Tok/s 47736 (52951)	Loss/tok 3.3357 (3.3875)	Learning Rate [0.00125]
1: TRAIN [1][110/3416]	Time 0.046 (0.059)	Data 0.00099 (0.00101)	Tok/s 47522 (52750)	Loss/tok 3.4221 (3.3738)	Learning Rate [0.00125]
0: TRAIN [1][110/3416]	Time 0.046 (0.059)	Data 0.00084 (0.00090)	Tok/s 47394 (52671)	Loss/tok 3.2842 (3.4114)	Learning Rate [0.00125]
6: TRAIN [1][110/3416]	Time 0.045 (0.059)	Data 0.00090 (0.00105)	Tok/s 47867 (53214)	Loss/tok 3.3310 (3.3823)	Learning Rate [0.00125]
7: TRAIN [1][110/3416]	Time 0.045 (0.059)	Data 0.00080 (0.00093)	Tok/s 47852 (53323)	Loss/tok 3.2531 (3.4005)	Learning Rate [0.00125]
14: TRAIN [1][110/3416]	Time 0.046 (0.059)	Data 0.00089 (0.00093)	Tok/s 47447 (53906)	Loss/tok 3.3160 (3.3957)	Learning Rate [0.00125]
8: TRAIN [1][110/3416]	Time 0.046 (0.059)	Data 0.00097 (0.00101)	Tok/s 47796 (53384)	Loss/tok 3.2344 (3.3961)	Learning Rate [0.00125]
9: TRAIN [1][110/3416]	Time 0.046 (0.059)	Data 0.00082 (0.00094)	Tok/s 47734 (53443)	Loss/tok 3.4232 (3.3914)	Learning Rate [0.00125]
4: TRAIN [1][110/3416]	Time 0.045 (0.059)	Data 0.00089 (0.00090)	Tok/s 47931 (53039)	Loss/tok 3.3713 (3.3907)	Learning Rate [0.00125]
15: TRAIN [1][110/3416]	Time 0.046 (0.059)	Data 0.00088 (0.00090)	Tok/s 47417 (53998)	Loss/tok 3.3969 (3.3961)	Learning Rate [0.00125]
11: TRAIN [1][110/3416]	Time 0.046 (0.059)	Data 0.00088 (0.00097)	Tok/s 47576 (53573)	Loss/tok 3.1955 (3.4205)	Learning Rate [0.00125]
13: TRAIN [1][110/3416]	Time 0.046 (0.059)	Data 0.00100 (0.00101)	Tok/s 47412 (53784)	Loss/tok 3.4180 (3.3929)	Learning Rate [0.00125]
10: TRAIN [1][110/3416]	Time 0.045 (0.059)	Data 0.00144 (0.00097)	Tok/s 48113 (53495)	Loss/tok 3.1285 (3.4294)	Learning Rate [0.00125]
12: TRAIN [1][110/3416]	Time 0.046 (0.059)	Data 0.00092 (0.00098)	Tok/s 47298 (53679)	Loss/tok 2.9472 (3.3909)	Learning Rate [0.00125]
14: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00101 (0.00093)	Tok/s 50997 (53349)	Loss/tok 3.1607 (3.3958)	Learning Rate [0.00125]
13: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00107 (0.00101)	Tok/s 50849 (53226)	Loss/tok 3.3318 (3.3913)	Learning Rate [0.00125]
12: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00105 (0.00098)	Tok/s 50660 (53117)	Loss/tok 3.4899 (3.3930)	Learning Rate [0.00125]
15: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00090 (0.00090)	Tok/s 50763 (53434)	Loss/tok 3.1350 (3.3869)	Learning Rate [0.00125]
11: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00121 (0.00098)	Tok/s 50559 (53001)	Loss/tok 3.7014 (3.4140)	Learning Rate [0.00125]
10: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00102 (0.00097)	Tok/s 50600 (52926)	Loss/tok 3.1809 (3.4242)	Learning Rate [0.00125]
0: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00095 (0.00090)	Tok/s 49553 (52117)	Loss/tok 3.2883 (3.4065)	Learning Rate [0.00125]
3: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00097 (0.00099)	Tok/s 49609 (52384)	Loss/tok 3.0360 (3.3780)	Learning Rate [0.00125]
9: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00104 (0.00094)	Tok/s 50601 (52876)	Loss/tok 3.1929 (3.3891)	Learning Rate [0.00125]
1: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00105 (0.00101)	Tok/s 49547 (52198)	Loss/tok 3.2971 (3.3711)	Learning Rate [0.00125]
8: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00110 (0.00101)	Tok/s 50600 (52818)	Loss/tok 3.3081 (3.3881)	Learning Rate [0.00125]
2: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00096 (0.00097)	Tok/s 49529 (52289)	Loss/tok 3.4336 (3.4069)	Learning Rate [0.00125]
7: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00096 (0.00093)	Tok/s 50593 (52757)	Loss/tok 3.6549 (3.3944)	Learning Rate [0.00125]
4: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00097 (0.00090)	Tok/s 49372 (52465)	Loss/tok 3.3675 (3.3880)	Learning Rate [0.00125]
6: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00098 (0.00105)	Tok/s 50141 (52644)	Loss/tok 3.2439 (3.3774)	Learning Rate [0.00125]
5: TRAIN [1][120/3416]	Time 0.049 (0.059)	Data 0.00099 (0.00097)	Tok/s 49361 (52557)	Loss/tok 3.4342 (3.4031)	Learning Rate [0.00125]
2: TRAIN [1][130/3416]	Time 0.061 (0.059)	Data 0.00107 (0.00097)	Tok/s 54377 (52318)	Loss/tok 3.4487 (3.4035)	Learning Rate [0.00125]
3: TRAIN [1][130/3416]	Time 0.061 (0.059)	Data 0.00107 (0.00099)	Tok/s 54311 (52404)	Loss/tok 3.3075 (3.3748)	Learning Rate [0.00125]
4: TRAIN [1][130/3416]	Time 0.061 (0.059)	Data 0.00086 (0.00090)	Tok/s 54196 (52482)	Loss/tok 3.4007 (3.3952)	Learning Rate [0.00125]
0: TRAIN [1][130/3416]	Time 0.061 (0.059)	Data 0.00100 (0.00090)	Tok/s 53677 (52125)	Loss/tok 3.5543 (3.4057)	Learning Rate [0.00125]
15: TRAIN [1][130/3416]	Time 0.061 (0.059)	Data 0.00098 (0.00090)	Tok/s 54365 (53415)	Loss/tok 3.6632 (3.3891)	Learning Rate [0.00125]
5: TRAIN [1][130/3416]	Time 0.062 (0.059)	Data 0.00101 (0.00098)	Tok/s 54071 (52579)	Loss/tok 3.3410 (3.4027)	Learning Rate [0.00125]
14: TRAIN [1][130/3416]	Time 0.061 (0.059)	Data 0.00087 (0.00093)	Tok/s 54322 (53334)	Loss/tok 3.3232 (3.3996)	Learning Rate [0.00125]
12: TRAIN [1][130/3416]	Time 0.061 (0.059)	Data 0.00101 (0.00098)	Tok/s 54189 (53118)	Loss/tok 3.5567 (3.3947)	Learning Rate [0.00125]
6: TRAIN [1][130/3416]	Time 0.062 (0.059)	Data 0.00102 (0.00105)	Tok/s 53984 (52660)	Loss/tok 3.5356 (3.3822)	Learning Rate [0.00125]
13: TRAIN [1][130/3416]	Time 0.061 (0.059)	Data 0.00095 (0.00101)	Tok/s 54200 (53221)	Loss/tok 3.3518 (3.3926)	Learning Rate [0.00125]
11: TRAIN [1][130/3416]	Time 0.062 (0.059)	Data 0.00099 (0.00101)	Tok/s 54103 (53001)	Loss/tok 3.2146 (3.4073)	Learning Rate [0.00125]
10: TRAIN [1][130/3416]	Time 0.062 (0.059)	Data 0.00103 (0.00097)	Tok/s 53908 (52927)	Loss/tok 3.5012 (3.4241)	Learning Rate [0.00125]
8: TRAIN [1][130/3416]	Time 0.062 (0.059)	Data 0.00102 (0.00101)	Tok/s 53858 (52829)	Loss/tok 3.5060 (3.3922)	Learning Rate [0.00125]
7: TRAIN [1][130/3416]	Time 0.062 (0.059)	Data 0.00092 (0.00093)	Tok/s 53901 (52765)	Loss/tok 3.3160 (3.4036)	Learning Rate [0.00125]
1: TRAIN [1][130/3416]	Time 0.061 (0.059)	Data 0.00110 (0.00101)	Tok/s 54417 (52217)	Loss/tok 3.6481 (3.3740)	Learning Rate [0.00125]
9: TRAIN [1][130/3416]	Time 0.062 (0.059)	Data 0.00124 (0.00094)	Tok/s 53902 (52875)	Loss/tok 3.4547 (3.3925)	Learning Rate [0.00125]
7: TRAIN [1][140/3416]	Time 0.058 (0.059)	Data 0.00092 (0.00093)	Tok/s 51695 (53521)	Loss/tok 3.1643 (3.4063)	Learning Rate [0.00125]
5: TRAIN [1][140/3416]	Time 0.058 (0.059)	Data 0.00093 (0.00097)	Tok/s 51754 (53326)	Loss/tok 3.3857 (3.4124)	Learning Rate [0.00125]
6: TRAIN [1][140/3416]	Time 0.058 (0.059)	Data 0.00113 (0.00105)	Tok/s 51758 (53412)	Loss/tok 3.4087 (3.3897)	Learning Rate [0.00125]
4: TRAIN [1][140/3416]	Time 0.058 (0.059)	Data 0.00094 (0.00090)	Tok/s 51757 (53233)	Loss/tok 3.5336 (3.3931)	Learning Rate [0.00125]
8: TRAIN [1][140/3416]	Time 0.058 (0.059)	Data 0.00102 (0.00101)	Tok/s 51560 (53579)	Loss/tok 3.2307 (3.3974)	Learning Rate [0.00125]
2: TRAIN [1][140/3416]	Time 0.058 (0.059)	Data 0.00103 (0.00097)	Tok/s 51643 (53059)	Loss/tok 3.4398 (3.4087)	Learning Rate [0.00125]
9: TRAIN [1][140/3416]	Time 0.058 (0.059)	Data 0.00098 (0.00094)	Tok/s 51474 (53630)	Loss/tok 3.6428 (3.4016)	Learning Rate [0.00125]
3: TRAIN [1][140/3416]	Time 0.058 (0.059)	Data 0.00109 (0.00100)	Tok/s 51698 (53154)	Loss/tok 3.0498 (3.3698)	Learning Rate [0.00125]
10: TRAIN [1][140/3416]	Time 0.059 (0.059)	Data 0.00104 (0.00097)	Tok/s 51328 (53682)	Loss/tok 3.2590 (3.4174)	Learning Rate [0.00125]
1: TRAIN [1][140/3416]	Time 0.058 (0.059)	Data 0.00095 (0.00101)	Tok/s 51515 (52971)	Loss/tok 3.3896 (3.3736)	Learning Rate [0.00125]
12: TRAIN [1][140/3416]	Time 0.059 (0.059)	Data 0.00089 (0.00097)	Tok/s 51230 (53867)	Loss/tok 3.4703 (3.4048)	Learning Rate [0.00125]
11: TRAIN [1][140/3416]	Time 0.059 (0.059)	Data 0.00103 (0.00101)	Tok/s 51261 (53750)	Loss/tok 3.4580 (3.4065)	Learning Rate [0.00125]
0: TRAIN [1][140/3416]	Time 0.059 (0.059)	Data 0.00095 (0.00090)	Tok/s 51414 (52876)	Loss/tok 3.2649 (3.4220)	Learning Rate [0.00125]
13: TRAIN [1][140/3416]	Time 0.059 (0.059)	Data 0.00105 (0.00101)	Tok/s 51168 (53967)	Loss/tok 3.6195 (3.3939)	Learning Rate [0.00125]
14: TRAIN [1][140/3416]	Time 0.059 (0.059)	Data 0.00095 (0.00093)	Tok/s 51244 (54078)	Loss/tok 3.5182 (3.4018)	Learning Rate [0.00125]
15: TRAIN [1][140/3416]	Time 0.059 (0.059)	Data 0.00093 (0.00090)	Tok/s 51291 (54166)	Loss/tok 3.3493 (3.3827)	Learning Rate [0.00125]
2: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00090 (0.00097)	Tok/s 41222 (53492)	Loss/tok 3.5055 (3.4105)	Learning Rate [0.00125]
1: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00093 (0.00100)	Tok/s 41149 (53409)	Loss/tok 3.4423 (3.3786)	Learning Rate [0.00125]
0: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00086 (0.00090)	Tok/s 41052 (53316)	Loss/tok 3.2099 (3.4193)	Learning Rate [0.00125]
3: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00097 (0.00100)	Tok/s 41256 (53597)	Loss/tok 3.3983 (3.3707)	Learning Rate [0.00125]
4: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00085 (0.00089)	Tok/s 41211 (53683)	Loss/tok 3.2284 (3.3903)	Learning Rate [0.00125]
15: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00088 (0.00090)	Tok/s 42272 (54629)	Loss/tok 3.1728 (3.3809)	Learning Rate [0.00125]
5: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00085 (0.00097)	Tok/s 41237 (53769)	Loss/tok 3.2867 (3.4050)	Learning Rate [0.00125]
14: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00087 (0.00093)	Tok/s 42306 (54533)	Loss/tok 3.1304 (3.3970)	Learning Rate [0.00125]
13: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00100 (0.00101)	Tok/s 42277 (54420)	Loss/tok 3.1723 (3.3922)	Learning Rate [0.00125]
6: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00094 (0.00105)	Tok/s 41217 (53846)	Loss/tok 2.9510 (3.3908)	Learning Rate [0.00125]
12: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00091 (0.00097)	Tok/s 41568 (54302)	Loss/tok 2.9786 (3.3981)	Learning Rate [0.00125]
11: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00093 (0.00100)	Tok/s 40949 (54184)	Loss/tok 2.9499 (3.4036)	Learning Rate [0.00125]
8: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00094 (0.00101)	Tok/s 41091 (54010)	Loss/tok 3.3821 (3.3930)	Learning Rate [0.00125]
10: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00091 (0.00097)	Tok/s 40960 (54116)	Loss/tok 3.3215 (3.4121)	Learning Rate [0.00125]
7: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00084 (0.00093)	Tok/s 41143 (53955)	Loss/tok 2.9734 (3.3991)	Learning Rate [0.00125]
9: TRAIN [1][150/3416]	Time 0.048 (0.059)	Data 0.00094 (0.00094)	Tok/s 41013 (54059)	Loss/tok 3.4006 (3.4008)	Learning Rate [0.00125]
4: TRAIN [1][160/3416]	Time 0.070 (0.059)	Data 0.00087 (0.00089)	Tok/s 64589 (53499)	Loss/tok 3.4541 (3.3860)	Learning Rate [0.00125]
2: TRAIN [1][160/3416]	Time 0.070 (0.059)	Data 0.00098 (0.00097)	Tok/s 64626 (53319)	Loss/tok 3.6580 (3.4109)	Learning Rate [0.00125]
3: TRAIN [1][160/3416]	Time 0.070 (0.059)	Data 0.00099 (0.00100)	Tok/s 64575 (53418)	Loss/tok 3.3659 (3.3727)	Learning Rate [0.00125]
1: TRAIN [1][160/3416]	Time 0.070 (0.059)	Data 0.00099 (0.00100)	Tok/s 64652 (53241)	Loss/tok 3.6837 (3.3775)	Learning Rate [0.00125]
7: TRAIN [1][160/3416]	Time 0.071 (0.059)	Data 0.00093 (0.00093)	Tok/s 64302 (53788)	Loss/tok 3.5987 (3.3967)	Learning Rate [0.00125]
6: TRAIN [1][160/3416]	Time 0.071 (0.059)	Data 0.00108 (0.00105)	Tok/s 64348 (53681)	Loss/tok 3.4617 (3.3916)	Learning Rate [0.00125]
0: TRAIN [1][160/3416]	Time 0.070 (0.059)	Data 0.00090 (0.00090)	Tok/s 64582 (53153)	Loss/tok 3.8221 (3.4140)	Learning Rate [0.00125]
5: TRAIN [1][160/3416]	Time 0.071 (0.059)	Data 0.00101 (0.00097)	Tok/s 64431 (53597)	Loss/tok 3.5170 (3.4062)	Learning Rate [0.00125]
8: TRAIN [1][160/3416]	Time 0.071 (0.059)	Data 0.00098 (0.00101)	Tok/s 64269 (53842)	Loss/tok 3.4460 (3.3923)	Learning Rate [0.00125]
15: TRAIN [1][160/3416]	Time 0.070 (0.059)	Data 0.00097 (0.00090)	Tok/s 65467 (54447)	Loss/tok 3.8523 (3.3850)	Learning Rate [0.00125]
9: TRAIN [1][160/3416]	Time 0.071 (0.059)	Data 0.00090 (0.00094)	Tok/s 64278 (53893)	Loss/tok 3.4027 (3.3979)	Learning Rate [0.00125]
14: TRAIN [1][160/3416]	Time 0.070 (0.059)	Data 0.00091 (0.00092)	Tok/s 65117 (54355)	Loss/tok 3.5039 (3.3982)	Learning Rate [0.00125]
10: TRAIN [1][160/3416]	Time 0.071 (0.059)	Data 0.00099 (0.00097)	Tok/s 64283 (53946)	Loss/tok 3.5191 (3.4073)	Learning Rate [0.00125]
13: TRAIN [1][160/3416]	Time 0.071 (0.059)	Data 0.00097 (0.00101)	Tok/s 64431 (54239)	Loss/tok 3.2286 (3.3898)	Learning Rate [0.00125]
12: TRAIN [1][160/3416]	Time 0.071 (0.059)	Data 0.00095 (0.00097)	Tok/s 64305 (54123)	Loss/tok 3.3664 (3.3961)	Learning Rate [0.00125]
11: TRAIN [1][160/3416]	Time 0.071 (0.059)	Data 0.00232 (0.00101)	Tok/s 64312 (54009)	Loss/tok 3.3700 (3.4043)	Learning Rate [0.00125]
5: TRAIN [1][170/3416]	Time 0.052 (0.059)	Data 0.00091 (0.00097)	Tok/s 51634 (54094)	Loss/tok 3.4469 (3.4061)	Learning Rate [0.00125]
4: TRAIN [1][170/3416]	Time 0.052 (0.059)	Data 0.00092 (0.00089)	Tok/s 51573 (53995)	Loss/tok 3.3252 (3.3849)	Learning Rate [0.00125]
6: TRAIN [1][170/3416]	Time 0.052 (0.059)	Data 0.00102 (0.00105)	Tok/s 51634 (54179)	Loss/tok 3.2247 (3.3922)	Learning Rate [0.00125]
3: TRAIN [1][170/3416]	Time 0.052 (0.059)	Data 0.00100 (0.00100)	Tok/s 51444 (53912)	Loss/tok 3.1742 (3.3756)	Learning Rate [0.00125]
2: TRAIN [1][170/3416]	Time 0.052 (0.059)	Data 0.00099 (0.00098)	Tok/s 51356 (53815)	Loss/tok 3.5580 (3.4119)	Learning Rate [0.00125]
8: TRAIN [1][170/3416]	Time 0.052 (0.059)	Data 0.00109 (0.00101)	Tok/s 51568 (54347)	Loss/tok 3.2701 (3.3930)	Learning Rate [0.00125]
1: TRAIN [1][170/3416]	Time 0.052 (0.059)	Data 0.00109 (0.00100)	Tok/s 51271 (53742)	Loss/tok 3.4550 (3.3745)	Learning Rate [0.00125]
9: TRAIN [1][170/3416]	Time 0.052 (0.059)	Data 0.00095 (0.00094)	Tok/s 51363 (54399)	Loss/tok 3.4574 (3.3990)	Learning Rate [0.00125]
10: TRAIN [1][170/3416]	Time 0.052 (0.059)	Data 0.00098 (0.00097)	Tok/s 51300 (54459)	Loss/tok 3.0377 (3.4072)	Learning Rate [0.00125]
11: TRAIN [1][170/3416]	Time 0.053 (0.059)	Data 0.00100 (0.00101)	Tok/s 51187 (54521)	Loss/tok 3.5348 (3.4013)	Learning Rate [0.00125]
15: TRAIN [1][170/3416]	Time 0.053 (0.059)	Data 0.00089 (0.00090)	Tok/s 51038 (54955)	Loss/tok 3.3927 (3.3818)	Learning Rate [0.00125]
14: TRAIN [1][170/3416]	Time 0.053 (0.059)	Data 0.00088 (0.00092)	Tok/s 50957 (54858)	Loss/tok 3.3097 (3.3966)	Learning Rate [0.00125]
13: TRAIN [1][170/3416]	Time 0.053 (0.059)	Data 0.00102 (0.00100)	Tok/s 51010 (54741)	Loss/tok 3.0340 (3.3833)	Learning Rate [0.00125]
12: TRAIN [1][170/3416]	Time 0.053 (0.059)	Data 0.00122 (0.00097)	Tok/s 51020 (54630)	Loss/tok 3.1957 (3.4001)	Learning Rate [0.00125]
7: TRAIN [1][170/3416]	Time 0.053 (0.059)	Data 0.00096 (0.00093)	Tok/s 50690 (54283)	Loss/tok 3.1337 (3.3908)	Learning Rate [0.00125]
0: TRAIN [1][170/3416]	Time 0.053 (0.059)	Data 0.00108 (0.00091)	Tok/s 50344 (53652)	Loss/tok 3.2410 (3.4086)	Learning Rate [0.00125]
11: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00115 (0.00100)	Tok/s 58628 (54408)	Loss/tok 3.4789 (3.4010)	Learning Rate [0.00125]
12: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00087 (0.00097)	Tok/s 58539 (54512)	Loss/tok 3.3074 (3.3969)	Learning Rate [0.00125]
10: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00088 (0.00096)	Tok/s 58611 (54345)	Loss/tok 3.2791 (3.4057)	Learning Rate [0.00125]
8: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00106 (0.00102)	Tok/s 58707 (54238)	Loss/tok 3.4183 (3.3939)	Learning Rate [0.00125]
9: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00088 (0.00094)	Tok/s 58666 (54287)	Loss/tok 3.6873 (3.3974)	Learning Rate [0.00125]
14: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00086 (0.00092)	Tok/s 59369 (54734)	Loss/tok 3.3177 (3.3931)	Learning Rate [0.00125]
7: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00087 (0.00093)	Tok/s 58725 (54182)	Loss/tok 3.4260 (3.3893)	Learning Rate [0.00125]
6: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00095 (0.00104)	Tok/s 58717 (54077)	Loss/tok 3.6707 (3.3907)	Learning Rate [0.00125]
5: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00092 (0.00097)	Tok/s 58676 (53990)	Loss/tok 3.5532 (3.4018)	Learning Rate [0.00125]
15: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00087 (0.00090)	Tok/s 59254 (54830)	Loss/tok 3.4365 (3.3800)	Learning Rate [0.00125]
4: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00087 (0.00089)	Tok/s 58583 (53888)	Loss/tok 3.3963 (3.3850)	Learning Rate [0.00125]
0: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00082 (0.00091)	Tok/s 58301 (53560)	Loss/tok 3.6526 (3.4072)	Learning Rate [0.00125]
2: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00090 (0.00098)	Tok/s 58393 (53709)	Loss/tok 3.8294 (3.4089)	Learning Rate [0.00125]
1: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00096 (0.00099)	Tok/s 58406 (53640)	Loss/tok 3.5672 (3.3756)	Learning Rate [0.00125]
3: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00092 (0.00099)	Tok/s 58511 (53801)	Loss/tok 3.3146 (3.3729)	Learning Rate [0.00125]
13: TRAIN [1][180/3416]	Time 0.068 (0.059)	Data 0.00089 (0.00100)	Tok/s 58686 (54618)	Loss/tok 3.3121 (3.3807)	Learning Rate [0.00125]
9: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
2: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00090 (0.00098)	Tok/s 54174 (53451)	Loss/tok 3.3695 (3.4053)	Learning Rate [0.00125]
3: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00099 (0.00099)	Tok/s 55041 (53543)	Loss/tok 3.4993 (3.3715)	Learning Rate [0.00125]
4: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00079 (0.00089)	Tok/s 55027 (53624)	Loss/tok 3.3196 (3.3836)	Learning Rate [0.00125]
5: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00095 (0.00097)	Tok/s 55014 (53720)	Loss/tok 3.4230 (3.3987)	Learning Rate [0.00125]
1: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00098 (0.00099)	Tok/s 54024 (53383)	Loss/tok 3.4893 (3.3769)	Learning Rate [0.00125]
0: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00088 (0.00091)	Tok/s 54028 (53296)	Loss/tok 3.6326 (3.4082)	Learning Rate [0.00125]
6: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00100 (0.00104)	Tok/s 55040 (53802)	Loss/tok 3.5360 (3.3900)	Learning Rate [0.00125]
15: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00094 (0.00090)	Tok/s 54975 (54561)	Loss/tok 3.4576 (3.3841)	Learning Rate [0.00125]
14: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00086 (0.00092)	Tok/s 55014 (54457)	Loss/tok 3.3099 (3.3914)	Learning Rate [0.00125]
7: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00094 (0.00093)	Tok/s 54994 (53901)	Loss/tok 3.3586 (3.3909)	Learning Rate [0.00125]
8: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00107 (0.00102)	Tok/s 55005 (53953)	Loss/tok 3.7440 (3.3948)	Learning Rate [0.00125]
13: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00099 (0.00100)	Tok/s 54991 (54342)	Loss/tok 3.5908 (3.3810)	Learning Rate [0.00125]
10: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00101 (0.00096)	Tok/s 55029 (54064)	Loss/tok 3.4373 (3.4067)	Learning Rate [0.00125]
12: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00107 (0.00097)	Tok/s 54978 (54234)	Loss/tok 3.5781 (3.3964)	Learning Rate [0.00125]
9: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00090 (0.00093)	Tok/s 55003 (54000)	Loss/tok 3.2775 (3.3965)	Learning Rate [0.00125]
11: TRAIN [1][190/3416]	Time 0.065 (0.059)	Data 0.00096 (0.00100)	Tok/s 54990 (54129)	Loss/tok 3.5882 (3.3998)	Learning Rate [0.00125]
4: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00084 (0.00089)	Tok/s 57078 (53519)	Loss/tok 3.5202 (3.3844)	Learning Rate [0.00125]
3: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00096 (0.00099)	Tok/s 57139 (53440)	Loss/tok 3.3470 (3.3738)	Learning Rate [0.00125]
2: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00091 (0.00098)	Tok/s 57119 (53345)	Loss/tok 3.5210 (3.4072)	Learning Rate [0.00125]
1: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00094 (0.00099)	Tok/s 57171 (53276)	Loss/tok 3.6453 (3.3821)	Learning Rate [0.00125]
6: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00102 (0.00104)	Tok/s 56887 (53695)	Loss/tok 3.6044 (3.3947)	Learning Rate [0.00125]
7: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00098 (0.00093)	Tok/s 56788 (53790)	Loss/tok 3.1957 (3.3914)	Learning Rate [0.00125]
0: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00098 (0.00091)	Tok/s 57029 (53194)	Loss/tok 3.3141 (3.4083)	Learning Rate [0.00125]
8: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00102 (0.00102)	Tok/s 56805 (53849)	Loss/tok 3.5667 (3.3938)	Learning Rate [0.00125]
10: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00096 (0.00096)	Tok/s 56911 (53955)	Loss/tok 3.3666 (3.4097)	Learning Rate [0.00125]
15: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00091 (0.00090)	Tok/s 57134 (54439)	Loss/tok 3.3404 (3.3838)	Learning Rate [0.00125]
14: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00088 (0.00092)	Tok/s 57084 (54336)	Loss/tok 3.5197 (3.3926)	Learning Rate [0.00125]
12: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00093 (0.00097)	Tok/s 56818 (54119)	Loss/tok 3.6647 (3.3975)	Learning Rate [0.00125]
9: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00094 (0.00093)	Tok/s 56807 (53894)	Loss/tok 3.5190 (3.3986)	Learning Rate [0.00125]
11: TRAIN [1][200/3416]	Time 0.065 (0.059)	Data 0.00091 (0.00101)	Tok/s 56846 (54016)	Loss/tok 3.5696 (3.4044)	Learning Rate [0.00125]
5: TRAIN [1][200/3416]	Time 0.066 (0.059)	Data 0.00095 (0.00097)	Tok/s 56246 (53609)	Loss/tok 3.5148 (3.3984)	Learning Rate [0.00125]
13: TRAIN [1][200/3416]	Time 0.066 (0.059)	Data 0.00096 (0.00100)	Tok/s 56203 (54224)	Loss/tok 3.4008 (3.3835)	Learning Rate [0.00125]
0: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00089 (0.00091)	Tok/s 28864 (53067)	Loss/tok 2.9436 (3.4109)	Learning Rate [0.00125]
15: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00080 (0.00090)	Tok/s 31540 (54310)	Loss/tok 3.0349 (3.3814)	Learning Rate [0.00125]
14: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00080 (0.00092)	Tok/s 31460 (54213)	Loss/tok 2.7323 (3.3911)	Learning Rate [0.00125]
1: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00096 (0.00099)	Tok/s 29747 (53154)	Loss/tok 2.7525 (3.3801)	Learning Rate [0.00125]
2: TRAIN [1][210/3416]	Time 0.045 (0.059)	Data 0.00094 (0.00098)	Tok/s 30996 (53229)	Loss/tok 2.7843 (3.4017)	Learning Rate [0.00125]
13: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00093 (0.00100)	Tok/s 30668 (54104)	Loss/tok 2.9524 (3.3792)	Learning Rate [0.00125]
11: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00092 (0.00100)	Tok/s 30079 (53891)	Loss/tok 2.7640 (3.4048)	Learning Rate [0.00125]
3: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00092 (0.00099)	Tok/s 30247 (53326)	Loss/tok 2.7075 (3.3705)	Learning Rate [0.00125]
4: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00082 (0.00089)	Tok/s 30227 (53401)	Loss/tok 2.7793 (3.3838)	Learning Rate [0.00125]
5: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00091 (0.00097)	Tok/s 30260 (53491)	Loss/tok 2.9340 (3.3958)	Learning Rate [0.00125]
9: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00089 (0.00093)	Tok/s 30079 (53769)	Loss/tok 2.7926 (3.3972)	Learning Rate [0.00125]
6: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00095 (0.00105)	Tok/s 30181 (53569)	Loss/tok 2.7943 (3.3933)	Learning Rate [0.00125]
8: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00092 (0.00102)	Tok/s 30092 (53724)	Loss/tok 2.9119 (3.3918)	Learning Rate [0.00125]
7: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00092 (0.00093)	Tok/s 30162 (53661)	Loss/tok 2.8175 (3.3878)	Learning Rate [0.00125]
12: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00116 (0.00097)	Tok/s 30074 (53984)	Loss/tok 2.8663 (3.3978)	Learning Rate [0.00125]
10: TRAIN [1][210/3416]	Time 0.047 (0.059)	Data 0.00110 (0.00096)	Tok/s 30052 (53827)	Loss/tok 2.9683 (3.4072)	Learning Rate [0.00125]
4: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00082 (0.00089)	Tok/s 49877 (53312)	Loss/tok 3.1522 (3.3820)	Learning Rate [0.00125]
3: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00086 (0.00099)	Tok/s 49911 (53237)	Loss/tok 3.2315 (3.3690)	Learning Rate [0.00125]
2: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00089 (0.00098)	Tok/s 49958 (53138)	Loss/tok 3.5508 (3.4029)	Learning Rate [0.00125]
5: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00088 (0.00097)	Tok/s 49777 (53411)	Loss/tok 3.4082 (3.3972)	Learning Rate [0.00125]
1: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00096 (0.00099)	Tok/s 49934 (53051)	Loss/tok 3.1761 (3.3801)	Learning Rate [0.00125]
6: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00093 (0.00104)	Tok/s 49793 (53491)	Loss/tok 3.2666 (3.3942)	Learning Rate [0.00125]
7: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00084 (0.00093)	Tok/s 49792 (53584)	Loss/tok 3.5558 (3.3893)	Learning Rate [0.00125]
0: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00102 (0.00091)	Tok/s 49859 (52960)	Loss/tok 3.1967 (3.4096)	Learning Rate [0.00125]
8: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00089 (0.00102)	Tok/s 49785 (53648)	Loss/tok 3.5253 (3.3906)	Learning Rate [0.00125]
15: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00089 (0.00090)	Tok/s 51201 (54244)	Loss/tok 3.2737 (3.3832)	Learning Rate [0.00125]
14: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00085 (0.00092)	Tok/s 51208 (54140)	Loss/tok 3.6204 (3.3922)	Learning Rate [0.00125]
9: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00094 (0.00093)	Tok/s 49817 (53694)	Loss/tok 3.3135 (3.3957)	Learning Rate [0.00125]
10: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00097 (0.00096)	Tok/s 49817 (53756)	Loss/tok 3.0530 (3.4062)	Learning Rate [0.00125]
12: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00090 (0.00097)	Tok/s 50931 (53922)	Loss/tok 3.4119 (3.3973)	Learning Rate [0.00125]
13: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00106 (0.00100)	Tok/s 51148 (54036)	Loss/tok 3.3559 (3.3800)	Learning Rate [0.00125]
11: TRAIN [1][220/3416]	Time 0.051 (0.059)	Data 0.00110 (0.00100)	Tok/s 49748 (53814)	Loss/tok 3.2339 (3.4016)	Learning Rate [0.00125]
11: TRAIN [1][230/3416]	Time 0.060 (0.059)	Data 0.00118 (0.00100)	Tok/s 53508 (53969)	Loss/tok 3.5533 (3.4068)	Learning Rate [0.00125]
10: TRAIN [1][230/3416]	Time 0.060 (0.059)	Data 0.00093 (0.00096)	Tok/s 53001 (53913)	Loss/tok 3.2939 (3.4059)	Learning Rate [0.00125]
12: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00113 (0.00097)	Tok/s 52847 (54071)	Loss/tok 3.6156 (3.3969)	Learning Rate [0.00125]
9: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00090 (0.00093)	Tok/s 52833 (53853)	Loss/tok 3.5530 (3.3981)	Learning Rate [0.00125]
13: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00103 (0.00100)	Tok/s 52720 (54181)	Loss/tok 3.3637 (3.3833)	Learning Rate [0.00125]
8: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00095 (0.00101)	Tok/s 52768 (53803)	Loss/tok 3.4005 (3.3949)	Learning Rate [0.00125]
14: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00086 (0.00091)	Tok/s 52609 (54281)	Loss/tok 3.3058 (3.3922)	Learning Rate [0.00125]
7: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00086 (0.00093)	Tok/s 52646 (53739)	Loss/tok 3.1143 (3.3924)	Learning Rate [0.00125]
15: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00088 (0.00090)	Tok/s 52521 (54385)	Loss/tok 3.4980 (3.3863)	Learning Rate [0.00125]
5: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00092 (0.00097)	Tok/s 52493 (53556)	Loss/tok 3.2826 (3.3973)	Learning Rate [0.00125]
6: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00099 (0.00104)	Tok/s 52576 (53641)	Loss/tok 3.6081 (3.3942)	Learning Rate [0.00125]
0: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00085 (0.00091)	Tok/s 52398 (53116)	Loss/tok 3.3476 (3.4119)	Learning Rate [0.00125]
4: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00081 (0.00089)	Tok/s 52364 (53457)	Loss/tok 3.3578 (3.3819)	Learning Rate [0.00125]
2: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00087 (0.00098)	Tok/s 52255 (53286)	Loss/tok 3.3230 (3.4064)	Learning Rate [0.00125]
1: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00088 (0.00098)	Tok/s 52274 (53204)	Loss/tok 3.4913 (3.3831)	Learning Rate [0.00125]
3: TRAIN [1][230/3416]	Time 0.061 (0.059)	Data 0.00089 (0.00099)	Tok/s 52293 (53383)	Loss/tok 3.5785 (3.3734)	Learning Rate [0.00125]
2: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00090 (0.00098)	Tok/s 54427 (53198)	Loss/tok 3.7017 (3.4067)	Learning Rate [0.00125]
3: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00085 (0.00099)	Tok/s 54522 (53292)	Loss/tok 3.4293 (3.3761)	Learning Rate [0.00125]
4: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00080 (0.00089)	Tok/s 55313 (53366)	Loss/tok 3.2335 (3.3835)	Learning Rate [0.00125]
5: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00084 (0.00097)	Tok/s 55501 (53464)	Loss/tok 3.5364 (3.3976)	Learning Rate [0.00125]
1: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00092 (0.00098)	Tok/s 54325 (53117)	Loss/tok 3.8409 (3.3831)	Learning Rate [0.00125]
0: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00085 (0.00091)	Tok/s 54274 (53033)	Loss/tok 3.4172 (3.4149)	Learning Rate [0.00125]
7: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00087 (0.00093)	Tok/s 55500 (53647)	Loss/tok 3.2695 (3.3915)	Learning Rate [0.00125]
14: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00080 (0.00091)	Tok/s 55305 (54183)	Loss/tok 3.2901 (3.3927)	Learning Rate [0.00125]
8: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00101 (0.00101)	Tok/s 55496 (53713)	Loss/tok 3.6150 (3.3955)	Learning Rate [0.00125]
9: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00095 (0.00093)	Tok/s 55507 (53761)	Loss/tok 3.4091 (3.4008)	Learning Rate [0.00125]
13: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00100 (0.00100)	Tok/s 55312 (54087)	Loss/tok 3.3725 (3.3834)	Learning Rate [0.00125]
12: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00090 (0.00097)	Tok/s 55325 (53978)	Loss/tok 3.4798 (3.3978)	Learning Rate [0.00125]
15: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00088 (0.00090)	Tok/s 55239 (54287)	Loss/tok 3.5556 (3.3873)	Learning Rate [0.00125]
11: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00085 (0.00100)	Tok/s 55350 (53878)	Loss/tok 3.4505 (3.4051)	Learning Rate [0.00125]
10: TRAIN [1][240/3416]	Time 0.066 (0.059)	Data 0.00092 (0.00096)	Tok/s 55330 (53821)	Loss/tok 3.3126 (3.4053)	Learning Rate [0.00125]
6: TRAIN [1][240/3416]	Time 0.065 (0.059)	Data 0.00110 (0.00104)	Tok/s 55711 (53544)	Loss/tok 3.4296 (3.3962)	Learning Rate [0.00125]
10: TRAIN [1][250/3416]	Time 0.044 (0.059)	Data 0.00105 (0.00096)	Tok/s 47752 (53775)	Loss/tok 2.9886 (3.4042)	Learning Rate [0.00125]
11: TRAIN [1][250/3416]	Time 0.044 (0.059)	Data 0.00095 (0.00100)	Tok/s 47754 (53829)	Loss/tok 3.3316 (3.4061)	Learning Rate [0.00125]
12: TRAIN [1][250/3416]	Time 0.044 (0.059)	Data 0.00103 (0.00097)	Tok/s 47694 (53930)	Loss/tok 3.1383 (3.3998)	Learning Rate [0.00125]
9: TRAIN [1][250/3416]	Time 0.044 (0.059)	Data 0.00105 (0.00094)	Tok/s 47553 (53717)	Loss/tok 3.3416 (3.4020)	Learning Rate [0.00125]
13: TRAIN [1][250/3416]	Time 0.044 (0.059)	Data 0.00118 (0.00100)	Tok/s 47588 (54039)	Loss/tok 3.1816 (3.3826)	Learning Rate [0.00125]
8: TRAIN [1][250/3416]	Time 0.045 (0.059)	Data 0.00104 (0.00101)	Tok/s 47403 (53668)	Loss/tok 3.0373 (3.3966)	Learning Rate [0.00125]
14: TRAIN [1][250/3416]	Time 0.044 (0.059)	Data 0.00099 (0.00091)	Tok/s 47474 (54130)	Loss/tok 3.3952 (3.3940)	Learning Rate [0.00125]
15: TRAIN [1][250/3416]	Time 0.045 (0.059)	Data 0.00103 (0.00090)	Tok/s 47355 (54233)	Loss/tok 3.1866 (3.3841)	Learning Rate [0.00125]
0: TRAIN [1][250/3416]	Time 0.045 (0.059)	Data 0.00097 (0.00091)	Tok/s 45807 (52988)	Loss/tok 3.4264 (3.4164)	Learning Rate [0.00125]
7: TRAIN [1][250/3416]	Time 0.045 (0.059)	Data 0.00101 (0.00093)	Tok/s 47321 (53598)	Loss/tok 3.2367 (3.3896)	Learning Rate [0.00125]
5: TRAIN [1][250/3416]	Time 0.045 (0.059)	Data 0.00098 (0.00096)	Tok/s 47055 (53416)	Loss/tok 3.3201 (3.3975)	Learning Rate [0.00125]
6: TRAIN [1][250/3416]	Time 0.045 (0.059)	Data 0.00107 (0.00104)	Tok/s 47139 (53498)	Loss/tok 3.3253 (3.3964)	Learning Rate [0.00125]
1: TRAIN [1][250/3416]	Time 0.045 (0.059)	Data 0.00112 (0.00098)	Tok/s 45694 (53071)	Loss/tok 3.2446 (3.3839)	Learning Rate [0.00125]
4: TRAIN [1][250/3416]	Time 0.045 (0.059)	Data 0.00099 (0.00089)	Tok/s 46945 (53322)	Loss/tok 3.3777 (3.3836)	Learning Rate [0.00125]
2: TRAIN [1][250/3416]	Time 0.045 (0.059)	Data 0.00104 (0.00097)	Tok/s 45529 (53151)	Loss/tok 3.1289 (3.4053)	Learning Rate [0.00125]
3: TRAIN [1][250/3416]	Time 0.045 (0.059)	Data 0.00095 (0.00099)	Tok/s 45810 (53245)	Loss/tok 3.2330 (3.3743)	Learning Rate [0.00125]
7: TRAIN [1][260/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00093)	Tok/s 30399 (53409)	Loss/tok 2.7829 (3.3852)	Learning Rate [0.00125]
5: TRAIN [1][260/3416]	Time 0.040 (0.059)	Data 0.00096 (0.00096)	Tok/s 30228 (53232)	Loss/tok 2.6078 (3.3941)	Learning Rate [0.00125]
4: TRAIN [1][260/3416]	Time 0.040 (0.059)	Data 0.00092 (0.00089)	Tok/s 28760 (53131)	Loss/tok 2.7244 (3.3827)	Learning Rate [0.00125]
6: TRAIN [1][260/3416]	Time 0.039 (0.058)	Data 0.00114 (0.00104)	Tok/s 31008 (53311)	Loss/tok 2.8261 (3.3941)	Learning Rate [0.00125]
9: TRAIN [1][260/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00094)	Tok/s 30268 (53522)	Loss/tok 2.7794 (3.3984)	Learning Rate [0.00125]
3: TRAIN [1][260/3416]	Time 0.040 (0.058)	Data 0.00097 (0.00099)	Tok/s 28683 (53054)	Loss/tok 2.5043 (3.3746)	Learning Rate [0.00125]
2: TRAIN [1][260/3416]	Time 0.040 (0.059)	Data 0.00101 (0.00097)	Tok/s 28647 (52963)	Loss/tok 2.3784 (3.4043)	Learning Rate [0.00125]
10: TRAIN [1][260/3416]	Time 0.040 (0.059)	Data 0.00098 (0.00096)	Tok/s 30268 (53582)	Loss/tok 2.6800 (3.4023)	Learning Rate [0.00125]
1: TRAIN [1][260/3416]	Time 0.040 (0.059)	Data 0.00086 (0.00098)	Tok/s 28537 (52883)	Loss/tok 2.6688 (3.3836)	Learning Rate [0.00125]
12: TRAIN [1][260/3416]	Time 0.040 (0.059)	Data 0.00100 (0.00097)	Tok/s 30153 (53741)	Loss/tok 2.7318 (3.3978)	Learning Rate [0.00125]
11: TRAIN [1][260/3416]	Time 0.040 (0.059)	Data 0.00102 (0.00100)	Tok/s 30220 (53639)	Loss/tok 2.7377 (3.4017)	Learning Rate [0.00125]
0: TRAIN [1][260/3416]	Time 0.041 (0.059)	Data 0.00082 (0.00091)	Tok/s 28429 (52798)	Loss/tok 2.5937 (3.4109)	Learning Rate [0.00125]
15: TRAIN [1][260/3416]	Time 0.040 (0.059)	Data 0.00094 (0.00090)	Tok/s 31631 (54049)	Loss/tok 2.7761 (3.3811)	Learning Rate [0.00125]
14: TRAIN [1][260/3416]	Time 0.040 (0.059)	Data 0.00086 (0.00091)	Tok/s 31508 (53942)	Loss/tok 2.6773 (3.3919)	Learning Rate [0.00125]
8: TRAIN [1][260/3416]	Time 0.040 (0.059)	Data 0.00109 (0.00101)	Tok/s 30383 (53472)	Loss/tok 2.6942 (3.3951)	Learning Rate [0.00125]
13: TRAIN [1][260/3416]	Time 0.040 (0.059)	Data 0.00112 (0.00101)	Tok/s 30152 (53845)	Loss/tok 2.8732 (3.3821)	Learning Rate [0.00125]
1: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 36202 (52689)	Loss/tok 3.0870 (3.3809)	Learning Rate [0.00125]
2: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00097)	Tok/s 36598 (52768)	Loss/tok 3.3978 (3.4041)	Learning Rate [0.00125]
3: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00099)	Tok/s 36572 (52856)	Loss/tok 3.0910 (3.3738)	Learning Rate [0.00125]
15: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00090)	Tok/s 36705 (53855)	Loss/tok 3.1699 (3.3815)	Learning Rate [0.00125]
0: TRAIN [1][270/3416]	Time 0.050 (0.058)	Data 0.00112 (0.00092)	Tok/s 36050 (52604)	Loss/tok 3.0623 (3.4126)	Learning Rate [0.00125]
14: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00091)	Tok/s 36717 (53749)	Loss/tok 3.3034 (3.3944)	Learning Rate [0.00125]
4: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00089)	Tok/s 36518 (52935)	Loss/tok 3.0155 (3.3819)	Learning Rate [0.00125]
5: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00096)	Tok/s 36536 (53032)	Loss/tok 3.1331 (3.3946)	Learning Rate [0.00125]
13: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00101)	Tok/s 36689 (53653)	Loss/tok 3.1791 (3.3825)	Learning Rate [0.00125]
12: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00097)	Tok/s 36709 (53545)	Loss/tok 3.0665 (3.3966)	Learning Rate [0.00125]
11: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00100)	Tok/s 36703 (53444)	Loss/tok 2.9347 (3.4006)	Learning Rate [0.00125]
10: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00096)	Tok/s 36598 (53388)	Loss/tok 3.3450 (3.4021)	Learning Rate [0.00125]
7: TRAIN [1][270/3416]	Time 0.050 (0.058)	Data 0.00109 (0.00093)	Tok/s 37191 (53206)	Loss/tok 3.0993 (3.3834)	Learning Rate [0.00125]
8: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00101)	Tok/s 36556 (53280)	Loss/tok 3.0621 (3.3917)	Learning Rate [0.00125]
9: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00094)	Tok/s 36595 (53329)	Loss/tok 3.1323 (3.3967)	Learning Rate [0.00125]
6: TRAIN [1][270/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00104)	Tok/s 36488 (53109)	Loss/tok 2.8840 (3.3909)	Learning Rate [0.00125]
5: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00096)	Tok/s 53579 (53064)	Loss/tok 3.6133 (3.3974)	Learning Rate [0.00125]
4: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00089)	Tok/s 53509 (52969)	Loss/tok 3.3677 (3.3823)	Learning Rate [0.00125]
6: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00104)	Tok/s 53629 (53142)	Loss/tok 3.5176 (3.3923)	Learning Rate [0.00125]
7: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00093)	Tok/s 53592 (53237)	Loss/tok 3.5643 (3.3869)	Learning Rate [0.00125]
3: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00099)	Tok/s 53496 (52889)	Loss/tok 3.5915 (3.3732)	Learning Rate [0.00125]
2: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00097)	Tok/s 53476 (52805)	Loss/tok 3.5295 (3.4055)	Learning Rate [0.00125]
8: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00101)	Tok/s 53855 (53309)	Loss/tok 3.1843 (3.3932)	Learning Rate [0.00125]
1: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00097)	Tok/s 53517 (52728)	Loss/tok 3.6953 (3.3801)	Learning Rate [0.00125]
9: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00094)	Tok/s 54623 (53360)	Loss/tok 3.7761 (3.3959)	Learning Rate [0.00125]
0: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00080 (0.00092)	Tok/s 53523 (52645)	Loss/tok 3.3990 (3.4076)	Learning Rate [0.00125]
10: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00084 (0.00096)	Tok/s 54660 (53423)	Loss/tok 3.7271 (3.4017)	Learning Rate [0.00125]
15: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00077 (0.00090)	Tok/s 54510 (53893)	Loss/tok 3.6478 (3.3833)	Learning Rate [0.00125]
11: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00100)	Tok/s 54653 (53482)	Loss/tok 3.5753 (3.4007)	Learning Rate [0.00125]
12: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00097)	Tok/s 54625 (53586)	Loss/tok 3.7532 (3.3971)	Learning Rate [0.00125]
14: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00091)	Tok/s 54485 (53787)	Loss/tok 3.3435 (3.3931)	Learning Rate [0.00125]
13: TRAIN [1][280/3416]	Time 0.063 (0.058)	Data 0.00084 (0.00102)	Tok/s 54635 (53693)	Loss/tok 3.3886 (3.3822)	Learning Rate [0.00125]
5: Gradient norm: inf
6: Gradient norm: inf
3: Gradient norm: inf
4: Gradient norm: inf
7: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
1: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
15: Gradient norm: inf
14: Gradient norm: inf
12: Gradient norm: inf
11: Gradient norm: inf
13: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
13: TRAIN [1][290/3416]	Time 0.072 (0.059)	Data 0.00089 (0.00102)	Tok/s 65922 (53971)	Loss/tok 3.3729 (3.3809)	Learning Rate [0.00125]
11: TRAIN [1][290/3416]	Time 0.072 (0.059)	Data 0.00093 (0.00099)	Tok/s 65761 (53766)	Loss/tok 3.3096 (3.4021)	Learning Rate [0.00125]
12: TRAIN [1][290/3416]	Time 0.072 (0.059)	Data 0.00086 (0.00097)	Tok/s 65776 (53868)	Loss/tok 3.6851 (3.3991)	Learning Rate [0.00125]
10: TRAIN [1][290/3416]	Time 0.072 (0.059)	Data 0.00122 (0.00096)	Tok/s 66170 (53703)	Loss/tok 3.3077 (3.4018)	Learning Rate [0.00125]
14: TRAIN [1][290/3416]	Time 0.072 (0.059)	Data 0.00090 (0.00091)	Tok/s 65791 (54062)	Loss/tok 3.5779 (3.3942)	Learning Rate [0.00125]
9: TRAIN [1][290/3416]	Time 0.072 (0.059)	Data 0.00097 (0.00094)	Tok/s 65635 (53639)	Loss/tok 3.4912 (3.3959)	Learning Rate [0.00125]
8: TRAIN [1][290/3416]	Time 0.072 (0.059)	Data 0.00090 (0.00101)	Tok/s 65523 (53590)	Loss/tok 3.5929 (3.3952)	Learning Rate [0.00125]
7: TRAIN [1][290/3416]	Time 0.072 (0.059)	Data 0.00089 (0.00093)	Tok/s 65114 (53519)	Loss/tok 3.4923 (3.3884)	Learning Rate [0.00125]
15: TRAIN [1][290/3416]	Time 0.072 (0.059)	Data 0.00096 (0.00090)	Tok/s 65719 (54164)	Loss/tok 3.4613 (3.3852)	Learning Rate [0.00125]
6: TRAIN [1][290/3416]	Time 0.073 (0.059)	Data 0.00099 (0.00104)	Tok/s 64420 (53420)	Loss/tok 3.5194 (3.3966)	Learning Rate [0.00125]
5: TRAIN [1][290/3416]	Time 0.073 (0.059)	Data 0.00090 (0.00096)	Tok/s 64418 (53343)	Loss/tok 3.4659 (3.3961)	Learning Rate [0.00125]
3: TRAIN [1][290/3416]	Time 0.072 (0.059)	Data 0.00089 (0.00098)	Tok/s 64533 (53169)	Loss/tok 3.4539 (3.3782)	Learning Rate [0.00125]
0: TRAIN [1][290/3416]	Time 0.072 (0.059)	Data 0.00146 (0.00092)	Tok/s 64769 (52923)	Loss/tok 3.3632 (3.4100)	Learning Rate [0.00125]
4: TRAIN [1][290/3416]	Time 0.073 (0.059)	Data 0.00088 (0.00089)	Tok/s 64426 (53251)	Loss/tok 3.2472 (3.3837)	Learning Rate [0.00125]
2: TRAIN [1][290/3416]	Time 0.072 (0.059)	Data 0.00090 (0.00098)	Tok/s 64489 (53081)	Loss/tok 3.5232 (3.4077)	Learning Rate [0.00125]
1: TRAIN [1][290/3416]	Time 0.072 (0.059)	Data 0.00087 (0.00097)	Tok/s 64575 (53005)	Loss/tok 3.5764 (3.3829)	Learning Rate [0.00125]
10: TRAIN [1][300/3416]	Time 0.062 (0.059)	Data 0.00097 (0.00096)	Tok/s 51311 (53761)	Loss/tok 3.3245 (3.4008)	Learning Rate [0.00125]
9: TRAIN [1][300/3416]	Time 0.062 (0.059)	Data 0.00091 (0.00094)	Tok/s 51230 (53695)	Loss/tok 3.4524 (3.3982)	Learning Rate [0.00125]
12: TRAIN [1][300/3416]	Time 0.062 (0.059)	Data 0.00102 (0.00096)	Tok/s 51347 (53921)	Loss/tok 3.3169 (3.4016)	Learning Rate [0.00125]
11: TRAIN [1][300/3416]	Time 0.062 (0.059)	Data 0.00100 (0.00099)	Tok/s 51265 (53822)	Loss/tok 3.5034 (3.4031)	Learning Rate [0.00125]
8: TRAIN [1][300/3416]	Time 0.063 (0.059)	Data 0.00093 (0.00101)	Tok/s 51118 (53646)	Loss/tok 3.4884 (3.3979)	Learning Rate [0.00125]
13: TRAIN [1][300/3416]	Time 0.062 (0.059)	Data 0.00093 (0.00101)	Tok/s 51309 (54020)	Loss/tok 3.4526 (3.3828)	Learning Rate [0.00125]
7: TRAIN [1][300/3416]	Time 0.063 (0.059)	Data 0.00087 (0.00093)	Tok/s 51066 (53577)	Loss/tok 3.7442 (3.3910)	Learning Rate [0.00125]
6: TRAIN [1][300/3416]	Time 0.063 (0.059)	Data 0.00095 (0.00104)	Tok/s 50933 (53482)	Loss/tok 3.5091 (3.3969)	Learning Rate [0.00125]
14: TRAIN [1][300/3416]	Time 0.063 (0.059)	Data 0.00087 (0.00091)	Tok/s 51178 (54110)	Loss/tok 3.4746 (3.3946)	Learning Rate [0.00125]
4: TRAIN [1][300/3416]	Time 0.063 (0.059)	Data 0.00095 (0.00089)	Tok/s 50946 (53311)	Loss/tok 3.3953 (3.3879)	Learning Rate [0.00125]
15: TRAIN [1][300/3416]	Time 0.063 (0.059)	Data 0.00086 (0.00090)	Tok/s 51116 (54209)	Loss/tok 3.3875 (3.3872)	Learning Rate [0.00125]
3: TRAIN [1][300/3416]	Time 0.063 (0.059)	Data 0.00097 (0.00098)	Tok/s 50956 (53231)	Loss/tok 3.4513 (3.3811)	Learning Rate [0.00125]
2: TRAIN [1][300/3416]	Time 0.063 (0.059)	Data 0.00095 (0.00097)	Tok/s 50918 (53146)	Loss/tok 3.4882 (3.4081)	Learning Rate [0.00125]
0: TRAIN [1][300/3416]	Time 0.063 (0.059)	Data 0.00097 (0.00092)	Tok/s 51121 (52993)	Loss/tok 3.3264 (3.4116)	Learning Rate [0.00125]
1: TRAIN [1][300/3416]	Time 0.063 (0.059)	Data 0.00091 (0.00097)	Tok/s 51041 (53073)	Loss/tok 3.3964 (3.3854)	Learning Rate [0.00125]
5: TRAIN [1][300/3416]	Time 0.063 (0.059)	Data 0.00090 (0.00096)	Tok/s 50893 (53405)	Loss/tok 3.4457 (3.3967)	Learning Rate [0.00125]
5: TRAIN [1][310/3416]	Time 0.057 (0.059)	Data 0.00100 (0.00096)	Tok/s 51107 (53355)	Loss/tok 3.2773 (3.3945)	Learning Rate [0.00125]
6: TRAIN [1][310/3416]	Time 0.057 (0.059)	Data 0.00100 (0.00103)	Tok/s 51362 (53430)	Loss/tok 3.6701 (3.3969)	Learning Rate [0.00125]
10: TRAIN [1][310/3416]	Time 0.057 (0.059)	Data 0.00097 (0.00096)	Tok/s 51248 (53711)	Loss/tok 3.3481 (3.3981)	Learning Rate [0.00125]
7: TRAIN [1][310/3416]	Time 0.057 (0.059)	Data 0.00087 (0.00093)	Tok/s 51256 (53528)	Loss/tok 3.1200 (3.3893)	Learning Rate [0.00125]
4: TRAIN [1][310/3416]	Time 0.057 (0.059)	Data 0.00087 (0.00089)	Tok/s 50270 (53258)	Loss/tok 3.0885 (3.3860)	Learning Rate [0.00125]
8: TRAIN [1][310/3416]	Time 0.058 (0.059)	Data 0.00093 (0.00100)	Tok/s 51143 (53598)	Loss/tok 3.4550 (3.3977)	Learning Rate [0.00125]
3: TRAIN [1][310/3416]	Time 0.057 (0.059)	Data 0.00097 (0.00098)	Tok/s 50266 (53176)	Loss/tok 3.1666 (3.3796)	Learning Rate [0.00125]
2: TRAIN [1][310/3416]	Time 0.057 (0.059)	Data 0.00098 (0.00097)	Tok/s 50284 (53092)	Loss/tok 3.6139 (3.4063)	Learning Rate [0.00125]
11: TRAIN [1][310/3416]	Time 0.057 (0.059)	Data 0.00102 (0.00099)	Tok/s 51261 (53769)	Loss/tok 3.3274 (3.4037)	Learning Rate [0.00125]
9: TRAIN [1][310/3416]	Time 0.058 (0.059)	Data 0.00091 (0.00094)	Tok/s 51103 (53647)	Loss/tok 3.3350 (3.3978)	Learning Rate [0.00125]
1: TRAIN [1][310/3416]	Time 0.057 (0.059)	Data 0.00102 (0.00097)	Tok/s 50249 (53016)	Loss/tok 3.1383 (3.3841)	Learning Rate [0.00125]
12: TRAIN [1][310/3416]	Time 0.058 (0.059)	Data 0.00094 (0.00096)	Tok/s 51181 (53865)	Loss/tok 3.5256 (3.3995)	Learning Rate [0.00125]
0: TRAIN [1][310/3416]	Time 0.057 (0.059)	Data 0.00089 (0.00092)	Tok/s 50229 (52938)	Loss/tok 3.3293 (3.4100)	Learning Rate [0.00125]
15: TRAIN [1][310/3416]	Time 0.057 (0.059)	Data 0.00101 (0.00090)	Tok/s 51310 (54168)	Loss/tok 3.3886 (3.3852)	Learning Rate [0.00125]
13: TRAIN [1][310/3416]	Time 0.058 (0.059)	Data 0.00098 (0.00101)	Tok/s 51158 (53963)	Loss/tok 3.2658 (3.3833)	Learning Rate [0.00125]
14: TRAIN [1][310/3416]	Time 0.058 (0.059)	Data 0.00084 (0.00091)	Tok/s 51188 (54063)	Loss/tok 3.5901 (3.3931)	Learning Rate [0.00125]
5: TRAIN [1][320/3416]	Time 0.060 (0.059)	Data 0.00089 (0.00096)	Tok/s 54012 (53326)	Loss/tok 3.4132 (3.3938)	Learning Rate [0.00125]
10: TRAIN [1][320/3416]	Time 0.060 (0.059)	Data 0.00089 (0.00096)	Tok/s 54241 (53685)	Loss/tok 3.3401 (3.3990)	Learning Rate [0.00125]
8: TRAIN [1][320/3416]	Time 0.060 (0.059)	Data 0.00090 (0.00100)	Tok/s 54191 (53570)	Loss/tok 3.3845 (3.3972)	Learning Rate [0.00125]
4: TRAIN [1][320/3416]	Time 0.060 (0.059)	Data 0.00093 (0.00089)	Tok/s 53952 (53230)	Loss/tok 3.5367 (3.3868)	Learning Rate [0.00125]
9: TRAIN [1][320/3416]	Time 0.060 (0.059)	Data 0.00102 (0.00094)	Tok/s 54254 (53620)	Loss/tok 3.4587 (3.3981)	Learning Rate [0.00125]
2: TRAIN [1][320/3416]	Time 0.061 (0.059)	Data 0.00093 (0.00097)	Tok/s 53776 (53069)	Loss/tok 3.3338 (3.4045)	Learning Rate [0.00125]
12: TRAIN [1][320/3416]	Time 0.060 (0.059)	Data 0.00094 (0.00096)	Tok/s 54912 (53843)	Loss/tok 3.4597 (3.4005)	Learning Rate [0.00125]
7: TRAIN [1][320/3416]	Time 0.060 (0.059)	Data 0.00100 (0.00093)	Tok/s 54056 (53500)	Loss/tok 3.4240 (3.3898)	Learning Rate [0.00125]
6: TRAIN [1][320/3416]	Time 0.060 (0.059)	Data 0.00090 (0.00103)	Tok/s 54084 (53405)	Loss/tok 3.3403 (3.3954)	Learning Rate [0.00125]
0: TRAIN [1][320/3416]	Time 0.061 (0.059)	Data 0.00080 (0.00091)	Tok/s 53776 (52907)	Loss/tok 3.2303 (3.4088)	Learning Rate [0.00125]
11: TRAIN [1][320/3416]	Time 0.060 (0.059)	Data 0.00087 (0.00099)	Tok/s 54160 (53743)	Loss/tok 3.3033 (3.4043)	Learning Rate [0.00125]
1: TRAIN [1][320/3416]	Time 0.061 (0.059)	Data 0.00085 (0.00096)	Tok/s 53769 (52987)	Loss/tok 3.3373 (3.3861)	Learning Rate [0.00125]
15: TRAIN [1][320/3416]	Time 0.060 (0.059)	Data 0.00095 (0.00090)	Tok/s 55062 (54149)	Loss/tok 3.8079 (3.3856)	Learning Rate [0.00125]
3: TRAIN [1][320/3416]	Time 0.061 (0.059)	Data 0.00095 (0.00098)	Tok/s 53852 (53150)	Loss/tok 3.2025 (3.3818)	Learning Rate [0.00125]
14: TRAIN [1][320/3416]	Time 0.061 (0.059)	Data 0.00102 (0.00091)	Tok/s 54956 (54049)	Loss/tok 3.4823 (3.3941)	Learning Rate [0.00125]
13: TRAIN [1][320/3416]	Time 0.061 (0.059)	Data 0.00085 (0.00101)	Tok/s 54997 (53946)	Loss/tok 3.4048 (3.3841)	Learning Rate [0.00125]
1: TRAIN [1][330/3416]	Time 0.069 (0.059)	Data 0.00079 (0.00096)	Tok/s 64518 (52896)	Loss/tok 3.3469 (3.3844)	Learning Rate [0.00125]
0: TRAIN [1][330/3416]	Time 0.069 (0.059)	Data 0.00080 (0.00091)	Tok/s 64470 (52813)	Loss/tok 3.5401 (3.4061)	Learning Rate [0.00125]
2: TRAIN [1][330/3416]	Time 0.070 (0.059)	Data 0.00084 (0.00097)	Tok/s 64432 (52974)	Loss/tok 3.5626 (3.4023)	Learning Rate [0.00125]
15: TRAIN [1][330/3416]	Time 0.069 (0.059)	Data 0.00097 (0.00090)	Tok/s 65400 (54055)	Loss/tok 3.3408 (3.3841)	Learning Rate [0.00125]
14: TRAIN [1][330/3416]	Time 0.070 (0.059)	Data 0.00082 (0.00091)	Tok/s 65341 (53952)	Loss/tok 3.5254 (3.3913)	Learning Rate [0.00125]
4: TRAIN [1][330/3416]	Time 0.070 (0.059)	Data 0.00078 (0.00089)	Tok/s 64225 (53131)	Loss/tok 3.4506 (3.3858)	Learning Rate [0.00125]
13: TRAIN [1][330/3416]	Time 0.070 (0.059)	Data 0.00091 (0.00101)	Tok/s 65115 (53852)	Loss/tok 3.4403 (3.3820)	Learning Rate [0.00125]
3: TRAIN [1][330/3416]	Time 0.070 (0.059)	Data 0.00094 (0.00098)	Tok/s 64314 (53052)	Loss/tok 3.5979 (3.3810)	Learning Rate [0.00125]
5: TRAIN [1][330/3416]	Time 0.070 (0.059)	Data 0.00088 (0.00096)	Tok/s 64235 (53229)	Loss/tok 3.5204 (3.3924)	Learning Rate [0.00125]
12: TRAIN [1][330/3416]	Time 0.070 (0.059)	Data 0.00092 (0.00096)	Tok/s 64273 (53750)	Loss/tok 3.3674 (3.3983)	Learning Rate [0.00125]
11: TRAIN [1][330/3416]	Time 0.070 (0.059)	Data 0.00088 (0.00099)	Tok/s 64156 (53649)	Loss/tok 3.5640 (3.4018)	Learning Rate [0.00125]
6: TRAIN [1][330/3416]	Time 0.070 (0.059)	Data 0.00090 (0.00103)	Tok/s 64161 (53308)	Loss/tok 3.5008 (3.3935)	Learning Rate [0.00125]
10: TRAIN [1][330/3416]	Time 0.070 (0.059)	Data 0.00082 (0.00096)	Tok/s 64079 (53586)	Loss/tok 3.7145 (3.3976)	Learning Rate [0.00125]
7: TRAIN [1][330/3416]	Time 0.070 (0.059)	Data 0.00099 (0.00093)	Tok/s 64070 (53401)	Loss/tok 3.3558 (3.3881)	Learning Rate [0.00125]
8: TRAIN [1][330/3416]	Time 0.070 (0.059)	Data 0.00085 (0.00100)	Tok/s 64013 (53473)	Loss/tok 3.6245 (3.3954)	Learning Rate [0.00125]
9: TRAIN [1][330/3416]	Time 0.070 (0.059)	Data 0.00094 (0.00094)	Tok/s 64010 (53521)	Loss/tok 3.7651 (3.3976)	Learning Rate [0.00125]
10: TRAIN [1][340/3416]	Time 0.049 (0.059)	Data 0.00091 (0.00096)	Tok/s 50996 (53679)	Loss/tok 3.3130 (3.3988)	Learning Rate [0.00125]
9: TRAIN [1][340/3416]	Time 0.049 (0.059)	Data 0.00093 (0.00094)	Tok/s 50943 (53613)	Loss/tok 3.5499 (3.3996)	Learning Rate [0.00125]
11: TRAIN [1][340/3416]	Time 0.049 (0.059)	Data 0.00102 (0.00099)	Tok/s 50891 (53740)	Loss/tok 3.5836 (3.4009)	Learning Rate [0.00125]
8: TRAIN [1][340/3416]	Time 0.049 (0.059)	Data 0.00094 (0.00100)	Tok/s 50927 (53566)	Loss/tok 3.1531 (3.3956)	Learning Rate [0.00125]
13: TRAIN [1][340/3416]	Time 0.049 (0.059)	Data 0.00098 (0.00101)	Tok/s 50648 (53938)	Loss/tok 3.3774 (3.3845)	Learning Rate [0.00125]
7: TRAIN [1][340/3416]	Time 0.049 (0.059)	Data 0.00105 (0.00093)	Tok/s 50896 (53494)	Loss/tok 3.3396 (3.3876)	Learning Rate [0.00125]
12: TRAIN [1][340/3416]	Time 0.049 (0.059)	Data 0.00089 (0.00096)	Tok/s 50758 (53837)	Loss/tok 3.4606 (3.3989)	Learning Rate [0.00125]
6: TRAIN [1][340/3416]	Time 0.049 (0.059)	Data 0.00093 (0.00103)	Tok/s 50665 (53402)	Loss/tok 3.2958 (3.3961)	Learning Rate [0.00125]
14: TRAIN [1][340/3416]	Time 0.049 (0.059)	Data 0.00085 (0.00091)	Tok/s 50524 (54040)	Loss/tok 2.8420 (3.3893)	Learning Rate [0.00125]
5: TRAIN [1][340/3416]	Time 0.049 (0.059)	Data 0.00098 (0.00096)	Tok/s 50540 (53325)	Loss/tok 3.1505 (3.3919)	Learning Rate [0.00125]
15: TRAIN [1][340/3416]	Time 0.050 (0.059)	Data 0.00097 (0.00091)	Tok/s 50386 (54149)	Loss/tok 3.2250 (3.3858)	Learning Rate [0.00125]
0: TRAIN [1][340/3416]	Time 0.050 (0.059)	Data 0.00083 (0.00091)	Tok/s 50338 (52916)	Loss/tok 3.3010 (3.4065)	Learning Rate [0.00125]
4: TRAIN [1][340/3416]	Time 0.049 (0.059)	Data 0.00085 (0.00089)	Tok/s 50436 (53230)	Loss/tok 3.5488 (3.3884)	Learning Rate [0.00125]
2: TRAIN [1][340/3416]	Time 0.050 (0.059)	Data 0.00093 (0.00097)	Tok/s 50168 (53075)	Loss/tok 3.2644 (3.3999)	Learning Rate [0.00125]
3: TRAIN [1][340/3416]	Time 0.050 (0.059)	Data 0.00093 (0.00098)	Tok/s 50287 (53153)	Loss/tok 3.3684 (3.3836)	Learning Rate [0.00125]
1: TRAIN [1][340/3416]	Time 0.050 (0.059)	Data 0.00083 (0.00096)	Tok/s 50113 (52997)	Loss/tok 3.4199 (3.3859)	Learning Rate [0.00125]
7: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00093)	Tok/s 32654 (53204)	Loss/tok 3.0451 (3.3872)	Learning Rate [0.00125]
8: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00100)	Tok/s 32627 (53273)	Loss/tok 3.1460 (3.3927)	Learning Rate [0.00125]
5: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00096)	Tok/s 32530 (53040)	Loss/tok 3.2747 (3.3883)	Learning Rate [0.00125]
6: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00103)	Tok/s 32501 (53115)	Loss/tok 2.8944 (3.3933)	Learning Rate [0.00125]
9: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00094)	Tok/s 32597 (53319)	Loss/tok 2.9554 (3.3962)	Learning Rate [0.00125]
4: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00077 (0.00089)	Tok/s 32520 (52947)	Loss/tok 2.8481 (3.3869)	Learning Rate [0.00125]
10: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00096)	Tok/s 32575 (53384)	Loss/tok 2.9911 (3.3948)	Learning Rate [0.00125]
12: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00096)	Tok/s 32681 (53551)	Loss/tok 3.0290 (3.3958)	Learning Rate [0.00125]
11: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00099)	Tok/s 32631 (53449)	Loss/tok 3.0853 (3.3987)	Learning Rate [0.00125]
2: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00097)	Tok/s 32546 (52788)	Loss/tok 2.8089 (3.3950)	Learning Rate [0.00125]
3: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00098)	Tok/s 32558 (52865)	Loss/tok 2.8544 (3.3809)	Learning Rate [0.00125]
0: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00091)	Tok/s 32497 (52632)	Loss/tok 3.0963 (3.4016)	Learning Rate [0.00125]
13: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00101)	Tok/s 32647 (53650)	Loss/tok 2.7879 (3.3818)	Learning Rate [0.00125]
1: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00096)	Tok/s 32497 (52713)	Loss/tok 2.6487 (3.3823)	Learning Rate [0.00125]
14: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00083 (0.00091)	Tok/s 33453 (53755)	Loss/tok 3.2020 (3.3866)	Learning Rate [0.00125]
15: TRAIN [1][350/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00091)	Tok/s 33932 (53863)	Loss/tok 3.0173 (3.3827)	Learning Rate [0.00125]
10: TRAIN [1][360/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 68981 (53446)	Loss/tok 3.3725 (3.3937)	Learning Rate [0.00125]
11: TRAIN [1][360/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00099)	Tok/s 68972 (53515)	Loss/tok 3.4125 (3.3966)	Learning Rate [0.00125]
9: TRAIN [1][360/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00094)	Tok/s 69104 (53379)	Loss/tok 3.4173 (3.3968)	Learning Rate [0.00125]
8: TRAIN [1][360/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 69110 (53334)	Loss/tok 3.5153 (3.3906)	Learning Rate [0.00125]
12: TRAIN [1][360/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00096)	Tok/s 68972 (53616)	Loss/tok 3.3894 (3.3944)	Learning Rate [0.00125]
7: TRAIN [1][360/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00093)	Tok/s 69117 (53264)	Loss/tok 3.4337 (3.3875)	Learning Rate [0.00125]
13: TRAIN [1][360/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00101)	Tok/s 69002 (53715)	Loss/tok 3.6423 (3.3832)	Learning Rate [0.00125]
6: TRAIN [1][360/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00102)	Tok/s 69121 (53175)	Loss/tok 3.4725 (3.3923)	Learning Rate [0.00125]
14: TRAIN [1][360/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 69002 (53821)	Loss/tok 3.5799 (3.3871)	Learning Rate [0.00125]
5: TRAIN [1][360/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00095)	Tok/s 68690 (53100)	Loss/tok 3.4757 (3.3863)	Learning Rate [0.00125]
4: TRAIN [1][360/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00089)	Tok/s 68211 (53005)	Loss/tok 3.3577 (3.3862)	Learning Rate [0.00125]
0: TRAIN [1][360/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 68116 (52691)	Loss/tok 3.6237 (3.4020)	Learning Rate [0.00125]
15: TRAIN [1][360/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00091)	Tok/s 69042 (53929)	Loss/tok 3.5791 (3.3849)	Learning Rate [0.00125]
2: TRAIN [1][360/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00097)	Tok/s 68168 (52845)	Loss/tok 3.4458 (3.3971)	Learning Rate [0.00125]
3: TRAIN [1][360/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00098)	Tok/s 68208 (52919)	Loss/tok 3.4520 (3.3804)	Learning Rate [0.00125]
1: TRAIN [1][360/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00096)	Tok/s 68100 (52771)	Loss/tok 3.4460 (3.3832)	Learning Rate [0.00125]
8: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00094 (0.00100)	Tok/s 48207 (53454)	Loss/tok 3.4052 (3.3891)	Learning Rate [0.00125]
14: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00091 (0.00091)	Tok/s 47996 (53943)	Loss/tok 3.1144 (3.3886)	Learning Rate [0.00125]
15: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00105 (0.00091)	Tok/s 48056 (54052)	Loss/tok 3.4038 (3.3835)	Learning Rate [0.00125]
5: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00093 (0.00095)	Tok/s 48288 (53219)	Loss/tok 3.4375 (3.3867)	Learning Rate [0.00125]
0: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00090 (0.00091)	Tok/s 48061 (52809)	Loss/tok 3.5182 (3.4024)	Learning Rate [0.00125]
6: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00100 (0.00102)	Tok/s 48287 (53295)	Loss/tok 3.4046 (3.3925)	Learning Rate [0.00125]
13: TRAIN [1][370/3416]	Time 0.046 (0.059)	Data 0.00095 (0.00101)	Tok/s 47798 (53834)	Loss/tok 3.1786 (3.3798)	Learning Rate [0.00125]
12: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00093 (0.00096)	Tok/s 47862 (53736)	Loss/tok 3.2350 (3.3914)	Learning Rate [0.00125]
9: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00087 (0.00094)	Tok/s 48084 (53500)	Loss/tok 3.2819 (3.3942)	Learning Rate [0.00125]
1: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00087 (0.00096)	Tok/s 48055 (52887)	Loss/tok 3.5904 (3.3831)	Learning Rate [0.00125]
2: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00097 (0.00097)	Tok/s 48073 (52959)	Loss/tok 3.3610 (3.3953)	Learning Rate [0.00125]
11: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00093 (0.00099)	Tok/s 47850 (53637)	Loss/tok 3.1002 (3.3944)	Learning Rate [0.00125]
7: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00112 (0.00094)	Tok/s 48284 (53382)	Loss/tok 2.8559 (3.3845)	Learning Rate [0.00125]
4: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00108 (0.00090)	Tok/s 48198 (53121)	Loss/tok 3.1154 (3.3874)	Learning Rate [0.00125]
10: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00093 (0.00097)	Tok/s 47978 (53569)	Loss/tok 3.0259 (3.3898)	Learning Rate [0.00125]
3: TRAIN [1][370/3416]	Time 0.045 (0.059)	Data 0.00119 (0.00098)	Tok/s 48119 (53034)	Loss/tok 3.0486 (3.3808)	Learning Rate [0.00125]
12: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00096 (0.00096)	Tok/s 55401 (53741)	Loss/tok 3.4180 (3.3918)	Learning Rate [0.00125]
11: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00097 (0.00099)	Tok/s 55292 (53641)	Loss/tok 3.3864 (3.3957)	Learning Rate [0.00125]
10: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00092 (0.00097)	Tok/s 55221 (53572)	Loss/tok 3.5117 (3.3887)	Learning Rate [0.00125]
9: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00092 (0.00094)	Tok/s 55143 (53505)	Loss/tok 3.7042 (3.3959)	Learning Rate [0.00125]
14: TRAIN [1][380/3416]	Time 0.063 (0.059)	Data 0.00088 (0.00091)	Tok/s 55700 (53947)	Loss/tok 3.4039 (3.3891)	Learning Rate [0.00125]
13: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00096 (0.00101)	Tok/s 55301 (53841)	Loss/tok 3.2998 (3.3799)	Learning Rate [0.00125]
8: TRAIN [1][380/3416]	Time 0.063 (0.059)	Data 0.00110 (0.00100)	Tok/s 55680 (53460)	Loss/tok 3.2817 (3.3895)	Learning Rate [0.00125]
15: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00097 (0.00092)	Tok/s 55679 (54054)	Loss/tok 3.4911 (3.3856)	Learning Rate [0.00125]
0: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00095 (0.00091)	Tok/s 55165 (52823)	Loss/tok 3.6629 (3.4028)	Learning Rate [0.00125]
7: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00110 (0.00094)	Tok/s 54936 (53390)	Loss/tok 3.4742 (3.3857)	Learning Rate [0.00125]
2: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00105 (0.00097)	Tok/s 55027 (52974)	Loss/tok 3.5608 (3.3958)	Learning Rate [0.00125]
4: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00097 (0.00090)	Tok/s 54934 (53136)	Loss/tok 3.4736 (3.3896)	Learning Rate [0.00125]
5: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00093 (0.00095)	Tok/s 54865 (53231)	Loss/tok 3.8623 (3.3892)	Learning Rate [0.00125]
1: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00093 (0.00096)	Tok/s 55067 (52900)	Loss/tok 3.3755 (3.3851)	Learning Rate [0.00125]
3: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00100 (0.00098)	Tok/s 54923 (53049)	Loss/tok 3.4465 (3.3805)	Learning Rate [0.00125]
6: TRAIN [1][380/3416]	Time 0.064 (0.059)	Data 0.00100 (0.00102)	Tok/s 54853 (53304)	Loss/tok 3.4175 (3.3929)	Learning Rate [0.00125]
14: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00081 (0.00091)	Tok/s 44251 (53973)	Loss/tok 2.7887 (3.3881)	Learning Rate [0.00125]
0: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00083 (0.00091)	Tok/s 44366 (52852)	Loss/tok 3.4364 (3.4039)	Learning Rate [0.00125]
13: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00089 (0.00101)	Tok/s 44201 (53867)	Loss/tok 3.2199 (3.3817)	Learning Rate [0.00125]
1: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00080 (0.00095)	Tok/s 44358 (52929)	Loss/tok 3.1849 (3.3856)	Learning Rate [0.00125]
12: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00090 (0.00096)	Tok/s 44085 (53763)	Loss/tok 3.2927 (3.3944)	Learning Rate [0.00125]
15: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00097 (0.00092)	Tok/s 44344 (54078)	Loss/tok 3.1672 (3.3874)	Learning Rate [0.00125]
2: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00090 (0.00097)	Tok/s 44413 (53002)	Loss/tok 3.2416 (3.3961)	Learning Rate [0.00125]
11: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00093 (0.00099)	Tok/s 44149 (53663)	Loss/tok 3.4716 (3.3973)	Learning Rate [0.00125]
10: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00092 (0.00097)	Tok/s 44101 (53592)	Loss/tok 3.4742 (3.3931)	Learning Rate [0.00125]
3: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00086 (0.00098)	Tok/s 44406 (53077)	Loss/tok 3.3011 (3.3824)	Learning Rate [0.00125]
4: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00095 (0.00090)	Tok/s 44339 (53162)	Loss/tok 3.0812 (3.3905)	Learning Rate [0.00125]
5: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00085 (0.00095)	Tok/s 44332 (53255)	Loss/tok 3.1467 (3.3905)	Learning Rate [0.00125]
8: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00088 (0.00099)	Tok/s 44178 (53480)	Loss/tok 3.5318 (3.3915)	Learning Rate [0.00125]
9: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00082 (0.00094)	Tok/s 44098 (53524)	Loss/tok 3.3687 (3.3974)	Learning Rate [0.00125]
6: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00093 (0.00102)	Tok/s 44273 (53326)	Loss/tok 3.2504 (3.3940)	Learning Rate [0.00125]
7: TRAIN [1][390/3416]	Time 0.046 (0.059)	Data 0.00103 (0.00094)	Tok/s 44161 (53410)	Loss/tok 3.2564 (3.3863)	Learning Rate [0.00125]
11: TRAIN [1][400/3416]	Time 0.068 (0.059)	Data 0.00093 (0.00099)	Tok/s 62774 (53796)	Loss/tok 3.7978 (3.4001)	Learning Rate [0.00125]
10: TRAIN [1][400/3416]	Time 0.068 (0.059)	Data 0.00091 (0.00096)	Tok/s 62763 (53726)	Loss/tok 3.7272 (3.3957)	Learning Rate [0.00125]
12: TRAIN [1][400/3416]	Time 0.068 (0.059)	Data 0.00091 (0.00096)	Tok/s 62675 (53895)	Loss/tok 3.4315 (3.3952)	Learning Rate [0.00125]
13: TRAIN [1][400/3416]	Time 0.068 (0.059)	Data 0.00090 (0.00101)	Tok/s 62617 (53998)	Loss/tok 3.5655 (3.3828)	Learning Rate [0.00125]
9: TRAIN [1][400/3416]	Time 0.068 (0.059)	Data 0.00087 (0.00094)	Tok/s 62762 (53658)	Loss/tok 3.6355 (3.3984)	Learning Rate [0.00125]
8: TRAIN [1][400/3416]	Time 0.068 (0.059)	Data 0.00092 (0.00099)	Tok/s 62741 (53611)	Loss/tok 3.3353 (3.3921)	Learning Rate [0.00125]
14: TRAIN [1][400/3416]	Time 0.069 (0.059)	Data 0.00085 (0.00091)	Tok/s 62532 (54101)	Loss/tok 3.5895 (3.3883)	Learning Rate [0.00125]
7: TRAIN [1][400/3416]	Time 0.068 (0.059)	Data 0.00098 (0.00094)	Tok/s 62772 (53539)	Loss/tok 3.4268 (3.3870)	Learning Rate [0.00125]
15: TRAIN [1][400/3416]	Time 0.069 (0.059)	Data 0.00098 (0.00092)	Tok/s 62501 (54204)	Loss/tok 3.8271 (3.3895)	Learning Rate [0.00125]
6: TRAIN [1][400/3416]	Time 0.068 (0.059)	Data 0.00102 (0.00102)	Tok/s 62685 (53457)	Loss/tok 3.4784 (3.3954)	Learning Rate [0.00125]
0: TRAIN [1][400/3416]	Time 0.069 (0.059)	Data 0.00086 (0.00091)	Tok/s 61854 (52983)	Loss/tok 3.5195 (3.4046)	Learning Rate [0.00125]
5: TRAIN [1][400/3416]	Time 0.069 (0.059)	Data 0.00092 (0.00095)	Tok/s 62580 (53384)	Loss/tok 3.6218 (3.3902)	Learning Rate [0.00125]
1: TRAIN [1][400/3416]	Time 0.069 (0.059)	Data 0.00087 (0.00095)	Tok/s 62435 (53060)	Loss/tok 3.4520 (3.3868)	Learning Rate [0.00125]
2: TRAIN [1][400/3416]	Time 0.069 (0.059)	Data 0.00092 (0.00097)	Tok/s 62443 (53131)	Loss/tok 3.5884 (3.3961)	Learning Rate [0.00125]
4: TRAIN [1][400/3416]	Time 0.069 (0.059)	Data 0.00085 (0.00090)	Tok/s 62492 (53290)	Loss/tok 3.5333 (3.3890)	Learning Rate [0.00125]
3: TRAIN [1][400/3416]	Time 0.069 (0.059)	Data 0.00091 (0.00098)	Tok/s 62446 (53207)	Loss/tok 3.5276 (3.3822)	Learning Rate [0.00125]
9: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00085 (0.00094)	Tok/s 53824 (53477)	Loss/tok 3.4661 (3.3975)	Learning Rate [0.00125]
10: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00093 (0.00096)	Tok/s 53776 (53543)	Loss/tok 3.5230 (3.3953)	Learning Rate [0.00125]
8: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00086 (0.00099)	Tok/s 53734 (53428)	Loss/tok 3.6378 (3.3922)	Learning Rate [0.00125]
7: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00100 (0.00094)	Tok/s 53595 (53356)	Loss/tok 3.7504 (3.3873)	Learning Rate [0.00125]
12: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00098 (0.00096)	Tok/s 53800 (53710)	Loss/tok 3.7064 (3.3954)	Learning Rate [0.00125]
6: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00093 (0.00102)	Tok/s 53528 (53271)	Loss/tok 3.3618 (3.3942)	Learning Rate [0.00125]
14: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00088 (0.00091)	Tok/s 53841 (53916)	Loss/tok 3.5453 (3.3868)	Learning Rate [0.00125]
13: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00089 (0.00101)	Tok/s 53782 (53813)	Loss/tok 3.2584 (3.3807)	Learning Rate [0.00125]
5: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00095 (0.00095)	Tok/s 53484 (53196)	Loss/tok 3.5593 (3.3902)	Learning Rate [0.00125]
4: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00085 (0.00090)	Tok/s 53513 (53104)	Loss/tok 3.3216 (3.3877)	Learning Rate [0.00125]
3: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00094 (0.00098)	Tok/s 53526 (53020)	Loss/tok 3.0835 (3.3814)	Learning Rate [0.00125]
2: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00096 (0.00097)	Tok/s 53511 (52946)	Loss/tok 3.3632 (3.3940)	Learning Rate [0.00125]
1: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00090 (0.00095)	Tok/s 53527 (52873)	Loss/tok 3.4482 (3.3860)	Learning Rate [0.00125]
0: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00087 (0.00091)	Tok/s 53525 (52795)	Loss/tok 3.6753 (3.4043)	Learning Rate [0.00125]
15: TRAIN [1][410/3416]	Time 0.062 (0.059)	Data 0.00096 (0.00092)	Tok/s 53907 (54020)	Loss/tok 3.6083 (3.3884)	Learning Rate [0.00125]
11: TRAIN [1][410/3416]	Time 0.063 (0.059)	Data 0.00097 (0.00099)	Tok/s 52692 (53610)	Loss/tok 3.2934 (3.3994)	Learning Rate [0.00125]
11: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
13: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00098 (0.00100)	Tok/s 48474 (53837)	Loss/tok 3.4516 (3.3799)	Learning Rate [0.00125]
12: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00092 (0.00096)	Tok/s 48495 (53733)	Loss/tok 3.3728 (3.3962)	Learning Rate [0.00125]
14: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00088 (0.00091)	Tok/s 48323 (53937)	Loss/tok 3.2986 (3.3898)	Learning Rate [0.00125]
11: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00089 (0.00098)	Tok/s 48445 (53639)	Loss/tok 3.2867 (3.3997)	Learning Rate [0.00125]
15: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00095 (0.00092)	Tok/s 49424 (54041)	Loss/tok 3.4808 (3.3902)	Learning Rate [0.00125]
0: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00089 (0.00091)	Tok/s 48154 (52822)	Loss/tok 3.2696 (3.4045)	Learning Rate [0.00125]
10: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00096 (0.00096)	Tok/s 48353 (53570)	Loss/tok 3.2330 (3.3963)	Learning Rate [0.00125]
9: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00092 (0.00094)	Tok/s 48408 (53501)	Loss/tok 3.3913 (3.3986)	Learning Rate [0.00125]
2: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00096 (0.00097)	Tok/s 48194 (52975)	Loss/tok 3.3260 (3.3958)	Learning Rate [0.00125]
1: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00092 (0.00095)	Tok/s 48126 (52901)	Loss/tok 3.0751 (3.3859)	Learning Rate [0.00125]
8: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00096 (0.00099)	Tok/s 48397 (53450)	Loss/tok 3.3834 (3.3935)	Learning Rate [0.00125]
3: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00090 (0.00098)	Tok/s 48198 (53048)	Loss/tok 3.1390 (3.3832)	Learning Rate [0.00125]
6: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00097 (0.00102)	Tok/s 48359 (53296)	Loss/tok 2.9613 (3.3935)	Learning Rate [0.00125]
7: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00103 (0.00094)	Tok/s 48469 (53379)	Loss/tok 3.1891 (3.3887)	Learning Rate [0.00125]
4: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00091 (0.00089)	Tok/s 48166 (53131)	Loss/tok 3.3489 (3.3892)	Learning Rate [0.00125]
5: TRAIN [1][420/3416]	Time 0.048 (0.059)	Data 0.00094 (0.00095)	Tok/s 48279 (53223)	Loss/tok 3.4026 (3.3924)	Learning Rate [0.00125]
2: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00097)	Tok/s 51260 (52928)	Loss/tok 3.3220 (3.3942)	Learning Rate [0.00125]
3: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00092 (0.00098)	Tok/s 51148 (53000)	Loss/tok 3.6198 (3.3832)	Learning Rate [0.00125]
1: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00095)	Tok/s 51201 (52855)	Loss/tok 3.4632 (3.3860)	Learning Rate [0.00125]
4: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00086 (0.00089)	Tok/s 50976 (53084)	Loss/tok 3.3614 (3.3888)	Learning Rate [0.00125]
0: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00091)	Tok/s 51203 (52778)	Loss/tok 3.4508 (3.4058)	Learning Rate [0.00125]
15: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00092)	Tok/s 51228 (54000)	Loss/tok 3.2990 (3.3896)	Learning Rate [0.00125]
5: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00095)	Tok/s 50900 (53175)	Loss/tok 3.5421 (3.3923)	Learning Rate [0.00125]
14: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00091)	Tok/s 51170 (53890)	Loss/tok 3.2503 (3.3886)	Learning Rate [0.00125]
13: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00094 (0.00100)	Tok/s 51186 (53786)	Loss/tok 3.3244 (3.3791)	Learning Rate [0.00125]
6: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00106 (0.00101)	Tok/s 51055 (53248)	Loss/tok 3.4939 (3.3912)	Learning Rate [0.00125]
12: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00096)	Tok/s 51153 (53685)	Loss/tok 3.5419 (3.3972)	Learning Rate [0.00125]
7: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00100 (0.00094)	Tok/s 50863 (53329)	Loss/tok 3.2342 (3.3872)	Learning Rate [0.00125]
10: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00096)	Tok/s 50964 (53523)	Loss/tok 3.4928 (3.3947)	Learning Rate [0.00125]
11: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00095 (0.00098)	Tok/s 51048 (53590)	Loss/tok 3.4465 (3.3974)	Learning Rate [0.00125]
8: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00106 (0.00099)	Tok/s 50894 (53404)	Loss/tok 3.0656 (3.3934)	Learning Rate [0.00125]
9: TRAIN [1][430/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00094)	Tok/s 50880 (53456)	Loss/tok 3.3092 (3.3965)	Learning Rate [0.00125]
7: Gradient norm: inf
6: Gradient norm: inf
8: Gradient norm: inf
13: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
12: Gradient norm: inf
5: Gradient norm: inf
0: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
11: Gradient norm: inf
14: Gradient norm: inf
1: Gradient norm: inf
10: Gradient norm: inf
4: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
10: TRAIN [1][440/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00096)	Tok/s 48329 (53485)	Loss/tok 3.1400 (3.3920)	Learning Rate [0.00125]
11: TRAIN [1][440/3416]	Time 0.046 (0.058)	Data 0.00102 (0.00098)	Tok/s 48222 (53550)	Loss/tok 3.1695 (3.3966)	Learning Rate [0.00125]
12: TRAIN [1][440/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00096)	Tok/s 48105 (53646)	Loss/tok 3.4236 (3.3970)	Learning Rate [0.00125]
13: TRAIN [1][440/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00100)	Tok/s 47937 (53747)	Loss/tok 3.1996 (3.3790)	Learning Rate [0.00125]
14: TRAIN [1][440/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00091)	Tok/s 47939 (53851)	Loss/tok 3.2284 (3.3873)	Learning Rate [0.00125]
8: TRAIN [1][440/3416]	Time 0.046 (0.058)	Data 0.00106 (0.00099)	Tok/s 48275 (53366)	Loss/tok 3.4147 (3.3919)	Learning Rate [0.00125]
15: TRAIN [1][440/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00092)	Tok/s 47965 (53957)	Loss/tok 3.1313 (3.3890)	Learning Rate [0.00125]
7: TRAIN [1][440/3416]	Time 0.046 (0.058)	Data 0.00117 (0.00095)	Tok/s 48226 (53292)	Loss/tok 3.3177 (3.3870)	Learning Rate [0.00125]
6: TRAIN [1][440/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00101)	Tok/s 48264 (53208)	Loss/tok 3.3626 (3.3913)	Learning Rate [0.00125]
0: TRAIN [1][440/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00091)	Tok/s 47826 (52736)	Loss/tok 3.2223 (3.4049)	Learning Rate [0.00125]
5: TRAIN [1][440/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00095)	Tok/s 48183 (53136)	Loss/tok 3.1591 (3.3909)	Learning Rate [0.00125]
4: TRAIN [1][440/3416]	Time 0.047 (0.058)	Data 0.00109 (0.00089)	Tok/s 48161 (53044)	Loss/tok 3.2493 (3.3869)	Learning Rate [0.00125]
2: TRAIN [1][440/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00097)	Tok/s 47989 (52883)	Loss/tok 3.4544 (3.3931)	Learning Rate [0.00125]
3: TRAIN [1][440/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00098)	Tok/s 48057 (52957)	Loss/tok 3.3976 (3.3826)	Learning Rate [0.00125]
9: TRAIN [1][440/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00094)	Tok/s 47537 (53416)	Loss/tok 3.0321 (3.3950)	Learning Rate [0.00125]
1: TRAIN [1][440/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00095)	Tok/s 47245 (52811)	Loss/tok 3.2182 (3.3856)	Learning Rate [0.00125]
10: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00085 (0.00096)	Tok/s 52079 (53608)	Loss/tok 3.3981 (3.3958)	Learning Rate [0.00125]
11: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00081 (0.00098)	Tok/s 52097 (53673)	Loss/tok 3.2399 (3.3986)	Learning Rate [0.00125]
12: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00088 (0.00096)	Tok/s 52894 (53771)	Loss/tok 3.4306 (3.3974)	Learning Rate [0.00125]
9: TRAIN [1][450/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00094)	Tok/s 52130 (53540)	Loss/tok 3.2853 (3.3963)	Learning Rate [0.00125]
14: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00094 (0.00091)	Tok/s 53252 (53975)	Loss/tok 3.4109 (3.3898)	Learning Rate [0.00125]
7: TRAIN [1][450/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00095)	Tok/s 52082 (53413)	Loss/tok 3.4820 (3.3883)	Learning Rate [0.00125]
15: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00095 (0.00093)	Tok/s 53238 (54081)	Loss/tok 3.4193 (3.3888)	Learning Rate [0.00125]
8: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00088 (0.00099)	Tok/s 52165 (53489)	Loss/tok 3.1714 (3.3948)	Learning Rate [0.00125]
6: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00092 (0.00101)	Tok/s 52111 (53330)	Loss/tok 3.3095 (3.3934)	Learning Rate [0.00125]
0: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00083 (0.00091)	Tok/s 51962 (52862)	Loss/tok 3.0743 (3.4056)	Learning Rate [0.00125]
5: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00092 (0.00095)	Tok/s 52082 (53260)	Loss/tok 3.5198 (3.3910)	Learning Rate [0.00125]
4: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00084 (0.00089)	Tok/s 52089 (53170)	Loss/tok 3.4718 (3.3879)	Learning Rate [0.00125]
1: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00085 (0.00095)	Tok/s 52006 (52938)	Loss/tok 3.2015 (3.3875)	Learning Rate [0.00125]
2: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00085 (0.00097)	Tok/s 52001 (53008)	Loss/tok 3.4591 (3.3952)	Learning Rate [0.00125]
13: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00107 (0.00100)	Tok/s 53196 (53871)	Loss/tok 3.3211 (3.3806)	Learning Rate [0.00125]
3: TRAIN [1][450/3416]	Time 0.052 (0.059)	Data 0.00121 (0.00098)	Tok/s 52001 (53081)	Loss/tok 3.4986 (3.3847)	Learning Rate [0.00125]
12: TRAIN [1][460/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00096)	Tok/s 56783 (53758)	Loss/tok 3.4716 (3.4000)	Learning Rate [0.00125]
10: TRAIN [1][460/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00096)	Tok/s 56662 (53596)	Loss/tok 3.5162 (3.3970)	Learning Rate [0.00125]
11: TRAIN [1][460/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00098)	Tok/s 56764 (53662)	Loss/tok 3.4607 (3.3995)	Learning Rate [0.00125]
13: TRAIN [1][460/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00100)	Tok/s 56740 (53857)	Loss/tok 3.5164 (3.3807)	Learning Rate [0.00125]
9: TRAIN [1][460/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00094)	Tok/s 56634 (53529)	Loss/tok 3.6364 (3.3982)	Learning Rate [0.00125]
14: TRAIN [1][460/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00091)	Tok/s 56682 (53958)	Loss/tok 3.5052 (3.3909)	Learning Rate [0.00125]
8: TRAIN [1][460/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00099)	Tok/s 56623 (53476)	Loss/tok 3.5414 (3.3967)	Learning Rate [0.00125]
4: TRAIN [1][460/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00089)	Tok/s 56522 (53160)	Loss/tok 3.3529 (3.3888)	Learning Rate [0.00125]
0: TRAIN [1][460/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00092)	Tok/s 56553 (52854)	Loss/tok 3.3196 (3.4049)	Learning Rate [0.00125]
15: TRAIN [1][460/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00093)	Tok/s 57182 (54062)	Loss/tok 3.4470 (3.3910)	Learning Rate [0.00125]
7: TRAIN [1][460/3416]	Time 0.066 (0.058)	Data 0.00100 (0.00095)	Tok/s 56607 (53400)	Loss/tok 3.6418 (3.3895)	Learning Rate [0.00125]
2: TRAIN [1][460/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00097)	Tok/s 56422 (53000)	Loss/tok 3.5188 (3.3948)	Learning Rate [0.00125]
1: TRAIN [1][460/3416]	Time 0.066 (0.058)	Data 0.00094 (0.00095)	Tok/s 56477 (52930)	Loss/tok 3.7109 (3.3876)	Learning Rate [0.00125]
3: TRAIN [1][460/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00098)	Tok/s 56475 (53074)	Loss/tok 3.3150 (3.3848)	Learning Rate [0.00125]
5: TRAIN [1][460/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00095)	Tok/s 56537 (53248)	Loss/tok 3.3977 (3.3914)	Learning Rate [0.00125]
6: TRAIN [1][460/3416]	Time 0.066 (0.058)	Data 0.00105 (0.00101)	Tok/s 56578 (53319)	Loss/tok 3.5572 (3.3930)	Learning Rate [0.00125]
14: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00091)	Tok/s 74356 (53917)	Loss/tok 3.5086 (3.3908)	Learning Rate [0.00125]
15: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 74362 (54021)	Loss/tok 3.6395 (3.3923)	Learning Rate [0.00125]
0: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 73389 (52821)	Loss/tok 3.6175 (3.4045)	Learning Rate [0.00125]
13: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00100)	Tok/s 74267 (53819)	Loss/tok 3.3609 (3.3798)	Learning Rate [0.00125]
12: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00096)	Tok/s 74264 (53720)	Loss/tok 3.2151 (3.3991)	Learning Rate [0.00125]
10: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00096)	Tok/s 74298 (53561)	Loss/tok 3.4476 (3.3972)	Learning Rate [0.00125]
2: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 73417 (52965)	Loss/tok 3.5585 (3.3961)	Learning Rate [0.00125]
11: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 74255 (53625)	Loss/tok 3.3713 (3.3980)	Learning Rate [0.00125]
1: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00095)	Tok/s 73363 (52896)	Loss/tok 3.5268 (3.3880)	Learning Rate [0.00125]
8: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00099)	Tok/s 74277 (53441)	Loss/tok 3.4948 (3.3977)	Learning Rate [0.00125]
9: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00094)	Tok/s 74292 (53496)	Loss/tok 3.2917 (3.3981)	Learning Rate [0.00125]
4: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00089)	Tok/s 73328 (53126)	Loss/tok 3.3457 (3.3890)	Learning Rate [0.00125]
3: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 73353 (53041)	Loss/tok 3.7190 (3.3879)	Learning Rate [0.00125]
6: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00101)	Tok/s 73931 (53285)	Loss/tok 3.6216 (3.3938)	Learning Rate [0.00125]
7: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00095)	Tok/s 74204 (53365)	Loss/tok 3.3852 (3.3898)	Learning Rate [0.00125]
5: TRAIN [1][470/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00095)	Tok/s 73366 (53214)	Loss/tok 3.4345 (3.3921)	Learning Rate [0.00125]
8: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00099)	Tok/s 52016 (53396)	Loss/tok 3.2592 (3.3965)	Learning Rate [0.00125]
6: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00101)	Tok/s 52150 (53238)	Loss/tok 3.4708 (3.3955)	Learning Rate [0.00125]
7: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00095)	Tok/s 52133 (53318)	Loss/tok 3.3420 (3.3889)	Learning Rate [0.00125]
4: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00089)	Tok/s 52140 (53080)	Loss/tok 3.2243 (3.3886)	Learning Rate [0.00125]
5: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00095)	Tok/s 52103 (53169)	Loss/tok 3.1939 (3.3914)	Learning Rate [0.00125]
9: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00094)	Tok/s 52622 (53453)	Loss/tok 3.5562 (3.3987)	Learning Rate [0.00125]
10: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00096)	Tok/s 52978 (53518)	Loss/tok 3.4666 (3.3966)	Learning Rate [0.00125]
2: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00097)	Tok/s 52122 (52915)	Loss/tok 3.2657 (3.3941)	Learning Rate [0.00125]
3: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00098)	Tok/s 52129 (52995)	Loss/tok 3.6364 (3.3879)	Learning Rate [0.00125]
12: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00096)	Tok/s 52850 (53675)	Loss/tok 3.4616 (3.3985)	Learning Rate [0.00125]
0: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00092)	Tok/s 51945 (52771)	Loss/tok 3.5306 (3.4038)	Learning Rate [0.00125]
1: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00095)	Tok/s 51971 (52845)	Loss/tok 3.2667 (3.3881)	Learning Rate [0.00125]
13: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00100)	Tok/s 52822 (53772)	Loss/tok 3.2682 (3.3778)	Learning Rate [0.00125]
14: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00091)	Tok/s 52893 (53870)	Loss/tok 3.4499 (3.3910)	Learning Rate [0.00125]
15: TRAIN [1][480/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00093)	Tok/s 52907 (53976)	Loss/tok 3.5106 (3.3905)	Learning Rate [0.00125]
11: TRAIN [1][480/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00098)	Tok/s 52342 (53579)	Loss/tok 3.4789 (3.3986)	Learning Rate [0.00125]
11: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00098)	Tok/s 71435 (53557)	Loss/tok 3.3597 (3.3964)	Learning Rate [0.00125]
12: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 71440 (53651)	Loss/tok 3.3294 (3.3967)	Learning Rate [0.00125]
13: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 71436 (53747)	Loss/tok 3.2782 (3.3760)	Learning Rate [0.00125]
10: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00096)	Tok/s 71414 (53495)	Loss/tok 3.6973 (3.3969)	Learning Rate [0.00125]
9: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00094)	Tok/s 71425 (53430)	Loss/tok 3.7950 (3.3981)	Learning Rate [0.00125]
8: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00099)	Tok/s 71414 (53374)	Loss/tok 3.3991 (3.3959)	Learning Rate [0.00125]
14: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 71246 (53844)	Loss/tok 3.2444 (3.3889)	Learning Rate [0.00125]
15: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 71126 (53953)	Loss/tok 3.6567 (3.3909)	Learning Rate [0.00125]
6: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00101)	Tok/s 71218 (53216)	Loss/tok 3.6736 (3.3958)	Learning Rate [0.00125]
0: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 70140 (52744)	Loss/tok 3.3337 (3.4026)	Learning Rate [0.00125]
4: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00089)	Tok/s 70292 (53058)	Loss/tok 3.4815 (3.3882)	Learning Rate [0.00125]
1: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00095)	Tok/s 70138 (52819)	Loss/tok 3.5256 (3.3875)	Learning Rate [0.00125]
5: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00095)	Tok/s 70425 (53145)	Loss/tok 3.6796 (3.3904)	Learning Rate [0.00125]
3: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 70157 (52972)	Loss/tok 3.4389 (3.3866)	Learning Rate [0.00125]
2: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 70131 (52889)	Loss/tok 3.5016 (3.3935)	Learning Rate [0.00125]
7: TRAIN [1][490/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00095)	Tok/s 71312 (53297)	Loss/tok 3.3531 (3.3868)	Learning Rate [0.00125]
2: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00097)	Tok/s 56430 (52853)	Loss/tok 3.3747 (3.3920)	Learning Rate [0.00125]
0: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00092)	Tok/s 56492 (52707)	Loss/tok 3.5795 (3.4018)	Learning Rate [0.00125]
1: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00094)	Tok/s 56437 (52782)	Loss/tok 3.4561 (3.3857)	Learning Rate [0.00125]
3: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00098)	Tok/s 56417 (52936)	Loss/tok 3.4068 (3.3850)	Learning Rate [0.00125]
15: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00093)	Tok/s 57409 (53917)	Loss/tok 3.4869 (3.3904)	Learning Rate [0.00125]
5: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00095)	Tok/s 56412 (53110)	Loss/tok 3.5387 (3.3913)	Learning Rate [0.00125]
6: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00101)	Tok/s 57135 (53181)	Loss/tok 3.4954 (3.3959)	Learning Rate [0.00125]
14: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00092)	Tok/s 57397 (53806)	Loss/tok 3.3310 (3.3886)	Learning Rate [0.00125]
7: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00095)	Tok/s 57404 (53261)	Loss/tok 3.0582 (3.3866)	Learning Rate [0.00125]
8: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00099)	Tok/s 57393 (53335)	Loss/tok 3.5382 (3.3943)	Learning Rate [0.00125]
13: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00100)	Tok/s 57382 (53710)	Loss/tok 3.6226 (3.3764)	Learning Rate [0.00125]
10: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00096)	Tok/s 57427 (53456)	Loss/tok 3.7297 (3.3972)	Learning Rate [0.00125]
9: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00094)	Tok/s 57414 (53390)	Loss/tok 3.3596 (3.3966)	Learning Rate [0.00125]
12: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00095)	Tok/s 57386 (53616)	Loss/tok 3.4349 (3.3955)	Learning Rate [0.00125]
11: TRAIN [1][500/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00098)	Tok/s 57434 (53520)	Loss/tok 3.5486 (3.3958)	Learning Rate [0.00125]
4: TRAIN [1][500/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00089)	Tok/s 55470 (53020)	Loss/tok 3.5255 (3.3868)	Learning Rate [0.00125]
7: TRAIN [1][510/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00095)	Tok/s 71982 (53259)	Loss/tok 3.3695 (3.3867)	Learning Rate [0.00125]
6: TRAIN [1][510/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00101)	Tok/s 71992 (53179)	Loss/tok 3.7064 (3.3966)	Learning Rate [0.00125]
8: TRAIN [1][510/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00099)	Tok/s 71815 (53332)	Loss/tok 3.5139 (3.3941)	Learning Rate [0.00125]
5: TRAIN [1][510/3416]	Time 0.069 (0.058)	Data 0.00113 (0.00095)	Tok/s 71875 (53106)	Loss/tok 3.6103 (3.3925)	Learning Rate [0.00125]
9: TRAIN [1][510/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00094)	Tok/s 71669 (53388)	Loss/tok 3.4569 (3.3979)	Learning Rate [0.00125]
4: TRAIN [1][510/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00089)	Tok/s 71005 (53017)	Loss/tok 3.5140 (3.3877)	Learning Rate [0.00125]
10: TRAIN [1][510/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00096)	Tok/s 71569 (53452)	Loss/tok 3.6613 (3.3963)	Learning Rate [0.00125]
3: TRAIN [1][510/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 71013 (52931)	Loss/tok 3.5572 (3.3865)	Learning Rate [0.00125]
11: TRAIN [1][510/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00098)	Tok/s 71587 (53516)	Loss/tok 3.4995 (3.3962)	Learning Rate [0.00125]
12: TRAIN [1][510/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00095)	Tok/s 71522 (53614)	Loss/tok 3.1852 (3.3955)	Learning Rate [0.00125]
13: TRAIN [1][510/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00100)	Tok/s 71576 (53706)	Loss/tok 3.5802 (3.3779)	Learning Rate [0.00125]
1: TRAIN [1][510/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00094)	Tok/s 70894 (52773)	Loss/tok 3.5166 (3.3880)	Learning Rate [0.00125]
0: TRAIN [1][510/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 70855 (52698)	Loss/tok 3.3640 (3.4005)	Learning Rate [0.00125]
2: TRAIN [1][510/3416]	Time 0.069 (0.058)	Data 0.00130 (0.00097)	Tok/s 71032 (52849)	Loss/tok 3.4605 (3.3932)	Learning Rate [0.00125]
14: TRAIN [1][510/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00092)	Tok/s 71513 (53800)	Loss/tok 3.4202 (3.3885)	Learning Rate [0.00125]
15: TRAIN [1][510/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 71685 (53910)	Loss/tok 3.6125 (3.3937)	Learning Rate [0.00125]
8: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00099)	Tok/s 57273 (53279)	Loss/tok 3.6269 (3.3943)	Learning Rate [0.00125]
9: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00094)	Tok/s 57710 (53337)	Loss/tok 3.2323 (3.3988)	Learning Rate [0.00125]
7: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00095)	Tok/s 57257 (53206)	Loss/tok 3.5496 (3.3874)	Learning Rate [0.00125]
10: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00096)	Tok/s 58153 (53402)	Loss/tok 3.4780 (3.3963)	Learning Rate [0.00125]
6: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00101)	Tok/s 57237 (53127)	Loss/tok 3.6986 (3.3976)	Learning Rate [0.00125]
4: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00089)	Tok/s 57275 (52967)	Loss/tok 3.7307 (3.3886)	Learning Rate [0.00125]
5: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00095)	Tok/s 57293 (53056)	Loss/tok 3.3492 (3.3924)	Learning Rate [0.00125]
12: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00095)	Tok/s 58151 (53564)	Loss/tok 3.6387 (3.3968)	Learning Rate [0.00125]
3: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 57305 (52881)	Loss/tok 3.4955 (3.3860)	Learning Rate [0.00125]
11: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00098)	Tok/s 58236 (53466)	Loss/tok 3.3573 (3.3966)	Learning Rate [0.00125]
13: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 58195 (53657)	Loss/tok 3.2338 (3.3760)	Learning Rate [0.00125]
2: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 57296 (52801)	Loss/tok 3.7117 (3.3946)	Learning Rate [0.00125]
14: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 58086 (53750)	Loss/tok 3.5448 (3.3887)	Learning Rate [0.00125]
1: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00094)	Tok/s 57259 (52726)	Loss/tok 3.8793 (3.3895)	Learning Rate [0.00125]
15: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 58076 (53859)	Loss/tok 3.4545 (3.3946)	Learning Rate [0.00125]
0: TRAIN [1][520/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 57212 (52650)	Loss/tok 3.6103 (3.4013)	Learning Rate [0.00125]
11: TRAIN [1][530/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 59884 (53445)	Loss/tok 3.5923 (3.3964)	Learning Rate [0.00125]
10: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00096)	Tok/s 59848 (53382)	Loss/tok 3.5680 (3.3954)	Learning Rate [0.00125]
12: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00095)	Tok/s 59742 (53541)	Loss/tok 3.8650 (3.3970)	Learning Rate [0.00125]
9: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00094)	Tok/s 59231 (53317)	Loss/tok 3.6957 (3.4001)	Learning Rate [0.00125]
14: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 59591 (53729)	Loss/tok 3.6868 (3.3890)	Learning Rate [0.00125]
8: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00099)	Tok/s 58767 (53259)	Loss/tok 3.7304 (3.3948)	Learning Rate [0.00125]
7: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00095)	Tok/s 58732 (53186)	Loss/tok 3.5339 (3.3870)	Learning Rate [0.00125]
15: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 59492 (53839)	Loss/tok 3.5444 (3.3948)	Learning Rate [0.00125]
13: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00100)	Tok/s 59657 (53636)	Loss/tok 3.5912 (3.3770)	Learning Rate [0.00125]
6: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00101)	Tok/s 58637 (53107)	Loss/tok 3.4390 (3.3966)	Learning Rate [0.00125]
5: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 58518 (53037)	Loss/tok 3.5630 (3.3919)	Learning Rate [0.00125]
4: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00089)	Tok/s 58447 (52946)	Loss/tok 3.6370 (3.3897)	Learning Rate [0.00125]
1: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00094)	Tok/s 58393 (52703)	Loss/tok 3.6227 (3.3883)	Learning Rate [0.00125]
2: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 58302 (52778)	Loss/tok 3.5901 (3.3929)	Learning Rate [0.00125]
3: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 58345 (52858)	Loss/tok 3.5676 (3.3848)	Learning Rate [0.00125]
0: TRAIN [1][530/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 58473 (52628)	Loss/tok 3.5375 (3.4012)	Learning Rate [0.00125]
5: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00094 (0.00096)	Tok/s 20053 (52924)	Loss/tok 2.2531 (3.3907)	Learning Rate [0.00125]
4: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00087 (0.00089)	Tok/s 18190 (52830)	Loss/tok 2.0206 (3.3883)	Learning Rate [0.00125]
7: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00080 (0.00094)	Tok/s 21938 (53079)	Loss/tok 2.4595 (3.3863)	Learning Rate [0.00125]
8: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00085 (0.00099)	Tok/s 23575 (53159)	Loss/tok 2.0922 (3.3930)	Learning Rate [0.00125]
2: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00093 (0.00097)	Tok/s 15419 (52657)	Loss/tok 1.9049 (3.3929)	Learning Rate [0.00125]
3: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00091 (0.00097)	Tok/s 16336 (52739)	Loss/tok 1.7005 (3.3851)	Learning Rate [0.00125]
9: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00093 (0.00094)	Tok/s 23680 (53216)	Loss/tok 2.1182 (3.3999)	Learning Rate [0.00125]
10: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00102 (0.00096)	Tok/s 23610 (53280)	Loss/tok 2.0191 (3.3936)	Learning Rate [0.00125]
11: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00091 (0.00097)	Tok/s 23577 (53342)	Loss/tok 1.9943 (3.3954)	Learning Rate [0.00125]
12: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00098 (0.00095)	Tok/s 25077 (53441)	Loss/tok 2.3487 (3.3963)	Learning Rate [0.00125]
1: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00084 (0.00094)	Tok/s 12874 (52579)	Loss/tok 1.9238 (3.3881)	Learning Rate [0.00125]
13: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00096 (0.00100)	Tok/s 25410 (53539)	Loss/tok 2.3739 (3.3771)	Learning Rate [0.00125]
15: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00085 (0.00092)	Tok/s 27264 (53744)	Loss/tok 2.4470 (3.3928)	Learning Rate [0.00125]
14: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00090 (0.00092)	Tok/s 26515 (53635)	Loss/tok 2.2901 (3.3874)	Learning Rate [0.00125]
6: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00099 (0.00101)	Tok/s 21126 (52996)	Loss/tok 2.3037 (3.3960)	Learning Rate [0.00125]
0: TRAIN [1][540/3416]	Time 0.035 (0.058)	Data 0.00086 (0.00092)	Tok/s 9250 (52497)	Loss/tok 1.5795 (3.4007)	Learning Rate [0.00125]
15: TRAIN [1][550/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00092)	Tok/s 51712 (53784)	Loss/tok 3.5262 (3.3937)	Learning Rate [0.00125]
14: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00110 (0.00092)	Tok/s 51621 (53676)	Loss/tok 3.4147 (3.3898)	Learning Rate [0.00125]
13: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00100)	Tok/s 51651 (53580)	Loss/tok 3.5575 (3.3791)	Learning Rate [0.00125]
12: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00085 (0.00095)	Tok/s 51538 (53480)	Loss/tok 3.3162 (3.3969)	Learning Rate [0.00125]
2: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00097)	Tok/s 51307 (52707)	Loss/tok 3.4637 (3.3941)	Learning Rate [0.00125]
11: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00088 (0.00097)	Tok/s 51501 (53383)	Loss/tok 3.4971 (3.3984)	Learning Rate [0.00125]
3: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00097)	Tok/s 51205 (52787)	Loss/tok 3.4330 (3.3866)	Learning Rate [0.00125]
10: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00097)	Tok/s 51401 (53322)	Loss/tok 3.3311 (3.3948)	Learning Rate [0.00125]
4: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00109 (0.00089)	Tok/s 51114 (52876)	Loss/tok 3.4183 (3.3893)	Learning Rate [0.00125]
5: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00124 (0.00096)	Tok/s 51003 (52969)	Loss/tok 3.4353 (3.3902)	Learning Rate [0.00125]
9: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00107 (0.00094)	Tok/s 51270 (53259)	Loss/tok 3.4190 (3.4019)	Learning Rate [0.00125]
8: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00098)	Tok/s 51118 (53202)	Loss/tok 3.3989 (3.3945)	Learning Rate [0.00125]
7: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00094)	Tok/s 51049 (53122)	Loss/tok 3.2369 (3.3868)	Learning Rate [0.00125]
0: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00092)	Tok/s 51555 (52550)	Loss/tok 3.6292 (3.4033)	Learning Rate [0.00125]
6: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00105 (0.00101)	Tok/s 51014 (53041)	Loss/tok 3.4459 (3.3969)	Learning Rate [0.00125]
1: TRAIN [1][550/3416]	Time 0.055 (0.058)	Data 0.00124 (0.00094)	Tok/s 51472 (52628)	Loss/tok 3.3123 (3.3884)	Learning Rate [0.00125]
13: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00100)	Tok/s 33531 (53364)	Loss/tok 3.0209 (3.3764)	Learning Rate [0.00125]
10: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00097)	Tok/s 33527 (53105)	Loss/tok 2.9737 (3.3924)	Learning Rate [0.00125]
3: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00097)	Tok/s 33379 (52569)	Loss/tok 3.2190 (3.3837)	Learning Rate [0.00125]
12: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00095)	Tok/s 33501 (53265)	Loss/tok 3.1906 (3.3947)	Learning Rate [0.00125]
14: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00082 (0.00092)	Tok/s 34396 (53460)	Loss/tok 3.1198 (3.3880)	Learning Rate [0.00125]
2: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00080 (0.00097)	Tok/s 33291 (52488)	Loss/tok 2.9809 (3.3917)	Learning Rate [0.00125]
11: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00097)	Tok/s 33485 (53166)	Loss/tok 2.8789 (3.3962)	Learning Rate [0.00125]
15: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00092)	Tok/s 34587 (53571)	Loss/tok 3.1690 (3.3907)	Learning Rate [0.00125]
4: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00089)	Tok/s 33301 (52658)	Loss/tok 3.2344 (3.3872)	Learning Rate [0.00125]
1: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00094)	Tok/s 33249 (52408)	Loss/tok 2.9319 (3.3852)	Learning Rate [0.00125]
9: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00094)	Tok/s 33537 (53043)	Loss/tok 3.1737 (3.4000)	Learning Rate [0.00125]
5: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00096)	Tok/s 33318 (52750)	Loss/tok 3.0283 (3.3888)	Learning Rate [0.00125]
8: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00098)	Tok/s 33403 (52985)	Loss/tok 3.1587 (3.3920)	Learning Rate [0.00125]
6: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00101)	Tok/s 33289 (52823)	Loss/tok 2.9362 (3.3948)	Learning Rate [0.00125]
0: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 33310 (52325)	Loss/tok 2.9572 (3.4002)	Learning Rate [0.00125]
7: TRAIN [1][560/3416]	Time 0.052 (0.058)	Data 0.00079 (0.00094)	Tok/s 33243 (52906)	Loss/tok 3.2830 (3.3840)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
12: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00095)	Tok/s 52398 (53097)	Loss/tok 3.1022 (3.3916)	Learning Rate [0.00125]
11: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00097)	Tok/s 52365 (52997)	Loss/tok 3.2273 (3.3944)	Learning Rate [0.00125]
13: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00100)	Tok/s 52281 (53194)	Loss/tok 3.5047 (3.3754)	Learning Rate [0.00125]
14: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00092)	Tok/s 52214 (53295)	Loss/tok 3.3856 (3.3851)	Learning Rate [0.00125]
10: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00097)	Tok/s 52399 (52934)	Loss/tok 3.4692 (3.3903)	Learning Rate [0.00125]
9: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00094)	Tok/s 52442 (52874)	Loss/tok 3.3271 (3.3974)	Learning Rate [0.00125]
15: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00092)	Tok/s 52075 (53405)	Loss/tok 3.5982 (3.3892)	Learning Rate [0.00125]
8: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00099)	Tok/s 52387 (52816)	Loss/tok 3.3213 (3.3901)	Learning Rate [0.00125]
7: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00094)	Tok/s 52365 (52735)	Loss/tok 3.2075 (3.3830)	Learning Rate [0.00125]
4: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00089)	Tok/s 52244 (52479)	Loss/tok 3.4059 (3.3858)	Learning Rate [0.00125]
1: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00094)	Tok/s 52073 (52218)	Loss/tok 3.3016 (3.3845)	Learning Rate [0.00125]
5: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00096)	Tok/s 52308 (52574)	Loss/tok 3.3527 (3.3877)	Learning Rate [0.00125]
6: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00101)	Tok/s 52361 (52648)	Loss/tok 3.5849 (3.3930)	Learning Rate [0.00125]
3: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00097)	Tok/s 52147 (52387)	Loss/tok 3.2845 (3.3821)	Learning Rate [0.00125]
2: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00114 (0.00097)	Tok/s 52123 (52302)	Loss/tok 3.3463 (3.3909)	Learning Rate [0.00125]
0: TRAIN [1][570/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00092)	Tok/s 52071 (52129)	Loss/tok 3.2943 (3.3989)	Learning Rate [0.00125]
12: TRAIN [1][580/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00095)	Tok/s 72615 (53031)	Loss/tok 3.6312 (3.3922)	Learning Rate [0.00125]
13: TRAIN [1][580/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00100)	Tok/s 72676 (53131)	Loss/tok 3.7520 (3.3757)	Learning Rate [0.00125]
14: TRAIN [1][580/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 73015 (53232)	Loss/tok 3.7969 (3.3851)	Learning Rate [0.00125]
15: TRAIN [1][580/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 73801 (53343)	Loss/tok 3.4583 (3.3893)	Learning Rate [0.00125]
0: TRAIN [1][580/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 71948 (52070)	Loss/tok 3.4494 (3.3984)	Learning Rate [0.00125]
11: TRAIN [1][580/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 72476 (52931)	Loss/tok 3.7345 (3.3953)	Learning Rate [0.00125]
1: TRAIN [1][580/3416]	Time 0.069 (0.058)	Data 0.00076 (0.00094)	Tok/s 71946 (52157)	Loss/tok 3.6546 (3.3848)	Learning Rate [0.00125]
10: TRAIN [1][580/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 72479 (52870)	Loss/tok 3.3373 (3.3880)	Learning Rate [0.00125]
4: TRAIN [1][580/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00089)	Tok/s 72800 (52415)	Loss/tok 3.5900 (3.3856)	Learning Rate [0.00125]
5: TRAIN [1][580/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 72697 (52512)	Loss/tok 3.4054 (3.3869)	Learning Rate [0.00125]
3: TRAIN [1][580/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00097)	Tok/s 72688 (52324)	Loss/tok 3.2849 (3.3812)	Learning Rate [0.00125]
2: TRAIN [1][580/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 71893 (52239)	Loss/tok 3.4620 (3.3904)	Learning Rate [0.00125]
8: TRAIN [1][580/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 72499 (52752)	Loss/tok 3.5253 (3.3883)	Learning Rate [0.00125]
9: TRAIN [1][580/3416]	Time 0.070 (0.058)	Data 0.00078 (0.00094)	Tok/s 72500 (52809)	Loss/tok 3.4303 (3.3960)	Learning Rate [0.00125]
7: TRAIN [1][580/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00094)	Tok/s 72539 (52673)	Loss/tok 3.4569 (3.3820)	Learning Rate [0.00125]
6: TRAIN [1][580/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00101)	Tok/s 72581 (52588)	Loss/tok 3.4243 (3.3914)	Learning Rate [0.00125]
7: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00094)	Tok/s 59576 (52625)	Loss/tok 3.4267 (3.3809)	Learning Rate [0.00125]
8: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00098)	Tok/s 59570 (52707)	Loss/tok 3.5471 (3.3864)	Learning Rate [0.00125]
6: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00101)	Tok/s 59463 (52536)	Loss/tok 3.6003 (3.3897)	Learning Rate [0.00125]
4: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00089)	Tok/s 59338 (52367)	Loss/tok 3.3328 (3.3846)	Learning Rate [0.00125]
9: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00094)	Tok/s 59528 (52763)	Loss/tok 3.4441 (3.3954)	Learning Rate [0.00125]
10: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00097)	Tok/s 60184 (52826)	Loss/tok 3.5238 (3.3873)	Learning Rate [0.00125]
5: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00095)	Tok/s 59402 (52462)	Loss/tok 3.6465 (3.3859)	Learning Rate [0.00125]
3: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00097)	Tok/s 59255 (52277)	Loss/tok 3.4701 (3.3803)	Learning Rate [0.00125]
11: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00097)	Tok/s 60225 (52888)	Loss/tok 3.3474 (3.3934)	Learning Rate [0.00125]
2: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00098)	Tok/s 59104 (52194)	Loss/tok 3.4264 (3.3897)	Learning Rate [0.00125]
12: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00095)	Tok/s 60183 (52990)	Loss/tok 3.5209 (3.3904)	Learning Rate [0.00125]
1: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00080 (0.00094)	Tok/s 59035 (52112)	Loss/tok 3.7692 (3.3846)	Learning Rate [0.00125]
13: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00100)	Tok/s 60098 (53089)	Loss/tok 3.8684 (3.3765)	Learning Rate [0.00125]
15: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00092)	Tok/s 59933 (53297)	Loss/tok 3.5322 (3.3872)	Learning Rate [0.00125]
14: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 60045 (53189)	Loss/tok 3.3032 (3.3835)	Learning Rate [0.00125]
0: TRAIN [1][590/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 59055 (52026)	Loss/tok 3.2787 (3.3981)	Learning Rate [0.00125]
12: TRAIN [1][600/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00095)	Tok/s 56168 (53110)	Loss/tok 3.1991 (3.3919)	Learning Rate [0.00125]
7: TRAIN [1][600/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00094)	Tok/s 56295 (52742)	Loss/tok 3.7657 (3.3812)	Learning Rate [0.00125]
8: TRAIN [1][600/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00098)	Tok/s 56266 (52826)	Loss/tok 3.3927 (3.3875)	Learning Rate [0.00125]
13: TRAIN [1][600/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00100)	Tok/s 56071 (53207)	Loss/tok 3.2247 (3.3760)	Learning Rate [0.00125]
11: TRAIN [1][600/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00097)	Tok/s 56155 (53010)	Loss/tok 3.3397 (3.3933)	Learning Rate [0.00125]
10: TRAIN [1][600/3416]	Time 0.060 (0.058)	Data 0.00105 (0.00097)	Tok/s 56173 (52946)	Loss/tok 3.2120 (3.3875)	Learning Rate [0.00125]
6: TRAIN [1][600/3416]	Time 0.060 (0.058)	Data 0.00100 (0.00100)	Tok/s 56197 (52655)	Loss/tok 3.5054 (3.3901)	Learning Rate [0.00125]
9: TRAIN [1][600/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00094)	Tok/s 56202 (52883)	Loss/tok 3.2298 (3.3949)	Learning Rate [0.00125]
14: TRAIN [1][600/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00092)	Tok/s 55922 (53307)	Loss/tok 3.3921 (3.3848)	Learning Rate [0.00125]
15: TRAIN [1][600/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00092)	Tok/s 55864 (53415)	Loss/tok 3.3779 (3.3883)	Learning Rate [0.00125]
4: TRAIN [1][600/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00089)	Tok/s 56004 (52488)	Loss/tok 3.2115 (3.3853)	Learning Rate [0.00125]
0: TRAIN [1][600/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00092)	Tok/s 54749 (52147)	Loss/tok 3.2709 (3.3989)	Learning Rate [0.00125]
3: TRAIN [1][600/3416]	Time 0.061 (0.058)	Data 0.00101 (0.00097)	Tok/s 55948 (52399)	Loss/tok 3.2372 (3.3809)	Learning Rate [0.00125]
2: TRAIN [1][600/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00098)	Tok/s 55816 (52318)	Loss/tok 3.3905 (3.3901)	Learning Rate [0.00125]
5: TRAIN [1][600/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00096)	Tok/s 56113 (52582)	Loss/tok 3.1770 (3.3860)	Learning Rate [0.00125]
1: TRAIN [1][600/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00094)	Tok/s 54699 (52233)	Loss/tok 3.1820 (3.3850)	Learning Rate [0.00125]
0: Gradient norm: inf
14: Gradient norm: inf
1: Gradient norm: inf
8: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
9: Gradient norm: inf
7: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
10: Gradient norm: inf
11: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
0: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 69974 (52248)	Loss/tok 3.4234 (3.3984)	Learning Rate [0.00125]
15: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00092)	Tok/s 70881 (53517)	Loss/tok 3.5081 (3.3888)	Learning Rate [0.00125]
1: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00094)	Tok/s 69970 (52334)	Loss/tok 3.5367 (3.3856)	Learning Rate [0.00125]
12: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00095)	Tok/s 71024 (53211)	Loss/tok 3.5030 (3.3923)	Learning Rate [0.00125]
2: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 69995 (52417)	Loss/tok 3.7351 (3.3900)	Learning Rate [0.00125]
11: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 71071 (53112)	Loss/tok 3.4968 (3.3940)	Learning Rate [0.00125]
13: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00100)	Tok/s 70906 (53308)	Loss/tok 3.6019 (3.3781)	Learning Rate [0.00125]
14: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 70948 (53409)	Loss/tok 3.4268 (3.3840)	Learning Rate [0.00125]
10: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 70542 (53048)	Loss/tok 3.4720 (3.3871)	Learning Rate [0.00125]
3: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 69985 (52497)	Loss/tok 3.5870 (3.3821)	Learning Rate [0.00125]
4: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00089)	Tok/s 69996 (52587)	Loss/tok 3.6939 (3.3841)	Learning Rate [0.00125]
8: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 70077 (52921)	Loss/tok 3.5000 (3.3875)	Learning Rate [0.00125]
9: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00094)	Tok/s 70025 (52983)	Loss/tok 3.6858 (3.3956)	Learning Rate [0.00125]
5: TRAIN [1][610/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 69952 (52679)	Loss/tok 3.4900 (3.3860)	Learning Rate [0.00125]
7: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00094)	Tok/s 70035 (52837)	Loss/tok 3.8197 (3.3819)	Learning Rate [0.00125]
6: TRAIN [1][610/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00100)	Tok/s 70032 (52751)	Loss/tok 3.4662 (3.3892)	Learning Rate [0.00125]
11: TRAIN [1][620/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00097)	Tok/s 59329 (53176)	Loss/tok 3.6785 (3.3951)	Learning Rate [0.00125]
12: TRAIN [1][620/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00095)	Tok/s 60065 (53275)	Loss/tok 3.4868 (3.3945)	Learning Rate [0.00125]
10: TRAIN [1][620/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00097)	Tok/s 59207 (53113)	Loss/tok 3.4681 (3.3878)	Learning Rate [0.00125]
9: TRAIN [1][620/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00094)	Tok/s 59220 (53049)	Loss/tok 3.5443 (3.3958)	Learning Rate [0.00125]
13: TRAIN [1][620/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00100)	Tok/s 60008 (53372)	Loss/tok 3.5006 (3.3786)	Learning Rate [0.00125]
8: TRAIN [1][620/3416]	Time 0.068 (0.058)	Data 0.00080 (0.00099)	Tok/s 59102 (52987)	Loss/tok 3.3699 (3.3883)	Learning Rate [0.00125]
14: TRAIN [1][620/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00092)	Tok/s 59912 (53474)	Loss/tok 3.4588 (3.3850)	Learning Rate [0.00125]
15: TRAIN [1][620/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00092)	Tok/s 59823 (53581)	Loss/tok 3.5255 (3.3882)	Learning Rate [0.00125]
7: TRAIN [1][620/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00094)	Tok/s 59025 (52904)	Loss/tok 3.4678 (3.3837)	Learning Rate [0.00125]
0: TRAIN [1][620/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 58789 (52319)	Loss/tok 3.3517 (3.3985)	Learning Rate [0.00125]
6: TRAIN [1][620/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00100)	Tok/s 58963 (52819)	Loss/tok 3.7365 (3.3893)	Learning Rate [0.00125]
4: TRAIN [1][620/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00089)	Tok/s 58763 (52656)	Loss/tok 3.5822 (3.3851)	Learning Rate [0.00125]
1: TRAIN [1][620/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00093)	Tok/s 58676 (52404)	Loss/tok 3.2585 (3.3855)	Learning Rate [0.00125]
5: TRAIN [1][620/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 58858 (52748)	Loss/tok 3.4408 (3.3873)	Learning Rate [0.00125]
2: TRAIN [1][620/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 58660 (52487)	Loss/tok 3.7233 (3.3910)	Learning Rate [0.00125]
3: TRAIN [1][620/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 58704 (52567)	Loss/tok 3.6830 (3.3833)	Learning Rate [0.00125]
5: TRAIN [1][630/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00096)	Tok/s 53350 (52771)	Loss/tok 3.6066 (3.3897)	Learning Rate [0.00125]
6: TRAIN [1][630/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00100)	Tok/s 54355 (52841)	Loss/tok 3.3043 (3.3901)	Learning Rate [0.00125]
4: TRAIN [1][630/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00089)	Tok/s 53230 (52680)	Loss/tok 3.3576 (3.3856)	Learning Rate [0.00125]
3: TRAIN [1][630/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00097)	Tok/s 53178 (52592)	Loss/tok 3.7085 (3.3851)	Learning Rate [0.00125]
8: TRAIN [1][630/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00098)	Tok/s 54098 (53009)	Loss/tok 3.5622 (3.3893)	Learning Rate [0.00125]
7: TRAIN [1][630/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00094)	Tok/s 54126 (52925)	Loss/tok 3.5352 (3.3841)	Learning Rate [0.00125]
10: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00097)	Tok/s 53958 (53135)	Loss/tok 3.5688 (3.3883)	Learning Rate [0.00125]
1: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00080 (0.00093)	Tok/s 52965 (52432)	Loss/tok 3.4987 (3.3855)	Learning Rate [0.00125]
0: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00092)	Tok/s 52893 (52348)	Loss/tok 3.6098 (3.3990)	Learning Rate [0.00125]
9: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00080 (0.00094)	Tok/s 53985 (53072)	Loss/tok 3.5292 (3.3982)	Learning Rate [0.00125]
2: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00098)	Tok/s 53081 (52513)	Loss/tok 3.6349 (3.3924)	Learning Rate [0.00125]
14: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 53654 (53495)	Loss/tok 3.5738 (3.3854)	Learning Rate [0.00125]
11: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00097)	Tok/s 53816 (53198)	Loss/tok 3.6735 (3.3958)	Learning Rate [0.00125]
15: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00092)	Tok/s 53734 (53601)	Loss/tok 3.5347 (3.3888)	Learning Rate [0.00125]
12: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00095)	Tok/s 53743 (53296)	Loss/tok 3.6126 (3.3945)	Learning Rate [0.00125]
13: TRAIN [1][630/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00100)	Tok/s 53663 (53393)	Loss/tok 3.5238 (3.3798)	Learning Rate [0.00125]
13: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00100)	Tok/s 54212 (53431)	Loss/tok 3.1366 (3.3781)	Learning Rate [0.00125]
14: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00092)	Tok/s 54236 (53531)	Loss/tok 3.4922 (3.3856)	Learning Rate [0.00125]
12: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00095)	Tok/s 54085 (53334)	Loss/tok 3.4296 (3.3946)	Learning Rate [0.00125]
11: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00086 (0.00097)	Tok/s 53963 (53238)	Loss/tok 3.3274 (3.3953)	Learning Rate [0.00125]
15: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00078 (0.00092)	Tok/s 54200 (53637)	Loss/tok 3.4437 (3.3894)	Learning Rate [0.00125]
1: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00093)	Tok/s 54238 (52472)	Loss/tok 3.4467 (3.3849)	Learning Rate [0.00125]
9: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00094)	Tok/s 54001 (53111)	Loss/tok 3.2831 (3.3973)	Learning Rate [0.00125]
0: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00092)	Tok/s 54176 (52390)	Loss/tok 3.2087 (3.3991)	Learning Rate [0.00125]
8: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00098)	Tok/s 54003 (53047)	Loss/tok 3.6929 (3.3895)	Learning Rate [0.00125]
10: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00103 (0.00097)	Tok/s 53973 (53174)	Loss/tok 3.4058 (3.3889)	Learning Rate [0.00125]
7: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00094)	Tok/s 54049 (52964)	Loss/tok 3.1737 (3.3846)	Learning Rate [0.00125]
2: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00110 (0.00098)	Tok/s 54155 (52556)	Loss/tok 3.4106 (3.3915)	Learning Rate [0.00125]
4: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00089)	Tok/s 54083 (52721)	Loss/tok 3.1378 (3.3853)	Learning Rate [0.00125]
3: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00097)	Tok/s 54129 (52634)	Loss/tok 3.2799 (3.3840)	Learning Rate [0.00125]
6: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00100)	Tok/s 54004 (52879)	Loss/tok 3.5597 (3.3905)	Learning Rate [0.00125]
5: TRAIN [1][640/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00096)	Tok/s 54023 (52810)	Loss/tok 3.3358 (3.3905)	Learning Rate [0.00125]
0: TRAIN [1][650/3416]	Time 0.053 (0.058)	Data 0.00103 (0.00092)	Tok/s 52976 (52434)	Loss/tok 3.2811 (3.3991)	Learning Rate [0.00125]
15: TRAIN [1][650/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00092)	Tok/s 54165 (53676)	Loss/tok 3.6980 (3.3900)	Learning Rate [0.00125]
1: TRAIN [1][650/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00093)	Tok/s 52798 (52515)	Loss/tok 3.4440 (3.3861)	Learning Rate [0.00125]
14: TRAIN [1][650/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00092)	Tok/s 53992 (53569)	Loss/tok 3.3363 (3.3861)	Learning Rate [0.00125]
2: TRAIN [1][650/3416]	Time 0.054 (0.058)	Data 0.00094 (0.00098)	Tok/s 52620 (52600)	Loss/tok 3.3400 (3.3915)	Learning Rate [0.00125]
13: TRAIN [1][650/3416]	Time 0.053 (0.058)	Data 0.00104 (0.00100)	Tok/s 53943 (53469)	Loss/tok 3.6541 (3.3795)	Learning Rate [0.00125]
12: TRAIN [1][650/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00095)	Tok/s 53841 (53372)	Loss/tok 3.4356 (3.3958)	Learning Rate [0.00125]
5: TRAIN [1][650/3416]	Time 0.054 (0.058)	Data 0.00104 (0.00096)	Tok/s 52481 (52851)	Loss/tok 3.4269 (3.3911)	Learning Rate [0.00125]
4: TRAIN [1][650/3416]	Time 0.054 (0.058)	Data 0.00085 (0.00089)	Tok/s 52486 (52762)	Loss/tok 3.3632 (3.3856)	Learning Rate [0.00125]
3: TRAIN [1][650/3416]	Time 0.054 (0.058)	Data 0.00097 (0.00097)	Tok/s 52588 (52677)	Loss/tok 3.4476 (3.3850)	Learning Rate [0.00125]
6: TRAIN [1][650/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00100)	Tok/s 52407 (52919)	Loss/tok 3.3723 (3.3922)	Learning Rate [0.00125]
10: TRAIN [1][650/3416]	Time 0.054 (0.058)	Data 0.00104 (0.00097)	Tok/s 52577 (53211)	Loss/tok 3.3806 (3.3894)	Learning Rate [0.00125]
11: TRAIN [1][650/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00097)	Tok/s 53726 (53276)	Loss/tok 3.3755 (3.3959)	Learning Rate [0.00125]
7: TRAIN [1][650/3416]	Time 0.054 (0.058)	Data 0.00101 (0.00094)	Tok/s 52410 (53003)	Loss/tok 3.4168 (3.3846)	Learning Rate [0.00125]
8: TRAIN [1][650/3416]	Time 0.054 (0.058)	Data 0.00093 (0.00098)	Tok/s 52426 (53086)	Loss/tok 3.1722 (3.3898)	Learning Rate [0.00125]
9: TRAIN [1][650/3416]	Time 0.054 (0.058)	Data 0.00085 (0.00094)	Tok/s 52450 (53149)	Loss/tok 3.7105 (3.3994)	Learning Rate [0.00125]
8: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00098)	Tok/s 50589 (53100)	Loss/tok 3.4022 (3.3909)	Learning Rate [0.00125]
7: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00094)	Tok/s 50614 (53016)	Loss/tok 3.2698 (3.3838)	Learning Rate [0.00125]
9: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00094)	Tok/s 50510 (53162)	Loss/tok 3.1378 (3.3992)	Learning Rate [0.00125]
10: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00097)	Tok/s 50314 (53224)	Loss/tok 3.6418 (3.3903)	Learning Rate [0.00125]
6: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00100)	Tok/s 50510 (52931)	Loss/tok 3.2405 (3.3930)	Learning Rate [0.00125]
12: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00095)	Tok/s 50201 (53384)	Loss/tok 3.5575 (3.3955)	Learning Rate [0.00125]
5: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00096)	Tok/s 50384 (52864)	Loss/tok 3.3624 (3.3909)	Learning Rate [0.00125]
11: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00097)	Tok/s 50257 (53289)	Loss/tok 3.1915 (3.3950)	Learning Rate [0.00125]
4: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00089)	Tok/s 50325 (52775)	Loss/tok 3.2744 (3.3849)	Learning Rate [0.00125]
13: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00100)	Tok/s 50121 (53480)	Loss/tok 3.3013 (3.3792)	Learning Rate [0.00125]
3: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00097)	Tok/s 50270 (52690)	Loss/tok 3.4979 (3.3849)	Learning Rate [0.00125]
14: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00092)	Tok/s 50146 (53579)	Loss/tok 3.3828 (3.3854)	Learning Rate [0.00125]
2: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00098)	Tok/s 50234 (52612)	Loss/tok 3.2765 (3.3912)	Learning Rate [0.00125]
15: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00092)	Tok/s 50193 (53687)	Loss/tok 3.2235 (3.3890)	Learning Rate [0.00125]
1: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00093)	Tok/s 50228 (52527)	Loss/tok 3.3893 (3.3860)	Learning Rate [0.00125]
0: TRAIN [1][660/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00092)	Tok/s 50157 (52447)	Loss/tok 3.3679 (3.3978)	Learning Rate [0.00125]
6: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00100)	Tok/s 58127 (52948)	Loss/tok 3.6065 (3.3933)	Learning Rate [0.00125]
5: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00096)	Tok/s 58132 (52882)	Loss/tok 3.6395 (3.3903)	Learning Rate [0.00125]
7: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00094)	Tok/s 58049 (53034)	Loss/tok 3.4435 (3.3846)	Learning Rate [0.00125]
4: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00089)	Tok/s 58052 (52794)	Loss/tok 3.5497 (3.3842)	Learning Rate [0.00125]
8: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00098)	Tok/s 58135 (53116)	Loss/tok 3.4697 (3.3910)	Learning Rate [0.00125]
2: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 58201 (52633)	Loss/tok 3.4448 (3.3907)	Learning Rate [0.00125]
3: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 58163 (52710)	Loss/tok 3.6472 (3.3862)	Learning Rate [0.00125]
9: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00094)	Tok/s 58077 (53179)	Loss/tok 3.4715 (3.3990)	Learning Rate [0.00125]
10: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00097)	Tok/s 58548 (53241)	Loss/tok 3.4551 (3.3894)	Learning Rate [0.00125]
11: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 59072 (53307)	Loss/tok 3.2323 (3.3947)	Learning Rate [0.00125]
0: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 58181 (52469)	Loss/tok 3.3457 (3.3976)	Learning Rate [0.00125]
12: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00095)	Tok/s 59067 (53402)	Loss/tok 3.6135 (3.3957)	Learning Rate [0.00125]
14: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 59024 (53596)	Loss/tok 3.6168 (3.3866)	Learning Rate [0.00125]
15: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 59007 (53702)	Loss/tok 3.3796 (3.3889)	Learning Rate [0.00125]
1: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 58103 (52548)	Loss/tok 3.3320 (3.3852)	Learning Rate [0.00125]
13: TRAIN [1][670/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00100)	Tok/s 59091 (53498)	Loss/tok 3.5641 (3.3795)	Learning Rate [0.00125]
12: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00095)	Tok/s 81280 (53498)	Loss/tok 3.4958 (3.3964)	Learning Rate [0.00125]
0: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 79585 (52562)	Loss/tok 3.3378 (3.3976)	Learning Rate [0.00125]
13: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00100)	Tok/s 81258 (53593)	Loss/tok 3.2695 (3.3806)	Learning Rate [0.00125]
1: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 79743 (52640)	Loss/tok 3.3451 (3.3860)	Learning Rate [0.00125]
2: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 79774 (52723)	Loss/tok 3.4452 (3.3924)	Learning Rate [0.00125]
15: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 81752 (53796)	Loss/tok 3.3153 (3.3895)	Learning Rate [0.00125]
11: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 81181 (53404)	Loss/tok 3.4084 (3.3958)	Learning Rate [0.00125]
10: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00097)	Tok/s 81169 (53337)	Loss/tok 3.3663 (3.3904)	Learning Rate [0.00125]
14: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 81208 (53691)	Loss/tok 3.3180 (3.3870)	Learning Rate [0.00125]
3: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 80567 (52802)	Loss/tok 3.5065 (3.3886)	Learning Rate [0.00125]
4: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00089)	Tok/s 80548 (52886)	Loss/tok 3.5361 (3.3850)	Learning Rate [0.00125]
9: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00094)	Tok/s 80572 (53274)	Loss/tok 3.3451 (3.3978)	Learning Rate [0.00125]
5: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 80399 (52975)	Loss/tok 3.3664 (3.3913)	Learning Rate [0.00125]
8: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 80224 (53208)	Loss/tok 3.3583 (3.3913)	Learning Rate [0.00125]
6: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00100)	Tok/s 80306 (53042)	Loss/tok 3.2739 (3.3923)	Learning Rate [0.00125]
7: TRAIN [1][680/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00094)	Tok/s 80175 (53127)	Loss/tok 3.3366 (3.3853)	Learning Rate [0.00125]
14: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00092)	Tok/s 50121 (53618)	Loss/tok 3.1504 (3.3862)	Learning Rate [0.00125]
12: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00095)	Tok/s 50018 (53424)	Loss/tok 3.3316 (3.3962)	Learning Rate [0.00125]
13: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00100)	Tok/s 50144 (53519)	Loss/tok 3.1870 (3.3800)	Learning Rate [0.00125]
10: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00097)	Tok/s 49789 (53261)	Loss/tok 3.3308 (3.3898)	Learning Rate [0.00125]
11: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00097)	Tok/s 49877 (53329)	Loss/tok 3.3571 (3.3952)	Learning Rate [0.00125]
0: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00092)	Tok/s 49923 (52491)	Loss/tok 3.1810 (3.3964)	Learning Rate [0.00125]
15: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00092)	Tok/s 50348 (53725)	Loss/tok 3.2499 (3.3894)	Learning Rate [0.00125]
1: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00093)	Tok/s 49708 (52569)	Loss/tok 3.2562 (3.3850)	Learning Rate [0.00125]
2: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00098)	Tok/s 49568 (52652)	Loss/tok 3.3285 (3.3915)	Learning Rate [0.00125]
9: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00094)	Tok/s 49617 (53197)	Loss/tok 3.2008 (3.3966)	Learning Rate [0.00125]
8: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00098)	Tok/s 49529 (53132)	Loss/tok 3.1268 (3.3890)	Learning Rate [0.00125]
7: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00094)	Tok/s 49451 (53052)	Loss/tok 3.3106 (3.3843)	Learning Rate [0.00125]
3: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00097)	Tok/s 49610 (52729)	Loss/tok 3.3096 (3.3878)	Learning Rate [0.00125]
5: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00102 (0.00096)	Tok/s 49475 (52902)	Loss/tok 3.3147 (3.3899)	Learning Rate [0.00125]
4: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00086 (0.00089)	Tok/s 49491 (52813)	Loss/tok 3.1131 (3.3841)	Learning Rate [0.00125]
6: TRAIN [1][690/3416]	Time 0.049 (0.058)	Data 0.00105 (0.00100)	Tok/s 49477 (52968)	Loss/tok 3.1400 (3.3915)	Learning Rate [0.00125]
11: TRAIN [1][700/3416]	Time 0.057 (0.058)	Data 0.00098 (0.00097)	Tok/s 52453 (53309)	Loss/tok 3.3128 (3.3963)	Learning Rate [0.00125]
10: TRAIN [1][700/3416]	Time 0.057 (0.058)	Data 0.00103 (0.00097)	Tok/s 51487 (53240)	Loss/tok 3.4870 (3.3891)	Learning Rate [0.00125]
12: TRAIN [1][700/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00095)	Tok/s 52410 (53402)	Loss/tok 3.3713 (3.3971)	Learning Rate [0.00125]
13: TRAIN [1][700/3416]	Time 0.058 (0.058)	Data 0.00105 (0.00100)	Tok/s 52304 (53498)	Loss/tok 3.2217 (3.3795)	Learning Rate [0.00125]
8: TRAIN [1][700/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00098)	Tok/s 51415 (53112)	Loss/tok 3.4492 (3.3907)	Learning Rate [0.00125]
9: TRAIN [1][700/3416]	Time 0.057 (0.058)	Data 0.00109 (0.00094)	Tok/s 51385 (53177)	Loss/tok 3.4381 (3.3966)	Learning Rate [0.00125]
7: TRAIN [1][700/3416]	Time 0.057 (0.058)	Data 0.00102 (0.00094)	Tok/s 51362 (53032)	Loss/tok 3.2059 (3.3841)	Learning Rate [0.00125]
14: TRAIN [1][700/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00092)	Tok/s 52233 (53597)	Loss/tok 3.7022 (3.3863)	Learning Rate [0.00125]
15: TRAIN [1][700/3416]	Time 0.058 (0.058)	Data 0.00114 (0.00092)	Tok/s 52154 (53704)	Loss/tok 3.5359 (3.3892)	Learning Rate [0.00125]
0: TRAIN [1][700/3416]	Time 0.058 (0.058)	Data 0.00103 (0.00092)	Tok/s 51162 (52472)	Loss/tok 3.4048 (3.3960)	Learning Rate [0.00125]
6: TRAIN [1][700/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00100)	Tok/s 51300 (52948)	Loss/tok 3.6374 (3.3919)	Learning Rate [0.00125]
5: TRAIN [1][700/3416]	Time 0.057 (0.058)	Data 0.00108 (0.00096)	Tok/s 51212 (52880)	Loss/tok 3.2078 (3.3900)	Learning Rate [0.00125]
1: TRAIN [1][700/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00093)	Tok/s 51115 (52550)	Loss/tok 3.6336 (3.3855)	Learning Rate [0.00125]
4: TRAIN [1][700/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00089)	Tok/s 51140 (52791)	Loss/tok 3.4688 (3.3845)	Learning Rate [0.00125]
2: TRAIN [1][700/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00098)	Tok/s 51117 (52632)	Loss/tok 3.3585 (3.3924)	Learning Rate [0.00125]
3: TRAIN [1][700/3416]	Time 0.058 (0.058)	Data 0.00108 (0.00097)	Tok/s 51106 (52708)	Loss/tok 3.5258 (3.3884)	Learning Rate [0.00125]
3: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 69005 (52766)	Loss/tok 3.4162 (3.3874)	Learning Rate [0.00125]
2: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00098)	Tok/s 68806 (52690)	Loss/tok 3.3667 (3.3916)	Learning Rate [0.00125]
4: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00089)	Tok/s 68943 (52847)	Loss/tok 3.4770 (3.3843)	Learning Rate [0.00125]
5: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 68959 (52936)	Loss/tok 3.6005 (3.3888)	Learning Rate [0.00125]
1: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 68507 (52607)	Loss/tok 3.4803 (3.3843)	Learning Rate [0.00125]
0: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 67943 (52528)	Loss/tok 3.5136 (3.3951)	Learning Rate [0.00125]
15: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 69719 (53763)	Loss/tok 3.5394 (3.3885)	Learning Rate [0.00125]
6: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 68953 (53004)	Loss/tok 3.7038 (3.3929)	Learning Rate [0.00125]
7: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00094)	Tok/s 68988 (53087)	Loss/tok 3.5588 (3.3836)	Learning Rate [0.00125]
8: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 68935 (53167)	Loss/tok 3.6737 (3.3904)	Learning Rate [0.00125]
14: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 69680 (53656)	Loss/tok 3.4530 (3.3861)	Learning Rate [0.00125]
13: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00100)	Tok/s 69119 (53555)	Loss/tok 3.6412 (3.3792)	Learning Rate [0.00125]
12: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00117 (0.00095)	Tok/s 68852 (53460)	Loss/tok 3.7292 (3.3969)	Learning Rate [0.00125]
9: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00094)	Tok/s 68911 (53233)	Loss/tok 3.5181 (3.3950)	Learning Rate [0.00125]
10: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00097)	Tok/s 68882 (53297)	Loss/tok 3.3308 (3.3883)	Learning Rate [0.00125]
11: TRAIN [1][710/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 68833 (53366)	Loss/tok 3.7589 (3.3959)	Learning Rate [0.00125]
3: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00097)	Tok/s 54986 (52730)	Loss/tok 3.1828 (3.3863)	Learning Rate [0.00125]
2: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00098 (0.00098)	Tok/s 54955 (52655)	Loss/tok 3.5684 (3.3930)	Learning Rate [0.00125]
4: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00098 (0.00089)	Tok/s 54855 (52810)	Loss/tok 3.6317 (3.3842)	Learning Rate [0.00125]
5: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00096)	Tok/s 54772 (52899)	Loss/tok 3.6339 (3.3888)	Learning Rate [0.00125]
1: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00093)	Tok/s 54925 (52571)	Loss/tok 3.2403 (3.3840)	Learning Rate [0.00125]
0: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00092)	Tok/s 54914 (52491)	Loss/tok 3.2795 (3.3959)	Learning Rate [0.00125]
15: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00103 (0.00092)	Tok/s 54858 (53722)	Loss/tok 3.2143 (3.3881)	Learning Rate [0.00125]
6: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00100)	Tok/s 54649 (52967)	Loss/tok 3.4503 (3.3929)	Learning Rate [0.00125]
7: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00094)	Tok/s 54546 (53049)	Loss/tok 3.3675 (3.3834)	Learning Rate [0.00125]
8: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00098)	Tok/s 54473 (53128)	Loss/tok 3.5109 (3.3904)	Learning Rate [0.00125]
14: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00092)	Tok/s 54707 (53616)	Loss/tok 3.5103 (3.3863)	Learning Rate [0.00125]
12: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00104 (0.00095)	Tok/s 54540 (53423)	Loss/tok 3.5546 (3.3981)	Learning Rate [0.00125]
13: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00099)	Tok/s 54601 (53517)	Loss/tok 3.4277 (3.3794)	Learning Rate [0.00125]
10: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00097)	Tok/s 54405 (53258)	Loss/tok 3.8027 (3.3892)	Learning Rate [0.00125]
9: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00088 (0.00094)	Tok/s 54366 (53194)	Loss/tok 3.3024 (3.3944)	Learning Rate [0.00125]
11: TRAIN [1][720/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00097)	Tok/s 54418 (53330)	Loss/tok 3.4788 (3.3961)	Learning Rate [0.00125]
0: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00092)	Tok/s 51278 (52498)	Loss/tok 3.2859 (3.3966)	Learning Rate [0.00125]
15: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00092)	Tok/s 52453 (53752)	Loss/tok 3.4343 (3.3891)	Learning Rate [0.00125]
1: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00093)	Tok/s 51255 (52581)	Loss/tok 3.5581 (3.3852)	Learning Rate [0.00125]
14: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00092)	Tok/s 52422 (53646)	Loss/tok 3.2232 (3.3861)	Learning Rate [0.00125]
2: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00098)	Tok/s 51249 (52669)	Loss/tok 3.3806 (3.3930)	Learning Rate [0.00125]
13: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00285 (0.00100)	Tok/s 52439 (53547)	Loss/tok 3.3604 (3.3793)	Learning Rate [0.00125]
12: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00113 (0.00095)	Tok/s 52435 (53452)	Loss/tok 3.1990 (3.3979)	Learning Rate [0.00125]
3: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00097)	Tok/s 51263 (52745)	Loss/tok 3.6544 (3.3864)	Learning Rate [0.00125]
4: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00089)	Tok/s 51275 (52828)	Loss/tok 3.3225 (3.3837)	Learning Rate [0.00125]
11: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00097)	Tok/s 52434 (53358)	Loss/tok 3.3370 (3.3961)	Learning Rate [0.00125]
10: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00097)	Tok/s 52454 (53282)	Loss/tok 3.1330 (3.3898)	Learning Rate [0.00125]
9: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00083 (0.00094)	Tok/s 52479 (53219)	Loss/tok 3.4256 (3.3936)	Learning Rate [0.00125]
8: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00098)	Tok/s 52501 (53154)	Loss/tok 3.4754 (3.3905)	Learning Rate [0.00125]
5: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00096)	Tok/s 51499 (52919)	Loss/tok 3.3368 (3.3895)	Learning Rate [0.00125]
6: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00100)	Tok/s 52592 (52992)	Loss/tok 3.3898 (3.3925)	Learning Rate [0.00125]
7: TRAIN [1][730/3416]	Time 0.049 (0.058)	Data 0.00125 (0.00094)	Tok/s 52657 (53074)	Loss/tok 3.2816 (3.3841)	Learning Rate [0.00125]
10: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
2: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00098)	Tok/s 49227 (52732)	Loss/tok 3.2060 (3.3921)	Learning Rate [0.00125]
1: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00093)	Tok/s 49155 (52643)	Loss/tok 3.4534 (3.3857)	Learning Rate [0.00125]
0: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00082 (0.00092)	Tok/s 49035 (52560)	Loss/tok 3.2962 (3.3962)	Learning Rate [0.00125]
4: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00074 (0.00089)	Tok/s 49247 (52890)	Loss/tok 3.4185 (3.3841)	Learning Rate [0.00125]
15: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00092)	Tok/s 49218 (53819)	Loss/tok 3.2657 (3.3886)	Learning Rate [0.00125]
5: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00096)	Tok/s 49273 (52980)	Loss/tok 3.1989 (3.3888)	Learning Rate [0.00125]
14: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 49085 (53713)	Loss/tok 3.3825 (3.3861)	Learning Rate [0.00125]
3: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00097)	Tok/s 49266 (52808)	Loss/tok 3.3013 (3.3861)	Learning Rate [0.00125]
12: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00095)	Tok/s 49069 (53515)	Loss/tok 3.2742 (3.3978)	Learning Rate [0.00125]
6: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00105 (0.00100)	Tok/s 49259 (53052)	Loss/tok 3.2473 (3.3918)	Learning Rate [0.00125]
13: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00100)	Tok/s 49018 (53609)	Loss/tok 3.4525 (3.3797)	Learning Rate [0.00125]
8: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00098)	Tok/s 49218 (53213)	Loss/tok 3.3258 (3.3894)	Learning Rate [0.00125]
7: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00094)	Tok/s 49251 (53135)	Loss/tok 3.3680 (3.3842)	Learning Rate [0.00125]
10: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 49099 (53345)	Loss/tok 3.2758 (3.3900)	Learning Rate [0.00125]
11: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 49058 (53420)	Loss/tok 3.3180 (3.3960)	Learning Rate [0.00125]
9: TRAIN [1][740/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00094)	Tok/s 49141 (53278)	Loss/tok 3.1118 (3.3932)	Learning Rate [0.00125]
14: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00092)	Tok/s 34774 (53658)	Loss/tok 3.0860 (3.3859)	Learning Rate [0.00125]
13: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00100)	Tok/s 34751 (53555)	Loss/tok 3.0356 (3.3796)	Learning Rate [0.00125]
12: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00095)	Tok/s 34704 (53462)	Loss/tok 2.6940 (3.3965)	Learning Rate [0.00125]
10: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00097)	Tok/s 34664 (53292)	Loss/tok 3.0689 (3.3891)	Learning Rate [0.00125]
15: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00092)	Tok/s 34763 (53763)	Loss/tok 3.1426 (3.3877)	Learning Rate [0.00125]
11: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00097)	Tok/s 34628 (53367)	Loss/tok 3.0621 (3.3957)	Learning Rate [0.00125]
0: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 34592 (52510)	Loss/tok 3.1250 (3.3956)	Learning Rate [0.00125]
9: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00094)	Tok/s 34719 (53226)	Loss/tok 3.2646 (3.3925)	Learning Rate [0.00125]
1: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00081 (0.00093)	Tok/s 34758 (52591)	Loss/tok 3.2619 (3.3846)	Learning Rate [0.00125]
8: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00109 (0.00098)	Tok/s 34711 (53161)	Loss/tok 2.8806 (3.3893)	Learning Rate [0.00125]
7: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00094)	Tok/s 34688 (53082)	Loss/tok 3.0131 (3.3825)	Learning Rate [0.00125]
2: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00098)	Tok/s 34775 (52680)	Loss/tok 3.2472 (3.3899)	Learning Rate [0.00125]
3: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00097)	Tok/s 34745 (52757)	Loss/tok 2.9982 (3.3855)	Learning Rate [0.00125]
4: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00089)	Tok/s 34790 (52838)	Loss/tok 3.3029 (3.3837)	Learning Rate [0.00125]
5: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00096)	Tok/s 34672 (52927)	Loss/tok 3.1027 (3.3887)	Learning Rate [0.00125]
6: TRAIN [1][750/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00100)	Tok/s 34697 (52998)	Loss/tok 3.0955 (3.3907)	Learning Rate [0.00125]
15: TRAIN [1][760/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00092)	Tok/s 62602 (53829)	Loss/tok 3.4394 (3.3887)	Learning Rate [0.00125]
14: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 61883 (53724)	Loss/tok 3.4084 (3.3870)	Learning Rate [0.00125]
0: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 61434 (52580)	Loss/tok 3.3981 (3.3960)	Learning Rate [0.00125]
1: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00079 (0.00093)	Tok/s 61335 (52661)	Loss/tok 3.5365 (3.3864)	Learning Rate [0.00125]
12: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00095)	Tok/s 61335 (53528)	Loss/tok 3.6059 (3.3954)	Learning Rate [0.00125]
13: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00100)	Tok/s 61297 (53620)	Loss/tok 3.4648 (3.3804)	Learning Rate [0.00125]
2: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00098)	Tok/s 61162 (52751)	Loss/tok 3.5099 (3.3907)	Learning Rate [0.00125]
10: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 61130 (53360)	Loss/tok 3.7131 (3.3905)	Learning Rate [0.00125]
11: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 61199 (53435)	Loss/tok 3.5631 (3.3971)	Learning Rate [0.00125]
3: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 61129 (52828)	Loss/tok 3.8693 (3.3875)	Learning Rate [0.00125]
4: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00089)	Tok/s 61043 (52908)	Loss/tok 3.3821 (3.3843)	Learning Rate [0.00125]
9: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00094)	Tok/s 60981 (53294)	Loss/tok 3.3546 (3.3931)	Learning Rate [0.00125]
5: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 60941 (52995)	Loss/tok 3.5792 (3.3910)	Learning Rate [0.00125]
8: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 60861 (53229)	Loss/tok 3.4651 (3.3908)	Learning Rate [0.00125]
7: TRAIN [1][760/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00094)	Tok/s 60740 (53150)	Loss/tok 3.4511 (3.3838)	Learning Rate [0.00125]
6: TRAIN [1][760/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 60861 (53067)	Loss/tok 3.4659 (3.3917)	Learning Rate [0.00125]
8: Gradient norm: inf
9: Gradient norm: inf
7: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
6: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
4: Gradient norm: inf
5: Gradient norm: inf
11: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
1: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
14: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
15: TRAIN [1][770/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 71072 (53856)	Loss/tok 3.4552 (3.3876)	Learning Rate [0.00125]
7: TRAIN [1][770/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00094)	Tok/s 70210 (53178)	Loss/tok 3.7498 (3.3845)	Learning Rate [0.00125]
8: TRAIN [1][770/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 69990 (53256)	Loss/tok 3.2992 (3.3900)	Learning Rate [0.00125]
0: TRAIN [1][770/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 70163 (52608)	Loss/tok 3.4121 (3.3945)	Learning Rate [0.00125]
9: TRAIN [1][770/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00094)	Tok/s 70588 (53323)	Loss/tok 3.4151 (3.3926)	Learning Rate [0.00125]
1: TRAIN [1][770/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 70172 (52688)	Loss/tok 3.5212 (3.3861)	Learning Rate [0.00125]
14: TRAIN [1][770/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 70782 (53753)	Loss/tok 3.2162 (3.3868)	Learning Rate [0.00125]
10: TRAIN [1][770/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 70822 (53389)	Loss/tok 3.4481 (3.3902)	Learning Rate [0.00125]
5: TRAIN [1][770/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00096)	Tok/s 70173 (53023)	Loss/tok 3.3155 (3.3910)	Learning Rate [0.00125]
12: TRAIN [1][770/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00095)	Tok/s 70682 (53558)	Loss/tok 3.6009 (3.3945)	Learning Rate [0.00125]
2: TRAIN [1][770/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00098)	Tok/s 70187 (52778)	Loss/tok 3.2412 (3.3902)	Learning Rate [0.00125]
13: TRAIN [1][770/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00100)	Tok/s 70770 (53649)	Loss/tok 3.7456 (3.3808)	Learning Rate [0.00125]
4: TRAIN [1][770/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00089)	Tok/s 70184 (52936)	Loss/tok 3.5850 (3.3829)	Learning Rate [0.00125]
6: TRAIN [1][770/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00100)	Tok/s 70195 (53094)	Loss/tok 3.2591 (3.3904)	Learning Rate [0.00125]
11: TRAIN [1][770/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 70750 (53464)	Loss/tok 3.5233 (3.3973)	Learning Rate [0.00125]
3: TRAIN [1][770/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00097)	Tok/s 70146 (52854)	Loss/tok 3.4340 (3.3878)	Learning Rate [0.00125]
12: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00095)	Tok/s 39718 (53594)	Loss/tok 3.1385 (3.3935)	Learning Rate [0.00125]
11: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00098)	Tok/s 39715 (53501)	Loss/tok 3.0914 (3.3962)	Learning Rate [0.00125]
10: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00097)	Tok/s 39551 (53427)	Loss/tok 3.0386 (3.3899)	Learning Rate [0.00125]
9: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00080 (0.00094)	Tok/s 39508 (53361)	Loss/tok 3.3093 (3.3926)	Learning Rate [0.00125]
13: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00100)	Tok/s 39850 (53686)	Loss/tok 3.1039 (3.3804)	Learning Rate [0.00125]
8: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00098)	Tok/s 39406 (53295)	Loss/tok 3.1573 (3.3898)	Learning Rate [0.00125]
14: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 39625 (53789)	Loss/tok 3.1994 (3.3871)	Learning Rate [0.00125]
7: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00094)	Tok/s 38210 (53215)	Loss/tok 2.9835 (3.3850)	Learning Rate [0.00125]
15: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00092)	Tok/s 39710 (53893)	Loss/tok 3.2484 (3.3876)	Learning Rate [0.00125]
0: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00092)	Tok/s 38293 (52641)	Loss/tok 3.2131 (3.3944)	Learning Rate [0.00125]
6: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00100)	Tok/s 38035 (53130)	Loss/tok 3.1042 (3.3909)	Learning Rate [0.00125]
4: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00089)	Tok/s 38053 (52973)	Loss/tok 3.0869 (3.3823)	Learning Rate [0.00125]
5: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00096)	Tok/s 38035 (53060)	Loss/tok 3.2501 (3.3921)	Learning Rate [0.00125]
1: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00092)	Tok/s 38188 (52722)	Loss/tok 3.0467 (3.3862)	Learning Rate [0.00125]
2: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00098)	Tok/s 38115 (52815)	Loss/tok 3.1113 (3.3906)	Learning Rate [0.00125]
3: TRAIN [1][780/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00097)	Tok/s 38040 (52892)	Loss/tok 2.9447 (3.3868)	Learning Rate [0.00125]
0: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 71752 (52738)	Loss/tok 3.3435 (3.3943)	Learning Rate [0.00125]
15: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 73635 (53995)	Loss/tok 3.4780 (3.3881)	Learning Rate [0.00125]
1: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 71938 (52818)	Loss/tok 3.6810 (3.3867)	Learning Rate [0.00125]
14: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00092)	Tok/s 73541 (53889)	Loss/tok 3.6787 (3.3867)	Learning Rate [0.00125]
2: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00098)	Tok/s 72607 (52910)	Loss/tok 3.4381 (3.3906)	Learning Rate [0.00125]
3: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 72652 (52988)	Loss/tok 3.2893 (3.3864)	Learning Rate [0.00125]
13: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00100)	Tok/s 73426 (53785)	Loss/tok 3.6061 (3.3800)	Learning Rate [0.00125]
12: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00095)	Tok/s 73097 (53691)	Loss/tok 3.3431 (3.3919)	Learning Rate [0.00125]
4: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00089)	Tok/s 72586 (53068)	Loss/tok 3.6089 (3.3825)	Learning Rate [0.00125]
11: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00098)	Tok/s 72365 (53597)	Loss/tok 3.6046 (3.3955)	Learning Rate [0.00125]
5: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00096)	Tok/s 72596 (53154)	Loss/tok 3.3440 (3.3903)	Learning Rate [0.00125]
10: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 72297 (53524)	Loss/tok 3.1466 (3.3889)	Learning Rate [0.00125]
6: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00100)	Tok/s 72553 (53224)	Loss/tok 3.3274 (3.3896)	Learning Rate [0.00125]
7: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00094)	Tok/s 72433 (53310)	Loss/tok 3.6393 (3.3853)	Learning Rate [0.00125]
8: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00098)	Tok/s 72375 (53389)	Loss/tok 3.5566 (3.3892)	Learning Rate [0.00125]
9: TRAIN [1][790/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00094)	Tok/s 72281 (53455)	Loss/tok 3.6239 (3.3916)	Learning Rate [0.00125]
14: TRAIN [1][800/3416]	Time 0.040 (0.058)	Data 0.00087 (0.00092)	Tok/s 31791 (53872)	Loss/tok 2.5404 (3.3860)	Learning Rate [0.00125]
12: TRAIN [1][800/3416]	Time 0.040 (0.058)	Data 0.00089 (0.00095)	Tok/s 31676 (53674)	Loss/tok 2.6549 (3.3917)	Learning Rate [0.00125]
13: TRAIN [1][800/3416]	Time 0.040 (0.058)	Data 0.00093 (0.00099)	Tok/s 31812 (53767)	Loss/tok 2.7315 (3.3787)	Learning Rate [0.00125]
15: TRAIN [1][800/3416]	Time 0.040 (0.058)	Data 0.00091 (0.00092)	Tok/s 31789 (53979)	Loss/tok 2.8001 (3.3869)	Learning Rate [0.00125]
11: TRAIN [1][800/3416]	Time 0.040 (0.058)	Data 0.00083 (0.00098)	Tok/s 30109 (53577)	Loss/tok 2.7089 (3.3954)	Learning Rate [0.00125]
0: TRAIN [1][800/3416]	Time 0.040 (0.058)	Data 0.00085 (0.00092)	Tok/s 28447 (52715)	Loss/tok 2.5999 (3.3926)	Learning Rate [0.00125]
10: TRAIN [1][800/3416]	Time 0.041 (0.058)	Data 0.00083 (0.00097)	Tok/s 29932 (53505)	Loss/tok 2.7165 (3.3885)	Learning Rate [0.00125]
9: TRAIN [1][800/3416]	Time 0.041 (0.058)	Data 0.00082 (0.00094)	Tok/s 29907 (53436)	Loss/tok 2.6323 (3.3900)	Learning Rate [0.00125]
1: TRAIN [1][800/3416]	Time 0.041 (0.058)	Data 0.00097 (0.00092)	Tok/s 28352 (52795)	Loss/tok 2.6081 (3.3854)	Learning Rate [0.00125]
8: TRAIN [1][800/3416]	Time 0.041 (0.058)	Data 0.00087 (0.00098)	Tok/s 29831 (53370)	Loss/tok 2.8396 (3.3875)	Learning Rate [0.00125]
2: TRAIN [1][800/3416]	Time 0.041 (0.058)	Data 0.00105 (0.00098)	Tok/s 28298 (52887)	Loss/tok 2.7157 (3.3895)	Learning Rate [0.00125]
7: TRAIN [1][800/3416]	Time 0.041 (0.058)	Data 0.00086 (0.00094)	Tok/s 29689 (53291)	Loss/tok 2.6991 (3.3841)	Learning Rate [0.00125]
5: TRAIN [1][800/3416]	Time 0.041 (0.058)	Data 0.00087 (0.00096)	Tok/s 29677 (53133)	Loss/tok 2.6826 (3.3897)	Learning Rate [0.00125]
4: TRAIN [1][800/3416]	Time 0.041 (0.058)	Data 0.00087 (0.00089)	Tok/s 29269 (53047)	Loss/tok 2.6246 (3.3818)	Learning Rate [0.00125]
3: TRAIN [1][800/3416]	Time 0.041 (0.058)	Data 0.00102 (0.00097)	Tok/s 28244 (52965)	Loss/tok 2.6375 (3.3849)	Learning Rate [0.00125]
6: TRAIN [1][800/3416]	Time 0.041 (0.058)	Data 0.00103 (0.00100)	Tok/s 29661 (53203)	Loss/tok 2.6381 (3.3895)	Learning Rate [0.00125]
10: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 59356 (53531)	Loss/tok 3.5559 (3.3899)	Learning Rate [0.00125]
8: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00098)	Tok/s 59363 (53397)	Loss/tok 3.7424 (3.3893)	Learning Rate [0.00125]
9: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00094)	Tok/s 59369 (53462)	Loss/tok 3.4436 (3.3914)	Learning Rate [0.00125]
11: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 59314 (53602)	Loss/tok 3.6170 (3.3955)	Learning Rate [0.00125]
7: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00094)	Tok/s 59296 (53319)	Loss/tok 3.5674 (3.3844)	Learning Rate [0.00125]
12: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00095)	Tok/s 59304 (53698)	Loss/tok 3.6739 (3.3928)	Learning Rate [0.00125]
6: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 59287 (53229)	Loss/tok 3.4643 (3.3912)	Learning Rate [0.00125]
13: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00099)	Tok/s 59327 (53791)	Loss/tok 3.5829 (3.3804)	Learning Rate [0.00125]
5: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 59251 (53158)	Loss/tok 3.7654 (3.3922)	Learning Rate [0.00125]
14: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 59356 (53896)	Loss/tok 3.6668 (3.3873)	Learning Rate [0.00125]
15: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00092)	Tok/s 59396 (54002)	Loss/tok 3.4200 (3.3873)	Learning Rate [0.00125]
4: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00090)	Tok/s 59285 (53072)	Loss/tok 3.3944 (3.3845)	Learning Rate [0.00125]
0: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 59324 (52742)	Loss/tok 3.6778 (3.3936)	Learning Rate [0.00125]
3: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 59268 (52990)	Loss/tok 3.4536 (3.3860)	Learning Rate [0.00125]
2: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00098)	Tok/s 59290 (52913)	Loss/tok 3.5645 (3.3910)	Learning Rate [0.00125]
1: TRAIN [1][810/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00093)	Tok/s 59309 (52821)	Loss/tok 3.7261 (3.3867)	Learning Rate [0.00125]
10: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00097)	Tok/s 33391 (53499)	Loss/tok 3.1014 (3.3892)	Learning Rate [0.00125]
7: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00094)	Tok/s 33323 (53289)	Loss/tok 2.8744 (3.3839)	Learning Rate [0.00125]
9: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00113 (0.00094)	Tok/s 33345 (53431)	Loss/tok 3.2932 (3.3905)	Learning Rate [0.00125]
6: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00100)	Tok/s 33282 (53201)	Loss/tok 3.0685 (3.3907)	Learning Rate [0.00125]
5: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00096)	Tok/s 33185 (53130)	Loss/tok 3.0040 (3.3911)	Learning Rate [0.00125]
11: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00097)	Tok/s 33346 (53573)	Loss/tok 3.0973 (3.3938)	Learning Rate [0.00125]
8: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00098)	Tok/s 33335 (53367)	Loss/tok 3.1420 (3.3881)	Learning Rate [0.00125]
12: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00204 (0.00095)	Tok/s 33650 (53672)	Loss/tok 3.2258 (3.3922)	Learning Rate [0.00125]
4: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00090)	Tok/s 33156 (53044)	Loss/tok 3.0909 (3.3837)	Learning Rate [0.00125]
13: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00099)	Tok/s 34478 (53764)	Loss/tok 2.9215 (3.3795)	Learning Rate [0.00125]
3: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00097)	Tok/s 33093 (52964)	Loss/tok 3.0070 (3.3848)	Learning Rate [0.00125]
2: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00112 (0.00098)	Tok/s 33083 (52885)	Loss/tok 3.1719 (3.3909)	Learning Rate [0.00125]
14: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00109 (0.00092)	Tok/s 34412 (53869)	Loss/tok 3.1854 (3.3873)	Learning Rate [0.00125]
15: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00092)	Tok/s 34380 (53975)	Loss/tok 3.3024 (3.3866)	Learning Rate [0.00125]
0: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00092)	Tok/s 33065 (52714)	Loss/tok 3.3169 (3.3929)	Learning Rate [0.00125]
1: TRAIN [1][820/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00093)	Tok/s 33075 (52793)	Loss/tok 3.0407 (3.3856)	Learning Rate [0.00125]
14: TRAIN [1][830/3416]	Time 0.057 (0.058)	Data 0.00090 (0.00092)	Tok/s 54775 (53892)	Loss/tok 3.3222 (3.3873)	Learning Rate [0.00125]
13: TRAIN [1][830/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00099)	Tok/s 54845 (53788)	Loss/tok 3.3515 (3.3791)	Learning Rate [0.00125]
12: TRAIN [1][830/3416]	Time 0.057 (0.058)	Data 0.00099 (0.00095)	Tok/s 54833 (53695)	Loss/tok 3.2137 (3.3931)	Learning Rate [0.00125]
0: TRAIN [1][830/3416]	Time 0.057 (0.058)	Data 0.00083 (0.00092)	Tok/s 54641 (52740)	Loss/tok 3.4097 (3.3929)	Learning Rate [0.00125]
11: TRAIN [1][830/3416]	Time 0.057 (0.058)	Data 0.00095 (0.00097)	Tok/s 54784 (53597)	Loss/tok 3.5112 (3.3945)	Learning Rate [0.00125]
10: TRAIN [1][830/3416]	Time 0.057 (0.058)	Data 0.00087 (0.00097)	Tok/s 54682 (53523)	Loss/tok 3.3457 (3.3894)	Learning Rate [0.00125]
2: TRAIN [1][830/3416]	Time 0.058 (0.058)	Data 0.00102 (0.00098)	Tok/s 54429 (52911)	Loss/tok 3.4490 (3.3905)	Learning Rate [0.00125]
3: TRAIN [1][830/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00097)	Tok/s 54392 (52989)	Loss/tok 3.4801 (3.3843)	Learning Rate [0.00125]
5: TRAIN [1][830/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00096)	Tok/s 54345 (53155)	Loss/tok 3.5457 (3.3925)	Learning Rate [0.00125]
9: TRAIN [1][830/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00094)	Tok/s 54556 (53455)	Loss/tok 3.3331 (3.3912)	Learning Rate [0.00125]
8: TRAIN [1][830/3416]	Time 0.058 (0.058)	Data 0.00089 (0.00098)	Tok/s 54492 (53391)	Loss/tok 3.3554 (3.3885)	Learning Rate [0.00125]
7: TRAIN [1][830/3416]	Time 0.058 (0.058)	Data 0.00084 (0.00094)	Tok/s 54321 (53314)	Loss/tok 3.2937 (3.3843)	Learning Rate [0.00125]
6: TRAIN [1][830/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00100)	Tok/s 54321 (53225)	Loss/tok 3.4032 (3.3917)	Learning Rate [0.00125]
1: TRAIN [1][830/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00093)	Tok/s 54504 (52819)	Loss/tok 3.4639 (3.3865)	Learning Rate [0.00125]
15: TRAIN [1][830/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00092)	Tok/s 54608 (53995)	Loss/tok 3.2983 (3.3880)	Learning Rate [0.00125]
4: TRAIN [1][830/3416]	Time 0.058 (0.058)	Data 0.00116 (0.00090)	Tok/s 54192 (53067)	Loss/tok 3.4041 (3.3841)	Learning Rate [0.00125]
2: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00098)	Tok/s 50809 (52857)	Loss/tok 3.2399 (3.3895)	Learning Rate [0.00125]
3: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00097)	Tok/s 50928 (52935)	Loss/tok 3.2286 (3.3842)	Learning Rate [0.00125]
4: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00090)	Tok/s 50905 (53014)	Loss/tok 3.1581 (3.3845)	Learning Rate [0.00125]
5: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00096)	Tok/s 50914 (53100)	Loss/tok 3.4955 (3.3927)	Learning Rate [0.00125]
0: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00092)	Tok/s 50665 (52688)	Loss/tok 3.2737 (3.3921)	Learning Rate [0.00125]
1: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00092)	Tok/s 50716 (52766)	Loss/tok 3.1037 (3.3852)	Learning Rate [0.00125]
6: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00100)	Tok/s 50925 (53172)	Loss/tok 3.2468 (3.3917)	Learning Rate [0.00125]
15: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 50479 (53942)	Loss/tok 3.2672 (3.3877)	Learning Rate [0.00125]
14: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00092)	Tok/s 50400 (53838)	Loss/tok 3.5054 (3.3877)	Learning Rate [0.00125]
8: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00098)	Tok/s 50767 (53337)	Loss/tok 3.2642 (3.3874)	Learning Rate [0.00125]
7: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00094)	Tok/s 50853 (53261)	Loss/tok 3.0611 (3.3840)	Learning Rate [0.00125]
13: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00099)	Tok/s 50487 (53735)	Loss/tok 3.2568 (3.3787)	Learning Rate [0.00125]
12: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00095)	Tok/s 50460 (53640)	Loss/tok 3.3112 (3.3934)	Learning Rate [0.00125]
10: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00097)	Tok/s 50517 (53468)	Loss/tok 3.3499 (3.3893)	Learning Rate [0.00125]
11: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00097)	Tok/s 50477 (53541)	Loss/tok 3.3999 (3.3947)	Learning Rate [0.00125]
9: TRAIN [1][840/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00094)	Tok/s 50634 (53401)	Loss/tok 3.1703 (3.3916)	Learning Rate [0.00125]
14: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 70569 (53934)	Loss/tok 3.5682 (3.3882)	Learning Rate [0.00125]
12: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00095)	Tok/s 70653 (53737)	Loss/tok 3.3342 (3.3945)	Learning Rate [0.00125]
15: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00092)	Tok/s 70515 (54037)	Loss/tok 3.3956 (3.3876)	Learning Rate [0.00125]
11: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 70633 (53638)	Loss/tok 3.6787 (3.3956)	Learning Rate [0.00125]
10: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00097)	Tok/s 70653 (53563)	Loss/tok 3.3943 (3.3889)	Learning Rate [0.00125]
0: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 69614 (52782)	Loss/tok 3.2426 (3.3923)	Learning Rate [0.00125]
13: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00099)	Tok/s 70628 (53831)	Loss/tok 3.5759 (3.3792)	Learning Rate [0.00125]
9: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00094)	Tok/s 69837 (53494)	Loss/tok 3.5450 (3.3921)	Learning Rate [0.00125]
1: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 69604 (52859)	Loss/tok 3.5675 (3.3862)	Learning Rate [0.00125]
8: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00098)	Tok/s 69680 (53430)	Loss/tok 3.5923 (3.3874)	Learning Rate [0.00125]
2: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00098)	Tok/s 69544 (52948)	Loss/tok 3.4736 (3.3902)	Learning Rate [0.00125]
5: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 69590 (53194)	Loss/tok 3.6657 (3.3939)	Learning Rate [0.00125]
4: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00090)	Tok/s 69605 (53107)	Loss/tok 3.4944 (3.3856)	Learning Rate [0.00125]
3: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 69577 (53027)	Loss/tok 3.5248 (3.3857)	Learning Rate [0.00125]
6: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00100)	Tok/s 69643 (53265)	Loss/tok 3.6556 (3.3932)	Learning Rate [0.00125]
7: TRAIN [1][850/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00094)	Tok/s 69679 (53353)	Loss/tok 3.4101 (3.3850)	Learning Rate [0.00125]
5: TRAIN [1][860/3416]	Time 0.043 (0.058)	Data 0.00096 (0.00096)	Tok/s 29605 (53126)	Loss/tok 2.6532 (3.3929)	Learning Rate [0.00125]
4: TRAIN [1][860/3416]	Time 0.043 (0.058)	Data 0.00098 (0.00090)	Tok/s 29620 (53040)	Loss/tok 2.7881 (3.3848)	Learning Rate [0.00125]
7: TRAIN [1][860/3416]	Time 0.043 (0.058)	Data 0.00102 (0.00094)	Tok/s 30023 (53284)	Loss/tok 2.7786 (3.3846)	Learning Rate [0.00125]
6: TRAIN [1][860/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00100)	Tok/s 29528 (53196)	Loss/tok 2.7371 (3.3926)	Learning Rate [0.00125]
2: TRAIN [1][860/3416]	Time 0.043 (0.058)	Data 0.00100 (0.00098)	Tok/s 29607 (52882)	Loss/tok 2.7664 (3.3894)	Learning Rate [0.00125]
3: TRAIN [1][860/3416]	Time 0.043 (0.058)	Data 0.00098 (0.00097)	Tok/s 29630 (52959)	Loss/tok 2.6875 (3.3857)	Learning Rate [0.00125]
8: TRAIN [1][860/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00098)	Tok/s 30854 (53361)	Loss/tok 2.7217 (3.3866)	Learning Rate [0.00125]
1: TRAIN [1][860/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00092)	Tok/s 29586 (52794)	Loss/tok 2.7454 (3.3857)	Learning Rate [0.00125]
9: TRAIN [1][860/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00094)	Tok/s 30811 (53424)	Loss/tok 2.7624 (3.3912)	Learning Rate [0.00125]
0: TRAIN [1][860/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00092)	Tok/s 29552 (52717)	Loss/tok 2.8168 (3.3917)	Learning Rate [0.00125]
10: TRAIN [1][860/3416]	Time 0.044 (0.058)	Data 0.00102 (0.00097)	Tok/s 30725 (53492)	Loss/tok 2.6637 (3.3887)	Learning Rate [0.00125]
15: TRAIN [1][860/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00092)	Tok/s 30965 (53968)	Loss/tok 2.5929 (3.3870)	Learning Rate [0.00125]
12: TRAIN [1][860/3416]	Time 0.044 (0.058)	Data 0.00102 (0.00095)	Tok/s 30813 (53669)	Loss/tok 2.6438 (3.3938)	Learning Rate [0.00125]
11: TRAIN [1][860/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00097)	Tok/s 30771 (53569)	Loss/tok 2.9473 (3.3948)	Learning Rate [0.00125]
14: TRAIN [1][860/3416]	Time 0.043 (0.058)	Data 0.00087 (0.00092)	Tok/s 30900 (53865)	Loss/tok 2.8376 (3.3871)	Learning Rate [0.00125]
13: TRAIN [1][860/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00099)	Tok/s 30841 (53763)	Loss/tok 2.7630 (3.3794)	Learning Rate [0.00125]
10: TRAIN [1][870/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00097)	Tok/s 53967 (53476)	Loss/tok 3.3038 (3.3883)	Learning Rate [0.00125]
8: TRAIN [1][870/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00098)	Tok/s 54056 (53346)	Loss/tok 3.3540 (3.3870)	Learning Rate [0.00125]
9: TRAIN [1][870/3416]	Time 0.058 (0.058)	Data 0.00083 (0.00094)	Tok/s 54058 (53408)	Loss/tok 3.5806 (3.3912)	Learning Rate [0.00125]
12: TRAIN [1][870/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00095)	Tok/s 53838 (53652)	Loss/tok 3.3842 (3.3935)	Learning Rate [0.00125]
7: TRAIN [1][870/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00094)	Tok/s 53876 (53269)	Loss/tok 3.2202 (3.3844)	Learning Rate [0.00125]
11: TRAIN [1][870/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00097)	Tok/s 53902 (53552)	Loss/tok 3.3687 (3.3950)	Learning Rate [0.00125]
13: TRAIN [1][870/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00099)	Tok/s 53758 (53745)	Loss/tok 3.5348 (3.3798)	Learning Rate [0.00125]
5: TRAIN [1][870/3416]	Time 0.058 (0.058)	Data 0.00103 (0.00096)	Tok/s 52737 (53108)	Loss/tok 3.3365 (3.3932)	Learning Rate [0.00125]
14: TRAIN [1][870/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00092)	Tok/s 53605 (53846)	Loss/tok 3.4890 (3.3879)	Learning Rate [0.00125]
4: TRAIN [1][870/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00090)	Tok/s 52590 (53024)	Loss/tok 3.4614 (3.3848)	Learning Rate [0.00125]
15: TRAIN [1][870/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00092)	Tok/s 53477 (53948)	Loss/tok 3.2782 (3.3870)	Learning Rate [0.00125]
0: TRAIN [1][870/3416]	Time 0.059 (0.058)	Data 0.00080 (0.00092)	Tok/s 52312 (52703)	Loss/tok 3.3690 (3.3914)	Learning Rate [0.00125]
6: TRAIN [1][870/3416]	Time 0.058 (0.058)	Data 0.00122 (0.00101)	Tok/s 53104 (53179)	Loss/tok 3.1753 (3.3917)	Learning Rate [0.00125]
2: TRAIN [1][870/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00098)	Tok/s 52429 (52867)	Loss/tok 3.5135 (3.3902)	Learning Rate [0.00125]
1: TRAIN [1][870/3416]	Time 0.059 (0.058)	Data 0.00082 (0.00092)	Tok/s 52381 (52780)	Loss/tok 3.3622 (3.3863)	Learning Rate [0.00125]
3: TRAIN [1][870/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00097)	Tok/s 52526 (52944)	Loss/tok 3.2962 (3.3868)	Learning Rate [0.00125]
6: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00101)	Tok/s 52415 (53126)	Loss/tok 3.4430 (3.3912)	Learning Rate [0.00125]
5: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00106 (0.00096)	Tok/s 52268 (53055)	Loss/tok 3.5896 (3.3929)	Learning Rate [0.00125]
7: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00094)	Tok/s 52378 (53215)	Loss/tok 3.3554 (3.3849)	Learning Rate [0.00125]
4: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00090)	Tok/s 52171 (52970)	Loss/tok 3.3958 (3.3842)	Learning Rate [0.00125]
8: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00098)	Tok/s 52377 (53292)	Loss/tok 3.4959 (3.3870)	Learning Rate [0.00125]
3: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00097)	Tok/s 52082 (52891)	Loss/tok 3.3160 (3.3860)	Learning Rate [0.00125]
10: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00097)	Tok/s 52326 (53423)	Loss/tok 3.4994 (3.3880)	Learning Rate [0.00125]
2: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00098)	Tok/s 51931 (52814)	Loss/tok 3.5269 (3.3902)	Learning Rate [0.00125]
1: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00092)	Tok/s 51963 (52727)	Loss/tok 3.5002 (3.3861)	Learning Rate [0.00125]
11: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00097)	Tok/s 52239 (53500)	Loss/tok 3.6037 (3.3954)	Learning Rate [0.00125]
12: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00218 (0.00095)	Tok/s 52129 (53599)	Loss/tok 3.2772 (3.3930)	Learning Rate [0.00125]
0: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00092)	Tok/s 51950 (52651)	Loss/tok 3.4453 (3.3911)	Learning Rate [0.00125]
9: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00094)	Tok/s 52360 (53355)	Loss/tok 3.5830 (3.3915)	Learning Rate [0.00125]
15: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00092)	Tok/s 51982 (53893)	Loss/tok 3.4691 (3.3877)	Learning Rate [0.00125]
13: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00099)	Tok/s 52024 (53692)	Loss/tok 3.4843 (3.3802)	Learning Rate [0.00125]
14: TRAIN [1][880/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00092)	Tok/s 51954 (53792)	Loss/tok 3.3014 (3.3886)	Learning Rate [0.00125]
0: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 50189 (52589)	Loss/tok 3.3741 (3.3906)	Learning Rate [0.00125]
14: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00092)	Tok/s 49938 (53724)	Loss/tok 3.2438 (3.3878)	Learning Rate [0.00125]
1: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00127 (0.00092)	Tok/s 50215 (52664)	Loss/tok 3.2723 (3.3855)	Learning Rate [0.00125]
10: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00097)	Tok/s 50005 (53359)	Loss/tok 3.4086 (3.3877)	Learning Rate [0.00125]
2: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00098)	Tok/s 50243 (52750)	Loss/tok 3.1903 (3.3897)	Learning Rate [0.00125]
11: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00097)	Tok/s 49891 (53435)	Loss/tok 3.3599 (3.3943)	Learning Rate [0.00125]
12: TRAIN [1][890/3416]	Time 0.048 (0.058)	Data 0.00108 (0.00095)	Tok/s 49814 (53533)	Loss/tok 3.2739 (3.3924)	Learning Rate [0.00125]
13: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00099)	Tok/s 50063 (53625)	Loss/tok 3.4199 (3.3788)	Learning Rate [0.00125]
15: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00092)	Tok/s 50099 (53824)	Loss/tok 3.3340 (3.3871)	Learning Rate [0.00125]
9: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00094)	Tok/s 49905 (53291)	Loss/tok 3.3458 (3.3906)	Learning Rate [0.00125]
8: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00098)	Tok/s 49931 (53229)	Loss/tok 3.4947 (3.3860)	Learning Rate [0.00125]
4: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00090)	Tok/s 50132 (52908)	Loss/tok 3.2779 (3.3833)	Learning Rate [0.00125]
3: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00097)	Tok/s 50208 (52830)	Loss/tok 3.2024 (3.3853)	Learning Rate [0.00125]
5: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00096)	Tok/s 50062 (52992)	Loss/tok 3.3262 (3.3926)	Learning Rate [0.00125]
7: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00094)	Tok/s 49918 (53152)	Loss/tok 3.2824 (3.3842)	Learning Rate [0.00125]
6: TRAIN [1][890/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00101)	Tok/s 49955 (53063)	Loss/tok 3.6018 (3.3907)	Learning Rate [0.00125]
11: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
7: TRAIN [1][900/3416]	Time 0.041 (0.058)	Data 0.00099 (0.00094)	Tok/s 29370 (53134)	Loss/tok 3.0348 (3.3849)	Learning Rate [0.00125]
8: TRAIN [1][900/3416]	Time 0.041 (0.058)	Data 0.00091 (0.00098)	Tok/s 29381 (53211)	Loss/tok 2.5445 (3.3855)	Learning Rate [0.00125]
5: TRAIN [1][900/3416]	Time 0.042 (0.058)	Data 0.00094 (0.00096)	Tok/s 29293 (52976)	Loss/tok 2.8532 (3.3929)	Learning Rate [0.00125]
6: TRAIN [1][900/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00100)	Tok/s 29301 (53047)	Loss/tok 2.8333 (3.3911)	Learning Rate [0.00125]
9: TRAIN [1][900/3416]	Time 0.041 (0.058)	Data 0.00091 (0.00094)	Tok/s 29319 (53273)	Loss/tok 2.5767 (3.3912)	Learning Rate [0.00125]
10: TRAIN [1][900/3416]	Time 0.042 (0.058)	Data 0.00102 (0.00097)	Tok/s 29274 (53342)	Loss/tok 2.8276 (3.3883)	Learning Rate [0.00125]
4: TRAIN [1][900/3416]	Time 0.042 (0.058)	Data 0.00096 (0.00090)	Tok/s 29103 (52892)	Loss/tok 2.7785 (3.3834)	Learning Rate [0.00125]
11: TRAIN [1][900/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00097)	Tok/s 29346 (53416)	Loss/tok 2.6489 (3.3947)	Learning Rate [0.00125]
3: TRAIN [1][900/3416]	Time 0.042 (0.058)	Data 0.00089 (0.00097)	Tok/s 27566 (52813)	Loss/tok 2.5423 (3.3856)	Learning Rate [0.00125]
2: TRAIN [1][900/3416]	Time 0.042 (0.058)	Data 0.00088 (0.00098)	Tok/s 27472 (52734)	Loss/tok 2.6294 (3.3886)	Learning Rate [0.00125]
12: TRAIN [1][900/3416]	Time 0.042 (0.058)	Data 0.00090 (0.00095)	Tok/s 30634 (53515)	Loss/tok 2.9550 (3.3921)	Learning Rate [0.00125]
13: TRAIN [1][900/3416]	Time 0.042 (0.058)	Data 0.00097 (0.00099)	Tok/s 30596 (53606)	Loss/tok 2.7742 (3.3791)	Learning Rate [0.00125]
14: TRAIN [1][900/3416]	Time 0.042 (0.058)	Data 0.00095 (0.00092)	Tok/s 30505 (53705)	Loss/tok 3.0029 (3.3880)	Learning Rate [0.00125]
1: TRAIN [1][900/3416]	Time 0.042 (0.058)	Data 0.00085 (0.00092)	Tok/s 27415 (52647)	Loss/tok 2.7527 (3.3851)	Learning Rate [0.00125]
0: TRAIN [1][900/3416]	Time 0.042 (0.058)	Data 0.00081 (0.00092)	Tok/s 27431 (52572)	Loss/tok 2.5277 (3.3906)	Learning Rate [0.00125]
15: TRAIN [1][900/3416]	Time 0.043 (0.058)	Data 0.00089 (0.00092)	Tok/s 30111 (53804)	Loss/tok 2.9039 (3.3868)	Learning Rate [0.00125]
0: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 60964 (52503)	Loss/tok 3.4969 (3.3913)	Learning Rate [0.00125]
1: TRAIN [1][910/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00092)	Tok/s 61699 (52581)	Loss/tok 3.4792 (3.3851)	Learning Rate [0.00125]
2: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 61394 (52672)	Loss/tok 3.5078 (3.3875)	Learning Rate [0.00125]
15: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 61490 (53751)	Loss/tok 3.5577 (3.3862)	Learning Rate [0.00125]
3: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 61336 (52751)	Loss/tok 3.5089 (3.3848)	Learning Rate [0.00125]
4: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00090)	Tok/s 61251 (52831)	Loss/tok 3.4017 (3.3826)	Learning Rate [0.00125]
5: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00096)	Tok/s 61172 (52918)	Loss/tok 3.6501 (3.3920)	Learning Rate [0.00125]
14: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 61388 (53651)	Loss/tok 3.7581 (3.3881)	Learning Rate [0.00125]
13: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00099)	Tok/s 61290 (53551)	Loss/tok 3.5765 (3.3787)	Learning Rate [0.00125]
6: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00100)	Tok/s 61069 (52989)	Loss/tok 3.5371 (3.3913)	Learning Rate [0.00125]
12: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00095)	Tok/s 61209 (53459)	Loss/tok 3.4252 (3.3913)	Learning Rate [0.00125]
7: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00120 (0.00094)	Tok/s 61034 (53076)	Loss/tok 3.5472 (3.3845)	Learning Rate [0.00125]
8: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 60997 (53153)	Loss/tok 3.6332 (3.3849)	Learning Rate [0.00125]
11: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 61137 (53359)	Loss/tok 3.5008 (3.3938)	Learning Rate [0.00125]
10: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00097)	Tok/s 61030 (53284)	Loss/tok 3.4720 (3.3872)	Learning Rate [0.00125]
9: TRAIN [1][910/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 60994 (53216)	Loss/tok 3.5873 (3.3907)	Learning Rate [0.00125]
12: TRAIN [1][920/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00095)	Tok/s 55208 (53437)	Loss/tok 3.5391 (3.3916)	Learning Rate [0.00125]
10: TRAIN [1][920/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00097)	Tok/s 54600 (53263)	Loss/tok 3.6698 (3.3877)	Learning Rate [0.00125]
11: TRAIN [1][920/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00097)	Tok/s 55218 (53337)	Loss/tok 3.3862 (3.3930)	Learning Rate [0.00125]
13: TRAIN [1][920/3416]	Time 0.067 (0.058)	Data 0.00102 (0.00099)	Tok/s 55120 (53528)	Loss/tok 3.6496 (3.3789)	Learning Rate [0.00125]
14: TRAIN [1][920/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00092)	Tok/s 55034 (53627)	Loss/tok 3.8189 (3.3886)	Learning Rate [0.00125]
15: TRAIN [1][920/3416]	Time 0.068 (0.058)	Data 0.00079 (0.00092)	Tok/s 54886 (53725)	Loss/tok 3.5525 (3.3863)	Learning Rate [0.00125]
8: TRAIN [1][920/3416]	Time 0.067 (0.058)	Data 0.00108 (0.00097)	Tok/s 54308 (53127)	Loss/tok 3.5225 (3.3849)	Learning Rate [0.00125]
9: TRAIN [1][920/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00093)	Tok/s 54257 (53191)	Loss/tok 3.1845 (3.3904)	Learning Rate [0.00125]
0: TRAIN [1][920/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00092)	Tok/s 53978 (52481)	Loss/tok 3.6741 (3.3913)	Learning Rate [0.00125]
1: TRAIN [1][920/3416]	Time 0.068 (0.058)	Data 0.00080 (0.00092)	Tok/s 53976 (52559)	Loss/tok 3.3914 (3.3856)	Learning Rate [0.00125]
7: TRAIN [1][920/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00094)	Tok/s 54232 (53050)	Loss/tok 3.4124 (3.3850)	Learning Rate [0.00125]
6: TRAIN [1][920/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00100)	Tok/s 54185 (52963)	Loss/tok 3.4936 (3.3915)	Learning Rate [0.00125]
5: TRAIN [1][920/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00096)	Tok/s 54078 (52893)	Loss/tok 3.5479 (3.3918)	Learning Rate [0.00125]
2: TRAIN [1][920/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00098)	Tok/s 53961 (52649)	Loss/tok 3.5958 (3.3874)	Learning Rate [0.00125]
4: TRAIN [1][920/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00090)	Tok/s 54014 (52807)	Loss/tok 3.4812 (3.3827)	Learning Rate [0.00125]
3: TRAIN [1][920/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00097)	Tok/s 53973 (52727)	Loss/tok 3.4341 (3.3852)	Learning Rate [0.00125]
2: Gradient norm: inf
1: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
15: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
8: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
10: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
0: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00092)	Tok/s 55427 (52584)	Loss/tok 3.3855 (3.3904)	Learning Rate [0.00125]
15: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00092)	Tok/s 56345 (53832)	Loss/tok 3.6237 (3.3870)	Learning Rate [0.00125]
1: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00092)	Tok/s 55318 (52662)	Loss/tok 3.4619 (3.3865)	Learning Rate [0.00125]
14: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00092)	Tok/s 56325 (53733)	Loss/tok 3.2964 (3.3884)	Learning Rate [0.00125]
2: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00098)	Tok/s 55263 (52751)	Loss/tok 3.3509 (3.3868)	Learning Rate [0.00125]
13: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00099)	Tok/s 56245 (53634)	Loss/tok 3.3016 (3.3785)	Learning Rate [0.00125]
12: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00095)	Tok/s 56212 (53541)	Loss/tok 3.5130 (3.3914)	Learning Rate [0.00125]
3: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00097)	Tok/s 55202 (52830)	Loss/tok 3.4541 (3.3862)	Learning Rate [0.00125]
4: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00090)	Tok/s 55109 (52910)	Loss/tok 3.5918 (3.3841)	Learning Rate [0.00125]
5: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00096)	Tok/s 55011 (52995)	Loss/tok 3.3680 (3.3922)	Learning Rate [0.00125]
10: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00097)	Tok/s 55457 (53364)	Loss/tok 3.6160 (3.3885)	Learning Rate [0.00125]
6: TRAIN [1][930/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00100)	Tok/s 54982 (53066)	Loss/tok 3.2587 (3.3908)	Learning Rate [0.00125]
11: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00097)	Tok/s 56122 (53440)	Loss/tok 3.2790 (3.3925)	Learning Rate [0.00125]
8: TRAIN [1][930/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00098)	Tok/s 54965 (53228)	Loss/tok 3.5499 (3.3859)	Learning Rate [0.00125]
9: TRAIN [1][930/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00093)	Tok/s 55001 (53292)	Loss/tok 3.3835 (3.3903)	Learning Rate [0.00125]
7: TRAIN [1][930/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00094)	Tok/s 54901 (53152)	Loss/tok 3.4878 (3.3844)	Learning Rate [0.00125]
13: TRAIN [1][940/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00099)	Tok/s 60135 (53560)	Loss/tok 3.5127 (3.3781)	Learning Rate [0.00125]
12: TRAIN [1][940/3416]	Time 0.068 (0.058)	Data 0.00109 (0.00095)	Tok/s 60023 (53468)	Loss/tok 3.5891 (3.3912)	Learning Rate [0.00125]
11: TRAIN [1][940/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00097)	Tok/s 59957 (53368)	Loss/tok 3.5938 (3.3915)	Learning Rate [0.00125]
14: TRAIN [1][940/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 60174 (53661)	Loss/tok 3.4981 (3.3876)	Learning Rate [0.00125]
15: TRAIN [1][940/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00092)	Tok/s 60101 (53758)	Loss/tok 3.3305 (3.3860)	Learning Rate [0.00125]
10: TRAIN [1][940/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 59828 (53293)	Loss/tok 3.4186 (3.3882)	Learning Rate [0.00125]
0: TRAIN [1][940/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00091)	Tok/s 60103 (52512)	Loss/tok 3.5230 (3.3896)	Learning Rate [0.00125]
9: TRAIN [1][940/3416]	Time 0.068 (0.058)	Data 0.00081 (0.00093)	Tok/s 59819 (53219)	Loss/tok 3.4906 (3.3898)	Learning Rate [0.00125]
8: TRAIN [1][940/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00098)	Tok/s 59647 (53155)	Loss/tok 3.4895 (3.3850)	Learning Rate [0.00125]
1: TRAIN [1][940/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00092)	Tok/s 59953 (52591)	Loss/tok 3.6542 (3.3864)	Learning Rate [0.00125]
2: TRAIN [1][940/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00098)	Tok/s 59815 (52680)	Loss/tok 3.7814 (3.3864)	Learning Rate [0.00125]
7: TRAIN [1][940/3416]	Time 0.068 (0.058)	Data 0.00079 (0.00094)	Tok/s 60123 (53079)	Loss/tok 3.3339 (3.3832)	Learning Rate [0.00125]
5: TRAIN [1][940/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00096)	Tok/s 59640 (52923)	Loss/tok 3.3795 (3.3915)	Learning Rate [0.00125]
4: TRAIN [1][940/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00090)	Tok/s 59738 (52839)	Loss/tok 3.4957 (3.3841)	Learning Rate [0.00125]
6: TRAIN [1][940/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 59556 (52993)	Loss/tok 3.6664 (3.3904)	Learning Rate [0.00125]
3: TRAIN [1][940/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 59728 (52759)	Loss/tok 3.5234 (3.3859)	Learning Rate [0.00125]
8: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00098)	Tok/s 37258 (53141)	Loss/tok 3.1131 (3.3845)	Learning Rate [0.00125]
11: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 37162 (53354)	Loss/tok 3.4921 (3.3913)	Learning Rate [0.00125]
9: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00093)	Tok/s 37116 (53204)	Loss/tok 3.1231 (3.3900)	Learning Rate [0.00125]
10: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00097)	Tok/s 37084 (53279)	Loss/tok 2.9056 (3.3879)	Learning Rate [0.00125]
7: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00094)	Tok/s 37124 (53065)	Loss/tok 3.1637 (3.3826)	Learning Rate [0.00125]
12: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00095)	Tok/s 37034 (53454)	Loss/tok 2.9270 (3.3906)	Learning Rate [0.00125]
5: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00222 (0.00097)	Tok/s 37148 (52908)	Loss/tok 2.9218 (3.3908)	Learning Rate [0.00125]
14: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00092)	Tok/s 37078 (53645)	Loss/tok 3.4149 (3.3869)	Learning Rate [0.00125]
6: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00100)	Tok/s 37149 (52978)	Loss/tok 3.2430 (3.3914)	Learning Rate [0.00125]
13: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00099)	Tok/s 37066 (53545)	Loss/tok 3.0721 (3.3777)	Learning Rate [0.00125]
4: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00090)	Tok/s 37116 (52825)	Loss/tok 3.1532 (3.3841)	Learning Rate [0.00125]
3: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00097)	Tok/s 36762 (52745)	Loss/tok 2.9262 (3.3858)	Learning Rate [0.00125]
15: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00092)	Tok/s 37052 (53741)	Loss/tok 3.3247 (3.3860)	Learning Rate [0.00125]
1: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00092)	Tok/s 35864 (52576)	Loss/tok 2.9140 (3.3860)	Learning Rate [0.00125]
2: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00098)	Tok/s 35823 (52665)	Loss/tok 3.1640 (3.3855)	Learning Rate [0.00125]
0: TRAIN [1][950/3416]	Time 0.052 (0.058)	Data 0.00079 (0.00091)	Tok/s 35669 (52498)	Loss/tok 3.1215 (3.3898)	Learning Rate [0.00125]
6: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00094 (0.00100)	Tok/s 26517 (52952)	Loss/tok 2.6303 (3.3922)	Learning Rate [0.00125]
5: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00103 (0.00097)	Tok/s 26407 (52883)	Loss/tok 2.6245 (3.3905)	Learning Rate [0.00125]
4: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00093 (0.00090)	Tok/s 26374 (52800)	Loss/tok 2.5469 (3.3846)	Learning Rate [0.00125]
7: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00097 (0.00094)	Tok/s 26505 (53039)	Loss/tok 2.6558 (3.3828)	Learning Rate [0.00125]
8: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00109 (0.00098)	Tok/s 27515 (53115)	Loss/tok 2.3680 (3.3836)	Learning Rate [0.00125]
9: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00093 (0.00093)	Tok/s 28206 (53178)	Loss/tok 2.2466 (3.3901)	Learning Rate [0.00125]
3: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00101 (0.00097)	Tok/s 25154 (52720)	Loss/tok 2.4366 (3.3860)	Learning Rate [0.00125]
2: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00101 (0.00098)	Tok/s 24725 (52641)	Loss/tok 2.2104 (3.3856)	Learning Rate [0.00125]
10: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00109 (0.00097)	Tok/s 28135 (53252)	Loss/tok 2.4852 (3.3882)	Learning Rate [0.00125]
11: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00102 (0.00097)	Tok/s 28176 (53327)	Loss/tok 2.3990 (3.3911)	Learning Rate [0.00125]
1: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00090 (0.00092)	Tok/s 24724 (52550)	Loss/tok 2.3314 (3.3852)	Learning Rate [0.00125]
15: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00092 (0.00092)	Tok/s 29731 (53718)	Loss/tok 2.3959 (3.3866)	Learning Rate [0.00125]
0: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00094 (0.00091)	Tok/s 24716 (52472)	Loss/tok 2.3592 (3.3895)	Learning Rate [0.00125]
12: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00102 (0.00095)	Tok/s 28099 (53427)	Loss/tok 2.4823 (3.3905)	Learning Rate [0.00125]
13: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00097 (0.00099)	Tok/s 28060 (53519)	Loss/tok 2.5847 (3.3777)	Learning Rate [0.00125]
14: TRAIN [1][960/3416]	Time 0.039 (0.058)	Data 0.00101 (0.00092)	Tok/s 28977 (53620)	Loss/tok 2.6390 (3.3868)	Learning Rate [0.00125]
5: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00097)	Tok/s 50444 (52879)	Loss/tok 3.4056 (3.3904)	Learning Rate [0.00125]
4: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00090)	Tok/s 50333 (52797)	Loss/tok 3.2461 (3.3844)	Learning Rate [0.00125]
6: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00100)	Tok/s 50498 (52948)	Loss/tok 3.2676 (3.3927)	Learning Rate [0.00125]
3: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00097)	Tok/s 50354 (52717)	Loss/tok 3.1449 (3.3861)	Learning Rate [0.00125]
7: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00094)	Tok/s 50468 (53034)	Loss/tok 3.1795 (3.3822)	Learning Rate [0.00125]
2: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00098)	Tok/s 50349 (52638)	Loss/tok 3.2028 (3.3854)	Learning Rate [0.00125]
8: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00098)	Tok/s 50454 (53109)	Loss/tok 3.2935 (3.3840)	Learning Rate [0.00125]
0: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00091)	Tok/s 50336 (52470)	Loss/tok 3.3869 (3.3894)	Learning Rate [0.00125]
1: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 50349 (52547)	Loss/tok 3.2991 (3.3860)	Learning Rate [0.00125]
9: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00093)	Tok/s 50896 (53172)	Loss/tok 3.4003 (3.3906)	Learning Rate [0.00125]
15: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00091)	Tok/s 51644 (53713)	Loss/tok 3.5308 (3.3871)	Learning Rate [0.00125]
10: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00097)	Tok/s 51696 (53249)	Loss/tok 3.5100 (3.3890)	Learning Rate [0.00125]
11: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00097)	Tok/s 51689 (53324)	Loss/tok 3.3595 (3.3920)	Learning Rate [0.00125]
14: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00092)	Tok/s 51753 (53615)	Loss/tok 3.3017 (3.3873)	Learning Rate [0.00125]
12: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00095)	Tok/s 51699 (53425)	Loss/tok 3.5948 (3.3912)	Learning Rate [0.00125]
13: TRAIN [1][970/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00099)	Tok/s 51624 (53515)	Loss/tok 3.3567 (3.3783)	Learning Rate [0.00125]
12: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00130 (0.00095)	Tok/s 74114 (53409)	Loss/tok 3.5285 (3.3915)	Learning Rate [0.00125]
13: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00123 (0.00099)	Tok/s 74038 (53499)	Loss/tok 3.4635 (3.3786)	Learning Rate [0.00125]
14: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00092)	Tok/s 73904 (53599)	Loss/tok 3.3932 (3.3886)	Learning Rate [0.00125]
11: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00097)	Tok/s 73989 (53308)	Loss/tok 3.5294 (3.3921)	Learning Rate [0.00125]
0: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00091)	Tok/s 73028 (52454)	Loss/tok 3.5913 (3.3896)	Learning Rate [0.00125]
10: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00118 (0.00097)	Tok/s 74009 (53232)	Loss/tok 3.1610 (3.3888)	Learning Rate [0.00125]
1: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 73043 (52531)	Loss/tok 3.4480 (3.3862)	Learning Rate [0.00125]
9: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00093)	Tok/s 74045 (53156)	Loss/tok 3.6315 (3.3913)	Learning Rate [0.00125]
2: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00098)	Tok/s 72974 (52622)	Loss/tok 3.3563 (3.3853)	Learning Rate [0.00125]
8: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00098)	Tok/s 74092 (53093)	Loss/tok 3.6689 (3.3848)	Learning Rate [0.00125]
6: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00100)	Tok/s 73780 (52931)	Loss/tok 3.7227 (3.3933)	Learning Rate [0.00125]
5: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 73188 (52863)	Loss/tok 3.3612 (3.3908)	Learning Rate [0.00125]
7: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00094)	Tok/s 74240 (53019)	Loss/tok 3.4351 (3.3821)	Learning Rate [0.00125]
3: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00097)	Tok/s 73042 (52700)	Loss/tok 3.5078 (3.3868)	Learning Rate [0.00125]
15: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00092)	Tok/s 74033 (53695)	Loss/tok 3.4656 (3.3876)	Learning Rate [0.00125]
4: TRAIN [1][980/3416]	Time 0.070 (0.058)	Data 0.00119 (0.00090)	Tok/s 73087 (52779)	Loss/tok 3.6132 (3.3855)	Learning Rate [0.00125]
9: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 63008 (53140)	Loss/tok 3.3474 (3.3913)	Learning Rate [0.00125]
8: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 63022 (53077)	Loss/tok 3.4885 (3.3850)	Learning Rate [0.00125]
10: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 62929 (53215)	Loss/tok 3.5110 (3.3897)	Learning Rate [0.00125]
7: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00093)	Tok/s 63023 (53002)	Loss/tok 3.5543 (3.3825)	Learning Rate [0.00125]
11: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00096)	Tok/s 63008 (53289)	Loss/tok 3.6709 (3.3921)	Learning Rate [0.00125]
6: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 63071 (52914)	Loss/tok 3.5002 (3.3932)	Learning Rate [0.00125]
12: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00096)	Tok/s 62993 (53390)	Loss/tok 3.5155 (3.3911)	Learning Rate [0.00125]
5: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00096)	Tok/s 63032 (52846)	Loss/tok 3.3297 (3.3903)	Learning Rate [0.00125]
4: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00090)	Tok/s 63021 (52763)	Loss/tok 3.4233 (3.3854)	Learning Rate [0.00125]
13: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00099)	Tok/s 62978 (53481)	Loss/tok 3.7109 (3.3793)	Learning Rate [0.00125]
14: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 63000 (53580)	Loss/tok 3.4336 (3.3885)	Learning Rate [0.00125]
3: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 63038 (52682)	Loss/tok 3.5377 (3.3876)	Learning Rate [0.00125]
0: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 62984 (52436)	Loss/tok 3.4570 (3.3893)	Learning Rate [0.00125]
15: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 63559 (53677)	Loss/tok 3.7532 (3.3884)	Learning Rate [0.00125]
2: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 63023 (52603)	Loss/tok 3.5701 (3.3858)	Learning Rate [0.00125]
1: TRAIN [1][990/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 63019 (52513)	Loss/tok 3.5153 (3.3861)	Learning Rate [0.00125]
9: TRAIN [1][1000/3416]	Time 0.047 (0.058)	Data 0.00083 (0.00093)	Tok/s 50180 (53086)	Loss/tok 3.2171 (3.3912)	Learning Rate [0.00125]
10: TRAIN [1][1000/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00097)	Tok/s 50109 (53161)	Loss/tok 3.3267 (3.3889)	Learning Rate [0.00125]
8: TRAIN [1][1000/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00098)	Tok/s 50118 (53024)	Loss/tok 2.9400 (3.3846)	Learning Rate [0.00125]
7: TRAIN [1][1000/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00093)	Tok/s 49985 (52950)	Loss/tok 3.4329 (3.3820)	Learning Rate [0.00125]
11: TRAIN [1][1000/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00096)	Tok/s 49936 (53236)	Loss/tok 3.5017 (3.3917)	Learning Rate [0.00125]
12: TRAIN [1][1000/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00096)	Tok/s 49842 (53336)	Loss/tok 3.4516 (3.3908)	Learning Rate [0.00125]
5: TRAIN [1][1000/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00096)	Tok/s 49771 (52794)	Loss/tok 3.4950 (3.3899)	Learning Rate [0.00125]
6: TRAIN [1][1000/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00100)	Tok/s 49891 (52861)	Loss/tok 3.3021 (3.3926)	Learning Rate [0.00125]
13: TRAIN [1][1000/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00099)	Tok/s 49699 (53427)	Loss/tok 3.2364 (3.3793)	Learning Rate [0.00125]
14: TRAIN [1][1000/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00092)	Tok/s 49570 (53527)	Loss/tok 2.8319 (3.3876)	Learning Rate [0.00125]
3: TRAIN [1][1000/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00097)	Tok/s 49550 (52631)	Loss/tok 3.4065 (3.3872)	Learning Rate [0.00125]
15: TRAIN [1][1000/3416]	Time 0.048 (0.058)	Data 0.00082 (0.00092)	Tok/s 49495 (53624)	Loss/tok 3.2625 (3.3881)	Learning Rate [0.00125]
2: TRAIN [1][1000/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00098)	Tok/s 49424 (52552)	Loss/tok 3.0847 (3.3848)	Learning Rate [0.00125]
4: TRAIN [1][1000/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00090)	Tok/s 49648 (52712)	Loss/tok 3.0833 (3.3845)	Learning Rate [0.00125]
1: TRAIN [1][1000/3416]	Time 0.048 (0.058)	Data 0.00081 (0.00092)	Tok/s 49325 (52462)	Loss/tok 3.3206 (3.3861)	Learning Rate [0.00125]
0: TRAIN [1][1000/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00091)	Tok/s 49365 (52386)	Loss/tok 3.4003 (3.3888)	Learning Rate [0.00125]
2: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00098)	Tok/s 53045 (52560)	Loss/tok 3.3272 (3.3850)	Learning Rate [0.00125]
3: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00097)	Tok/s 52993 (52638)	Loss/tok 3.1847 (3.3874)	Learning Rate [0.00125]
1: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00092)	Tok/s 53046 (52470)	Loss/tok 3.2193 (3.3855)	Learning Rate [0.00125]
0: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00091)	Tok/s 53045 (52393)	Loss/tok 3.6070 (3.3897)	Learning Rate [0.00125]
4: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00090)	Tok/s 52938 (52718)	Loss/tok 3.3861 (3.3852)	Learning Rate [0.00125]
15: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00082 (0.00092)	Tok/s 53000 (53625)	Loss/tok 3.3494 (3.3877)	Learning Rate [0.00125]
5: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00097)	Tok/s 52978 (52800)	Loss/tok 3.4620 (3.3903)	Learning Rate [0.00125]
13: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00099)	Tok/s 53086 (53430)	Loss/tok 3.5201 (3.3805)	Learning Rate [0.00125]
6: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00100)	Tok/s 52970 (52868)	Loss/tok 3.3183 (3.3917)	Learning Rate [0.00125]
7: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00093)	Tok/s 52934 (52956)	Loss/tok 3.1221 (3.3819)	Learning Rate [0.00125]
12: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00107 (0.00096)	Tok/s 52977 (53340)	Loss/tok 3.3079 (3.3903)	Learning Rate [0.00125]
8: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00098)	Tok/s 52991 (53030)	Loss/tok 3.3224 (3.3846)	Learning Rate [0.00125]
14: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00092)	Tok/s 52989 (53529)	Loss/tok 3.4916 (3.3874)	Learning Rate [0.00125]
11: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00096)	Tok/s 53063 (53241)	Loss/tok 3.2757 (3.3919)	Learning Rate [0.00125]
10: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00097)	Tok/s 53044 (53167)	Loss/tok 3.5618 (3.3897)	Learning Rate [0.00125]
9: TRAIN [1][1010/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00093)	Tok/s 52962 (53092)	Loss/tok 3.7611 (3.3912)	Learning Rate [0.00125]
15: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00092)	Tok/s 34673 (53564)	Loss/tok 3.0920 (3.3873)	Learning Rate [0.00125]
0: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00091)	Tok/s 34662 (52335)	Loss/tok 3.1982 (3.3889)	Learning Rate [0.00125]
12: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00096)	Tok/s 34536 (53281)	Loss/tok 3.1356 (3.3902)	Learning Rate [0.00125]
13: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00099)	Tok/s 34571 (53371)	Loss/tok 3.2381 (3.3794)	Learning Rate [0.00125]
11: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00096)	Tok/s 34463 (53183)	Loss/tok 3.1281 (3.3913)	Learning Rate [0.00125]
1: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00092)	Tok/s 34663 (52413)	Loss/tok 3.0798 (3.3846)	Learning Rate [0.00125]
10: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00097)	Tok/s 34380 (53109)	Loss/tok 3.2075 (3.3886)	Learning Rate [0.00125]
2: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00098)	Tok/s 34628 (52502)	Loss/tok 3.0503 (3.3839)	Learning Rate [0.00125]
3: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00097)	Tok/s 34574 (52579)	Loss/tok 2.9825 (3.3860)	Learning Rate [0.00125]
8: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00097)	Tok/s 34388 (52974)	Loss/tok 2.9253 (3.3843)	Learning Rate [0.00125]
4: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00110 (0.00090)	Tok/s 34502 (52659)	Loss/tok 3.3416 (3.3854)	Learning Rate [0.00125]
7: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00093)	Tok/s 34383 (52900)	Loss/tok 3.0063 (3.3808)	Learning Rate [0.00125]
6: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00100)	Tok/s 34412 (52812)	Loss/tok 3.2697 (3.3903)	Learning Rate [0.00125]
5: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00097)	Tok/s 34443 (52742)	Loss/tok 3.0548 (3.3897)	Learning Rate [0.00125]
14: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00092)	Tok/s 34688 (53469)	Loss/tok 3.1246 (3.3868)	Learning Rate [0.00125]
9: TRAIN [1][1020/3416]	Time 0.052 (0.058)	Data 0.00108 (0.00093)	Tok/s 34380 (53034)	Loss/tok 3.0838 (3.3907)	Learning Rate [0.00125]
15: TRAIN [1][1030/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 61235 (53595)	Loss/tok 3.6495 (3.3879)	Learning Rate [0.00125]
14: TRAIN [1][1030/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 61256 (53501)	Loss/tok 3.8887 (3.3881)	Learning Rate [0.00125]
0: TRAIN [1][1030/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00091)	Tok/s 60963 (52368)	Loss/tok 3.6548 (3.3902)	Learning Rate [0.00125]
13: TRAIN [1][1030/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00099)	Tok/s 61227 (53401)	Loss/tok 3.4225 (3.3801)	Learning Rate [0.00125]
1: TRAIN [1][1030/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 61050 (52445)	Loss/tok 3.6922 (3.3857)	Learning Rate [0.00125]
12: TRAIN [1][1030/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00096)	Tok/s 61269 (53310)	Loss/tok 3.4479 (3.3909)	Learning Rate [0.00125]
2: TRAIN [1][1030/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 60993 (52533)	Loss/tok 3.7032 (3.3851)	Learning Rate [0.00125]
11: TRAIN [1][1030/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 60925 (53213)	Loss/tok 3.4335 (3.3915)	Learning Rate [0.00125]
3: TRAIN [1][1030/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 60898 (52610)	Loss/tok 3.6030 (3.3871)	Learning Rate [0.00125]
10: TRAIN [1][1030/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 60938 (53140)	Loss/tok 3.3167 (3.3888)	Learning Rate [0.00125]
4: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00090)	Tok/s 60734 (52690)	Loss/tok 3.7116 (3.3872)	Learning Rate [0.00125]
5: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00097)	Tok/s 60679 (52775)	Loss/tok 3.6979 (3.3907)	Learning Rate [0.00125]
8: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 60752 (53006)	Loss/tok 3.4213 (3.3846)	Learning Rate [0.00125]
9: TRAIN [1][1030/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00093)	Tok/s 60791 (53066)	Loss/tok 3.5264 (3.3911)	Learning Rate [0.00125]
7: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 60582 (52932)	Loss/tok 3.6887 (3.3826)	Learning Rate [0.00125]
6: TRAIN [1][1030/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00100)	Tok/s 60500 (52844)	Loss/tok 3.5666 (3.3911)	Learning Rate [0.00125]
4: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00090)	Tok/s 55699 (52825)	Loss/tok 3.3395 (3.3868)	Learning Rate [0.00125]
2: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00098)	Tok/s 54861 (52668)	Loss/tok 3.6338 (3.3851)	Learning Rate [0.00125]
3: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00097)	Tok/s 54834 (52745)	Loss/tok 3.7257 (3.3877)	Learning Rate [0.00125]
5: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00097)	Tok/s 55791 (52910)	Loss/tok 3.3039 (3.3909)	Learning Rate [0.00125]
1: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00091)	Tok/s 54882 (52579)	Loss/tok 3.3614 (3.3861)	Learning Rate [0.00125]
0: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00102 (0.00091)	Tok/s 54890 (52502)	Loss/tok 3.1818 (3.3900)	Learning Rate [0.00125]
6: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00101 (0.00100)	Tok/s 55796 (52978)	Loss/tok 3.4362 (3.3914)	Learning Rate [0.00125]
15: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00083 (0.00091)	Tok/s 55870 (53729)	Loss/tok 3.5708 (3.3885)	Learning Rate [0.00125]
14: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00092)	Tok/s 55878 (53635)	Loss/tok 3.5516 (3.3879)	Learning Rate [0.00125]
7: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00093)	Tok/s 55821 (53066)	Loss/tok 3.4334 (3.3827)	Learning Rate [0.00125]
10: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00097)	Tok/s 55876 (53275)	Loss/tok 3.5343 (3.3888)	Learning Rate [0.00125]
8: TRAIN [1][1040/3416]	Time 0.064 (0.058)	Data 0.00117 (0.00097)	Tok/s 56601 (53138)	Loss/tok 3.6087 (3.3845)	Learning Rate [0.00125]
9: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00093)	Tok/s 55868 (53201)	Loss/tok 3.5172 (3.3904)	Learning Rate [0.00125]
11: TRAIN [1][1040/3416]	Time 0.064 (0.058)	Data 0.00105 (0.00096)	Tok/s 56661 (53347)	Loss/tok 3.3379 (3.3916)	Learning Rate [0.00125]
13: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00106 (0.00099)	Tok/s 55885 (53536)	Loss/tok 3.5402 (3.3814)	Learning Rate [0.00125]
12: TRAIN [1][1040/3416]	Time 0.065 (0.058)	Data 0.00114 (0.00096)	Tok/s 55911 (53444)	Loss/tok 3.2882 (3.3909)	Learning Rate [0.00125]
14: TRAIN [1][1050/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00092)	Tok/s 35584 (53661)	Loss/tok 3.0367 (3.3875)	Learning Rate [0.00125]
15: TRAIN [1][1050/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00091)	Tok/s 35534 (53756)	Loss/tok 3.1501 (3.3888)	Learning Rate [0.00125]
0: TRAIN [1][1050/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00091)	Tok/s 34235 (52530)	Loss/tok 2.9538 (3.3893)	Learning Rate [0.00125]
4: TRAIN [1][1050/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00090)	Tok/s 34073 (52852)	Loss/tok 3.1466 (3.3868)	Learning Rate [0.00125]
5: TRAIN [1][1050/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00097)	Tok/s 34065 (52937)	Loss/tok 3.0436 (3.3916)	Learning Rate [0.00125]
1: TRAIN [1][1050/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00091)	Tok/s 34139 (52607)	Loss/tok 2.9341 (3.3863)	Learning Rate [0.00125]
3: TRAIN [1][1050/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00097)	Tok/s 34062 (52772)	Loss/tok 2.9396 (3.3872)	Learning Rate [0.00125]
13: TRAIN [1][1050/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00099)	Tok/s 34765 (53560)	Loss/tok 3.2946 (3.3815)	Learning Rate [0.00125]
2: TRAIN [1][1050/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00098)	Tok/s 34095 (52695)	Loss/tok 2.8524 (3.3843)	Learning Rate [0.00125]
12: TRAIN [1][1050/3416]	Time 0.050 (0.058)	Data 0.00108 (0.00096)	Tok/s 34293 (53469)	Loss/tok 3.0308 (3.3906)	Learning Rate [0.00125]
6: TRAIN [1][1050/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00100)	Tok/s 34090 (53004)	Loss/tok 2.9730 (3.3916)	Learning Rate [0.00125]
7: TRAIN [1][1050/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00093)	Tok/s 34139 (53091)	Loss/tok 3.0536 (3.3825)	Learning Rate [0.00125]
8: TRAIN [1][1050/3416]	Time 0.051 (0.058)	Data 0.00111 (0.00098)	Tok/s 34146 (53162)	Loss/tok 2.8952 (3.3835)	Learning Rate [0.00125]
11: TRAIN [1][1050/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00096)	Tok/s 34240 (53373)	Loss/tok 2.7837 (3.3915)	Learning Rate [0.00125]
10: TRAIN [1][1050/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00097)	Tok/s 34186 (53300)	Loss/tok 2.9562 (3.3877)	Learning Rate [0.00125]
9: TRAIN [1][1050/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00093)	Tok/s 34168 (53225)	Loss/tok 3.1865 (3.3908)	Learning Rate [0.00125]
10: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
1: Gradient norm: inf
0: Gradient norm: inf
2: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
14: Gradient norm: inf
5: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
7: Gradient norm: inf
6: Gradient norm: inf
12: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
9: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
7: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00088 (0.00093)	Tok/s 29684 (53161)	Loss/tok 2.6717 (3.3821)	Learning Rate [0.00125]
8: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00108 (0.00098)	Tok/s 29636 (53232)	Loss/tok 2.7186 (3.3837)	Learning Rate [0.00125]
6: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00113 (0.00100)	Tok/s 29660 (53075)	Loss/tok 2.7266 (3.3914)	Learning Rate [0.00125]
5: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00103 (0.00097)	Tok/s 29683 (53008)	Loss/tok 2.5676 (3.3916)	Learning Rate [0.00125]
4: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00098 (0.00091)	Tok/s 29582 (52922)	Loss/tok 2.8671 (3.3873)	Learning Rate [0.00125]
10: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00098 (0.00097)	Tok/s 29464 (53370)	Loss/tok 2.5970 (3.3887)	Learning Rate [0.00125]
9: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00086 (0.00093)	Tok/s 29504 (53294)	Loss/tok 2.6353 (3.3915)	Learning Rate [0.00125]
2: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00105 (0.00098)	Tok/s 28069 (52763)	Loss/tok 2.5933 (3.3853)	Learning Rate [0.00125]
3: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00099 (0.00097)	Tok/s 28109 (52841)	Loss/tok 2.7137 (3.3872)	Learning Rate [0.00125]
11: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00100 (0.00096)	Tok/s 29384 (53443)	Loss/tok 2.4569 (3.3913)	Learning Rate [0.00125]
12: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00114 (0.00096)	Tok/s 29784 (53539)	Loss/tok 2.6531 (3.3909)	Learning Rate [0.00125]
1: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00089 (0.00091)	Tok/s 27959 (52675)	Loss/tok 2.8105 (3.3867)	Learning Rate [0.00125]
14: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00088 (0.00092)	Tok/s 30940 (53732)	Loss/tok 2.8577 (3.3883)	Learning Rate [0.00125]
0: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00097 (0.00091)	Tok/s 27856 (52598)	Loss/tok 2.8352 (3.3893)	Learning Rate [0.00125]
13: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00095 (0.00099)	Tok/s 30883 (53631)	Loss/tok 2.8767 (3.3816)	Learning Rate [0.00125]
15: TRAIN [1][1060/3416]	Time 0.041 (0.058)	Data 0.00087 (0.00091)	Tok/s 30892 (53827)	Loss/tok 2.9742 (3.3892)	Learning Rate [0.00125]
12: TRAIN [1][1070/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00096)	Tok/s 49293 (53601)	Loss/tok 3.3935 (3.3897)	Learning Rate [0.00125]
11: TRAIN [1][1070/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00096)	Tok/s 49226 (53505)	Loss/tok 3.1633 (3.3908)	Learning Rate [0.00125]
13: TRAIN [1][1070/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00099)	Tok/s 49214 (53692)	Loss/tok 3.2012 (3.3815)	Learning Rate [0.00125]
10: TRAIN [1][1070/3416]	Time 0.044 (0.058)	Data 0.00101 (0.00097)	Tok/s 49071 (53430)	Loss/tok 3.4300 (3.3878)	Learning Rate [0.00125]
14: TRAIN [1][1070/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00092)	Tok/s 49528 (53794)	Loss/tok 3.1780 (3.3875)	Learning Rate [0.00125]
15: TRAIN [1][1070/3416]	Time 0.044 (0.058)	Data 0.00080 (0.00091)	Tok/s 50360 (53891)	Loss/tok 3.1616 (3.3883)	Learning Rate [0.00125]
9: TRAIN [1][1070/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00093)	Tok/s 48982 (53353)	Loss/tok 3.2130 (3.3906)	Learning Rate [0.00125]
8: TRAIN [1][1070/3416]	Time 0.045 (0.058)	Data 0.00107 (0.00098)	Tok/s 48868 (53291)	Loss/tok 3.0159 (3.3827)	Learning Rate [0.00125]
0: TRAIN [1][1070/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00092)	Tok/s 48845 (52656)	Loss/tok 3.3398 (3.3889)	Learning Rate [0.00125]
7: TRAIN [1][1070/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00093)	Tok/s 48743 (53220)	Loss/tok 3.2844 (3.3807)	Learning Rate [0.00125]
1: TRAIN [1][1070/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00091)	Tok/s 48687 (52732)	Loss/tok 3.2716 (3.3868)	Learning Rate [0.00125]
2: TRAIN [1][1070/3416]	Time 0.044 (0.058)	Data 0.00114 (0.00098)	Tok/s 49561 (52820)	Loss/tok 3.3613 (3.3845)	Learning Rate [0.00125]
6: TRAIN [1][1070/3416]	Time 0.044 (0.058)	Data 0.00123 (0.00100)	Tok/s 49527 (53134)	Loss/tok 3.1326 (3.3905)	Learning Rate [0.00125]
4: TRAIN [1][1070/3416]	Time 0.045 (0.058)	Data 0.00103 (0.00091)	Tok/s 48623 (52980)	Loss/tok 3.3373 (3.3869)	Learning Rate [0.00125]
3: TRAIN [1][1070/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 48550 (52897)	Loss/tok 3.2362 (3.3868)	Learning Rate [0.00125]
5: TRAIN [1][1070/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00097)	Tok/s 48585 (53067)	Loss/tok 3.2060 (3.3901)	Learning Rate [0.00125]
9: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00103 (0.00093)	Tok/s 50037 (53353)	Loss/tok 2.9915 (3.3904)	Learning Rate [0.00125]
7: TRAIN [1][1080/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00093)	Tok/s 50167 (53222)	Loss/tok 3.4315 (3.3811)	Learning Rate [0.00125]
6: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00100)	Tok/s 50101 (53137)	Loss/tok 3.2484 (3.3906)	Learning Rate [0.00125]
4: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00107 (0.00091)	Tok/s 49923 (52983)	Loss/tok 3.5345 (3.3871)	Learning Rate [0.00125]
3: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00113 (0.00097)	Tok/s 49718 (52900)	Loss/tok 3.4575 (3.3874)	Learning Rate [0.00125]
5: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00107 (0.00097)	Tok/s 49957 (53070)	Loss/tok 3.4480 (3.3900)	Learning Rate [0.00125]
11: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00101 (0.00096)	Tok/s 49654 (53503)	Loss/tok 3.2184 (3.3912)	Learning Rate [0.00125]
2: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00106 (0.00098)	Tok/s 49631 (52823)	Loss/tok 3.3343 (3.3847)	Learning Rate [0.00125]
12: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00096)	Tok/s 49977 (53599)	Loss/tok 3.5909 (3.3905)	Learning Rate [0.00125]
1: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00120 (0.00091)	Tok/s 49504 (52734)	Loss/tok 3.3357 (3.3869)	Learning Rate [0.00125]
0: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00116 (0.00092)	Tok/s 49668 (52659)	Loss/tok 3.3734 (3.3887)	Learning Rate [0.00125]
8: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00098)	Tok/s 49971 (53292)	Loss/tok 3.3739 (3.3826)	Learning Rate [0.00125]
13: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00099)	Tok/s 50681 (53691)	Loss/tok 3.2309 (3.3813)	Learning Rate [0.00125]
15: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00091)	Tok/s 50603 (53892)	Loss/tok 3.1799 (3.3889)	Learning Rate [0.00125]
14: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00092)	Tok/s 50632 (53793)	Loss/tok 3.4459 (3.3877)	Learning Rate [0.00125]
10: TRAIN [1][1080/3416]	Time 0.049 (0.058)	Data 0.00114 (0.00097)	Tok/s 49423 (53429)	Loss/tok 3.2859 (3.3877)	Learning Rate [0.00125]
14: TRAIN [1][1090/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 68403 (53770)	Loss/tok 3.6437 (3.3888)	Learning Rate [0.00125]
11: TRAIN [1][1090/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00096)	Tok/s 68153 (53482)	Loss/tok 3.4683 (3.3909)	Learning Rate [0.00125]
13: TRAIN [1][1090/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 68293 (53669)	Loss/tok 3.6881 (3.3817)	Learning Rate [0.00125]
10: TRAIN [1][1090/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 68067 (53408)	Loss/tok 3.4786 (3.3878)	Learning Rate [0.00125]
12: TRAIN [1][1090/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00096)	Tok/s 68287 (53577)	Loss/tok 3.6066 (3.3907)	Learning Rate [0.00125]
0: TRAIN [1][1090/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00092)	Tok/s 67448 (52637)	Loss/tok 3.6243 (3.3885)	Learning Rate [0.00125]
9: TRAIN [1][1090/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 68072 (53331)	Loss/tok 3.3544 (3.3897)	Learning Rate [0.00125]
1: TRAIN [1][1090/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00091)	Tok/s 67402 (52712)	Loss/tok 3.5837 (3.3871)	Learning Rate [0.00125]
15: TRAIN [1][1090/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00091)	Tok/s 68364 (53869)	Loss/tok 3.8643 (3.3882)	Learning Rate [0.00125]
7: TRAIN [1][1090/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00093)	Tok/s 68027 (53200)	Loss/tok 3.2762 (3.3802)	Learning Rate [0.00125]
2: TRAIN [1][1090/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 67372 (52800)	Loss/tok 3.4410 (3.3844)	Learning Rate [0.00125]
6: TRAIN [1][1090/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00100)	Tok/s 68035 (53116)	Loss/tok 3.4727 (3.3898)	Learning Rate [0.00125]
5: TRAIN [1][1090/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 68038 (53048)	Loss/tok 3.5280 (3.3899)	Learning Rate [0.00125]
3: TRAIN [1][1090/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 67265 (52877)	Loss/tok 3.5400 (3.3874)	Learning Rate [0.00125]
4: TRAIN [1][1090/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00091)	Tok/s 67538 (52961)	Loss/tok 3.6106 (3.3867)	Learning Rate [0.00125]
8: TRAIN [1][1090/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 67448 (53269)	Loss/tok 3.2402 (3.3826)	Learning Rate [0.00125]
7: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00093)	Tok/s 72283 (53180)	Loss/tok 3.5430 (3.3801)	Learning Rate [0.00125]
6: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00100)	Tok/s 72235 (53096)	Loss/tok 3.4083 (3.3896)	Learning Rate [0.00125]
5: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00097)	Tok/s 72228 (53028)	Loss/tok 3.5896 (3.3900)	Learning Rate [0.00125]
8: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00098)	Tok/s 72293 (53248)	Loss/tok 3.5467 (3.3827)	Learning Rate [0.00125]
4: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00091)	Tok/s 72287 (52942)	Loss/tok 3.5716 (3.3864)	Learning Rate [0.00125]
9: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00093)	Tok/s 72291 (53311)	Loss/tok 3.5434 (3.3892)	Learning Rate [0.00125]
0: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00092)	Tok/s 72103 (52621)	Loss/tok 3.3534 (3.3886)	Learning Rate [0.00125]
15: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 73409 (53850)	Loss/tok 3.4565 (3.3878)	Learning Rate [0.00125]
1: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00092)	Tok/s 72398 (52696)	Loss/tok 3.0750 (3.3862)	Learning Rate [0.00125]
10: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 72616 (53388)	Loss/tok 3.7216 (3.3877)	Learning Rate [0.00125]
3: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 72255 (52859)	Loss/tok 3.4502 (3.3869)	Learning Rate [0.00125]
2: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00098)	Tok/s 72253 (52782)	Loss/tok 3.3966 (3.3838)	Learning Rate [0.00125]
11: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00225 (0.00096)	Tok/s 73159 (53464)	Loss/tok 3.3823 (3.3904)	Learning Rate [0.00125]
12: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00096)	Tok/s 73171 (53559)	Loss/tok 3.4103 (3.3904)	Learning Rate [0.00125]
14: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 73218 (53751)	Loss/tok 3.3186 (3.3885)	Learning Rate [0.00125]
13: TRAIN [1][1100/3416]	Time 0.070 (0.058)	Data 0.00113 (0.00099)	Tok/s 73516 (53650)	Loss/tok 3.4532 (3.3822)	Learning Rate [0.00125]
4: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00091)	Tok/s 59426 (53009)	Loss/tok 3.4147 (3.3869)	Learning Rate [0.00125]
5: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 59452 (53094)	Loss/tok 3.5375 (3.3907)	Learning Rate [0.00125]
7: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 59509 (53245)	Loss/tok 3.8384 (3.3822)	Learning Rate [0.00125]
6: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00100)	Tok/s 59458 (53161)	Loss/tok 3.7406 (3.3905)	Learning Rate [0.00125]
3: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00097)	Tok/s 59280 (52926)	Loss/tok 3.5079 (3.3875)	Learning Rate [0.00125]
2: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 59243 (52850)	Loss/tok 3.5933 (3.3848)	Learning Rate [0.00125]
1: TRAIN [1][1110/3416]	Time 0.068 (0.058)	Data 0.00123 (0.00092)	Tok/s 60268 (52763)	Loss/tok 3.6933 (3.3866)	Learning Rate [0.00125]
8: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 59431 (53314)	Loss/tok 3.3619 (3.3843)	Learning Rate [0.00125]
0: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 59294 (52688)	Loss/tok 3.7157 (3.3903)	Learning Rate [0.00125]
15: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 60287 (53914)	Loss/tok 3.5357 (3.3879)	Learning Rate [0.00125]
14: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 60314 (53815)	Loss/tok 3.6867 (3.3891)	Learning Rate [0.00125]
9: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 59495 (53376)	Loss/tok 3.4772 (3.3900)	Learning Rate [0.00125]
11: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 59417 (53527)	Loss/tok 3.9426 (3.3918)	Learning Rate [0.00125]
12: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00096)	Tok/s 59581 (53622)	Loss/tok 3.6640 (3.3911)	Learning Rate [0.00125]
13: TRAIN [1][1110/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00099)	Tok/s 60245 (53713)	Loss/tok 3.4515 (3.3836)	Learning Rate [0.00125]
10: TRAIN [1][1110/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00097)	Tok/s 57903 (53451)	Loss/tok 3.4721 (3.3879)	Learning Rate [0.00125]
4: TRAIN [1][1120/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00091)	Tok/s 50199 (53034)	Loss/tok 3.4717 (3.3877)	Learning Rate [0.00125]
2: TRAIN [1][1120/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00098)	Tok/s 50136 (52877)	Loss/tok 3.2609 (3.3851)	Learning Rate [0.00125]
5: TRAIN [1][1120/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00097)	Tok/s 50068 (53119)	Loss/tok 3.2784 (3.3907)	Learning Rate [0.00125]
3: TRAIN [1][1120/3416]	Time 0.046 (0.058)	Data 0.00108 (0.00097)	Tok/s 50263 (52952)	Loss/tok 3.1878 (3.3877)	Learning Rate [0.00125]
1: TRAIN [1][1120/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00092)	Tok/s 50078 (52790)	Loss/tok 3.2116 (3.3867)	Learning Rate [0.00125]
6: TRAIN [1][1120/3416]	Time 0.046 (0.058)	Data 0.00102 (0.00100)	Tok/s 49909 (53185)	Loss/tok 3.5663 (3.3908)	Learning Rate [0.00125]
7: TRAIN [1][1120/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00093)	Tok/s 49794 (53268)	Loss/tok 3.5284 (3.3827)	Learning Rate [0.00125]
8: TRAIN [1][1120/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00098)	Tok/s 49666 (53336)	Loss/tok 3.5316 (3.3842)	Learning Rate [0.00125]
0: TRAIN [1][1120/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00092)	Tok/s 49898 (52715)	Loss/tok 3.2510 (3.3905)	Learning Rate [0.00125]
11: TRAIN [1][1120/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00097)	Tok/s 49555 (53550)	Loss/tok 3.4190 (3.3926)	Learning Rate [0.00125]
15: TRAIN [1][1120/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00092)	Tok/s 51199 (53938)	Loss/tok 3.2887 (3.3879)	Learning Rate [0.00125]
12: TRAIN [1][1120/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00096)	Tok/s 49586 (53644)	Loss/tok 3.5844 (3.3908)	Learning Rate [0.00125]
9: TRAIN [1][1120/3416]	Time 0.047 (0.058)	Data 0.00113 (0.00093)	Tok/s 49540 (53398)	Loss/tok 3.3133 (3.3904)	Learning Rate [0.00125]
14: TRAIN [1][1120/3416]	Time 0.046 (0.058)	Data 0.00100 (0.00092)	Tok/s 50192 (53838)	Loss/tok 3.3834 (3.3886)	Learning Rate [0.00125]
10: TRAIN [1][1120/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00097)	Tok/s 49409 (53476)	Loss/tok 3.1455 (3.3881)	Learning Rate [0.00125]
13: TRAIN [1][1120/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00099)	Tok/s 49499 (53735)	Loss/tok 3.4213 (3.3840)	Learning Rate [0.00125]
12: TRAIN [1][1130/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00096)	Tok/s 54569 (53654)	Loss/tok 3.7681 (3.3910)	Learning Rate [0.00125]
13: TRAIN [1][1130/3416]	Time 0.063 (0.058)	Data 0.00085 (0.00099)	Tok/s 54882 (53747)	Loss/tok 3.4326 (3.3845)	Learning Rate [0.00125]
14: TRAIN [1][1130/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00092)	Tok/s 55389 (53850)	Loss/tok 3.4642 (3.3887)	Learning Rate [0.00125]
11: TRAIN [1][1130/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00097)	Tok/s 54539 (53561)	Loss/tok 3.3951 (3.3920)	Learning Rate [0.00125]
10: TRAIN [1][1130/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00097)	Tok/s 54557 (53487)	Loss/tok 3.6521 (3.3883)	Learning Rate [0.00125]
15: TRAIN [1][1130/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00092)	Tok/s 55350 (53950)	Loss/tok 3.4643 (3.3883)	Learning Rate [0.00125]
9: TRAIN [1][1130/3416]	Time 0.063 (0.058)	Data 0.00082 (0.00093)	Tok/s 54556 (53410)	Loss/tok 3.2741 (3.3904)	Learning Rate [0.00125]
1: TRAIN [1][1130/3416]	Time 0.064 (0.058)	Data 0.00083 (0.00092)	Tok/s 54355 (52803)	Loss/tok 3.7381 (3.3870)	Learning Rate [0.00125]
0: TRAIN [1][1130/3416]	Time 0.064 (0.058)	Data 0.00085 (0.00092)	Tok/s 54314 (52728)	Loss/tok 3.6423 (3.3910)	Learning Rate [0.00125]
8: TRAIN [1][1130/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00098)	Tok/s 54553 (53347)	Loss/tok 3.3545 (3.3844)	Learning Rate [0.00125]
2: TRAIN [1][1130/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00098)	Tok/s 54373 (52889)	Loss/tok 3.4182 (3.3847)	Learning Rate [0.00125]
7: TRAIN [1][1130/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00093)	Tok/s 54533 (53279)	Loss/tok 3.2331 (3.3829)	Learning Rate [0.00125]
3: TRAIN [1][1130/3416]	Time 0.064 (0.058)	Data 0.00102 (0.00097)	Tok/s 54392 (52965)	Loss/tok 3.4091 (3.3876)	Learning Rate [0.00125]
5: TRAIN [1][1130/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00097)	Tok/s 54454 (53130)	Loss/tok 3.5435 (3.3909)	Learning Rate [0.00125]
6: TRAIN [1][1130/3416]	Time 0.063 (0.058)	Data 0.00084 (0.00100)	Tok/s 54523 (53196)	Loss/tok 3.7312 (3.3907)	Learning Rate [0.00125]
4: TRAIN [1][1130/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00091)	Tok/s 54383 (53045)	Loss/tok 3.3948 (3.3882)	Learning Rate [0.00125]
13: TRAIN [1][1140/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00099)	Tok/s 57782 (53741)	Loss/tok 3.4753 (3.3841)	Learning Rate [0.00125]
12: TRAIN [1][1140/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00096)	Tok/s 57642 (53648)	Loss/tok 3.4588 (3.3906)	Learning Rate [0.00125]
14: TRAIN [1][1140/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00092)	Tok/s 57771 (53845)	Loss/tok 3.2204 (3.3880)	Learning Rate [0.00125]
15: TRAIN [1][1140/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00092)	Tok/s 57784 (53945)	Loss/tok 3.3082 (3.3880)	Learning Rate [0.00125]
11: TRAIN [1][1140/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00097)	Tok/s 57674 (53553)	Loss/tok 3.6036 (3.3915)	Learning Rate [0.00125]
10: TRAIN [1][1140/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00097)	Tok/s 57648 (53479)	Loss/tok 3.7336 (3.3885)	Learning Rate [0.00125]
0: TRAIN [1][1140/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00092)	Tok/s 56763 (52722)	Loss/tok 3.5492 (3.3907)	Learning Rate [0.00125]
9: TRAIN [1][1140/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00093)	Tok/s 57670 (53402)	Loss/tok 3.7074 (3.3899)	Learning Rate [0.00125]
8: TRAIN [1][1140/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00098)	Tok/s 57676 (53339)	Loss/tok 3.4146 (3.3843)	Learning Rate [0.00125]
1: TRAIN [1][1140/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00092)	Tok/s 56765 (52796)	Loss/tok 3.6514 (3.3872)	Learning Rate [0.00125]
2: TRAIN [1][1140/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00098)	Tok/s 56781 (52881)	Loss/tok 3.2276 (3.3842)	Learning Rate [0.00125]
7: TRAIN [1][1140/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00093)	Tok/s 57644 (53271)	Loss/tok 3.5222 (3.3828)	Learning Rate [0.00125]
5: TRAIN [1][1140/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00097)	Tok/s 57717 (53123)	Loss/tok 3.6681 (3.3907)	Learning Rate [0.00125]
6: TRAIN [1][1140/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00100)	Tok/s 57670 (53189)	Loss/tok 3.4118 (3.3905)	Learning Rate [0.00125]
4: TRAIN [1][1140/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00091)	Tok/s 57699 (53039)	Loss/tok 3.4654 (3.3872)	Learning Rate [0.00125]
3: TRAIN [1][1140/3416]	Time 0.066 (0.058)	Data 0.00100 (0.00097)	Tok/s 57181 (52959)	Loss/tok 3.3346 (3.3874)	Learning Rate [0.00125]
15: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00099 (0.00092)	Tok/s 80063 (53934)	Loss/tok 3.3188 (3.3877)	Learning Rate [0.00125]
14: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00098 (0.00092)	Tok/s 79351 (53834)	Loss/tok 3.2569 (3.3875)	Learning Rate [0.00125]
13: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00096 (0.00099)	Tok/s 79304 (53730)	Loss/tok 3.3260 (3.3838)	Learning Rate [0.00125]
1: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00092 (0.00092)	Tok/s 77427 (52785)	Loss/tok 3.3443 (3.3865)	Learning Rate [0.00125]
12: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00100 (0.00096)	Tok/s 79322 (53637)	Loss/tok 3.2422 (3.3901)	Learning Rate [0.00125]
11: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00106 (0.00097)	Tok/s 79335 (53543)	Loss/tok 3.3719 (3.3910)	Learning Rate [0.00125]
3: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00109 (0.00097)	Tok/s 78278 (52949)	Loss/tok 3.2339 (3.3872)	Learning Rate [0.00125]
2: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00101 (0.00098)	Tok/s 77716 (52871)	Loss/tok 3.3283 (3.3840)	Learning Rate [0.00125]
10: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00099 (0.00097)	Tok/s 79309 (53469)	Loss/tok 3.4885 (3.3881)	Learning Rate [0.00125]
4: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00096 (0.00091)	Tok/s 78339 (53030)	Loss/tok 3.3998 (3.3867)	Learning Rate [0.00125]
9: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00103 (0.00093)	Tok/s 79242 (53392)	Loss/tok 3.1141 (3.3888)	Learning Rate [0.00125]
5: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00104 (0.00097)	Tok/s 78328 (53112)	Loss/tok 3.3568 (3.3901)	Learning Rate [0.00125]
8: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00110 (0.00098)	Tok/s 78400 (53329)	Loss/tok 3.3808 (3.3837)	Learning Rate [0.00125]
6: TRAIN [1][1150/3416]	Time 0.072 (0.058)	Data 0.00098 (0.00100)	Tok/s 78271 (53179)	Loss/tok 3.4284 (3.3897)	Learning Rate [0.00125]
0: TRAIN [1][1150/3416]	Time 0.073 (0.058)	Data 0.00107 (0.00092)	Tok/s 76594 (52711)	Loss/tok 3.2710 (3.3902)	Learning Rate [0.00125]
7: TRAIN [1][1150/3416]	Time 0.073 (0.058)	Data 0.00097 (0.00093)	Tok/s 77415 (53261)	Loss/tok 3.3666 (3.3826)	Learning Rate [0.00125]
4: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00091)	Tok/s 52304 (52991)	Loss/tok 3.5985 (3.3869)	Learning Rate [0.00125]
5: TRAIN [1][1160/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00097)	Tok/s 52435 (53073)	Loss/tok 3.4239 (3.3901)	Learning Rate [0.00125]
6: TRAIN [1][1160/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00100)	Tok/s 52481 (53139)	Loss/tok 3.1944 (3.3890)	Learning Rate [0.00125]
7: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00093)	Tok/s 52387 (53221)	Loss/tok 3.0469 (3.3820)	Learning Rate [0.00125]
3: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00104 (0.00097)	Tok/s 52204 (52911)	Loss/tok 3.4136 (3.3868)	Learning Rate [0.00125]
2: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00098)	Tok/s 52097 (52833)	Loss/tok 3.3994 (3.3839)	Learning Rate [0.00125]
1: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00092)	Tok/s 52034 (52748)	Loss/tok 3.3720 (3.3864)	Learning Rate [0.00125]
0: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00092)	Tok/s 52047 (52673)	Loss/tok 3.6024 (3.3900)	Learning Rate [0.00125]
9: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00093)	Tok/s 52353 (53351)	Loss/tok 3.2551 (3.3891)	Learning Rate [0.00125]
15: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00085 (0.00092)	Tok/s 52087 (53895)	Loss/tok 3.3266 (3.3879)	Learning Rate [0.00125]
10: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00097)	Tok/s 52342 (53428)	Loss/tok 3.2701 (3.3878)	Learning Rate [0.00125]
14: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00092)	Tok/s 52051 (53792)	Loss/tok 3.4033 (3.3878)	Learning Rate [0.00125]
11: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00097)	Tok/s 52357 (53503)	Loss/tok 3.3993 (3.3910)	Learning Rate [0.00125]
12: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00096)	Tok/s 52107 (53596)	Loss/tok 3.4988 (3.3898)	Learning Rate [0.00125]
13: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00099)	Tok/s 52111 (53689)	Loss/tok 3.4291 (3.3830)	Learning Rate [0.00125]
8: TRAIN [1][1160/3416]	Time 0.053 (0.058)	Data 0.00103 (0.00098)	Tok/s 52195 (53288)	Loss/tok 3.2797 (3.3831)	Learning Rate [0.00125]
12: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00096)	Tok/s 59616 (53630)	Loss/tok 3.5676 (3.3905)	Learning Rate [0.00125]
11: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00097)	Tok/s 59557 (53537)	Loss/tok 3.5174 (3.3911)	Learning Rate [0.00125]
13: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 59627 (53724)	Loss/tok 3.6205 (3.3834)	Learning Rate [0.00125]
10: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00097)	Tok/s 59396 (53462)	Loss/tok 3.5085 (3.3874)	Learning Rate [0.00125]
14: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 59601 (53826)	Loss/tok 3.6803 (3.3878)	Learning Rate [0.00125]
9: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 59323 (53384)	Loss/tok 3.5532 (3.3896)	Learning Rate [0.00125]
15: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 59653 (53929)	Loss/tok 3.4821 (3.3875)	Learning Rate [0.00125]
8: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00098)	Tok/s 59330 (53321)	Loss/tok 3.6220 (3.3832)	Learning Rate [0.00125]
0: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 59392 (52707)	Loss/tok 3.4607 (3.3904)	Learning Rate [0.00125]
1: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 59359 (52781)	Loss/tok 3.2765 (3.3861)	Learning Rate [0.00125]
7: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 59253 (53253)	Loss/tok 3.6030 (3.3818)	Learning Rate [0.00125]
6: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00100)	Tok/s 59307 (53171)	Loss/tok 3.7102 (3.3883)	Learning Rate [0.00125]
2: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 59337 (52866)	Loss/tok 3.5065 (3.3836)	Learning Rate [0.00125]
4: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00091)	Tok/s 59270 (53023)	Loss/tok 3.7317 (3.3875)	Learning Rate [0.00125]
3: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00097)	Tok/s 59313 (52943)	Loss/tok 3.5394 (3.3867)	Learning Rate [0.00125]
5: TRAIN [1][1170/3416]	Time 0.069 (0.058)	Data 0.00125 (0.00097)	Tok/s 59375 (53105)	Loss/tok 3.5089 (3.3909)	Learning Rate [0.00125]
1: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 70868 (52823)	Loss/tok 3.5017 (3.3864)	Learning Rate [0.00125]
4: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 70673 (53069)	Loss/tok 3.4099 (3.3884)	Learning Rate [0.00125]
9: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 71705 (53435)	Loss/tok 3.5751 (3.3896)	Learning Rate [0.00125]
0: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 70894 (52747)	Loss/tok 3.3947 (3.3904)	Learning Rate [0.00125]
2: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 70747 (52909)	Loss/tok 3.3355 (3.3837)	Learning Rate [0.00125]
8: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 71582 (53372)	Loss/tok 3.2011 (3.3833)	Learning Rate [0.00125]
5: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 70615 (53153)	Loss/tok 3.3833 (3.3910)	Learning Rate [0.00125]
10: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00097)	Tok/s 71579 (53512)	Loss/tok 3.2692 (3.3873)	Learning Rate [0.00125]
12: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 71702 (53682)	Loss/tok 3.6855 (3.3913)	Learning Rate [0.00125]
6: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00100)	Tok/s 70539 (53220)	Loss/tok 3.6834 (3.3886)	Learning Rate [0.00125]
15: TRAIN [1][1180/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 71841 (53981)	Loss/tok 3.2803 (3.3883)	Learning Rate [0.00125]
11: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00097)	Tok/s 71795 (53588)	Loss/tok 3.3990 (3.3911)	Learning Rate [0.00125]
7: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00093)	Tok/s 71185 (53303)	Loss/tok 3.8160 (3.3830)	Learning Rate [0.00125]
3: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00097)	Tok/s 70694 (52988)	Loss/tok 3.6469 (3.3879)	Learning Rate [0.00125]
14: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 71704 (53878)	Loss/tok 3.5941 (3.3882)	Learning Rate [0.00125]
13: TRAIN [1][1180/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00099)	Tok/s 71785 (53776)	Loss/tok 3.5058 (3.3849)	Learning Rate [0.00125]
13: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
5: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00097)	Tok/s 29048 (53119)	Loss/tok 2.8197 (3.3913)	Learning Rate [0.00125]
4: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00091)	Tok/s 29054 (53035)	Loss/tok 2.6781 (3.3882)	Learning Rate [0.00125]
7: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00078 (0.00093)	Tok/s 30362 (53270)	Loss/tok 2.6057 (3.3824)	Learning Rate [0.00125]
6: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00105 (0.00100)	Tok/s 29791 (53186)	Loss/tok 2.8847 (3.3881)	Learning Rate [0.00125]
2: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00098)	Tok/s 29053 (52877)	Loss/tok 2.8691 (3.3844)	Learning Rate [0.00125]
3: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00097)	Tok/s 29066 (52955)	Loss/tok 2.9867 (3.3875)	Learning Rate [0.00125]
8: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00098)	Tok/s 30331 (53339)	Loss/tok 2.7508 (3.3827)	Learning Rate [0.00125]
1: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00092)	Tok/s 29062 (52792)	Loss/tok 2.8310 (3.3865)	Learning Rate [0.00125]
0: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00092)	Tok/s 29062 (52716)	Loss/tok 2.7889 (3.3907)	Learning Rate [0.00125]
9: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00093)	Tok/s 30326 (53401)	Loss/tok 2.8054 (3.3892)	Learning Rate [0.00125]
10: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00108 (0.00097)	Tok/s 30342 (53479)	Loss/tok 2.8343 (3.3868)	Learning Rate [0.00125]
11: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00102 (0.00097)	Tok/s 30342 (53555)	Loss/tok 2.7299 (3.3908)	Learning Rate [0.00125]
12: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00096)	Tok/s 30377 (53650)	Loss/tok 2.7512 (3.3911)	Learning Rate [0.00125]
15: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00092)	Tok/s 31933 (53950)	Loss/tok 3.0001 (3.3881)	Learning Rate [0.00125]
14: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00093)	Tok/s 31730 (53848)	Loss/tok 2.8366 (3.3882)	Learning Rate [0.00125]
13: TRAIN [1][1190/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00099)	Tok/s 30373 (53744)	Loss/tok 2.7915 (3.3847)	Learning Rate [0.00125]
13: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00099)	Tok/s 57670 (53738)	Loss/tok 3.6860 (3.3844)	Learning Rate [0.00125]
14: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00093)	Tok/s 57582 (53841)	Loss/tok 3.4409 (3.3884)	Learning Rate [0.00125]
15: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 57469 (53944)	Loss/tok 3.5990 (3.3879)	Learning Rate [0.00125]
12: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00096)	Tok/s 57655 (53643)	Loss/tok 3.4633 (3.3908)	Learning Rate [0.00125]
0: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00092)	Tok/s 56570 (52695)	Loss/tok 3.3006 (3.3901)	Learning Rate [0.00125]
11: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00097)	Tok/s 57749 (53548)	Loss/tok 3.3983 (3.3905)	Learning Rate [0.00125]
2: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00098)	Tok/s 57218 (52863)	Loss/tok 3.5832 (3.3850)	Learning Rate [0.00125]
1: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00113 (0.00092)	Tok/s 57263 (52774)	Loss/tok 3.5521 (3.3866)	Learning Rate [0.00125]
10: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00097)	Tok/s 57489 (53472)	Loss/tok 3.4872 (3.3862)	Learning Rate [0.00125]
3: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00118 (0.00097)	Tok/s 57145 (52943)	Loss/tok 3.5899 (3.3879)	Learning Rate [0.00125]
9: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00093)	Tok/s 57430 (53394)	Loss/tok 3.3956 (3.3888)	Learning Rate [0.00125]
8: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00098)	Tok/s 57368 (53331)	Loss/tok 3.6478 (3.3824)	Learning Rate [0.00125]
4: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00091)	Tok/s 57081 (53023)	Loss/tok 3.5753 (3.3882)	Learning Rate [0.00125]
6: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00100)	Tok/s 57235 (53176)	Loss/tok 3.3862 (3.3878)	Learning Rate [0.00125]
7: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00093)	Tok/s 57285 (53261)	Loss/tok 3.8650 (3.3826)	Learning Rate [0.00125]
5: TRAIN [1][1200/3416]	Time 0.068 (0.058)	Data 0.00106 (0.00097)	Tok/s 57081 (53108)	Loss/tok 3.4616 (3.3911)	Learning Rate [0.00125]
2: TRAIN [1][1210/3416]	Time 0.056 (0.058)	Data 0.00096 (0.00098)	Tok/s 51362 (52797)	Loss/tok 3.3832 (3.3845)	Learning Rate [0.00125]
1: TRAIN [1][1210/3416]	Time 0.056 (0.058)	Data 0.00096 (0.00092)	Tok/s 51330 (52706)	Loss/tok 3.2313 (3.3858)	Learning Rate [0.00125]
3: TRAIN [1][1210/3416]	Time 0.056 (0.058)	Data 0.00111 (0.00097)	Tok/s 51318 (52877)	Loss/tok 3.3263 (3.3868)	Learning Rate [0.00125]
4: TRAIN [1][1210/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00091)	Tok/s 52211 (52960)	Loss/tok 3.3492 (3.3876)	Learning Rate [0.00125]
0: TRAIN [1][1210/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00092)	Tok/s 51317 (52625)	Loss/tok 3.1960 (3.3891)	Learning Rate [0.00125]
14: TRAIN [1][1210/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00093)	Tok/s 52261 (53782)	Loss/tok 3.3733 (3.3878)	Learning Rate [0.00125]
15: TRAIN [1][1210/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00092)	Tok/s 52374 (53886)	Loss/tok 3.3763 (3.3865)	Learning Rate [0.00125]
5: TRAIN [1][1210/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00097)	Tok/s 52074 (53047)	Loss/tok 3.6876 (3.3906)	Learning Rate [0.00125]
6: TRAIN [1][1210/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00100)	Tok/s 51938 (53115)	Loss/tok 3.3814 (3.3869)	Learning Rate [0.00125]
13: TRAIN [1][1210/3416]	Time 0.056 (0.058)	Data 0.00087 (0.00099)	Tok/s 52175 (53680)	Loss/tok 3.3054 (3.3837)	Learning Rate [0.00125]
7: TRAIN [1][1210/3416]	Time 0.057 (0.058)	Data 0.00086 (0.00093)	Tok/s 51909 (53201)	Loss/tok 3.3734 (3.3819)	Learning Rate [0.00125]
12: TRAIN [1][1210/3416]	Time 0.057 (0.058)	Data 0.00086 (0.00096)	Tok/s 52047 (53585)	Loss/tok 3.1832 (3.3894)	Learning Rate [0.00125]
8: TRAIN [1][1210/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00098)	Tok/s 51786 (53270)	Loss/tok 3.4941 (3.3820)	Learning Rate [0.00125]
11: TRAIN [1][1210/3416]	Time 0.057 (0.058)	Data 0.00112 (0.00097)	Tok/s 51960 (53490)	Loss/tok 3.3353 (3.3899)	Learning Rate [0.00125]
9: TRAIN [1][1210/3416]	Time 0.057 (0.058)	Data 0.00085 (0.00093)	Tok/s 51796 (53333)	Loss/tok 3.3386 (3.3884)	Learning Rate [0.00125]
10: TRAIN [1][1210/3416]	Time 0.057 (0.058)	Data 0.00088 (0.00097)	Tok/s 51773 (53412)	Loss/tok 3.6751 (3.3857)	Learning Rate [0.00125]
3: Gradient norm: inf
2: Gradient norm: inf
4: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
6: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
14: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
9: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
13: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
9: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00083 (0.00093)	Tok/s 55553 (53351)	Loss/tok 3.6229 (3.3885)	Learning Rate [0.00125]
10: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00097)	Tok/s 55453 (53430)	Loss/tok 3.6974 (3.3860)	Learning Rate [0.00125]
8: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00098)	Tok/s 55549 (53286)	Loss/tok 3.2908 (3.3818)	Learning Rate [0.00125]
11: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00104 (0.00097)	Tok/s 55445 (53506)	Loss/tok 3.3965 (3.3905)	Learning Rate [0.00125]
7: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00093)	Tok/s 55523 (53216)	Loss/tok 3.5804 (3.3825)	Learning Rate [0.00125]
12: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00096)	Tok/s 55456 (53601)	Loss/tok 3.3363 (3.3895)	Learning Rate [0.00125]
6: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00100)	Tok/s 55517 (53131)	Loss/tok 3.3981 (3.3866)	Learning Rate [0.00125]
13: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00092 (0.00099)	Tok/s 55523 (53695)	Loss/tok 3.5967 (3.3849)	Learning Rate [0.00125]
5: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00097)	Tok/s 55541 (53061)	Loss/tok 3.3108 (3.3898)	Learning Rate [0.00125]
3: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00104 (0.00097)	Tok/s 55621 (52893)	Loss/tok 3.3752 (3.3863)	Learning Rate [0.00125]
14: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00093)	Tok/s 55433 (53796)	Loss/tok 3.1594 (3.3877)	Learning Rate [0.00125]
15: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00092)	Tok/s 55440 (53900)	Loss/tok 3.6410 (3.3867)	Learning Rate [0.00125]
2: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00098)	Tok/s 55529 (52812)	Loss/tok 3.4410 (3.3842)	Learning Rate [0.00125]
1: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00102 (0.00092)	Tok/s 55502 (52722)	Loss/tok 3.4539 (3.3857)	Learning Rate [0.00125]
0: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00092)	Tok/s 54927 (52640)	Loss/tok 3.4676 (3.3892)	Learning Rate [0.00125]
4: TRAIN [1][1220/3416]	Time 0.061 (0.058)	Data 0.00089 (0.00091)	Tok/s 55492 (52974)	Loss/tok 3.3059 (3.3872)	Learning Rate [0.00125]
12: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00096)	Tok/s 52910 (53570)	Loss/tok 3.2590 (3.3892)	Learning Rate [0.00125]
11: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00101 (0.00097)	Tok/s 52816 (53475)	Loss/tok 3.5505 (3.3904)	Learning Rate [0.00125]
13: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00099)	Tok/s 52881 (53665)	Loss/tok 3.3513 (3.3848)	Learning Rate [0.00125]
10: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00097)	Tok/s 52680 (53399)	Loss/tok 3.3067 (3.3852)	Learning Rate [0.00125]
14: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00093)	Tok/s 52883 (53765)	Loss/tok 3.4354 (3.3876)	Learning Rate [0.00125]
15: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00092)	Tok/s 52928 (53868)	Loss/tok 3.1600 (3.3861)	Learning Rate [0.00125]
9: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00080 (0.00093)	Tok/s 52608 (53320)	Loss/tok 3.3646 (3.3886)	Learning Rate [0.00125]
0: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00092)	Tok/s 51751 (52612)	Loss/tok 3.6604 (3.3893)	Learning Rate [0.00125]
8: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00098)	Tok/s 52573 (53256)	Loss/tok 3.3189 (3.3815)	Learning Rate [0.00125]
1: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00092)	Tok/s 51711 (52693)	Loss/tok 3.3779 (3.3855)	Learning Rate [0.00125]
7: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00083 (0.00093)	Tok/s 52617 (53185)	Loss/tok 3.3246 (3.3824)	Learning Rate [0.00125]
2: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00098)	Tok/s 51600 (52783)	Loss/tok 3.3821 (3.3843)	Learning Rate [0.00125]
6: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00103 (0.00100)	Tok/s 52599 (53100)	Loss/tok 3.4485 (3.3867)	Learning Rate [0.00125]
5: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00086 (0.00097)	Tok/s 52537 (53031)	Loss/tok 3.3478 (3.3893)	Learning Rate [0.00125]
4: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00091)	Tok/s 52348 (52945)	Loss/tok 3.3771 (3.3876)	Learning Rate [0.00125]
3: TRAIN [1][1230/3416]	Time 0.056 (0.058)	Data 0.00100 (0.00097)	Tok/s 51531 (52863)	Loss/tok 3.2458 (3.3863)	Learning Rate [0.00125]
0: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 65622 (52583)	Loss/tok 3.4078 (3.3883)	Learning Rate [0.00125]
15: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 66527 (53837)	Loss/tok 3.4615 (3.3854)	Learning Rate [0.00125]
10: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 65907 (53367)	Loss/tok 3.6702 (3.3849)	Learning Rate [0.00125]
11: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 66737 (53443)	Loss/tok 3.3086 (3.3900)	Learning Rate [0.00125]
14: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 66581 (53734)	Loss/tok 3.4415 (3.3871)	Learning Rate [0.00125]
2: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00098)	Tok/s 65638 (52754)	Loss/tok 3.4314 (3.3841)	Learning Rate [0.00125]
12: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 66626 (53538)	Loss/tok 3.7608 (3.3888)	Learning Rate [0.00125]
13: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00099)	Tok/s 66584 (53633)	Loss/tok 3.5752 (3.3848)	Learning Rate [0.00125]
9: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 65646 (53289)	Loss/tok 3.6595 (3.3886)	Learning Rate [0.00125]
3: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 65582 (52833)	Loss/tok 3.2590 (3.3858)	Learning Rate [0.00125]
8: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00098)	Tok/s 65577 (53225)	Loss/tok 3.5294 (3.3813)	Learning Rate [0.00125]
1: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 65601 (52663)	Loss/tok 3.7995 (3.3852)	Learning Rate [0.00125]
4: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00091)	Tok/s 65544 (52915)	Loss/tok 3.6275 (3.3875)	Learning Rate [0.00125]
7: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 65448 (53155)	Loss/tok 3.3546 (3.3820)	Learning Rate [0.00125]
6: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00100)	Tok/s 65444 (53071)	Loss/tok 3.4695 (3.3863)	Learning Rate [0.00125]
5: TRAIN [1][1240/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 65485 (53001)	Loss/tok 3.4083 (3.3886)	Learning Rate [0.00125]
12: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00096)	Tok/s 58550 (53549)	Loss/tok 3.6793 (3.3897)	Learning Rate [0.00125]
13: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00099)	Tok/s 58542 (53643)	Loss/tok 3.4522 (3.3855)	Learning Rate [0.00125]
15: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00091)	Tok/s 58456 (53847)	Loss/tok 3.6426 (3.3854)	Learning Rate [0.00125]
14: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00093)	Tok/s 58466 (53744)	Loss/tok 3.4159 (3.3878)	Learning Rate [0.00125]
0: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 57433 (52593)	Loss/tok 3.3593 (3.3880)	Learning Rate [0.00125]
11: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00097)	Tok/s 58377 (53455)	Loss/tok 3.5830 (3.3897)	Learning Rate [0.00125]
10: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00097)	Tok/s 58268 (53379)	Loss/tok 3.7089 (3.3855)	Learning Rate [0.00125]
9: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00079 (0.00093)	Tok/s 57676 (53301)	Loss/tok 3.6936 (3.3890)	Learning Rate [0.00125]
1: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00092)	Tok/s 57349 (52673)	Loss/tok 3.6390 (3.3857)	Learning Rate [0.00125]
8: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00097)	Tok/s 57130 (53237)	Loss/tok 3.3987 (3.3817)	Learning Rate [0.00125]
2: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00098)	Tok/s 57364 (52762)	Loss/tok 3.5710 (3.3842)	Learning Rate [0.00125]
7: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00093)	Tok/s 57186 (53166)	Loss/tok 3.5090 (3.3823)	Learning Rate [0.00125]
3: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00097)	Tok/s 57312 (52842)	Loss/tok 3.5492 (3.3864)	Learning Rate [0.00125]
5: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00097)	Tok/s 57190 (53013)	Loss/tok 3.6478 (3.3889)	Learning Rate [0.00125]
6: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00100)	Tok/s 57149 (53082)	Loss/tok 3.4699 (3.3864)	Learning Rate [0.00125]
4: TRAIN [1][1250/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00091)	Tok/s 57166 (52924)	Loss/tok 3.4507 (3.3875)	Learning Rate [0.00125]
1: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00104 (0.00092)	Tok/s 51706 (52646)	Loss/tok 3.7899 (3.3859)	Learning Rate [0.00125]
0: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00092)	Tok/s 51720 (52566)	Loss/tok 3.4773 (3.3879)	Learning Rate [0.00125]
15: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00091)	Tok/s 52747 (53818)	Loss/tok 3.5604 (3.3851)	Learning Rate [0.00125]
2: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00098)	Tok/s 51574 (52734)	Loss/tok 3.4402 (3.3838)	Learning Rate [0.00125]
14: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00095 (0.00093)	Tok/s 52706 (53716)	Loss/tok 3.2980 (3.3874)	Learning Rate [0.00125]
4: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00090 (0.00091)	Tok/s 51444 (52897)	Loss/tok 3.4900 (3.3875)	Learning Rate [0.00125]
3: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00114 (0.00097)	Tok/s 51497 (52814)	Loss/tok 3.4328 (3.3870)	Learning Rate [0.00125]
13: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00099)	Tok/s 52591 (53615)	Loss/tok 3.3558 (3.3856)	Learning Rate [0.00125]
5: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00097)	Tok/s 51348 (52985)	Loss/tok 3.8538 (3.3892)	Learning Rate [0.00125]
11: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00113 (0.00097)	Tok/s 52471 (53426)	Loss/tok 3.2741 (3.3890)	Learning Rate [0.00125]
12: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00105 (0.00096)	Tok/s 52507 (53520)	Loss/tok 3.5913 (3.3892)	Learning Rate [0.00125]
10: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00097)	Tok/s 52369 (53351)	Loss/tok 3.4831 (3.3850)	Learning Rate [0.00125]
6: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00103 (0.00100)	Tok/s 52293 (53054)	Loss/tok 3.3659 (3.3865)	Learning Rate [0.00125]
8: TRAIN [1][1260/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00097)	Tok/s 52199 (53209)	Loss/tok 3.4782 (3.3812)	Learning Rate [0.00125]
7: TRAIN [1][1260/3416]	Time 0.063 (0.058)	Data 0.00100 (0.00093)	Tok/s 52221 (53138)	Loss/tok 3.2910 (3.3817)	Learning Rate [0.00125]
9: TRAIN [1][1260/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00093)	Tok/s 52275 (53273)	Loss/tok 3.6725 (3.3890)	Learning Rate [0.00125]
10: TRAIN [1][1270/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00097)	Tok/s 50934 (53355)	Loss/tok 3.2569 (3.3856)	Learning Rate [0.00125]
8: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00097)	Tok/s 50834 (53213)	Loss/tok 3.0355 (3.3812)	Learning Rate [0.00125]
11: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00097)	Tok/s 50861 (53429)	Loss/tok 3.4148 (3.3890)	Learning Rate [0.00125]
6: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00114 (0.00100)	Tok/s 50694 (53057)	Loss/tok 3.1671 (3.3873)	Learning Rate [0.00125]
9: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00093)	Tok/s 50849 (53277)	Loss/tok 3.2761 (3.3890)	Learning Rate [0.00125]
5: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00097)	Tok/s 50468 (52988)	Loss/tok 3.1560 (3.3884)	Learning Rate [0.00125]
2: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00098)	Tok/s 50326 (52738)	Loss/tok 3.2246 (3.3838)	Learning Rate [0.00125]
7: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00093)	Tok/s 50774 (53141)	Loss/tok 3.3242 (3.3817)	Learning Rate [0.00125]
12: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00096)	Tok/s 50631 (53522)	Loss/tok 3.1835 (3.3890)	Learning Rate [0.00125]
4: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00091)	Tok/s 50317 (52899)	Loss/tok 3.4274 (3.3873)	Learning Rate [0.00125]
3: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00097)	Tok/s 50234 (52817)	Loss/tok 3.4170 (3.3873)	Learning Rate [0.00125]
14: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00110 (0.00093)	Tok/s 50406 (53717)	Loss/tok 3.3192 (3.3873)	Learning Rate [0.00125]
1: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00092)	Tok/s 50192 (52649)	Loss/tok 3.2680 (3.3862)	Learning Rate [0.00125]
15: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00091)	Tok/s 50256 (53819)	Loss/tok 2.9531 (3.3853)	Learning Rate [0.00125]
0: TRAIN [1][1270/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00092)	Tok/s 50100 (52570)	Loss/tok 3.4512 (3.3879)	Learning Rate [0.00125]
13: TRAIN [1][1270/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00099)	Tok/s 49247 (53615)	Loss/tok 3.1635 (3.3856)	Learning Rate [0.00125]
14: TRAIN [1][1280/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00093)	Tok/s 54415 (53726)	Loss/tok 3.1689 (3.3873)	Learning Rate [0.00125]
15: TRAIN [1][1280/3416]	Time 0.061 (0.058)	Data 0.00083 (0.00091)	Tok/s 54331 (53827)	Loss/tok 3.4370 (3.3858)	Learning Rate [0.00125]
13: TRAIN [1][1280/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00099)	Tok/s 54416 (53624)	Loss/tok 3.4407 (3.3858)	Learning Rate [0.00125]
0: TRAIN [1][1280/3416]	Time 0.061 (0.058)	Data 0.00080 (0.00092)	Tok/s 54257 (52578)	Loss/tok 3.4644 (3.3880)	Learning Rate [0.00125]
12: TRAIN [1][1280/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00096)	Tok/s 54386 (53530)	Loss/tok 3.6467 (3.3891)	Learning Rate [0.00125]
10: TRAIN [1][1280/3416]	Time 0.061 (0.058)	Data 0.00094 (0.00097)	Tok/s 54219 (53362)	Loss/tok 3.1942 (3.3859)	Learning Rate [0.00125]
1: TRAIN [1][1280/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00092)	Tok/s 54173 (52657)	Loss/tok 3.3120 (3.3857)	Learning Rate [0.00125]
11: TRAIN [1][1280/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00097)	Tok/s 54266 (53436)	Loss/tok 3.2867 (3.3888)	Learning Rate [0.00125]
2: TRAIN [1][1280/3416]	Time 0.062 (0.058)	Data 0.00088 (0.00098)	Tok/s 54044 (52746)	Loss/tok 3.2614 (3.3831)	Learning Rate [0.00125]
3: TRAIN [1][1280/3416]	Time 0.062 (0.058)	Data 0.00106 (0.00097)	Tok/s 53989 (52825)	Loss/tok 3.8292 (3.3874)	Learning Rate [0.00125]
9: TRAIN [1][1280/3416]	Time 0.061 (0.058)	Data 0.00083 (0.00093)	Tok/s 54127 (53284)	Loss/tok 3.5476 (3.3893)	Learning Rate [0.00125]
8: TRAIN [1][1280/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00097)	Tok/s 53979 (53220)	Loss/tok 3.4653 (3.3811)	Learning Rate [0.00125]
4: TRAIN [1][1280/3416]	Time 0.062 (0.058)	Data 0.00078 (0.00091)	Tok/s 53817 (52908)	Loss/tok 3.2635 (3.3872)	Learning Rate [0.00125]
7: TRAIN [1][1280/3416]	Time 0.062 (0.058)	Data 0.00105 (0.00093)	Tok/s 53910 (53149)	Loss/tok 3.3372 (3.3818)	Learning Rate [0.00125]
5: TRAIN [1][1280/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00097)	Tok/s 53732 (52996)	Loss/tok 3.4780 (3.3888)	Learning Rate [0.00125]
6: TRAIN [1][1280/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00100)	Tok/s 53799 (53065)	Loss/tok 3.6267 (3.3882)	Learning Rate [0.00125]
6: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00111 (0.00100)	Tok/s 51534 (53096)	Loss/tok 3.3933 (3.3890)	Learning Rate [0.00125]
7: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00109 (0.00093)	Tok/s 51484 (53179)	Loss/tok 3.4299 (3.3823)	Learning Rate [0.00125]
5: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00097)	Tok/s 51499 (53027)	Loss/tok 3.4927 (3.3895)	Learning Rate [0.00125]
4: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00091)	Tok/s 51510 (52939)	Loss/tok 3.3277 (3.3881)	Learning Rate [0.00125]
8: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00097)	Tok/s 51318 (53250)	Loss/tok 3.3567 (3.3815)	Learning Rate [0.00125]
9: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00093)	Tok/s 51256 (53315)	Loss/tok 3.3515 (3.3897)	Learning Rate [0.00125]
10: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00097)	Tok/s 51485 (53393)	Loss/tok 3.1085 (3.3867)	Learning Rate [0.00125]
2: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00098)	Tok/s 51245 (52777)	Loss/tok 3.6055 (3.3839)	Learning Rate [0.00125]
3: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00097)	Tok/s 51439 (52857)	Loss/tok 3.2125 (3.3873)	Learning Rate [0.00125]
1: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00092)	Tok/s 51192 (52689)	Loss/tok 3.0160 (3.3866)	Learning Rate [0.00125]
0: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00092)	Tok/s 51145 (52609)	Loss/tok 3.3794 (3.3886)	Learning Rate [0.00125]
12: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00096)	Tok/s 52120 (53561)	Loss/tok 3.5083 (3.3901)	Learning Rate [0.00125]
11: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00097)	Tok/s 52139 (53467)	Loss/tok 3.6080 (3.3899)	Learning Rate [0.00125]
15: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00091)	Tok/s 52179 (53857)	Loss/tok 3.4792 (3.3865)	Learning Rate [0.00125]
14: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00093)	Tok/s 52118 (53757)	Loss/tok 3.5066 (3.3879)	Learning Rate [0.00125]
13: TRAIN [1][1290/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00099)	Tok/s 51966 (53656)	Loss/tok 3.3456 (3.3867)	Learning Rate [0.00125]
4: TRAIN [1][1300/3416]	Time 0.053 (0.058)	Data 0.00080 (0.00091)	Tok/s 49499 (52991)	Loss/tok 3.6675 (3.3890)	Learning Rate [0.00125]
5: TRAIN [1][1300/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00097)	Tok/s 49459 (53078)	Loss/tok 3.3357 (3.3896)	Learning Rate [0.00125]
3: TRAIN [1][1300/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00097)	Tok/s 49474 (52909)	Loss/tok 3.3845 (3.3877)	Learning Rate [0.00125]
1: TRAIN [1][1300/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00092)	Tok/s 49518 (52743)	Loss/tok 3.3054 (3.3870)	Learning Rate [0.00125]
7: TRAIN [1][1300/3416]	Time 0.053 (0.058)	Data 0.00104 (0.00093)	Tok/s 50717 (53231)	Loss/tok 3.5650 (3.3824)	Learning Rate [0.00125]
2: TRAIN [1][1300/3416]	Time 0.052 (0.058)	Data 0.00111 (0.00098)	Tok/s 50245 (52830)	Loss/tok 3.2530 (3.3848)	Learning Rate [0.00125]
0: TRAIN [1][1300/3416]	Time 0.053 (0.058)	Data 0.00085 (0.00092)	Tok/s 49513 (52663)	Loss/tok 3.3862 (3.3890)	Learning Rate [0.00125]
6: TRAIN [1][1300/3416]	Time 0.052 (0.058)	Data 0.00113 (0.00100)	Tok/s 51371 (53147)	Loss/tok 3.2093 (3.3898)	Learning Rate [0.00125]
15: TRAIN [1][1300/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00091)	Tok/s 50675 (53909)	Loss/tok 3.0442 (3.3870)	Learning Rate [0.00125]
14: TRAIN [1][1300/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00093)	Tok/s 50774 (53809)	Loss/tok 3.4366 (3.3878)	Learning Rate [0.00125]
8: TRAIN [1][1300/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00097)	Tok/s 50704 (53303)	Loss/tok 3.6199 (3.3813)	Learning Rate [0.00125]
12: TRAIN [1][1300/3416]	Time 0.053 (0.058)	Data 0.00101 (0.00096)	Tok/s 50788 (53614)	Loss/tok 3.4971 (3.3907)	Learning Rate [0.00125]
10: TRAIN [1][1300/3416]	Time 0.052 (0.058)	Data 0.00115 (0.00097)	Tok/s 51514 (53447)	Loss/tok 3.2510 (3.3871)	Learning Rate [0.00125]
13: TRAIN [1][1300/3416]	Time 0.053 (0.058)	Data 0.00108 (0.00099)	Tok/s 50744 (53708)	Loss/tok 3.2836 (3.3870)	Learning Rate [0.00125]
11: TRAIN [1][1300/3416]	Time 0.052 (0.058)	Data 0.00116 (0.00097)	Tok/s 51568 (53521)	Loss/tok 3.1850 (3.3897)	Learning Rate [0.00125]
9: TRAIN [1][1300/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00093)	Tok/s 50726 (53369)	Loss/tok 3.5415 (3.3906)	Learning Rate [0.00125]
4: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00091)	Tok/s 79023 (52988)	Loss/tok 3.3721 (3.3882)	Learning Rate [0.00125]
6: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00100)	Tok/s 79192 (53145)	Loss/tok 3.5237 (3.3894)	Learning Rate [0.00125]
3: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00097)	Tok/s 78773 (52907)	Loss/tok 3.4109 (3.3868)	Learning Rate [0.00125]
2: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 77876 (52826)	Loss/tok 3.2926 (3.3842)	Learning Rate [0.00125]
10: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00097)	Tok/s 79436 (53445)	Loss/tok 3.4646 (3.3867)	Learning Rate [0.00125]
7: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 79176 (53228)	Loss/tok 3.4231 (3.3819)	Learning Rate [0.00125]
8: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 79150 (53300)	Loss/tok 3.2568 (3.3807)	Learning Rate [0.00125]
5: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 79120 (53075)	Loss/tok 3.5142 (3.3891)	Learning Rate [0.00125]
1: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 77641 (52739)	Loss/tok 3.3361 (3.3860)	Learning Rate [0.00125]
9: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 79124 (53366)	Loss/tok 3.5622 (3.3903)	Learning Rate [0.00125]
11: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 79902 (53519)	Loss/tok 3.3249 (3.3891)	Learning Rate [0.00125]
12: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 79768 (53613)	Loss/tok 3.2556 (3.3902)	Learning Rate [0.00125]
0: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 77613 (52660)	Loss/tok 3.2473 (3.3887)	Learning Rate [0.00125]
15: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00091)	Tok/s 79422 (53907)	Loss/tok 3.1381 (3.3861)	Learning Rate [0.00125]
13: TRAIN [1][1310/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00099)	Tok/s 79631 (53706)	Loss/tok 3.2740 (3.3865)	Learning Rate [0.00125]
14: TRAIN [1][1310/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00093)	Tok/s 78316 (53806)	Loss/tok 3.4402 (3.3871)	Learning Rate [0.00125]
15: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00091)	Tok/s 70840 (53918)	Loss/tok 3.3545 (3.3864)	Learning Rate [0.00125]
10: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00097)	Tok/s 69728 (53453)	Loss/tok 3.4050 (3.3871)	Learning Rate [0.00125]
14: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00093)	Tok/s 70734 (53817)	Loss/tok 3.4725 (3.3877)	Learning Rate [0.00125]
8: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 69695 (53308)	Loss/tok 3.5821 (3.3816)	Learning Rate [0.00125]
13: TRAIN [1][1320/3416]	Time 0.069 (0.058)	Data 0.00113 (0.00099)	Tok/s 71793 (53717)	Loss/tok 3.6853 (3.3879)	Learning Rate [0.00125]
3: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00116 (0.00097)	Tok/s 69826 (52917)	Loss/tok 3.7666 (3.3873)	Learning Rate [0.00125]
0: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 69075 (52672)	Loss/tok 3.8171 (3.3889)	Learning Rate [0.00125]
6: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00100)	Tok/s 69731 (53154)	Loss/tok 3.5727 (3.3894)	Learning Rate [0.00125]
1: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 69919 (52751)	Loss/tok 3.3882 (3.3862)	Learning Rate [0.00125]
2: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 69922 (52838)	Loss/tok 3.3466 (3.3845)	Learning Rate [0.00125]
11: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 69707 (53528)	Loss/tok 3.5203 (3.3897)	Learning Rate [0.00125]
7: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00093)	Tok/s 69724 (53236)	Loss/tok 3.5262 (3.3820)	Learning Rate [0.00125]
12: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00096)	Tok/s 69740 (53623)	Loss/tok 3.5524 (3.3908)	Learning Rate [0.00125]
5: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00097)	Tok/s 69853 (53084)	Loss/tok 3.4887 (3.3891)	Learning Rate [0.00125]
9: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00093)	Tok/s 69666 (53374)	Loss/tok 3.3530 (3.3908)	Learning Rate [0.00125]
4: TRAIN [1][1320/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00091)	Tok/s 69881 (52998)	Loss/tok 3.4968 (3.3882)	Learning Rate [0.00125]
10: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00097)	Tok/s 34559 (53425)	Loss/tok 2.9145 (3.3867)	Learning Rate [0.00125]
11: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00097)	Tok/s 34547 (53501)	Loss/tok 2.9043 (3.3898)	Learning Rate [0.00125]
9: TRAIN [1][1330/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00093)	Tok/s 35219 (53345)	Loss/tok 2.9085 (3.3900)	Learning Rate [0.00125]
8: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00097)	Tok/s 34620 (53279)	Loss/tok 3.1234 (3.3814)	Learning Rate [0.00125]
12: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00096)	Tok/s 34502 (53595)	Loss/tok 3.0874 (3.3905)	Learning Rate [0.00125]
7: TRAIN [1][1330/3416]	Time 0.051 (0.058)	Data 0.00111 (0.00093)	Tok/s 35206 (53208)	Loss/tok 3.0147 (3.3818)	Learning Rate [0.00125]
13: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00099)	Tok/s 34391 (53689)	Loss/tok 3.1349 (3.3874)	Learning Rate [0.00125]
14: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00093)	Tok/s 34337 (53790)	Loss/tok 2.9641 (3.3876)	Learning Rate [0.00125]
15: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00091)	Tok/s 34388 (53879)	Loss/tok 3.1364 (3.3858)	Learning Rate [0.00125]
6: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00100)	Tok/s 34557 (53125)	Loss/tok 3.3202 (3.3900)	Learning Rate [0.00125]
4: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00091)	Tok/s 34453 (52970)	Loss/tok 3.1021 (3.3880)	Learning Rate [0.00125]
5: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00112 (0.00097)	Tok/s 34520 (53057)	Loss/tok 3.2982 (3.3890)	Learning Rate [0.00125]
2: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00098)	Tok/s 34328 (52810)	Loss/tok 3.2278 (3.3840)	Learning Rate [0.00125]
1: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00081 (0.00092)	Tok/s 34287 (52724)	Loss/tok 3.1461 (3.3856)	Learning Rate [0.00125]
3: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 34375 (52889)	Loss/tok 3.0498 (3.3869)	Learning Rate [0.00125]
0: TRAIN [1][1330/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00092)	Tok/s 34262 (52644)	Loss/tok 3.0702 (3.3892)	Learning Rate [0.00125]
5: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
7: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00099 (0.00093)	Tok/s 28655 (53180)	Loss/tok 2.4310 (3.3819)	Learning Rate [0.00125]
8: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00095 (0.00097)	Tok/s 28649 (53250)	Loss/tok 2.6262 (3.3811)	Learning Rate [0.00125]
10: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00088 (0.00097)	Tok/s 28757 (53396)	Loss/tok 2.6023 (3.3863)	Learning Rate [0.00125]
6: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00104 (0.00100)	Tok/s 27400 (53096)	Loss/tok 2.5232 (3.3902)	Learning Rate [0.00125]
5: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00105 (0.00097)	Tok/s 26893 (53027)	Loss/tok 2.7490 (3.3884)	Learning Rate [0.00125]
9: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00088 (0.00093)	Tok/s 28658 (53317)	Loss/tok 2.3770 (3.3898)	Learning Rate [0.00125]
11: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00107 (0.00097)	Tok/s 28799 (53472)	Loss/tok 2.3930 (3.3903)	Learning Rate [0.00125]
4: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00093 (0.00091)	Tok/s 26887 (52941)	Loss/tok 2.5780 (3.3880)	Learning Rate [0.00125]
2: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00091 (0.00098)	Tok/s 25956 (52782)	Loss/tok 2.3382 (3.3837)	Learning Rate [0.00125]
3: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00095 (0.00097)	Tok/s 26884 (52861)	Loss/tok 2.5437 (3.3866)	Learning Rate [0.00125]
1: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00092 (0.00092)	Tok/s 25223 (52695)	Loss/tok 2.4091 (3.3856)	Learning Rate [0.00125]
12: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00093 (0.00096)	Tok/s 28677 (53566)	Loss/tok 2.6832 (3.3904)	Learning Rate [0.00125]
15: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00084 (0.00091)	Tok/s 30387 (53851)	Loss/tok 2.5855 (3.3854)	Learning Rate [0.00125]
13: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00156 (0.00099)	Tok/s 30337 (53662)	Loss/tok 2.5165 (3.3874)	Learning Rate [0.00125]
14: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00089 (0.00093)	Tok/s 30330 (53762)	Loss/tok 2.6636 (3.3880)	Learning Rate [0.00125]
0: TRAIN [1][1340/3416]	Time 0.038 (0.058)	Data 0.00097 (0.00092)	Tok/s 25280 (52615)	Loss/tok 2.2428 (3.3893)	Learning Rate [0.00125]
4: TRAIN [1][1350/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00091)	Tok/s 62146 (52955)	Loss/tok 3.4203 (3.3875)	Learning Rate [0.00125]
5: TRAIN [1][1350/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00097)	Tok/s 62013 (53040)	Loss/tok 3.4559 (3.3880)	Learning Rate [0.00125]
3: TRAIN [1][1350/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00097)	Tok/s 62065 (52874)	Loss/tok 3.6087 (3.3864)	Learning Rate [0.00125]
2: TRAIN [1][1350/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00098)	Tok/s 61972 (52796)	Loss/tok 3.2858 (3.3833)	Learning Rate [0.00125]
1: TRAIN [1][1350/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00092)	Tok/s 61933 (52709)	Loss/tok 3.4471 (3.3850)	Learning Rate [0.00125]
6: TRAIN [1][1350/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00100)	Tok/s 61931 (53109)	Loss/tok 3.4848 (3.3900)	Learning Rate [0.00125]
7: TRAIN [1][1350/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00093)	Tok/s 61879 (53194)	Loss/tok 3.4938 (3.3811)	Learning Rate [0.00125]
10: TRAIN [1][1350/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00097)	Tok/s 61595 (53410)	Loss/tok 3.3248 (3.3858)	Learning Rate [0.00125]
13: TRAIN [1][1350/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 61674 (53676)	Loss/tok 3.5592 (3.3873)	Learning Rate [0.00125]
8: TRAIN [1][1350/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00097)	Tok/s 61734 (53265)	Loss/tok 3.5422 (3.3811)	Learning Rate [0.00125]
14: TRAIN [1][1350/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 62658 (53777)	Loss/tok 3.5645 (3.3885)	Learning Rate [0.00125]
15: TRAIN [1][1350/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00091)	Tok/s 62694 (53866)	Loss/tok 3.5883 (3.3851)	Learning Rate [0.00125]
11: TRAIN [1][1350/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 61564 (53486)	Loss/tok 3.3686 (3.3900)	Learning Rate [0.00125]
12: TRAIN [1][1350/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00096)	Tok/s 61529 (53580)	Loss/tok 3.4031 (3.3898)	Learning Rate [0.00125]
9: TRAIN [1][1350/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00093)	Tok/s 61645 (53330)	Loss/tok 3.6814 (3.3896)	Learning Rate [0.00125]
0: TRAIN [1][1350/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00092)	Tok/s 61803 (52629)	Loss/tok 3.4801 (3.3891)	Learning Rate [0.00125]
9: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 55077 (53295)	Loss/tok 3.6146 (3.3897)	Learning Rate [0.00125]
8: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 55017 (53229)	Loss/tok 3.5877 (3.3808)	Learning Rate [0.00125]
10: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 55086 (53376)	Loss/tok 3.6062 (3.3854)	Learning Rate [0.00125]
7: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 54931 (53157)	Loss/tok 3.3373 (3.3806)	Learning Rate [0.00125]
11: TRAIN [1][1360/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00097)	Tok/s 55144 (53453)	Loss/tok 3.3456 (3.3899)	Learning Rate [0.00125]
12: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00096)	Tok/s 55074 (53547)	Loss/tok 3.5207 (3.3894)	Learning Rate [0.00125]
5: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 54770 (53004)	Loss/tok 3.1478 (3.3875)	Learning Rate [0.00125]
6: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00100)	Tok/s 54755 (53073)	Loss/tok 3.5422 (3.3893)	Learning Rate [0.00125]
13: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00099)	Tok/s 55025 (53645)	Loss/tok 3.5967 (3.3870)	Learning Rate [0.00125]
4: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00091)	Tok/s 54773 (52917)	Loss/tok 3.2796 (3.3867)	Learning Rate [0.00125]
2: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00098)	Tok/s 54901 (52756)	Loss/tok 3.4934 (3.3830)	Learning Rate [0.00125]
14: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 54851 (53745)	Loss/tok 3.6902 (3.3881)	Learning Rate [0.00125]
3: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 54746 (52835)	Loss/tok 3.5505 (3.3863)	Learning Rate [0.00125]
1: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 54634 (52668)	Loss/tok 3.5892 (3.3846)	Learning Rate [0.00125]
15: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 54865 (53834)	Loss/tok 3.5737 (3.3846)	Learning Rate [0.00125]
0: TRAIN [1][1360/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00092)	Tok/s 53852 (52585)	Loss/tok 3.7671 (3.3893)	Learning Rate [0.00125]
3: TRAIN [1][1370/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00097)	Tok/s 54383 (52847)	Loss/tok 3.4395 (3.3868)	Learning Rate [0.00125]
1: TRAIN [1][1370/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00092)	Tok/s 54218 (52681)	Loss/tok 3.3496 (3.3845)	Learning Rate [0.00125]
4: TRAIN [1][1370/3416]	Time 0.062 (0.058)	Data 0.00103 (0.00091)	Tok/s 54361 (52928)	Loss/tok 3.3406 (3.3865)	Learning Rate [0.00125]
2: TRAIN [1][1370/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00098)	Tok/s 54324 (52768)	Loss/tok 3.3085 (3.3826)	Learning Rate [0.00125]
5: TRAIN [1][1370/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00097)	Tok/s 54360 (53014)	Loss/tok 3.3137 (3.3869)	Learning Rate [0.00125]
15: TRAIN [1][1370/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00091)	Tok/s 55086 (53843)	Loss/tok 3.3786 (3.3843)	Learning Rate [0.00125]
6: TRAIN [1][1370/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00100)	Tok/s 54323 (53082)	Loss/tok 3.3592 (3.3888)	Learning Rate [0.00125]
11: TRAIN [1][1370/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00097)	Tok/s 55218 (53463)	Loss/tok 3.3153 (3.3897)	Learning Rate [0.00125]
7: TRAIN [1][1370/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00093)	Tok/s 54214 (53166)	Loss/tok 3.3359 (3.3804)	Learning Rate [0.00125]
14: TRAIN [1][1370/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00093)	Tok/s 55076 (53754)	Loss/tok 3.3184 (3.3884)	Learning Rate [0.00125]
10: TRAIN [1][1370/3416]	Time 0.063 (0.058)	Data 0.00108 (0.00097)	Tok/s 55191 (53386)	Loss/tok 3.5716 (3.3852)	Learning Rate [0.00125]
8: TRAIN [1][1370/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00097)	Tok/s 54233 (53238)	Loss/tok 3.3753 (3.3807)	Learning Rate [0.00125]
9: TRAIN [1][1370/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00093)	Tok/s 55111 (53304)	Loss/tok 3.4925 (3.3889)	Learning Rate [0.00125]
12: TRAIN [1][1370/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00096)	Tok/s 55170 (53556)	Loss/tok 3.3746 (3.3899)	Learning Rate [0.00125]
13: TRAIN [1][1370/3416]	Time 0.063 (0.058)	Data 0.00106 (0.00099)	Tok/s 55062 (53654)	Loss/tok 3.2890 (3.3873)	Learning Rate [0.00125]
0: TRAIN [1][1370/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00092)	Tok/s 54094 (52598)	Loss/tok 3.7222 (3.3899)	Learning Rate [0.00125]
5: Gradient norm: inf
6: Gradient norm: inf
4: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
1: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
10: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
15: Gradient norm: inf
14: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
5: TRAIN [1][1380/3416]	Time 0.059 (0.058)	Data 0.00112 (0.00097)	Tok/s 54420 (53055)	Loss/tok 3.3259 (3.3869)	Learning Rate [0.00125]
4: TRAIN [1][1380/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00091)	Tok/s 54074 (52968)	Loss/tok 3.2071 (3.3867)	Learning Rate [0.00125]
6: TRAIN [1][1380/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00100)	Tok/s 54019 (53124)	Loss/tok 3.3636 (3.3889)	Learning Rate [0.00125]
3: TRAIN [1][1380/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00097)	Tok/s 54077 (52888)	Loss/tok 3.6281 (3.3864)	Learning Rate [0.00125]
7: TRAIN [1][1380/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00093)	Tok/s 53896 (53208)	Loss/tok 3.6365 (3.3809)	Learning Rate [0.00125]
2: TRAIN [1][1380/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00098)	Tok/s 52890 (52808)	Loss/tok 3.4403 (3.3824)	Learning Rate [0.00125]
8: TRAIN [1][1380/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00097)	Tok/s 53791 (53279)	Loss/tok 3.3073 (3.3807)	Learning Rate [0.00125]
1: TRAIN [1][1380/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00092)	Tok/s 52757 (52721)	Loss/tok 3.3584 (3.3845)	Learning Rate [0.00125]
9: TRAIN [1][1380/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00093)	Tok/s 53756 (53346)	Loss/tok 3.2868 (3.3883)	Learning Rate [0.00125]
10: TRAIN [1][1380/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00097)	Tok/s 53758 (53428)	Loss/tok 3.2793 (3.3846)	Learning Rate [0.00125]
15: TRAIN [1][1380/3416]	Time 0.060 (0.058)	Data 0.00081 (0.00091)	Tok/s 53771 (53885)	Loss/tok 3.1292 (3.3845)	Learning Rate [0.00125]
14: TRAIN [1][1380/3416]	Time 0.060 (0.058)	Data 0.00083 (0.00093)	Tok/s 53706 (53796)	Loss/tok 3.4166 (3.3882)	Learning Rate [0.00125]
11: TRAIN [1][1380/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00097)	Tok/s 53742 (53504)	Loss/tok 3.3019 (3.3894)	Learning Rate [0.00125]
13: TRAIN [1][1380/3416]	Time 0.060 (0.058)	Data 0.00115 (0.00099)	Tok/s 53734 (53696)	Loss/tok 3.5309 (3.3873)	Learning Rate [0.00125]
12: TRAIN [1][1380/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00096)	Tok/s 53724 (53599)	Loss/tok 3.4371 (3.3903)	Learning Rate [0.00125]
0: TRAIN [1][1380/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00092)	Tok/s 52677 (52639)	Loss/tok 3.3190 (3.3903)	Learning Rate [0.00125]
10: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00097)	Tok/s 61580 (53411)	Loss/tok 3.6914 (3.3846)	Learning Rate [0.00125]
9: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 61586 (53329)	Loss/tok 3.6585 (3.3887)	Learning Rate [0.00125]
11: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 61453 (53487)	Loss/tok 3.5307 (3.3900)	Learning Rate [0.00125]
8: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 61572 (53263)	Loss/tok 3.7741 (3.3811)	Learning Rate [0.00125]
12: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00096)	Tok/s 61357 (53581)	Loss/tok 3.5267 (3.3902)	Learning Rate [0.00125]
7: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00093)	Tok/s 61532 (53191)	Loss/tok 3.2256 (3.3806)	Learning Rate [0.00125]
13: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 61201 (53679)	Loss/tok 3.6029 (3.3872)	Learning Rate [0.00125]
14: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 61199 (53778)	Loss/tok 3.3462 (3.3877)	Learning Rate [0.00125]
6: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00100)	Tok/s 61478 (53107)	Loss/tok 3.6558 (3.3892)	Learning Rate [0.00125]
5: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 61392 (53038)	Loss/tok 3.3305 (3.3870)	Learning Rate [0.00125]
4: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00091)	Tok/s 61295 (52951)	Loss/tok 3.6166 (3.3866)	Learning Rate [0.00125]
3: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 61203 (52871)	Loss/tok 3.5773 (3.3866)	Learning Rate [0.00125]
2: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 61118 (52792)	Loss/tok 3.5792 (3.3824)	Learning Rate [0.00125]
0: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00092)	Tok/s 60442 (52624)	Loss/tok 3.4976 (3.3907)	Learning Rate [0.00125]
1: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 61128 (52705)	Loss/tok 3.5113 (3.3844)	Learning Rate [0.00125]
15: TRAIN [1][1390/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00091)	Tok/s 61082 (53867)	Loss/tok 3.6608 (3.3847)	Learning Rate [0.00125]
5: TRAIN [1][1400/3416]	Time 0.034 (0.058)	Data 0.00102 (0.00097)	Tok/s 19512 (53002)	Loss/tok 2.5077 (3.3869)	Learning Rate [0.00125]
4: TRAIN [1][1400/3416]	Time 0.034 (0.058)	Data 0.00090 (0.00091)	Tok/s 16848 (52915)	Loss/tok 1.8751 (3.3861)	Learning Rate [0.00125]
3: TRAIN [1][1400/3416]	Time 0.034 (0.058)	Data 0.00101 (0.00097)	Tok/s 16692 (52835)	Loss/tok 1.6852 (3.3865)	Learning Rate [0.00125]
2: TRAIN [1][1400/3416]	Time 0.034 (0.058)	Data 0.00094 (0.00098)	Tok/s 14466 (52754)	Loss/tok 2.1481 (3.3822)	Learning Rate [0.00125]
7: TRAIN [1][1400/3416]	Time 0.034 (0.058)	Data 0.00087 (0.00093)	Tok/s 22039 (53158)	Loss/tok 2.2929 (3.3807)	Learning Rate [0.00125]
8: TRAIN [1][1400/3416]	Time 0.035 (0.058)	Data 0.00097 (0.00097)	Tok/s 22750 (53230)	Loss/tok 2.2470 (3.3807)	Learning Rate [0.00125]
1: TRAIN [1][1400/3416]	Time 0.034 (0.058)	Data 0.00089 (0.00092)	Tok/s 10840 (52664)	Loss/tok 1.7077 (3.3840)	Learning Rate [0.00125]
9: TRAIN [1][1400/3416]	Time 0.035 (0.058)	Data 0.00085 (0.00093)	Tok/s 23991 (53298)	Loss/tok 2.0750 (3.3888)	Learning Rate [0.00125]
6: TRAIN [1][1400/3416]	Time 0.034 (0.058)	Data 0.00095 (0.00100)	Tok/s 20495 (53072)	Loss/tok 2.3745 (3.3891)	Learning Rate [0.00125]
0: TRAIN [1][1400/3416]	Time 0.035 (0.058)	Data 0.00097 (0.00092)	Tok/s 9239 (52581)	Loss/tok 1.6330 (3.3908)	Learning Rate [0.00125]
10: TRAIN [1][1400/3416]	Time 0.035 (0.058)	Data 0.00091 (0.00097)	Tok/s 23905 (53379)	Loss/tok 2.0063 (3.3845)	Learning Rate [0.00125]
15: TRAIN [1][1400/3416]	Time 0.035 (0.058)	Data 0.00091 (0.00091)	Tok/s 25789 (53836)	Loss/tok 2.4385 (3.3842)	Learning Rate [0.00125]
11: TRAIN [1][1400/3416]	Time 0.035 (0.058)	Data 0.00086 (0.00097)	Tok/s 23772 (53454)	Loss/tok 1.9531 (3.3899)	Learning Rate [0.00125]
14: TRAIN [1][1400/3416]	Time 0.035 (0.058)	Data 0.00085 (0.00093)	Tok/s 25795 (53747)	Loss/tok 2.4802 (3.3874)	Learning Rate [0.00125]
13: TRAIN [1][1400/3416]	Time 0.035 (0.058)	Data 0.00092 (0.00099)	Tok/s 25693 (53647)	Loss/tok 2.4818 (3.3871)	Learning Rate [0.00125]
12: TRAIN [1][1400/3416]	Time 0.035 (0.058)	Data 0.00090 (0.00096)	Tok/s 23815 (53548)	Loss/tok 1.9760 (3.3899)	Learning Rate [0.00125]
4: TRAIN [1][1410/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00091)	Tok/s 57859 (52934)	Loss/tok 3.6256 (3.3858)	Learning Rate [0.00125]
10: TRAIN [1][1410/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00097)	Tok/s 57308 (53399)	Loss/tok 3.5731 (3.3846)	Learning Rate [0.00125]
11: TRAIN [1][1410/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00097)	Tok/s 57132 (53475)	Loss/tok 3.6375 (3.3896)	Learning Rate [0.00125]
12: TRAIN [1][1410/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00096)	Tok/s 57187 (53570)	Loss/tok 3.6315 (3.3899)	Learning Rate [0.00125]
13: TRAIN [1][1410/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00099)	Tok/s 57272 (53669)	Loss/tok 3.3180 (3.3868)	Learning Rate [0.00125]
14: TRAIN [1][1410/3416]	Time 0.062 (0.058)	Data 0.00083 (0.00093)	Tok/s 57350 (53768)	Loss/tok 3.7046 (3.3871)	Learning Rate [0.00125]
15: TRAIN [1][1410/3416]	Time 0.062 (0.058)	Data 0.00082 (0.00091)	Tok/s 57432 (53858)	Loss/tok 3.3697 (3.3838)	Learning Rate [0.00125]
5: TRAIN [1][1410/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00097)	Tok/s 57743 (53022)	Loss/tok 3.3505 (3.3868)	Learning Rate [0.00125]
3: TRAIN [1][1410/3416]	Time 0.062 (0.058)	Data 0.00098 (0.00097)	Tok/s 57781 (52855)	Loss/tok 3.3817 (3.3865)	Learning Rate [0.00125]
2: TRAIN [1][1410/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00098)	Tok/s 57733 (52775)	Loss/tok 3.3705 (3.3821)	Learning Rate [0.00125]
8: TRAIN [1][1410/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00097)	Tok/s 57427 (53250)	Loss/tok 3.3962 (3.3808)	Learning Rate [0.00125]
6: TRAIN [1][1410/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00100)	Tok/s 57626 (53091)	Loss/tok 3.7945 (3.3882)	Learning Rate [0.00125]
0: TRAIN [1][1410/3416]	Time 0.062 (0.058)	Data 0.00093 (0.00092)	Tok/s 56512 (52601)	Loss/tok 3.6090 (3.3912)	Learning Rate [0.00125]
7: TRAIN [1][1410/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00093)	Tok/s 57568 (53177)	Loss/tok 3.3013 (3.3798)	Learning Rate [0.00125]
9: TRAIN [1][1410/3416]	Time 0.063 (0.058)	Data 0.00082 (0.00093)	Tok/s 57336 (53317)	Loss/tok 3.3691 (3.3882)	Learning Rate [0.00125]
1: TRAIN [1][1410/3416]	Time 0.062 (0.058)	Data 0.00086 (0.00092)	Tok/s 56975 (52684)	Loss/tok 3.3601 (3.3834)	Learning Rate [0.00125]
12: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00096)	Tok/s 79834 (53572)	Loss/tok 3.2172 (3.3892)	Learning Rate [0.00125]
3: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 78653 (52857)	Loss/tok 3.2774 (3.3857)	Learning Rate [0.00125]
10: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 78976 (53400)	Loss/tok 3.5514 (3.3851)	Learning Rate [0.00125]
9: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 79120 (53318)	Loss/tok 3.3536 (3.3880)	Learning Rate [0.00125]
13: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00099)	Tok/s 79755 (53672)	Loss/tok 3.4880 (3.3866)	Learning Rate [0.00125]
11: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 79680 (53476)	Loss/tok 3.5709 (3.3894)	Learning Rate [0.00125]
8: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 79141 (53251)	Loss/tok 3.3366 (3.3798)	Learning Rate [0.00125]
4: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00091)	Tok/s 79111 (52924)	Loss/tok 3.1995 (3.3849)	Learning Rate [0.00125]
14: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00093)	Tok/s 79659 (53772)	Loss/tok 3.4246 (3.3872)	Learning Rate [0.00125]
6: TRAIN [1][1420/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00100)	Tok/s 79206 (53092)	Loss/tok 3.4089 (3.3881)	Learning Rate [0.00125]
2: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 77986 (52776)	Loss/tok 3.4004 (3.3814)	Learning Rate [0.00125]
15: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00078 (0.00091)	Tok/s 79625 (53860)	Loss/tok 3.4417 (3.3833)	Learning Rate [0.00125]
7: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00093)	Tok/s 79093 (53178)	Loss/tok 3.2935 (3.3792)	Learning Rate [0.00125]
1: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 77908 (52686)	Loss/tok 3.4920 (3.3832)	Learning Rate [0.00125]
5: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 79001 (53023)	Loss/tok 3.5027 (3.3862)	Learning Rate [0.00125]
0: TRAIN [1][1420/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00092)	Tok/s 77937 (52601)	Loss/tok 3.2114 (3.3909)	Learning Rate [0.00125]
2: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00094 (0.00098)	Tok/s 16078 (52765)	Loss/tok 1.6888 (3.3818)	Learning Rate [0.00125]
3: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00093 (0.00097)	Tok/s 17104 (52847)	Loss/tok 1.5050 (3.3862)	Learning Rate [0.00125]
4: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00090 (0.00091)	Tok/s 19212 (52914)	Loss/tok 2.3165 (3.3851)	Learning Rate [0.00125]
5: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00094 (0.00097)	Tok/s 20910 (53015)	Loss/tok 2.1036 (3.3871)	Learning Rate [0.00125]
12: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00088 (0.00096)	Tok/s 25792 (53566)	Loss/tok 2.3038 (3.3891)	Learning Rate [0.00125]
1: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00087 (0.00092)	Tok/s 11756 (52672)	Loss/tok 1.9622 (3.3834)	Learning Rate [0.00125]
11: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00093 (0.00097)	Tok/s 24645 (53470)	Loss/tok 1.9985 (3.3895)	Learning Rate [0.00125]
13: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00096 (0.00099)	Tok/s 26430 (53666)	Loss/tok 2.5122 (3.3864)	Learning Rate [0.00125]
10: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00087 (0.00097)	Tok/s 24640 (53393)	Loss/tok 1.9472 (3.3853)	Learning Rate [0.00125]
15: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00091 (0.00091)	Tok/s 27857 (53855)	Loss/tok 2.2650 (3.3830)	Learning Rate [0.00125]
14: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00088 (0.00093)	Tok/s 26349 (53765)	Loss/tok 2.5616 (3.3880)	Learning Rate [0.00125]
8: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00097 (0.00097)	Tok/s 24301 (53244)	Loss/tok 2.1223 (3.3804)	Learning Rate [0.00125]
6: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00110 (0.00100)	Tok/s 21767 (53084)	Loss/tok 2.1514 (3.3890)	Learning Rate [0.00125]
9: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00102 (0.00093)	Tok/s 24600 (53311)	Loss/tok 2.1566 (3.3876)	Learning Rate [0.00125]
7: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00095 (0.00093)	Tok/s 22769 (53170)	Loss/tok 2.4023 (3.3792)	Learning Rate [0.00125]
0: TRAIN [1][1430/3416]	Time 0.034 (0.058)	Data 0.00089 (0.00092)	Tok/s 9420 (52586)	Loss/tok 1.4318 (3.3909)	Learning Rate [0.00125]
5: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00097)	Tok/s 60033 (53064)	Loss/tok 3.5893 (3.3871)	Learning Rate [0.00125]
4: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00091)	Tok/s 59938 (52964)	Loss/tok 3.5714 (3.3849)	Learning Rate [0.00125]
2: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00098)	Tok/s 59931 (52815)	Loss/tok 3.4983 (3.3816)	Learning Rate [0.00125]
8: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00097)	Tok/s 60041 (53293)	Loss/tok 3.4419 (3.3801)	Learning Rate [0.00125]
7: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00093)	Tok/s 60046 (53220)	Loss/tok 3.2947 (3.3787)	Learning Rate [0.00125]
3: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00116 (0.00097)	Tok/s 59999 (52897)	Loss/tok 3.7488 (3.3863)	Learning Rate [0.00125]
1: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00092)	Tok/s 59935 (52722)	Loss/tok 3.5709 (3.3836)	Learning Rate [0.00125]
9: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00093)	Tok/s 60027 (53361)	Loss/tok 3.4618 (3.3877)	Learning Rate [0.00125]
10: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00097)	Tok/s 60033 (53443)	Loss/tok 3.3107 (3.3849)	Learning Rate [0.00125]
15: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00091)	Tok/s 59890 (53906)	Loss/tok 3.4636 (3.3828)	Learning Rate [0.00125]
14: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00093)	Tok/s 59948 (53815)	Loss/tok 3.5975 (3.3881)	Learning Rate [0.00125]
11: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00097)	Tok/s 60019 (53519)	Loss/tok 3.4044 (3.3889)	Learning Rate [0.00125]
12: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00096)	Tok/s 59949 (53616)	Loss/tok 3.5777 (3.3892)	Learning Rate [0.00125]
0: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00092)	Tok/s 59915 (52637)	Loss/tok 3.7544 (3.3905)	Learning Rate [0.00125]
6: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00117 (0.00100)	Tok/s 60150 (53132)	Loss/tok 3.3836 (3.3891)	Learning Rate [0.00125]
13: TRAIN [1][1440/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00099)	Tok/s 60036 (53715)	Loss/tok 3.4983 (3.3864)	Learning Rate [0.00125]
8: TRAIN [1][1450/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00097)	Tok/s 55416 (53305)	Loss/tok 3.4198 (3.3809)	Learning Rate [0.00125]
9: TRAIN [1][1450/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00093)	Tok/s 55323 (53374)	Loss/tok 3.3075 (3.3883)	Learning Rate [0.00125]
7: TRAIN [1][1450/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00093)	Tok/s 55408 (53231)	Loss/tok 3.4232 (3.3789)	Learning Rate [0.00125]
10: TRAIN [1][1450/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00097)	Tok/s 55231 (53456)	Loss/tok 3.3810 (3.3845)	Learning Rate [0.00125]
5: TRAIN [1][1450/3416]	Time 0.060 (0.058)	Data 0.00081 (0.00097)	Tok/s 55329 (53076)	Loss/tok 3.5327 (3.3873)	Learning Rate [0.00125]
12: TRAIN [1][1450/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00096)	Tok/s 55063 (53628)	Loss/tok 3.4264 (3.3899)	Learning Rate [0.00125]
6: TRAIN [1][1450/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00100)	Tok/s 55385 (53145)	Loss/tok 3.0887 (3.3892)	Learning Rate [0.00125]
11: TRAIN [1][1450/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00097)	Tok/s 55121 (53531)	Loss/tok 3.6044 (3.3893)	Learning Rate [0.00125]
4: TRAIN [1][1450/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00091)	Tok/s 55206 (52976)	Loss/tok 3.3504 (3.3854)	Learning Rate [0.00125]
13: TRAIN [1][1450/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00099)	Tok/s 54896 (53727)	Loss/tok 3.6533 (3.3868)	Learning Rate [0.00125]
2: TRAIN [1][1450/3416]	Time 0.060 (0.058)	Data 0.00091 (0.00098)	Tok/s 55039 (52828)	Loss/tok 3.1640 (3.3821)	Learning Rate [0.00125]
3: TRAIN [1][1450/3416]	Time 0.060 (0.058)	Data 0.00094 (0.00097)	Tok/s 55130 (52909)	Loss/tok 3.3030 (3.3865)	Learning Rate [0.00125]
1: TRAIN [1][1450/3416]	Time 0.061 (0.058)	Data 0.00082 (0.00092)	Tok/s 54934 (52735)	Loss/tok 3.3957 (3.3841)	Learning Rate [0.00125]
15: TRAIN [1][1450/3416]	Time 0.061 (0.058)	Data 0.00081 (0.00091)	Tok/s 54887 (53917)	Loss/tok 3.3308 (3.3829)	Learning Rate [0.00125]
14: TRAIN [1][1450/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00093)	Tok/s 54769 (53827)	Loss/tok 3.2791 (3.3882)	Learning Rate [0.00125]
0: TRAIN [1][1450/3416]	Time 0.061 (0.058)	Data 0.00079 (0.00092)	Tok/s 54873 (52651)	Loss/tok 3.6006 (3.3912)	Learning Rate [0.00125]
15: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00091)	Tok/s 51611 (53946)	Loss/tok 3.2835 (3.3823)	Learning Rate [0.00125]
13: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00099)	Tok/s 51545 (53755)	Loss/tok 3.5912 (3.3867)	Learning Rate [0.00125]
12: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00096)	Tok/s 51512 (53655)	Loss/tok 3.2033 (3.3890)	Learning Rate [0.00125]
11: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 51550 (53559)	Loss/tok 3.5075 (3.3897)	Learning Rate [0.00125]
1: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00081 (0.00092)	Tok/s 50330 (52763)	Loss/tok 3.2527 (3.3841)	Learning Rate [0.00125]
14: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00093)	Tok/s 51562 (53856)	Loss/tok 3.3284 (3.3878)	Learning Rate [0.00125]
10: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00097)	Tok/s 51489 (53483)	Loss/tok 3.4790 (3.3840)	Learning Rate [0.00125]
2: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00098)	Tok/s 50303 (52855)	Loss/tok 3.2407 (3.3821)	Learning Rate [0.00125]
9: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00093)	Tok/s 51507 (53401)	Loss/tok 3.8441 (3.3884)	Learning Rate [0.00125]
3: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00097)	Tok/s 50361 (52937)	Loss/tok 3.0790 (3.3863)	Learning Rate [0.00125]
8: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00097)	Tok/s 51525 (53332)	Loss/tok 2.9552 (3.3810)	Learning Rate [0.00125]
5: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 51506 (53104)	Loss/tok 3.2543 (3.3872)	Learning Rate [0.00125]
4: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00091)	Tok/s 50330 (53004)	Loss/tok 3.3462 (3.3850)	Learning Rate [0.00125]
7: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00093)	Tok/s 51531 (53259)	Loss/tok 3.4355 (3.3788)	Learning Rate [0.00125]
6: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00100)	Tok/s 51546 (53172)	Loss/tok 3.4153 (3.3892)	Learning Rate [0.00125]
0: TRAIN [1][1460/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00092)	Tok/s 50347 (52678)	Loss/tok 3.1786 (3.3912)	Learning Rate [0.00125]
4: TRAIN [1][1470/3416]	Time 0.060 (0.058)	Data 0.00100 (0.00091)	Tok/s 53482 (53016)	Loss/tok 3.4991 (3.3854)	Learning Rate [0.00125]
5: TRAIN [1][1470/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00097)	Tok/s 53417 (53117)	Loss/tok 3.3788 (3.3875)	Learning Rate [0.00125]
3: TRAIN [1][1470/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00097)	Tok/s 53379 (52949)	Loss/tok 3.4891 (3.3861)	Learning Rate [0.00125]
2: TRAIN [1][1470/3416]	Time 0.060 (0.058)	Data 0.00081 (0.00098)	Tok/s 53301 (52868)	Loss/tok 3.3535 (3.3821)	Learning Rate [0.00125]
1: TRAIN [1][1470/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00092)	Tok/s 53197 (52776)	Loss/tok 3.4166 (3.3843)	Learning Rate [0.00125]
6: TRAIN [1][1470/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00100)	Tok/s 53753 (53185)	Loss/tok 3.5463 (3.3894)	Learning Rate [0.00125]
7: TRAIN [1][1470/3416]	Time 0.060 (0.058)	Data 0.00100 (0.00093)	Tok/s 54306 (53271)	Loss/tok 3.5418 (3.3786)	Learning Rate [0.00125]
8: TRAIN [1][1470/3416]	Time 0.060 (0.058)	Data 0.00096 (0.00097)	Tok/s 54210 (53345)	Loss/tok 3.5933 (3.3817)	Learning Rate [0.00125]
15: TRAIN [1][1470/3416]	Time 0.060 (0.058)	Data 0.00081 (0.00091)	Tok/s 54058 (53956)	Loss/tok 3.3252 (3.3827)	Learning Rate [0.00125]
9: TRAIN [1][1470/3416]	Time 0.060 (0.058)	Data 0.00089 (0.00093)	Tok/s 54119 (53413)	Loss/tok 3.4535 (3.3883)	Learning Rate [0.00125]
10: TRAIN [1][1470/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00097)	Tok/s 54006 (53495)	Loss/tok 3.2643 (3.3842)	Learning Rate [0.00125]
14: TRAIN [1][1470/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00093)	Tok/s 53929 (53867)	Loss/tok 3.6112 (3.3880)	Learning Rate [0.00125]
13: TRAIN [1][1470/3416]	Time 0.059 (0.058)	Data 0.00137 (0.00099)	Tok/s 55028 (53766)	Loss/tok 3.4305 (3.3864)	Learning Rate [0.00125]
11: TRAIN [1][1470/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00097)	Tok/s 53921 (53571)	Loss/tok 3.3120 (3.3898)	Learning Rate [0.00125]
12: TRAIN [1][1470/3416]	Time 0.061 (0.058)	Data 0.00099 (0.00096)	Tok/s 53874 (53667)	Loss/tok 3.4439 (3.3892)	Learning Rate [0.00125]
0: TRAIN [1][1470/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00092)	Tok/s 53098 (52692)	Loss/tok 3.4532 (3.3911)	Learning Rate [0.00125]
12: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00096)	Tok/s 74230 (53733)	Loss/tok 3.2010 (3.3884)	Learning Rate [0.00125]
11: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 74321 (53637)	Loss/tok 3.5463 (3.3896)	Learning Rate [0.00125]
13: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00099)	Tok/s 74328 (53831)	Loss/tok 3.5566 (3.3865)	Learning Rate [0.00125]
14: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 74367 (53931)	Loss/tok 3.2686 (3.3875)	Learning Rate [0.00125]
15: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 74330 (54020)	Loss/tok 3.4065 (3.3822)	Learning Rate [0.00125]
10: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 74158 (53562)	Loss/tok 3.3463 (3.3841)	Learning Rate [0.00125]
9: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 74234 (53480)	Loss/tok 3.3192 (3.3881)	Learning Rate [0.00125]
8: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 74232 (53411)	Loss/tok 3.4405 (3.3816)	Learning Rate [0.00125]
2: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00098)	Tok/s 73473 (52935)	Loss/tok 3.4471 (3.3819)	Learning Rate [0.00125]
7: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00093)	Tok/s 73883 (53337)	Loss/tok 3.3973 (3.3786)	Learning Rate [0.00125]
5: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00097)	Tok/s 73425 (53183)	Loss/tok 3.5615 (3.3876)	Learning Rate [0.00125]
1: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 73471 (52843)	Loss/tok 3.4630 (3.3841)	Learning Rate [0.00125]
3: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 73458 (53016)	Loss/tok 3.3840 (3.3862)	Learning Rate [0.00125]
6: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00100)	Tok/s 73415 (53251)	Loss/tok 3.6969 (3.3895)	Learning Rate [0.00125]
4: TRAIN [1][1480/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00091)	Tok/s 73409 (53082)	Loss/tok 3.4863 (3.3855)	Learning Rate [0.00125]
0: TRAIN [1][1480/3416]	Time 0.071 (0.058)	Data 0.00089 (0.00092)	Tok/s 72176 (52758)	Loss/tok 3.4518 (3.3910)	Learning Rate [0.00125]
5: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00097)	Tok/s 34617 (53181)	Loss/tok 3.1903 (3.3878)	Learning Rate [0.00125]
4: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00091)	Tok/s 34658 (53081)	Loss/tok 2.8964 (3.3852)	Learning Rate [0.00125]
6: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00100)	Tok/s 34621 (53248)	Loss/tok 3.0912 (3.3895)	Learning Rate [0.00125]
7: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00093)	Tok/s 34490 (53336)	Loss/tok 3.1279 (3.3785)	Learning Rate [0.00125]
3: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00097)	Tok/s 34559 (53013)	Loss/tok 3.0314 (3.3856)	Learning Rate [0.00125]
2: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00098)	Tok/s 34504 (52932)	Loss/tok 3.0219 (3.3821)	Learning Rate [0.00125]
8: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00097)	Tok/s 34406 (53409)	Loss/tok 3.2088 (3.3811)	Learning Rate [0.00125]
10: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 34274 (53560)	Loss/tok 3.2125 (3.3843)	Learning Rate [0.00125]
1: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00092)	Tok/s 34423 (52841)	Loss/tok 3.0254 (3.3840)	Learning Rate [0.00125]
9: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00093)	Tok/s 34335 (53478)	Loss/tok 3.3085 (3.3879)	Learning Rate [0.00125]
15: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00091)	Tok/s 34819 (54017)	Loss/tok 3.3600 (3.3826)	Learning Rate [0.00125]
11: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00097)	Tok/s 34221 (53636)	Loss/tok 3.0058 (3.3892)	Learning Rate [0.00125]
12: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00096)	Tok/s 34223 (53731)	Loss/tok 3.3353 (3.3884)	Learning Rate [0.00125]
13: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00099)	Tok/s 34268 (53828)	Loss/tok 2.9444 (3.3861)	Learning Rate [0.00125]
14: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00108 (0.00093)	Tok/s 34287 (53928)	Loss/tok 3.0216 (3.3872)	Learning Rate [0.00125]
0: TRAIN [1][1490/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00092)	Tok/s 34303 (52758)	Loss/tok 3.2215 (3.3908)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
2: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 66020 (52908)	Loss/tok 3.4667 (3.3824)	Learning Rate [0.00125]
8: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
3: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 65933 (52989)	Loss/tok 3.7370 (3.3862)	Learning Rate [0.00125]
14: Upscaling, new scale: 2048.0
1: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 66050 (52818)	Loss/tok 3.1989 (3.3839)	Learning Rate [0.00125]
12: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
4: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00091)	Tok/s 65977 (53055)	Loss/tok 3.7968 (3.3856)	Learning Rate [0.00125]
13: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
10: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 67175 (53535)	Loss/tok 3.4690 (3.3841)	Learning Rate [0.00125]
5: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00097)	Tok/s 65979 (53155)	Loss/tok 3.4927 (3.3881)	Learning Rate [0.00125]
15: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 66984 (53990)	Loss/tok 3.4045 (3.3827)	Learning Rate [0.00125]
8: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00097)	Tok/s 67071 (53384)	Loss/tok 3.6966 (3.3813)	Learning Rate [0.00125]
11: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 67147 (53610)	Loss/tok 3.6532 (3.3895)	Learning Rate [0.00125]
7: TRAIN [1][1500/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00093)	Tok/s 67127 (53310)	Loss/tok 3.4729 (3.3779)	Learning Rate [0.00125]
12: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00096)	Tok/s 67028 (53705)	Loss/tok 3.1760 (3.3881)	Learning Rate [0.00125]
13: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00099)	Tok/s 66996 (53802)	Loss/tok 3.5733 (3.3862)	Learning Rate [0.00125]
6: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00100)	Tok/s 65970 (53222)	Loss/tok 3.4508 (3.3893)	Learning Rate [0.00125]
14: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 66938 (53902)	Loss/tok 3.6835 (3.3870)	Learning Rate [0.00125]
9: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 67084 (53453)	Loss/tok 3.4537 (3.3877)	Learning Rate [0.00125]
0: Upscaling, new scale: 2048.0
0: TRAIN [1][1500/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 65911 (52735)	Loss/tok 3.2802 (3.3903)	Learning Rate [0.00125]
2: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00098)	Tok/s 65288 (52876)	Loss/tok 3.7344 (3.3819)	Learning Rate [0.00125]
3: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 65298 (52957)	Loss/tok 3.4780 (3.3855)	Learning Rate [0.00125]
4: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 65237 (53024)	Loss/tok 3.5916 (3.3851)	Learning Rate [0.00125]
15: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00091)	Tok/s 65846 (53966)	Loss/tok 3.2993 (3.3821)	Learning Rate [0.00125]
5: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 65249 (53124)	Loss/tok 3.3809 (3.3878)	Learning Rate [0.00125]
6: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 65237 (53192)	Loss/tok 3.4514 (3.3887)	Learning Rate [0.00125]
13: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00099)	Tok/s 64845 (53776)	Loss/tok 3.5042 (3.3859)	Learning Rate [0.00125]
7: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 65092 (53280)	Loss/tok 3.2648 (3.3773)	Learning Rate [0.00125]
12: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00096)	Tok/s 64845 (53678)	Loss/tok 3.4306 (3.3873)	Learning Rate [0.00125]
11: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 64853 (53582)	Loss/tok 3.4050 (3.3889)	Learning Rate [0.00125]
10: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 64885 (53505)	Loss/tok 3.7891 (3.3833)	Learning Rate [0.00125]
8: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 65009 (53354)	Loss/tok 3.5397 (3.3806)	Learning Rate [0.00125]
9: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 64893 (53423)	Loss/tok 3.5528 (3.3874)	Learning Rate [0.00125]
0: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 65023 (52699)	Loss/tok 3.4583 (3.3899)	Learning Rate [0.00125]
1: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00092)	Tok/s 65084 (52784)	Loss/tok 3.4991 (3.3834)	Learning Rate [0.00125]
14: TRAIN [1][1510/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 65343 (53876)	Loss/tok 3.7496 (3.3865)	Learning Rate [0.00125]
1: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 59654 (52823)	Loss/tok 3.3393 (3.3832)	Learning Rate [0.00125]
0: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 59767 (52739)	Loss/tok 3.4760 (3.3900)	Learning Rate [0.00125]
2: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 59528 (52915)	Loss/tok 3.6517 (3.3828)	Learning Rate [0.00125]
15: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00091)	Tok/s 60443 (54002)	Loss/tok 3.4271 (3.3828)	Learning Rate [0.00125]
3: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 59456 (52996)	Loss/tok 3.6589 (3.3859)	Learning Rate [0.00125]
4: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 59361 (53063)	Loss/tok 3.3738 (3.3852)	Learning Rate [0.00125]
5: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 59230 (53162)	Loss/tok 3.4100 (3.3881)	Learning Rate [0.00125]
13: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 59587 (53813)	Loss/tok 3.6210 (3.3861)	Learning Rate [0.00125]
12: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00096)	Tok/s 59502 (53715)	Loss/tok 3.3907 (3.3874)	Learning Rate [0.00125]
7: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 59228 (53318)	Loss/tok 3.6581 (3.3781)	Learning Rate [0.00125]
6: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00100)	Tok/s 59165 (53230)	Loss/tok 3.4343 (3.3888)	Learning Rate [0.00125]
11: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 59417 (53619)	Loss/tok 3.6510 (3.3890)	Learning Rate [0.00125]
10: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 59324 (53543)	Loss/tok 3.4034 (3.3833)	Learning Rate [0.00125]
8: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 59164 (53392)	Loss/tok 3.3713 (3.3806)	Learning Rate [0.00125]
9: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 59150 (53461)	Loss/tok 3.8037 (3.3877)	Learning Rate [0.00125]
14: TRAIN [1][1520/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00093)	Tok/s 59651 (53912)	Loss/tok 3.3512 (3.3864)	Learning Rate [0.00125]
2: Gradient norm: inf
1: Gradient norm: inf
7: Gradient norm: inf
6: Gradient norm: inf
3: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
13: Gradient norm: inf
0: Gradient norm: inf
5: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
8: Gradient norm: inf
15: Gradient norm: inf
9: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
14: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
14: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
5: TRAIN [1][1530/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 58863 (53146)	Loss/tok 3.6203 (3.3875)	Learning Rate [0.00125]
3: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00136 (0.00097)	Tok/s 58857 (52978)	Loss/tok 3.4445 (3.3849)	Learning Rate [0.00125]
4: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 58809 (53047)	Loss/tok 3.6176 (3.3849)	Learning Rate [0.00125]
6: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00100)	Tok/s 58688 (53213)	Loss/tok 3.3809 (3.3884)	Learning Rate [0.00125]
7: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00093)	Tok/s 58654 (53301)	Loss/tok 3.5730 (3.3775)	Learning Rate [0.00125]
2: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00098)	Tok/s 58833 (52898)	Loss/tok 3.3334 (3.3821)	Learning Rate [0.00125]
8: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 58669 (53376)	Loss/tok 3.3369 (3.3800)	Learning Rate [0.00125]
1: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 58824 (52806)	Loss/tok 3.3593 (3.3827)	Learning Rate [0.00125]
9: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 58728 (53444)	Loss/tok 3.3818 (3.3875)	Learning Rate [0.00125]
11: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00097)	Tok/s 58773 (53603)	Loss/tok 3.5715 (3.3883)	Learning Rate [0.00125]
0: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 58806 (52722)	Loss/tok 3.5215 (3.3893)	Learning Rate [0.00125]
10: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 58729 (53527)	Loss/tok 3.4487 (3.3828)	Learning Rate [0.00125]
15: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00091)	Tok/s 58779 (53988)	Loss/tok 3.4511 (3.3821)	Learning Rate [0.00125]
12: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00096)	Tok/s 58722 (53700)	Loss/tok 3.7357 (3.3866)	Learning Rate [0.00125]
13: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00099)	Tok/s 58709 (53799)	Loss/tok 3.4565 (3.3855)	Learning Rate [0.00125]
14: TRAIN [1][1530/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00093)	Tok/s 58832 (53899)	Loss/tok 3.7633 (3.3860)	Learning Rate [0.00125]
1: TRAIN [1][1540/3416]	Time 0.067 (0.058)	Data 0.00109 (0.00092)	Tok/s 54189 (52801)	Loss/tok 3.3802 (3.3824)	Learning Rate [0.00125]
0: TRAIN [1][1540/3416]	Time 0.067 (0.058)	Data 0.00107 (0.00092)	Tok/s 54163 (52716)	Loss/tok 3.3958 (3.3889)	Learning Rate [0.00125]
2: TRAIN [1][1540/3416]	Time 0.067 (0.058)	Data 0.00104 (0.00098)	Tok/s 54114 (52894)	Loss/tok 3.5204 (3.3818)	Learning Rate [0.00125]
15: TRAIN [1][1540/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00091)	Tok/s 55077 (53993)	Loss/tok 3.6046 (3.3818)	Learning Rate [0.00125]
3: TRAIN [1][1540/3416]	Time 0.068 (0.058)	Data 0.00111 (0.00097)	Tok/s 54015 (52975)	Loss/tok 3.5910 (3.3848)	Learning Rate [0.00125]
4: TRAIN [1][1540/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00092)	Tok/s 53935 (53043)	Loss/tok 3.3723 (3.3844)	Learning Rate [0.00125]
13: TRAIN [1][1540/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00099)	Tok/s 54285 (53801)	Loss/tok 3.5082 (3.3852)	Learning Rate [0.00125]
5: TRAIN [1][1540/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00097)	Tok/s 53826 (53144)	Loss/tok 3.3558 (3.3875)	Learning Rate [0.00125]
10: TRAIN [1][1540/3416]	Time 0.068 (0.058)	Data 0.00109 (0.00097)	Tok/s 53776 (53528)	Loss/tok 3.5264 (3.3822)	Learning Rate [0.00125]
12: TRAIN [1][1540/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00096)	Tok/s 53857 (53701)	Loss/tok 3.6847 (3.3859)	Learning Rate [0.00125]
11: TRAIN [1][1540/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00097)	Tok/s 53784 (53604)	Loss/tok 3.6700 (3.3873)	Learning Rate [0.00125]
6: TRAIN [1][1540/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00100)	Tok/s 53756 (53213)	Loss/tok 3.5208 (3.3881)	Learning Rate [0.00125]
8: TRAIN [1][1540/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00097)	Tok/s 53595 (53376)	Loss/tok 3.3477 (3.3797)	Learning Rate [0.00125]
9: TRAIN [1][1540/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00093)	Tok/s 53651 (53445)	Loss/tok 3.5598 (3.3873)	Learning Rate [0.00125]
14: TRAIN [1][1540/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00092)	Tok/s 55023 (53902)	Loss/tok 3.5384 (3.3855)	Learning Rate [0.00125]
7: TRAIN [1][1540/3416]	Time 0.068 (0.058)	Data 0.00109 (0.00093)	Tok/s 53647 (53301)	Loss/tok 3.4673 (3.3775)	Learning Rate [0.00125]
2: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00098)	Tok/s 36644 (52910)	Loss/tok 3.0099 (3.3818)	Learning Rate [0.00125]
1: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 36628 (52817)	Loss/tok 3.0044 (3.3827)	Learning Rate [0.00125]
3: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00097)	Tok/s 36710 (52992)	Loss/tok 3.1089 (3.3844)	Learning Rate [0.00125]
0: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00092)	Tok/s 36504 (52732)	Loss/tok 3.0479 (3.3882)	Learning Rate [0.00125]
4: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 37899 (53061)	Loss/tok 3.2715 (3.3840)	Learning Rate [0.00125]
15: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00091)	Tok/s 37676 (54008)	Loss/tok 3.0178 (3.3818)	Learning Rate [0.00125]
5: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00097)	Tok/s 37933 (53161)	Loss/tok 3.3468 (3.3875)	Learning Rate [0.00125]
6: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00100)	Tok/s 37947 (53230)	Loss/tok 3.0139 (3.3883)	Learning Rate [0.00125]
13: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00099)	Tok/s 37667 (53817)	Loss/tok 3.0086 (3.3850)	Learning Rate [0.00125]
12: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00096)	Tok/s 37676 (53717)	Loss/tok 3.2853 (3.3862)	Learning Rate [0.00125]
10: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00097)	Tok/s 37749 (53543)	Loss/tok 2.9517 (3.3822)	Learning Rate [0.00125]
11: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00097)	Tok/s 37688 (53620)	Loss/tok 3.0627 (3.3866)	Learning Rate [0.00125]
7: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00093)	Tok/s 37904 (53317)	Loss/tok 3.2051 (3.3774)	Learning Rate [0.00125]
8: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00097)	Tok/s 37804 (53391)	Loss/tok 2.8537 (3.3791)	Learning Rate [0.00125]
9: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 37743 (53460)	Loss/tok 2.8415 (3.3876)	Learning Rate [0.00125]
14: TRAIN [1][1550/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00092)	Tok/s 37690 (53917)	Loss/tok 3.2621 (3.3857)	Learning Rate [0.00125]
7: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00093)	Tok/s 63081 (53337)	Loss/tok 3.4566 (3.3779)	Learning Rate [0.00125]
6: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 63118 (53250)	Loss/tok 3.6477 (3.3882)	Learning Rate [0.00125]
8: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00097)	Tok/s 63056 (53411)	Loss/tok 3.4534 (3.3792)	Learning Rate [0.00125]
5: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00114 (0.00097)	Tok/s 63083 (53181)	Loss/tok 3.5934 (3.3876)	Learning Rate [0.00125]
9: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 63094 (53479)	Loss/tok 3.3021 (3.3875)	Learning Rate [0.00125]
11: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 63154 (53639)	Loss/tok 3.4253 (3.3863)	Learning Rate [0.00125]
10: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 63086 (53562)	Loss/tok 3.3537 (3.3825)	Learning Rate [0.00125]
3: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00097)	Tok/s 63116 (53011)	Loss/tok 3.3625 (3.3841)	Learning Rate [0.00125]
12: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00096)	Tok/s 63172 (53736)	Loss/tok 3.2866 (3.3861)	Learning Rate [0.00125]
2: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 63108 (52930)	Loss/tok 3.3149 (3.3815)	Learning Rate [0.00125]
4: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00092)	Tok/s 63148 (53081)	Loss/tok 3.3363 (3.3830)	Learning Rate [0.00125]
1: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 63185 (52837)	Loss/tok 3.4395 (3.3825)	Learning Rate [0.00125]
13: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00099)	Tok/s 63169 (53836)	Loss/tok 3.7226 (3.3854)	Learning Rate [0.00125]
0: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 62408 (52752)	Loss/tok 3.4487 (3.3880)	Learning Rate [0.00125]
15: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 63080 (54025)	Loss/tok 3.6549 (3.3824)	Learning Rate [0.00125]
14: TRAIN [1][1560/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 63088 (53935)	Loss/tok 3.6316 (3.3861)	Learning Rate [0.00125]
5: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00097)	Tok/s 68806 (53187)	Loss/tok 3.3426 (3.3877)	Learning Rate [0.00125]
6: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 68737 (53256)	Loss/tok 3.6653 (3.3886)	Learning Rate [0.00125]
7: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00093)	Tok/s 68611 (53345)	Loss/tok 3.5708 (3.3785)	Learning Rate [0.00125]
4: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00078 (0.00092)	Tok/s 68779 (53087)	Loss/tok 3.3805 (3.3829)	Learning Rate [0.00125]
8: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 68489 (53419)	Loss/tok 3.3519 (3.3796)	Learning Rate [0.00125]
9: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 68438 (53487)	Loss/tok 3.4302 (3.3880)	Learning Rate [0.00125]
3: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 68574 (53019)	Loss/tok 3.6542 (3.3845)	Learning Rate [0.00125]
2: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 67701 (52937)	Loss/tok 3.6316 (3.3821)	Learning Rate [0.00125]
10: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00097)	Tok/s 68250 (53569)	Loss/tok 3.5477 (3.3827)	Learning Rate [0.00125]
1: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 67654 (52844)	Loss/tok 3.5581 (3.3830)	Learning Rate [0.00125]
12: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00096)	Tok/s 68247 (53742)	Loss/tok 3.2508 (3.3860)	Learning Rate [0.00125]
11: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 68195 (53646)	Loss/tok 3.5181 (3.3863)	Learning Rate [0.00125]
0: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 67529 (52759)	Loss/tok 3.3109 (3.3881)	Learning Rate [0.00125]
15: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00091)	Tok/s 68749 (54030)	Loss/tok 3.8307 (3.3831)	Learning Rate [0.00125]
14: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 68290 (53940)	Loss/tok 3.2511 (3.3855)	Learning Rate [0.00125]
13: TRAIN [1][1570/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00099)	Tok/s 68193 (53841)	Loss/tok 3.3201 (3.3851)	Learning Rate [0.00125]
4: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00078 (0.00092)	Tok/s 70703 (53120)	Loss/tok 3.4330 (3.3833)	Learning Rate [0.00125]
3: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00097)	Tok/s 70764 (53051)	Loss/tok 3.3181 (3.3847)	Learning Rate [0.00125]
5: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00097)	Tok/s 70713 (53219)	Loss/tok 3.5947 (3.3881)	Learning Rate [0.00125]
2: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00098)	Tok/s 70758 (52970)	Loss/tok 3.5132 (3.3821)	Learning Rate [0.00125]
6: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00100)	Tok/s 70741 (53288)	Loss/tok 3.6105 (3.3893)	Learning Rate [0.00125]
1: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00076 (0.00092)	Tok/s 70727 (52878)	Loss/tok 3.3179 (3.3829)	Learning Rate [0.00125]
8: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 71699 (53451)	Loss/tok 3.3536 (3.3793)	Learning Rate [0.00125]
10: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00097)	Tok/s 71774 (53600)	Loss/tok 3.5536 (3.3830)	Learning Rate [0.00125]
0: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 70808 (52793)	Loss/tok 3.3888 (3.3881)	Learning Rate [0.00125]
9: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00093)	Tok/s 71664 (53519)	Loss/tok 3.3101 (3.3879)	Learning Rate [0.00125]
7: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00093)	Tok/s 71464 (53377)	Loss/tok 3.3189 (3.3783)	Learning Rate [0.00125]
15: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 71648 (54062)	Loss/tok 3.4159 (3.3830)	Learning Rate [0.00125]
14: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 71657 (53972)	Loss/tok 3.5769 (3.3856)	Learning Rate [0.00125]
13: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00099)	Tok/s 71657 (53873)	Loss/tok 3.3244 (3.3853)	Learning Rate [0.00125]
11: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 71702 (53677)	Loss/tok 3.4427 (3.3868)	Learning Rate [0.00125]
12: TRAIN [1][1580/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 71655 (53774)	Loss/tok 3.5093 (3.3859)	Learning Rate [0.00125]
8: TRAIN [1][1590/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 69361 (53484)	Loss/tok 3.2235 (3.3793)	Learning Rate [0.00125]
2: TRAIN [1][1590/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00098)	Tok/s 69265 (53004)	Loss/tok 3.5614 (3.3821)	Learning Rate [0.00125]
10: TRAIN [1][1590/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 69190 (53633)	Loss/tok 3.6131 (3.3828)	Learning Rate [0.00125]
3: TRAIN [1][1590/3416]	Time 0.069 (0.058)	Data 0.00130 (0.00097)	Tok/s 69370 (53085)	Loss/tok 3.2632 (3.3840)	Learning Rate [0.00125]
9: TRAIN [1][1590/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 69265 (53551)	Loss/tok 3.5483 (3.3878)	Learning Rate [0.00125]
7: TRAIN [1][1590/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00093)	Tok/s 69371 (53411)	Loss/tok 3.4020 (3.3780)	Learning Rate [0.00125]
4: TRAIN [1][1590/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 69272 (53154)	Loss/tok 3.6258 (3.3834)	Learning Rate [0.00125]
6: TRAIN [1][1590/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00100)	Tok/s 69361 (53322)	Loss/tok 3.3973 (3.3891)	Learning Rate [0.00125]
11: TRAIN [1][1590/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 69087 (53710)	Loss/tok 3.4710 (3.3874)	Learning Rate [0.00125]
12: TRAIN [1][1590/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 68947 (53807)	Loss/tok 3.4816 (3.3857)	Learning Rate [0.00125]
14: TRAIN [1][1590/3416]	Time 0.070 (0.058)	Data 0.00112 (0.00092)	Tok/s 69817 (54007)	Loss/tok 3.8269 (3.3856)	Learning Rate [0.00125]
0: TRAIN [1][1590/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 68103 (52826)	Loss/tok 3.3789 (3.3877)	Learning Rate [0.00125]
5: TRAIN [1][1590/3416]	Time 0.069 (0.058)	Data 0.00119 (0.00097)	Tok/s 69345 (53253)	Loss/tok 3.3399 (3.3875)	Learning Rate [0.00125]
1: TRAIN [1][1590/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 69014 (52911)	Loss/tok 3.2814 (3.3832)	Learning Rate [0.00125]
13: TRAIN [1][1590/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00099)	Tok/s 69265 (53907)	Loss/tok 3.4446 (3.3852)	Learning Rate [0.00125]
15: TRAIN [1][1590/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00091)	Tok/s 69819 (54097)	Loss/tok 3.2471 (3.3830)	Learning Rate [0.00125]
4: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00092)	Tok/s 32878 (53141)	Loss/tok 2.8132 (3.3828)	Learning Rate [0.00125]
5: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00097)	Tok/s 32909 (53240)	Loss/tok 2.8579 (3.3870)	Learning Rate [0.00125]
6: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00100)	Tok/s 32949 (53309)	Loss/tok 3.1693 (3.3884)	Learning Rate [0.00125]
3: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00097)	Tok/s 32773 (53073)	Loss/tok 3.0306 (3.3840)	Learning Rate [0.00125]
8: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00097)	Tok/s 32957 (53469)	Loss/tok 2.8403 (3.3787)	Learning Rate [0.00125]
2: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00098)	Tok/s 32726 (52992)	Loss/tok 3.0661 (3.3816)	Learning Rate [0.00125]
7: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00093)	Tok/s 32958 (53397)	Loss/tok 3.1941 (3.3774)	Learning Rate [0.00125]
9: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00093)	Tok/s 32952 (53538)	Loss/tok 2.7728 (3.3871)	Learning Rate [0.00125]
10: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00097)	Tok/s 32919 (53619)	Loss/tok 3.1474 (3.3829)	Learning Rate [0.00125]
1: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00092)	Tok/s 32740 (52899)	Loss/tok 2.9342 (3.3828)	Learning Rate [0.00125]
0: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00092)	Tok/s 32706 (52812)	Loss/tok 3.2625 (3.3878)	Learning Rate [0.00125]
11: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00097)	Tok/s 32870 (53696)	Loss/tok 2.7986 (3.3870)	Learning Rate [0.00125]
12: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00096)	Tok/s 34095 (53794)	Loss/tok 3.0481 (3.3851)	Learning Rate [0.00125]
13: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00099)	Tok/s 34056 (53893)	Loss/tok 3.1039 (3.3847)	Learning Rate [0.00125]
15: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00091)	Tok/s 34002 (54083)	Loss/tok 2.8792 (3.3825)	Learning Rate [0.00125]
14: TRAIN [1][1600/3416]	Time 0.049 (0.058)	Data 0.00111 (0.00093)	Tok/s 34087 (53994)	Loss/tok 3.3222 (3.3856)	Learning Rate [0.00125]
15: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00091)	Tok/s 38560 (54103)	Loss/tok 3.0748 (3.3824)	Learning Rate [0.00125]
14: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00093)	Tok/s 38526 (54014)	Loss/tok 3.0765 (3.3860)	Learning Rate [0.00125]
13: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00099)	Tok/s 38602 (53914)	Loss/tok 3.3622 (3.3851)	Learning Rate [0.00125]
12: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00096)	Tok/s 38586 (53815)	Loss/tok 3.1677 (3.3849)	Learning Rate [0.00125]
0: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00092)	Tok/s 37283 (52834)	Loss/tok 3.1333 (3.3876)	Learning Rate [0.00125]
11: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00097)	Tok/s 38500 (53717)	Loss/tok 3.2473 (3.3869)	Learning Rate [0.00125]
10: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00097)	Tok/s 38481 (53640)	Loss/tok 3.1439 (3.3828)	Learning Rate [0.00125]
1: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00092)	Tok/s 37262 (52920)	Loss/tok 3.0091 (3.3829)	Learning Rate [0.00125]
2: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00098)	Tok/s 37228 (53013)	Loss/tok 2.8877 (3.3817)	Learning Rate [0.00125]
3: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00097)	Tok/s 37195 (53093)	Loss/tok 3.2564 (3.3844)	Learning Rate [0.00125]
9: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00080 (0.00093)	Tok/s 38372 (53558)	Loss/tok 3.1875 (3.3871)	Learning Rate [0.00125]
8: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00097)	Tok/s 38307 (53490)	Loss/tok 3.1094 (3.3789)	Learning Rate [0.00125]
4: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00092)	Tok/s 38256 (53162)	Loss/tok 3.0175 (3.3827)	Learning Rate [0.00125]
5: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00097)	Tok/s 38291 (53260)	Loss/tok 3.3577 (3.3866)	Learning Rate [0.00125]
6: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00100)	Tok/s 38187 (53329)	Loss/tok 3.1279 (3.3882)	Learning Rate [0.00125]
7: TRAIN [1][1610/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00093)	Tok/s 38206 (53417)	Loss/tok 3.2433 (3.3777)	Learning Rate [0.00125]
2: TRAIN [1][1620/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00098)	Tok/s 49148 (53008)	Loss/tok 3.4431 (3.3822)	Learning Rate [0.00125]
3: TRAIN [1][1620/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00097)	Tok/s 49071 (53089)	Loss/tok 3.2882 (3.3846)	Learning Rate [0.00125]
4: TRAIN [1][1620/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00092)	Tok/s 49938 (53160)	Loss/tok 3.3232 (3.3828)	Learning Rate [0.00125]
1: TRAIN [1][1620/3416]	Time 0.048 (0.058)	Data 0.00081 (0.00092)	Tok/s 49177 (52914)	Loss/tok 3.0609 (3.3829)	Learning Rate [0.00125]
5: TRAIN [1][1620/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00097)	Tok/s 50203 (53259)	Loss/tok 3.1553 (3.3866)	Learning Rate [0.00125]
0: TRAIN [1][1620/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 49166 (52826)	Loss/tok 3.0220 (3.3877)	Learning Rate [0.00125]
15: TRAIN [1][1620/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00091)	Tok/s 50412 (54103)	Loss/tok 3.5113 (3.3823)	Learning Rate [0.00125]
6: TRAIN [1][1620/3416]	Time 0.049 (0.058)	Data 0.00104 (0.00100)	Tok/s 50035 (53328)	Loss/tok 3.3769 (3.3885)	Learning Rate [0.00125]
13: TRAIN [1][1620/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00099)	Tok/s 51749 (53914)	Loss/tok 3.0317 (3.3850)	Learning Rate [0.00125]
14: TRAIN [1][1620/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00093)	Tok/s 50388 (54013)	Loss/tok 3.1308 (3.3860)	Learning Rate [0.00125]
8: TRAIN [1][1620/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00097)	Tok/s 49952 (53490)	Loss/tok 3.2679 (3.3789)	Learning Rate [0.00125]
7: TRAIN [1][1620/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00093)	Tok/s 49966 (53417)	Loss/tok 3.3516 (3.3781)	Learning Rate [0.00125]
9: TRAIN [1][1620/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00093)	Tok/s 49970 (53558)	Loss/tok 3.0154 (3.3872)	Learning Rate [0.00125]
12: TRAIN [1][1620/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00096)	Tok/s 50108 (53815)	Loss/tok 3.1353 (3.3852)	Learning Rate [0.00125]
10: TRAIN [1][1620/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00097)	Tok/s 49935 (53640)	Loss/tok 3.1488 (3.3830)	Learning Rate [0.00125]
11: TRAIN [1][1620/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00097)	Tok/s 50004 (53717)	Loss/tok 3.2202 (3.3867)	Learning Rate [0.00125]
2: TRAIN [1][1630/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 73918 (52997)	Loss/tok 3.3678 (3.3821)	Learning Rate [0.00125]
14: TRAIN [1][1630/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 74880 (53999)	Loss/tok 3.4032 (3.3856)	Learning Rate [0.00125]
15: TRAIN [1][1630/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 74935 (54089)	Loss/tok 3.4987 (3.3826)	Learning Rate [0.00125]
4: TRAIN [1][1630/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 73771 (53148)	Loss/tok 3.4677 (3.3829)	Learning Rate [0.00125]
3: TRAIN [1][1630/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00097)	Tok/s 73868 (53077)	Loss/tok 3.3215 (3.3844)	Learning Rate [0.00125]
1: TRAIN [1][1630/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 73943 (52904)	Loss/tok 3.2610 (3.3826)	Learning Rate [0.00125]
0: TRAIN [1][1630/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00092)	Tok/s 73937 (52816)	Loss/tok 3.2512 (3.3873)	Learning Rate [0.00125]
5: TRAIN [1][1630/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00097)	Tok/s 73615 (53246)	Loss/tok 3.4995 (3.3869)	Learning Rate [0.00125]
13: TRAIN [1][1630/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00099)	Tok/s 74616 (53900)	Loss/tok 3.4623 (3.3851)	Learning Rate [0.00125]
12: TRAIN [1][1630/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00096)	Tok/s 74526 (53801)	Loss/tok 3.3389 (3.3849)	Learning Rate [0.00125]
11: TRAIN [1][1630/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 74409 (53703)	Loss/tok 3.3551 (3.3866)	Learning Rate [0.00125]
6: TRAIN [1][1630/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 73442 (53315)	Loss/tok 3.4903 (3.3883)	Learning Rate [0.00125]
10: TRAIN [1][1630/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 74286 (53626)	Loss/tok 3.4016 (3.3831)	Learning Rate [0.00125]
8: TRAIN [1][1630/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 74232 (53477)	Loss/tok 3.4864 (3.3786)	Learning Rate [0.00125]
7: TRAIN [1][1630/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00093)	Tok/s 74074 (53403)	Loss/tok 3.3368 (3.3780)	Learning Rate [0.00125]
9: TRAIN [1][1630/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 74209 (53545)	Loss/tok 3.3247 (3.3870)	Learning Rate [0.00125]
3: TRAIN [1][1640/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00097)	Tok/s 56328 (53074)	Loss/tok 3.4207 (3.3844)	Learning Rate [0.00125]
2: TRAIN [1][1640/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00098)	Tok/s 56218 (52994)	Loss/tok 3.4754 (3.3821)	Learning Rate [0.00125]
1: TRAIN [1][1640/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00092)	Tok/s 56176 (52901)	Loss/tok 3.6724 (3.3828)	Learning Rate [0.00125]
4: TRAIN [1][1640/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00092)	Tok/s 56299 (53144)	Loss/tok 3.4445 (3.3828)	Learning Rate [0.00125]
5: TRAIN [1][1640/3416]	Time 0.067 (0.058)	Data 0.00116 (0.00097)	Tok/s 57259 (53243)	Loss/tok 3.6802 (3.3874)	Learning Rate [0.00125]
0: TRAIN [1][1640/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00092)	Tok/s 55981 (52813)	Loss/tok 3.5616 (3.3879)	Learning Rate [0.00125]
6: TRAIN [1][1640/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00100)	Tok/s 57205 (53312)	Loss/tok 3.6067 (3.3882)	Learning Rate [0.00125]
15: TRAIN [1][1640/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00091)	Tok/s 56889 (54084)	Loss/tok 3.6195 (3.3828)	Learning Rate [0.00125]
14: TRAIN [1][1640/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00093)	Tok/s 56785 (53995)	Loss/tok 3.4563 (3.3862)	Learning Rate [0.00125]
10: TRAIN [1][1640/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00096)	Tok/s 56945 (53621)	Loss/tok 3.4557 (3.3832)	Learning Rate [0.00125]
8: TRAIN [1][1640/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00097)	Tok/s 57040 (53472)	Loss/tok 3.4311 (3.3788)	Learning Rate [0.00125]
13: TRAIN [1][1640/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00099)	Tok/s 56805 (53895)	Loss/tok 3.5543 (3.3852)	Learning Rate [0.00125]
12: TRAIN [1][1640/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00096)	Tok/s 56792 (53796)	Loss/tok 3.3690 (3.3851)	Learning Rate [0.00125]
11: TRAIN [1][1640/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00097)	Tok/s 56835 (53697)	Loss/tok 3.5303 (3.3864)	Learning Rate [0.00125]
9: TRAIN [1][1640/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00093)	Tok/s 56901 (53540)	Loss/tok 3.5476 (3.3869)	Learning Rate [0.00125]
7: TRAIN [1][1640/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00093)	Tok/s 57114 (53400)	Loss/tok 3.5824 (3.3782)	Learning Rate [0.00125]
15: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 72045 (54083)	Loss/tok 3.3004 (3.3823)	Learning Rate [0.00125]
14: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 72117 (53992)	Loss/tok 3.3543 (3.3859)	Learning Rate [0.00125]
0: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 71038 (52804)	Loss/tok 3.4000 (3.3883)	Learning Rate [0.00125]
13: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00099)	Tok/s 72157 (53893)	Loss/tok 3.3976 (3.3858)	Learning Rate [0.00125]
1: TRAIN [1][1650/3416]	Time 0.068 (0.058)	Data 0.00119 (0.00092)	Tok/s 72121 (52893)	Loss/tok 3.2114 (3.3830)	Learning Rate [0.00125]
12: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00096)	Tok/s 72037 (53794)	Loss/tok 3.5565 (3.3854)	Learning Rate [0.00125]
2: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 71011 (52988)	Loss/tok 3.5646 (3.3818)	Learning Rate [0.00125]
11: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00097)	Tok/s 72137 (53694)	Loss/tok 3.2600 (3.3859)	Learning Rate [0.00125]
10: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00096)	Tok/s 72109 (53618)	Loss/tok 3.6046 (3.3835)	Learning Rate [0.00125]
4: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 70929 (53139)	Loss/tok 3.4448 (3.3827)	Learning Rate [0.00125]
5: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 71227 (53239)	Loss/tok 3.5304 (3.3877)	Learning Rate [0.00125]
9: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 72060 (53537)	Loss/tok 3.5756 (3.3870)	Learning Rate [0.00125]
8: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 72043 (53469)	Loss/tok 3.2722 (3.3783)	Learning Rate [0.00125]
6: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 71923 (53308)	Loss/tok 3.3097 (3.3882)	Learning Rate [0.00125]
7: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00093)	Tok/s 71873 (53396)	Loss/tok 3.3794 (3.3779)	Learning Rate [0.00125]
3: TRAIN [1][1650/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 70973 (53068)	Loss/tok 3.3780 (3.3846)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
10: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00114 (0.00097)	Tok/s 60125 (53606)	Loss/tok 3.2812 (3.3830)	Learning Rate [0.00125]
11: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00097)	Tok/s 60189 (53682)	Loss/tok 3.4464 (3.3851)	Learning Rate [0.00125]
12: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00096)	Tok/s 60213 (53782)	Loss/tok 3.2906 (3.3844)	Learning Rate [0.00125]
7: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 60139 (53384)	Loss/tok 3.4063 (3.3772)	Learning Rate [0.00125]
14: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00093)	Tok/s 60299 (53981)	Loss/tok 3.4668 (3.3856)	Learning Rate [0.00125]
9: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00093)	Tok/s 60032 (53525)	Loss/tok 3.6311 (3.3866)	Learning Rate [0.00125]
15: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 60297 (54072)	Loss/tok 3.6723 (3.3816)	Learning Rate [0.00125]
13: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00099)	Tok/s 60175 (53881)	Loss/tok 3.5143 (3.3849)	Learning Rate [0.00125]
8: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 60005 (53458)	Loss/tok 3.5513 (3.3780)	Learning Rate [0.00125]
6: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00100)	Tok/s 60001 (53295)	Loss/tok 3.6863 (3.3875)	Learning Rate [0.00125]
5: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00097)	Tok/s 60004 (53225)	Loss/tok 3.3885 (3.3871)	Learning Rate [0.00125]
4: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 60051 (53125)	Loss/tok 3.5119 (3.3823)	Learning Rate [0.00125]
0: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00092)	Tok/s 60177 (52784)	Loss/tok 3.4799 (3.3880)	Learning Rate [0.00125]
1: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 60129 (52875)	Loss/tok 3.4923 (3.3826)	Learning Rate [0.00125]
2: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00098)	Tok/s 60058 (52972)	Loss/tok 3.6333 (3.3813)	Learning Rate [0.00125]
3: TRAIN [1][1660/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 60011 (53053)	Loss/tok 3.4334 (3.3840)	Learning Rate [0.00125]
15: Gradient norm: inf
14: Gradient norm: inf
0: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
3: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
10: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
15: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00091)	Tok/s 54642 (54065)	Loss/tok 3.4765 (3.3813)	Learning Rate [0.00125]
14: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00093)	Tok/s 54665 (53974)	Loss/tok 3.3245 (3.3851)	Learning Rate [0.00125]
0: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00092)	Tok/s 54523 (52773)	Loss/tok 3.4286 (3.3876)	Learning Rate [0.00125]
7: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00093)	Tok/s 54516 (53373)	Loss/tok 3.5201 (3.3771)	Learning Rate [0.00125]
1: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00092)	Tok/s 54406 (52863)	Loss/tok 3.0161 (3.3819)	Learning Rate [0.00125]
13: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00099)	Tok/s 54644 (53874)	Loss/tok 3.4640 (3.3843)	Learning Rate [0.00125]
2: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00098)	Tok/s 54318 (52960)	Loss/tok 3.5238 (3.3812)	Learning Rate [0.00125]
10: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00097)	Tok/s 54683 (53597)	Loss/tok 3.3888 (3.3823)	Learning Rate [0.00125]
12: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00096)	Tok/s 54612 (53773)	Loss/tok 3.1378 (3.3838)	Learning Rate [0.00125]
3: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00097)	Tok/s 54273 (53041)	Loss/tok 3.4608 (3.3838)	Learning Rate [0.00125]
6: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00100)	Tok/s 54401 (53284)	Loss/tok 3.3618 (3.3868)	Learning Rate [0.00125]
5: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00097)	Tok/s 54362 (53215)	Loss/tok 3.7298 (3.3866)	Learning Rate [0.00125]
8: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00097)	Tok/s 54515 (53448)	Loss/tok 3.3510 (3.3775)	Learning Rate [0.00125]
4: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00092)	Tok/s 54257 (53114)	Loss/tok 3.4652 (3.3822)	Learning Rate [0.00125]
11: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00097)	Tok/s 54597 (53672)	Loss/tok 3.3524 (3.3847)	Learning Rate [0.00125]
9: TRAIN [1][1670/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00093)	Tok/s 54496 (53515)	Loss/tok 3.3548 (3.3863)	Learning Rate [0.00125]
2: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00098)	Tok/s 60184 (52966)	Loss/tok 3.3615 (3.3809)	Learning Rate [0.00125]
1: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 60188 (52870)	Loss/tok 3.6979 (3.3825)	Learning Rate [0.00125]
3: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00097)	Tok/s 60085 (53048)	Loss/tok 3.4697 (3.3840)	Learning Rate [0.00125]
4: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 60090 (53122)	Loss/tok 3.4612 (3.3822)	Learning Rate [0.00125]
0: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 60195 (52780)	Loss/tok 3.3500 (3.3875)	Learning Rate [0.00125]
15: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00080 (0.00091)	Tok/s 61150 (54072)	Loss/tok 3.4421 (3.3814)	Learning Rate [0.00125]
5: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00110 (0.00097)	Tok/s 60050 (53222)	Loss/tok 3.5670 (3.3867)	Learning Rate [0.00125]
14: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00093)	Tok/s 61092 (53981)	Loss/tok 3.4686 (3.3851)	Learning Rate [0.00125]
6: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00100)	Tok/s 60057 (53292)	Loss/tok 3.5589 (3.3865)	Learning Rate [0.00125]
13: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00099)	Tok/s 60473 (53881)	Loss/tok 3.4768 (3.3840)	Learning Rate [0.00125]
7: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 60072 (53380)	Loss/tok 3.5846 (3.3775)	Learning Rate [0.00125]
12: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00106 (0.00096)	Tok/s 60210 (53780)	Loss/tok 3.4413 (3.3840)	Learning Rate [0.00125]
8: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00097)	Tok/s 60075 (53455)	Loss/tok 3.3914 (3.3778)	Learning Rate [0.00125]
11: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 60160 (53680)	Loss/tok 3.6521 (3.3847)	Learning Rate [0.00125]
10: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00097)	Tok/s 60137 (53604)	Loss/tok 3.6668 (3.3829)	Learning Rate [0.00125]
9: TRAIN [1][1680/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00093)	Tok/s 60064 (53522)	Loss/tok 3.4908 (3.3862)	Learning Rate [0.00125]
2: Gradient norm: inf
1: Gradient norm: inf
2: Skipped batch, new scale: 512.0
3: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 512.0
3: Skipped batch, new scale: 512.0
4: Gradient norm: inf
15: Gradient norm: inf
0: Skipped batch, new scale: 512.0
5: Gradient norm: inf
4: Skipped batch, new scale: 512.0
15: Skipped batch, new scale: 512.0
14: Gradient norm: inf
6: Gradient norm: inf
5: Skipped batch, new scale: 512.0
13: Gradient norm: inf
6: Skipped batch, new scale: 512.0
14: Skipped batch, new scale: 512.0
7: Gradient norm: inf
12: Gradient norm: inf
13: Skipped batch, new scale: 512.0
8: Gradient norm: inf
7: Skipped batch, new scale: 512.0
12: Skipped batch, new scale: 512.0
11: Gradient norm: inf
10: Gradient norm: inf
9: Gradient norm: inf
8: Skipped batch, new scale: 512.0
11: Skipped batch, new scale: 512.0
9: Skipped batch, new scale: 512.0
10: Skipped batch, new scale: 512.0
15: TRAIN [1][1690/3416]	Time 0.049 (0.058)	Data 0.00082 (0.00091)	Tok/s 40868 (54119)	Loss/tok 3.1988 (3.3808)	Learning Rate [0.00125]
14: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00093)	Tok/s 39607 (54028)	Loss/tok 3.1112 (3.3847)	Learning Rate [0.00125]
0: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00092)	Tok/s 38224 (52813)	Loss/tok 3.1952 (3.3871)	Learning Rate [0.00125]
13: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00099)	Tok/s 39586 (53927)	Loss/tok 3.0863 (3.3831)	Learning Rate [0.00125]
1: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00092)	Tok/s 38144 (52906)	Loss/tok 3.1125 (3.3819)	Learning Rate [0.00125]
12: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00096)	Tok/s 39546 (53826)	Loss/tok 2.9373 (3.3832)	Learning Rate [0.00125]
2: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00098)	Tok/s 38044 (53003)	Loss/tok 3.1181 (3.3803)	Learning Rate [0.00125]
11: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00084 (0.00097)	Tok/s 39439 (53724)	Loss/tok 3.4649 (3.3841)	Learning Rate [0.00125]
10: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00111 (0.00097)	Tok/s 39380 (53649)	Loss/tok 3.1486 (3.3818)	Learning Rate [0.00125]
3: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00097)	Tok/s 38060 (53085)	Loss/tok 3.2663 (3.3836)	Learning Rate [0.00125]
5: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00097)	Tok/s 38069 (53262)	Loss/tok 3.1473 (3.3861)	Learning Rate [0.00125]
4: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00080 (0.00092)	Tok/s 38041 (53160)	Loss/tok 3.4886 (3.3815)	Learning Rate [0.00125]
8: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00097)	Tok/s 39335 (53497)	Loss/tok 3.2163 (3.3775)	Learning Rate [0.00125]
9: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00093)	Tok/s 39302 (53566)	Loss/tok 2.8874 (3.3856)	Learning Rate [0.00125]
6: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00100)	Tok/s 38058 (53331)	Loss/tok 3.0559 (3.3864)	Learning Rate [0.00125]
7: TRAIN [1][1690/3416]	Time 0.050 (0.058)	Data 0.00081 (0.00093)	Tok/s 38191 (53421)	Loss/tok 3.1210 (3.3767)	Learning Rate [0.00125]
4: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00092)	Tok/s 64914 (53174)	Loss/tok 3.5066 (3.3823)	Learning Rate [0.00125]
5: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 64928 (53275)	Loss/tok 3.4749 (3.3865)	Learning Rate [0.00125]
6: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00100)	Tok/s 64981 (53345)	Loss/tok 3.4159 (3.3871)	Learning Rate [0.00125]
15: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00091)	Tok/s 65580 (54132)	Loss/tok 3.4647 (3.3812)	Learning Rate [0.00125]
9: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00093)	Tok/s 64978 (53578)	Loss/tok 3.8609 (3.3862)	Learning Rate [0.00125]
14: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00093)	Tok/s 65581 (54040)	Loss/tok 3.3742 (3.3849)	Learning Rate [0.00125]
1: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00092)	Tok/s 64567 (52920)	Loss/tok 3.5650 (3.3824)	Learning Rate [0.00125]
8: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00097)	Tok/s 64932 (53510)	Loss/tok 3.2356 (3.3779)	Learning Rate [0.00125]
7: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 65135 (53435)	Loss/tok 3.6035 (3.3766)	Learning Rate [0.00125]
2: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00098)	Tok/s 64574 (53017)	Loss/tok 3.5537 (3.3810)	Learning Rate [0.00125]
0: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00219 (0.00092)	Tok/s 64530 (52828)	Loss/tok 3.3908 (3.3874)	Learning Rate [0.00125]
3: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00097)	Tok/s 64692 (53099)	Loss/tok 3.4067 (3.3841)	Learning Rate [0.00125]
10: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00117 (0.00097)	Tok/s 64758 (53661)	Loss/tok 3.5452 (3.3819)	Learning Rate [0.00125]
13: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00121 (0.00099)	Tok/s 65250 (53940)	Loss/tok 3.6520 (3.3836)	Learning Rate [0.00125]
12: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00096)	Tok/s 64622 (53839)	Loss/tok 3.6807 (3.3834)	Learning Rate [0.00125]
11: TRAIN [1][1700/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00097)	Tok/s 64677 (53737)	Loss/tok 3.5157 (3.3848)	Learning Rate [0.00125]
14: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00093)	Tok/s 55890 (54031)	Loss/tok 3.2250 (3.3844)	Learning Rate [0.00125]
15: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00105 (0.00091)	Tok/s 55780 (54124)	Loss/tok 3.3889 (3.3810)	Learning Rate [0.00125]
13: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00099)	Tok/s 55592 (53930)	Loss/tok 3.4201 (3.3834)	Learning Rate [0.00125]
12: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00104 (0.00096)	Tok/s 54831 (53829)	Loss/tok 3.2519 (3.3831)	Learning Rate [0.00125]
11: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00097)	Tok/s 54835 (53726)	Loss/tok 3.3830 (3.3845)	Learning Rate [0.00125]
10: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00110 (0.00097)	Tok/s 54808 (53649)	Loss/tok 3.1106 (3.3815)	Learning Rate [0.00125]
0: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00092)	Tok/s 54586 (52809)	Loss/tok 3.3419 (3.3874)	Learning Rate [0.00125]
1: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00092)	Tok/s 54611 (52903)	Loss/tok 3.4914 (3.3823)	Learning Rate [0.00125]
8: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00097)	Tok/s 54802 (53499)	Loss/tok 3.3049 (3.3777)	Learning Rate [0.00125]
2: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00098)	Tok/s 54630 (53002)	Loss/tok 3.3682 (3.3809)	Learning Rate [0.00125]
6: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00100)	Tok/s 54757 (53333)	Loss/tok 3.2860 (3.3868)	Learning Rate [0.00125]
3: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00097)	Tok/s 54622 (53084)	Loss/tok 3.3630 (3.3837)	Learning Rate [0.00125]
7: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00093)	Tok/s 54760 (53423)	Loss/tok 3.4835 (3.3764)	Learning Rate [0.00125]
5: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00097)	Tok/s 54673 (53261)	Loss/tok 3.5559 (3.3860)	Learning Rate [0.00125]
9: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00093)	Tok/s 54792 (53567)	Loss/tok 3.1330 (3.3861)	Learning Rate [0.00125]
4: TRAIN [1][1710/3416]	Time 0.060 (0.058)	Data 0.00103 (0.00092)	Tok/s 54636 (53161)	Loss/tok 3.0862 (3.3815)	Learning Rate [0.00125]
12: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00096)	Tok/s 34125 (53813)	Loss/tok 2.8781 (3.3832)	Learning Rate [0.00125]
13: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00099)	Tok/s 34195 (53915)	Loss/tok 2.9922 (3.3830)	Learning Rate [0.00125]
15: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00091)	Tok/s 34577 (54109)	Loss/tok 3.1504 (3.3809)	Learning Rate [0.00125]
14: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00079 (0.00093)	Tok/s 34014 (54015)	Loss/tok 3.0853 (3.3838)	Learning Rate [0.00125]
11: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 34208 (53712)	Loss/tok 3.1537 (3.3841)	Learning Rate [0.00125]
5: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00097)	Tok/s 34157 (53248)	Loss/tok 3.1622 (3.3861)	Learning Rate [0.00125]
4: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00092)	Tok/s 34164 (53148)	Loss/tok 3.0959 (3.3816)	Learning Rate [0.00125]
9: TRAIN [1][1720/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00093)	Tok/s 34223 (53553)	Loss/tok 3.1321 (3.3863)	Learning Rate [0.00125]
0: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00092)	Tok/s 34092 (52796)	Loss/tok 3.0215 (3.3878)	Learning Rate [0.00125]
6: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00100)	Tok/s 34135 (53319)	Loss/tok 2.9975 (3.3868)	Learning Rate [0.00125]
7: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00082 (0.00093)	Tok/s 34155 (53409)	Loss/tok 3.2636 (3.3763)	Learning Rate [0.00125]
8: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00097)	Tok/s 34184 (53484)	Loss/tok 3.1873 (3.3774)	Learning Rate [0.00125]
1: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00092)	Tok/s 34108 (52890)	Loss/tok 2.9658 (3.3822)	Learning Rate [0.00125]
3: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00097)	Tok/s 34121 (53071)	Loss/tok 2.9724 (3.3837)	Learning Rate [0.00125]
2: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00098)	Tok/s 34080 (52989)	Loss/tok 3.0223 (3.3811)	Learning Rate [0.00125]
10: TRAIN [1][1720/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00097)	Tok/s 33981 (53635)	Loss/tok 3.0826 (3.3816)	Learning Rate [0.00125]
9: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 51088 (53521)	Loss/tok 3.1997 (3.3858)	Learning Rate [0.00125]
8: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00097)	Tok/s 50982 (53453)	Loss/tok 3.0259 (3.3770)	Learning Rate [0.00125]
7: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00082 (0.00093)	Tok/s 50917 (53377)	Loss/tok 3.5524 (3.3759)	Learning Rate [0.00125]
10: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00097)	Tok/s 51036 (53604)	Loss/tok 3.2607 (3.3815)	Learning Rate [0.00125]
6: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00100)	Tok/s 50774 (53288)	Loss/tok 3.3498 (3.3864)	Learning Rate [0.00125]
5: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00097)	Tok/s 50736 (53216)	Loss/tok 3.1081 (3.3851)	Learning Rate [0.00125]
11: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00097)	Tok/s 50997 (53680)	Loss/tok 3.4531 (3.3840)	Learning Rate [0.00125]
4: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00092)	Tok/s 50768 (53115)	Loss/tok 3.1455 (3.3805)	Learning Rate [0.00125]
3: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00097)	Tok/s 50771 (53038)	Loss/tok 3.3843 (3.3829)	Learning Rate [0.00125]
13: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00099)	Tok/s 52314 (53883)	Loss/tok 3.4338 (3.3828)	Learning Rate [0.00125]
2: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00097)	Tok/s 50732 (52955)	Loss/tok 3.1062 (3.3807)	Learning Rate [0.00125]
14: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00093)	Tok/s 52293 (53983)	Loss/tok 3.2394 (3.3832)	Learning Rate [0.00125]
1: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00092)	Tok/s 50825 (52857)	Loss/tok 3.2550 (3.3816)	Learning Rate [0.00125]
15: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00091)	Tok/s 52192 (54077)	Loss/tok 3.4575 (3.3804)	Learning Rate [0.00125]
0: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00092)	Tok/s 50789 (52763)	Loss/tok 3.2342 (3.3872)	Learning Rate [0.00125]
12: TRAIN [1][1730/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00096)	Tok/s 50782 (53782)	Loss/tok 3.2558 (3.3829)	Learning Rate [0.00125]
4: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00092)	Tok/s 45962 (53137)	Loss/tok 3.3538 (3.3803)	Learning Rate [0.00125]
5: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00097)	Tok/s 45876 (53238)	Loss/tok 3.0523 (3.3850)	Learning Rate [0.00125]
2: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00097)	Tok/s 45869 (52976)	Loss/tok 3.1543 (3.3806)	Learning Rate [0.00125]
6: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00100)	Tok/s 45755 (53310)	Loss/tok 3.0648 (3.3857)	Learning Rate [0.00125]
3: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00103 (0.00097)	Tok/s 45932 (53059)	Loss/tok 3.0292 (3.3828)	Learning Rate [0.00125]
1: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00092)	Tok/s 45796 (52878)	Loss/tok 3.1452 (3.3813)	Learning Rate [0.00125]
7: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00093)	Tok/s 45705 (53399)	Loss/tok 3.3334 (3.3762)	Learning Rate [0.00125]
0: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00092)	Tok/s 45650 (52784)	Loss/tok 3.1988 (3.3872)	Learning Rate [0.00125]
8: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00111 (0.00097)	Tok/s 45695 (53473)	Loss/tok 3.4131 (3.3767)	Learning Rate [0.00125]
15: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00091)	Tok/s 45670 (54097)	Loss/tok 3.1869 (3.3807)	Learning Rate [0.00125]
14: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00092)	Tok/s 45705 (54003)	Loss/tok 3.1487 (3.3830)	Learning Rate [0.00125]
9: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00093)	Tok/s 45694 (53541)	Loss/tok 3.3168 (3.3855)	Learning Rate [0.00125]
10: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 45634 (53624)	Loss/tok 3.3072 (3.3813)	Learning Rate [0.00125]
12: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00096)	Tok/s 45646 (53802)	Loss/tok 2.9367 (3.3826)	Learning Rate [0.00125]
13: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00099)	Tok/s 45641 (53903)	Loss/tok 3.1695 (3.3831)	Learning Rate [0.00125]
11: TRAIN [1][1740/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 45614 (53700)	Loss/tok 3.4521 (3.3838)	Learning Rate [0.00125]
14: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00086 (0.00093)	Tok/s 32242 (54016)	Loss/tok 2.5837 (3.3823)	Learning Rate [0.00125]
15: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00097 (0.00092)	Tok/s 32211 (54110)	Loss/tok 2.9442 (3.3808)	Learning Rate [0.00125]
8: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00094 (0.00097)	Tok/s 32261 (53487)	Loss/tok 2.7006 (3.3768)	Learning Rate [0.00125]
7: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00084 (0.00093)	Tok/s 32260 (53412)	Loss/tok 2.6980 (3.3764)	Learning Rate [0.00125]
2: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00097)	Tok/s 30781 (52989)	Loss/tok 2.9369 (3.3809)	Learning Rate [0.00125]
3: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00102 (0.00097)	Tok/s 30776 (53072)	Loss/tok 2.7837 (3.3828)	Learning Rate [0.00125]
10: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00103 (0.00097)	Tok/s 32209 (53637)	Loss/tok 2.5973 (3.3813)	Learning Rate [0.00125]
13: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00104 (0.00099)	Tok/s 32215 (53917)	Loss/tok 2.7242 (3.3832)	Learning Rate [0.00125]
6: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00096 (0.00100)	Tok/s 31323 (53323)	Loss/tok 2.4158 (3.3857)	Learning Rate [0.00125]
4: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00096 (0.00092)	Tok/s 30767 (53150)	Loss/tok 2.6972 (3.3804)	Learning Rate [0.00125]
11: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00097 (0.00097)	Tok/s 32180 (53714)	Loss/tok 2.6614 (3.3840)	Learning Rate [0.00125]
0: TRAIN [1][1750/3416]	Time 0.043 (0.058)	Data 0.00110 (0.00092)	Tok/s 29794 (52798)	Loss/tok 2.6175 (3.3872)	Learning Rate [0.00125]
1: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00110 (0.00092)	Tok/s 30707 (52891)	Loss/tok 2.8621 (3.3812)	Learning Rate [0.00125]
9: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00091 (0.00093)	Tok/s 32226 (53554)	Loss/tok 2.8039 (3.3855)	Learning Rate [0.00125]
12: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00099 (0.00096)	Tok/s 32210 (53816)	Loss/tok 2.7372 (3.3824)	Learning Rate [0.00125]
5: TRAIN [1][1750/3416]	Time 0.042 (0.058)	Data 0.00104 (0.00097)	Tok/s 30751 (53251)	Loss/tok 2.9062 (3.3848)	Learning Rate [0.00125]
0: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00092)	Tok/s 56970 (52801)	Loss/tok 3.4409 (3.3864)	Learning Rate [0.00125]
1: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00081 (0.00092)	Tok/s 57324 (52895)	Loss/tok 3.6542 (3.3812)	Learning Rate [0.00125]
14: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00092)	Tok/s 57393 (54019)	Loss/tok 3.3938 (3.3818)	Learning Rate [0.00125]
2: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00097)	Tok/s 57196 (52992)	Loss/tok 3.4538 (3.3809)	Learning Rate [0.00125]
15: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00092)	Tok/s 57444 (54114)	Loss/tok 3.3250 (3.3803)	Learning Rate [0.00125]
13: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00099)	Tok/s 57327 (53920)	Loss/tok 3.3967 (3.3826)	Learning Rate [0.00125]
12: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00096)	Tok/s 57227 (53819)	Loss/tok 3.5093 (3.3820)	Learning Rate [0.00125]
3: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00107 (0.00097)	Tok/s 57144 (53075)	Loss/tok 3.4663 (3.3825)	Learning Rate [0.00125]
4: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00092)	Tok/s 57031 (53153)	Loss/tok 3.6136 (3.3801)	Learning Rate [0.00125]
10: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00097)	Tok/s 57129 (53642)	Loss/tok 3.5391 (3.3815)	Learning Rate [0.00125]
5: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00097)	Tok/s 56962 (53254)	Loss/tok 3.6137 (3.3849)	Learning Rate [0.00125]
11: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00095 (0.00097)	Tok/s 57193 (53718)	Loss/tok 3.2730 (3.3831)	Learning Rate [0.00125]
6: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00100)	Tok/s 56959 (53326)	Loss/tok 3.2638 (3.3850)	Learning Rate [0.00125]
8: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00097)	Tok/s 57004 (53491)	Loss/tok 3.7694 (3.3770)	Learning Rate [0.00125]
9: TRAIN [1][1760/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00093)	Tok/s 56992 (53559)	Loss/tok 3.4257 (3.3858)	Learning Rate [0.00125]
7: TRAIN [1][1760/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00093)	Tok/s 56840 (53416)	Loss/tok 3.5084 (3.3760)	Learning Rate [0.00125]
4: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00092)	Tok/s 56275 (53165)	Loss/tok 3.4342 (3.3802)	Learning Rate [0.00125]
2: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00097)	Tok/s 56348 (53004)	Loss/tok 3.3849 (3.3811)	Learning Rate [0.00125]
1: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00080 (0.00092)	Tok/s 56377 (52906)	Loss/tok 3.5188 (3.3811)	Learning Rate [0.00125]
3: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00097)	Tok/s 56377 (53087)	Loss/tok 3.5684 (3.3826)	Learning Rate [0.00125]
0: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00092)	Tok/s 56322 (52813)	Loss/tok 3.3351 (3.3862)	Learning Rate [0.00125]
15: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00092)	Tok/s 57329 (54124)	Loss/tok 3.5814 (3.3805)	Learning Rate [0.00125]
14: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00092)	Tok/s 57372 (54030)	Loss/tok 3.1452 (3.3813)	Learning Rate [0.00125]
6: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00100)	Tok/s 56194 (53337)	Loss/tok 3.4102 (3.3849)	Learning Rate [0.00125]
7: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00093)	Tok/s 56243 (53427)	Loss/tok 3.4730 (3.3758)	Learning Rate [0.00125]
5: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00097)	Tok/s 56242 (53265)	Loss/tok 3.4376 (3.3850)	Learning Rate [0.00125]
9: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00093)	Tok/s 56293 (53569)	Loss/tok 3.4414 (3.3857)	Learning Rate [0.00125]
8: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00097)	Tok/s 56201 (53501)	Loss/tok 3.5823 (3.3773)	Learning Rate [0.00125]
13: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00099)	Tok/s 56753 (53931)	Loss/tok 3.3782 (3.3826)	Learning Rate [0.00125]
12: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00096)	Tok/s 56282 (53830)	Loss/tok 3.5093 (3.3825)	Learning Rate [0.00125]
11: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00097)	Tok/s 56254 (53728)	Loss/tok 3.3057 (3.3834)	Learning Rate [0.00125]
10: TRAIN [1][1770/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00097)	Tok/s 56235 (53652)	Loss/tok 3.5432 (3.3816)	Learning Rate [0.00125]
2: TRAIN [1][1780/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 78805 (52977)	Loss/tok 3.4805 (3.3812)	Learning Rate [0.00125]
1: TRAIN [1][1780/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 78513 (52880)	Loss/tok 3.2996 (3.3804)	Learning Rate [0.00125]
4: TRAIN [1][1780/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00092)	Tok/s 79402 (53138)	Loss/tok 3.2712 (3.3796)	Learning Rate [0.00125]
5: TRAIN [1][1780/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 79308 (53238)	Loss/tok 3.3134 (3.3846)	Learning Rate [0.00125]
0: TRAIN [1][1780/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 78448 (52787)	Loss/tok 3.2424 (3.3860)	Learning Rate [0.00125]
14: TRAIN [1][1780/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 80262 (54003)	Loss/tok 3.3749 (3.3808)	Learning Rate [0.00125]
3: TRAIN [1][1780/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 79373 (53061)	Loss/tok 3.3140 (3.3817)	Learning Rate [0.00125]
7: TRAIN [1][1780/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 79242 (53400)	Loss/tok 3.1808 (3.3753)	Learning Rate [0.00125]
10: TRAIN [1][1780/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00097)	Tok/s 79444 (53624)	Loss/tok 3.4440 (3.3813)	Learning Rate [0.00125]
15: TRAIN [1][1780/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 80377 (54098)	Loss/tok 3.3496 (3.3803)	Learning Rate [0.00125]
8: TRAIN [1][1780/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 79104 (53474)	Loss/tok 3.2901 (3.3771)	Learning Rate [0.00125]
6: TRAIN [1][1780/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00100)	Tok/s 79271 (53310)	Loss/tok 3.3964 (3.3845)	Learning Rate [0.00125]
9: TRAIN [1][1780/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00093)	Tok/s 79080 (53541)	Loss/tok 3.2684 (3.3852)	Learning Rate [0.00125]
13: TRAIN [1][1780/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00099)	Tok/s 80136 (53904)	Loss/tok 3.4620 (3.3827)	Learning Rate [0.00125]
12: TRAIN [1][1780/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00096)	Tok/s 79994 (53803)	Loss/tok 3.3666 (3.3823)	Learning Rate [0.00125]
11: TRAIN [1][1780/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 79798 (53701)	Loss/tok 3.2978 (3.3830)	Learning Rate [0.00125]
12: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00096)	Tok/s 60396 (53847)	Loss/tok 3.7349 (3.3830)	Learning Rate [0.00125]
11: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00097)	Tok/s 59760 (53745)	Loss/tok 3.6175 (3.3830)	Learning Rate [0.00125]
1: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00092)	Tok/s 59668 (52923)	Loss/tok 3.4132 (3.3809)	Learning Rate [0.00125]
10: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00097)	Tok/s 59480 (53667)	Loss/tok 3.5687 (3.3820)	Learning Rate [0.00125]
13: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00099)	Tok/s 60385 (53948)	Loss/tok 3.5194 (3.3825)	Learning Rate [0.00125]
2: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 59674 (53021)	Loss/tok 3.5730 (3.3816)	Learning Rate [0.00125]
5: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 59684 (53283)	Loss/tok 3.4150 (3.3842)	Learning Rate [0.00125]
0: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00092)	Tok/s 59540 (52831)	Loss/tok 3.4080 (3.3862)	Learning Rate [0.00125]
14: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00092)	Tok/s 60432 (54046)	Loss/tok 3.4083 (3.3808)	Learning Rate [0.00125]
4: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00073 (0.00092)	Tok/s 59686 (53182)	Loss/tok 3.7264 (3.3794)	Learning Rate [0.00125]
15: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00092)	Tok/s 60440 (54141)	Loss/tok 3.7062 (3.3802)	Learning Rate [0.00125]
9: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00093)	Tok/s 59489 (53585)	Loss/tok 3.3487 (3.3855)	Learning Rate [0.00125]
6: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00100)	Tok/s 59631 (53354)	Loss/tok 3.5388 (3.3846)	Learning Rate [0.00125]
8: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00097)	Tok/s 59494 (53518)	Loss/tok 3.2958 (3.3771)	Learning Rate [0.00125]
3: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00097)	Tok/s 59682 (53104)	Loss/tok 3.3120 (3.3820)	Learning Rate [0.00125]
7: TRAIN [1][1790/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00093)	Tok/s 59536 (53444)	Loss/tok 3.2869 (3.3756)	Learning Rate [0.00125]
10: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00097)	Tok/s 61167 (53652)	Loss/tok 3.4569 (3.3817)	Learning Rate [0.00125]
11: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00097)	Tok/s 61140 (53729)	Loss/tok 3.7112 (3.3833)	Learning Rate [0.00125]
9: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00078 (0.00093)	Tok/s 61046 (53569)	Loss/tok 3.4921 (3.3858)	Learning Rate [0.00125]
12: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00096)	Tok/s 61203 (53831)	Loss/tok 3.5580 (3.3831)	Learning Rate [0.00125]
13: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00099)	Tok/s 61210 (53932)	Loss/tok 3.5031 (3.3821)	Learning Rate [0.00125]
7: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00093)	Tok/s 61056 (53429)	Loss/tok 3.2665 (3.3756)	Learning Rate [0.00125]
5: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 61124 (53268)	Loss/tok 3.5770 (3.3844)	Learning Rate [0.00125]
14: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 61468 (54030)	Loss/tok 3.5738 (3.3812)	Learning Rate [0.00125]
8: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 61073 (53503)	Loss/tok 3.4384 (3.3770)	Learning Rate [0.00125]
6: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00100)	Tok/s 61116 (53339)	Loss/tok 3.6000 (3.3847)	Learning Rate [0.00125]
15: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 62101 (54125)	Loss/tok 3.3994 (3.3802)	Learning Rate [0.00125]
4: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 61074 (53168)	Loss/tok 3.5479 (3.3792)	Learning Rate [0.00125]
3: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00097)	Tok/s 61119 (53090)	Loss/tok 3.3185 (3.3822)	Learning Rate [0.00125]
2: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 61133 (53006)	Loss/tok 3.2426 (3.3821)	Learning Rate [0.00125]
1: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 61125 (52909)	Loss/tok 3.6356 (3.3812)	Learning Rate [0.00125]
0: TRAIN [1][1800/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 61113 (52817)	Loss/tok 3.6283 (3.3863)	Learning Rate [0.00125]
6: TRAIN [1][1810/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 66559 (53358)	Loss/tok 3.5998 (3.3850)	Learning Rate [0.00125]
7: TRAIN [1][1810/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 66545 (53447)	Loss/tok 3.2993 (3.3755)	Learning Rate [0.00125]
5: TRAIN [1][1810/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 66407 (53286)	Loss/tok 3.2799 (3.3840)	Learning Rate [0.00125]
9: TRAIN [1][1810/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 67410 (53587)	Loss/tok 3.4884 (3.3855)	Learning Rate [0.00125]
4: TRAIN [1][1810/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00092)	Tok/s 66288 (53186)	Loss/tok 3.5286 (3.3790)	Learning Rate [0.00125]
10: TRAIN [1][1810/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00097)	Tok/s 67311 (53669)	Loss/tok 3.4301 (3.3812)	Learning Rate [0.00125]
11: TRAIN [1][1810/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 67253 (53747)	Loss/tok 3.3236 (3.3829)	Learning Rate [0.00125]
3: TRAIN [1][1810/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 66190 (53108)	Loss/tok 3.4565 (3.3819)	Learning Rate [0.00125]
2: TRAIN [1][1810/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 66101 (53025)	Loss/tok 3.5435 (3.3822)	Learning Rate [0.00125]
0: TRAIN [1][1810/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 66059 (52836)	Loss/tok 3.3674 (3.3862)	Learning Rate [0.00125]
12: TRAIN [1][1810/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00096)	Tok/s 67134 (53849)	Loss/tok 3.5247 (3.3829)	Learning Rate [0.00125]
14: TRAIN [1][1810/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 67014 (54047)	Loss/tok 3.5099 (3.3814)	Learning Rate [0.00125]
1: TRAIN [1][1810/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 65946 (52928)	Loss/tok 3.7007 (3.3814)	Learning Rate [0.00125]
13: TRAIN [1][1810/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00099)	Tok/s 66986 (53950)	Loss/tok 3.6844 (3.3822)	Learning Rate [0.00125]
15: TRAIN [1][1810/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 66884 (54142)	Loss/tok 3.3960 (3.3801)	Learning Rate [0.00125]
8: TRAIN [1][1810/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 65993 (53520)	Loss/tok 3.6325 (3.3771)	Learning Rate [0.00125]
7: Upscaling, new scale: 1024.0
8: Upscaling, new scale: 1024.0
6: Upscaling, new scale: 1024.0
5: Upscaling, new scale: 1024.0
10: Upscaling, new scale: 1024.0
9: Upscaling, new scale: 1024.0
4: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
11: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
12: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
15: Upscaling, new scale: 1024.0
14: Upscaling, new scale: 1024.0
13: Upscaling, new scale: 1024.0
9: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00093)	Tok/s 59058 (53595)	Loss/tok 3.5461 (3.3854)	Learning Rate [0.00125]
10: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00097)	Tok/s 59041 (53678)	Loss/tok 3.7347 (3.3811)	Learning Rate [0.00125]
8: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00097)	Tok/s 59072 (53528)	Loss/tok 3.3119 (3.3769)	Learning Rate [0.00125]
12: TRAIN [1][1820/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00096)	Tok/s 58765 (53858)	Loss/tok 3.5136 (3.3826)	Learning Rate [0.00125]
15: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00092)	Tok/s 59084 (54150)	Loss/tok 3.3496 (3.3798)	Learning Rate [0.00125]
11: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00097)	Tok/s 58871 (53756)	Loss/tok 3.3302 (3.3825)	Learning Rate [0.00125]
4: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00092)	Tok/s 59147 (53195)	Loss/tok 3.4215 (3.3789)	Learning Rate [0.00125]
13: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00099)	Tok/s 58874 (53959)	Loss/tok 3.4328 (3.3820)	Learning Rate [0.00125]
5: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00097)	Tok/s 59066 (53295)	Loss/tok 3.4116 (3.3836)	Learning Rate [0.00125]
6: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00100)	Tok/s 59087 (53367)	Loss/tok 3.3527 (3.3851)	Learning Rate [0.00125]
7: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00093)	Tok/s 59109 (53455)	Loss/tok 3.7506 (3.3754)	Learning Rate [0.00125]
0: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00092)	Tok/s 58926 (52846)	Loss/tok 3.2864 (3.3860)	Learning Rate [0.00125]
1: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00092)	Tok/s 58923 (52938)	Loss/tok 3.3478 (3.3814)	Learning Rate [0.00125]
2: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00097)	Tok/s 58928 (53034)	Loss/tok 3.5398 (3.3820)	Learning Rate [0.00125]
3: TRAIN [1][1820/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00097)	Tok/s 58916 (53117)	Loss/tok 3.6126 (3.3827)	Learning Rate [0.00125]
14: TRAIN [1][1820/3416]	Time 0.071 (0.058)	Data 0.00094 (0.00092)	Tok/s 57039 (54055)	Loss/tok 3.6269 (3.3814)	Learning Rate [0.00125]
0: TRAIN [1][1830/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00092)	Tok/s 54409 (52851)	Loss/tok 3.3932 (3.3860)	Learning Rate [0.00125]
14: TRAIN [1][1830/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00092)	Tok/s 55399 (54061)	Loss/tok 3.8712 (3.3818)	Learning Rate [0.00125]
15: TRAIN [1][1830/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00092)	Tok/s 55323 (54155)	Loss/tok 3.5041 (3.3805)	Learning Rate [0.00125]
3: TRAIN [1][1830/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00097)	Tok/s 54112 (53122)	Loss/tok 3.2502 (3.3826)	Learning Rate [0.00125]
2: TRAIN [1][1830/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00097)	Tok/s 54126 (53039)	Loss/tok 3.6367 (3.3825)	Learning Rate [0.00125]
13: TRAIN [1][1830/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00099)	Tok/s 55287 (53964)	Loss/tok 3.5799 (3.3821)	Learning Rate [0.00125]
1: TRAIN [1][1830/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00092)	Tok/s 54242 (52943)	Loss/tok 3.5243 (3.3816)	Learning Rate [0.00125]
12: TRAIN [1][1830/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00096)	Tok/s 55253 (53863)	Loss/tok 3.7682 (3.3831)	Learning Rate [0.00125]
10: TRAIN [1][1830/3416]	Time 0.063 (0.058)	Data 0.00093 (0.00097)	Tok/s 54138 (53683)	Loss/tok 3.1652 (3.3806)	Learning Rate [0.00125]
4: TRAIN [1][1830/3416]	Time 0.063 (0.058)	Data 0.00103 (0.00092)	Tok/s 53925 (53200)	Loss/tok 3.4910 (3.3790)	Learning Rate [0.00125]
11: TRAIN [1][1830/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00097)	Tok/s 54841 (53761)	Loss/tok 3.4036 (3.3824)	Learning Rate [0.00125]
5: TRAIN [1][1830/3416]	Time 0.063 (0.058)	Data 0.00102 (0.00097)	Tok/s 53859 (53299)	Loss/tok 3.3097 (3.3841)	Learning Rate [0.00125]
6: TRAIN [1][1830/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00100)	Tok/s 53777 (53371)	Loss/tok 3.3751 (3.3853)	Learning Rate [0.00125]
7: TRAIN [1][1830/3416]	Time 0.063 (0.058)	Data 0.00086 (0.00093)	Tok/s 53839 (53460)	Loss/tok 3.3166 (3.3755)	Learning Rate [0.00125]
9: TRAIN [1][1830/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00093)	Tok/s 53928 (53600)	Loss/tok 3.4290 (3.3855)	Learning Rate [0.00125]
8: TRAIN [1][1830/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00097)	Tok/s 53847 (53532)	Loss/tok 3.7425 (3.3773)	Learning Rate [0.00125]
15: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 82076 (54164)	Loss/tok 3.3859 (3.3799)	Learning Rate [0.00125]
0: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 79903 (52862)	Loss/tok 3.2264 (3.3855)	Learning Rate [0.00125]
1: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 79944 (52953)	Loss/tok 3.3166 (3.3814)	Learning Rate [0.00125]
13: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00099)	Tok/s 81548 (53973)	Loss/tok 3.3267 (3.3819)	Learning Rate [0.00125]
12: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00096)	Tok/s 81431 (53872)	Loss/tok 3.3080 (3.3830)	Learning Rate [0.00125]
14: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00092)	Tok/s 81623 (54069)	Loss/tok 3.2556 (3.3813)	Learning Rate [0.00125]
11: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00097)	Tok/s 81254 (53770)	Loss/tok 3.0912 (3.3814)	Learning Rate [0.00125]
2: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 80354 (53049)	Loss/tok 3.4922 (3.3820)	Learning Rate [0.00125]
10: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00097)	Tok/s 81126 (53691)	Loss/tok 3.2590 (3.3800)	Learning Rate [0.00125]
3: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 80761 (53132)	Loss/tok 3.1221 (3.3820)	Learning Rate [0.00125]
4: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 80593 (53210)	Loss/tok 3.3799 (3.3788)	Learning Rate [0.00125]
5: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 80531 (53309)	Loss/tok 3.2048 (3.3834)	Learning Rate [0.00125]
8: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 80289 (53541)	Loss/tok 3.3308 (3.3770)	Learning Rate [0.00125]
9: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 80574 (53609)	Loss/tok 3.4253 (3.3854)	Learning Rate [0.00125]
7: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00093)	Tok/s 80286 (53468)	Loss/tok 3.2691 (3.3754)	Learning Rate [0.00125]
6: TRAIN [1][1840/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 80402 (53380)	Loss/tok 3.4100 (3.3849)	Learning Rate [0.00125]
8: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00097)	Tok/s 32994 (53547)	Loss/tok 3.2485 (3.3775)	Learning Rate [0.00125]
7: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00093)	Tok/s 33008 (53474)	Loss/tok 2.7481 (3.3751)	Learning Rate [0.00125]
9: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00093)	Tok/s 32983 (53615)	Loss/tok 3.0334 (3.3855)	Learning Rate [0.00125]
10: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 32964 (53698)	Loss/tok 3.2095 (3.3797)	Learning Rate [0.00125]
6: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00100)	Tok/s 33016 (53387)	Loss/tok 2.8503 (3.3852)	Learning Rate [0.00125]
11: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00097)	Tok/s 33012 (53776)	Loss/tok 2.9935 (3.3815)	Learning Rate [0.00125]
4: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00092)	Tok/s 33005 (53216)	Loss/tok 2.9794 (3.3788)	Learning Rate [0.00125]
5: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00097)	Tok/s 33003 (53315)	Loss/tok 3.1702 (3.3835)	Learning Rate [0.00125]
12: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00096)	Tok/s 33003 (53878)	Loss/tok 2.9908 (3.3833)	Learning Rate [0.00125]
3: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00172 (0.00097)	Tok/s 32996 (53139)	Loss/tok 2.7058 (3.3820)	Learning Rate [0.00125]
2: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00097)	Tok/s 33001 (53056)	Loss/tok 3.0573 (3.3824)	Learning Rate [0.00125]
14: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 34225 (54074)	Loss/tok 3.0657 (3.3812)	Learning Rate [0.00125]
13: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00099)	Tok/s 33216 (53978)	Loss/tok 3.2172 (3.3819)	Learning Rate [0.00125]
0: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 33036 (52869)	Loss/tok 3.1887 (3.3851)	Learning Rate [0.00125]
1: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00091)	Tok/s 33003 (52960)	Loss/tok 3.0626 (3.3816)	Learning Rate [0.00125]
15: TRAIN [1][1850/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00092)	Tok/s 34223 (54170)	Loss/tok 3.0114 (3.3800)	Learning Rate [0.00125]
7: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00092 (0.00093)	Tok/s 51426 (53474)	Loss/tok 3.5356 (3.3750)	Learning Rate [0.00125]
6: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00102 (0.00100)	Tok/s 51374 (53386)	Loss/tok 3.2966 (3.3848)	Learning Rate [0.00125]
8: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00108 (0.00097)	Tok/s 51328 (53548)	Loss/tok 3.2833 (3.3770)	Learning Rate [0.00125]
5: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00110 (0.00097)	Tok/s 51320 (53315)	Loss/tok 3.4139 (3.3835)	Learning Rate [0.00125]
4: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00092)	Tok/s 51222 (53217)	Loss/tok 3.4204 (3.3787)	Learning Rate [0.00125]
9: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00096 (0.00093)	Tok/s 51234 (53616)	Loss/tok 3.0602 (3.3849)	Learning Rate [0.00125]
10: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00097)	Tok/s 51145 (53698)	Loss/tok 3.4096 (3.3797)	Learning Rate [0.00125]
3: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00110 (0.00097)	Tok/s 51075 (53139)	Loss/tok 3.5613 (3.3818)	Learning Rate [0.00125]
2: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00100 (0.00097)	Tok/s 50995 (53056)	Loss/tok 3.5772 (3.3824)	Learning Rate [0.00125]
12: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00096)	Tok/s 50990 (53878)	Loss/tok 3.3712 (3.3832)	Learning Rate [0.00125]
11: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00097)	Tok/s 51042 (53776)	Loss/tok 3.3539 (3.3812)	Learning Rate [0.00125]
1: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00091)	Tok/s 50878 (52960)	Loss/tok 3.4276 (3.3810)	Learning Rate [0.00125]
0: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00089 (0.00092)	Tok/s 50771 (52870)	Loss/tok 3.5287 (3.3852)	Learning Rate [0.00125]
15: TRAIN [1][1860/3416]	Time 0.056 (0.058)	Data 0.00086 (0.00092)	Tok/s 50713 (54170)	Loss/tok 3.4247 (3.3798)	Learning Rate [0.00125]
13: TRAIN [1][1860/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00099)	Tok/s 50857 (53978)	Loss/tok 3.1673 (3.3816)	Learning Rate [0.00125]
14: TRAIN [1][1860/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00092)	Tok/s 50732 (54074)	Loss/tok 3.2966 (3.3807)	Learning Rate [0.00125]
12: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00096)	Tok/s 32322 (53873)	Loss/tok 3.3194 (3.3833)	Learning Rate [0.00125]
11: TRAIN [1][1870/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00097)	Tok/s 32064 (53771)	Loss/tok 2.7780 (3.3809)	Learning Rate [0.00125]
10: TRAIN [1][1870/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00097)	Tok/s 31087 (53693)	Loss/tok 2.9889 (3.3797)	Learning Rate [0.00125]
9: TRAIN [1][1870/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00093)	Tok/s 31107 (53610)	Loss/tok 2.7821 (3.3846)	Learning Rate [0.00125]
13: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00099)	Tok/s 32241 (53973)	Loss/tok 3.0491 (3.3813)	Learning Rate [0.00125]
8: TRAIN [1][1870/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00097)	Tok/s 31105 (53542)	Loss/tok 3.2349 (3.3770)	Learning Rate [0.00125]
14: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00092)	Tok/s 32255 (54069)	Loss/tok 2.8857 (3.3804)	Learning Rate [0.00125]
15: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 32250 (54165)	Loss/tok 2.9806 (3.3795)	Learning Rate [0.00125]
7: TRAIN [1][1870/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00093)	Tok/s 31119 (53469)	Loss/tok 3.2019 (3.3748)	Learning Rate [0.00125]
0: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00092)	Tok/s 30959 (52865)	Loss/tok 2.9635 (3.3851)	Learning Rate [0.00125]
6: TRAIN [1][1870/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00100)	Tok/s 31118 (53382)	Loss/tok 2.9359 (3.3846)	Learning Rate [0.00125]
5: TRAIN [1][1870/3416]	Time 0.049 (0.058)	Data 0.00106 (0.00097)	Tok/s 31104 (53311)	Loss/tok 2.9442 (3.3835)	Learning Rate [0.00125]
1: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00091)	Tok/s 30985 (52956)	Loss/tok 2.9309 (3.3808)	Learning Rate [0.00125]
4: TRAIN [1][1870/3416]	Time 0.049 (0.058)	Data 0.00097 (0.00092)	Tok/s 31094 (53212)	Loss/tok 2.9335 (3.3786)	Learning Rate [0.00125]
2: TRAIN [1][1870/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 30963 (53051)	Loss/tok 2.8999 (3.3821)	Learning Rate [0.00125]
3: TRAIN [1][1870/3416]	Time 0.049 (0.058)	Data 0.00108 (0.00097)	Tok/s 31104 (53135)	Loss/tok 2.8849 (3.3816)	Learning Rate [0.00125]
12: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00096)	Tok/s 68867 (53905)	Loss/tok 3.2549 (3.3832)	Learning Rate [0.00125]
11: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 68832 (53803)	Loss/tok 3.5504 (3.3815)	Learning Rate [0.00125]
13: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 68781 (54004)	Loss/tok 3.3118 (3.3813)	Learning Rate [0.00125]
10: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 68771 (53724)	Loss/tok 3.6083 (3.3795)	Learning Rate [0.00125]
15: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 69673 (54196)	Loss/tok 3.4370 (3.3797)	Learning Rate [0.00125]
14: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 68594 (54100)	Loss/tok 3.5093 (3.3808)	Learning Rate [0.00125]
9: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 68787 (53642)	Loss/tok 3.6603 (3.3851)	Learning Rate [0.00125]
0: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 67708 (52899)	Loss/tok 3.3899 (3.3851)	Learning Rate [0.00125]
8: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 68801 (53574)	Loss/tok 3.6916 (3.3776)	Learning Rate [0.00125]
7: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00093)	Tok/s 68767 (53501)	Loss/tok 3.3270 (3.3748)	Learning Rate [0.00125]
1: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00091)	Tok/s 67703 (52989)	Loss/tok 3.6476 (3.3810)	Learning Rate [0.00125]
2: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 67783 (53084)	Loss/tok 3.7686 (3.3825)	Learning Rate [0.00125]
6: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00100)	Tok/s 68799 (53414)	Loss/tok 3.6907 (3.3845)	Learning Rate [0.00125]
5: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00115 (0.00097)	Tok/s 68776 (53343)	Loss/tok 3.5599 (3.3837)	Learning Rate [0.00125]
4: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00092)	Tok/s 68760 (53245)	Loss/tok 3.3275 (3.3788)	Learning Rate [0.00125]
3: TRAIN [1][1880/3416]	Time 0.070 (0.058)	Data 0.00122 (0.00097)	Tok/s 68199 (53168)	Loss/tok 3.5271 (3.3815)	Learning Rate [0.00125]
8: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00097)	Tok/s 36421 (53581)	Loss/tok 2.9244 (3.3777)	Learning Rate [0.00125]
9: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00093)	Tok/s 36430 (53649)	Loss/tok 3.1916 (3.3852)	Learning Rate [0.00125]
10: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 36419 (53730)	Loss/tok 3.2117 (3.3793)	Learning Rate [0.00125]
7: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00093)	Tok/s 36330 (53508)	Loss/tok 2.9743 (3.3753)	Learning Rate [0.00125]
6: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00100)	Tok/s 36264 (53422)	Loss/tok 3.0493 (3.3844)	Learning Rate [0.00125]
11: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00097)	Tok/s 36403 (53809)	Loss/tok 3.0397 (3.3815)	Learning Rate [0.00125]
5: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00108 (0.00097)	Tok/s 36186 (53352)	Loss/tok 3.1353 (3.3838)	Learning Rate [0.00125]
4: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00092)	Tok/s 36091 (53253)	Loss/tok 3.0775 (3.3789)	Learning Rate [0.00125]
12: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00096)	Tok/s 36369 (53911)	Loss/tok 3.0739 (3.3832)	Learning Rate [0.00125]
2: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00097)	Tok/s 36082 (53092)	Loss/tok 3.1593 (3.3830)	Learning Rate [0.00125]
13: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00099)	Tok/s 36289 (54011)	Loss/tok 3.0474 (3.3813)	Learning Rate [0.00125]
14: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00092)	Tok/s 36185 (54107)	Loss/tok 3.2855 (3.3806)	Learning Rate [0.00125]
15: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 36164 (54203)	Loss/tok 2.9012 (3.3797)	Learning Rate [0.00125]
3: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00110 (0.00097)	Tok/s 36079 (53176)	Loss/tok 2.9959 (3.3815)	Learning Rate [0.00125]
1: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00092)	Tok/s 36080 (52997)	Loss/tok 3.4293 (3.3810)	Learning Rate [0.00125]
0: TRAIN [1][1890/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00092)	Tok/s 35200 (52906)	Loss/tok 3.2045 (3.3851)	Learning Rate [0.00125]
9: TRAIN [1][1900/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00093)	Tok/s 52385 (53622)	Loss/tok 3.5107 (3.3851)	Learning Rate [0.00125]
8: TRAIN [1][1900/3416]	Time 0.058 (0.058)	Data 0.00104 (0.00097)	Tok/s 52294 (53555)	Loss/tok 3.0964 (3.3774)	Learning Rate [0.00125]
7: TRAIN [1][1900/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00093)	Tok/s 52248 (53482)	Loss/tok 3.6541 (3.3750)	Learning Rate [0.00125]
10: TRAIN [1][1900/3416]	Time 0.057 (0.058)	Data 0.00098 (0.00097)	Tok/s 52352 (53703)	Loss/tok 3.2847 (3.3791)	Learning Rate [0.00125]
11: TRAIN [1][1900/3416]	Time 0.057 (0.058)	Data 0.00103 (0.00097)	Tok/s 52336 (53782)	Loss/tok 3.5352 (3.3812)	Learning Rate [0.00125]
12: TRAIN [1][1900/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00096)	Tok/s 52316 (53884)	Loss/tok 3.3991 (3.3829)	Learning Rate [0.00125]
5: TRAIN [1][1900/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00097)	Tok/s 51989 (53324)	Loss/tok 3.2691 (3.3836)	Learning Rate [0.00125]
4: TRAIN [1][1900/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00092)	Tok/s 51961 (53225)	Loss/tok 3.4172 (3.3789)	Learning Rate [0.00125]
6: TRAIN [1][1900/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00100)	Tok/s 52077 (53395)	Loss/tok 3.3740 (3.3840)	Learning Rate [0.00125]
14: TRAIN [1][1900/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00092)	Tok/s 52246 (54080)	Loss/tok 3.4457 (3.3804)	Learning Rate [0.00125]
13: TRAIN [1][1900/3416]	Time 0.058 (0.058)	Data 0.00097 (0.00099)	Tok/s 52255 (53984)	Loss/tok 3.4748 (3.3812)	Learning Rate [0.00125]
15: TRAIN [1][1900/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00092)	Tok/s 52141 (54176)	Loss/tok 3.3970 (3.3793)	Learning Rate [0.00125]
1: TRAIN [1][1900/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00092)	Tok/s 51995 (52965)	Loss/tok 3.6157 (3.3808)	Learning Rate [0.00125]
0: TRAIN [1][1900/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00092)	Tok/s 52033 (52873)	Loss/tok 3.3328 (3.3849)	Learning Rate [0.00125]
2: TRAIN [1][1900/3416]	Time 0.058 (0.058)	Data 0.00100 (0.00097)	Tok/s 51949 (53061)	Loss/tok 3.4700 (3.3824)	Learning Rate [0.00125]
3: TRAIN [1][1900/3416]	Time 0.058 (0.058)	Data 0.00131 (0.00097)	Tok/s 52013 (53145)	Loss/tok 3.4310 (3.3808)	Learning Rate [0.00125]
8: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 51352 (53569)	Loss/tok 3.1322 (3.3774)	Learning Rate [0.00125]
9: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00082 (0.00093)	Tok/s 51375 (53636)	Loss/tok 3.5375 (3.3857)	Learning Rate [0.00125]
12: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00096)	Tok/s 51514 (53899)	Loss/tok 3.1669 (3.3830)	Learning Rate [0.00125]
7: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00076 (0.00093)	Tok/s 51298 (53496)	Loss/tok 2.9838 (3.3755)	Learning Rate [0.00125]
10: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 51380 (53718)	Loss/tok 3.1993 (3.3792)	Learning Rate [0.00125]
13: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00099)	Tok/s 51518 (53998)	Loss/tok 3.1831 (3.3813)	Learning Rate [0.00125]
14: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00092)	Tok/s 51560 (54094)	Loss/tok 3.4048 (3.3805)	Learning Rate [0.00125]
6: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00100)	Tok/s 51289 (53410)	Loss/tok 3.1384 (3.3844)	Learning Rate [0.00125]
11: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00097)	Tok/s 51375 (53797)	Loss/tok 3.1034 (3.3818)	Learning Rate [0.00125]
4: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00092)	Tok/s 51223 (53241)	Loss/tok 3.0785 (3.3794)	Learning Rate [0.00125]
15: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00081 (0.00091)	Tok/s 51440 (54190)	Loss/tok 3.1044 (3.3792)	Learning Rate [0.00125]
0: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00092)	Tok/s 51405 (52891)	Loss/tok 3.2002 (3.3854)	Learning Rate [0.00125]
2: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00097)	Tok/s 51247 (53077)	Loss/tok 3.3392 (3.3824)	Learning Rate [0.00125]
5: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00097)	Tok/s 51265 (53340)	Loss/tok 3.3085 (3.3840)	Learning Rate [0.00125]
1: TRAIN [1][1910/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00091)	Tok/s 51288 (52982)	Loss/tok 3.0464 (3.3811)	Learning Rate [0.00125]
3: TRAIN [1][1910/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00097)	Tok/s 51193 (53162)	Loss/tok 3.2372 (3.3810)	Learning Rate [0.00125]
5: TRAIN [1][1920/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00097)	Tok/s 57578 (53368)	Loss/tok 3.6531 (3.3841)	Learning Rate [0.00125]
4: TRAIN [1][1920/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00092)	Tok/s 57570 (53270)	Loss/tok 3.5438 (3.3789)	Learning Rate [0.00125]
6: TRAIN [1][1920/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00100)	Tok/s 57502 (53437)	Loss/tok 3.6503 (3.3842)	Learning Rate [0.00125]
2: TRAIN [1][1920/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 57505 (53106)	Loss/tok 3.4908 (3.3824)	Learning Rate [0.00125]
7: TRAIN [1][1920/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 57399 (53524)	Loss/tok 3.3365 (3.3755)	Learning Rate [0.00125]
8: TRAIN [1][1920/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 57444 (53597)	Loss/tok 3.5347 (3.3774)	Learning Rate [0.00125]
3: TRAIN [1][1920/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 57561 (53190)	Loss/tok 3.2718 (3.3804)	Learning Rate [0.00125]
1: TRAIN [1][1920/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 57432 (53011)	Loss/tok 3.5023 (3.3813)	Learning Rate [0.00125]
9: TRAIN [1][1920/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 58123 (53664)	Loss/tok 3.4242 (3.3862)	Learning Rate [0.00125]
0: TRAIN [1][1920/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 57288 (52920)	Loss/tok 3.4193 (3.3856)	Learning Rate [0.00125]
15: TRAIN [1][1920/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00091)	Tok/s 58181 (54219)	Loss/tok 3.5478 (3.3794)	Learning Rate [0.00125]
10: TRAIN [1][1920/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 58005 (53745)	Loss/tok 3.6490 (3.3800)	Learning Rate [0.00125]
14: TRAIN [1][1920/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 58020 (54122)	Loss/tok 3.6353 (3.3812)	Learning Rate [0.00125]
11: TRAIN [1][1920/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 57932 (53825)	Loss/tok 3.4137 (3.3816)	Learning Rate [0.00125]
12: TRAIN [1][1920/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00096)	Tok/s 57952 (53926)	Loss/tok 3.7034 (3.3830)	Learning Rate [0.00125]
13: TRAIN [1][1920/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 58000 (54026)	Loss/tok 3.8482 (3.3815)	Learning Rate [0.00125]
14: TRAIN [1][1930/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 32396 (54092)	Loss/tok 3.1031 (3.3805)	Learning Rate [0.00125]
15: TRAIN [1][1930/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00091)	Tok/s 32347 (54190)	Loss/tok 3.0540 (3.3793)	Learning Rate [0.00125]
13: TRAIN [1][1930/3416]	Time 0.047 (0.058)	Data 0.00108 (0.00099)	Tok/s 32367 (53996)	Loss/tok 2.9382 (3.3814)	Learning Rate [0.00125]
12: TRAIN [1][1930/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00096)	Tok/s 32016 (53896)	Loss/tok 2.9606 (3.3828)	Learning Rate [0.00125]
0: TRAIN [1][1930/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00092)	Tok/s 30994 (52880)	Loss/tok 2.7019 (3.3853)	Learning Rate [0.00125]
11: TRAIN [1][1930/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00097)	Tok/s 30912 (53794)	Loss/tok 3.1177 (3.3811)	Learning Rate [0.00125]
1: TRAIN [1][1930/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00091)	Tok/s 30984 (52973)	Loss/tok 2.8266 (3.3813)	Learning Rate [0.00125]
2: TRAIN [1][1930/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00097)	Tok/s 30947 (53069)	Loss/tok 2.9755 (3.3820)	Learning Rate [0.00125]
10: TRAIN [1][1930/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00097)	Tok/s 30844 (53715)	Loss/tok 2.8737 (3.3797)	Learning Rate [0.00125]
9: TRAIN [1][1930/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00093)	Tok/s 30832 (53633)	Loss/tok 2.8282 (3.3856)	Learning Rate [0.00125]
4: TRAIN [1][1930/3416]	Time 0.048 (0.058)	Data 0.00106 (0.00092)	Tok/s 30853 (53235)	Loss/tok 3.0306 (3.3784)	Learning Rate [0.00125]
8: TRAIN [1][1930/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00097)	Tok/s 30817 (53567)	Loss/tok 3.0189 (3.3773)	Learning Rate [0.00125]
7: TRAIN [1][1930/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00093)	Tok/s 30822 (53493)	Loss/tok 3.3014 (3.3753)	Learning Rate [0.00125]
5: TRAIN [1][1930/3416]	Time 0.048 (0.058)	Data 0.00117 (0.00097)	Tok/s 30818 (53334)	Loss/tok 3.0442 (3.3839)	Learning Rate [0.00125]
6: TRAIN [1][1930/3416]	Time 0.048 (0.058)	Data 0.00124 (0.00100)	Tok/s 30803 (53405)	Loss/tok 3.1115 (3.3839)	Learning Rate [0.00125]
3: TRAIN [1][1930/3416]	Time 0.048 (0.058)	Data 0.00119 (0.00097)	Tok/s 30726 (53155)	Loss/tok 3.1012 (3.3801)	Learning Rate [0.00125]
11: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
12: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 84435 (53913)	Loss/tok 3.2897 (3.3832)	Learning Rate [0.00125]
0: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00092)	Tok/s 82651 (52899)	Loss/tok 3.2524 (3.3855)	Learning Rate [0.00125]
9: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 83309 (53651)	Loss/tok 3.3295 (3.3854)	Learning Rate [0.00125]
10: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 83185 (53732)	Loss/tok 3.3535 (3.3799)	Learning Rate [0.00125]
11: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 83846 (53812)	Loss/tok 3.3177 (3.3806)	Learning Rate [0.00125]
8: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 83364 (53585)	Loss/tok 3.3777 (3.3773)	Learning Rate [0.00125]
13: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00099)	Tok/s 84146 (54013)	Loss/tok 3.2001 (3.3815)	Learning Rate [0.00125]
3: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00110 (0.00098)	Tok/s 82689 (53173)	Loss/tok 3.1371 (3.3800)	Learning Rate [0.00125]
7: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 83344 (53511)	Loss/tok 3.1906 (3.3753)	Learning Rate [0.00125]
1: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00091)	Tok/s 82545 (52991)	Loss/tok 3.1080 (3.3810)	Learning Rate [0.00125]
14: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 84110 (54109)	Loss/tok 3.1829 (3.3802)	Learning Rate [0.00125]
2: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 82587 (53088)	Loss/tok 3.3220 (3.3819)	Learning Rate [0.00125]
6: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00100)	Tok/s 83114 (53424)	Loss/tok 3.2657 (3.3837)	Learning Rate [0.00125]
5: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00097)	Tok/s 82476 (53352)	Loss/tok 3.5403 (3.3840)	Learning Rate [0.00125]
4: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 82442 (53253)	Loss/tok 3.2892 (3.3783)	Learning Rate [0.00125]
15: TRAIN [1][1940/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 84496 (54206)	Loss/tok 3.2481 (3.3796)	Learning Rate [0.00125]
9: TRAIN [1][1950/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00093)	Tok/s 34188 (53647)	Loss/tok 2.9524 (3.3856)	Learning Rate [0.00125]
11: TRAIN [1][1950/3416]	Time 0.053 (0.058)	Data 0.00110 (0.00097)	Tok/s 34067 (53807)	Loss/tok 3.0718 (3.3807)	Learning Rate [0.00125]
8: TRAIN [1][1950/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 34152 (53580)	Loss/tok 3.0402 (3.3775)	Learning Rate [0.00125]
10: TRAIN [1][1950/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00097)	Tok/s 34072 (53728)	Loss/tok 3.1149 (3.3797)	Learning Rate [0.00125]
6: TRAIN [1][1950/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00100)	Tok/s 34169 (53420)	Loss/tok 3.0031 (3.3836)	Learning Rate [0.00125]
7: TRAIN [1][1950/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00093)	Tok/s 34191 (53507)	Loss/tok 3.1443 (3.3753)	Learning Rate [0.00125]
14: TRAIN [1][1950/3416]	Time 0.053 (0.058)	Data 0.00082 (0.00092)	Tok/s 33870 (54104)	Loss/tok 3.3724 (3.3804)	Learning Rate [0.00125]
12: TRAIN [1][1950/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00097)	Tok/s 33924 (53909)	Loss/tok 3.3828 (3.3832)	Learning Rate [0.00125]
5: TRAIN [1][1950/3416]	Time 0.052 (0.058)	Data 0.00113 (0.00097)	Tok/s 34137 (53349)	Loss/tok 3.2742 (3.3838)	Learning Rate [0.00125]
4: TRAIN [1][1950/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00092)	Tok/s 34076 (53250)	Loss/tok 3.1273 (3.3784)	Learning Rate [0.00125]
13: TRAIN [1][1950/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00099)	Tok/s 33859 (54008)	Loss/tok 2.9900 (3.3813)	Learning Rate [0.00125]
3: TRAIN [1][1950/3416]	Time 0.053 (0.058)	Data 0.00110 (0.00098)	Tok/s 33995 (53171)	Loss/tok 2.9676 (3.3801)	Learning Rate [0.00125]
2: TRAIN [1][1950/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00097)	Tok/s 33920 (53085)	Loss/tok 2.7768 (3.3821)	Learning Rate [0.00125]
1: TRAIN [1][1950/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00091)	Tok/s 33897 (52988)	Loss/tok 3.2836 (3.3812)	Learning Rate [0.00125]
0: TRAIN [1][1950/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00092)	Tok/s 33805 (52895)	Loss/tok 3.1802 (3.3857)	Learning Rate [0.00125]
15: TRAIN [1][1950/3416]	Time 0.053 (0.058)	Data 0.00089 (0.00091)	Tok/s 33834 (54200)	Loss/tok 3.0936 (3.3790)	Learning Rate [0.00125]
11: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00097)	Tok/s 62172 (53806)	Loss/tok 3.5282 (3.3806)	Learning Rate [0.00125]
12: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 62198 (53907)	Loss/tok 3.5089 (3.3833)	Learning Rate [0.00125]
10: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 62077 (53727)	Loss/tok 3.6314 (3.3797)	Learning Rate [0.00125]
13: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00099)	Tok/s 62173 (54006)	Loss/tok 3.5606 (3.3813)	Learning Rate [0.00125]
9: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 62096 (53646)	Loss/tok 3.5350 (3.3854)	Learning Rate [0.00125]
14: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 63137 (54102)	Loss/tok 3.5722 (3.3808)	Learning Rate [0.00125]
8: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 62086 (53579)	Loss/tok 3.5098 (3.3777)	Learning Rate [0.00125]
7: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 62117 (53506)	Loss/tok 3.3770 (3.3755)	Learning Rate [0.00125]
1: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 62273 (52989)	Loss/tok 3.4459 (3.3811)	Learning Rate [0.00125]
0: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 62222 (52896)	Loss/tok 3.6016 (3.3859)	Learning Rate [0.00125]
4: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 62192 (53250)	Loss/tok 3.2357 (3.3781)	Learning Rate [0.00125]
5: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00118 (0.00097)	Tok/s 62108 (53348)	Loss/tok 3.6489 (3.3842)	Learning Rate [0.00125]
6: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00100)	Tok/s 62098 (53420)	Loss/tok 3.3397 (3.3836)	Learning Rate [0.00125]
2: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 62219 (53085)	Loss/tok 3.6922 (3.3823)	Learning Rate [0.00125]
3: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00098)	Tok/s 62197 (53171)	Loss/tok 3.4252 (3.3800)	Learning Rate [0.00125]
15: TRAIN [1][1960/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00091)	Tok/s 63189 (54199)	Loss/tok 3.3308 (3.3792)	Learning Rate [0.00125]
2: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00097)	Tok/s 50106 (53063)	Loss/tok 3.2454 (3.3820)	Learning Rate [0.00125]
0: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00092)	Tok/s 50220 (52876)	Loss/tok 3.1538 (3.3858)	Learning Rate [0.00125]
1: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00086 (0.00091)	Tok/s 50130 (52968)	Loss/tok 3.3013 (3.3807)	Learning Rate [0.00125]
4: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00092)	Tok/s 51217 (53229)	Loss/tok 3.2029 (3.3779)	Learning Rate [0.00125]
12: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00097)	Tok/s 51661 (53886)	Loss/tok 3.3496 (3.3832)	Learning Rate [0.00125]
5: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00111 (0.00097)	Tok/s 51428 (53327)	Loss/tok 3.1286 (3.3835)	Learning Rate [0.00125]
15: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00091)	Tok/s 51420 (54177)	Loss/tok 3.2341 (3.3787)	Learning Rate [0.00125]
6: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00100)	Tok/s 51502 (53398)	Loss/tok 3.3607 (3.3833)	Learning Rate [0.00125]
14: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00078 (0.00092)	Tok/s 51407 (54080)	Loss/tok 3.5701 (3.3806)	Learning Rate [0.00125]
7: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00093)	Tok/s 51458 (53484)	Loss/tok 3.2879 (3.3754)	Learning Rate [0.00125]
8: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00097)	Tok/s 51521 (53557)	Loss/tok 3.0240 (3.3778)	Learning Rate [0.00125]
3: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00098)	Tok/s 50071 (53149)	Loss/tok 3.0253 (3.3796)	Learning Rate [0.00125]
13: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00099)	Tok/s 51593 (53984)	Loss/tok 3.0818 (3.3814)	Learning Rate [0.00125]
10: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00097)	Tok/s 51570 (53705)	Loss/tok 3.5489 (3.3799)	Learning Rate [0.00125]
11: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00097)	Tok/s 51629 (53784)	Loss/tok 3.4001 (3.3807)	Learning Rate [0.00125]
9: TRAIN [1][1970/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00093)	Tok/s 51464 (53624)	Loss/tok 3.0659 (3.3847)	Learning Rate [0.00125]
12: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 61207 (53921)	Loss/tok 3.6737 (3.3838)	Learning Rate [0.00125]
11: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 61224 (53820)	Loss/tok 3.4190 (3.3810)	Learning Rate [0.00125]
13: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 61213 (54019)	Loss/tok 3.5970 (3.3814)	Learning Rate [0.00125]
10: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 61184 (53741)	Loss/tok 3.3228 (3.3800)	Learning Rate [0.00125]
14: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 61207 (54115)	Loss/tok 3.4028 (3.3804)	Learning Rate [0.00125]
15: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00091)	Tok/s 61233 (54211)	Loss/tok 3.2353 (3.3792)	Learning Rate [0.00125]
8: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 61204 (53593)	Loss/tok 3.4701 (3.3782)	Learning Rate [0.00125]
0: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 60373 (52914)	Loss/tok 3.7749 (3.3861)	Learning Rate [0.00125]
9: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 61224 (53660)	Loss/tok 3.3100 (3.3851)	Learning Rate [0.00125]
1: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00091)	Tok/s 61213 (53006)	Loss/tok 3.4483 (3.3813)	Learning Rate [0.00125]
7: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 61192 (53521)	Loss/tok 3.4423 (3.3755)	Learning Rate [0.00125]
2: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 61233 (53101)	Loss/tok 3.2346 (3.3822)	Learning Rate [0.00125]
6: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00100)	Tok/s 61221 (53434)	Loss/tok 3.6765 (3.3841)	Learning Rate [0.00125]
4: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 61230 (53266)	Loss/tok 3.4607 (3.3784)	Learning Rate [0.00125]
5: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00120 (0.00097)	Tok/s 61207 (53363)	Loss/tok 3.6154 (3.3840)	Learning Rate [0.00125]
3: TRAIN [1][1980/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00098)	Tok/s 61224 (53187)	Loss/tok 3.4584 (3.3801)	Learning Rate [0.00125]
2: TRAIN [1][1990/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 73753 (53115)	Loss/tok 3.4202 (3.3818)	Learning Rate [0.00125]
1: TRAIN [1][1990/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 73676 (53020)	Loss/tok 3.4879 (3.3809)	Learning Rate [0.00125]
3: TRAIN [1][1990/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 73820 (53201)	Loss/tok 3.2411 (3.3803)	Learning Rate [0.00125]
0: TRAIN [1][1990/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 73567 (52927)	Loss/tok 3.3862 (3.3861)	Learning Rate [0.00125]
4: TRAIN [1][1990/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 73902 (53280)	Loss/tok 3.3899 (3.3781)	Learning Rate [0.00125]
5: TRAIN [1][1990/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 73806 (53377)	Loss/tok 3.5661 (3.3840)	Learning Rate [0.00125]
14: TRAIN [1][1990/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00092)	Tok/s 74175 (54128)	Loss/tok 3.2615 (3.3801)	Learning Rate [0.00125]
15: TRAIN [1][1990/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00091)	Tok/s 74414 (54225)	Loss/tok 3.3316 (3.3792)	Learning Rate [0.00125]
13: TRAIN [1][1990/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 74271 (54031)	Loss/tok 3.6705 (3.3822)	Learning Rate [0.00125]
6: TRAIN [1][1990/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 73737 (53447)	Loss/tok 3.2936 (3.3842)	Learning Rate [0.00125]
12: TRAIN [1][1990/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 74277 (53933)	Loss/tok 3.1276 (3.3839)	Learning Rate [0.00125]
7: TRAIN [1][1990/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 73835 (53534)	Loss/tok 3.3823 (3.3756)	Learning Rate [0.00125]
11: TRAIN [1][1990/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 74286 (53832)	Loss/tok 3.3947 (3.3810)	Learning Rate [0.00125]
8: TRAIN [1][1990/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 74446 (53607)	Loss/tok 3.7193 (3.3783)	Learning Rate [0.00125]
10: TRAIN [1][1990/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 74160 (53754)	Loss/tok 3.6237 (3.3798)	Learning Rate [0.00125]
9: TRAIN [1][1990/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 74280 (53674)	Loss/tok 3.4285 (3.3851)	Learning Rate [0.00125]
5: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 61223 (53359)	Loss/tok 3.2767 (3.3833)	Learning Rate [0.00125]
4: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 61157 (53263)	Loss/tok 3.5212 (3.3776)	Learning Rate [0.00125]
6: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 61234 (53430)	Loss/tok 3.3131 (3.3837)	Learning Rate [0.00125]
7: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00093)	Tok/s 61252 (53517)	Loss/tok 3.5671 (3.3754)	Learning Rate [0.00125]
3: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 61019 (53184)	Loss/tok 3.3717 (3.3799)	Learning Rate [0.00125]
1: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00091)	Tok/s 61039 (53004)	Loss/tok 3.5251 (3.3807)	Learning Rate [0.00125]
0: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 61094 (52912)	Loss/tok 3.7412 (3.3859)	Learning Rate [0.00125]
9: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 61251 (53656)	Loss/tok 3.6169 (3.3848)	Learning Rate [0.00125]
8: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 61219 (53590)	Loss/tok 3.7169 (3.3784)	Learning Rate [0.00125]
2: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 60948 (53099)	Loss/tok 3.5182 (3.3819)	Learning Rate [0.00125]
15: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00091)	Tok/s 61992 (54206)	Loss/tok 3.3828 (3.3788)	Learning Rate [0.00125]
10: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 61236 (53736)	Loss/tok 3.3164 (3.3795)	Learning Rate [0.00125]
11: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 61217 (53815)	Loss/tok 3.6491 (3.3808)	Learning Rate [0.00125]
14: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00092)	Tok/s 61984 (54109)	Loss/tok 3.2239 (3.3798)	Learning Rate [0.00125]
12: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 61089 (53914)	Loss/tok 3.3832 (3.3836)	Learning Rate [0.00125]
13: TRAIN [1][2000/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00099)	Tok/s 61549 (54012)	Loss/tok 3.6322 (3.3823)	Learning Rate [0.00125]
1: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00091)	Tok/s 50455 (52968)	Loss/tok 3.4656 (3.3805)	Learning Rate [0.00125]
0: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00092)	Tok/s 49482 (52874)	Loss/tok 3.1972 (3.3852)	Learning Rate [0.00125]
2: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00097)	Tok/s 50751 (53063)	Loss/tok 3.1135 (3.3812)	Learning Rate [0.00125]
15: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00091)	Tok/s 50860 (54168)	Loss/tok 3.2660 (3.3785)	Learning Rate [0.00125]
3: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00098)	Tok/s 50629 (53148)	Loss/tok 3.3591 (3.3794)	Learning Rate [0.00125]
14: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00078 (0.00092)	Tok/s 50776 (54072)	Loss/tok 3.2675 (3.3793)	Learning Rate [0.00125]
4: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 50471 (53226)	Loss/tok 3.0071 (3.3773)	Learning Rate [0.00125]
13: TRAIN [1][2010/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00099)	Tok/s 50972 (53975)	Loss/tok 3.3843 (3.3819)	Learning Rate [0.00125]
5: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00115 (0.00097)	Tok/s 50332 (53322)	Loss/tok 3.4837 (3.3826)	Learning Rate [0.00125]
12: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00096)	Tok/s 50691 (53877)	Loss/tok 3.0812 (3.3830)	Learning Rate [0.00125]
11: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00097)	Tok/s 50698 (53777)	Loss/tok 3.6184 (3.3804)	Learning Rate [0.00125]
10: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00097)	Tok/s 50477 (53699)	Loss/tok 3.1231 (3.3791)	Learning Rate [0.00125]
6: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00100)	Tok/s 50224 (53392)	Loss/tok 3.4580 (3.3832)	Learning Rate [0.00125]
7: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00082 (0.00093)	Tok/s 50243 (53479)	Loss/tok 3.0864 (3.3748)	Learning Rate [0.00125]
9: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00081 (0.00093)	Tok/s 50339 (53618)	Loss/tok 3.3686 (3.3843)	Learning Rate [0.00125]
8: TRAIN [1][2010/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00097)	Tok/s 50260 (53551)	Loss/tok 3.3780 (3.3781)	Learning Rate [0.00125]
1: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00091)	Tok/s 42744 (52978)	Loss/tok 3.4446 (3.3808)	Learning Rate [0.00125]
0: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00092)	Tok/s 42744 (52885)	Loss/tok 3.2968 (3.3856)	Learning Rate [0.00125]
3: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00098)	Tok/s 42697 (53158)	Loss/tok 3.0027 (3.3796)	Learning Rate [0.00125]
4: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00092)	Tok/s 42724 (53236)	Loss/tok 3.0050 (3.3774)	Learning Rate [0.00125]
15: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00091)	Tok/s 42734 (54176)	Loss/tok 3.2791 (3.3783)	Learning Rate [0.00125]
5: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00097)	Tok/s 42719 (53332)	Loss/tok 3.2640 (3.3832)	Learning Rate [0.00125]
14: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00092)	Tok/s 42722 (54080)	Loss/tok 3.1786 (3.3795)	Learning Rate [0.00125]
13: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00099)	Tok/s 42759 (53983)	Loss/tok 3.0343 (3.3826)	Learning Rate [0.00125]
6: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00100)	Tok/s 42712 (53401)	Loss/tok 3.0718 (3.3835)	Learning Rate [0.00125]
7: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00093)	Tok/s 42749 (53487)	Loss/tok 3.0706 (3.3751)	Learning Rate [0.00125]
12: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00096)	Tok/s 42730 (53886)	Loss/tok 3.4060 (3.3832)	Learning Rate [0.00125]
9: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00093)	Tok/s 42737 (53627)	Loss/tok 3.1991 (3.3845)	Learning Rate [0.00125]
11: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00097)	Tok/s 42729 (53786)	Loss/tok 3.1349 (3.3805)	Learning Rate [0.00125]
10: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00097)	Tok/s 42702 (53707)	Loss/tok 3.0560 (3.3791)	Learning Rate [0.00125]
2: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00119 (0.00097)	Tok/s 42712 (53073)	Loss/tok 3.2067 (3.3814)	Learning Rate [0.00125]
8: TRAIN [1][2020/3416]	Time 0.048 (0.058)	Data 0.00113 (0.00097)	Tok/s 42733 (53560)	Loss/tok 3.0658 (3.3784)	Learning Rate [0.00125]
2: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00097)	Tok/s 56154 (53085)	Loss/tok 3.5364 (3.3814)	Learning Rate [0.00125]
1: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00092 (0.00091)	Tok/s 56182 (52989)	Loss/tok 3.4907 (3.3808)	Learning Rate [0.00125]
0: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00092)	Tok/s 56152 (52897)	Loss/tok 3.4735 (3.3856)	Learning Rate [0.00125]
3: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00096 (0.00098)	Tok/s 56059 (53170)	Loss/tok 3.5449 (3.3794)	Learning Rate [0.00125]
4: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00092)	Tok/s 56050 (53248)	Loss/tok 3.2473 (3.3768)	Learning Rate [0.00125]
15: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00091)	Tok/s 57167 (54188)	Loss/tok 3.6547 (3.3782)	Learning Rate [0.00125]
5: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00111 (0.00098)	Tok/s 56053 (53343)	Loss/tok 3.2986 (3.3828)	Learning Rate [0.00125]
14: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00092)	Tok/s 57163 (54091)	Loss/tok 3.6345 (3.3793)	Learning Rate [0.00125]
13: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00102 (0.00099)	Tok/s 57137 (53995)	Loss/tok 3.3360 (3.3826)	Learning Rate [0.00125]
6: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00100)	Tok/s 56045 (53412)	Loss/tok 3.6003 (3.3834)	Learning Rate [0.00125]
12: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00096)	Tok/s 57133 (53897)	Loss/tok 3.5918 (3.3832)	Learning Rate [0.00125]
7: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00093)	Tok/s 56063 (53498)	Loss/tok 3.2561 (3.3750)	Learning Rate [0.00125]
8: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00109 (0.00097)	Tok/s 56092 (53571)	Loss/tok 3.5114 (3.3783)	Learning Rate [0.00125]
9: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00098 (0.00093)	Tok/s 56862 (53638)	Loss/tok 3.5890 (3.3844)	Learning Rate [0.00125]
10: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00097)	Tok/s 57097 (53718)	Loss/tok 3.4142 (3.3792)	Learning Rate [0.00125]
11: TRAIN [1][2030/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00097)	Tok/s 57253 (53797)	Loss/tok 3.3013 (3.3803)	Learning Rate [0.00125]
12: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00096)	Tok/s 52357 (53879)	Loss/tok 3.4327 (3.3828)	Learning Rate [0.00125]
13: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00091 (0.00099)	Tok/s 52305 (53977)	Loss/tok 3.3820 (3.3823)	Learning Rate [0.00125]
14: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00083 (0.00092)	Tok/s 52353 (54072)	Loss/tok 3.3640 (3.3790)	Learning Rate [0.00125]
11: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00097)	Tok/s 52378 (53779)	Loss/tok 3.1566 (3.3800)	Learning Rate [0.00125]
10: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00097)	Tok/s 52381 (53700)	Loss/tok 3.3142 (3.3790)	Learning Rate [0.00125]
0: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00092)	Tok/s 52369 (52880)	Loss/tok 3.2919 (3.3856)	Learning Rate [0.00125]
2: TRAIN [1][2040/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00097)	Tok/s 52478 (53067)	Loss/tok 3.4849 (3.3812)	Learning Rate [0.00125]
15: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00082 (0.00091)	Tok/s 52323 (54168)	Loss/tok 3.3063 (3.3779)	Learning Rate [0.00125]
8: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00097)	Tok/s 52404 (53552)	Loss/tok 3.5391 (3.3778)	Learning Rate [0.00125]
1: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00091)	Tok/s 52377 (52972)	Loss/tok 3.0970 (3.3806)	Learning Rate [0.00125]
9: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00078 (0.00093)	Tok/s 52366 (53620)	Loss/tok 3.1669 (3.3843)	Learning Rate [0.00125]
4: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00086 (0.00092)	Tok/s 52392 (53230)	Loss/tok 3.4349 (3.3764)	Learning Rate [0.00125]
6: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00100)	Tok/s 52400 (53395)	Loss/tok 3.0454 (3.3830)	Learning Rate [0.00125]
5: TRAIN [1][2040/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00098)	Tok/s 52509 (53326)	Loss/tok 3.3467 (3.3826)	Learning Rate [0.00125]
3: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00098)	Tok/s 52371 (53152)	Loss/tok 3.4989 (3.3790)	Learning Rate [0.00125]
7: TRAIN [1][2040/3416]	Time 0.053 (0.058)	Data 0.00081 (0.00092)	Tok/s 52269 (53480)	Loss/tok 3.1347 (3.3748)	Learning Rate [0.00125]
2: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 61252 (53105)	Loss/tok 3.5340 (3.3809)	Learning Rate [0.00125]
4: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00092)	Tok/s 61094 (53267)	Loss/tok 3.3451 (3.3764)	Learning Rate [0.00125]
3: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00098)	Tok/s 61187 (53189)	Loss/tok 3.4744 (3.3787)	Learning Rate [0.00125]
5: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00119 (0.00098)	Tok/s 60911 (53363)	Loss/tok 3.6058 (3.3823)	Learning Rate [0.00125]
1: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00091)	Tok/s 61200 (53009)	Loss/tok 3.5823 (3.3807)	Learning Rate [0.00125]
0: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00092)	Tok/s 61206 (52918)	Loss/tok 3.8509 (3.3854)	Learning Rate [0.00125]
15: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00091)	Tok/s 62140 (54205)	Loss/tok 3.5551 (3.3778)	Learning Rate [0.00125]
14: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 62031 (54109)	Loss/tok 3.5660 (3.3792)	Learning Rate [0.00125]
6: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00100)	Tok/s 60876 (53432)	Loss/tok 3.3297 (3.3826)	Learning Rate [0.00125]
7: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 60880 (53516)	Loss/tok 3.3713 (3.3747)	Learning Rate [0.00125]
8: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 60918 (53588)	Loss/tok 3.3625 (3.3774)	Learning Rate [0.00125]
9: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 60926 (53656)	Loss/tok 3.6936 (3.3844)	Learning Rate [0.00125]
13: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 61719 (54013)	Loss/tok 3.5707 (3.3820)	Learning Rate [0.00125]
12: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00096)	Tok/s 61056 (53916)	Loss/tok 3.4485 (3.3828)	Learning Rate [0.00125]
10: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 60925 (53736)	Loss/tok 3.5647 (3.3788)	Learning Rate [0.00125]
11: TRAIN [1][2050/3416]	Time 0.069 (0.058)	Data 0.00114 (0.00097)	Tok/s 60895 (53815)	Loss/tok 3.4458 (3.3798)	Learning Rate [0.00125]
7: TRAIN [1][2060/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00092)	Tok/s 32403 (53496)	Loss/tok 3.0574 (3.3748)	Learning Rate [0.00125]
9: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00093)	Tok/s 33630 (53635)	Loss/tok 2.9154 (3.3842)	Learning Rate [0.00125]
8: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00097)	Tok/s 33097 (53568)	Loss/tok 2.9645 (3.3773)	Learning Rate [0.00125]
5: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00098)	Tok/s 32280 (53342)	Loss/tok 3.0632 (3.3820)	Learning Rate [0.00125]
6: TRAIN [1][2060/3416]	Time 0.047 (0.058)	Data 0.00099 (0.00100)	Tok/s 32352 (53410)	Loss/tok 3.0175 (3.3828)	Learning Rate [0.00125]
4: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00092)	Tok/s 32181 (53247)	Loss/tok 2.7879 (3.3761)	Learning Rate [0.00125]
2: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00097)	Tok/s 32077 (53084)	Loss/tok 2.8470 (3.3809)	Learning Rate [0.00125]
3: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00098)	Tok/s 32104 (53168)	Loss/tok 2.9191 (3.3785)	Learning Rate [0.00125]
11: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00097)	Tok/s 33401 (53794)	Loss/tok 3.0904 (3.3794)	Learning Rate [0.00125]
10: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00097)	Tok/s 33470 (53715)	Loss/tok 2.7974 (3.3787)	Learning Rate [0.00125]
12: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00096)	Tok/s 33310 (53894)	Loss/tok 3.0412 (3.3824)	Learning Rate [0.00125]
0: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 31853 (52897)	Loss/tok 2.7743 (3.3851)	Learning Rate [0.00125]
1: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00100 (0.00091)	Tok/s 31923 (52989)	Loss/tok 2.9585 (3.3801)	Learning Rate [0.00125]
14: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00080 (0.00092)	Tok/s 33185 (54087)	Loss/tok 2.8004 (3.3790)	Learning Rate [0.00125]
13: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00099)	Tok/s 33213 (53991)	Loss/tok 2.9587 (3.3821)	Learning Rate [0.00125]
15: TRAIN [1][2060/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00091)	Tok/s 33094 (54184)	Loss/tok 3.0141 (3.3778)	Learning Rate [0.00125]
0: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
6: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
5: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00098)	Tok/s 67093 (53351)	Loss/tok 3.5286 (3.3822)	Learning Rate [0.00125]
6: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00100)	Tok/s 66939 (53419)	Loss/tok 3.2704 (3.3828)	Learning Rate [0.00125]
7: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00092)	Tok/s 66972 (53504)	Loss/tok 3.5154 (3.3752)	Learning Rate [0.00125]
2: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 67080 (53092)	Loss/tok 3.2551 (3.3806)	Learning Rate [0.00125]
3: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 67143 (53176)	Loss/tok 3.2729 (3.3785)	Learning Rate [0.00125]
8: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00097)	Tok/s 66978 (53576)	Loss/tok 3.2018 (3.3771)	Learning Rate [0.00125]
4: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 67086 (53255)	Loss/tok 3.4588 (3.3763)	Learning Rate [0.00125]
10: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 66920 (53723)	Loss/tok 3.6209 (3.3789)	Learning Rate [0.00125]
1: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00091)	Tok/s 67181 (52997)	Loss/tok 3.4863 (3.3802)	Learning Rate [0.00125]
0: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 67172 (52906)	Loss/tok 3.4807 (3.3853)	Learning Rate [0.00125]
9: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00093)	Tok/s 66965 (53643)	Loss/tok 3.5641 (3.3840)	Learning Rate [0.00125]
15: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 68080 (54194)	Loss/tok 3.2719 (3.3776)	Learning Rate [0.00125]
11: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00097)	Tok/s 67507 (53803)	Loss/tok 3.4418 (3.3793)	Learning Rate [0.00125]
14: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 68043 (54098)	Loss/tok 3.5978 (3.3788)	Learning Rate [0.00125]
12: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00096)	Tok/s 67920 (53903)	Loss/tok 3.5344 (3.3826)	Learning Rate [0.00125]
13: TRAIN [1][2070/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00099)	Tok/s 67969 (54001)	Loss/tok 3.6550 (3.3821)	Learning Rate [0.00125]
10: TRAIN [1][2080/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00097)	Tok/s 53703 (53736)	Loss/tok 3.2023 (3.3787)	Learning Rate [0.00125]
11: TRAIN [1][2080/3416]	Time 0.065 (0.058)	Data 0.00111 (0.00097)	Tok/s 53757 (53816)	Loss/tok 3.8102 (3.3796)	Learning Rate [0.00125]
9: TRAIN [1][2080/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00093)	Tok/s 53714 (53656)	Loss/tok 3.4961 (3.3845)	Learning Rate [0.00125]
12: TRAIN [1][2080/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00096)	Tok/s 53691 (53916)	Loss/tok 3.4133 (3.3827)	Learning Rate [0.00125]
8: TRAIN [1][2080/3416]	Time 0.066 (0.058)	Data 0.00107 (0.00097)	Tok/s 53703 (53590)	Loss/tok 3.2521 (3.3773)	Learning Rate [0.00125]
7: TRAIN [1][2080/3416]	Time 0.066 (0.058)	Data 0.00083 (0.00092)	Tok/s 53706 (53517)	Loss/tok 3.3196 (3.3749)	Learning Rate [0.00125]
13: TRAIN [1][2080/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00099)	Tok/s 53723 (54013)	Loss/tok 3.2124 (3.3819)	Learning Rate [0.00125]
15: TRAIN [1][2080/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00091)	Tok/s 53763 (54206)	Loss/tok 3.2462 (3.3778)	Learning Rate [0.00125]
14: TRAIN [1][2080/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00092)	Tok/s 53699 (54110)	Loss/tok 3.5068 (3.3786)	Learning Rate [0.00125]
5: TRAIN [1][2080/3416]	Time 0.066 (0.058)	Data 0.00115 (0.00098)	Tok/s 53736 (53365)	Loss/tok 3.4716 (3.3824)	Learning Rate [0.00125]
6: TRAIN [1][2080/3416]	Time 0.066 (0.058)	Data 0.00109 (0.00100)	Tok/s 53721 (53432)	Loss/tok 3.6908 (3.3828)	Learning Rate [0.00125]
4: TRAIN [1][2080/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00092)	Tok/s 53722 (53269)	Loss/tok 3.5689 (3.3762)	Learning Rate [0.00125]
0: TRAIN [1][2080/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00092)	Tok/s 53239 (52920)	Loss/tok 3.5874 (3.3852)	Learning Rate [0.00125]
2: TRAIN [1][2080/3416]	Time 0.065 (0.058)	Data 0.00099 (0.00097)	Tok/s 53774 (53106)	Loss/tok 3.6367 (3.3807)	Learning Rate [0.00125]
1: TRAIN [1][2080/3416]	Time 0.066 (0.058)	Data 0.00105 (0.00091)	Tok/s 53736 (53011)	Loss/tok 3.3736 (3.3805)	Learning Rate [0.00125]
3: TRAIN [1][2080/3416]	Time 0.066 (0.058)	Data 0.00106 (0.00098)	Tok/s 53708 (53189)	Loss/tok 3.5959 (3.3787)	Learning Rate [0.00125]
11: TRAIN [1][2090/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00097)	Tok/s 45568 (53815)	Loss/tok 3.0423 (3.3792)	Learning Rate [0.00125]
10: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00097)	Tok/s 45379 (53735)	Loss/tok 3.0030 (3.3784)	Learning Rate [0.00125]
12: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00096)	Tok/s 45316 (53915)	Loss/tok 3.0882 (3.3824)	Learning Rate [0.00125]
13: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00099)	Tok/s 45198 (54012)	Loss/tok 3.1333 (3.3818)	Learning Rate [0.00125]
8: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00097)	Tok/s 45172 (53589)	Loss/tok 3.0365 (3.3772)	Learning Rate [0.00125]
9: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00079 (0.00093)	Tok/s 45249 (53655)	Loss/tok 3.2008 (3.3842)	Learning Rate [0.00125]
14: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00092)	Tok/s 45135 (54110)	Loss/tok 3.2140 (3.3783)	Learning Rate [0.00125]
15: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00083 (0.00091)	Tok/s 45029 (54206)	Loss/tok 3.2959 (3.3778)	Learning Rate [0.00125]
7: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00083 (0.00092)	Tok/s 45019 (53517)	Loss/tok 3.2830 (3.3747)	Learning Rate [0.00125]
0: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00092)	Tok/s 43493 (52920)	Loss/tok 3.2070 (3.3848)	Learning Rate [0.00125]
6: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00100)	Tok/s 44949 (53432)	Loss/tok 2.9791 (3.3824)	Learning Rate [0.00125]
5: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00098)	Tok/s 44844 (53364)	Loss/tok 2.9607 (3.3825)	Learning Rate [0.00125]
4: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00092)	Tok/s 44524 (53268)	Loss/tok 3.0795 (3.3761)	Learning Rate [0.00125]
2: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00097)	Tok/s 43332 (53105)	Loss/tok 3.2914 (3.3806)	Learning Rate [0.00125]
3: TRAIN [1][2090/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00098)	Tok/s 43276 (53188)	Loss/tok 2.9298 (3.3783)	Learning Rate [0.00125]
1: TRAIN [1][2090/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00091)	Tok/s 42277 (53010)	Loss/tok 3.1804 (3.3804)	Learning Rate [0.00125]
12: Gradient norm: inf
11: Gradient norm: inf
13: Gradient norm: inf
12: Skipped batch, new scale: 2048.0
11: Skipped batch, new scale: 2048.0
13: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
14: Gradient norm: inf
10: Skipped batch, new scale: 2048.0
15: Gradient norm: inf
9: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
15: Skipped batch, new scale: 2048.0
8: Gradient norm: inf
0: Gradient norm: inf
7: Gradient norm: inf
8: Skipped batch, new scale: 2048.0
1: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
7: Skipped batch, new scale: 2048.0
6: Gradient norm: inf
2: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
4: Gradient norm: inf
6: Skipped batch, new scale: 2048.0
3: Gradient norm: inf
2: Skipped batch, new scale: 2048.0
5: Gradient norm: inf
4: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
13: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00096 (0.00099)	Tok/s 53843 (54011)	Loss/tok 3.3252 (3.3816)	Learning Rate [0.00125]
12: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00096)	Tok/s 53774 (53914)	Loss/tok 3.4375 (3.3820)	Learning Rate [0.00125]
14: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00083 (0.00092)	Tok/s 53855 (54109)	Loss/tok 3.1578 (3.3777)	Learning Rate [0.00125]
11: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00108 (0.00097)	Tok/s 53736 (53814)	Loss/tok 3.3893 (3.3789)	Learning Rate [0.00125]
15: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00091)	Tok/s 53836 (54205)	Loss/tok 3.3650 (3.3775)	Learning Rate [0.00125]
10: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00097)	Tok/s 53757 (53734)	Loss/tok 3.4379 (3.3780)	Learning Rate [0.00125]
0: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00092)	Tok/s 53833 (52920)	Loss/tok 3.5919 (3.3845)	Learning Rate [0.00125]
9: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00093)	Tok/s 53728 (53655)	Loss/tok 3.2002 (3.3837)	Learning Rate [0.00125]
1: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00091)	Tok/s 53830 (53011)	Loss/tok 3.4933 (3.3803)	Learning Rate [0.00125]
8: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00094 (0.00097)	Tok/s 53746 (53588)	Loss/tok 3.2407 (3.3769)	Learning Rate [0.00125]
2: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00088 (0.00097)	Tok/s 53837 (53105)	Loss/tok 3.5043 (3.3803)	Learning Rate [0.00125]
7: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00082 (0.00092)	Tok/s 53741 (53516)	Loss/tok 3.5268 (3.3744)	Learning Rate [0.00125]
4: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00084 (0.00092)	Tok/s 53768 (53268)	Loss/tok 3.1740 (3.3760)	Learning Rate [0.00125]
6: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00100)	Tok/s 53692 (53432)	Loss/tok 3.5017 (3.3822)	Learning Rate [0.00125]
5: TRAIN [1][2100/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00098)	Tok/s 53465 (53363)	Loss/tok 3.3767 (3.3823)	Learning Rate [0.00125]
3: TRAIN [1][2100/3416]	Time 0.059 (0.058)	Data 0.00116 (0.00098)	Tok/s 51314 (53187)	Loss/tok 3.2358 (3.3783)	Learning Rate [0.00125]
8: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00097)	Tok/s 33281 (53554)	Loss/tok 2.9844 (3.3764)	Learning Rate [0.00125]
7: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00092)	Tok/s 33348 (53481)	Loss/tok 3.0244 (3.3742)	Learning Rate [0.00125]
6: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00100)	Tok/s 33350 (53397)	Loss/tok 2.9938 (3.3818)	Learning Rate [0.00125]
5: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00098)	Tok/s 33345 (53329)	Loss/tok 2.9459 (3.3819)	Learning Rate [0.00125]
9: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00093)	Tok/s 33201 (53620)	Loss/tok 3.1786 (3.3833)	Learning Rate [0.00125]
4: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00092)	Tok/s 33298 (53234)	Loss/tok 3.6473 (3.3760)	Learning Rate [0.00125]
3: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00098)	Tok/s 33270 (53154)	Loss/tok 3.2900 (3.3780)	Learning Rate [0.00125]
10: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00097)	Tok/s 33122 (53699)	Loss/tok 3.2431 (3.3776)	Learning Rate [0.00125]
11: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00097)	Tok/s 33044 (53779)	Loss/tok 3.2589 (3.3786)	Learning Rate [0.00125]
2: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00097)	Tok/s 33138 (53070)	Loss/tok 2.8748 (3.3799)	Learning Rate [0.00125]
12: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00096)	Tok/s 32989 (53878)	Loss/tok 2.9327 (3.3816)	Learning Rate [0.00125]
0: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 33026 (52886)	Loss/tok 2.8998 (3.3842)	Learning Rate [0.00125]
13: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00099)	Tok/s 32930 (53975)	Loss/tok 2.9323 (3.3809)	Learning Rate [0.00125]
15: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00091)	Tok/s 34181 (54170)	Loss/tok 3.1231 (3.3772)	Learning Rate [0.00125]
14: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 33337 (54073)	Loss/tok 2.6674 (3.3774)	Learning Rate [0.00125]
1: TRAIN [1][2110/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00091)	Tok/s 33111 (52976)	Loss/tok 3.1877 (3.3800)	Learning Rate [0.00125]
4: TRAIN [1][2120/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00091)	Tok/s 59163 (53186)	Loss/tok 3.6641 (3.3758)	Learning Rate [0.00125]
3: TRAIN [1][2120/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 59175 (53104)	Loss/tok 3.4419 (3.3777)	Learning Rate [0.00125]
2: TRAIN [1][2120/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 59129 (53019)	Loss/tok 3.7521 (3.3799)	Learning Rate [0.00125]
5: TRAIN [1][2120/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 59044 (53282)	Loss/tok 3.3986 (3.3815)	Learning Rate [0.00125]
7: TRAIN [1][2120/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 58892 (53436)	Loss/tok 3.4957 (3.3741)	Learning Rate [0.00125]
6: TRAIN [1][2120/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00100)	Tok/s 58977 (53351)	Loss/tok 3.2784 (3.3815)	Learning Rate [0.00125]
0: TRAIN [1][2120/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 59177 (52829)	Loss/tok 3.5035 (3.3837)	Learning Rate [0.00125]
8: TRAIN [1][2120/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 58900 (53510)	Loss/tok 3.3614 (3.3758)	Learning Rate [0.00125]
15: TRAIN [1][2120/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 59697 (54129)	Loss/tok 3.6831 (3.3769)	Learning Rate [0.00125]
9: TRAIN [1][2120/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00093)	Tok/s 58924 (53576)	Loss/tok 3.6501 (3.3829)	Learning Rate [0.00125]
14: TRAIN [1][2120/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 59113 (54031)	Loss/tok 3.3981 (3.3770)	Learning Rate [0.00125]
13: TRAIN [1][2120/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00099)	Tok/s 59048 (53933)	Loss/tok 3.6128 (3.3806)	Learning Rate [0.00125]
10: TRAIN [1][2120/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00097)	Tok/s 58829 (53655)	Loss/tok 3.2781 (3.3772)	Learning Rate [0.00125]
11: TRAIN [1][2120/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00097)	Tok/s 58985 (53734)	Loss/tok 3.5780 (3.3783)	Learning Rate [0.00125]
12: TRAIN [1][2120/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00096)	Tok/s 58916 (53835)	Loss/tok 3.3857 (3.3814)	Learning Rate [0.00125]
1: TRAIN [1][2120/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 59242 (52922)	Loss/tok 3.4198 (3.3794)	Learning Rate [0.00125]
11: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00097)	Tok/s 53086 (53734)	Loss/tok 3.3650 (3.3786)	Learning Rate [0.00125]
12: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00096)	Tok/s 52999 (53835)	Loss/tok 3.3481 (3.3810)	Learning Rate [0.00125]
10: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00097)	Tok/s 53090 (53654)	Loss/tok 3.4974 (3.3772)	Learning Rate [0.00125]
9: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00084 (0.00093)	Tok/s 53107 (53575)	Loss/tok 3.2558 (3.3830)	Learning Rate [0.00125]
13: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00099)	Tok/s 52939 (53933)	Loss/tok 3.3879 (3.3807)	Learning Rate [0.00125]
8: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00097)	Tok/s 53092 (53509)	Loss/tok 3.3811 (3.3754)	Learning Rate [0.00125]
14: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00092)	Tok/s 52971 (54030)	Loss/tok 3.3689 (3.3766)	Learning Rate [0.00125]
7: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00092)	Tok/s 53057 (53435)	Loss/tok 3.4786 (3.3738)	Learning Rate [0.00125]
15: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00084 (0.00091)	Tok/s 52940 (54128)	Loss/tok 3.2493 (3.3771)	Learning Rate [0.00125]
0: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00077 (0.00092)	Tok/s 51836 (52828)	Loss/tok 3.4121 (3.3839)	Learning Rate [0.00125]
6: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00092 (0.00100)	Tok/s 53057 (53351)	Loss/tok 3.3166 (3.3812)	Learning Rate [0.00125]
5: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00088 (0.00098)	Tok/s 53038 (53282)	Loss/tok 3.6827 (3.3812)	Learning Rate [0.00125]
4: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00085 (0.00091)	Tok/s 53041 (53186)	Loss/tok 3.3426 (3.3761)	Learning Rate [0.00125]
2: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00090 (0.00097)	Tok/s 52973 (53018)	Loss/tok 3.3022 (3.3798)	Learning Rate [0.00125]
3: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00098)	Tok/s 53000 (53104)	Loss/tok 3.8157 (3.3777)	Learning Rate [0.00125]
1: TRAIN [1][2130/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00091)	Tok/s 52050 (52921)	Loss/tok 3.4769 (3.3790)	Learning Rate [0.00125]
7: TRAIN [1][2140/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00092)	Tok/s 32567 (53415)	Loss/tok 2.7692 (3.3735)	Learning Rate [0.00125]
8: TRAIN [1][2140/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00097)	Tok/s 32520 (53488)	Loss/tok 2.7101 (3.3745)	Learning Rate [0.00125]
6: TRAIN [1][2140/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00100)	Tok/s 32507 (53329)	Loss/tok 2.9411 (3.3806)	Learning Rate [0.00125]
9: TRAIN [1][2140/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00093)	Tok/s 32464 (53554)	Loss/tok 2.9328 (3.3825)	Learning Rate [0.00125]
4: TRAIN [1][2140/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00092)	Tok/s 32405 (53164)	Loss/tok 3.0089 (3.3756)	Learning Rate [0.00125]
10: TRAIN [1][2140/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00097)	Tok/s 32432 (53634)	Loss/tok 2.8735 (3.3771)	Learning Rate [0.00125]
11: TRAIN [1][2140/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00097)	Tok/s 33648 (53716)	Loss/tok 2.9521 (3.3780)	Learning Rate [0.00125]
3: TRAIN [1][2140/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00098)	Tok/s 32361 (53081)	Loss/tok 2.9327 (3.3776)	Learning Rate [0.00125]
5: TRAIN [1][2140/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00098)	Tok/s 32435 (53260)	Loss/tok 3.0293 (3.3808)	Learning Rate [0.00125]
2: TRAIN [1][2140/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00097)	Tok/s 32272 (52995)	Loss/tok 2.8828 (3.3796)	Learning Rate [0.00125]
12: TRAIN [1][2140/3416]	Time 0.048 (0.058)	Data 0.00107 (0.00096)	Tok/s 33572 (53817)	Loss/tok 2.9001 (3.3809)	Learning Rate [0.00125]
13: TRAIN [1][2140/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00099)	Tok/s 33537 (53915)	Loss/tok 2.9740 (3.3802)	Learning Rate [0.00125]
1: TRAIN [1][2140/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00091)	Tok/s 32214 (52897)	Loss/tok 2.6994 (3.3790)	Learning Rate [0.00125]
0: TRAIN [1][2140/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00092)	Tok/s 32164 (52803)	Loss/tok 2.8021 (3.3835)	Learning Rate [0.00125]
15: TRAIN [1][2140/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00091)	Tok/s 33412 (54110)	Loss/tok 2.9466 (3.3768)	Learning Rate [0.00125]
14: TRAIN [1][2140/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00092)	Tok/s 33423 (54012)	Loss/tok 2.7010 (3.3765)	Learning Rate [0.00125]
4: TRAIN [1][2150/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00092)	Tok/s 57022 (53161)	Loss/tok 3.3363 (3.3757)	Learning Rate [0.00125]
5: TRAIN [1][2150/3416]	Time 0.063 (0.058)	Data 0.00088 (0.00098)	Tok/s 56966 (53257)	Loss/tok 3.3083 (3.3808)	Learning Rate [0.00125]
2: TRAIN [1][2150/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00097)	Tok/s 56190 (52993)	Loss/tok 3.2274 (3.3796)	Learning Rate [0.00125]
6: TRAIN [1][2150/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00100)	Tok/s 56842 (53325)	Loss/tok 3.3065 (3.3808)	Learning Rate [0.00125]
1: TRAIN [1][2150/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00091)	Tok/s 55648 (52894)	Loss/tok 3.2726 (3.3788)	Learning Rate [0.00125]
10: TRAIN [1][2150/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00097)	Tok/s 56565 (53630)	Loss/tok 3.6048 (3.3774)	Learning Rate [0.00125]
7: TRAIN [1][2150/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00092)	Tok/s 56742 (53410)	Loss/tok 3.3996 (3.3738)	Learning Rate [0.00125]
0: TRAIN [1][2150/3416]	Time 0.063 (0.058)	Data 0.00096 (0.00092)	Tok/s 55547 (52800)	Loss/tok 3.3915 (3.3835)	Learning Rate [0.00125]
8: TRAIN [1][2150/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00097)	Tok/s 56639 (53484)	Loss/tok 3.7361 (3.3748)	Learning Rate [0.00125]
15: TRAIN [1][2150/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00091)	Tok/s 56511 (54104)	Loss/tok 3.4655 (3.3768)	Learning Rate [0.00125]
9: TRAIN [1][2150/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00093)	Tok/s 56580 (53550)	Loss/tok 3.3058 (3.3827)	Learning Rate [0.00125]
13: TRAIN [1][2150/3416]	Time 0.064 (0.058)	Data 0.00109 (0.00099)	Tok/s 56319 (53910)	Loss/tok 3.5315 (3.3804)	Learning Rate [0.00125]
14: TRAIN [1][2150/3416]	Time 0.064 (0.058)	Data 0.00093 (0.00092)	Tok/s 56396 (54007)	Loss/tok 3.3797 (3.3763)	Learning Rate [0.00125]
11: TRAIN [1][2150/3416]	Time 0.064 (0.058)	Data 0.00100 (0.00097)	Tok/s 56411 (53711)	Loss/tok 3.3390 (3.3780)	Learning Rate [0.00125]
12: TRAIN [1][2150/3416]	Time 0.064 (0.058)	Data 0.00104 (0.00096)	Tok/s 56293 (53813)	Loss/tok 3.3766 (3.3810)	Learning Rate [0.00125]
3: TRAIN [1][2150/3416]	Time 0.063 (0.058)	Data 0.00097 (0.00098)	Tok/s 56467 (53078)	Loss/tok 3.4559 (3.3777)	Learning Rate [0.00125]
7: TRAIN [1][2160/3416]	Time 0.042 (0.058)	Data 0.00088 (0.00092)	Tok/s 28706 (53385)	Loss/tok 2.6224 (3.3734)	Learning Rate [0.00125]
9: TRAIN [1][2160/3416]	Time 0.043 (0.058)	Data 0.00085 (0.00093)	Tok/s 28578 (53524)	Loss/tok 2.8321 (3.3827)	Learning Rate [0.00125]
8: TRAIN [1][2160/3416]	Time 0.042 (0.058)	Data 0.00093 (0.00097)	Tok/s 28628 (53458)	Loss/tok 2.5675 (3.3744)	Learning Rate [0.00125]
6: TRAIN [1][2160/3416]	Time 0.042 (0.058)	Data 0.00096 (0.00100)	Tok/s 28721 (53300)	Loss/tok 2.7851 (3.3803)	Learning Rate [0.00125]
4: TRAIN [1][2160/3416]	Time 0.042 (0.058)	Data 0.00094 (0.00092)	Tok/s 27575 (53136)	Loss/tok 2.6416 (3.3753)	Learning Rate [0.00125]
5: TRAIN [1][2160/3416]	Time 0.042 (0.058)	Data 0.00100 (0.00098)	Tok/s 28698 (53232)	Loss/tok 2.7382 (3.3805)	Learning Rate [0.00125]
10: TRAIN [1][2160/3416]	Time 0.043 (0.058)	Data 0.00109 (0.00097)	Tok/s 28460 (53604)	Loss/tok 2.6943 (3.3772)	Learning Rate [0.00125]
1: TRAIN [1][2160/3416]	Time 0.043 (0.058)	Data 0.00089 (0.00091)	Tok/s 27029 (52871)	Loss/tok 2.5477 (3.3784)	Learning Rate [0.00125]
2: TRAIN [1][2160/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00097)	Tok/s 27048 (52968)	Loss/tok 2.5993 (3.3796)	Learning Rate [0.00125]
0: TRAIN [1][2160/3416]	Time 0.043 (0.058)	Data 0.00089 (0.00092)	Tok/s 26971 (52776)	Loss/tok 2.6218 (3.3831)	Learning Rate [0.00125]
15: TRAIN [1][2160/3416]	Time 0.043 (0.058)	Data 0.00086 (0.00091)	Tok/s 29874 (54078)	Loss/tok 2.9012 (3.3766)	Learning Rate [0.00125]
11: TRAIN [1][2160/3416]	Time 0.043 (0.058)	Data 0.00093 (0.00097)	Tok/s 28352 (53685)	Loss/tok 2.7505 (3.3777)	Learning Rate [0.00125]
14: TRAIN [1][2160/3416]	Time 0.043 (0.058)	Data 0.00087 (0.00092)	Tok/s 29831 (53981)	Loss/tok 2.5894 (3.3759)	Learning Rate [0.00125]
12: TRAIN [1][2160/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00096)	Tok/s 28326 (53787)	Loss/tok 2.5793 (3.3805)	Learning Rate [0.00125]
13: TRAIN [1][2160/3416]	Time 0.043 (0.058)	Data 0.00097 (0.00099)	Tok/s 29595 (53885)	Loss/tok 2.9451 (3.3804)	Learning Rate [0.00125]
3: TRAIN [1][2160/3416]	Time 0.043 (0.058)	Data 0.00099 (0.00098)	Tok/s 26781 (53053)	Loss/tok 2.6158 (3.3773)	Learning Rate [0.00125]
10: TRAIN [1][2170/3416]	Time 0.059 (0.058)	Data 0.00102 (0.00097)	Tok/s 54812 (53617)	Loss/tok 3.3898 (3.3766)	Learning Rate [0.00125]
11: TRAIN [1][2170/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00097)	Tok/s 55097 (53698)	Loss/tok 3.4362 (3.3775)	Learning Rate [0.00125]
12: TRAIN [1][2170/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00097)	Tok/s 55003 (53799)	Loss/tok 3.3282 (3.3800)	Learning Rate [0.00125]
9: TRAIN [1][2170/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00093)	Tok/s 54076 (53536)	Loss/tok 3.4807 (3.3828)	Learning Rate [0.00125]
13: TRAIN [1][2170/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00099)	Tok/s 54933 (53897)	Loss/tok 3.5153 (3.3803)	Learning Rate [0.00125]
8: TRAIN [1][2170/3416]	Time 0.059 (0.058)	Data 0.00115 (0.00097)	Tok/s 54126 (53470)	Loss/tok 3.2671 (3.3734)	Learning Rate [0.00125]
15: TRAIN [1][2170/3416]	Time 0.060 (0.058)	Data 0.00083 (0.00091)	Tok/s 54781 (54091)	Loss/tok 3.2334 (3.3761)	Learning Rate [0.00125]
7: TRAIN [1][2170/3416]	Time 0.059 (0.058)	Data 0.00084 (0.00092)	Tok/s 54072 (53397)	Loss/tok 3.5412 (3.3733)	Learning Rate [0.00125]
14: TRAIN [1][2170/3416]	Time 0.060 (0.058)	Data 0.00083 (0.00092)	Tok/s 54823 (53993)	Loss/tok 3.0865 (3.3754)	Learning Rate [0.00125]
0: TRAIN [1][2170/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00092)	Tok/s 53661 (52789)	Loss/tok 3.4096 (3.3827)	Learning Rate [0.00125]
6: TRAIN [1][2170/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00100)	Tok/s 53981 (53312)	Loss/tok 3.1964 (3.3797)	Learning Rate [0.00125]
1: TRAIN [1][2170/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00091)	Tok/s 53672 (52883)	Loss/tok 3.3610 (3.3781)	Learning Rate [0.00125]
2: TRAIN [1][2170/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00097)	Tok/s 53735 (52981)	Loss/tok 3.3867 (3.3793)	Learning Rate [0.00125]
5: TRAIN [1][2170/3416]	Time 0.059 (0.058)	Data 0.00109 (0.00098)	Tok/s 53907 (53244)	Loss/tok 3.3301 (3.3800)	Learning Rate [0.00125]
3: TRAIN [1][2170/3416]	Time 0.060 (0.058)	Data 0.00101 (0.00098)	Tok/s 53718 (53066)	Loss/tok 3.4879 (3.3769)	Learning Rate [0.00125]
4: TRAIN [1][2170/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00092)	Tok/s 53843 (53148)	Loss/tok 3.4220 (3.3751)	Learning Rate [0.00125]
13: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00099)	Tok/s 53278 (53899)	Loss/tok 3.4317 (3.3804)	Learning Rate [0.00125]
12: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00097)	Tok/s 53167 (53801)	Loss/tok 3.4108 (3.3799)	Learning Rate [0.00125]
15: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00081 (0.00091)	Tok/s 53177 (54093)	Loss/tok 3.4943 (3.3760)	Learning Rate [0.00125]
11: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00097)	Tok/s 52973 (53701)	Loss/tok 3.2106 (3.3771)	Learning Rate [0.00125]
14: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00080 (0.00092)	Tok/s 53182 (53996)	Loss/tok 3.2399 (3.3757)	Learning Rate [0.00125]
9: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00093)	Tok/s 52944 (53538)	Loss/tok 3.5215 (3.3826)	Learning Rate [0.00125]
0: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00092)	Tok/s 53154 (52791)	Loss/tok 3.4017 (3.3826)	Learning Rate [0.00125]
1: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00091)	Tok/s 53094 (52885)	Loss/tok 3.4034 (3.3782)	Learning Rate [0.00125]
2: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00097)	Tok/s 53223 (52983)	Loss/tok 3.3016 (3.3791)	Learning Rate [0.00125]
7: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00091 (0.00092)	Tok/s 53016 (53399)	Loss/tok 3.3808 (3.3730)	Learning Rate [0.00125]
5: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00114 (0.00098)	Tok/s 53026 (53246)	Loss/tok 3.3905 (3.3804)	Learning Rate [0.00125]
8: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00109 (0.00097)	Tok/s 53016 (53472)	Loss/tok 3.6177 (3.3735)	Learning Rate [0.00125]
4: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00092)	Tok/s 53037 (53151)	Loss/tok 3.5303 (3.3753)	Learning Rate [0.00125]
3: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00098)	Tok/s 53170 (53068)	Loss/tok 3.3842 (3.3767)	Learning Rate [0.00125]
10: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00097)	Tok/s 53038 (53620)	Loss/tok 3.1837 (3.3764)	Learning Rate [0.00125]
6: TRAIN [1][2180/3416]	Time 0.059 (0.058)	Data 0.00107 (0.00100)	Tok/s 53033 (53314)	Loss/tok 3.4658 (3.3794)	Learning Rate [0.00125]
3: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00124 (0.00098)	Tok/s 54212 (53091)	Loss/tok 3.5688 (3.3771)	Learning Rate [0.00125]
2: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00107 (0.00097)	Tok/s 54251 (53006)	Loss/tok 3.4161 (3.3789)	Learning Rate [0.00125]
4: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00100 (0.00092)	Tok/s 54215 (53174)	Loss/tok 3.4127 (3.3752)	Learning Rate [0.00125]
1: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00097 (0.00091)	Tok/s 54244 (52908)	Loss/tok 3.6131 (3.3781)	Learning Rate [0.00125]
0: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00092)	Tok/s 54194 (52814)	Loss/tok 3.3664 (3.3827)	Learning Rate [0.00125]
5: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00122 (0.00098)	Tok/s 54250 (53269)	Loss/tok 3.4463 (3.3805)	Learning Rate [0.00125]
15: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00091)	Tok/s 54220 (54115)	Loss/tok 3.3802 (3.3760)	Learning Rate [0.00125]
7: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00092)	Tok/s 54215 (53422)	Loss/tok 3.3011 (3.3729)	Learning Rate [0.00125]
6: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00102 (0.00100)	Tok/s 54244 (53337)	Loss/tok 3.4397 (3.3795)	Learning Rate [0.00125]
12: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00105 (0.00097)	Tok/s 54358 (53815)	Loss/tok 3.2579 (3.3800)	Learning Rate [0.00125]
14: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00092)	Tok/s 54198 (54018)	Loss/tok 3.3101 (3.3757)	Learning Rate [0.00125]
8: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00111 (0.00097)	Tok/s 54283 (53495)	Loss/tok 3.1732 (3.3733)	Learning Rate [0.00125]
9: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00106 (0.00093)	Tok/s 54255 (53561)	Loss/tok 3.5807 (3.3826)	Learning Rate [0.00125]
13: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00111 (0.00099)	Tok/s 54215 (53913)	Loss/tok 3.3983 (3.3804)	Learning Rate [0.00125]
10: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00101 (0.00097)	Tok/s 54189 (53642)	Loss/tok 3.2854 (3.3761)	Learning Rate [0.00125]
11: TRAIN [1][2190/3416]	Time 0.061 (0.058)	Data 0.00115 (0.00097)	Tok/s 54189 (53723)	Loss/tok 3.5015 (3.3772)	Learning Rate [0.00125]
4: TRAIN [1][2200/3416]	Time 0.051 (0.058)	Data 0.00113 (0.00092)	Tok/s 32426 (53164)	Loss/tok 2.9091 (3.3752)	Learning Rate [0.00125]
5: TRAIN [1][2200/3416]	Time 0.051 (0.058)	Data 0.00114 (0.00098)	Tok/s 32403 (53259)	Loss/tok 3.0794 (3.3800)	Learning Rate [0.00125]
3: TRAIN [1][2200/3416]	Time 0.051 (0.058)	Data 0.00115 (0.00098)	Tok/s 32393 (53082)	Loss/tok 2.9372 (3.3774)	Learning Rate [0.00125]
7: TRAIN [1][2200/3416]	Time 0.052 (0.058)	Data 0.00109 (0.00092)	Tok/s 32285 (53412)	Loss/tok 3.0950 (3.3729)	Learning Rate [0.00125]
2: TRAIN [1][2200/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00097)	Tok/s 32410 (52996)	Loss/tok 3.0329 (3.3789)	Learning Rate [0.00125]
1: TRAIN [1][2200/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00091)	Tok/s 32401 (52900)	Loss/tok 3.2393 (3.3781)	Learning Rate [0.00125]
8: TRAIN [1][2200/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00097)	Tok/s 32247 (53485)	Loss/tok 3.1971 (3.3733)	Learning Rate [0.00125]
0: TRAIN [1][2200/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00092)	Tok/s 32404 (52806)	Loss/tok 2.7942 (3.3825)	Learning Rate [0.00125]
9: TRAIN [1][2200/3416]	Time 0.052 (0.058)	Data 0.00114 (0.00093)	Tok/s 32196 (53551)	Loss/tok 3.3111 (3.3825)	Learning Rate [0.00125]
15: TRAIN [1][2200/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00091)	Tok/s 33629 (54105)	Loss/tok 3.2660 (3.3760)	Learning Rate [0.00125]
14: TRAIN [1][2200/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00092)	Tok/s 33527 (54008)	Loss/tok 3.1348 (3.3759)	Learning Rate [0.00125]
11: TRAIN [1][2200/3416]	Time 0.052 (0.058)	Data 0.00115 (0.00097)	Tok/s 33383 (53713)	Loss/tok 3.2234 (3.3770)	Learning Rate [0.00125]
12: TRAIN [1][2200/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00097)	Tok/s 33418 (53805)	Loss/tok 2.9424 (3.3798)	Learning Rate [0.00125]
13: TRAIN [1][2200/3416]	Time 0.052 (0.058)	Data 0.00108 (0.00099)	Tok/s 33463 (53903)	Loss/tok 3.1562 (3.3805)	Learning Rate [0.00125]
6: TRAIN [1][2200/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00100)	Tok/s 31829 (53327)	Loss/tok 3.0658 (3.3795)	Learning Rate [0.00125]
10: TRAIN [1][2200/3416]	Time 0.052 (0.058)	Data 0.00114 (0.00097)	Tok/s 32204 (53632)	Loss/tok 3.1059 (3.3759)	Learning Rate [0.00125]
9: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00107 (0.00093)	Tok/s 56599 (53554)	Loss/tok 3.2500 (3.3823)	Learning Rate [0.00125]
7: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00091 (0.00092)	Tok/s 56467 (53415)	Loss/tok 3.4447 (3.3730)	Learning Rate [0.00125]
10: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00122 (0.00097)	Tok/s 56650 (53635)	Loss/tok 3.3362 (3.3760)	Learning Rate [0.00125]
8: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00107 (0.00097)	Tok/s 56622 (53488)	Loss/tok 3.3151 (3.3732)	Learning Rate [0.00125]
11: TRAIN [1][2210/3416]	Time 0.060 (0.058)	Data 0.00100 (0.00097)	Tok/s 57427 (53716)	Loss/tok 3.7633 (3.3771)	Learning Rate [0.00125]
6: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00108 (0.00100)	Tok/s 55599 (53331)	Loss/tok 3.2920 (3.3794)	Learning Rate [0.00125]
12: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00102 (0.00097)	Tok/s 56512 (53808)	Loss/tok 3.5081 (3.3798)	Learning Rate [0.00125]
4: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00092)	Tok/s 55468 (53168)	Loss/tok 3.3759 (3.3753)	Learning Rate [0.00125]
14: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00092)	Tok/s 56539 (54012)	Loss/tok 3.3583 (3.3759)	Learning Rate [0.00125]
13: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00107 (0.00099)	Tok/s 56509 (53907)	Loss/tok 3.2138 (3.3805)	Learning Rate [0.00125]
5: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00120 (0.00098)	Tok/s 55477 (53262)	Loss/tok 3.2793 (3.3802)	Learning Rate [0.00125]
0: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00096 (0.00092)	Tok/s 55581 (52810)	Loss/tok 3.2148 (3.3826)	Learning Rate [0.00125]
1: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00095 (0.00092)	Tok/s 55543 (52904)	Loss/tok 3.4897 (3.3780)	Learning Rate [0.00125]
15: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00090 (0.00091)	Tok/s 56606 (54108)	Loss/tok 3.2207 (3.3759)	Learning Rate [0.00125]
2: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00093 (0.00097)	Tok/s 55552 (53000)	Loss/tok 3.4135 (3.3787)	Learning Rate [0.00125]
3: TRAIN [1][2210/3416]	Time 0.061 (0.058)	Data 0.00109 (0.00098)	Tok/s 55620 (53086)	Loss/tok 3.0619 (3.3771)	Learning Rate [0.00125]
7: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00092)	Tok/s 57309 (53401)	Loss/tok 3.4039 (3.3728)	Learning Rate [0.00125]
8: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00097)	Tok/s 57237 (53475)	Loss/tok 3.4918 (3.3726)	Learning Rate [0.00125]
6: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00100)	Tok/s 57333 (53317)	Loss/tok 3.3559 (3.3794)	Learning Rate [0.00125]
5: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00098)	Tok/s 57305 (53249)	Loss/tok 3.5930 (3.3799)	Learning Rate [0.00125]
9: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00107 (0.00093)	Tok/s 57135 (53540)	Loss/tok 3.5040 (3.3821)	Learning Rate [0.00125]
4: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00092)	Tok/s 57318 (53155)	Loss/tok 3.6001 (3.3751)	Learning Rate [0.00125]
10: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00108 (0.00097)	Tok/s 57148 (53621)	Loss/tok 3.4569 (3.3758)	Learning Rate [0.00125]
3: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00110 (0.00098)	Tok/s 57313 (53072)	Loss/tok 3.2900 (3.3767)	Learning Rate [0.00125]
11: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00097)	Tok/s 57991 (53703)	Loss/tok 3.4693 (3.3766)	Learning Rate [0.00125]
2: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00107 (0.00098)	Tok/s 57301 (52987)	Loss/tok 3.1782 (3.3779)	Learning Rate [0.00125]
12: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00097)	Tok/s 58064 (53795)	Loss/tok 3.5995 (3.3798)	Learning Rate [0.00125]
0: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00092)	Tok/s 57348 (52797)	Loss/tok 3.3379 (3.3820)	Learning Rate [0.00125]
15: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00091)	Tok/s 58134 (54095)	Loss/tok 3.6998 (3.3756)	Learning Rate [0.00125]
1: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00092)	Tok/s 57243 (52890)	Loss/tok 3.0695 (3.3774)	Learning Rate [0.00125]
14: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00092)	Tok/s 58026 (53999)	Loss/tok 3.2160 (3.3757)	Learning Rate [0.00125]
13: TRAIN [1][2220/3416]	Time 0.068 (0.058)	Data 0.00115 (0.00099)	Tok/s 58020 (53894)	Loss/tok 3.6539 (3.3801)	Learning Rate [0.00125]
4: Gradient norm: inf
5: Gradient norm: inf
7: Gradient norm: inf
8: Gradient norm: inf
6: Gradient norm: inf
3: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
10: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
14: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
11: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
4: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00092)	Tok/s 51115 (53185)	Loss/tok 3.2139 (3.3751)	Learning Rate [0.00125]
5: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00098)	Tok/s 50981 (53279)	Loss/tok 3.1103 (3.3801)	Learning Rate [0.00125]
3: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00081 (0.00098)	Tok/s 51055 (53103)	Loss/tok 3.0305 (3.3771)	Learning Rate [0.00125]
2: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00098)	Tok/s 51048 (53018)	Loss/tok 3.1347 (3.3777)	Learning Rate [0.00125]
1: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00083 (0.00092)	Tok/s 51112 (52921)	Loss/tok 3.0573 (3.3775)	Learning Rate [0.00125]
14: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00082 (0.00092)	Tok/s 51008 (54028)	Loss/tok 3.1197 (3.3759)	Learning Rate [0.00125]
15: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00091)	Tok/s 51063 (54124)	Loss/tok 3.0432 (3.3757)	Learning Rate [0.00125]
6: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00100)	Tok/s 50843 (53347)	Loss/tok 3.4126 (3.3795)	Learning Rate [0.00125]
13: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00099)	Tok/s 50925 (53923)	Loss/tok 3.0463 (3.3800)	Learning Rate [0.00125]
12: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00100 (0.00097)	Tok/s 50789 (53825)	Loss/tok 3.3768 (3.3798)	Learning Rate [0.00125]
7: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00093)	Tok/s 50692 (53431)	Loss/tok 3.1816 (3.3728)	Learning Rate [0.00125]
0: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00092)	Tok/s 51109 (52827)	Loss/tok 3.2209 (3.3816)	Learning Rate [0.00125]
8: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00082 (0.00097)	Tok/s 50616 (53504)	Loss/tok 3.3342 (3.3728)	Learning Rate [0.00125]
11: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00103 (0.00097)	Tok/s 50704 (53733)	Loss/tok 3.2051 (3.3767)	Learning Rate [0.00125]
10: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00108 (0.00097)	Tok/s 50560 (53651)	Loss/tok 3.4623 (3.3757)	Learning Rate [0.00125]
9: TRAIN [1][2230/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00093)	Tok/s 50528 (53569)	Loss/tok 3.4358 (3.3824)	Learning Rate [0.00125]
5: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00098)	Tok/s 52903 (53276)	Loss/tok 3.4094 (3.3800)	Learning Rate [0.00125]
6: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00100)	Tok/s 52895 (53344)	Loss/tok 3.2505 (3.3791)	Learning Rate [0.00125]
7: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00093)	Tok/s 52843 (53428)	Loss/tok 3.2273 (3.3722)	Learning Rate [0.00125]
8: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00097)	Tok/s 52785 (53502)	Loss/tok 3.1292 (3.3723)	Learning Rate [0.00125]
4: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00092)	Tok/s 52908 (53181)	Loss/tok 3.2119 (3.3752)	Learning Rate [0.00125]
3: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00098)	Tok/s 51538 (53098)	Loss/tok 3.3837 (3.3768)	Learning Rate [0.00125]
9: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00093)	Tok/s 52835 (53568)	Loss/tok 3.2619 (3.3820)	Learning Rate [0.00125]
10: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00110 (0.00097)	Tok/s 52827 (53650)	Loss/tok 3.4099 (3.3757)	Learning Rate [0.00125]
2: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00098)	Tok/s 51574 (53013)	Loss/tok 3.0172 (3.3772)	Learning Rate [0.00125]
11: TRAIN [1][2240/3416]	Time 0.049 (0.058)	Data 0.00108 (0.00097)	Tok/s 52744 (53731)	Loss/tok 3.1714 (3.3762)	Learning Rate [0.00125]
1: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00091)	Tok/s 51639 (52914)	Loss/tok 3.2828 (3.3773)	Learning Rate [0.00125]
0: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00092)	Tok/s 51621 (52820)	Loss/tok 3.3853 (3.3817)	Learning Rate [0.00125]
15: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00091)	Tok/s 52963 (54123)	Loss/tok 3.2017 (3.3757)	Learning Rate [0.00125]
12: TRAIN [1][2240/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00097)	Tok/s 52766 (53823)	Loss/tok 3.0964 (3.3794)	Learning Rate [0.00125]
14: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00092)	Tok/s 52937 (54027)	Loss/tok 3.0112 (3.3756)	Learning Rate [0.00125]
13: TRAIN [1][2240/3416]	Time 0.048 (0.058)	Data 0.00105 (0.00099)	Tok/s 52863 (53922)	Loss/tok 3.4567 (3.3800)	Learning Rate [0.00125]
11: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00097)	Tok/s 53727 (53725)	Loss/tok 3.4499 (3.3762)	Learning Rate [0.00125]
10: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00097)	Tok/s 53749 (53644)	Loss/tok 3.3258 (3.3760)	Learning Rate [0.00125]
12: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00097)	Tok/s 53626 (53817)	Loss/tok 3.4728 (3.3797)	Learning Rate [0.00125]
9: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00093)	Tok/s 53767 (53562)	Loss/tok 3.4417 (3.3823)	Learning Rate [0.00125]
15: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00091)	Tok/s 53547 (54117)	Loss/tok 3.5207 (3.3756)	Learning Rate [0.00125]
14: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00092)	Tok/s 53501 (54020)	Loss/tok 3.5142 (3.3755)	Learning Rate [0.00125]
13: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00099)	Tok/s 53541 (53915)	Loss/tok 3.3125 (3.3800)	Learning Rate [0.00125]
8: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00104 (0.00097)	Tok/s 53746 (53496)	Loss/tok 3.6734 (3.3726)	Learning Rate [0.00125]
7: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00093)	Tok/s 53743 (53423)	Loss/tok 3.1502 (3.3726)	Learning Rate [0.00125]
0: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00092)	Tok/s 53367 (52814)	Loss/tok 3.7416 (3.3821)	Learning Rate [0.00125]
6: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00100)	Tok/s 53703 (53339)	Loss/tok 3.3188 (3.3791)	Learning Rate [0.00125]
5: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00098)	Tok/s 53657 (53270)	Loss/tok 3.7942 (3.3802)	Learning Rate [0.00125]
2: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00098)	Tok/s 53462 (53007)	Loss/tok 3.4172 (3.3771)	Learning Rate [0.00125]
4: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00092)	Tok/s 53654 (53175)	Loss/tok 3.1701 (3.3753)	Learning Rate [0.00125]
1: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00091)	Tok/s 53493 (52908)	Loss/tok 3.2515 (3.3775)	Learning Rate [0.00125]
3: TRAIN [1][2250/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00098)	Tok/s 53504 (53092)	Loss/tok 3.4459 (3.3768)	Learning Rate [0.00125]
6: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00100)	Tok/s 71785 (53364)	Loss/tok 3.5261 (3.3792)	Learning Rate [0.00125]
7: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00093)	Tok/s 71761 (53447)	Loss/tok 3.3020 (3.3723)	Learning Rate [0.00125]
4: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 71561 (53201)	Loss/tok 3.3713 (3.3752)	Learning Rate [0.00125]
8: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 71785 (53521)	Loss/tok 3.6537 (3.3728)	Learning Rate [0.00125]
5: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 71820 (53295)	Loss/tok 3.4120 (3.3800)	Learning Rate [0.00125]
3: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00098)	Tok/s 70865 (53118)	Loss/tok 3.4429 (3.3771)	Learning Rate [0.00125]
9: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00093)	Tok/s 71783 (53587)	Loss/tok 3.4643 (3.3820)	Learning Rate [0.00125]
10: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 71764 (53668)	Loss/tok 3.2052 (3.3758)	Learning Rate [0.00125]
1: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00091)	Tok/s 70868 (52933)	Loss/tok 3.2814 (3.3773)	Learning Rate [0.00125]
0: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 70906 (52839)	Loss/tok 3.3785 (3.3817)	Learning Rate [0.00125]
11: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 71768 (53750)	Loss/tok 3.4256 (3.3762)	Learning Rate [0.00125]
2: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 70860 (53032)	Loss/tok 3.5026 (3.3771)	Learning Rate [0.00125]
12: TRAIN [1][2260/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00097)	Tok/s 71713 (53841)	Loss/tok 3.1547 (3.3796)	Learning Rate [0.00125]
14: TRAIN [1][2260/3416]	Time 0.068 (0.058)	Data 0.00110 (0.00092)	Tok/s 74930 (54045)	Loss/tok 3.3885 (3.3753)	Learning Rate [0.00125]
15: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00091)	Tok/s 72666 (54141)	Loss/tok 3.4576 (3.3754)	Learning Rate [0.00125]
13: TRAIN [1][2260/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00099)	Tok/s 71721 (53939)	Loss/tok 3.3382 (3.3799)	Learning Rate [0.00125]
2: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00098)	Tok/s 52588 (53048)	Loss/tok 3.5467 (3.3772)	Learning Rate [0.00125]
1: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00082 (0.00091)	Tok/s 52527 (52948)	Loss/tok 3.0572 (3.3775)	Learning Rate [0.00125]
0: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00092)	Tok/s 52413 (52854)	Loss/tok 3.2700 (3.3818)	Learning Rate [0.00125]
3: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00090 (0.00098)	Tok/s 52588 (53133)	Loss/tok 3.0128 (3.3771)	Learning Rate [0.00125]
4: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00084 (0.00092)	Tok/s 52608 (53216)	Loss/tok 3.1030 (3.3752)	Learning Rate [0.00125]
5: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00098)	Tok/s 52601 (53310)	Loss/tok 3.3680 (3.3804)	Learning Rate [0.00125]
15: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00083 (0.00091)	Tok/s 52345 (54155)	Loss/tok 3.3496 (3.3753)	Learning Rate [0.00125]
14: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00077 (0.00092)	Tok/s 52377 (54058)	Loss/tok 3.2337 (3.3754)	Learning Rate [0.00125]
6: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00101 (0.00100)	Tok/s 52578 (53379)	Loss/tok 3.3172 (3.3792)	Learning Rate [0.00125]
7: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00097 (0.00093)	Tok/s 52559 (53462)	Loss/tok 3.1920 (3.3721)	Learning Rate [0.00125]
12: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00092 (0.00097)	Tok/s 52395 (53855)	Loss/tok 3.3207 (3.3796)	Learning Rate [0.00125]
8: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00097)	Tok/s 52546 (53536)	Loss/tok 3.5675 (3.3725)	Learning Rate [0.00125]
10: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00097)	Tok/s 52425 (53683)	Loss/tok 3.6843 (3.3757)	Learning Rate [0.00125]
11: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00089 (0.00097)	Tok/s 52402 (53764)	Loss/tok 3.3520 (3.3764)	Learning Rate [0.00125]
9: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00099 (0.00093)	Tok/s 52443 (53602)	Loss/tok 3.5835 (3.3819)	Learning Rate [0.00125]
13: TRAIN [1][2270/3416]	Time 0.056 (0.058)	Data 0.00106 (0.00099)	Tok/s 52403 (53953)	Loss/tok 3.3211 (3.3799)	Learning Rate [0.00125]
15: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00082 (0.00091)	Tok/s 31845 (54141)	Loss/tok 3.0605 (3.3752)	Learning Rate [0.00125]
13: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00100 (0.00099)	Tok/s 30181 (53939)	Loss/tok 2.5688 (3.3796)	Learning Rate [0.00125]
0: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00092)	Tok/s 28688 (52841)	Loss/tok 2.5634 (3.3817)	Learning Rate [0.00125]
12: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00084 (0.00097)	Tok/s 30147 (53841)	Loss/tok 2.4756 (3.3791)	Learning Rate [0.00125]
11: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00099 (0.00097)	Tok/s 30181 (53749)	Loss/tok 2.5218 (3.3762)	Learning Rate [0.00125]
1: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00086 (0.00091)	Tok/s 28648 (52935)	Loss/tok 2.5600 (3.3773)	Learning Rate [0.00125]
2: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00097 (0.00098)	Tok/s 28698 (53033)	Loss/tok 2.7502 (3.3772)	Learning Rate [0.00125]
10: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00093 (0.00097)	Tok/s 30173 (53668)	Loss/tok 2.5516 (3.3760)	Learning Rate [0.00125]
9: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00098 (0.00093)	Tok/s 30160 (53587)	Loss/tok 2.6721 (3.3816)	Learning Rate [0.00125]
7: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00099 (0.00093)	Tok/s 30195 (53448)	Loss/tok 2.6393 (3.3720)	Learning Rate [0.00125]
8: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00096 (0.00097)	Tok/s 30190 (53522)	Loss/tok 2.7939 (3.3724)	Learning Rate [0.00125]
14: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00084 (0.00092)	Tok/s 30392 (54044)	Loss/tok 2.6907 (3.3753)	Learning Rate [0.00125]
3: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00090 (0.00098)	Tok/s 28648 (53119)	Loss/tok 2.6833 (3.3770)	Learning Rate [0.00125]
4: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00093 (0.00092)	Tok/s 28648 (53201)	Loss/tok 2.5820 (3.3748)	Learning Rate [0.00125]
5: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00098 (0.00098)	Tok/s 28624 (53295)	Loss/tok 2.7315 (3.3803)	Learning Rate [0.00125]
6: TRAIN [1][2280/3416]	Time 0.040 (0.058)	Data 0.00089 (0.00100)	Tok/s 29607 (53364)	Loss/tok 2.6350 (3.3792)	Learning Rate [0.00125]
7: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00107 (0.00093)	Tok/s 52522 (53460)	Loss/tok 3.3010 (3.3722)	Learning Rate [0.00125]
3: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00098)	Tok/s 52423 (53132)	Loss/tok 3.5447 (3.3769)	Learning Rate [0.00125]
5: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00098)	Tok/s 52420 (53308)	Loss/tok 3.3225 (3.3805)	Learning Rate [0.00125]
4: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00092)	Tok/s 52279 (53213)	Loss/tok 3.3532 (3.3747)	Learning Rate [0.00125]
6: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00100)	Tok/s 52438 (53376)	Loss/tok 3.3638 (3.3793)	Learning Rate [0.00125]
2: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00098)	Tok/s 52298 (53046)	Loss/tok 3.2251 (3.3775)	Learning Rate [0.00125]
10: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00106 (0.00097)	Tok/s 52491 (53680)	Loss/tok 3.3101 (3.3759)	Learning Rate [0.00125]
8: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00124 (0.00097)	Tok/s 52421 (53534)	Loss/tok 3.4074 (3.3721)	Learning Rate [0.00125]
1: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00091 (0.00091)	Tok/s 52289 (52947)	Loss/tok 3.1821 (3.3774)	Learning Rate [0.00125]
0: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00092)	Tok/s 52296 (52854)	Loss/tok 3.5266 (3.3819)	Learning Rate [0.00125]
15: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00094 (0.00091)	Tok/s 52263 (54152)	Loss/tok 3.3766 (3.3750)	Learning Rate [0.00125]
14: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00095 (0.00092)	Tok/s 52286 (54055)	Loss/tok 3.2594 (3.3755)	Learning Rate [0.00125]
12: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00106 (0.00097)	Tok/s 52409 (53853)	Loss/tok 3.4184 (3.3794)	Learning Rate [0.00125]
13: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00106 (0.00099)	Tok/s 52447 (53950)	Loss/tok 3.4075 (3.3797)	Learning Rate [0.00125]
11: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00110 (0.00097)	Tok/s 52459 (53761)	Loss/tok 3.4696 (3.3762)	Learning Rate [0.00125]
9: TRAIN [1][2290/3416]	Time 0.055 (0.058)	Data 0.00108 (0.00093)	Tok/s 52418 (53599)	Loss/tok 3.2773 (3.3820)	Learning Rate [0.00125]
7: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00095 (0.00093)	Tok/s 42932 (53439)	Loss/tok 3.1873 (3.3719)	Learning Rate [0.00125]
6: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00100)	Tok/s 43036 (53355)	Loss/tok 3.0909 (3.3793)	Learning Rate [0.00125]
5: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00098)	Tok/s 43051 (53286)	Loss/tok 3.3047 (3.3803)	Learning Rate [0.00125]
4: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00092)	Tok/s 43028 (53192)	Loss/tok 2.9959 (3.3744)	Learning Rate [0.00125]
8: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00097)	Tok/s 42845 (53512)	Loss/tok 3.2362 (3.3720)	Learning Rate [0.00125]
3: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00098)	Tok/s 43113 (53110)	Loss/tok 3.1257 (3.3764)	Learning Rate [0.00125]
2: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00098)	Tok/s 43061 (53025)	Loss/tok 3.1556 (3.3771)	Learning Rate [0.00125]
10: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00097)	Tok/s 42799 (53659)	Loss/tok 3.0477 (3.3757)	Learning Rate [0.00125]
9: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00098 (0.00093)	Tok/s 42766 (53578)	Loss/tok 3.2918 (3.3817)	Learning Rate [0.00125]
1: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00091)	Tok/s 42996 (52926)	Loss/tok 3.1257 (3.3773)	Learning Rate [0.00125]
0: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00092)	Tok/s 42973 (52833)	Loss/tok 2.8452 (3.3816)	Learning Rate [0.00125]
11: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00097)	Tok/s 42757 (53739)	Loss/tok 3.1555 (3.3762)	Learning Rate [0.00125]
12: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00097)	Tok/s 42692 (53831)	Loss/tok 3.0832 (3.3791)	Learning Rate [0.00125]
15: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00091)	Tok/s 42909 (54130)	Loss/tok 3.0372 (3.3747)	Learning Rate [0.00125]
14: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 42799 (54033)	Loss/tok 3.0448 (3.3752)	Learning Rate [0.00125]
13: TRAIN [1][2300/3416]	Time 0.048 (0.058)	Data 0.00101 (0.00099)	Tok/s 42691 (53928)	Loss/tok 3.2270 (3.3795)	Learning Rate [0.00125]
15: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 59260 (54173)	Loss/tok 3.1129 (3.3746)	Learning Rate [0.00125]
13: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00099)	Tok/s 58647 (53971)	Loss/tok 3.3860 (3.3797)	Learning Rate [0.00125]
0: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00092)	Tok/s 58263 (52876)	Loss/tok 3.6595 (3.3823)	Learning Rate [0.00125]
12: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 58418 (53874)	Loss/tok 3.5829 (3.3795)	Learning Rate [0.00125]
14: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00092)	Tok/s 59342 (54076)	Loss/tok 3.3766 (3.3755)	Learning Rate [0.00125]
11: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00097)	Tok/s 58421 (53782)	Loss/tok 3.4703 (3.3765)	Learning Rate [0.00125]
10: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 58402 (53702)	Loss/tok 3.4507 (3.3759)	Learning Rate [0.00125]
1: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 58118 (52969)	Loss/tok 3.5768 (3.3777)	Learning Rate [0.00125]
2: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00098)	Tok/s 58050 (53068)	Loss/tok 3.3966 (3.3774)	Learning Rate [0.00125]
9: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00093)	Tok/s 58374 (53620)	Loss/tok 3.2909 (3.3812)	Learning Rate [0.00125]
8: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00097)	Tok/s 58283 (53555)	Loss/tok 3.5761 (3.3725)	Learning Rate [0.00125]
3: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 58015 (53153)	Loss/tok 3.5253 (3.3764)	Learning Rate [0.00125]
4: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00092)	Tok/s 58046 (53235)	Loss/tok 3.3200 (3.3744)	Learning Rate [0.00125]
7: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00093)	Tok/s 58168 (53482)	Loss/tok 3.3418 (3.3722)	Learning Rate [0.00125]
5: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 58041 (53329)	Loss/tok 3.2513 (3.3802)	Learning Rate [0.00125]
6: TRAIN [1][2310/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00100)	Tok/s 58097 (53398)	Loss/tok 3.7698 (3.3791)	Learning Rate [0.00125]
8: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 86980 (53553)	Loss/tok 3.1331 (3.3721)	Learning Rate [0.00125]
9: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 87036 (53619)	Loss/tok 3.0172 (3.3807)	Learning Rate [0.00125]
14: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00092)	Tok/s 89677 (54076)	Loss/tok 3.3473 (3.3750)	Learning Rate [0.00125]
10: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 87650 (53701)	Loss/tok 3.2508 (3.3756)	Learning Rate [0.00125]
15: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00091)	Tok/s 90708 (54174)	Loss/tok 3.1435 (3.3741)	Learning Rate [0.00125]
7: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00093)	Tok/s 86565 (53480)	Loss/tok 3.1596 (3.3721)	Learning Rate [0.00125]
11: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 88008 (53781)	Loss/tok 3.1280 (3.3762)	Learning Rate [0.00125]
12: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 88341 (53873)	Loss/tok 3.4151 (3.3795)	Learning Rate [0.00125]
0: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 85388 (52874)	Loss/tok 3.1513 (3.3815)	Learning Rate [0.00125]
6: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00100)	Tok/s 85911 (53395)	Loss/tok 3.2511 (3.3789)	Learning Rate [0.00125]
13: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00099)	Tok/s 89065 (53971)	Loss/tok 3.2297 (3.3793)	Learning Rate [0.00125]
5: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 85878 (53326)	Loss/tok 3.2204 (3.3798)	Learning Rate [0.00125]
1: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00091)	Tok/s 85205 (52967)	Loss/tok 3.1598 (3.3773)	Learning Rate [0.00125]
4: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 85905 (53232)	Loss/tok 3.2779 (3.3740)	Learning Rate [0.00125]
2: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 85086 (53065)	Loss/tok 3.2810 (3.3771)	Learning Rate [0.00125]
3: TRAIN [1][2320/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00098)	Tok/s 85391 (53151)	Loss/tok 3.2160 (3.3761)	Learning Rate [0.00125]
12: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00115 (0.00097)	Tok/s 64232 (53877)	Loss/tok 3.5150 (3.3795)	Learning Rate [0.00125]
6: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00100)	Tok/s 64083 (53400)	Loss/tok 3.3076 (3.3784)	Learning Rate [0.00125]
5: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00098)	Tok/s 64101 (53331)	Loss/tok 3.3730 (3.3795)	Learning Rate [0.00125]
7: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 64050 (53484)	Loss/tok 3.4610 (3.3720)	Learning Rate [0.00125]
4: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 64147 (53237)	Loss/tok 3.3759 (3.3737)	Learning Rate [0.00125]
14: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 64638 (54080)	Loss/tok 3.5126 (3.3749)	Learning Rate [0.00125]
10: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 63853 (53705)	Loss/tok 3.5220 (3.3755)	Learning Rate [0.00125]
13: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00099)	Tok/s 64652 (53975)	Loss/tok 3.5899 (3.3792)	Learning Rate [0.00125]
8: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00113 (0.00097)	Tok/s 64433 (53557)	Loss/tok 3.6539 (3.3724)	Learning Rate [0.00125]
11: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 63786 (53786)	Loss/tok 3.5974 (3.3762)	Learning Rate [0.00125]
9: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00093)	Tok/s 63867 (53623)	Loss/tok 3.5572 (3.3807)	Learning Rate [0.00125]
0: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 63733 (52879)	Loss/tok 3.3146 (3.3816)	Learning Rate [0.00125]
2: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 63876 (53071)	Loss/tok 3.3717 (3.3773)	Learning Rate [0.00125]
15: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00091)	Tok/s 64632 (54177)	Loss/tok 3.1773 (3.3740)	Learning Rate [0.00125]
3: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00098)	Tok/s 64062 (53156)	Loss/tok 3.6564 (3.3760)	Learning Rate [0.00125]
1: TRAIN [1][2330/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00091)	Tok/s 63784 (52973)	Loss/tok 3.6023 (3.3770)	Learning Rate [0.00125]
7: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00093)	Tok/s 52925 (53445)	Loss/tok 3.4552 (3.3717)	Learning Rate [0.00125]
6: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00099 (0.00100)	Tok/s 52906 (53360)	Loss/tok 3.2948 (3.3781)	Learning Rate [0.00125]
5: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00091 (0.00098)	Tok/s 52737 (53291)	Loss/tok 3.4971 (3.3791)	Learning Rate [0.00125]
4: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00092)	Tok/s 52640 (53197)	Loss/tok 3.5620 (3.3733)	Learning Rate [0.00125]
8: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00097)	Tok/s 52830 (53518)	Loss/tok 3.5420 (3.3722)	Learning Rate [0.00125]
3: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00098)	Tok/s 52531 (53115)	Loss/tok 3.3956 (3.3756)	Learning Rate [0.00125]
9: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00093)	Tok/s 52808 (53584)	Loss/tok 3.5892 (3.3806)	Learning Rate [0.00125]
10: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00097)	Tok/s 52840 (53666)	Loss/tok 3.3957 (3.3749)	Learning Rate [0.00125]
2: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00098)	Tok/s 52536 (53030)	Loss/tok 3.4327 (3.3769)	Learning Rate [0.00125]
0: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00096 (0.00092)	Tok/s 52554 (52836)	Loss/tok 3.4926 (3.3813)	Learning Rate [0.00125]
11: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00095 (0.00097)	Tok/s 52771 (53747)	Loss/tok 3.4613 (3.3757)	Learning Rate [0.00125]
12: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00098 (0.00097)	Tok/s 52803 (53838)	Loss/tok 3.4006 (3.3793)	Learning Rate [0.00125]
14: TRAIN [1][2340/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00092)	Tok/s 52502 (54041)	Loss/tok 3.4407 (3.3744)	Learning Rate [0.00125]
13: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00094 (0.00099)	Tok/s 52567 (53937)	Loss/tok 3.1998 (3.3787)	Learning Rate [0.00125]
15: TRAIN [1][2340/3416]	Time 0.058 (0.058)	Data 0.00087 (0.00091)	Tok/s 52900 (54139)	Loss/tok 3.5455 (3.3735)	Learning Rate [0.00125]
1: TRAIN [1][2340/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00091)	Tok/s 51350 (52930)	Loss/tok 3.3125 (3.3765)	Learning Rate [0.00125]
0: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
0: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 84825 (52884)	Loss/tok 3.2644 (3.3812)	Learning Rate [0.00125]
11: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
14: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 89252 (54089)	Loss/tok 3.2456 (3.3747)	Learning Rate [0.00125]
1: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00091)	Tok/s 84896 (52979)	Loss/tok 3.2092 (3.3770)	Learning Rate [0.00125]
15: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00091)	Tok/s 89822 (54187)	Loss/tok 3.1356 (3.3731)	Learning Rate [0.00125]
5: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
2: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 84829 (53077)	Loss/tok 3.2646 (3.3767)	Learning Rate [0.00125]
13: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00099)	Tok/s 88479 (53985)	Loss/tok 3.0557 (3.3783)	Learning Rate [0.00125]
12: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00097)	Tok/s 88135 (53885)	Loss/tok 3.0766 (3.3796)	Learning Rate [0.00125]
11: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 87661 (53794)	Loss/tok 3.3407 (3.3762)	Learning Rate [0.00125]
3: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00098)	Tok/s 85509 (53163)	Loss/tok 3.1785 (3.3753)	Learning Rate [0.00125]
6: Upscaling, new scale: 2048.0
4: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 85716 (53244)	Loss/tok 3.1512 (3.3730)	Learning Rate [0.00125]
10: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 87667 (53713)	Loss/tok 3.1975 (3.3749)	Learning Rate [0.00125]
5: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00098)	Tok/s 85739 (53338)	Loss/tok 3.0590 (3.3794)	Learning Rate [0.00125]
7: Upscaling, new scale: 2048.0
8: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 86764 (53565)	Loss/tok 3.1848 (3.3725)	Learning Rate [0.00125]
9: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00093)	Tok/s 86820 (53631)	Loss/tok 3.1767 (3.3805)	Learning Rate [0.00125]
6: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00100)	Tok/s 85715 (53407)	Loss/tok 3.0419 (3.3782)	Learning Rate [0.00125]
7: TRAIN [1][2350/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00093)	Tok/s 86381 (53491)	Loss/tok 3.3213 (3.3719)	Learning Rate [0.00125]
12: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00097)	Tok/s 88452 (53920)	Loss/tok 3.3579 (3.3794)	Learning Rate [0.00125]
13: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00099)	Tok/s 88912 (54019)	Loss/tok 3.1102 (3.3779)	Learning Rate [0.00125]
10: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 87623 (53747)	Loss/tok 3.4335 (3.3749)	Learning Rate [0.00125]
14: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 89717 (54123)	Loss/tok 3.1302 (3.3745)	Learning Rate [0.00125]
15: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00091)	Tok/s 90342 (54222)	Loss/tok 3.3180 (3.3729)	Learning Rate [0.00125]
11: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 87653 (53828)	Loss/tok 3.2201 (3.3761)	Learning Rate [0.00125]
0: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00107 (0.00092)	Tok/s 85167 (52917)	Loss/tok 3.3088 (3.3813)	Learning Rate [0.00125]
9: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00093)	Tok/s 86808 (53665)	Loss/tok 3.2221 (3.3806)	Learning Rate [0.00125]
1: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00091)	Tok/s 85066 (53012)	Loss/tok 3.2866 (3.3767)	Learning Rate [0.00125]
7: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00093)	Tok/s 86404 (53525)	Loss/tok 3.2383 (3.3714)	Learning Rate [0.00125]
2: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00098)	Tok/s 84900 (53111)	Loss/tok 3.3144 (3.3765)	Learning Rate [0.00125]
4: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00092)	Tok/s 85631 (53278)	Loss/tok 3.0726 (3.3728)	Learning Rate [0.00125]
8: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00097)	Tok/s 86348 (53598)	Loss/tok 3.1120 (3.3725)	Learning Rate [0.00125]
3: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00098)	Tok/s 85312 (53196)	Loss/tok 3.2584 (3.3753)	Learning Rate [0.00125]
5: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 85464 (53371)	Loss/tok 3.2544 (3.3790)	Learning Rate [0.00125]
6: TRAIN [1][2360/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00100)	Tok/s 85608 (53440)	Loss/tok 3.4117 (3.3780)	Learning Rate [0.00125]
3: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00098)	Tok/s 59364 (53181)	Loss/tok 3.4016 (3.3749)	Learning Rate [0.00125]
2: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00098)	Tok/s 59294 (53095)	Loss/tok 3.6739 (3.3765)	Learning Rate [0.00125]
4: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00092)	Tok/s 59370 (53262)	Loss/tok 3.5105 (3.3728)	Learning Rate [0.00125]
5: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00098)	Tok/s 59413 (53356)	Loss/tok 3.5214 (3.3789)	Learning Rate [0.00125]
1: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00091)	Tok/s 59306 (52996)	Loss/tok 3.7383 (3.3768)	Learning Rate [0.00125]
0: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00092)	Tok/s 59251 (52902)	Loss/tok 3.1931 (3.3810)	Learning Rate [0.00125]
7: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00093)	Tok/s 59384 (53508)	Loss/tok 3.2976 (3.3714)	Learning Rate [0.00125]
6: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00100)	Tok/s 59392 (53424)	Loss/tok 3.6602 (3.3780)	Learning Rate [0.00125]
15: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00091)	Tok/s 60164 (54207)	Loss/tok 3.6981 (3.3731)	Learning Rate [0.00125]
14: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00092)	Tok/s 60241 (54108)	Loss/tok 3.5346 (3.3746)	Learning Rate [0.00125]
8: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00106 (0.00097)	Tok/s 59398 (53582)	Loss/tok 3.7274 (3.3724)	Learning Rate [0.00125]
9: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00093)	Tok/s 59383 (53649)	Loss/tok 3.4183 (3.3803)	Learning Rate [0.00125]
13: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00099)	Tok/s 60209 (54004)	Loss/tok 3.6015 (3.3779)	Learning Rate [0.00125]
12: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00097)	Tok/s 60339 (53904)	Loss/tok 3.4511 (3.3793)	Learning Rate [0.00125]
10: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00097)	Tok/s 59343 (53732)	Loss/tok 3.2449 (3.3746)	Learning Rate [0.00125]
11: TRAIN [1][2370/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00097)	Tok/s 59967 (53812)	Loss/tok 3.7442 (3.3759)	Learning Rate [0.00125]
7: TRAIN [1][2380/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00093)	Tok/s 58952 (53478)	Loss/tok 3.4660 (3.3710)	Learning Rate [0.00125]
5: TRAIN [1][2380/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00098)	Tok/s 58927 (53325)	Loss/tok 3.2791 (3.3785)	Learning Rate [0.00125]
8: TRAIN [1][2380/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 58816 (53553)	Loss/tok 3.5232 (3.3719)	Learning Rate [0.00125]
9: TRAIN [1][2380/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00093)	Tok/s 58721 (53620)	Loss/tok 3.5113 (3.3799)	Learning Rate [0.00125]
4: TRAIN [1][2380/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00092)	Tok/s 58925 (53230)	Loss/tok 3.5033 (3.3723)	Learning Rate [0.00125]
10: TRAIN [1][2380/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 58633 (53702)	Loss/tok 3.6947 (3.3744)	Learning Rate [0.00125]
2: TRAIN [1][2380/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00098)	Tok/s 58852 (53062)	Loss/tok 3.4382 (3.3763)	Learning Rate [0.00125]
6: TRAIN [1][2380/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00100)	Tok/s 58923 (53394)	Loss/tok 3.5918 (3.3778)	Learning Rate [0.00125]
3: TRAIN [1][2380/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00098)	Tok/s 59004 (53149)	Loss/tok 3.4666 (3.3744)	Learning Rate [0.00125]
11: TRAIN [1][2380/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 58626 (53782)	Loss/tok 3.6001 (3.3757)	Learning Rate [0.00125]
12: TRAIN [1][2380/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 59491 (53875)	Loss/tok 3.5324 (3.3789)	Learning Rate [0.00125]
14: TRAIN [1][2380/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 59537 (54078)	Loss/tok 3.3868 (3.3744)	Learning Rate [0.00125]
0: TRAIN [1][2380/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 58697 (52867)	Loss/tok 3.4660 (3.3806)	Learning Rate [0.00125]
1: TRAIN [1][2380/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 58741 (52962)	Loss/tok 3.2822 (3.3760)	Learning Rate [0.00125]
13: TRAIN [1][2380/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00099)	Tok/s 59541 (53974)	Loss/tok 3.5923 (3.3776)	Learning Rate [0.00125]
15: TRAIN [1][2380/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 59561 (54177)	Loss/tok 3.5273 (3.3727)	Learning Rate [0.00125]
3: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00099 (0.00098)	Tok/s 53484 (53136)	Loss/tok 3.3650 (3.3743)	Learning Rate [0.00125]
2: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00103 (0.00098)	Tok/s 53463 (53050)	Loss/tok 3.2164 (3.3761)	Learning Rate [0.00125]
4: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00092)	Tok/s 53323 (53217)	Loss/tok 3.1139 (3.3720)	Learning Rate [0.00125]
5: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00084 (0.00098)	Tok/s 53231 (53312)	Loss/tok 3.2478 (3.3786)	Learning Rate [0.00125]
0: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00098 (0.00092)	Tok/s 53477 (52856)	Loss/tok 3.3966 (3.3806)	Learning Rate [0.00125]
1: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00081 (0.00091)	Tok/s 53440 (52951)	Loss/tok 3.5660 (3.3761)	Learning Rate [0.00125]
10: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00085 (0.00097)	Tok/s 53107 (53689)	Loss/tok 3.1392 (3.3739)	Learning Rate [0.00125]
9: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00091 (0.00093)	Tok/s 53011 (53607)	Loss/tok 3.4298 (3.3798)	Learning Rate [0.00125]
7: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00093)	Tok/s 53012 (53465)	Loss/tok 3.4445 (3.3707)	Learning Rate [0.00125]
8: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00087 (0.00097)	Tok/s 52967 (53539)	Loss/tok 3.2988 (3.3716)	Learning Rate [0.00125]
6: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00108 (0.00100)	Tok/s 53159 (53381)	Loss/tok 3.1505 (3.3776)	Learning Rate [0.00125]
14: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00090 (0.00092)	Tok/s 53154 (54064)	Loss/tok 3.2024 (3.3742)	Learning Rate [0.00125]
15: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00091)	Tok/s 53220 (54162)	Loss/tok 3.5457 (3.3724)	Learning Rate [0.00125]
11: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00096 (0.00097)	Tok/s 52987 (53769)	Loss/tok 3.3031 (3.3754)	Learning Rate [0.00125]
12: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00100 (0.00097)	Tok/s 53095 (53861)	Loss/tok 3.3930 (3.3788)	Learning Rate [0.00125]
13: TRAIN [1][2390/3416]	Time 0.054 (0.058)	Data 0.00089 (0.00099)	Tok/s 53171 (53960)	Loss/tok 3.4355 (3.3773)	Learning Rate [0.00125]
15: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00091)	Tok/s 74107 (54190)	Loss/tok 3.1964 (3.3724)	Learning Rate [0.00125]
0: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 73167 (52884)	Loss/tok 3.5220 (3.3804)	Learning Rate [0.00125]
14: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 74137 (54091)	Loss/tok 3.2439 (3.3740)	Learning Rate [0.00125]
13: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 74126 (53988)	Loss/tok 3.4395 (3.3771)	Learning Rate [0.00125]
1: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00091)	Tok/s 73186 (52979)	Loss/tok 3.4412 (3.3761)	Learning Rate [0.00125]
12: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 74070 (53888)	Loss/tok 3.3574 (3.3786)	Learning Rate [0.00125]
2: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00098)	Tok/s 73221 (53078)	Loss/tok 3.5448 (3.3762)	Learning Rate [0.00125]
11: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 74164 (53796)	Loss/tok 3.4887 (3.3754)	Learning Rate [0.00125]
3: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00098)	Tok/s 73144 (53164)	Loss/tok 3.3519 (3.3737)	Learning Rate [0.00125]
10: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 74128 (53716)	Loss/tok 3.5764 (3.3740)	Learning Rate [0.00125]
4: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00092)	Tok/s 73196 (53245)	Loss/tok 3.3533 (3.3723)	Learning Rate [0.00125]
9: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00093)	Tok/s 74124 (53634)	Loss/tok 3.4889 (3.3796)	Learning Rate [0.00125]
5: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 73216 (53340)	Loss/tok 3.2944 (3.3787)	Learning Rate [0.00125]
8: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 74130 (53567)	Loss/tok 3.3434 (3.3715)	Learning Rate [0.00125]
6: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00100)	Tok/s 73855 (53409)	Loss/tok 3.2025 (3.3773)	Learning Rate [0.00125]
7: TRAIN [1][2400/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 73990 (53493)	Loss/tok 3.6202 (3.3709)	Learning Rate [0.00125]
15: Gradient norm: inf
14: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
13: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
12: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
10: Gradient norm: inf
4: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
8: Gradient norm: inf
7: Gradient norm: inf
6: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
7: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00093)	Tok/s 52430 (53503)	Loss/tok 3.3225 (3.3705)	Learning Rate [0.00125]
6: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00100)	Tok/s 52449 (53419)	Loss/tok 3.2652 (3.3771)	Learning Rate [0.00125]
8: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00097)	Tok/s 52469 (53578)	Loss/tok 3.2336 (3.3716)	Learning Rate [0.00125]
5: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00098)	Tok/s 52469 (53350)	Loss/tok 3.2932 (3.3785)	Learning Rate [0.00125]
9: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00093)	Tok/s 52436 (53645)	Loss/tok 3.5645 (3.3795)	Learning Rate [0.00125]
10: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00097)	Tok/s 52494 (53726)	Loss/tok 3.4638 (3.3740)	Learning Rate [0.00125]
4: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00122 (0.00092)	Tok/s 52456 (53256)	Loss/tok 3.3698 (3.3721)	Learning Rate [0.00125]
11: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00108 (0.00097)	Tok/s 53552 (53807)	Loss/tok 3.4004 (3.3751)	Learning Rate [0.00125]
3: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00113 (0.00098)	Tok/s 52455 (53175)	Loss/tok 3.3916 (3.3734)	Learning Rate [0.00125]
2: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00112 (0.00098)	Tok/s 52436 (53089)	Loss/tok 3.3149 (3.3760)	Learning Rate [0.00125]
12: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00109 (0.00097)	Tok/s 53552 (53899)	Loss/tok 3.4278 (3.3784)	Learning Rate [0.00125]
1: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00106 (0.00091)	Tok/s 52425 (52990)	Loss/tok 3.3484 (3.3762)	Learning Rate [0.00125]
0: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00092)	Tok/s 52414 (52895)	Loss/tok 3.2678 (3.3800)	Learning Rate [0.00125]
14: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00092)	Tok/s 53364 (54101)	Loss/tok 3.6621 (3.3739)	Learning Rate [0.00125]
13: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00099)	Tok/s 53459 (53998)	Loss/tok 3.4956 (3.3767)	Learning Rate [0.00125]
15: TRAIN [1][2410/3416]	Time 0.059 (0.058)	Data 0.00089 (0.00091)	Tok/s 53416 (54200)	Loss/tok 3.2218 (3.3723)	Learning Rate [0.00125]
9: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00093)	Tok/s 61362 (53638)	Loss/tok 3.5807 (3.3789)	Learning Rate [0.00125]
10: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00097)	Tok/s 61385 (53720)	Loss/tok 3.2706 (3.3733)	Learning Rate [0.00125]
8: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00097)	Tok/s 61271 (53570)	Loss/tok 3.3383 (3.3714)	Learning Rate [0.00125]
7: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00093)	Tok/s 61155 (53495)	Loss/tok 3.6422 (3.3702)	Learning Rate [0.00125]
11: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00097)	Tok/s 61275 (53800)	Loss/tok 3.5081 (3.3746)	Learning Rate [0.00125]
12: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00097)	Tok/s 61277 (53893)	Loss/tok 3.5516 (3.3780)	Learning Rate [0.00125]
6: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00100)	Tok/s 61052 (53411)	Loss/tok 3.4474 (3.3764)	Learning Rate [0.00125]
5: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00098)	Tok/s 60948 (53343)	Loss/tok 3.6494 (3.3781)	Learning Rate [0.00125]
4: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00092)	Tok/s 60870 (53247)	Loss/tok 3.4422 (3.3718)	Learning Rate [0.00125]
14: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00077 (0.00092)	Tok/s 60981 (54095)	Loss/tok 3.5512 (3.3733)	Learning Rate [0.00125]
13: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00099)	Tok/s 61070 (53992)	Loss/tok 3.4900 (3.3761)	Learning Rate [0.00125]
15: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00091)	Tok/s 61825 (54195)	Loss/tok 3.3230 (3.3717)	Learning Rate [0.00125]
0: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00092)	Tok/s 60827 (52884)	Loss/tok 3.3235 (3.3795)	Learning Rate [0.00125]
1: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00091)	Tok/s 60750 (52980)	Loss/tok 3.6376 (3.3758)	Learning Rate [0.00125]
2: TRAIN [1][2420/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00098)	Tok/s 60686 (53079)	Loss/tok 3.6224 (3.3755)	Learning Rate [0.00125]
3: TRAIN [1][2420/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00098)	Tok/s 60730 (53166)	Loss/tok 3.3876 (3.3729)	Learning Rate [0.00125]
5: TRAIN [1][2430/3416]	Time 0.040 (0.058)	Data 0.00096 (0.00098)	Tok/s 29662 (53307)	Loss/tok 2.6394 (3.3773)	Learning Rate [0.00125]
4: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00097 (0.00092)	Tok/s 28434 (53211)	Loss/tok 2.4062 (3.3711)	Learning Rate [0.00125]
6: TRAIN [1][2430/3416]	Time 0.040 (0.058)	Data 0.00091 (0.00100)	Tok/s 30066 (53376)	Loss/tok 2.9014 (3.3758)	Learning Rate [0.00125]
3: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00105 (0.00098)	Tok/s 28340 (53129)	Loss/tok 2.6810 (3.3725)	Learning Rate [0.00125]
2: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00111 (0.00098)	Tok/s 28240 (53043)	Loss/tok 2.6225 (3.3750)	Learning Rate [0.00125]
7: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00098 (0.00093)	Tok/s 29989 (53460)	Loss/tok 2.6128 (3.3696)	Learning Rate [0.00125]
8: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00102 (0.00097)	Tok/s 29949 (53535)	Loss/tok 2.7786 (3.3709)	Learning Rate [0.00125]
1: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00095 (0.00091)	Tok/s 28149 (52943)	Loss/tok 2.6244 (3.3753)	Learning Rate [0.00125]
14: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00101 (0.00092)	Tok/s 31207 (54061)	Loss/tok 2.6384 (3.3725)	Learning Rate [0.00125]
9: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00096 (0.00093)	Tok/s 29872 (53602)	Loss/tok 2.4724 (3.3784)	Learning Rate [0.00125]
0: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00105 (0.00092)	Tok/s 28090 (52848)	Loss/tok 2.3809 (3.3790)	Learning Rate [0.00125]
10: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00102 (0.00097)	Tok/s 29745 (53684)	Loss/tok 2.7052 (3.3727)	Learning Rate [0.00125]
15: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00108 (0.00091)	Tok/s 31141 (54160)	Loss/tok 2.9263 (3.3712)	Learning Rate [0.00125]
11: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00108 (0.00097)	Tok/s 29684 (53764)	Loss/tok 2.6308 (3.3739)	Learning Rate [0.00125]
12: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00115 (0.00097)	Tok/s 29633 (53857)	Loss/tok 2.7280 (3.3773)	Learning Rate [0.00125]
13: TRAIN [1][2430/3416]	Time 0.041 (0.058)	Data 0.00104 (0.00099)	Tok/s 30463 (53957)	Loss/tok 2.5933 (3.3754)	Learning Rate [0.00125]
3: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 86167 (53165)	Loss/tok 3.0453 (3.3720)	Learning Rate [0.00125]
10: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00097)	Tok/s 87943 (53721)	Loss/tok 3.1453 (3.3724)	Learning Rate [0.00125]
12: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00097)	Tok/s 88589 (53894)	Loss/tok 3.1391 (3.3768)	Learning Rate [0.00125]
2: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 85516 (53079)	Loss/tok 3.0725 (3.3747)	Learning Rate [0.00125]
4: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 86095 (53247)	Loss/tok 3.1034 (3.3707)	Learning Rate [0.00125]
11: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 88015 (53801)	Loss/tok 3.1997 (3.3735)	Learning Rate [0.00125]
9: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00093)	Tok/s 86901 (53638)	Loss/tok 3.0470 (3.3783)	Learning Rate [0.00125]
0: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 85416 (52884)	Loss/tok 3.0470 (3.3787)	Learning Rate [0.00125]
1: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00091)	Tok/s 85258 (52980)	Loss/tok 3.2706 (3.3748)	Learning Rate [0.00125]
14: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00092)	Tok/s 89628 (54098)	Loss/tok 3.1314 (3.3725)	Learning Rate [0.00125]
8: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 86776 (53571)	Loss/tok 3.0831 (3.3707)	Learning Rate [0.00125]
13: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00099)	Tok/s 88969 (53994)	Loss/tok 3.1285 (3.3754)	Learning Rate [0.00125]
7: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 86665 (53496)	Loss/tok 3.4733 (3.3696)	Learning Rate [0.00125]
15: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00091)	Tok/s 90410 (54197)	Loss/tok 3.2551 (3.3709)	Learning Rate [0.00125]
6: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00100)	Tok/s 85923 (53412)	Loss/tok 3.2057 (3.3755)	Learning Rate [0.00125]
5: TRAIN [1][2440/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 85831 (53342)	Loss/tok 3.1101 (3.3767)	Learning Rate [0.00125]
8: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00097)	Tok/s 49448 (53555)	Loss/tok 3.0466 (3.3705)	Learning Rate [0.00125]
9: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00079 (0.00093)	Tok/s 49494 (53623)	Loss/tok 3.3415 (3.3781)	Learning Rate [0.00125]
7: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00093)	Tok/s 49318 (53481)	Loss/tok 2.9052 (3.3691)	Learning Rate [0.00125]
10: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00097)	Tok/s 49331 (53706)	Loss/tok 3.1770 (3.3720)	Learning Rate [0.00125]
6: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00100)	Tok/s 49181 (53397)	Loss/tok 3.2291 (3.3752)	Learning Rate [0.00125]
5: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00098)	Tok/s 49131 (53328)	Loss/tok 3.1167 (3.3766)	Learning Rate [0.00125]
4: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00082 (0.00092)	Tok/s 49188 (53232)	Loss/tok 3.0050 (3.3702)	Learning Rate [0.00125]
11: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00097)	Tok/s 49451 (53786)	Loss/tok 3.2571 (3.3733)	Learning Rate [0.00125]
12: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00106 (0.00097)	Tok/s 49503 (53878)	Loss/tok 3.2541 (3.3767)	Learning Rate [0.00125]
3: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00103 (0.00098)	Tok/s 49219 (53151)	Loss/tok 3.0868 (3.3717)	Learning Rate [0.00125]
15: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00091)	Tok/s 50800 (54183)	Loss/tok 3.2731 (3.3708)	Learning Rate [0.00125]
14: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00092)	Tok/s 49595 (54083)	Loss/tok 3.2990 (3.3724)	Learning Rate [0.00125]
1: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00084 (0.00091)	Tok/s 49237 (52965)	Loss/tok 3.0863 (3.3744)	Learning Rate [0.00125]
2: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00113 (0.00098)	Tok/s 49148 (53065)	Loss/tok 3.1189 (3.3741)	Learning Rate [0.00125]
0: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00081 (0.00092)	Tok/s 49270 (52869)	Loss/tok 2.9494 (3.3783)	Learning Rate [0.00125]
13: TRAIN [1][2450/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00099)	Tok/s 49393 (53979)	Loss/tok 3.1498 (3.3750)	Learning Rate [0.00125]
2: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00098)	Tok/s 62127 (53065)	Loss/tok 3.5262 (3.3739)	Learning Rate [0.00125]
14: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00092)	Tok/s 63108 (54081)	Loss/tok 3.7685 (3.3723)	Learning Rate [0.00125]
15: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 63177 (54181)	Loss/tok 3.5662 (3.3708)	Learning Rate [0.00125]
4: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 61996 (53232)	Loss/tok 3.4204 (3.3701)	Learning Rate [0.00125]
0: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 62194 (52869)	Loss/tok 3.4338 (3.3781)	Learning Rate [0.00125]
1: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00091)	Tok/s 62115 (52965)	Loss/tok 3.6156 (3.3743)	Learning Rate [0.00125]
12: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00097)	Tok/s 62398 (53876)	Loss/tok 3.5234 (3.3767)	Learning Rate [0.00125]
3: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 62072 (53151)	Loss/tok 3.6897 (3.3718)	Learning Rate [0.00125]
5: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00098)	Tok/s 61996 (53327)	Loss/tok 3.6452 (3.3764)	Learning Rate [0.00125]
13: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00099)	Tok/s 62276 (53976)	Loss/tok 3.4445 (3.3751)	Learning Rate [0.00125]
11: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 62198 (53783)	Loss/tok 3.3822 (3.3732)	Learning Rate [0.00125]
6: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00100)	Tok/s 61973 (53397)	Loss/tok 3.2399 (3.3750)	Learning Rate [0.00125]
10: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 62126 (53704)	Loss/tok 3.4527 (3.3720)	Learning Rate [0.00125]
9: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00093)	Tok/s 62063 (53621)	Loss/tok 3.5559 (3.3781)	Learning Rate [0.00125]
8: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 61998 (53554)	Loss/tok 3.3695 (3.3704)	Learning Rate [0.00125]
7: TRAIN [1][2460/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00093)	Tok/s 61998 (53480)	Loss/tok 3.2811 (3.3689)	Learning Rate [0.00125]
9: TRAIN [1][2470/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00093)	Tok/s 42296 (53637)	Loss/tok 3.2704 (3.3780)	Learning Rate [0.00125]
8: TRAIN [1][2470/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00097)	Tok/s 42225 (53570)	Loss/tok 3.1226 (3.3706)	Learning Rate [0.00125]
10: TRAIN [1][2470/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00097)	Tok/s 42220 (53721)	Loss/tok 3.3257 (3.3720)	Learning Rate [0.00125]
6: TRAIN [1][2470/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00100)	Tok/s 41995 (53413)	Loss/tok 2.9043 (3.3744)	Learning Rate [0.00125]
11: TRAIN [1][2470/3416]	Time 0.048 (0.058)	Data 0.00094 (0.00097)	Tok/s 42269 (53801)	Loss/tok 2.9932 (3.3730)	Learning Rate [0.00125]
14: TRAIN [1][2470/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00092)	Tok/s 42171 (54097)	Loss/tok 3.2424 (3.3727)	Learning Rate [0.00125]
4: TRAIN [1][2470/3416]	Time 0.049 (0.058)	Data 0.00085 (0.00092)	Tok/s 41889 (53248)	Loss/tok 3.2928 (3.3702)	Learning Rate [0.00125]
7: TRAIN [1][2470/3416]	Time 0.049 (0.058)	Data 0.00122 (0.00093)	Tok/s 42215 (53496)	Loss/tok 3.2904 (3.3687)	Learning Rate [0.00125]
12: TRAIN [1][2470/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00097)	Tok/s 42270 (53893)	Loss/tok 3.2275 (3.3768)	Learning Rate [0.00125]
2: TRAIN [1][2470/3416]	Time 0.049 (0.058)	Data 0.00102 (0.00098)	Tok/s 41923 (53082)	Loss/tok 3.0684 (3.3734)	Learning Rate [0.00125]
15: TRAIN [1][2470/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00091)	Tok/s 42039 (54197)	Loss/tok 3.3151 (3.3709)	Learning Rate [0.00125]
1: TRAIN [1][2470/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00091)	Tok/s 41914 (52982)	Loss/tok 3.1794 (3.3743)	Learning Rate [0.00125]
0: TRAIN [1][2470/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00092)	Tok/s 41924 (52885)	Loss/tok 3.3323 (3.3779)	Learning Rate [0.00125]
3: TRAIN [1][2470/3416]	Time 0.049 (0.058)	Data 0.00096 (0.00098)	Tok/s 41928 (53167)	Loss/tok 3.1889 (3.3722)	Learning Rate [0.00125]
5: TRAIN [1][2470/3416]	Time 0.049 (0.058)	Data 0.00109 (0.00098)	Tok/s 41829 (53344)	Loss/tok 3.4563 (3.3762)	Learning Rate [0.00125]
13: TRAIN [1][2470/3416]	Time 0.049 (0.058)	Data 0.00114 (0.00099)	Tok/s 42160 (53992)	Loss/tok 3.4417 (3.3749)	Learning Rate [0.00125]
2: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00104 (0.00098)	Tok/s 48812 (53083)	Loss/tok 3.2811 (3.3732)	Learning Rate [0.00125]
3: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00098)	Tok/s 48755 (53169)	Loss/tok 2.9657 (3.3719)	Learning Rate [0.00125]
1: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00078 (0.00091)	Tok/s 48639 (52982)	Loss/tok 3.2242 (3.3740)	Learning Rate [0.00125]
0: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00076 (0.00092)	Tok/s 48514 (52886)	Loss/tok 3.1779 (3.3776)	Learning Rate [0.00125]
4: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00092)	Tok/s 48578 (53249)	Loss/tok 3.1260 (3.3703)	Learning Rate [0.00125]
5: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00083 (0.00098)	Tok/s 48542 (53344)	Loss/tok 3.1917 (3.3759)	Learning Rate [0.00125]
15: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00091)	Tok/s 49817 (54197)	Loss/tok 3.4177 (3.3709)	Learning Rate [0.00125]
14: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00081 (0.00092)	Tok/s 49845 (54097)	Loss/tok 3.0730 (3.3726)	Learning Rate [0.00125]
13: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00099)	Tok/s 49835 (53993)	Loss/tok 3.2415 (3.3749)	Learning Rate [0.00125]
6: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00100)	Tok/s 48678 (53413)	Loss/tok 3.2453 (3.3744)	Learning Rate [0.00125]
12: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00097)	Tok/s 49798 (53892)	Loss/tok 3.2293 (3.3766)	Learning Rate [0.00125]
11: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00097)	Tok/s 49671 (53801)	Loss/tok 3.2957 (3.3729)	Learning Rate [0.00125]
8: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00082 (0.00097)	Tok/s 49549 (53570)	Loss/tok 3.2371 (3.3705)	Learning Rate [0.00125]
10: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00097)	Tok/s 49611 (53721)	Loss/tok 3.5121 (3.3720)	Learning Rate [0.00125]
7: TRAIN [1][2480/3416]	Time 0.046 (0.058)	Data 0.00081 (0.00093)	Tok/s 49614 (53496)	Loss/tok 3.3554 (3.3688)	Learning Rate [0.00125]
9: TRAIN [1][2480/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00093)	Tok/s 49500 (53638)	Loss/tok 3.1646 (3.3783)	Learning Rate [0.00125]
2: TRAIN [1][2490/3416]	Time 0.050 (0.058)	Data 0.00107 (0.00098)	Tok/s 31881 (53060)	Loss/tok 2.8342 (3.3731)	Learning Rate [0.00125]
1: TRAIN [1][2490/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00091)	Tok/s 31764 (52960)	Loss/tok 2.6581 (3.3737)	Learning Rate [0.00125]
4: TRAIN [1][2490/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00092)	Tok/s 31825 (53227)	Loss/tok 3.3005 (3.3700)	Learning Rate [0.00125]
0: TRAIN [1][2490/3416]	Time 0.050 (0.058)	Data 0.00083 (0.00092)	Tok/s 31697 (52864)	Loss/tok 3.1513 (3.3773)	Learning Rate [0.00125]
3: TRAIN [1][2490/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00098)	Tok/s 31807 (53146)	Loss/tok 2.9419 (3.3715)	Learning Rate [0.00125]
15: TRAIN [1][2490/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00091)	Tok/s 32876 (54176)	Loss/tok 3.1150 (3.3708)	Learning Rate [0.00125]
5: TRAIN [1][2490/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00098)	Tok/s 31775 (53322)	Loss/tok 2.9966 (3.3756)	Learning Rate [0.00125]
14: TRAIN [1][2490/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00092)	Tok/s 32794 (54076)	Loss/tok 2.9080 (3.3721)	Learning Rate [0.00125]
6: TRAIN [1][2490/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00100)	Tok/s 31735 (53391)	Loss/tok 2.9861 (3.3742)	Learning Rate [0.00125]
7: TRAIN [1][2490/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00092)	Tok/s 31671 (53474)	Loss/tok 3.2621 (3.3685)	Learning Rate [0.00125]
13: TRAIN [1][2490/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00099)	Tok/s 32712 (53971)	Loss/tok 2.9399 (3.3747)	Learning Rate [0.00125]
8: TRAIN [1][2490/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00097)	Tok/s 31585 (53548)	Loss/tok 3.1673 (3.3702)	Learning Rate [0.00125]
11: TRAIN [1][2490/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00097)	Tok/s 31471 (53778)	Loss/tok 2.8350 (3.3724)	Learning Rate [0.00125]
10: TRAIN [1][2490/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00097)	Tok/s 31491 (53699)	Loss/tok 2.8783 (3.3719)	Learning Rate [0.00125]
12: TRAIN [1][2490/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00097)	Tok/s 31851 (53870)	Loss/tok 3.1663 (3.3764)	Learning Rate [0.00125]
9: TRAIN [1][2490/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00093)	Tok/s 31520 (53616)	Loss/tok 3.0374 (3.3781)	Learning Rate [0.00125]
4: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00092)	Tok/s 38745 (53234)	Loss/tok 3.0905 (3.3695)	Learning Rate [0.00125]
5: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00098)	Tok/s 38695 (53329)	Loss/tok 3.0601 (3.3754)	Learning Rate [0.00125]
3: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00098)	Tok/s 38746 (53152)	Loss/tok 3.2795 (3.3714)	Learning Rate [0.00125]
2: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00106 (0.00098)	Tok/s 38761 (53066)	Loss/tok 3.2695 (3.3728)	Learning Rate [0.00125]
6: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00100)	Tok/s 38591 (53397)	Loss/tok 3.3212 (3.3744)	Learning Rate [0.00125]
7: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00092)	Tok/s 38523 (53480)	Loss/tok 3.0413 (3.3682)	Learning Rate [0.00125]
1: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00091)	Tok/s 38727 (52966)	Loss/tok 2.8578 (3.3737)	Learning Rate [0.00125]
0: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00092)	Tok/s 38678 (52869)	Loss/tok 3.2672 (3.3771)	Learning Rate [0.00125]
8: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00101 (0.00097)	Tok/s 39560 (53555)	Loss/tok 3.0196 (3.3701)	Learning Rate [0.00125]
15: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00091)	Tok/s 39989 (54180)	Loss/tok 2.8747 (3.3705)	Learning Rate [0.00125]
14: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00092)	Tok/s 39839 (54081)	Loss/tok 3.1192 (3.3720)	Learning Rate [0.00125]
9: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00093)	Tok/s 39621 (53622)	Loss/tok 3.4322 (3.3780)	Learning Rate [0.00125]
10: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00099 (0.00097)	Tok/s 39534 (53704)	Loss/tok 3.1201 (3.3717)	Learning Rate [0.00125]
13: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00099)	Tok/s 39780 (53976)	Loss/tok 3.0799 (3.3746)	Learning Rate [0.00125]
12: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00097)	Tok/s 39664 (53876)	Loss/tok 3.0339 (3.3762)	Learning Rate [0.00125]
11: TRAIN [1][2500/3416]	Time 0.050 (0.058)	Data 0.00108 (0.00097)	Tok/s 39585 (53783)	Loss/tok 3.2238 (3.3724)	Learning Rate [0.00125]
1: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00084 (0.00091)	Tok/s 30734 (52951)	Loss/tok 2.7236 (3.3738)	Learning Rate [0.00125]
2: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00111 (0.00098)	Tok/s 31122 (53051)	Loss/tok 2.6267 (3.3726)	Learning Rate [0.00125]
4: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00079 (0.00092)	Tok/s 32034 (53219)	Loss/tok 2.7289 (3.3694)	Learning Rate [0.00125]
0: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00078 (0.00092)	Tok/s 30717 (52855)	Loss/tok 2.8083 (3.3773)	Learning Rate [0.00125]
3: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00098)	Tok/s 32089 (53138)	Loss/tok 3.0109 (3.3713)	Learning Rate [0.00125]
15: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00091)	Tok/s 33631 (54167)	Loss/tok 3.1518 (3.3705)	Learning Rate [0.00125]
5: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00098)	Tok/s 31947 (53314)	Loss/tok 2.7965 (3.3753)	Learning Rate [0.00125]
14: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00083 (0.00092)	Tok/s 32158 (54067)	Loss/tok 2.8786 (3.3719)	Learning Rate [0.00125]
12: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00097)	Tok/s 32119 (53861)	Loss/tok 2.8627 (3.3765)	Learning Rate [0.00125]
7: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00083 (0.00092)	Tok/s 31949 (53465)	Loss/tok 2.6994 (3.3683)	Learning Rate [0.00125]
13: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00085 (0.00099)	Tok/s 32123 (53961)	Loss/tok 2.7547 (3.3746)	Learning Rate [0.00125]
6: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00100)	Tok/s 31928 (53383)	Loss/tok 2.8418 (3.3741)	Learning Rate [0.00125]
10: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00097)	Tok/s 32002 (53690)	Loss/tok 2.8562 (3.3717)	Learning Rate [0.00125]
11: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00097)	Tok/s 31983 (53769)	Loss/tok 2.8124 (3.3722)	Learning Rate [0.00125]
8: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00097)	Tok/s 31947 (53541)	Loss/tok 2.7811 (3.3698)	Learning Rate [0.00125]
9: TRAIN [1][2510/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00093)	Tok/s 31926 (53608)	Loss/tok 3.0345 (3.3779)	Learning Rate [0.00125]
8: TRAIN [1][2520/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00097)	Tok/s 55073 (53533)	Loss/tok 3.3962 (3.3696)	Learning Rate [0.00125]
7: TRAIN [1][2520/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00092)	Tok/s 54982 (53458)	Loss/tok 3.5451 (3.3681)	Learning Rate [0.00125]
9: TRAIN [1][2520/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00093)	Tok/s 54959 (53600)	Loss/tok 3.4699 (3.3777)	Learning Rate [0.00125]
10: TRAIN [1][2520/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00097)	Tok/s 55058 (53682)	Loss/tok 3.7543 (3.3719)	Learning Rate [0.00125]
6: TRAIN [1][2520/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00100)	Tok/s 55054 (53375)	Loss/tok 3.5155 (3.3741)	Learning Rate [0.00125]
11: TRAIN [1][2520/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00097)	Tok/s 55066 (53761)	Loss/tok 3.2653 (3.3720)	Learning Rate [0.00125]
5: TRAIN [1][2520/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00098)	Tok/s 55045 (53307)	Loss/tok 3.4684 (3.3750)	Learning Rate [0.00125]
4: TRAIN [1][2520/3416]	Time 0.067 (0.058)	Data 0.00081 (0.00092)	Tok/s 55052 (53212)	Loss/tok 3.4755 (3.3693)	Learning Rate [0.00125]
12: TRAIN [1][2520/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00097)	Tok/s 55064 (53852)	Loss/tok 3.3205 (3.3761)	Learning Rate [0.00125]
3: TRAIN [1][2520/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00098)	Tok/s 55063 (53130)	Loss/tok 3.5498 (3.3714)	Learning Rate [0.00125]
14: TRAIN [1][2520/3416]	Time 0.067 (0.058)	Data 0.00076 (0.00092)	Tok/s 55029 (54057)	Loss/tok 3.4504 (3.3722)	Learning Rate [0.00125]
13: TRAIN [1][2520/3416]	Time 0.067 (0.058)	Data 0.00107 (0.00099)	Tok/s 55281 (53952)	Loss/tok 3.4378 (3.3743)	Learning Rate [0.00125]
2: TRAIN [1][2520/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00098)	Tok/s 54940 (53043)	Loss/tok 3.3386 (3.3726)	Learning Rate [0.00125]
1: TRAIN [1][2520/3416]	Time 0.067 (0.058)	Data 0.00081 (0.00091)	Tok/s 55024 (52943)	Loss/tok 3.6087 (3.3736)	Learning Rate [0.00125]
0: TRAIN [1][2520/3416]	Time 0.068 (0.058)	Data 0.00084 (0.00092)	Tok/s 54941 (52847)	Loss/tok 3.6013 (3.3769)	Learning Rate [0.00125]
15: TRAIN [1][2520/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00092)	Tok/s 55731 (54157)	Loss/tok 3.6432 (3.3703)	Learning Rate [0.00125]
13: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00099)	Tok/s 44440 (53931)	Loss/tok 2.9795 (3.3738)	Learning Rate [0.00125]
12: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00097)	Tok/s 43144 (53830)	Loss/tok 3.1121 (3.3759)	Learning Rate [0.00125]
14: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00086 (0.00092)	Tok/s 44477 (54036)	Loss/tok 3.1147 (3.3719)	Learning Rate [0.00125]
15: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00092)	Tok/s 44434 (54135)	Loss/tok 3.2030 (3.3699)	Learning Rate [0.00125]
11: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00097)	Tok/s 43040 (53739)	Loss/tok 2.9972 (3.3717)	Learning Rate [0.00125]
10: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00333 (0.00097)	Tok/s 43034 (53660)	Loss/tok 3.0007 (3.3716)	Learning Rate [0.00125]
0: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00092)	Tok/s 43042 (52828)	Loss/tok 3.1897 (3.3764)	Learning Rate [0.00125]
9: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00093)	Tok/s 43069 (53578)	Loss/tok 3.0329 (3.3776)	Learning Rate [0.00125]
1: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00087 (0.00091)	Tok/s 43075 (52923)	Loss/tok 3.3664 (3.3734)	Learning Rate [0.00125]
2: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00098)	Tok/s 43168 (53023)	Loss/tok 3.0425 (3.3723)	Learning Rate [0.00125]
8: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00097)	Tok/s 43046 (53511)	Loss/tok 3.4267 (3.3696)	Learning Rate [0.00125]
7: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00078 (0.00092)	Tok/s 43098 (53436)	Loss/tok 2.7207 (3.3676)	Learning Rate [0.00125]
4: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00078 (0.00092)	Tok/s 43082 (53191)	Loss/tok 3.2237 (3.3693)	Learning Rate [0.00125]
3: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00101 (0.00098)	Tok/s 43017 (53110)	Loss/tok 3.0126 (3.3712)	Learning Rate [0.00125]
6: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00089 (0.00100)	Tok/s 43084 (53354)	Loss/tok 3.1091 (3.3742)	Learning Rate [0.00125]
5: TRAIN [1][2530/3416]	Time 0.046 (0.058)	Data 0.00091 (0.00098)	Tok/s 43004 (53286)	Loss/tok 3.1447 (3.3746)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
13: Gradient norm: inf
12: Gradient norm: inf
14: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
1: Gradient norm: inf
12: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 81596 (53853)	Loss/tok 3.1270 (3.3757)	Learning Rate [0.00125]
13: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00099)	Tok/s 81536 (53953)	Loss/tok 3.1949 (3.3735)	Learning Rate [0.00125]
9: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
14: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00092)	Tok/s 81444 (54058)	Loss/tok 3.1669 (3.3717)	Learning Rate [0.00125]
11: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 81618 (53761)	Loss/tok 3.3991 (3.3716)	Learning Rate [0.00125]
2: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
15: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 81424 (54158)	Loss/tok 3.1838 (3.3698)	Learning Rate [0.00125]
8: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
10: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 81557 (53682)	Loss/tok 3.3077 (3.3713)	Learning Rate [0.00125]
7: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
0: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 79328 (52851)	Loss/tok 3.2954 (3.3764)	Learning Rate [0.00125]
3: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
9: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00093)	Tok/s 81515 (53601)	Loss/tok 3.1897 (3.3772)	Learning Rate [0.00125]
5: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
1: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00091)	Tok/s 79335 (52946)	Loss/tok 3.3844 (3.3734)	Learning Rate [0.00125]
5: Skipped batch, new scale: 1024.0
2: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00098)	Tok/s 80044 (53046)	Loss/tok 3.2023 (3.3723)	Learning Rate [0.00125]
8: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 80693 (53534)	Loss/tok 3.1989 (3.3694)	Learning Rate [0.00125]
6: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00100)	Tok/s 80214 (53376)	Loss/tok 3.4316 (3.3741)	Learning Rate [0.00125]
3: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 80074 (53132)	Loss/tok 3.3495 (3.3712)	Learning Rate [0.00125]
7: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00092)	Tok/s 80339 (53458)	Loss/tok 3.2659 (3.3676)	Learning Rate [0.00125]
4: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 80008 (53213)	Loss/tok 3.1709 (3.3686)	Learning Rate [0.00125]
5: TRAIN [1][2540/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 80005 (53308)	Loss/tok 3.3445 (3.3743)	Learning Rate [0.00125]
12: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00090 (0.00097)	Tok/s 50552 (53858)	Loss/tok 3.3011 (3.3752)	Learning Rate [0.00125]
11: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00103 (0.00097)	Tok/s 50505 (53765)	Loss/tok 3.4618 (3.3716)	Learning Rate [0.00125]
10: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00097)	Tok/s 50538 (53687)	Loss/tok 3.4404 (3.3713)	Learning Rate [0.00125]
14: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00092)	Tok/s 50330 (54063)	Loss/tok 3.2259 (3.3715)	Learning Rate [0.00125]
13: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00099)	Tok/s 50373 (53958)	Loss/tok 3.2414 (3.3732)	Learning Rate [0.00125]
9: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00093)	Tok/s 50579 (53605)	Loss/tok 3.2518 (3.3767)	Learning Rate [0.00125]
15: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00080 (0.00091)	Tok/s 50189 (54163)	Loss/tok 3.0908 (3.3694)	Learning Rate [0.00125]
8: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00097)	Tok/s 50574 (53538)	Loss/tok 3.2020 (3.3694)	Learning Rate [0.00125]
0: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00092)	Tok/s 48884 (52856)	Loss/tok 3.5229 (3.3760)	Learning Rate [0.00125]
1: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00083 (0.00091)	Tok/s 48910 (52951)	Loss/tok 3.1383 (3.3731)	Learning Rate [0.00125]
7: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00092)	Tok/s 50573 (53463)	Loss/tok 3.4183 (3.3677)	Learning Rate [0.00125]
2: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00096 (0.00098)	Tok/s 48934 (53051)	Loss/tok 3.2225 (3.3721)	Learning Rate [0.00125]
6: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00100)	Tok/s 50513 (53381)	Loss/tok 3.1258 (3.3738)	Learning Rate [0.00125]
4: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00084 (0.00092)	Tok/s 49565 (53219)	Loss/tok 3.4371 (3.3683)	Learning Rate [0.00125]
3: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00092 (0.00098)	Tok/s 48934 (53138)	Loss/tok 3.1093 (3.3712)	Learning Rate [0.00125]
5: TRAIN [1][2550/3416]	Time 0.048 (0.058)	Data 0.00091 (0.00098)	Tok/s 50335 (53313)	Loss/tok 3.2041 (3.3739)	Learning Rate [0.00125]
13: TRAIN [1][2560/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00099)	Tok/s 58053 (53957)	Loss/tok 3.3706 (3.3733)	Learning Rate [0.00125]
12: TRAIN [1][2560/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00097)	Tok/s 58027 (53857)	Loss/tok 3.2668 (3.3751)	Learning Rate [0.00125]
14: TRAIN [1][2560/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00092)	Tok/s 57955 (54062)	Loss/tok 3.4107 (3.3716)	Learning Rate [0.00125]
11: TRAIN [1][2560/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00097)	Tok/s 57993 (53765)	Loss/tok 3.5436 (3.3718)	Learning Rate [0.00125]
10: TRAIN [1][2560/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00097)	Tok/s 57927 (53686)	Loss/tok 3.2660 (3.3714)	Learning Rate [0.00125]
15: TRAIN [1][2560/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00091)	Tok/s 57806 (54162)	Loss/tok 3.4304 (3.3693)	Learning Rate [0.00125]
0: TRAIN [1][2560/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00092)	Tok/s 56877 (52856)	Loss/tok 3.5224 (3.3762)	Learning Rate [0.00125]
1: TRAIN [1][2560/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00091)	Tok/s 56853 (52951)	Loss/tok 3.4300 (3.3734)	Learning Rate [0.00125]
2: TRAIN [1][2560/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00098)	Tok/s 56802 (53051)	Loss/tok 3.6908 (3.3722)	Learning Rate [0.00125]
9: TRAIN [1][2560/3416]	Time 0.067 (0.058)	Data 0.00122 (0.00093)	Tok/s 57887 (53605)	Loss/tok 3.3896 (3.3766)	Learning Rate [0.00125]
8: TRAIN [1][2560/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00097)	Tok/s 57070 (53538)	Loss/tok 3.3503 (3.3692)	Learning Rate [0.00125]
7: TRAIN [1][2560/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00092)	Tok/s 56862 (53463)	Loss/tok 3.3500 (3.3677)	Learning Rate [0.00125]
4: TRAIN [1][2560/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00092)	Tok/s 56857 (53219)	Loss/tok 3.4353 (3.3685)	Learning Rate [0.00125]
3: TRAIN [1][2560/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00098)	Tok/s 56841 (53138)	Loss/tok 3.6268 (3.3709)	Learning Rate [0.00125]
6: TRAIN [1][2560/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00100)	Tok/s 56831 (53381)	Loss/tok 3.6294 (3.3739)	Learning Rate [0.00125]
5: TRAIN [1][2560/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00098)	Tok/s 56674 (53313)	Loss/tok 3.6195 (3.3742)	Learning Rate [0.00125]
0: TRAIN [1][2570/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00092)	Tok/s 37080 (52859)	Loss/tok 3.1029 (3.3763)	Learning Rate [0.00125]
14: TRAIN [1][2570/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00092)	Tok/s 38344 (54063)	Loss/tok 3.0250 (3.3714)	Learning Rate [0.00125]
15: TRAIN [1][2570/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00091)	Tok/s 38354 (54162)	Loss/tok 3.4559 (3.3695)	Learning Rate [0.00125]
1: TRAIN [1][2570/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00091)	Tok/s 36992 (52954)	Loss/tok 2.8714 (3.3731)	Learning Rate [0.00125]
4: TRAIN [1][2570/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00092)	Tok/s 36932 (53220)	Loss/tok 3.4573 (3.3686)	Learning Rate [0.00125]
2: TRAIN [1][2570/3416]	Time 0.050 (0.058)	Data 0.00098 (0.00098)	Tok/s 36938 (53053)	Loss/tok 2.9563 (3.3721)	Learning Rate [0.00125]
3: TRAIN [1][2570/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00098)	Tok/s 36932 (53140)	Loss/tok 3.1015 (3.3709)	Learning Rate [0.00125]
13: TRAIN [1][2570/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00099)	Tok/s 38234 (53958)	Loss/tok 3.2002 (3.3730)	Learning Rate [0.00125]
5: TRAIN [1][2570/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00098)	Tok/s 37428 (53314)	Loss/tok 3.4769 (3.3744)	Learning Rate [0.00125]
12: TRAIN [1][2570/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00097)	Tok/s 38153 (53858)	Loss/tok 3.2801 (3.3749)	Learning Rate [0.00125]
11: TRAIN [1][2570/3416]	Time 0.050 (0.058)	Data 0.00105 (0.00097)	Tok/s 38071 (53766)	Loss/tok 3.2645 (3.3719)	Learning Rate [0.00125]
6: TRAIN [1][2570/3416]	Time 0.050 (0.058)	Data 0.00100 (0.00100)	Tok/s 38029 (53382)	Loss/tok 3.1239 (3.3739)	Learning Rate [0.00125]
10: TRAIN [1][2570/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00097)	Tok/s 38041 (53688)	Loss/tok 3.0009 (3.3712)	Learning Rate [0.00125]
9: TRAIN [1][2570/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00093)	Tok/s 37992 (53606)	Loss/tok 3.1048 (3.3766)	Learning Rate [0.00125]
7: TRAIN [1][2570/3416]	Time 0.051 (0.058)	Data 0.00101 (0.00092)	Tok/s 37951 (53464)	Loss/tok 2.9010 (3.3674)	Learning Rate [0.00125]
8: TRAIN [1][2570/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00097)	Tok/s 37936 (53539)	Loss/tok 3.1866 (3.3692)	Learning Rate [0.00125]
12: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 60426 (53882)	Loss/tok 3.4875 (3.3744)	Learning Rate [0.00125]
15: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00091)	Tok/s 60200 (54188)	Loss/tok 3.5387 (3.3690)	Learning Rate [0.00125]
11: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00097)	Tok/s 60352 (53790)	Loss/tok 3.2915 (3.3714)	Learning Rate [0.00125]
10: TRAIN [1][2580/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00097)	Tok/s 61170 (53711)	Loss/tok 3.4850 (3.3708)	Learning Rate [0.00125]
0: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 60171 (52881)	Loss/tok 3.1947 (3.3757)	Learning Rate [0.00125]
14: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 60117 (54088)	Loss/tok 3.5338 (3.3706)	Learning Rate [0.00125]
13: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00099)	Tok/s 60204 (53983)	Loss/tok 3.2960 (3.3724)	Learning Rate [0.00125]
9: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00093)	Tok/s 60323 (53629)	Loss/tok 3.5826 (3.3761)	Learning Rate [0.00125]
8: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 60202 (53562)	Loss/tok 3.1802 (3.3686)	Learning Rate [0.00125]
7: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 60206 (53486)	Loss/tok 3.4597 (3.3669)	Learning Rate [0.00125]
3: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 60178 (53162)	Loss/tok 3.4362 (3.3704)	Learning Rate [0.00125]
5: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 60008 (53336)	Loss/tok 3.6025 (3.3737)	Learning Rate [0.00125]
6: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00100)	Tok/s 60082 (53404)	Loss/tok 3.5704 (3.3737)	Learning Rate [0.00125]
2: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 60008 (53075)	Loss/tok 3.3992 (3.3715)	Learning Rate [0.00125]
1: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00091)	Tok/s 60177 (52975)	Loss/tok 3.7017 (3.3727)	Learning Rate [0.00125]
4: TRAIN [1][2580/3416]	Time 0.069 (0.058)	Data 0.00114 (0.00092)	Tok/s 60188 (53242)	Loss/tok 3.3474 (3.3683)	Learning Rate [0.00125]
10: TRAIN [1][2590/3416]	Time 0.050 (0.058)	Data 0.00107 (0.00097)	Tok/s 36933 (53688)	Loss/tok 3.2533 (3.3703)	Learning Rate [0.00125]
11: TRAIN [1][2590/3416]	Time 0.050 (0.058)	Data 0.00104 (0.00097)	Tok/s 36895 (53766)	Loss/tok 3.1895 (3.3708)	Learning Rate [0.00125]
12: TRAIN [1][2590/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00097)	Tok/s 36813 (53859)	Loss/tok 3.0782 (3.3741)	Learning Rate [0.00125]
9: TRAIN [1][2590/3416]	Time 0.050 (0.058)	Data 0.00079 (0.00093)	Tok/s 36808 (53605)	Loss/tok 3.1835 (3.3757)	Learning Rate [0.00125]
13: TRAIN [1][2590/3416]	Time 0.051 (0.058)	Data 0.00106 (0.00099)	Tok/s 36719 (53960)	Loss/tok 3.2749 (3.3720)	Learning Rate [0.00125]
8: TRAIN [1][2590/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00097)	Tok/s 36761 (53538)	Loss/tok 3.1523 (3.3683)	Learning Rate [0.00125]
14: TRAIN [1][2590/3416]	Time 0.051 (0.058)	Data 0.00087 (0.00092)	Tok/s 36651 (54064)	Loss/tok 3.3121 (3.3701)	Learning Rate [0.00125]
7: TRAIN [1][2590/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00092)	Tok/s 36673 (53462)	Loss/tok 2.9258 (3.3667)	Learning Rate [0.00125]
15: TRAIN [1][2590/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00091)	Tok/s 36671 (54165)	Loss/tok 3.1213 (3.3688)	Learning Rate [0.00125]
0: TRAIN [1][2590/3416]	Time 0.051 (0.058)	Data 0.00086 (0.00092)	Tok/s 36668 (52852)	Loss/tok 2.8307 (3.3752)	Learning Rate [0.00125]
6: TRAIN [1][2590/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00100)	Tok/s 36681 (53380)	Loss/tok 2.9507 (3.3730)	Learning Rate [0.00125]
5: TRAIN [1][2590/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00098)	Tok/s 36676 (53311)	Loss/tok 3.1568 (3.3731)	Learning Rate [0.00125]
1: TRAIN [1][2590/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00091)	Tok/s 36668 (52948)	Loss/tok 3.2208 (3.3721)	Learning Rate [0.00125]
4: TRAIN [1][2590/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 36657 (53216)	Loss/tok 3.1510 (3.3681)	Learning Rate [0.00125]
2: TRAIN [1][2590/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00098)	Tok/s 36684 (53048)	Loss/tok 2.9887 (3.3713)	Learning Rate [0.00125]
3: TRAIN [1][2590/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00098)	Tok/s 36660 (53135)	Loss/tok 2.9124 (3.3699)	Learning Rate [0.00125]
0: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 69619 (52907)	Loss/tok 3.5414 (3.3754)	Learning Rate [0.00125]
2: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 69704 (53104)	Loss/tok 3.2669 (3.3713)	Learning Rate [0.00125]
1: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00091)	Tok/s 69686 (53003)	Loss/tok 3.3792 (3.3722)	Learning Rate [0.00125]
4: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00092)	Tok/s 69586 (53272)	Loss/tok 3.3586 (3.3689)	Learning Rate [0.00125]
3: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00098)	Tok/s 69687 (53191)	Loss/tok 3.5043 (3.3702)	Learning Rate [0.00125]
15: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00091)	Tok/s 70376 (54220)	Loss/tok 3.3766 (3.3693)	Learning Rate [0.00125]
5: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00098)	Tok/s 69563 (53367)	Loss/tok 3.6060 (3.3732)	Learning Rate [0.00125]
14: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 70239 (54119)	Loss/tok 3.3552 (3.3704)	Learning Rate [0.00125]
13: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00099)	Tok/s 70191 (54015)	Loss/tok 3.3943 (3.3719)	Learning Rate [0.00125]
6: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00100)	Tok/s 69396 (53435)	Loss/tok 3.4757 (3.3732)	Learning Rate [0.00125]
12: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 70082 (53915)	Loss/tok 3.2844 (3.3744)	Learning Rate [0.00125]
11: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00097)	Tok/s 70029 (53821)	Loss/tok 3.2854 (3.3709)	Learning Rate [0.00125]
8: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 69869 (53594)	Loss/tok 3.4671 (3.3690)	Learning Rate [0.00125]
7: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 69323 (53518)	Loss/tok 3.4070 (3.3670)	Learning Rate [0.00125]
9: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 70052 (53660)	Loss/tok 3.4794 (3.3755)	Learning Rate [0.00125]
10: TRAIN [1][2600/3416]	Time 0.070 (0.058)	Data 0.00117 (0.00097)	Tok/s 70101 (53743)	Loss/tok 3.5610 (3.3709)	Learning Rate [0.00125]
5: TRAIN [1][2610/3416]	Time 0.038 (0.058)	Data 0.00094 (0.00098)	Tok/s 27218 (53344)	Loss/tok 2.5337 (3.3730)	Learning Rate [0.00125]
6: TRAIN [1][2610/3416]	Time 0.037 (0.058)	Data 0.00098 (0.00100)	Tok/s 27356 (53413)	Loss/tok 2.9310 (3.3728)	Learning Rate [0.00125]
7: TRAIN [1][2610/3416]	Time 0.037 (0.058)	Data 0.00086 (0.00092)	Tok/s 27788 (53496)	Loss/tok 2.4064 (3.3667)	Learning Rate [0.00125]
4: TRAIN [1][2610/3416]	Time 0.038 (0.058)	Data 0.00093 (0.00092)	Tok/s 27211 (53250)	Loss/tok 2.6194 (3.3685)	Learning Rate [0.00125]
8: TRAIN [1][2610/3416]	Time 0.037 (0.058)	Data 0.00099 (0.00097)	Tok/s 29068 (53573)	Loss/tok 2.4792 (3.3685)	Learning Rate [0.00125]
2: TRAIN [1][2610/3416]	Time 0.038 (0.058)	Data 0.00086 (0.00098)	Tok/s 25430 (53080)	Loss/tok 2.4594 (3.3708)	Learning Rate [0.00125]
9: TRAIN [1][2610/3416]	Time 0.037 (0.058)	Data 0.00087 (0.00093)	Tok/s 29083 (53639)	Loss/tok 2.5664 (3.3752)	Learning Rate [0.00125]
3: TRAIN [1][2610/3416]	Time 0.038 (0.058)	Data 0.00099 (0.00098)	Tok/s 25829 (53168)	Loss/tok 2.3046 (3.3698)	Learning Rate [0.00125]
10: TRAIN [1][2610/3416]	Time 0.037 (0.058)	Data 0.00103 (0.00097)	Tok/s 29068 (53721)	Loss/tok 2.4631 (3.3705)	Learning Rate [0.00125]
1: TRAIN [1][2610/3416]	Time 0.038 (0.058)	Data 0.00107 (0.00091)	Tok/s 25413 (52979)	Loss/tok 2.1064 (3.3718)	Learning Rate [0.00125]
0: TRAIN [1][2610/3416]	Time 0.038 (0.058)	Data 0.00087 (0.00092)	Tok/s 25448 (52883)	Loss/tok 2.2681 (3.3751)	Learning Rate [0.00125]
11: TRAIN [1][2610/3416]	Time 0.037 (0.058)	Data 0.00088 (0.00097)	Tok/s 29031 (53800)	Loss/tok 2.4938 (3.3705)	Learning Rate [0.00125]
15: TRAIN [1][2610/3416]	Time 0.038 (0.058)	Data 0.00083 (0.00091)	Tok/s 30515 (54199)	Loss/tok 2.6914 (3.3693)	Learning Rate [0.00125]
12: TRAIN [1][2610/3416]	Time 0.037 (0.058)	Data 0.00105 (0.00097)	Tok/s 29025 (53893)	Loss/tok 2.4106 (3.3740)	Learning Rate [0.00125]
13: TRAIN [1][2610/3416]	Time 0.038 (0.058)	Data 0.00103 (0.00099)	Tok/s 29752 (53994)	Loss/tok 2.3272 (3.3715)	Learning Rate [0.00125]
14: TRAIN [1][2610/3416]	Time 0.038 (0.058)	Data 0.00082 (0.00092)	Tok/s 30442 (54099)	Loss/tok 2.6662 (3.3703)	Learning Rate [0.00125]
4: TRAIN [1][2620/3416]	Time 0.067 (0.058)	Data 0.00099 (0.00092)	Tok/s 55984 (53235)	Loss/tok 3.4106 (3.3682)	Learning Rate [0.00125]
3: TRAIN [1][2620/3416]	Time 0.067 (0.058)	Data 0.00106 (0.00098)	Tok/s 55999 (53153)	Loss/tok 3.4540 (3.3696)	Learning Rate [0.00125]
2: TRAIN [1][2620/3416]	Time 0.067 (0.058)	Data 0.00103 (0.00098)	Tok/s 55994 (53065)	Loss/tok 3.3952 (3.3705)	Learning Rate [0.00125]
6: TRAIN [1][2620/3416]	Time 0.068 (0.058)	Data 0.00112 (0.00100)	Tok/s 55920 (53399)	Loss/tok 3.2738 (3.3725)	Learning Rate [0.00125]
1: TRAIN [1][2620/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00091)	Tok/s 56005 (52963)	Loss/tok 3.3516 (3.3715)	Learning Rate [0.00125]
0: TRAIN [1][2620/3416]	Time 0.067 (0.058)	Data 0.00085 (0.00092)	Tok/s 56044 (52866)	Loss/tok 3.5388 (3.3750)	Learning Rate [0.00125]
5: TRAIN [1][2620/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00098)	Tok/s 55959 (53330)	Loss/tok 3.2752 (3.3727)	Learning Rate [0.00125]
8: TRAIN [1][2620/3416]	Time 0.068 (0.058)	Data 0.00106 (0.00097)	Tok/s 55933 (53559)	Loss/tok 3.3715 (3.3684)	Learning Rate [0.00125]
7: TRAIN [1][2620/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00092)	Tok/s 55895 (53482)	Loss/tok 3.6929 (3.3662)	Learning Rate [0.00125]
15: TRAIN [1][2620/3416]	Time 0.067 (0.058)	Data 0.00082 (0.00091)	Tok/s 56044 (54186)	Loss/tok 3.6135 (3.3692)	Learning Rate [0.00125]
14: TRAIN [1][2620/3416]	Time 0.067 (0.058)	Data 0.00084 (0.00092)	Tok/s 56053 (54085)	Loss/tok 3.7236 (3.3701)	Learning Rate [0.00125]
10: TRAIN [1][2620/3416]	Time 0.067 (0.058)	Data 0.00107 (0.00097)	Tok/s 55951 (53707)	Loss/tok 3.2030 (3.3701)	Learning Rate [0.00125]
9: TRAIN [1][2620/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00093)	Tok/s 55918 (53625)	Loss/tok 3.5259 (3.3749)	Learning Rate [0.00125]
13: TRAIN [1][2620/3416]	Time 0.067 (0.058)	Data 0.00111 (0.00099)	Tok/s 56095 (53980)	Loss/tok 3.4789 (3.3714)	Learning Rate [0.00125]
12: TRAIN [1][2620/3416]	Time 0.067 (0.058)	Data 0.00114 (0.00097)	Tok/s 56049 (53879)	Loss/tok 3.5596 (3.3739)	Learning Rate [0.00125]
11: TRAIN [1][2620/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00097)	Tok/s 55956 (53785)	Loss/tok 3.2927 (3.3700)	Learning Rate [0.00125]
4: TRAIN [1][2630/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00092)	Tok/s 54260 (53257)	Loss/tok 3.4541 (3.3680)	Learning Rate [0.000625]
3: TRAIN [1][2630/3416]	Time 0.066 (0.058)	Data 0.00087 (0.00098)	Tok/s 54197 (53174)	Loss/tok 3.5021 (3.3694)	Learning Rate [0.000625]
2: TRAIN [1][2630/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00098)	Tok/s 54119 (53086)	Loss/tok 3.5921 (3.3705)	Learning Rate [0.000625]
5: TRAIN [1][2630/3416]	Time 0.066 (0.058)	Data 0.00101 (0.00098)	Tok/s 54359 (53352)	Loss/tok 3.1959 (3.3729)	Learning Rate [0.000625]
1: TRAIN [1][2630/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00091)	Tok/s 54021 (52984)	Loss/tok 3.3904 (3.3716)	Learning Rate [0.000625]
6: TRAIN [1][2630/3416]	Time 0.066 (0.058)	Data 0.00102 (0.00100)	Tok/s 54138 (53420)	Loss/tok 3.3319 (3.3720)	Learning Rate [0.000625]
7: TRAIN [1][2630/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00092)	Tok/s 54054 (53503)	Loss/tok 3.3324 (3.3661)	Learning Rate [0.000625]
0: TRAIN [1][2630/3416]	Time 0.066 (0.058)	Data 0.00079 (0.00092)	Tok/s 53926 (52887)	Loss/tok 3.3207 (3.3749)	Learning Rate [0.000625]
8: TRAIN [1][2630/3416]	Time 0.066 (0.058)	Data 0.00098 (0.00097)	Tok/s 53968 (53580)	Loss/tok 3.8201 (3.3686)	Learning Rate [0.000625]
15: TRAIN [1][2630/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00091)	Tok/s 54757 (54206)	Loss/tok 3.5840 (3.3689)	Learning Rate [0.000625]
14: TRAIN [1][2630/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00092)	Tok/s 54658 (54106)	Loss/tok 3.4901 (3.3700)	Learning Rate [0.000625]
9: TRAIN [1][2630/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00093)	Tok/s 53851 (53646)	Loss/tok 3.4744 (3.3747)	Learning Rate [0.000625]
11: TRAIN [1][2630/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00097)	Tok/s 54641 (53806)	Loss/tok 3.3002 (3.3699)	Learning Rate [0.000625]
13: TRAIN [1][2630/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00099)	Tok/s 54619 (54001)	Loss/tok 3.5099 (3.3716)	Learning Rate [0.000625]
10: TRAIN [1][2630/3416]	Time 0.067 (0.058)	Data 0.00100 (0.00097)	Tok/s 53759 (53728)	Loss/tok 3.5195 (3.3702)	Learning Rate [0.000625]
12: TRAIN [1][2630/3416]	Time 0.067 (0.058)	Data 0.00105 (0.00097)	Tok/s 54620 (53899)	Loss/tok 3.3299 (3.3743)	Learning Rate [0.000625]
4: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00087 (0.00092)	Tok/s 29639 (53279)	Loss/tok 2.8145 (3.3684)	Learning Rate [0.000625]
5: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00098)	Tok/s 30387 (53374)	Loss/tok 2.9198 (3.3731)	Learning Rate [0.000625]
7: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00085 (0.00092)	Tok/s 30452 (53524)	Loss/tok 3.0058 (3.3663)	Learning Rate [0.000625]
6: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00098 (0.00100)	Tok/s 30417 (53442)	Loss/tok 2.5831 (3.3716)	Learning Rate [0.000625]
3: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00085 (0.00098)	Tok/s 28628 (53195)	Loss/tok 2.7046 (3.3697)	Learning Rate [0.000625]
2: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00086 (0.00098)	Tok/s 28531 (53108)	Loss/tok 2.5399 (3.3704)	Learning Rate [0.000625]
8: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00094 (0.00097)	Tok/s 30384 (53601)	Loss/tok 2.5899 (3.3687)	Learning Rate [0.000625]
1: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00089 (0.00091)	Tok/s 28515 (53006)	Loss/tok 2.7951 (3.3719)	Learning Rate [0.000625]
0: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00077 (0.00092)	Tok/s 28511 (52909)	Loss/tok 2.7563 (3.3750)	Learning Rate [0.000625]
11: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00096 (0.00097)	Tok/s 30217 (53827)	Loss/tok 2.4808 (3.3697)	Learning Rate [0.000625]
9: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00089 (0.00093)	Tok/s 30374 (53667)	Loss/tok 2.8389 (3.3752)	Learning Rate [0.000625]
10: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00114 (0.00097)	Tok/s 30295 (53749)	Loss/tok 2.5803 (3.3702)	Learning Rate [0.000625]
12: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00101 (0.00097)	Tok/s 30975 (53921)	Loss/tok 2.5823 (3.3742)	Learning Rate [0.000625]
15: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00081 (0.00091)	Tok/s 31695 (54228)	Loss/tok 2.5806 (3.3690)	Learning Rate [0.000625]
14: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00076 (0.00092)	Tok/s 31686 (54128)	Loss/tok 2.6505 (3.3701)	Learning Rate [0.000625]
13: TRAIN [1][2640/3416]	Time 0.040 (0.058)	Data 0.00104 (0.00099)	Tok/s 31664 (54023)	Loss/tok 2.9119 (3.3716)	Learning Rate [0.000625]
5: TRAIN [1][2650/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00098)	Tok/s 51623 (53361)	Loss/tok 3.3167 (3.3731)	Learning Rate [0.000625]
4: TRAIN [1][2650/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00092)	Tok/s 51583 (53267)	Loss/tok 3.2177 (3.3682)	Learning Rate [0.000625]
6: TRAIN [1][2650/3416]	Time 0.052 (0.058)	Data 0.00098 (0.00100)	Tok/s 51474 (53429)	Loss/tok 3.1641 (3.3711)	Learning Rate [0.000625]
3: TRAIN [1][2650/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00098)	Tok/s 51530 (53183)	Loss/tok 3.1252 (3.3695)	Learning Rate [0.000625]
7: TRAIN [1][2650/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00092)	Tok/s 51342 (53512)	Loss/tok 3.2968 (3.3660)	Learning Rate [0.000625]
1: TRAIN [1][2650/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00091)	Tok/s 51486 (52994)	Loss/tok 3.3692 (3.3716)	Learning Rate [0.000625]
0: TRAIN [1][2650/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00092)	Tok/s 51453 (52897)	Loss/tok 3.4382 (3.3746)	Learning Rate [0.000625]
9: TRAIN [1][2650/3416]	Time 0.053 (0.058)	Data 0.00094 (0.00093)	Tok/s 51112 (53656)	Loss/tok 3.3711 (3.3748)	Learning Rate [0.000625]
8: TRAIN [1][2650/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00097)	Tok/s 51237 (53589)	Loss/tok 3.4607 (3.3682)	Learning Rate [0.000625]
10: TRAIN [1][2650/3416]	Time 0.053 (0.058)	Data 0.00100 (0.00097)	Tok/s 51037 (53737)	Loss/tok 3.3208 (3.3699)	Learning Rate [0.000625]
15: TRAIN [1][2650/3416]	Time 0.052 (0.058)	Data 0.00079 (0.00091)	Tok/s 51875 (54217)	Loss/tok 3.4206 (3.3685)	Learning Rate [0.000625]
11: TRAIN [1][2650/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00097)	Tok/s 51009 (53816)	Loss/tok 3.3540 (3.3694)	Learning Rate [0.000625]
14: TRAIN [1][2650/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00092)	Tok/s 51186 (54116)	Loss/tok 3.4389 (3.3696)	Learning Rate [0.000625]
12: TRAIN [1][2650/3416]	Time 0.053 (0.058)	Data 0.00107 (0.00097)	Tok/s 51031 (53909)	Loss/tok 3.5013 (3.3739)	Learning Rate [0.000625]
13: TRAIN [1][2650/3416]	Time 0.053 (0.058)	Data 0.00109 (0.00099)	Tok/s 51093 (54012)	Loss/tok 3.1833 (3.3710)	Learning Rate [0.000625]
2: TRAIN [1][2650/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00098)	Tok/s 51566 (53095)	Loss/tok 3.1108 (3.3700)	Learning Rate [0.000625]
4: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 62826 (53277)	Loss/tok 3.4423 (3.3683)	Learning Rate [0.000625]
3: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00081 (0.00098)	Tok/s 62428 (53193)	Loss/tok 3.5295 (3.3696)	Learning Rate [0.000625]
2: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00098)	Tok/s 62443 (53106)	Loss/tok 3.4835 (3.3702)	Learning Rate [0.000625]
5: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 63208 (53372)	Loss/tok 3.4492 (3.3728)	Learning Rate [0.000625]
1: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00091)	Tok/s 62499 (53005)	Loss/tok 3.4038 (3.3714)	Learning Rate [0.000625]
6: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00100)	Tok/s 63105 (53440)	Loss/tok 3.9649 (3.3712)	Learning Rate [0.000625]
10: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00097)	Tok/s 63047 (53748)	Loss/tok 3.1848 (3.3694)	Learning Rate [0.000625]
15: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00091)	Tok/s 63321 (54226)	Loss/tok 3.3096 (3.3683)	Learning Rate [0.000625]
7: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 62989 (53522)	Loss/tok 3.2695 (3.3657)	Learning Rate [0.000625]
8: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00109 (0.00097)	Tok/s 62892 (53599)	Loss/tok 3.1377 (3.3679)	Learning Rate [0.000625]
11: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 63030 (53827)	Loss/tok 3.4190 (3.3694)	Learning Rate [0.000625]
14: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00092)	Tok/s 63229 (54126)	Loss/tok 3.8144 (3.3694)	Learning Rate [0.000625]
9: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00093)	Tok/s 62949 (53666)	Loss/tok 3.8055 (3.3750)	Learning Rate [0.000625]
12: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00097)	Tok/s 63078 (53920)	Loss/tok 3.6547 (3.3739)	Learning Rate [0.000625]
13: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00106 (0.00099)	Tok/s 63171 (54022)	Loss/tok 3.5422 (3.3708)	Learning Rate [0.000625]
0: TRAIN [1][2660/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 62416 (52908)	Loss/tok 3.5194 (3.3743)	Learning Rate [0.000625]
15: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
7: TRAIN [1][2670/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 33664 (53517)	Loss/tok 3.0517 (3.3658)	Learning Rate [0.000625]
6: TRAIN [1][2670/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00100)	Tok/s 33657 (53435)	Loss/tok 3.1563 (3.3710)	Learning Rate [0.000625]
5: TRAIN [1][2670/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00098)	Tok/s 33657 (53368)	Loss/tok 3.0063 (3.3727)	Learning Rate [0.000625]
4: TRAIN [1][2670/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 33640 (53273)	Loss/tok 3.1115 (3.3681)	Learning Rate [0.000625]
10: TRAIN [1][2670/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00097)	Tok/s 33446 (53743)	Loss/tok 3.1265 (3.3692)	Learning Rate [0.000625]
9: TRAIN [1][2670/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00093)	Tok/s 33473 (53661)	Loss/tok 2.8615 (3.3747)	Learning Rate [0.000625]
2: TRAIN [1][2670/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00098)	Tok/s 33522 (53102)	Loss/tok 2.8675 (3.3699)	Learning Rate [0.000625]
3: TRAIN [1][2670/3416]	Time 0.051 (0.058)	Data 0.00107 (0.00098)	Tok/s 33598 (53189)	Loss/tok 2.9881 (3.3694)	Learning Rate [0.000625]
12: TRAIN [1][2670/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00097)	Tok/s 33276 (53914)	Loss/tok 2.9936 (3.3737)	Learning Rate [0.000625]
1: TRAIN [1][2670/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00091)	Tok/s 33447 (53001)	Loss/tok 3.0309 (3.3712)	Learning Rate [0.000625]
14: TRAIN [1][2670/3416]	Time 0.052 (0.058)	Data 0.00079 (0.00092)	Tok/s 34470 (54121)	Loss/tok 3.1769 (3.3693)	Learning Rate [0.000625]
13: TRAIN [1][2670/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00099)	Tok/s 33290 (54017)	Loss/tok 2.9659 (3.3707)	Learning Rate [0.000625]
15: TRAIN [1][2670/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00091)	Tok/s 34574 (54222)	Loss/tok 3.1422 (3.3682)	Learning Rate [0.000625]
0: TRAIN [1][2670/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00092)	Tok/s 33379 (52904)	Loss/tok 2.8789 (3.3741)	Learning Rate [0.000625]
8: TRAIN [1][2670/3416]	Time 0.052 (0.058)	Data 0.00110 (0.00097)	Tok/s 33017 (53594)	Loss/tok 3.1151 (3.3679)	Learning Rate [0.000625]
11: TRAIN [1][2670/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00097)	Tok/s 32816 (53821)	Loss/tok 3.1872 (3.3698)	Learning Rate [0.000625]
7: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 70332 (53555)	Loss/tok 3.4227 (3.3657)	Learning Rate [0.000625]
8: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 70258 (53632)	Loss/tok 3.3953 (3.3680)	Learning Rate [0.000625]
9: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00093)	Tok/s 70177 (53699)	Loss/tok 3.4471 (3.3749)	Learning Rate [0.000625]
4: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 70185 (53312)	Loss/tok 3.2573 (3.3680)	Learning Rate [0.000625]
6: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00100)	Tok/s 70308 (53473)	Loss/tok 3.3018 (3.3709)	Learning Rate [0.000625]
5: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00098)	Tok/s 70259 (53406)	Loss/tok 3.3414 (3.3727)	Learning Rate [0.000625]
10: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 70049 (53781)	Loss/tok 3.4688 (3.3693)	Learning Rate [0.000625]
12: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 71171 (53953)	Loss/tok 3.1299 (3.3734)	Learning Rate [0.000625]
3: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00098)	Tok/s 70143 (53227)	Loss/tok 3.2565 (3.3693)	Learning Rate [0.000625]
11: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 70160 (53860)	Loss/tok 3.4509 (3.3694)	Learning Rate [0.000625]
1: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00091)	Tok/s 70210 (53039)	Loss/tok 3.5511 (3.3709)	Learning Rate [0.000625]
2: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00098)	Tok/s 70062 (53140)	Loss/tok 3.3351 (3.3697)	Learning Rate [0.000625]
14: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00092)	Tok/s 71103 (54159)	Loss/tok 3.6143 (3.3697)	Learning Rate [0.000625]
13: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00099)	Tok/s 71072 (54054)	Loss/tok 3.5316 (3.3707)	Learning Rate [0.000625]
15: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00086 (0.00091)	Tok/s 71041 (54259)	Loss/tok 3.3943 (3.3679)	Learning Rate [0.000625]
0: TRAIN [1][2680/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 69859 (52943)	Loss/tok 3.5875 (3.3744)	Learning Rate [0.000625]
12: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00097)	Tok/s 79627 (53962)	Loss/tok 3.3687 (3.3733)	Learning Rate [0.000625]
11: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 79538 (53869)	Loss/tok 3.3238 (3.3692)	Learning Rate [0.000625]
13: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00099)	Tok/s 79640 (54064)	Loss/tok 3.0268 (3.3704)	Learning Rate [0.000625]
10: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00097)	Tok/s 78931 (53790)	Loss/tok 3.3298 (3.3692)	Learning Rate [0.000625]
14: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00092)	Tok/s 79402 (54168)	Loss/tok 3.2119 (3.3695)	Learning Rate [0.000625]
9: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00093)	Tok/s 78542 (53708)	Loss/tok 3.4316 (3.3749)	Learning Rate [0.000625]
15: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 79481 (54268)	Loss/tok 3.3004 (3.3678)	Learning Rate [0.000625]
8: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 78537 (53641)	Loss/tok 3.2331 (3.3680)	Learning Rate [0.000625]
7: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 78537 (53565)	Loss/tok 3.2048 (3.3653)	Learning Rate [0.000625]
3: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 78405 (53238)	Loss/tok 3.3001 (3.3692)	Learning Rate [0.000625]
2: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00098)	Tok/s 77463 (53151)	Loss/tok 3.5421 (3.3697)	Learning Rate [0.000625]
6: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00100)	Tok/s 78459 (53483)	Loss/tok 3.0025 (3.3705)	Learning Rate [0.000625]
5: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00098)	Tok/s 78482 (53416)	Loss/tok 3.0851 (3.3725)	Learning Rate [0.000625]
0: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00092)	Tok/s 77524 (52953)	Loss/tok 3.1160 (3.3740)	Learning Rate [0.000625]
1: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00114 (0.00091)	Tok/s 77607 (53050)	Loss/tok 3.1555 (3.3706)	Learning Rate [0.000625]
4: TRAIN [1][2690/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00092)	Tok/s 78517 (53321)	Loss/tok 3.4884 (3.3679)	Learning Rate [0.000625]
14: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 37137 (54152)	Loss/tok 3.1107 (3.3696)	Learning Rate [0.000625]
13: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00099)	Tok/s 37151 (54048)	Loss/tok 2.9638 (3.3703)	Learning Rate [0.000625]
12: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00097)	Tok/s 37077 (53946)	Loss/tok 3.0622 (3.3734)	Learning Rate [0.000625]
11: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00097)	Tok/s 37006 (53854)	Loss/tok 3.2129 (3.3692)	Learning Rate [0.000625]
15: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00077 (0.00091)	Tok/s 37050 (54252)	Loss/tok 3.0001 (3.3677)	Learning Rate [0.000625]
10: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00097)	Tok/s 36924 (53774)	Loss/tok 2.9045 (3.3690)	Learning Rate [0.000625]
0: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00092)	Tok/s 35738 (52938)	Loss/tok 3.3023 (3.3736)	Learning Rate [0.000625]
1: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00091)	Tok/s 35715 (53035)	Loss/tok 3.2963 (3.3703)	Learning Rate [0.000625]
8: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00097)	Tok/s 36895 (53626)	Loss/tok 3.1057 (3.3678)	Learning Rate [0.000625]
9: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00093)	Tok/s 36870 (53692)	Loss/tok 3.0864 (3.3749)	Learning Rate [0.000625]
7: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00092)	Tok/s 36862 (53549)	Loss/tok 3.0244 (3.3651)	Learning Rate [0.000625]
2: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00104 (0.00098)	Tok/s 35710 (53136)	Loss/tok 2.9491 (3.3698)	Learning Rate [0.000625]
3: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00098)	Tok/s 36518 (53223)	Loss/tok 3.2096 (3.3691)	Learning Rate [0.000625]
4: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00092)	Tok/s 36901 (53307)	Loss/tok 3.1425 (3.3679)	Learning Rate [0.000625]
6: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00100)	Tok/s 36864 (53467)	Loss/tok 3.1537 (3.3704)	Learning Rate [0.000625]
5: TRAIN [1][2700/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00098)	Tok/s 36886 (53401)	Loss/tok 3.0182 (3.3724)	Learning Rate [0.000625]
2: TRAIN [1][2710/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00098)	Tok/s 51329 (53116)	Loss/tok 3.1299 (3.3691)	Learning Rate [0.000625]
1: TRAIN [1][2710/3416]	Time 0.051 (0.058)	Data 0.00080 (0.00091)	Tok/s 51179 (53013)	Loss/tok 3.2846 (3.3700)	Learning Rate [0.000625]
0: TRAIN [1][2710/3416]	Time 0.051 (0.058)	Data 0.00083 (0.00091)	Tok/s 51115 (52913)	Loss/tok 3.2491 (3.3735)	Learning Rate [0.000625]
15: TRAIN [1][2710/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00091)	Tok/s 52211 (54240)	Loss/tok 3.1730 (3.3671)	Learning Rate [0.000625]
3: TRAIN [1][2710/3416]	Time 0.051 (0.058)	Data 0.00107 (0.00098)	Tok/s 51318 (53203)	Loss/tok 3.4307 (3.3682)	Learning Rate [0.000625]
4: TRAIN [1][2710/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00092)	Tok/s 51255 (53289)	Loss/tok 3.1754 (3.3675)	Learning Rate [0.000625]
14: TRAIN [1][2710/3416]	Time 0.050 (0.058)	Data 0.00109 (0.00092)	Tok/s 53240 (54139)	Loss/tok 3.3863 (3.3691)	Learning Rate [0.000625]
5: TRAIN [1][2710/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00098)	Tok/s 51275 (53384)	Loss/tok 3.5773 (3.3718)	Learning Rate [0.000625]
12: TRAIN [1][2710/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00097)	Tok/s 52286 (53932)	Loss/tok 3.2926 (3.3730)	Learning Rate [0.000625]
6: TRAIN [1][2710/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00100)	Tok/s 51255 (53451)	Loss/tok 3.5126 (3.3701)	Learning Rate [0.000625]
7: TRAIN [1][2710/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00092)	Tok/s 51995 (53534)	Loss/tok 3.1234 (3.3643)	Learning Rate [0.000625]
13: TRAIN [1][2710/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00099)	Tok/s 52177 (54035)	Loss/tok 3.5128 (3.3697)	Learning Rate [0.000625]
8: TRAIN [1][2710/3416]	Time 0.051 (0.058)	Data 0.00100 (0.00097)	Tok/s 52365 (53612)	Loss/tok 3.0962 (3.3671)	Learning Rate [0.000625]
9: TRAIN [1][2710/3416]	Time 0.051 (0.058)	Data 0.00085 (0.00093)	Tok/s 52260 (53678)	Loss/tok 3.2570 (3.3744)	Learning Rate [0.000625]
10: TRAIN [1][2710/3416]	Time 0.051 (0.058)	Data 0.00095 (0.00097)	Tok/s 52203 (53760)	Loss/tok 3.4131 (3.3685)	Learning Rate [0.000625]
11: TRAIN [1][2710/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00097)	Tok/s 51749 (53839)	Loss/tok 3.1523 (3.3686)	Learning Rate [0.000625]
10: TRAIN [1][2720/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00097)	Tok/s 54030 (53762)	Loss/tok 3.4745 (3.3682)	Learning Rate [0.000625]
11: TRAIN [1][2720/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00097)	Tok/s 53896 (53841)	Loss/tok 3.2913 (3.3684)	Learning Rate [0.000625]
12: TRAIN [1][2720/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00097)	Tok/s 53890 (53934)	Loss/tok 3.2729 (3.3729)	Learning Rate [0.000625]
9: TRAIN [1][2720/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00093)	Tok/s 54071 (53680)	Loss/tok 3.4913 (3.3741)	Learning Rate [0.000625]
8: TRAIN [1][2720/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00097)	Tok/s 54071 (53614)	Loss/tok 3.0600 (3.3668)	Learning Rate [0.000625]
7: TRAIN [1][2720/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00092)	Tok/s 54046 (53536)	Loss/tok 3.2841 (3.3644)	Learning Rate [0.000625]
13: TRAIN [1][2720/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00099)	Tok/s 53722 (54036)	Loss/tok 3.3873 (3.3696)	Learning Rate [0.000625]
14: TRAIN [1][2720/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00092)	Tok/s 53705 (54140)	Loss/tok 3.3161 (3.3690)	Learning Rate [0.000625]
6: TRAIN [1][2720/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00099)	Tok/s 54065 (53454)	Loss/tok 3.3167 (3.3699)	Learning Rate [0.000625]
15: TRAIN [1][2720/3416]	Time 0.060 (0.058)	Data 0.00084 (0.00091)	Tok/s 53763 (54241)	Loss/tok 3.4035 (3.3669)	Learning Rate [0.000625]
4: TRAIN [1][2720/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00092)	Tok/s 53990 (53291)	Loss/tok 3.3877 (3.3673)	Learning Rate [0.000625]
5: TRAIN [1][2720/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00098)	Tok/s 54024 (53386)	Loss/tok 3.3303 (3.3716)	Learning Rate [0.000625]
0: TRAIN [1][2720/3416]	Time 0.060 (0.058)	Data 0.00080 (0.00091)	Tok/s 53686 (52916)	Loss/tok 3.2658 (3.3735)	Learning Rate [0.000625]
1: TRAIN [1][2720/3416]	Time 0.060 (0.058)	Data 0.00090 (0.00091)	Tok/s 53765 (53016)	Loss/tok 3.3323 (3.3698)	Learning Rate [0.000625]
2: TRAIN [1][2720/3416]	Time 0.059 (0.058)	Data 0.00104 (0.00098)	Tok/s 53803 (53118)	Loss/tok 3.3878 (3.3691)	Learning Rate [0.000625]
3: TRAIN [1][2720/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00098)	Tok/s 53874 (53205)	Loss/tok 3.2255 (3.3681)	Learning Rate [0.000625]
1: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00091)	Tok/s 56808 (53027)	Loss/tok 3.4011 (3.3697)	Learning Rate [0.000625]
2: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00099 (0.00098)	Tok/s 56767 (53129)	Loss/tok 3.4486 (3.3687)	Learning Rate [0.000625]
0: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00091)	Tok/s 56718 (52927)	Loss/tok 3.2979 (3.3735)	Learning Rate [0.000625]
4: TRAIN [1][2730/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00092)	Tok/s 56899 (53301)	Loss/tok 3.3931 (3.3668)	Learning Rate [0.000625]
15: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00091)	Tok/s 57547 (54250)	Loss/tok 3.6052 (3.3670)	Learning Rate [0.000625]
3: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00098)	Tok/s 56815 (53216)	Loss/tok 3.5286 (3.3681)	Learning Rate [0.000625]
14: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00092)	Tok/s 57484 (54149)	Loss/tok 3.1650 (3.3688)	Learning Rate [0.000625]
12: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 56948 (53943)	Loss/tok 3.5505 (3.3729)	Learning Rate [0.000625]
5: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00111 (0.00098)	Tok/s 56838 (53396)	Loss/tok 3.3727 (3.3714)	Learning Rate [0.000625]
7: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00082 (0.00092)	Tok/s 56822 (53546)	Loss/tok 3.4559 (3.3642)	Learning Rate [0.000625]
13: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00099)	Tok/s 57487 (54045)	Loss/tok 3.2686 (3.3695)	Learning Rate [0.000625]
6: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00099)	Tok/s 56783 (53464)	Loss/tok 3.5380 (3.3698)	Learning Rate [0.000625]
9: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00093)	Tok/s 56689 (53689)	Loss/tok 3.2741 (3.3739)	Learning Rate [0.000625]
11: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00097)	Tok/s 56529 (53850)	Loss/tok 3.3469 (3.3682)	Learning Rate [0.000625]
8: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00097)	Tok/s 56701 (53623)	Loss/tok 3.2827 (3.3665)	Learning Rate [0.000625]
10: TRAIN [1][2730/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00097)	Tok/s 56521 (53770)	Loss/tok 3.4154 (3.3684)	Learning Rate [0.000625]
2: TRAIN [1][2740/3416]	Time 0.069 (0.058)	Data 0.00108 (0.00098)	Tok/s 67396 (53140)	Loss/tok 3.7176 (3.3688)	Learning Rate [0.000625]
4: TRAIN [1][2740/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00092)	Tok/s 67218 (53312)	Loss/tok 3.3133 (3.3667)	Learning Rate [0.000625]
1: TRAIN [1][2740/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00091)	Tok/s 67304 (53037)	Loss/tok 3.1924 (3.3696)	Learning Rate [0.000625]
3: TRAIN [1][2740/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 67212 (53227)	Loss/tok 3.6482 (3.3679)	Learning Rate [0.000625]
0: TRAIN [1][2740/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00091)	Tok/s 67281 (52938)	Loss/tok 3.5108 (3.3734)	Learning Rate [0.000625]
15: TRAIN [1][2740/3416]	Time 0.070 (0.058)	Data 0.00104 (0.00091)	Tok/s 68139 (54261)	Loss/tok 3.4094 (3.3665)	Learning Rate [0.000625]
14: TRAIN [1][2740/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00092)	Tok/s 68034 (54160)	Loss/tok 3.5343 (3.3689)	Learning Rate [0.000625]
11: TRAIN [1][2740/3416]	Time 0.070 (0.058)	Data 0.00105 (0.00097)	Tok/s 67896 (53860)	Loss/tok 3.4598 (3.3683)	Learning Rate [0.000625]
6: TRAIN [1][2740/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00099)	Tok/s 66951 (53474)	Loss/tok 3.2627 (3.3695)	Learning Rate [0.000625]
8: TRAIN [1][2740/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 67674 (53634)	Loss/tok 3.4924 (3.3663)	Learning Rate [0.000625]
9: TRAIN [1][2740/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00093)	Tok/s 67682 (53699)	Loss/tok 3.3870 (3.3739)	Learning Rate [0.000625]
7: TRAIN [1][2740/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00092)	Tok/s 66922 (53556)	Loss/tok 3.2177 (3.3641)	Learning Rate [0.000625]
13: TRAIN [1][2740/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00099)	Tok/s 67828 (54056)	Loss/tok 3.3799 (3.3695)	Learning Rate [0.000625]
5: TRAIN [1][2740/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 66929 (53407)	Loss/tok 3.4262 (3.3710)	Learning Rate [0.000625]
10: TRAIN [1][2740/3416]	Time 0.070 (0.058)	Data 0.00114 (0.00097)	Tok/s 67495 (53781)	Loss/tok 3.3228 (3.3682)	Learning Rate [0.000625]
12: TRAIN [1][2740/3416]	Time 0.070 (0.058)	Data 0.00111 (0.00097)	Tok/s 67528 (53952)	Loss/tok 3.6271 (3.3729)	Learning Rate [0.000625]
5: TRAIN [1][2750/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00098)	Tok/s 57872 (53403)	Loss/tok 3.7153 (3.3708)	Learning Rate [0.000625]
4: TRAIN [1][2750/3416]	Time 0.066 (0.058)	Data 0.00083 (0.00092)	Tok/s 57811 (53308)	Loss/tok 3.2933 (3.3665)	Learning Rate [0.000625]
6: TRAIN [1][2750/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00099)	Tok/s 57866 (53470)	Loss/tok 3.3488 (3.3693)	Learning Rate [0.000625]
2: TRAIN [1][2750/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00098)	Tok/s 57354 (53136)	Loss/tok 3.2875 (3.3688)	Learning Rate [0.000625]
3: TRAIN [1][2750/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00098)	Tok/s 57662 (53223)	Loss/tok 3.2058 (3.3678)	Learning Rate [0.000625]
7: TRAIN [1][2750/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00092)	Tok/s 57872 (53552)	Loss/tok 3.3382 (3.3641)	Learning Rate [0.000625]
14: TRAIN [1][2750/3416]	Time 0.066 (0.058)	Data 0.00087 (0.00092)	Tok/s 57845 (54155)	Loss/tok 3.4758 (3.3689)	Learning Rate [0.000625]
8: TRAIN [1][2750/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00097)	Tok/s 57874 (53630)	Loss/tok 3.5653 (3.3660)	Learning Rate [0.000625]
1: TRAIN [1][2750/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00091)	Tok/s 56731 (53034)	Loss/tok 3.4062 (3.3695)	Learning Rate [0.000625]
13: TRAIN [1][2750/3416]	Time 0.066 (0.058)	Data 0.00106 (0.00099)	Tok/s 57876 (54051)	Loss/tok 3.3411 (3.3694)	Learning Rate [0.000625]
0: TRAIN [1][2750/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00091)	Tok/s 56732 (52934)	Loss/tok 3.3700 (3.3731)	Learning Rate [0.000625]
15: TRAIN [1][2750/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00091)	Tok/s 57794 (54257)	Loss/tok 3.4466 (3.3662)	Learning Rate [0.000625]
12: TRAIN [1][2750/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00097)	Tok/s 57878 (53948)	Loss/tok 3.2471 (3.3727)	Learning Rate [0.000625]
9: TRAIN [1][2750/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00093)	Tok/s 57889 (53695)	Loss/tok 3.4062 (3.3737)	Learning Rate [0.000625]
10: TRAIN [1][2750/3416]	Time 0.066 (0.058)	Data 0.00087 (0.00097)	Tok/s 57905 (53776)	Loss/tok 3.3597 (3.3680)	Learning Rate [0.000625]
11: TRAIN [1][2750/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00097)	Tok/s 57899 (53856)	Loss/tok 3.3329 (3.3680)	Learning Rate [0.000625]
12: TRAIN [1][2760/3416]	Time 0.050 (0.058)	Data 0.00093 (0.00097)	Tok/s 51700 (53943)	Loss/tok 3.6002 (3.3727)	Learning Rate [0.000625]
11: TRAIN [1][2760/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00097)	Tok/s 51712 (53851)	Loss/tok 3.1419 (3.3680)	Learning Rate [0.000625]
10: TRAIN [1][2760/3416]	Time 0.050 (0.058)	Data 0.00087 (0.00097)	Tok/s 51711 (53771)	Loss/tok 3.0216 (3.3676)	Learning Rate [0.000625]
13: TRAIN [1][2760/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00099)	Tok/s 51707 (54046)	Loss/tok 3.4282 (3.3691)	Learning Rate [0.000625]
14: TRAIN [1][2760/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00092)	Tok/s 51769 (54150)	Loss/tok 3.1668 (3.3684)	Learning Rate [0.000625]
15: TRAIN [1][2760/3416]	Time 0.049 (0.058)	Data 0.00101 (0.00091)	Tok/s 51769 (54251)	Loss/tok 3.3333 (3.3661)	Learning Rate [0.000625]
9: TRAIN [1][2760/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00093)	Tok/s 51725 (53690)	Loss/tok 3.2050 (3.3733)	Learning Rate [0.000625]
0: TRAIN [1][2760/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00091)	Tok/s 50465 (52928)	Loss/tok 3.1984 (3.3730)	Learning Rate [0.000625]
8: TRAIN [1][2760/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00097)	Tok/s 51699 (53625)	Loss/tok 3.5283 (3.3657)	Learning Rate [0.000625]
7: TRAIN [1][2760/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00092)	Tok/s 51732 (53547)	Loss/tok 3.0476 (3.3638)	Learning Rate [0.000625]
1: TRAIN [1][2760/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00091)	Tok/s 50429 (53027)	Loss/tok 3.1183 (3.3691)	Learning Rate [0.000625]
2: TRAIN [1][2760/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00098)	Tok/s 50414 (53130)	Loss/tok 2.9588 (3.3686)	Learning Rate [0.000625]
4: TRAIN [1][2760/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00092)	Tok/s 51721 (53303)	Loss/tok 3.3168 (3.3662)	Learning Rate [0.000625]
6: TRAIN [1][2760/3416]	Time 0.050 (0.058)	Data 0.00103 (0.00099)	Tok/s 51652 (53465)	Loss/tok 3.2062 (3.3691)	Learning Rate [0.000625]
5: TRAIN [1][2760/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00098)	Tok/s 51673 (53398)	Loss/tok 3.2677 (3.3707)	Learning Rate [0.000625]
3: TRAIN [1][2760/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00098)	Tok/s 50650 (53218)	Loss/tok 3.2799 (3.3674)	Learning Rate [0.000625]
14: TRAIN [1][2770/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00092)	Tok/s 53682 (54153)	Loss/tok 3.3237 (3.3685)	Learning Rate [0.000625]
13: TRAIN [1][2770/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00099)	Tok/s 53671 (54049)	Loss/tok 3.4104 (3.3691)	Learning Rate [0.000625]
12: TRAIN [1][2770/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00097)	Tok/s 53562 (53947)	Loss/tok 3.5030 (3.3725)	Learning Rate [0.000625]
10: TRAIN [1][2770/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00097)	Tok/s 53464 (53775)	Loss/tok 3.6114 (3.3678)	Learning Rate [0.000625]
11: TRAIN [1][2770/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00097)	Tok/s 53477 (53854)	Loss/tok 3.3704 (3.3679)	Learning Rate [0.000625]
15: TRAIN [1][2770/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00091)	Tok/s 53601 (54254)	Loss/tok 3.6118 (3.3662)	Learning Rate [0.000625]
0: TRAIN [1][2770/3416]	Time 0.064 (0.058)	Data 0.00087 (0.00091)	Tok/s 52599 (52932)	Loss/tok 3.3787 (3.3730)	Learning Rate [0.000625]
1: TRAIN [1][2770/3416]	Time 0.064 (0.058)	Data 0.00081 (0.00091)	Tok/s 52604 (53031)	Loss/tok 3.2971 (3.3687)	Learning Rate [0.000625]
8: TRAIN [1][2770/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00097)	Tok/s 53299 (53628)	Loss/tok 3.2976 (3.3656)	Learning Rate [0.000625]
2: TRAIN [1][2770/3416]	Time 0.065 (0.058)	Data 0.00086 (0.00098)	Tok/s 52541 (53134)	Loss/tok 3.4258 (3.3684)	Learning Rate [0.000625]
9: TRAIN [1][2770/3416]	Time 0.065 (0.058)	Data 0.00084 (0.00093)	Tok/s 53276 (53694)	Loss/tok 3.4847 (3.3732)	Learning Rate [0.000625]
7: TRAIN [1][2770/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00092)	Tok/s 53289 (53551)	Loss/tok 3.3401 (3.3638)	Learning Rate [0.000625]
4: TRAIN [1][2770/3416]	Time 0.065 (0.058)	Data 0.00085 (0.00092)	Tok/s 52376 (53306)	Loss/tok 3.5822 (3.3662)	Learning Rate [0.000625]
3: TRAIN [1][2770/3416]	Time 0.065 (0.058)	Data 0.00090 (0.00098)	Tok/s 52542 (53221)	Loss/tok 3.1265 (3.3673)	Learning Rate [0.000625]
6: TRAIN [1][2770/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00099)	Tok/s 52552 (53469)	Loss/tok 3.3059 (3.3694)	Learning Rate [0.000625]
5: TRAIN [1][2770/3416]	Time 0.065 (0.058)	Data 0.00093 (0.00098)	Tok/s 52342 (53401)	Loss/tok 3.1795 (3.3705)	Learning Rate [0.000625]
13: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00100 (0.00099)	Tok/s 56099 (54065)	Loss/tok 3.2935 (3.3687)	Learning Rate [0.000625]
12: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00095 (0.00097)	Tok/s 56063 (53963)	Loss/tok 3.3857 (3.3726)	Learning Rate [0.000625]
14: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00083 (0.00092)	Tok/s 56059 (54169)	Loss/tok 3.3186 (3.3681)	Learning Rate [0.000625]
11: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00097)	Tok/s 56100 (53870)	Loss/tok 3.6451 (3.3678)	Learning Rate [0.000625]
15: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00100 (0.00091)	Tok/s 56084 (54270)	Loss/tok 3.1564 (3.3661)	Learning Rate [0.000625]
10: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00097)	Tok/s 56061 (53790)	Loss/tok 3.3460 (3.3677)	Learning Rate [0.000625]
0: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00091)	Tok/s 55045 (52949)	Loss/tok 3.5316 (3.3730)	Learning Rate [0.000625]
1: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00091)	Tok/s 55065 (53048)	Loss/tok 3.3257 (3.3686)	Learning Rate [0.000625]
9: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00093)	Tok/s 56070 (53710)	Loss/tok 3.5432 (3.3729)	Learning Rate [0.000625]
8: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00098 (0.00097)	Tok/s 56065 (53644)	Loss/tok 3.3494 (3.3656)	Learning Rate [0.000625]
2: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00105 (0.00098)	Tok/s 55083 (53150)	Loss/tok 3.3318 (3.3683)	Learning Rate [0.000625]
7: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00099 (0.00092)	Tok/s 56067 (53567)	Loss/tok 3.1548 (3.3637)	Learning Rate [0.000625]
4: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00097 (0.00092)	Tok/s 55066 (53322)	Loss/tok 3.2556 (3.3660)	Learning Rate [0.000625]
6: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00104 (0.00099)	Tok/s 55968 (53485)	Loss/tok 3.4494 (3.3689)	Learning Rate [0.000625]
3: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00109 (0.00098)	Tok/s 55025 (53238)	Loss/tok 3.3320 (3.3671)	Learning Rate [0.000625]
5: TRAIN [1][2780/3416]	Time 0.064 (0.058)	Data 0.00101 (0.00098)	Tok/s 55033 (53417)	Loss/tok 3.6761 (3.3703)	Learning Rate [0.000625]
0: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00084 (0.00091)	Tok/s 34147 (52967)	Loss/tok 2.8598 (3.3728)	Learning Rate [0.000625]
15: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00091)	Tok/s 35381 (54286)	Loss/tok 3.0720 (3.3660)	Learning Rate [0.000625]
1: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00091)	Tok/s 34184 (53066)	Loss/tok 2.7385 (3.3680)	Learning Rate [0.000625]
2: TRAIN [1][2790/3416]	Time 0.050 (0.058)	Data 0.00109 (0.00098)	Tok/s 34788 (53168)	Loss/tok 2.9307 (3.3680)	Learning Rate [0.000625]
14: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 35225 (54185)	Loss/tok 3.1243 (3.3679)	Learning Rate [0.000625]
13: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00089 (0.00099)	Tok/s 34020 (54081)	Loss/tok 3.1664 (3.3686)	Learning Rate [0.000625]
3: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00098)	Tok/s 34074 (53255)	Loss/tok 2.9956 (3.3671)	Learning Rate [0.000625]
4: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00094 (0.00092)	Tok/s 34025 (53340)	Loss/tok 2.9726 (3.3659)	Learning Rate [0.000625]
12: TRAIN [1][2790/3416]	Time 0.050 (0.058)	Data 0.00109 (0.00097)	Tok/s 34658 (53979)	Loss/tok 2.8206 (3.3722)	Learning Rate [0.000625]
11: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00097)	Tok/s 34005 (53887)	Loss/tok 2.8876 (3.3677)	Learning Rate [0.000625]
10: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00097)	Tok/s 34016 (53807)	Loss/tok 2.9277 (3.3677)	Learning Rate [0.000625]
5: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00105 (0.00098)	Tok/s 34026 (53435)	Loss/tok 2.9437 (3.3700)	Learning Rate [0.000625]
9: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00091 (0.00093)	Tok/s 34036 (53726)	Loss/tok 2.9656 (3.3728)	Learning Rate [0.000625]
6: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00099)	Tok/s 34000 (53502)	Loss/tok 3.0998 (3.3687)	Learning Rate [0.000625]
8: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00097)	Tok/s 34022 (53661)	Loss/tok 3.0205 (3.3654)	Learning Rate [0.000625]
7: TRAIN [1][2790/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00092)	Tok/s 34031 (53584)	Loss/tok 3.0513 (3.3636)	Learning Rate [0.000625]
6: Upscaling, new scale: 4096.0
7: Upscaling, new scale: 4096.0
5: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
8: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
9: Upscaling, new scale: 4096.0
10: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
3: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00098)	Tok/s 63018 (53262)	Loss/tok 3.5099 (3.3670)	Learning Rate [0.000625]
4: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00092)	Tok/s 62920 (53346)	Loss/tok 3.2956 (3.3656)	Learning Rate [0.000625]
2: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00085 (0.00098)	Tok/s 62908 (53175)	Loss/tok 3.4011 (3.3680)	Learning Rate [0.000625]
5: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00098)	Tok/s 62872 (53442)	Loss/tok 3.4742 (3.3698)	Learning Rate [0.000625]
1: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00091)	Tok/s 62959 (53073)	Loss/tok 3.3146 (3.3675)	Learning Rate [0.000625]
8: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00097)	Tok/s 62817 (53667)	Loss/tok 3.4725 (3.3652)	Learning Rate [0.000625]
9: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00093)	Tok/s 62848 (53732)	Loss/tok 3.3898 (3.3728)	Learning Rate [0.000625]
0: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00091)	Tok/s 62896 (52974)	Loss/tok 3.2688 (3.3724)	Learning Rate [0.000625]
6: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00099)	Tok/s 62843 (53509)	Loss/tok 3.2442 (3.3684)	Learning Rate [0.000625]
14: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00092)	Tok/s 63870 (54191)	Loss/tok 3.3277 (3.3675)	Learning Rate [0.000625]
10: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00112 (0.00097)	Tok/s 62948 (53812)	Loss/tok 3.2259 (3.3671)	Learning Rate [0.000625]
15: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00091)	Tok/s 63946 (54291)	Loss/tok 3.3806 (3.3660)	Learning Rate [0.000625]
7: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00127 (0.00092)	Tok/s 62923 (53590)	Loss/tok 3.6857 (3.3634)	Learning Rate [0.000625]
11: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00097)	Tok/s 63686 (53893)	Loss/tok 3.2284 (3.3674)	Learning Rate [0.000625]
12: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00097)	Tok/s 63828 (53985)	Loss/tok 3.4947 (3.3723)	Learning Rate [0.000625]
13: TRAIN [1][2800/3416]	Time 0.068 (0.058)	Data 0.00090 (0.00099)	Tok/s 63816 (54087)	Loss/tok 3.7282 (3.3684)	Learning Rate [0.000625]
7: TRAIN [1][2810/3416]	Time 0.039 (0.058)	Data 0.00087 (0.00092)	Tok/s 27498 (53570)	Loss/tok 2.3685 (3.3629)	Learning Rate [0.000625]
8: TRAIN [1][2810/3416]	Time 0.039 (0.058)	Data 0.00100 (0.00097)	Tok/s 27856 (53646)	Loss/tok 2.6814 (3.3649)	Learning Rate [0.000625]
6: TRAIN [1][2810/3416]	Time 0.039 (0.058)	Data 0.00101 (0.00099)	Tok/s 26300 (53488)	Loss/tok 2.4364 (3.3682)	Learning Rate [0.000625]
4: TRAIN [1][2810/3416]	Time 0.039 (0.058)	Data 0.00091 (0.00092)	Tok/s 26220 (53326)	Loss/tok 2.3027 (3.3648)	Learning Rate [0.000625]
5: TRAIN [1][2810/3416]	Time 0.039 (0.058)	Data 0.00095 (0.00098)	Tok/s 26274 (53421)	Loss/tok 2.5037 (3.3696)	Learning Rate [0.000625]
9: TRAIN [1][2810/3416]	Time 0.039 (0.058)	Data 0.00088 (0.00093)	Tok/s 27748 (53711)	Loss/tok 2.7222 (3.3727)	Learning Rate [0.000625]
10: TRAIN [1][2810/3416]	Time 0.039 (0.058)	Data 0.00097 (0.00097)	Tok/s 27708 (53791)	Loss/tok 2.3908 (3.3668)	Learning Rate [0.000625]
3: TRAIN [1][2810/3416]	Time 0.039 (0.058)	Data 0.00120 (0.00098)	Tok/s 26171 (53241)	Loss/tok 2.4657 (3.3665)	Learning Rate [0.000625]
11: TRAIN [1][2810/3416]	Time 0.039 (0.058)	Data 0.00089 (0.00097)	Tok/s 27590 (53872)	Loss/tok 2.4639 (3.3667)	Learning Rate [0.000625]
2: TRAIN [1][2810/3416]	Time 0.039 (0.058)	Data 0.00087 (0.00098)	Tok/s 24499 (53154)	Loss/tok 2.2834 (3.3675)	Learning Rate [0.000625]
0: TRAIN [1][2810/3416]	Time 0.039 (0.058)	Data 0.00079 (0.00091)	Tok/s 24341 (52953)	Loss/tok 2.2193 (3.3720)	Learning Rate [0.000625]
1: TRAIN [1][2810/3416]	Time 0.039 (0.058)	Data 0.00086 (0.00091)	Tok/s 24387 (53052)	Loss/tok 2.2840 (3.3672)	Learning Rate [0.000625]
12: TRAIN [1][2810/3416]	Time 0.040 (0.058)	Data 0.00100 (0.00097)	Tok/s 27815 (53965)	Loss/tok 2.4770 (3.3718)	Learning Rate [0.000625]
15: TRAIN [1][2810/3416]	Time 0.040 (0.058)	Data 0.00099 (0.00091)	Tok/s 29137 (54271)	Loss/tok 2.3886 (3.3655)	Learning Rate [0.000625]
13: TRAIN [1][2810/3416]	Time 0.040 (0.058)	Data 0.00091 (0.00099)	Tok/s 29060 (54067)	Loss/tok 2.4879 (3.3678)	Learning Rate [0.000625]
14: TRAIN [1][2810/3416]	Time 0.040 (0.058)	Data 0.00074 (0.00091)	Tok/s 29062 (54171)	Loss/tok 2.6639 (3.3673)	Learning Rate [0.000625]
1: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
2: Gradient norm: inf
15: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
15: Skipped batch, new scale: 2048.0
14: Gradient norm: inf
4: Gradient norm: inf
3: Gradient norm: inf
14: Skipped batch, new scale: 2048.0
13: Gradient norm: inf
4: Skipped batch, new scale: 2048.0
12: Gradient norm: inf
13: Skipped batch, new scale: 2048.0
5: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
6: Gradient norm: inf
11: Gradient norm: inf
12: Skipped batch, new scale: 2048.0
6: Skipped batch, new scale: 2048.0
5: Skipped batch, new scale: 2048.0
7: Gradient norm: inf
11: Skipped batch, new scale: 2048.0
10: Gradient norm: inf
7: Skipped batch, new scale: 2048.0
9: Gradient norm: inf
8: Gradient norm: inf
10: Skipped batch, new scale: 2048.0
8: Skipped batch, new scale: 2048.0
9: Skipped batch, new scale: 2048.0
12: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00097)	Tok/s 49385 (53956)	Loss/tok 3.0788 (3.3714)	Learning Rate [0.000625]
11: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00105 (0.00097)	Tok/s 49302 (53864)	Loss/tok 3.1687 (3.3663)	Learning Rate [0.000625]
10: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00097)	Tok/s 49284 (53782)	Loss/tok 3.4582 (3.3668)	Learning Rate [0.000625]
14: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00082 (0.00091)	Tok/s 49251 (54162)	Loss/tok 3.3348 (3.3671)	Learning Rate [0.000625]
13: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00110 (0.00099)	Tok/s 49308 (54058)	Loss/tok 3.1454 (3.3678)	Learning Rate [0.000625]
15: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00115 (0.00091)	Tok/s 50039 (54263)	Loss/tok 3.2060 (3.3654)	Learning Rate [0.000625]
9: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00093)	Tok/s 49251 (53702)	Loss/tok 3.1455 (3.3726)	Learning Rate [0.000625]
8: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00112 (0.00097)	Tok/s 49251 (53638)	Loss/tok 3.2880 (3.3645)	Learning Rate [0.000625]
0: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00091)	Tok/s 49053 (52944)	Loss/tok 2.9968 (3.3716)	Learning Rate [0.000625]
7: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00092)	Tok/s 49273 (53561)	Loss/tok 3.0895 (3.3625)	Learning Rate [0.000625]
1: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00107 (0.00091)	Tok/s 49007 (53043)	Loss/tok 3.1119 (3.3668)	Learning Rate [0.000625]
2: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00098)	Tok/s 49043 (53144)	Loss/tok 3.2904 (3.3672)	Learning Rate [0.000625]
6: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00099)	Tok/s 49214 (53479)	Loss/tok 3.1270 (3.3681)	Learning Rate [0.000625]
4: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00160 (0.00092)	Tok/s 49081 (53317)	Loss/tok 3.2221 (3.3642)	Learning Rate [0.000625]
3: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00098)	Tok/s 49017 (53232)	Loss/tok 3.2498 (3.3662)	Learning Rate [0.000625]
5: TRAIN [1][2820/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00098)	Tok/s 49077 (53412)	Loss/tok 2.9694 (3.3693)	Learning Rate [0.000625]
10: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 65228 (53781)	Loss/tok 3.1601 (3.3663)	Learning Rate [0.000625]
11: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 65781 (53862)	Loss/tok 3.3388 (3.3659)	Learning Rate [0.000625]
12: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00097)	Tok/s 66191 (53954)	Loss/tok 3.6743 (3.3711)	Learning Rate [0.000625]
13: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00099)	Tok/s 66131 (54056)	Loss/tok 3.3774 (3.3673)	Learning Rate [0.000625]
8: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 65223 (53637)	Loss/tok 3.3260 (3.3643)	Learning Rate [0.000625]
7: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00076 (0.00092)	Tok/s 65198 (53560)	Loss/tok 3.5647 (3.3624)	Learning Rate [0.000625]
15: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00091)	Tok/s 66104 (54261)	Loss/tok 3.5918 (3.3653)	Learning Rate [0.000625]
0: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00091)	Tok/s 65199 (52943)	Loss/tok 3.4798 (3.3716)	Learning Rate [0.000625]
6: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00099)	Tok/s 65201 (53477)	Loss/tok 3.3125 (3.3680)	Learning Rate [0.000625]
4: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00092)	Tok/s 65199 (53315)	Loss/tok 3.3706 (3.3639)	Learning Rate [0.000625]
5: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 65197 (53410)	Loss/tok 3.4357 (3.3690)	Learning Rate [0.000625]
1: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00080 (0.00091)	Tok/s 65208 (53041)	Loss/tok 3.2383 (3.3666)	Learning Rate [0.000625]
9: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00093)	Tok/s 65141 (53701)	Loss/tok 3.4642 (3.3724)	Learning Rate [0.000625]
2: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00098)	Tok/s 65171 (53142)	Loss/tok 3.3257 (3.3668)	Learning Rate [0.000625]
3: TRAIN [1][2830/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 65196 (53231)	Loss/tok 3.4729 (3.3660)	Learning Rate [0.000625]
14: TRAIN [1][2830/3416]	Time 0.071 (0.058)	Data 0.00082 (0.00091)	Tok/s 64987 (54160)	Loss/tok 3.3520 (3.3667)	Learning Rate [0.000625]
1: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
15: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
14: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
4: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
13: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
12: Gradient norm: inf
5: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
10: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
8: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
12: TRAIN [1][2840/3416]	Time 0.066 (0.058)	Data 0.00083 (0.00097)	Tok/s 62685 (53952)	Loss/tok 3.5647 (3.3709)	Learning Rate [0.000625]
13: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00101 (0.00099)	Tok/s 62499 (54055)	Loss/tok 3.5877 (3.3670)	Learning Rate [0.000625]
14: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00091)	Tok/s 62361 (54159)	Loss/tok 3.5377 (3.3663)	Learning Rate [0.000625]
11: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00097)	Tok/s 62508 (53860)	Loss/tok 3.5050 (3.3658)	Learning Rate [0.000625]
15: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00091)	Tok/s 62584 (54260)	Loss/tok 3.4758 (3.3647)	Learning Rate [0.000625]
10: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00097)	Tok/s 62500 (53779)	Loss/tok 3.4608 (3.3657)	Learning Rate [0.000625]
0: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00091)	Tok/s 62164 (52937)	Loss/tok 3.4510 (3.3712)	Learning Rate [0.000625]
9: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00093)	Tok/s 62491 (53699)	Loss/tok 3.4052 (3.3720)	Learning Rate [0.000625]
1: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00091)	Tok/s 62069 (53036)	Loss/tok 3.6209 (3.3664)	Learning Rate [0.000625]
8: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00097)	Tok/s 62484 (53634)	Loss/tok 3.3902 (3.3637)	Learning Rate [0.000625]
7: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00088 (0.00092)	Tok/s 62337 (53557)	Loss/tok 3.6338 (3.3624)	Learning Rate [0.000625]
2: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00098)	Tok/s 62068 (53138)	Loss/tok 3.4621 (3.3666)	Learning Rate [0.000625]
6: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00099)	Tok/s 62214 (53474)	Loss/tok 3.3822 (3.3676)	Learning Rate [0.000625]
4: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00091 (0.00092)	Tok/s 62088 (53312)	Loss/tok 3.6336 (3.3638)	Learning Rate [0.000625]
5: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00114 (0.00098)	Tok/s 62155 (53407)	Loss/tok 3.4848 (3.3686)	Learning Rate [0.000625]
3: TRAIN [1][2840/3416]	Time 0.067 (0.058)	Data 0.00098 (0.00098)	Tok/s 61999 (53227)	Loss/tok 3.2295 (3.3657)	Learning Rate [0.000625]
5: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00098)	Tok/s 54109 (53393)	Loss/tok 3.2260 (3.3685)	Learning Rate [0.000625]
4: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00092)	Tok/s 54097 (53298)	Loss/tok 3.4432 (3.3635)	Learning Rate [0.000625]
6: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00103 (0.00099)	Tok/s 54120 (53460)	Loss/tok 3.5004 (3.3676)	Learning Rate [0.000625]
7: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00092)	Tok/s 54066 (53543)	Loss/tok 3.2041 (3.3622)	Learning Rate [0.000625]
3: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00106 (0.00098)	Tok/s 54087 (53213)	Loss/tok 3.3569 (3.3655)	Learning Rate [0.000625]
8: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00100 (0.00097)	Tok/s 53994 (53619)	Loss/tok 3.5003 (3.3637)	Learning Rate [0.000625]
2: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00098)	Tok/s 54081 (53124)	Loss/tok 3.2642 (3.3664)	Learning Rate [0.000625]
0: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00088 (0.00091)	Tok/s 54076 (52923)	Loss/tok 3.3251 (3.3708)	Learning Rate [0.000625]
1: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00091)	Tok/s 54041 (53022)	Loss/tok 3.2985 (3.3662)	Learning Rate [0.000625]
9: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00093)	Tok/s 54087 (53684)	Loss/tok 3.5395 (3.3718)	Learning Rate [0.000625]
10: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00091 (0.00097)	Tok/s 54098 (53763)	Loss/tok 3.4635 (3.3656)	Learning Rate [0.000625]
15: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00089 (0.00091)	Tok/s 54036 (54245)	Loss/tok 3.4598 (3.3646)	Learning Rate [0.000625]
14: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00087 (0.00091)	Tok/s 54039 (54144)	Loss/tok 3.4927 (3.3663)	Learning Rate [0.000625]
11: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00094 (0.00097)	Tok/s 54090 (53845)	Loss/tok 3.2449 (3.3656)	Learning Rate [0.000625]
13: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00095 (0.00099)	Tok/s 54100 (54040)	Loss/tok 3.1900 (3.3666)	Learning Rate [0.000625]
12: TRAIN [1][2850/3416]	Time 0.065 (0.058)	Data 0.00099 (0.00097)	Tok/s 54014 (53937)	Loss/tok 3.3014 (3.3708)	Learning Rate [0.000625]
5: TRAIN [1][2860/3416]	Time 0.051 (0.058)	Data 0.00098 (0.00098)	Tok/s 32321 (53388)	Loss/tok 2.7027 (3.3685)	Learning Rate [0.000625]
4: TRAIN [1][2860/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00092)	Tok/s 32263 (53293)	Loss/tok 2.8574 (3.3631)	Learning Rate [0.000625]
6: TRAIN [1][2860/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00099)	Tok/s 32318 (53455)	Loss/tok 3.1525 (3.3672)	Learning Rate [0.000625]
3: TRAIN [1][2860/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00098)	Tok/s 32191 (53208)	Loss/tok 2.7496 (3.3653)	Learning Rate [0.000625]
2: TRAIN [1][2860/3416]	Time 0.052 (0.058)	Data 0.00110 (0.00098)	Tok/s 32144 (53119)	Loss/tok 3.1117 (3.3663)	Learning Rate [0.000625]
8: TRAIN [1][2860/3416]	Time 0.051 (0.058)	Data 0.00109 (0.00097)	Tok/s 32317 (53614)	Loss/tok 2.9842 (3.3637)	Learning Rate [0.000625]
0: TRAIN [1][2860/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00091)	Tok/s 32177 (52919)	Loss/tok 3.1180 (3.3706)	Learning Rate [0.000625]
7: TRAIN [1][2860/3416]	Time 0.051 (0.058)	Data 0.00096 (0.00092)	Tok/s 32327 (53537)	Loss/tok 2.9234 (3.3622)	Learning Rate [0.000625]
1: TRAIN [1][2860/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00091)	Tok/s 32128 (53017)	Loss/tok 2.9806 (3.3658)	Learning Rate [0.000625]
9: TRAIN [1][2860/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00093)	Tok/s 32319 (53678)	Loss/tok 2.9250 (3.3718)	Learning Rate [0.000625]
10: TRAIN [1][2860/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00097)	Tok/s 32495 (53758)	Loss/tok 2.9489 (3.3654)	Learning Rate [0.000625]
11: TRAIN [1][2860/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00097)	Tok/s 33485 (53839)	Loss/tok 3.1175 (3.3655)	Learning Rate [0.000625]
14: TRAIN [1][2860/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00091)	Tok/s 33373 (54138)	Loss/tok 2.8887 (3.3663)	Learning Rate [0.000625]
13: TRAIN [1][2860/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00099)	Tok/s 33377 (54034)	Loss/tok 3.0956 (3.3666)	Learning Rate [0.000625]
12: TRAIN [1][2860/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00097)	Tok/s 33368 (53932)	Loss/tok 2.9445 (3.3705)	Learning Rate [0.000625]
15: TRAIN [1][2860/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00091)	Tok/s 33376 (54239)	Loss/tok 3.1686 (3.3646)	Learning Rate [0.000625]
4: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00077 (0.00092)	Tok/s 27106 (53294)	Loss/tok 2.6741 (3.3631)	Learning Rate [0.000625]
3: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00099 (0.00098)	Tok/s 27069 (53209)	Loss/tok 2.5615 (3.3652)	Learning Rate [0.000625]
2: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00098 (0.00098)	Tok/s 25502 (53120)	Loss/tok 2.2871 (3.3659)	Learning Rate [0.000625]
1: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00086 (0.00091)	Tok/s 25205 (53018)	Loss/tok 2.4974 (3.3656)	Learning Rate [0.000625]
0: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00078 (0.00091)	Tok/s 25236 (52920)	Loss/tok 2.4317 (3.3702)	Learning Rate [0.000625]
6: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00094 (0.00099)	Tok/s 27135 (53455)	Loss/tok 2.4740 (3.3669)	Learning Rate [0.000625]
5: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00097 (0.00098)	Tok/s 27130 (53388)	Loss/tok 2.4816 (3.3677)	Learning Rate [0.000625]
8: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00098 (0.00097)	Tok/s 28887 (53616)	Loss/tok 2.4350 (3.3634)	Learning Rate [0.000625]
7: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00088 (0.00092)	Tok/s 28290 (53539)	Loss/tok 2.4661 (3.3619)	Learning Rate [0.000625]
14: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00079 (0.00091)	Tok/s 30290 (54141)	Loss/tok 2.6323 (3.3661)	Learning Rate [0.000625]
9: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00084 (0.00093)	Tok/s 28777 (53680)	Loss/tok 2.5890 (3.3716)	Learning Rate [0.000625]
10: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00085 (0.00097)	Tok/s 28676 (53760)	Loss/tok 2.4451 (3.3648)	Learning Rate [0.000625]
13: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00097 (0.00099)	Tok/s 30245 (54037)	Loss/tok 2.7049 (3.3663)	Learning Rate [0.000625]
11: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00087 (0.00097)	Tok/s 28676 (53841)	Loss/tok 2.5325 (3.3654)	Learning Rate [0.000625]
12: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00086 (0.00097)	Tok/s 28602 (53934)	Loss/tok 2.3914 (3.3700)	Learning Rate [0.000625]
15: TRAIN [1][2870/3416]	Time 0.038 (0.058)	Data 0.00083 (0.00091)	Tok/s 30241 (54241)	Loss/tok 2.5154 (3.3644)	Learning Rate [0.000625]
7: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00085 (0.00092)	Tok/s 55841 (53544)	Loss/tok 3.4506 (3.3615)	Learning Rate [0.000625]
8: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00108 (0.00097)	Tok/s 56144 (53621)	Loss/tok 3.3519 (3.3632)	Learning Rate [0.000625]
6: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00091 (0.00099)	Tok/s 55177 (53460)	Loss/tok 3.0686 (3.3665)	Learning Rate [0.000625]
10: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00083 (0.00097)	Tok/s 56169 (53765)	Loss/tok 3.5534 (3.3646)	Learning Rate [0.000625]
5: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00098)	Tok/s 55163 (53394)	Loss/tok 3.4664 (3.3675)	Learning Rate [0.000625]
4: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00080 (0.00092)	Tok/s 55146 (53299)	Loss/tok 3.5211 (3.3630)	Learning Rate [0.000625]
9: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00093)	Tok/s 56108 (53685)	Loss/tok 3.3017 (3.3711)	Learning Rate [0.000625]
2: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00098)	Tok/s 55193 (53126)	Loss/tok 3.5040 (3.3658)	Learning Rate [0.000625]
11: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00097)	Tok/s 56150 (53847)	Loss/tok 3.4482 (3.3651)	Learning Rate [0.000625]
0: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00082 (0.00091)	Tok/s 55177 (52926)	Loss/tok 3.3076 (3.3697)	Learning Rate [0.000625]
1: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00083 (0.00091)	Tok/s 55153 (53025)	Loss/tok 3.3303 (3.3652)	Learning Rate [0.000625]
12: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00081 (0.00097)	Tok/s 56066 (53940)	Loss/tok 3.6319 (3.3700)	Learning Rate [0.000625]
13: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00099 (0.00099)	Tok/s 56135 (54042)	Loss/tok 3.0967 (3.3662)	Learning Rate [0.000625]
14: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00086 (0.00091)	Tok/s 56120 (54146)	Loss/tok 3.6251 (3.3659)	Learning Rate [0.000625]
3: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00092 (0.00098)	Tok/s 55170 (53215)	Loss/tok 3.2294 (3.3648)	Learning Rate [0.000625]
15: TRAIN [1][2880/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00091)	Tok/s 56106 (54246)	Loss/tok 3.8050 (3.3644)	Learning Rate [0.000625]
5: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00100 (0.00098)	Tok/s 76008 (53403)	Loss/tok 3.5467 (3.3675)	Learning Rate [0.000625]
4: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00087 (0.00092)	Tok/s 75886 (53308)	Loss/tok 3.1479 (3.3626)	Learning Rate [0.000625]
6: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00099)	Tok/s 76002 (53469)	Loss/tok 3.3474 (3.3661)	Learning Rate [0.000625]
2: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00106 (0.00098)	Tok/s 75576 (53134)	Loss/tok 3.3383 (3.3654)	Learning Rate [0.000625]
3: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00097 (0.00098)	Tok/s 75777 (53224)	Loss/tok 3.1661 (3.3646)	Learning Rate [0.000625]
8: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00097)	Tok/s 75974 (53630)	Loss/tok 3.3557 (3.3631)	Learning Rate [0.000625]
7: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00090 (0.00092)	Tok/s 75975 (53553)	Loss/tok 3.0164 (3.3610)	Learning Rate [0.000625]
1: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00092 (0.00091)	Tok/s 74634 (53033)	Loss/tok 3.4402 (3.3649)	Learning Rate [0.000625]
0: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00085 (0.00091)	Tok/s 74580 (52935)	Loss/tok 3.2631 (3.3693)	Learning Rate [0.000625]
10: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00102 (0.00097)	Tok/s 75845 (53774)	Loss/tok 3.3473 (3.3644)	Learning Rate [0.000625]
9: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00087 (0.00093)	Tok/s 75829 (53694)	Loss/tok 3.2934 (3.3707)	Learning Rate [0.000625]
14: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00085 (0.00091)	Tok/s 76348 (54155)	Loss/tok 3.4924 (3.3654)	Learning Rate [0.000625]
12: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00106 (0.00097)	Tok/s 76406 (53950)	Loss/tok 3.3257 (3.3695)	Learning Rate [0.000625]
11: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00095 (0.00097)	Tok/s 76502 (53856)	Loss/tok 3.2230 (3.3644)	Learning Rate [0.000625]
13: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00100 (0.00099)	Tok/s 76354 (54052)	Loss/tok 3.2100 (3.3660)	Learning Rate [0.000625]
15: TRAIN [1][2890/3416]	Time 0.071 (0.058)	Data 0.00086 (0.00091)	Tok/s 76298 (54256)	Loss/tok 3.3330 (3.3640)	Learning Rate [0.000625]
9: TRAIN [1][2900/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00093)	Tok/s 47711 (53710)	Loss/tok 3.1961 (3.3707)	Learning Rate [0.000625]
8: TRAIN [1][2900/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00097)	Tok/s 47726 (53645)	Loss/tok 3.0537 (3.3630)	Learning Rate [0.000625]
10: TRAIN [1][2900/3416]	Time 0.044 (0.058)	Data 0.00092 (0.00097)	Tok/s 48938 (53790)	Loss/tok 3.1656 (3.3643)	Learning Rate [0.000625]
6: TRAIN [1][2900/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00099)	Tok/s 47449 (53484)	Loss/tok 3.2107 (3.3660)	Learning Rate [0.000625]
11: TRAIN [1][2900/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00097)	Tok/s 48825 (53871)	Loss/tok 3.2723 (3.3641)	Learning Rate [0.000625]
7: TRAIN [1][2900/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00092)	Tok/s 47517 (53567)	Loss/tok 3.1067 (3.3608)	Learning Rate [0.000625]
12: TRAIN [1][2900/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00097)	Tok/s 48721 (53965)	Loss/tok 3.2698 (3.3691)	Learning Rate [0.000625]
13: TRAIN [1][2900/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00099)	Tok/s 48550 (54067)	Loss/tok 3.2153 (3.3652)	Learning Rate [0.000625]
5: TRAIN [1][2900/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00098)	Tok/s 47221 (53417)	Loss/tok 3.0451 (3.3671)	Learning Rate [0.000625]
4: TRAIN [1][2900/3416]	Time 0.045 (0.058)	Data 0.00096 (0.00092)	Tok/s 47096 (53322)	Loss/tok 3.3482 (3.3626)	Learning Rate [0.000625]
14: TRAIN [1][2900/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00091)	Tok/s 48729 (54171)	Loss/tok 3.3479 (3.3651)	Learning Rate [0.000625]
3: TRAIN [1][2900/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00098)	Tok/s 46968 (53238)	Loss/tok 3.3942 (3.3642)	Learning Rate [0.000625]
2: TRAIN [1][2900/3416]	Time 0.045 (0.058)	Data 0.00106 (0.00098)	Tok/s 46850 (53148)	Loss/tok 2.9029 (3.3652)	Learning Rate [0.000625]
0: TRAIN [1][2900/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00091)	Tok/s 46791 (52946)	Loss/tok 3.0205 (3.3690)	Learning Rate [0.000625]
1: TRAIN [1][2900/3416]	Time 0.045 (0.058)	Data 0.00095 (0.00091)	Tok/s 46770 (53046)	Loss/tok 2.8817 (3.3646)	Learning Rate [0.000625]
15: TRAIN [1][2900/3416]	Time 0.045 (0.058)	Data 0.00082 (0.00091)	Tok/s 48451 (54271)	Loss/tok 3.0508 (3.3639)	Learning Rate [0.000625]
4: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00089 (0.00092)	Tok/s 55043 (53335)	Loss/tok 3.3181 (3.3623)	Learning Rate [0.000625]
1: TRAIN [1][2910/3416]	Time 0.061 (0.058)	Data 0.00087 (0.00091)	Tok/s 55165 (53059)	Loss/tok 3.4261 (3.3649)	Learning Rate [0.000625]
3: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00098)	Tok/s 55088 (53250)	Loss/tok 3.3727 (3.3642)	Learning Rate [0.000625]
5: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00106 (0.00098)	Tok/s 54975 (53430)	Loss/tok 3.1450 (3.3671)	Learning Rate [0.000625]
6: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00103 (0.00099)	Tok/s 54928 (53497)	Loss/tok 3.6477 (3.3660)	Learning Rate [0.000625]
2: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00098)	Tok/s 55049 (53160)	Loss/tok 3.2558 (3.3648)	Learning Rate [0.000625]
8: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00099 (0.00097)	Tok/s 54810 (53658)	Loss/tok 3.0516 (3.3626)	Learning Rate [0.000625]
11: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00091 (0.00097)	Tok/s 55257 (53883)	Loss/tok 3.3320 (3.3639)	Learning Rate [0.000625]
7: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00092)	Tok/s 54795 (53580)	Loss/tok 3.4819 (3.3607)	Learning Rate [0.000625]
0: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00091)	Tok/s 55066 (52959)	Loss/tok 3.1946 (3.3691)	Learning Rate [0.000625]
9: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00097 (0.00093)	Tok/s 54839 (53722)	Loss/tok 3.4525 (3.3708)	Learning Rate [0.000625]
10: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00107 (0.00097)	Tok/s 54833 (53802)	Loss/tok 3.2791 (3.3641)	Learning Rate [0.000625]
14: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00092 (0.00091)	Tok/s 56049 (54183)	Loss/tok 3.4497 (3.3651)	Learning Rate [0.000625]
12: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00102 (0.00097)	Tok/s 55944 (53978)	Loss/tok 3.3133 (3.3690)	Learning Rate [0.000625]
13: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00101 (0.00099)	Tok/s 55989 (54080)	Loss/tok 3.4729 (3.3649)	Learning Rate [0.000625]
15: TRAIN [1][2910/3416]	Time 0.062 (0.058)	Data 0.00087 (0.00091)	Tok/s 56176 (54283)	Loss/tok 3.4712 (3.3640)	Learning Rate [0.000625]
14: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00078 (0.00091)	Tok/s 53122 (54194)	Loss/tok 3.2606 (3.3654)	Learning Rate [0.000625]
0: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00091)	Tok/s 51678 (52972)	Loss/tok 3.2918 (3.3689)	Learning Rate [0.000625]
13: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00099)	Tok/s 53102 (54091)	Loss/tok 3.3199 (3.3650)	Learning Rate [0.000625]
12: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00097)	Tok/s 53101 (53989)	Loss/tok 3.0899 (3.3690)	Learning Rate [0.000625]
10: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00097)	Tok/s 52858 (53812)	Loss/tok 3.1682 (3.3640)	Learning Rate [0.000625]
1: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00091)	Tok/s 51641 (53070)	Loss/tok 3.1421 (3.3646)	Learning Rate [0.000625]
11: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00097)	Tok/s 53081 (53893)	Loss/tok 3.3322 (3.3642)	Learning Rate [0.000625]
2: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00098)	Tok/s 51652 (53172)	Loss/tok 3.2525 (3.3648)	Learning Rate [0.000625]
9: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00093)	Tok/s 51882 (53732)	Loss/tok 3.4465 (3.3707)	Learning Rate [0.000625]
8: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00097)	Tok/s 51936 (53668)	Loss/tok 3.1345 (3.3628)	Learning Rate [0.000625]
4: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00078 (0.00092)	Tok/s 51668 (53346)	Loss/tok 3.3115 (3.3624)	Learning Rate [0.000625]
3: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00098)	Tok/s 51619 (53261)	Loss/tok 3.4008 (3.3642)	Learning Rate [0.000625]
7: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00092)	Tok/s 51824 (53590)	Loss/tok 3.1268 (3.3605)	Learning Rate [0.000625]
15: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00082 (0.00091)	Tok/s 52995 (54294)	Loss/tok 3.0674 (3.3642)	Learning Rate [0.000625]
5: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00098)	Tok/s 51632 (53441)	Loss/tok 3.3800 (3.3670)	Learning Rate [0.000625]
6: TRAIN [1][2920/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00099)	Tok/s 51719 (53507)	Loss/tok 3.3712 (3.3663)	Learning Rate [0.000625]
0: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00091)	Tok/s 52139 (52966)	Loss/tok 3.2123 (3.3686)	Learning Rate [0.000625]
1: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00090 (0.00091)	Tok/s 52294 (53065)	Loss/tok 3.4925 (3.3645)	Learning Rate [0.000625]
14: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00091)	Tok/s 53185 (54187)	Loss/tok 3.6118 (3.3653)	Learning Rate [0.000625]
2: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00110 (0.00098)	Tok/s 52981 (53166)	Loss/tok 3.5178 (3.3644)	Learning Rate [0.000625]
13: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00106 (0.00099)	Tok/s 53179 (54083)	Loss/tok 3.1427 (3.3649)	Learning Rate [0.000625]
10: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00092 (0.00097)	Tok/s 53110 (53805)	Loss/tok 3.6044 (3.3642)	Learning Rate [0.000625]
3: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00098)	Tok/s 52885 (53255)	Loss/tok 3.1750 (3.3641)	Learning Rate [0.000625]
12: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00101 (0.00097)	Tok/s 53182 (53981)	Loss/tok 3.5098 (3.3689)	Learning Rate [0.000625]
4: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00087 (0.00092)	Tok/s 52806 (53339)	Loss/tok 3.4858 (3.3623)	Learning Rate [0.000625]
11: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00099 (0.00097)	Tok/s 53101 (53886)	Loss/tok 3.1410 (3.3639)	Learning Rate [0.000625]
8: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00098 (0.00097)	Tok/s 52980 (53661)	Loss/tok 3.2264 (3.3628)	Learning Rate [0.000625]
15: TRAIN [1][2930/3416]	Time 0.062 (0.058)	Data 0.00094 (0.00091)	Tok/s 53269 (54287)	Loss/tok 3.3082 (3.3640)	Learning Rate [0.000625]
5: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00089 (0.00098)	Tok/s 52828 (53434)	Loss/tok 3.1231 (3.3665)	Learning Rate [0.000625]
9: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00095 (0.00093)	Tok/s 52951 (53725)	Loss/tok 3.2157 (3.3702)	Learning Rate [0.000625]
6: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00109 (0.00099)	Tok/s 52839 (53500)	Loss/tok 3.4758 (3.3662)	Learning Rate [0.000625]
7: TRAIN [1][2930/3416]	Time 0.063 (0.058)	Data 0.00091 (0.00092)	Tok/s 52811 (53583)	Loss/tok 3.3883 (3.3601)	Learning Rate [0.000625]
1: TRAIN [1][2940/3416]	Time 0.071 (0.058)	Data 0.00084 (0.00091)	Tok/s 63655 (53078)	Loss/tok 3.2632 (3.3641)	Learning Rate [0.000625]
0: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00082 (0.00091)	Tok/s 62992 (52979)	Loss/tok 3.4470 (3.3682)	Learning Rate [0.000625]
2: TRAIN [1][2940/3416]	Time 0.071 (0.058)	Data 0.00096 (0.00098)	Tok/s 63569 (53179)	Loss/tok 3.6967 (3.3642)	Learning Rate [0.000625]
14: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00094 (0.00091)	Tok/s 63808 (54197)	Loss/tok 3.6283 (3.3652)	Learning Rate [0.000625]
4: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00078 (0.00092)	Tok/s 63402 (53351)	Loss/tok 3.4332 (3.3621)	Learning Rate [0.000625]
3: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00089 (0.00098)	Tok/s 63465 (53268)	Loss/tok 3.8363 (3.3642)	Learning Rate [0.000625]
13: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00087 (0.00099)	Tok/s 63258 (54094)	Loss/tok 3.4878 (3.3648)	Learning Rate [0.000625]
5: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00089 (0.00098)	Tok/s 63293 (53446)	Loss/tok 3.4715 (3.3667)	Learning Rate [0.000625]
12: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00091 (0.00097)	Tok/s 63154 (53992)	Loss/tok 3.4302 (3.3689)	Learning Rate [0.000625]
11: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00092 (0.00097)	Tok/s 63078 (53896)	Loss/tok 3.1822 (3.3638)	Learning Rate [0.000625]
6: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00099 (0.00099)	Tok/s 63225 (53512)	Loss/tok 3.4911 (3.3662)	Learning Rate [0.000625]
10: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00090 (0.00097)	Tok/s 62973 (53815)	Loss/tok 3.1226 (3.3639)	Learning Rate [0.000625]
7: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00084 (0.00092)	Tok/s 63114 (53594)	Loss/tok 3.3990 (3.3601)	Learning Rate [0.000625]
9: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00089 (0.00093)	Tok/s 62965 (53736)	Loss/tok 3.3966 (3.3701)	Learning Rate [0.000625]
8: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00089 (0.00097)	Tok/s 63012 (53672)	Loss/tok 3.4218 (3.3628)	Learning Rate [0.000625]
15: TRAIN [1][2940/3416]	Time 0.072 (0.058)	Data 0.00086 (0.00091)	Tok/s 64360 (54297)	Loss/tok 3.5674 (3.3639)	Learning Rate [0.000625]
14: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00091)	Tok/s 49888 (54164)	Loss/tok 3.2628 (3.3648)	Learning Rate [0.000625]
0: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00091)	Tok/s 49744 (52941)	Loss/tok 3.1228 (3.3677)	Learning Rate [0.000625]
13: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00090 (0.00099)	Tok/s 49867 (54061)	Loss/tok 3.3349 (3.3645)	Learning Rate [0.000625]
1: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00091)	Tok/s 49654 (53041)	Loss/tok 3.1762 (3.3638)	Learning Rate [0.000625]
12: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00097 (0.00097)	Tok/s 49895 (53959)	Loss/tok 3.2245 (3.3684)	Learning Rate [0.000625]
2: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00087 (0.00098)	Tok/s 49580 (53143)	Loss/tok 3.3112 (3.3639)	Learning Rate [0.000625]
11: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00095 (0.00097)	Tok/s 49875 (53863)	Loss/tok 3.1085 (3.3635)	Learning Rate [0.000625]
10: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00096 (0.00097)	Tok/s 49823 (53782)	Loss/tok 3.2572 (3.3635)	Learning Rate [0.000625]
3: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00098)	Tok/s 49552 (53231)	Loss/tok 3.3987 (3.3638)	Learning Rate [0.000625]
4: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00088 (0.00092)	Tok/s 49561 (53316)	Loss/tok 3.3006 (3.3615)	Learning Rate [0.000625]
9: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00098 (0.00093)	Tok/s 49801 (53703)	Loss/tok 3.1321 (3.3695)	Learning Rate [0.000625]
5: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00093 (0.00098)	Tok/s 49600 (53411)	Loss/tok 3.0929 (3.3663)	Learning Rate [0.000625]
8: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00099 (0.00097)	Tok/s 49716 (53639)	Loss/tok 3.2913 (3.3620)	Learning Rate [0.000625]
7: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00084 (0.00092)	Tok/s 49651 (53560)	Loss/tok 3.4629 (3.3599)	Learning Rate [0.000625]
15: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00092 (0.00091)	Tok/s 49857 (54264)	Loss/tok 3.0819 (3.3633)	Learning Rate [0.000625]
6: TRAIN [1][2950/3416]	Time 0.053 (0.058)	Data 0.00105 (0.00099)	Tok/s 49586 (53477)	Loss/tok 2.9194 (3.3656)	Learning Rate [0.000625]
4: TRAIN [1][2960/3416]	Time 0.059 (0.058)	Data 0.00085 (0.00092)	Tok/s 51840 (53322)	Loss/tok 3.1691 (3.3611)	Learning Rate [0.000625]
3: TRAIN [1][2960/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00098)	Tok/s 51727 (53237)	Loss/tok 3.2227 (3.3634)	Learning Rate [0.000625]
0: TRAIN [1][2960/3416]	Time 0.060 (0.058)	Data 0.00093 (0.00091)	Tok/s 51559 (52947)	Loss/tok 3.1061 (3.3674)	Learning Rate [0.000625]
2: TRAIN [1][2960/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00098)	Tok/s 51639 (53148)	Loss/tok 3.1814 (3.3638)	Learning Rate [0.000625]
5: TRAIN [1][2960/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00098)	Tok/s 51684 (53417)	Loss/tok 3.6776 (3.3661)	Learning Rate [0.000625]
6: TRAIN [1][2960/3416]	Time 0.059 (0.058)	Data 0.00098 (0.00099)	Tok/s 51695 (53483)	Loss/tok 3.2020 (3.3650)	Learning Rate [0.000625]
7: TRAIN [1][2960/3416]	Time 0.059 (0.058)	Data 0.00090 (0.00092)	Tok/s 51698 (53566)	Loss/tok 3.3216 (3.3597)	Learning Rate [0.000625]
8: TRAIN [1][2960/3416]	Time 0.059 (0.058)	Data 0.00123 (0.00097)	Tok/s 52341 (53644)	Loss/tok 3.3713 (3.3618)	Learning Rate [0.000625]
14: TRAIN [1][2960/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00091)	Tok/s 52640 (54169)	Loss/tok 3.1767 (3.3647)	Learning Rate [0.000625]
12: TRAIN [1][2960/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00097)	Tok/s 52714 (53964)	Loss/tok 3.1075 (3.3683)	Learning Rate [0.000625]
15: TRAIN [1][2960/3416]	Time 0.060 (0.058)	Data 0.00111 (0.00091)	Tok/s 52629 (54270)	Loss/tok 3.3748 (3.3630)	Learning Rate [0.000625]
9: TRAIN [1][2960/3416]	Time 0.060 (0.058)	Data 0.00112 (0.00093)	Tok/s 51595 (53708)	Loss/tok 3.4243 (3.3692)	Learning Rate [0.000625]
11: TRAIN [1][2960/3416]	Time 0.060 (0.058)	Data 0.00097 (0.00097)	Tok/s 52639 (53868)	Loss/tok 3.3962 (3.3632)	Learning Rate [0.000625]
10: TRAIN [1][2960/3416]	Time 0.060 (0.058)	Data 0.00098 (0.00097)	Tok/s 51632 (53787)	Loss/tok 3.2461 (3.3633)	Learning Rate [0.000625]
13: TRAIN [1][2960/3416]	Time 0.059 (0.058)	Data 0.00132 (0.00099)	Tok/s 53285 (54066)	Loss/tok 3.1746 (3.3642)	Learning Rate [0.000625]
1: TRAIN [1][2960/3416]	Time 0.060 (0.058)	Data 0.00095 (0.00091)	Tok/s 51535 (53046)	Loss/tok 3.2703 (3.3637)	Learning Rate [0.000625]
8: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
7: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
4: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00092)	Tok/s 53127 (53327)	Loss/tok 3.5092 (3.3610)	Learning Rate [0.000625]
5: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00098)	Tok/s 53189 (53422)	Loss/tok 3.4092 (3.3658)	Learning Rate [0.000625]
6: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00099)	Tok/s 53145 (53488)	Loss/tok 3.4029 (3.3648)	Learning Rate [0.000625]
7: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00092)	Tok/s 53217 (53570)	Loss/tok 3.2968 (3.3598)	Learning Rate [0.000625]
3: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00098)	Tok/s 53010 (53242)	Loss/tok 3.3662 (3.3635)	Learning Rate [0.000625]
2: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00098)	Tok/s 52930 (53153)	Loss/tok 3.3588 (3.3638)	Learning Rate [0.000625]
1: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00087 (0.00091)	Tok/s 52876 (53052)	Loss/tok 3.4181 (3.3639)	Learning Rate [0.000625]
8: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00097)	Tok/s 53136 (53648)	Loss/tok 3.4878 (3.3619)	Learning Rate [0.000625]
9: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00093)	Tok/s 53093 (53711)	Loss/tok 3.2375 (3.3692)	Learning Rate [0.000625]
15: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00091)	Tok/s 53962 (54273)	Loss/tok 3.2105 (3.3626)	Learning Rate [0.000625]
0: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00082 (0.00091)	Tok/s 52817 (52952)	Loss/tok 3.4921 (3.3673)	Learning Rate [0.000625]
10: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00097)	Tok/s 52945 (53791)	Loss/tok 3.3193 (3.3631)	Learning Rate [0.000625]
13: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00099)	Tok/s 53902 (54070)	Loss/tok 3.1040 (3.3642)	Learning Rate [0.000625]
14: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00091)	Tok/s 53845 (54173)	Loss/tok 3.2446 (3.3648)	Learning Rate [0.000625]
11: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00097)	Tok/s 52807 (53871)	Loss/tok 3.5318 (3.3632)	Learning Rate [0.000625]
12: TRAIN [1][2970/3416]	Time 0.059 (0.058)	Data 0.00094 (0.00097)	Tok/s 53310 (53968)	Loss/tok 3.3123 (3.3680)	Learning Rate [0.000625]
3: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00098)	Tok/s 48200 (53231)	Loss/tok 3.2097 (3.3631)	Learning Rate [0.000625]
2: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00098)	Tok/s 48278 (53143)	Loss/tok 3.1934 (3.3636)	Learning Rate [0.000625]
5: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00098)	Tok/s 48220 (53411)	Loss/tok 3.1411 (3.3655)	Learning Rate [0.000625]
1: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00091)	Tok/s 48313 (53042)	Loss/tok 3.0372 (3.3636)	Learning Rate [0.000625]
4: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00082 (0.00092)	Tok/s 48250 (53316)	Loss/tok 3.1347 (3.3607)	Learning Rate [0.000625]
0: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00085 (0.00091)	Tok/s 48295 (52942)	Loss/tok 3.1632 (3.3667)	Learning Rate [0.000625]
15: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00091)	Tok/s 49690 (54263)	Loss/tok 3.2651 (3.3621)	Learning Rate [0.000625]
14: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00091)	Tok/s 49751 (54163)	Loss/tok 3.0859 (3.3644)	Learning Rate [0.000625]
12: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00097)	Tok/s 49773 (53958)	Loss/tok 3.1979 (3.3677)	Learning Rate [0.000625]
9: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00093)	Tok/s 49701 (53702)	Loss/tok 3.1112 (3.3689)	Learning Rate [0.000625]
6: TRAIN [1][2980/3416]	Time 0.047 (0.058)	Data 0.00112 (0.00099)	Tok/s 48164 (53477)	Loss/tok 3.6171 (3.3647)	Learning Rate [0.000625]
8: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00097)	Tok/s 49583 (53638)	Loss/tok 2.9829 (3.3614)	Learning Rate [0.000625]
10: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00103 (0.00097)	Tok/s 49636 (53781)	Loss/tok 3.2189 (3.3629)	Learning Rate [0.000625]
13: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00099)	Tok/s 49646 (54060)	Loss/tok 3.4853 (3.3639)	Learning Rate [0.000625]
11: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00096 (0.00097)	Tok/s 49724 (53862)	Loss/tok 3.2066 (3.3630)	Learning Rate [0.000625]
7: TRAIN [1][2980/3416]	Time 0.046 (0.058)	Data 0.00095 (0.00092)	Tok/s 49113 (53560)	Loss/tok 3.0983 (3.3594)	Learning Rate [0.000625]
4: TRAIN [1][2990/3416]	Time 0.044 (0.058)	Data 0.00082 (0.00092)	Tok/s 29384 (53296)	Loss/tok 2.8269 (3.3604)	Learning Rate [0.000625]
3: TRAIN [1][2990/3416]	Time 0.043 (0.058)	Data 0.00105 (0.00098)	Tok/s 29927 (53211)	Loss/tok 2.9180 (3.3627)	Learning Rate [0.000625]
5: TRAIN [1][2990/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00098)	Tok/s 29381 (53391)	Loss/tok 2.9255 (3.3651)	Learning Rate [0.000625]
2: TRAIN [1][2990/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00098)	Tok/s 29356 (53123)	Loss/tok 2.6834 (3.3630)	Learning Rate [0.000625]
1: TRAIN [1][2990/3416]	Time 0.044 (0.058)	Data 0.00088 (0.00091)	Tok/s 29324 (53022)	Loss/tok 2.8864 (3.3633)	Learning Rate [0.000625]
6: TRAIN [1][2990/3416]	Time 0.044 (0.058)	Data 0.00111 (0.00099)	Tok/s 30106 (53456)	Loss/tok 2.6871 (3.3642)	Learning Rate [0.000625]
0: TRAIN [1][2990/3416]	Time 0.044 (0.058)	Data 0.00082 (0.00091)	Tok/s 29368 (52922)	Loss/tok 2.6236 (3.3663)	Learning Rate [0.000625]
15: TRAIN [1][2990/3416]	Time 0.044 (0.058)	Data 0.00084 (0.00091)	Tok/s 30820 (54242)	Loss/tok 2.7043 (3.3619)	Learning Rate [0.000625]
8: TRAIN [1][2990/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00097)	Tok/s 30863 (53617)	Loss/tok 2.7086 (3.3611)	Learning Rate [0.000625]
14: TRAIN [1][2990/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00091)	Tok/s 30825 (54142)	Loss/tok 2.9533 (3.3643)	Learning Rate [0.000625]
9: TRAIN [1][2990/3416]	Time 0.043 (0.058)	Data 0.00095 (0.00093)	Tok/s 30930 (53681)	Loss/tok 2.6248 (3.3685)	Learning Rate [0.000625]
10: TRAIN [1][2990/3416]	Time 0.043 (0.058)	Data 0.00094 (0.00097)	Tok/s 30911 (53760)	Loss/tok 2.6396 (3.3624)	Learning Rate [0.000625]
13: TRAIN [1][2990/3416]	Time 0.043 (0.058)	Data 0.00136 (0.00099)	Tok/s 31421 (54039)	Loss/tok 2.7532 (3.3636)	Learning Rate [0.000625]
12: TRAIN [1][2990/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00097)	Tok/s 30820 (53937)	Loss/tok 2.6635 (3.3672)	Learning Rate [0.000625]
11: TRAIN [1][2990/3416]	Time 0.044 (0.058)	Data 0.00094 (0.00097)	Tok/s 30798 (53840)	Loss/tok 2.7674 (3.3627)	Learning Rate [0.000625]
7: TRAIN [1][2990/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00092)	Tok/s 30872 (53539)	Loss/tok 2.6914 (3.3589)	Learning Rate [0.000625]
15: Gradient norm: inf
14: Gradient norm: inf
15: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
13: Gradient norm: inf
1: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
12: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
12: Skipped batch, new scale: 1024.0
11: Gradient norm: inf
3: Gradient norm: inf
10: Gradient norm: inf
3: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
4: Gradient norm: inf
9: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
9: Skipped batch, new scale: 1024.0
8: Gradient norm: inf
7: Gradient norm: inf
6: Gradient norm: inf
8: Skipped batch, new scale: 1024.0
5: Gradient norm: inf
7: Skipped batch, new scale: 1024.0
6: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
14: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00091)	Tok/s 65589 (54142)	Loss/tok 3.4193 (3.3639)	Learning Rate [0.000625]
13: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00104 (0.00099)	Tok/s 65621 (54038)	Loss/tok 3.3939 (3.3632)	Learning Rate [0.000625]
12: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00104 (0.00097)	Tok/s 65646 (53935)	Loss/tok 3.4879 (3.3668)	Learning Rate [0.000625]
0: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00088 (0.00091)	Tok/s 65511 (52920)	Loss/tok 3.1593 (3.3658)	Learning Rate [0.000625]
11: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00083 (0.00097)	Tok/s 65661 (53838)	Loss/tok 3.5476 (3.3625)	Learning Rate [0.000625]
1: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00091)	Tok/s 65478 (53019)	Loss/tok 3.2070 (3.3630)	Learning Rate [0.000625]
10: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00097)	Tok/s 65612 (53758)	Loss/tok 3.2106 (3.3620)	Learning Rate [0.000625]
2: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00097 (0.00098)	Tok/s 65507 (53120)	Loss/tok 3.3620 (3.3625)	Learning Rate [0.000625]
9: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00081 (0.00093)	Tok/s 65591 (53679)	Loss/tok 3.3937 (3.3682)	Learning Rate [0.000625]
15: TRAIN [1][3000/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00091)	Tok/s 65874 (54242)	Loss/tok 3.3962 (3.3612)	Learning Rate [0.000625]
3: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00096 (0.00098)	Tok/s 65465 (53209)	Loss/tok 3.4486 (3.3627)	Learning Rate [0.000625]
4: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00092)	Tok/s 65502 (53293)	Loss/tok 3.0327 (3.3596)	Learning Rate [0.000625]
8: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00093 (0.00097)	Tok/s 65602 (53615)	Loss/tok 3.4564 (3.3606)	Learning Rate [0.000625]
5: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00089 (0.00098)	Tok/s 65625 (53388)	Loss/tok 3.5271 (3.3648)	Learning Rate [0.000625]
6: TRAIN [1][3000/3416]	Time 0.066 (0.058)	Data 0.00110 (0.00099)	Tok/s 65542 (53454)	Loss/tok 3.3936 (3.3637)	Learning Rate [0.000625]
7: TRAIN [1][3000/3416]	Time 0.067 (0.058)	Data 0.00080 (0.00092)	Tok/s 65312 (53538)	Loss/tok 3.3301 (3.3586)	Learning Rate [0.000625]
6: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00099)	Tok/s 50443 (53467)	Loss/tok 3.2764 (3.3637)	Learning Rate [0.000625]
5: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00082 (0.00098)	Tok/s 50391 (53401)	Loss/tok 3.1470 (3.3648)	Learning Rate [0.000625]
3: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00098)	Tok/s 50502 (53222)	Loss/tok 3.1517 (3.3628)	Learning Rate [0.000625]
4: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00092)	Tok/s 50430 (53307)	Loss/tok 2.9388 (3.3594)	Learning Rate [0.000625]
8: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00089 (0.00097)	Tok/s 50918 (53628)	Loss/tok 3.4586 (3.3606)	Learning Rate [0.000625]
9: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00083 (0.00093)	Tok/s 51419 (53692)	Loss/tok 3.2037 (3.3681)	Learning Rate [0.000625]
2: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00114 (0.00098)	Tok/s 50383 (53133)	Loss/tok 3.2420 (3.3626)	Learning Rate [0.000625]
1: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00088 (0.00091)	Tok/s 50356 (53032)	Loss/tok 3.1398 (3.3630)	Learning Rate [0.000625]
0: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00091)	Tok/s 50279 (52933)	Loss/tok 3.0356 (3.3655)	Learning Rate [0.000625]
15: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00091)	Tok/s 51507 (54254)	Loss/tok 3.2412 (3.3610)	Learning Rate [0.000625]
12: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00097)	Tok/s 51324 (53948)	Loss/tok 3.0572 (3.3667)	Learning Rate [0.000625]
14: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00082 (0.00091)	Tok/s 51359 (54154)	Loss/tok 3.1433 (3.3638)	Learning Rate [0.000625]
11: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00097)	Tok/s 51285 (53851)	Loss/tok 3.1214 (3.3625)	Learning Rate [0.000625]
10: TRAIN [1][3010/3416]	Time 0.048 (0.058)	Data 0.00089 (0.00097)	Tok/s 51119 (53771)	Loss/tok 3.0662 (3.3617)	Learning Rate [0.000625]
7: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00085 (0.00092)	Tok/s 50338 (53551)	Loss/tok 3.3484 (3.3585)	Learning Rate [0.000625]
13: TRAIN [1][3010/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00099)	Tok/s 51293 (54050)	Loss/tok 3.0169 (3.3634)	Learning Rate [0.000625]
6: TRAIN [1][3020/3416]	Time 0.066 (0.058)	Data 0.00105 (0.00099)	Tok/s 55984 (53470)	Loss/tok 3.4180 (3.3637)	Learning Rate [0.000625]
8: TRAIN [1][3020/3416]	Time 0.066 (0.058)	Data 0.00095 (0.00097)	Tok/s 55910 (53632)	Loss/tok 3.6188 (3.3605)	Learning Rate [0.000625]
5: TRAIN [1][3020/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00098)	Tok/s 55787 (53404)	Loss/tok 3.2612 (3.3645)	Learning Rate [0.000625]
9: TRAIN [1][3020/3416]	Time 0.067 (0.058)	Data 0.00083 (0.00093)	Tok/s 55800 (53695)	Loss/tok 3.2297 (3.3680)	Learning Rate [0.000625]
4: TRAIN [1][3020/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00092)	Tok/s 55705 (53310)	Loss/tok 3.4615 (3.3591)	Learning Rate [0.000625]
10: TRAIN [1][3020/3416]	Time 0.067 (0.058)	Data 0.00087 (0.00097)	Tok/s 55718 (53774)	Loss/tok 3.4062 (3.3617)	Learning Rate [0.000625]
2: TRAIN [1][3020/3416]	Time 0.067 (0.058)	Data 0.00094 (0.00098)	Tok/s 55483 (53137)	Loss/tok 3.5332 (3.3624)	Learning Rate [0.000625]
3: TRAIN [1][3020/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00098)	Tok/s 55609 (53225)	Loss/tok 3.1063 (3.3626)	Learning Rate [0.000625]
12: TRAIN [1][3020/3416]	Time 0.067 (0.058)	Data 0.00096 (0.00097)	Tok/s 55582 (53950)	Loss/tok 3.3696 (3.3667)	Learning Rate [0.000625]
11: TRAIN [1][3020/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00097)	Tok/s 55638 (53854)	Loss/tok 3.3396 (3.3623)	Learning Rate [0.000625]
14: TRAIN [1][3020/3416]	Time 0.067 (0.058)	Data 0.00090 (0.00091)	Tok/s 55485 (54157)	Loss/tok 3.3360 (3.3635)	Learning Rate [0.000625]
1: TRAIN [1][3020/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00091)	Tok/s 55428 (53036)	Loss/tok 3.3124 (3.3628)	Learning Rate [0.000625]
13: TRAIN [1][3020/3416]	Time 0.067 (0.058)	Data 0.00102 (0.00099)	Tok/s 55472 (54053)	Loss/tok 3.5193 (3.3635)	Learning Rate [0.000625]
0: TRAIN [1][3020/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00091)	Tok/s 55337 (52937)	Loss/tok 3.4522 (3.3652)	Learning Rate [0.000625]
15: TRAIN [1][3020/3416]	Time 0.067 (0.058)	Data 0.00093 (0.00091)	Tok/s 55322 (54256)	Loss/tok 3.4501 (3.3607)	Learning Rate [0.000625]
7: TRAIN [1][3020/3416]	Time 0.066 (0.058)	Data 0.00090 (0.00092)	Tok/s 55954 (53554)	Loss/tok 3.3934 (3.3583)	Learning Rate [0.000625]
0: TRAIN [1][3030/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00091)	Tok/s 58930 (52894)	Loss/tok 3.3195 (3.3646)	Learning Rate [0.000625]
15: TRAIN [1][3030/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00091)	Tok/s 59246 (54213)	Loss/tok 3.4187 (3.3603)	Learning Rate [0.000625]
1: TRAIN [1][3030/3416]	Time 0.069 (0.058)	Data 0.00107 (0.00091)	Tok/s 58837 (52992)	Loss/tok 3.8400 (3.3627)	Learning Rate [0.000625]
14: TRAIN [1][3030/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 58820 (54113)	Loss/tok 3.5322 (3.3631)	Learning Rate [0.000625]
12: TRAIN [1][3030/3416]	Time 0.068 (0.058)	Data 0.00104 (0.00097)	Tok/s 58923 (53907)	Loss/tok 3.6055 (3.3661)	Learning Rate [0.000625]
2: TRAIN [1][3030/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 58692 (53093)	Loss/tok 3.2781 (3.3617)	Learning Rate [0.000625]
13: TRAIN [1][3030/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00099)	Tok/s 58891 (54009)	Loss/tok 3.4821 (3.3632)	Learning Rate [0.000625]
3: TRAIN [1][3030/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00098)	Tok/s 58635 (53181)	Loss/tok 3.4061 (3.3621)	Learning Rate [0.000625]
4: TRAIN [1][3030/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 58578 (53266)	Loss/tok 3.4646 (3.3585)	Learning Rate [0.000625]
5: TRAIN [1][3030/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 58569 (53360)	Loss/tok 3.6260 (3.3642)	Learning Rate [0.000625]
10: TRAIN [1][3030/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 58761 (53729)	Loss/tok 3.4249 (3.3611)	Learning Rate [0.000625]
11: TRAIN [1][3030/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 58807 (53810)	Loss/tok 3.5651 (3.3620)	Learning Rate [0.000625]
6: TRAIN [1][3030/3416]	Time 0.069 (0.058)	Data 0.00117 (0.00099)	Tok/s 58588 (53426)	Loss/tok 3.2783 (3.3630)	Learning Rate [0.000625]
9: TRAIN [1][3030/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00093)	Tok/s 58692 (53650)	Loss/tok 3.3997 (3.3673)	Learning Rate [0.000625]
8: TRAIN [1][3030/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00097)	Tok/s 58487 (53587)	Loss/tok 3.5431 (3.3600)	Learning Rate [0.000625]
7: TRAIN [1][3030/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00092)	Tok/s 58502 (53509)	Loss/tok 3.2843 (3.3578)	Learning Rate [0.000625]
10: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00097)	Tok/s 53390 (53734)	Loss/tok 2.9372 (3.3609)	Learning Rate [0.000625]
11: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00097)	Tok/s 53223 (53815)	Loss/tok 3.0506 (3.3618)	Learning Rate [0.000625]
9: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00093)	Tok/s 53335 (53655)	Loss/tok 3.1999 (3.3673)	Learning Rate [0.000625]
8: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00097)	Tok/s 53326 (53592)	Loss/tok 3.2815 (3.3601)	Learning Rate [0.000625]
12: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00097)	Tok/s 53099 (53911)	Loss/tok 3.1732 (3.3661)	Learning Rate [0.000625]
13: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00099)	Tok/s 52976 (54013)	Loss/tok 3.5076 (3.3631)	Learning Rate [0.000625]
14: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00091)	Tok/s 52815 (54117)	Loss/tok 3.3066 (3.3630)	Learning Rate [0.000625]
5: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00098)	Tok/s 53143 (53365)	Loss/tok 3.4994 (3.3640)	Learning Rate [0.000625]
6: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00111 (0.00099)	Tok/s 53268 (53431)	Loss/tok 3.2047 (3.3629)	Learning Rate [0.000625]
15: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00091)	Tok/s 52758 (54217)	Loss/tok 3.3949 (3.3603)	Learning Rate [0.000625]
0: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00091)	Tok/s 52798 (52899)	Loss/tok 3.1135 (3.3647)	Learning Rate [0.000625]
4: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00092)	Tok/s 53041 (53271)	Loss/tok 3.1329 (3.3583)	Learning Rate [0.000625]
2: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00098)	Tok/s 52804 (53097)	Loss/tok 3.0045 (3.3615)	Learning Rate [0.000625]
1: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00091)	Tok/s 52758 (52997)	Loss/tok 3.4499 (3.3627)	Learning Rate [0.000625]
3: TRAIN [1][3040/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00098)	Tok/s 52942 (53186)	Loss/tok 3.1962 (3.3620)	Learning Rate [0.000625]
7: TRAIN [1][3040/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00092)	Tok/s 53539 (53514)	Loss/tok 3.5369 (3.3576)	Learning Rate [0.000625]
12: TRAIN [1][3050/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00097)	Tok/s 69794 (53927)	Loss/tok 3.5294 (3.3663)	Learning Rate [0.000625]
14: TRAIN [1][3050/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 68878 (54132)	Loss/tok 3.1675 (3.3627)	Learning Rate [0.000625]
13: TRAIN [1][3050/3416]	Time 0.069 (0.058)	Data 0.00104 (0.00099)	Tok/s 69767 (54029)	Loss/tok 3.2458 (3.3630)	Learning Rate [0.000625]
10: TRAIN [1][3050/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00097)	Tok/s 68821 (53750)	Loss/tok 3.4150 (3.3610)	Learning Rate [0.000625]
0: TRAIN [1][3050/3416]	Time 0.070 (0.058)	Data 0.00079 (0.00091)	Tok/s 67980 (52915)	Loss/tok 3.4988 (3.3649)	Learning Rate [0.000625]
11: TRAIN [1][3050/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 68814 (53831)	Loss/tok 3.0913 (3.3616)	Learning Rate [0.000625]
1: TRAIN [1][3050/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00091)	Tok/s 67991 (53013)	Loss/tok 3.4771 (3.3626)	Learning Rate [0.000625]
4: TRAIN [1][3050/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00092)	Tok/s 68154 (53288)	Loss/tok 3.2455 (3.3581)	Learning Rate [0.000625]
9: TRAIN [1][3050/3416]	Time 0.070 (0.058)	Data 0.00101 (0.00093)	Tok/s 68783 (53671)	Loss/tok 3.4576 (3.3675)	Learning Rate [0.000625]
2: TRAIN [1][3050/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00098)	Tok/s 67976 (53114)	Loss/tok 3.4671 (3.3614)	Learning Rate [0.000625]
5: TRAIN [1][3050/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00098)	Tok/s 68610 (53382)	Loss/tok 3.2275 (3.3639)	Learning Rate [0.000625]
8: TRAIN [1][3050/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00097)	Tok/s 68851 (53608)	Loss/tok 3.6355 (3.3604)	Learning Rate [0.000625]
15: TRAIN [1][3050/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00091)	Tok/s 68790 (54232)	Loss/tok 3.3523 (3.3602)	Learning Rate [0.000625]
6: TRAIN [1][3050/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00099)	Tok/s 68852 (53448)	Loss/tok 3.2015 (3.3626)	Learning Rate [0.000625]
7: TRAIN [1][3050/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00092)	Tok/s 68922 (53531)	Loss/tok 3.3925 (3.3576)	Learning Rate [0.000625]
3: TRAIN [1][3050/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 68028 (53202)	Loss/tok 3.5576 (3.3619)	Learning Rate [0.000625]
15: TRAIN [1][3060/3416]	Time 0.049 (0.058)	Data 0.00083 (0.00091)	Tok/s 51106 (54219)	Loss/tok 2.8716 (3.3598)	Learning Rate [0.000625]
14: TRAIN [1][3060/3416]	Time 0.049 (0.058)	Data 0.00091 (0.00091)	Tok/s 51002 (54119)	Loss/tok 3.3625 (3.3623)	Learning Rate [0.000625]
0: TRAIN [1][3060/3416]	Time 0.049 (0.058)	Data 0.00077 (0.00091)	Tok/s 50994 (52904)	Loss/tok 3.2177 (3.3648)	Learning Rate [0.000625]
1: TRAIN [1][3060/3416]	Time 0.049 (0.058)	Data 0.00083 (0.00091)	Tok/s 50981 (53001)	Loss/tok 3.2941 (3.3623)	Learning Rate [0.000625]
13: TRAIN [1][3060/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00099)	Tok/s 50867 (54016)	Loss/tok 3.3213 (3.3626)	Learning Rate [0.000625]
12: TRAIN [1][3060/3416]	Time 0.049 (0.058)	Data 0.00095 (0.00097)	Tok/s 50719 (53914)	Loss/tok 3.4860 (3.3663)	Learning Rate [0.000625]
2: TRAIN [1][3060/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00098)	Tok/s 50919 (53102)	Loss/tok 3.2837 (3.3612)	Learning Rate [0.000625]
11: TRAIN [1][3060/3416]	Time 0.049 (0.058)	Data 0.00084 (0.00097)	Tok/s 50589 (53818)	Loss/tok 3.2684 (3.3612)	Learning Rate [0.000625]
3: TRAIN [1][3060/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00098)	Tok/s 50768 (53190)	Loss/tok 3.1749 (3.3619)	Learning Rate [0.000625]
10: TRAIN [1][3060/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00097)	Tok/s 50476 (53737)	Loss/tok 3.2057 (3.3610)	Learning Rate [0.000625]
4: TRAIN [1][3060/3416]	Time 0.049 (0.058)	Data 0.00081 (0.00092)	Tok/s 50659 (53275)	Loss/tok 3.1657 (3.3580)	Learning Rate [0.000625]
9: TRAIN [1][3060/3416]	Time 0.050 (0.058)	Data 0.00091 (0.00093)	Tok/s 50329 (53659)	Loss/tok 3.2938 (3.3672)	Learning Rate [0.000625]
5: TRAIN [1][3060/3416]	Time 0.049 (0.058)	Data 0.00107 (0.00098)	Tok/s 50557 (53370)	Loss/tok 3.1771 (3.3634)	Learning Rate [0.000625]
8: TRAIN [1][3060/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00097)	Tok/s 50362 (53596)	Loss/tok 3.5441 (3.3602)	Learning Rate [0.000625]
7: TRAIN [1][3060/3416]	Time 0.050 (0.058)	Data 0.00097 (0.00092)	Tok/s 50364 (53519)	Loss/tok 3.4151 (3.3574)	Learning Rate [0.000625]
6: TRAIN [1][3060/3416]	Time 0.049 (0.058)	Data 0.00087 (0.00099)	Tok/s 50431 (53436)	Loss/tok 3.3163 (3.3623)	Learning Rate [0.000625]
2: TRAIN [1][3070/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00098)	Tok/s 60841 (53106)	Loss/tok 3.6566 (3.3611)	Learning Rate [0.000625]
4: TRAIN [1][3070/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00092)	Tok/s 61665 (53280)	Loss/tok 3.2805 (3.3578)	Learning Rate [0.000625]
5: TRAIN [1][3070/3416]	Time 0.070 (0.058)	Data 0.00103 (0.00098)	Tok/s 61612 (53375)	Loss/tok 3.5110 (3.3633)	Learning Rate [0.000625]
6: TRAIN [1][3070/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00099)	Tok/s 61508 (53441)	Loss/tok 3.2193 (3.3623)	Learning Rate [0.000625]
0: TRAIN [1][3070/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00091)	Tok/s 60761 (52908)	Loss/tok 3.6077 (3.3649)	Learning Rate [0.000625]
15: TRAIN [1][3070/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00091)	Tok/s 61522 (54223)	Loss/tok 3.0869 (3.3596)	Learning Rate [0.000625]
8: TRAIN [1][3070/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 61445 (53600)	Loss/tok 3.5749 (3.3601)	Learning Rate [0.000625]
7: TRAIN [1][3070/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00092)	Tok/s 61398 (53523)	Loss/tok 3.3449 (3.3572)	Learning Rate [0.000625]
3: TRAIN [1][3070/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00098)	Tok/s 60772 (53194)	Loss/tok 3.3907 (3.3617)	Learning Rate [0.000625]
9: TRAIN [1][3070/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00093)	Tok/s 61419 (53663)	Loss/tok 3.1713 (3.3669)	Learning Rate [0.000625]
14: TRAIN [1][3070/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00091)	Tok/s 61505 (54123)	Loss/tok 3.3951 (3.3622)	Learning Rate [0.000625]
10: TRAIN [1][3070/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 61422 (53741)	Loss/tok 3.4357 (3.3609)	Learning Rate [0.000625]
13: TRAIN [1][3070/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 61484 (54020)	Loss/tok 3.5139 (3.3624)	Learning Rate [0.000625]
11: TRAIN [1][3070/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 61578 (53821)	Loss/tok 3.7179 (3.3613)	Learning Rate [0.000625]
12: TRAIN [1][3070/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00097)	Tok/s 61462 (53918)	Loss/tok 3.4235 (3.3663)	Learning Rate [0.000625]
1: TRAIN [1][3070/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00091)	Tok/s 60821 (53006)	Loss/tok 3.2167 (3.3624)	Learning Rate [0.000625]
15: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00091)	Tok/s 73450 (54212)	Loss/tok 3.2217 (3.3594)	Learning Rate [0.000625]
0: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00091)	Tok/s 71516 (52897)	Loss/tok 3.4770 (3.3646)	Learning Rate [0.000625]
14: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00085 (0.00091)	Tok/s 72776 (54112)	Loss/tok 3.4567 (3.3620)	Learning Rate [0.000625]
13: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00099)	Tok/s 72518 (54008)	Loss/tok 3.2151 (3.3621)	Learning Rate [0.000625]
12: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 72456 (53907)	Loss/tok 3.1548 (3.3657)	Learning Rate [0.000625]
2: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 71324 (53095)	Loss/tok 3.5192 (3.3607)	Learning Rate [0.000625]
10: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 72346 (53729)	Loss/tok 3.2564 (3.3605)	Learning Rate [0.000625]
11: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00097)	Tok/s 72315 (53810)	Loss/tok 3.4202 (3.3609)	Learning Rate [0.000625]
3: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00098)	Tok/s 71316 (53183)	Loss/tok 3.2490 (3.3613)	Learning Rate [0.000625]
4: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00092)	Tok/s 72062 (53268)	Loss/tok 3.3247 (3.3576)	Learning Rate [0.000625]
9: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 72275 (53651)	Loss/tok 3.0931 (3.3664)	Learning Rate [0.000625]
5: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00098)	Tok/s 72047 (53363)	Loss/tok 3.4120 (3.3630)	Learning Rate [0.000625]
8: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 72176 (53588)	Loss/tok 3.2558 (3.3598)	Learning Rate [0.000625]
7: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00092)	Tok/s 72093 (53511)	Loss/tok 3.4698 (3.3568)	Learning Rate [0.000625]
6: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00099)	Tok/s 71996 (53429)	Loss/tok 3.3717 (3.3617)	Learning Rate [0.000625]
1: TRAIN [1][3080/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00091)	Tok/s 71392 (52995)	Loss/tok 3.2220 (3.3621)	Learning Rate [0.000625]
10: TRAIN [1][3090/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 78331 (53732)	Loss/tok 3.3529 (3.3603)	Learning Rate [0.000625]
12: TRAIN [1][3090/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 78131 (53909)	Loss/tok 3.3271 (3.3658)	Learning Rate [0.000625]
11: TRAIN [1][3090/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00097)	Tok/s 78119 (53812)	Loss/tok 3.3682 (3.3610)	Learning Rate [0.000625]
8: TRAIN [1][3090/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 77407 (53590)	Loss/tok 3.2717 (3.3597)	Learning Rate [0.000625]
9: TRAIN [1][3090/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00093)	Tok/s 77319 (53654)	Loss/tok 3.0446 (3.3659)	Learning Rate [0.000625]
5: TRAIN [1][3090/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 77552 (53366)	Loss/tok 3.3584 (3.3630)	Learning Rate [0.000625]
13: TRAIN [1][3090/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00099)	Tok/s 78131 (54010)	Loss/tok 3.2655 (3.3618)	Learning Rate [0.000625]
6: TRAIN [1][3090/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00099)	Tok/s 77617 (53432)	Loss/tok 3.1810 (3.3616)	Learning Rate [0.000625]
4: TRAIN [1][3090/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00092)	Tok/s 77469 (53271)	Loss/tok 3.3693 (3.3572)	Learning Rate [0.000625]
14: TRAIN [1][3090/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00091)	Tok/s 78049 (54113)	Loss/tok 3.2857 (3.3620)	Learning Rate [0.000625]
7: TRAIN [1][3090/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 77408 (53514)	Loss/tok 3.1763 (3.3563)	Learning Rate [0.000625]
15: TRAIN [1][3090/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00091)	Tok/s 78098 (54213)	Loss/tok 3.2626 (3.3591)	Learning Rate [0.000625]
2: TRAIN [1][3090/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 77357 (53098)	Loss/tok 3.1915 (3.3604)	Learning Rate [0.000625]
0: TRAIN [1][3090/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00091)	Tok/s 76293 (52901)	Loss/tok 3.2906 (3.3644)	Learning Rate [0.000625]
3: TRAIN [1][3090/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00098)	Tok/s 77468 (53186)	Loss/tok 3.4470 (3.3612)	Learning Rate [0.000625]
1: TRAIN [1][3090/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00091)	Tok/s 76490 (52998)	Loss/tok 3.2558 (3.3618)	Learning Rate [0.000625]
12: TRAIN [1][3100/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00097)	Tok/s 50243 (53929)	Loss/tok 3.0979 (3.3655)	Learning Rate [0.000625]
13: TRAIN [1][3100/3416]	Time 0.047 (0.058)	Data 0.00103 (0.00099)	Tok/s 50141 (54030)	Loss/tok 3.3294 (3.3615)	Learning Rate [0.000625]
11: TRAIN [1][3100/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00097)	Tok/s 50230 (53832)	Loss/tok 3.4171 (3.3606)	Learning Rate [0.000625]
10: TRAIN [1][3100/3416]	Time 0.047 (0.058)	Data 0.00095 (0.00097)	Tok/s 50244 (53752)	Loss/tok 3.2184 (3.3599)	Learning Rate [0.000625]
14: TRAIN [1][3100/3416]	Time 0.047 (0.058)	Data 0.00093 (0.00091)	Tok/s 50051 (54133)	Loss/tok 2.9267 (3.3617)	Learning Rate [0.000625]
15: TRAIN [1][3100/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00091)	Tok/s 49892 (54233)	Loss/tok 3.1610 (3.3588)	Learning Rate [0.000625]
9: TRAIN [1][3100/3416]	Time 0.047 (0.058)	Data 0.00106 (0.00093)	Tok/s 50243 (53674)	Loss/tok 3.0652 (3.3655)	Learning Rate [0.000625]
8: TRAIN [1][3100/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00097)	Tok/s 50155 (53610)	Loss/tok 3.2250 (3.3594)	Learning Rate [0.000625]
7: TRAIN [1][3100/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00092)	Tok/s 50102 (53534)	Loss/tok 3.0406 (3.3560)	Learning Rate [0.000625]
2: TRAIN [1][3100/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00098)	Tok/s 49672 (53118)	Loss/tok 3.2994 (3.3602)	Learning Rate [0.000625]
6: TRAIN [1][3100/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00099)	Tok/s 49939 (53452)	Loss/tok 3.2711 (3.3614)	Learning Rate [0.000625]
5: TRAIN [1][3100/3416]	Time 0.048 (0.058)	Data 0.00097 (0.00098)	Tok/s 49824 (53386)	Loss/tok 3.0512 (3.3626)	Learning Rate [0.000625]
4: TRAIN [1][3100/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00092)	Tok/s 49740 (53291)	Loss/tok 3.3177 (3.3570)	Learning Rate [0.000625]
3: TRAIN [1][3100/3416]	Time 0.048 (0.058)	Data 0.00093 (0.00098)	Tok/s 49668 (53206)	Loss/tok 3.5120 (3.3608)	Learning Rate [0.000625]
0: TRAIN [1][3100/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00091)	Tok/s 49476 (52920)	Loss/tok 2.9467 (3.3637)	Learning Rate [0.000625]
1: TRAIN [1][3100/3416]	Time 0.048 (0.058)	Data 0.00087 (0.00091)	Tok/s 49308 (53018)	Loss/tok 3.2700 (3.3619)	Learning Rate [0.000625]
10: TRAIN [1][3110/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00097)	Tok/s 38802 (53751)	Loss/tok 3.2552 (3.3598)	Learning Rate [0.000625]
12: TRAIN [1][3110/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00097)	Tok/s 38735 (53928)	Loss/tok 3.0492 (3.3650)	Learning Rate [0.000625]
13: TRAIN [1][3110/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00099)	Tok/s 39001 (54029)	Loss/tok 3.3004 (3.3615)	Learning Rate [0.000625]
9: TRAIN [1][3110/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00093)	Tok/s 38798 (53673)	Loss/tok 3.0758 (3.3650)	Learning Rate [0.000625]
8: TRAIN [1][3110/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00097)	Tok/s 38835 (53609)	Loss/tok 3.1694 (3.3593)	Learning Rate [0.000625]
14: TRAIN [1][3110/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00091)	Tok/s 38537 (54132)	Loss/tok 3.3098 (3.3615)	Learning Rate [0.000625]
11: TRAIN [1][3110/3416]	Time 0.049 (0.058)	Data 0.00094 (0.00097)	Tok/s 38820 (53831)	Loss/tok 3.0834 (3.3601)	Learning Rate [0.000625]
15: TRAIN [1][3110/3416]	Time 0.050 (0.058)	Data 0.00082 (0.00091)	Tok/s 38550 (54232)	Loss/tok 3.0393 (3.3584)	Learning Rate [0.000625]
7: TRAIN [1][3110/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00092)	Tok/s 38937 (53533)	Loss/tok 2.9904 (3.3555)	Learning Rate [0.000625]
0: TRAIN [1][3110/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00091)	Tok/s 37273 (52919)	Loss/tok 2.9290 (3.3632)	Learning Rate [0.000625]
5: TRAIN [1][3110/3416]	Time 0.050 (0.058)	Data 0.00094 (0.00098)	Tok/s 38758 (53385)	Loss/tok 3.1818 (3.3622)	Learning Rate [0.000625]
4: TRAIN [1][3110/3416]	Time 0.050 (0.058)	Data 0.00076 (0.00092)	Tok/s 38703 (53290)	Loss/tok 3.2007 (3.3566)	Learning Rate [0.000625]
6: TRAIN [1][3110/3416]	Time 0.049 (0.058)	Data 0.00103 (0.00099)	Tok/s 38831 (53451)	Loss/tok 3.2377 (3.3613)	Learning Rate [0.000625]
2: TRAIN [1][3110/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00098)	Tok/s 37295 (53116)	Loss/tok 3.0901 (3.3597)	Learning Rate [0.000625]
3: TRAIN [1][3110/3416]	Time 0.050 (0.058)	Data 0.00096 (0.00098)	Tok/s 38121 (53204)	Loss/tok 3.1279 (3.3606)	Learning Rate [0.000625]
1: TRAIN [1][3110/3416]	Time 0.050 (0.058)	Data 0.00085 (0.00091)	Tok/s 37260 (53016)	Loss/tok 2.7705 (3.3614)	Learning Rate [0.000625]
14: TRAIN [1][3120/3416]	Time 0.070 (0.058)	Data 0.00083 (0.00091)	Tok/s 68973 (54151)	Loss/tok 3.2411 (3.3613)	Learning Rate [0.000625]
11: TRAIN [1][3120/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00097)	Tok/s 69019 (53850)	Loss/tok 3.2951 (3.3601)	Learning Rate [0.000625]
12: TRAIN [1][3120/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 68990 (53947)	Loss/tok 3.2067 (3.3647)	Learning Rate [0.000625]
13: TRAIN [1][3120/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00099)	Tok/s 68878 (54048)	Loss/tok 3.4544 (3.3612)	Learning Rate [0.000625]
10: TRAIN [1][3120/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00097)	Tok/s 68985 (53770)	Loss/tok 3.5123 (3.3596)	Learning Rate [0.000625]
2: TRAIN [1][3120/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00098)	Tok/s 68536 (53135)	Loss/tok 3.2652 (3.3594)	Learning Rate [0.000625]
9: TRAIN [1][3120/3416]	Time 0.070 (0.058)	Data 0.00084 (0.00093)	Tok/s 68999 (53692)	Loss/tok 3.3604 (3.3648)	Learning Rate [0.000625]
8: TRAIN [1][3120/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 69043 (53629)	Loss/tok 3.3789 (3.3594)	Learning Rate [0.000625]
5: TRAIN [1][3120/3416]	Time 0.069 (0.058)	Data 0.00124 (0.00098)	Tok/s 69104 (53403)	Loss/tok 3.4027 (3.3620)	Learning Rate [0.000625]
0: TRAIN [1][3120/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00091)	Tok/s 68058 (52937)	Loss/tok 3.4469 (3.3631)	Learning Rate [0.000625]
6: TRAIN [1][3120/3416]	Time 0.069 (0.058)	Data 0.00113 (0.00099)	Tok/s 69186 (53470)	Loss/tok 3.3157 (3.3609)	Learning Rate [0.000625]
7: TRAIN [1][3120/3416]	Time 0.070 (0.058)	Data 0.00082 (0.00092)	Tok/s 69060 (53553)	Loss/tok 3.3721 (3.3556)	Learning Rate [0.000625]
3: TRAIN [1][3120/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 69041 (53223)	Loss/tok 3.1528 (3.3605)	Learning Rate [0.000625]
4: TRAIN [1][3120/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00092)	Tok/s 69281 (53309)	Loss/tok 3.4616 (3.3565)	Learning Rate [0.000625]
15: TRAIN [1][3120/3416]	Time 0.070 (0.058)	Data 0.00081 (0.00091)	Tok/s 69308 (54251)	Loss/tok 3.3821 (3.3582)	Learning Rate [0.000625]
1: TRAIN [1][3120/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00091)	Tok/s 68354 (53035)	Loss/tok 3.3668 (3.3609)	Learning Rate [0.000625]
7: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
14: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00091)	Tok/s 56749 (54160)	Loss/tok 3.5635 (3.3614)	Learning Rate [0.0003125]
11: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00111 (0.00097)	Tok/s 56566 (53859)	Loss/tok 3.2438 (3.3600)	Learning Rate [0.0003125]
12: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00097)	Tok/s 56509 (53956)	Loss/tok 3.2411 (3.3646)	Learning Rate [0.0003125]
13: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00099)	Tok/s 56554 (54057)	Loss/tok 3.3485 (3.3612)	Learning Rate [0.0003125]
15: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00091)	Tok/s 56652 (54260)	Loss/tok 3.5759 (3.3581)	Learning Rate [0.0003125]
0: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00091)	Tok/s 55707 (52947)	Loss/tok 3.6796 (3.3631)	Learning Rate [0.0003125]
10: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 56349 (53779)	Loss/tok 3.6869 (3.3596)	Learning Rate [0.0003125]
2: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 55633 (53144)	Loss/tok 3.5293 (3.3594)	Learning Rate [0.0003125]
9: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00093)	Tok/s 56175 (53701)	Loss/tok 3.2991 (3.3647)	Learning Rate [0.0003125]
3: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00098)	Tok/s 55587 (53232)	Loss/tok 3.1939 (3.3604)	Learning Rate [0.0003125]
4: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 56129 (53318)	Loss/tok 3.2826 (3.3563)	Learning Rate [0.0003125]
8: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00097)	Tok/s 56243 (53638)	Loss/tok 3.3660 (3.3591)	Learning Rate [0.0003125]
7: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00092)	Tok/s 56243 (53561)	Loss/tok 3.4702 (3.3553)	Learning Rate [0.0003125]
6: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00099)	Tok/s 56283 (53479)	Loss/tok 3.4648 (3.3607)	Learning Rate [0.0003125]
1: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00084 (0.00091)	Tok/s 55712 (53045)	Loss/tok 3.5449 (3.3608)	Learning Rate [0.0003125]
5: TRAIN [1][3130/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 56270 (53412)	Loss/tok 3.3075 (3.3618)	Learning Rate [0.0003125]
9: TRAIN [1][3140/3416]	Time 0.059 (0.058)	Data 0.00086 (0.00093)	Tok/s 52751 (53716)	Loss/tok 3.3746 (3.3647)	Learning Rate [0.0003125]
10: TRAIN [1][3140/3416]	Time 0.059 (0.058)	Data 0.00088 (0.00097)	Tok/s 52778 (53794)	Loss/tok 3.4014 (3.3594)	Learning Rate [0.0003125]
8: TRAIN [1][3140/3416]	Time 0.060 (0.058)	Data 0.00085 (0.00097)	Tok/s 52681 (53653)	Loss/tok 3.3309 (3.3588)	Learning Rate [0.0003125]
7: TRAIN [1][3140/3416]	Time 0.060 (0.058)	Data 0.00083 (0.00092)	Tok/s 52553 (53577)	Loss/tok 3.2782 (3.3552)	Learning Rate [0.0003125]
11: TRAIN [1][3140/3416]	Time 0.059 (0.058)	Data 0.00111 (0.00097)	Tok/s 52857 (53874)	Loss/tok 3.2684 (3.3602)	Learning Rate [0.0003125]
12: TRAIN [1][3140/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00097)	Tok/s 52810 (53970)	Loss/tok 3.2190 (3.3645)	Learning Rate [0.0003125]
6: TRAIN [1][3140/3416]	Time 0.060 (0.058)	Data 0.00107 (0.00099)	Tok/s 52469 (53495)	Loss/tok 3.4063 (3.3605)	Learning Rate [0.0003125]
5: TRAIN [1][3140/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00098)	Tok/s 52451 (53428)	Loss/tok 3.4644 (3.3618)	Learning Rate [0.0003125]
13: TRAIN [1][3140/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00099)	Tok/s 52786 (54072)	Loss/tok 3.3741 (3.3610)	Learning Rate [0.0003125]
4: TRAIN [1][3140/3416]	Time 0.060 (0.058)	Data 0.00082 (0.00092)	Tok/s 52419 (53333)	Loss/tok 3.1794 (3.3561)	Learning Rate [0.0003125]
14: TRAIN [1][3140/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00091)	Tok/s 52673 (54174)	Loss/tok 3.1855 (3.3610)	Learning Rate [0.0003125]
2: TRAIN [1][3140/3416]	Time 0.060 (0.058)	Data 0.00087 (0.00098)	Tok/s 52508 (53160)	Loss/tok 3.4645 (3.3593)	Learning Rate [0.0003125]
15: TRAIN [1][3140/3416]	Time 0.060 (0.058)	Data 0.00099 (0.00091)	Tok/s 52592 (54274)	Loss/tok 3.1262 (3.3579)	Learning Rate [0.0003125]
3: TRAIN [1][3140/3416]	Time 0.060 (0.058)	Data 0.00088 (0.00098)	Tok/s 52446 (53247)	Loss/tok 3.4200 (3.3606)	Learning Rate [0.0003125]
0: TRAIN [1][3140/3416]	Time 0.060 (0.058)	Data 0.00086 (0.00091)	Tok/s 52508 (52963)	Loss/tok 3.3546 (3.3631)	Learning Rate [0.0003125]
1: TRAIN [1][3140/3416]	Time 0.060 (0.058)	Data 0.00092 (0.00091)	Tok/s 52474 (53060)	Loss/tok 3.4993 (3.3611)	Learning Rate [0.0003125]
4: TRAIN [1][3150/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00092)	Tok/s 60707 (53334)	Loss/tok 3.3841 (3.3555)	Learning Rate [0.0003125]
2: TRAIN [1][3150/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00098)	Tok/s 60797 (53160)	Loss/tok 3.6536 (3.3592)	Learning Rate [0.0003125]
3: TRAIN [1][3150/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00098)	Tok/s 60805 (53248)	Loss/tok 3.5017 (3.3601)	Learning Rate [0.0003125]
5: TRAIN [1][3150/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00098)	Tok/s 60613 (53428)	Loss/tok 3.3929 (3.3615)	Learning Rate [0.0003125]
6: TRAIN [1][3150/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00099)	Tok/s 60677 (53495)	Loss/tok 3.5432 (3.3602)	Learning Rate [0.0003125]
0: TRAIN [1][3150/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00091)	Tok/s 60792 (52964)	Loss/tok 3.4391 (3.3630)	Learning Rate [0.0003125]
7: TRAIN [1][3150/3416]	Time 0.069 (0.058)	Data 0.00080 (0.00092)	Tok/s 60695 (53577)	Loss/tok 3.4222 (3.3548)	Learning Rate [0.0003125]
8: TRAIN [1][3150/3416]	Time 0.069 (0.058)	Data 0.00110 (0.00097)	Tok/s 60688 (53654)	Loss/tok 3.4841 (3.3584)	Learning Rate [0.0003125]
15: TRAIN [1][3150/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00091)	Tok/s 61061 (54275)	Loss/tok 3.3968 (3.3575)	Learning Rate [0.0003125]
14: TRAIN [1][3150/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00091)	Tok/s 60784 (54175)	Loss/tok 3.4048 (3.3606)	Learning Rate [0.0003125]
10: TRAIN [1][3150/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00097)	Tok/s 60692 (53795)	Loss/tok 3.2491 (3.3591)	Learning Rate [0.0003125]
9: TRAIN [1][3150/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 60711 (53717)	Loss/tok 3.3794 (3.3640)	Learning Rate [0.0003125]
13: TRAIN [1][3150/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00099)	Tok/s 60736 (54072)	Loss/tok 3.1977 (3.3603)	Learning Rate [0.0003125]
12: TRAIN [1][3150/3416]	Time 0.068 (0.058)	Data 0.00100 (0.00097)	Tok/s 60751 (53971)	Loss/tok 3.4222 (3.3639)	Learning Rate [0.0003125]
11: TRAIN [1][3150/3416]	Time 0.068 (0.058)	Data 0.00107 (0.00097)	Tok/s 60765 (53875)	Loss/tok 3.4930 (3.3598)	Learning Rate [0.0003125]
1: TRAIN [1][3150/3416]	Time 0.068 (0.058)	Data 0.00110 (0.00091)	Tok/s 60813 (53061)	Loss/tok 3.2098 (3.3607)	Learning Rate [0.0003125]
12: Gradient norm: inf
11: Gradient norm: inf
13: Gradient norm: inf
12: Skipped batch, new scale: 1024.0
11: Skipped batch, new scale: 1024.0
13: Skipped batch, new scale: 1024.0
10: Gradient norm: inf
14: Gradient norm: inf
15: Gradient norm: inf
10: Skipped batch, new scale: 1024.0
9: Gradient norm: inf
14: Skipped batch, new scale: 1024.0
15: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
8: Gradient norm: inf
9: Skipped batch, new scale: 1024.0
6: Gradient norm: inf
5: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
8: Skipped batch, new scale: 1024.0
7: Gradient norm: inf
4: Gradient norm: inf
6: Skipped batch, new scale: 1024.0
5: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
4: Skipped batch, new scale: 1024.0
7: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
3: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00098)	Tok/s 50217 (53248)	Loss/tok 3.0957 (3.3597)	Learning Rate [0.0003125]
2: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00098)	Tok/s 50150 (53161)	Loss/tok 3.0939 (3.3589)	Learning Rate [0.0003125]
4: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00084 (0.00092)	Tok/s 50242 (53334)	Loss/tok 3.2234 (3.3552)	Learning Rate [0.0003125]
5: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00098)	Tok/s 50270 (53430)	Loss/tok 3.2169 (3.3612)	Learning Rate [0.0003125]
0: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00091)	Tok/s 50150 (52964)	Loss/tok 3.0552 (3.3626)	Learning Rate [0.0003125]
6: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00106 (0.00099)	Tok/s 50270 (53496)	Loss/tok 3.4003 (3.3600)	Learning Rate [0.0003125]
15: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00095 (0.00091)	Tok/s 51372 (54277)	Loss/tok 3.1260 (3.3572)	Learning Rate [0.0003125]
8: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00097)	Tok/s 50272 (53654)	Loss/tok 3.1163 (3.3579)	Learning Rate [0.0003125]
14: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00085 (0.00091)	Tok/s 51393 (54177)	Loss/tok 3.0880 (3.3601)	Learning Rate [0.0003125]
13: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00099)	Tok/s 51401 (54074)	Loss/tok 3.3178 (3.3598)	Learning Rate [0.0003125]
12: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00097)	Tok/s 51415 (53973)	Loss/tok 3.0397 (3.3636)	Learning Rate [0.0003125]
10: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00097)	Tok/s 51460 (53796)	Loss/tok 3.1757 (3.3588)	Learning Rate [0.0003125]
9: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00093)	Tok/s 51251 (53718)	Loss/tok 3.4386 (3.3635)	Learning Rate [0.0003125]
11: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00105 (0.00097)	Tok/s 51416 (53876)	Loss/tok 3.3859 (3.3593)	Learning Rate [0.0003125]
7: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00092)	Tok/s 50192 (53578)	Loss/tok 3.1121 (3.3542)	Learning Rate [0.0003125]
1: TRAIN [1][3160/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00091)	Tok/s 50143 (53062)	Loss/tok 2.9859 (3.3604)	Learning Rate [0.0003125]
10: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00097)	Tok/s 34305 (53779)	Loss/tok 2.8403 (3.3585)	Learning Rate [0.0003125]
9: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00093)	Tok/s 34246 (53701)	Loss/tok 2.9349 (3.3633)	Learning Rate [0.0003125]
11: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00107 (0.00097)	Tok/s 34301 (53858)	Loss/tok 3.0313 (3.3590)	Learning Rate [0.0003125]
8: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00097)	Tok/s 34229 (53637)	Loss/tok 3.1860 (3.3578)	Learning Rate [0.0003125]
12: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00097)	Tok/s 34324 (53955)	Loss/tok 2.9359 (3.3633)	Learning Rate [0.0003125]
13: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00099)	Tok/s 34557 (54057)	Loss/tok 3.4036 (3.3597)	Learning Rate [0.0003125]
7: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00092)	Tok/s 34232 (53561)	Loss/tok 2.9866 (3.3539)	Learning Rate [0.0003125]
5: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00108 (0.00098)	Tok/s 34275 (53411)	Loss/tok 2.6451 (3.3609)	Learning Rate [0.0003125]
6: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00106 (0.00099)	Tok/s 34236 (53479)	Loss/tok 3.3122 (3.3599)	Learning Rate [0.0003125]
14: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00091)	Tok/s 35501 (54160)	Loss/tok 3.2310 (3.3598)	Learning Rate [0.0003125]
15: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00091)	Tok/s 35524 (54260)	Loss/tok 3.0078 (3.3569)	Learning Rate [0.0003125]
4: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00092)	Tok/s 34237 (53316)	Loss/tok 2.9356 (3.3550)	Learning Rate [0.0003125]
0: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00091)	Tok/s 34262 (52943)	Loss/tok 2.9288 (3.3624)	Learning Rate [0.0003125]
2: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00106 (0.00098)	Tok/s 34251 (53141)	Loss/tok 3.2034 (3.3587)	Learning Rate [0.0003125]
3: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00096 (0.00098)	Tok/s 34174 (53229)	Loss/tok 2.9374 (3.3596)	Learning Rate [0.0003125]
1: TRAIN [1][3170/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00091)	Tok/s 34275 (53041)	Loss/tok 2.9325 (3.3601)	Learning Rate [0.0003125]
2: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00098)	Tok/s 47049 (53115)	Loss/tok 3.0964 (3.3583)	Learning Rate [0.0003125]
0: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00091)	Tok/s 47150 (52917)	Loss/tok 3.1191 (3.3620)	Learning Rate [0.0003125]
3: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00087 (0.00098)	Tok/s 47000 (53202)	Loss/tok 2.8698 (3.3592)	Learning Rate [0.0003125]
15: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00101 (0.00091)	Tok/s 48493 (54233)	Loss/tok 3.0000 (3.3563)	Learning Rate [0.0003125]
4: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00093 (0.00092)	Tok/s 46983 (53289)	Loss/tok 3.1330 (3.3546)	Learning Rate [0.0003125]
14: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00091)	Tok/s 48491 (54133)	Loss/tok 3.2562 (3.3594)	Learning Rate [0.0003125]
5: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00086 (0.00098)	Tok/s 46983 (53384)	Loss/tok 2.9773 (3.3604)	Learning Rate [0.0003125]
13: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00099)	Tok/s 48561 (54030)	Loss/tok 3.0680 (3.3593)	Learning Rate [0.0003125]
12: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 48553 (53927)	Loss/tok 3.1673 (3.3631)	Learning Rate [0.0003125]
10: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 47202 (53751)	Loss/tok 2.9509 (3.3580)	Learning Rate [0.0003125]
7: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00084 (0.00092)	Tok/s 46988 (53534)	Loss/tok 2.9869 (3.3534)	Learning Rate [0.0003125]
6: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00106 (0.00099)	Tok/s 46983 (53452)	Loss/tok 3.0021 (3.3594)	Learning Rate [0.0003125]
11: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00102 (0.00097)	Tok/s 48535 (53830)	Loss/tok 2.9138 (3.3585)	Learning Rate [0.0003125]
1: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00088 (0.00091)	Tok/s 47105 (53015)	Loss/tok 3.2126 (3.3598)	Learning Rate [0.0003125]
9: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00085 (0.00093)	Tok/s 47007 (53673)	Loss/tok 2.9351 (3.3629)	Learning Rate [0.0003125]
8: TRAIN [1][3180/3416]	Time 0.045 (0.058)	Data 0.00092 (0.00097)	Tok/s 47003 (53610)	Loss/tok 3.4804 (3.3576)	Learning Rate [0.0003125]
3: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00091 (0.00098)	Tok/s 58298 (53213)	Loss/tok 3.3760 (3.3593)	Learning Rate [0.0003125]
4: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00092)	Tok/s 58206 (53300)	Loss/tok 3.1463 (3.3543)	Learning Rate [0.0003125]
5: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00090 (0.00098)	Tok/s 58109 (53396)	Loss/tok 3.0783 (3.3600)	Learning Rate [0.0003125]
2: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00098)	Tok/s 58310 (53124)	Loss/tok 3.2516 (3.3579)	Learning Rate [0.0003125]
6: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00107 (0.00099)	Tok/s 58024 (53463)	Loss/tok 3.6676 (3.3594)	Learning Rate [0.0003125]
0: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00091)	Tok/s 58042 (52925)	Loss/tok 3.4041 (3.3617)	Learning Rate [0.0003125]
15: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00106 (0.00091)	Tok/s 58187 (54246)	Loss/tok 3.2427 (3.3561)	Learning Rate [0.0003125]
7: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00094 (0.00092)	Tok/s 57876 (53545)	Loss/tok 3.2883 (3.3532)	Learning Rate [0.0003125]
8: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00089 (0.00097)	Tok/s 57769 (53622)	Loss/tok 3.5031 (3.3575)	Learning Rate [0.0003125]
12: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00101 (0.00097)	Tok/s 57706 (53939)	Loss/tok 3.3422 (3.3626)	Learning Rate [0.0003125]
9: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00093)	Tok/s 57646 (53685)	Loss/tok 3.2907 (3.3623)	Learning Rate [0.0003125]
14: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00103 (0.00091)	Tok/s 57845 (54145)	Loss/tok 3.0245 (3.3592)	Learning Rate [0.0003125]
10: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00092 (0.00097)	Tok/s 57561 (53763)	Loss/tok 3.4171 (3.3580)	Learning Rate [0.0003125]
13: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00086 (0.00099)	Tok/s 57754 (54042)	Loss/tok 3.2750 (3.3590)	Learning Rate [0.0003125]
11: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00112 (0.00097)	Tok/s 57579 (53842)	Loss/tok 3.7192 (3.3584)	Learning Rate [0.0003125]
1: TRAIN [1][3190/3416]	Time 0.064 (0.058)	Data 0.00096 (0.00091)	Tok/s 58143 (53024)	Loss/tok 3.3352 (3.3597)	Learning Rate [0.0003125]
0: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00091)	Tok/s 50479 (52937)	Loss/tok 3.4598 (3.3615)	Learning Rate [0.0003125]
2: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00122 (0.00098)	Tok/s 50311 (53136)	Loss/tok 3.3170 (3.3575)	Learning Rate [0.0003125]
15: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00107 (0.00091)	Tok/s 51580 (54258)	Loss/tok 3.2432 (3.3556)	Learning Rate [0.0003125]
3: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00106 (0.00098)	Tok/s 50248 (53224)	Loss/tok 3.2395 (3.3589)	Learning Rate [0.0003125]
14: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00111 (0.00091)	Tok/s 51542 (54156)	Loss/tok 3.4280 (3.3588)	Learning Rate [0.0003125]
4: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00097 (0.00092)	Tok/s 50243 (53311)	Loss/tok 3.2809 (3.3540)	Learning Rate [0.0003125]
13: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00098 (0.00099)	Tok/s 51520 (54053)	Loss/tok 3.2877 (3.3586)	Learning Rate [0.0003125]
12: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00097)	Tok/s 51538 (53950)	Loss/tok 2.9327 (3.3622)	Learning Rate [0.0003125]
5: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00104 (0.00098)	Tok/s 50868 (53407)	Loss/tok 3.1582 (3.3595)	Learning Rate [0.0003125]
11: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00115 (0.00097)	Tok/s 51479 (53854)	Loss/tok 3.0947 (3.3577)	Learning Rate [0.0003125]
6: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00117 (0.00099)	Tok/s 51389 (53475)	Loss/tok 3.3223 (3.3589)	Learning Rate [0.0003125]
10: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00105 (0.00097)	Tok/s 51288 (53774)	Loss/tok 3.0781 (3.3577)	Learning Rate [0.0003125]
1: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00091)	Tok/s 50316 (53036)	Loss/tok 3.4074 (3.3591)	Learning Rate [0.0003125]
7: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00099 (0.00092)	Tok/s 51357 (53557)	Loss/tok 3.2634 (3.3528)	Learning Rate [0.0003125]
8: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00103 (0.00097)	Tok/s 51335 (53633)	Loss/tok 2.8712 (3.3568)	Learning Rate [0.0003125]
9: TRAIN [1][3200/3416]	Time 0.055 (0.058)	Data 0.00101 (0.00093)	Tok/s 51398 (53696)	Loss/tok 3.3889 (3.3619)	Learning Rate [0.0003125]
15: TRAIN [1][3210/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00091)	Tok/s 58498 (54256)	Loss/tok 3.3986 (3.3555)	Learning Rate [0.0003125]
0: TRAIN [1][3210/3416]	Time 0.069 (0.058)	Data 0.00082 (0.00091)	Tok/s 57495 (52938)	Loss/tok 3.4180 (3.3612)	Learning Rate [0.0003125]
2: TRAIN [1][3210/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00098)	Tok/s 57406 (53136)	Loss/tok 3.1303 (3.3573)	Learning Rate [0.0003125]
14: TRAIN [1][3210/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00091)	Tok/s 58603 (54156)	Loss/tok 3.3311 (3.3588)	Learning Rate [0.0003125]
13: TRAIN [1][3210/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00099)	Tok/s 58345 (54052)	Loss/tok 3.0880 (3.3584)	Learning Rate [0.0003125]
12: TRAIN [1][3210/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00097)	Tok/s 58153 (53950)	Loss/tok 3.2174 (3.3618)	Learning Rate [0.0003125]
11: TRAIN [1][3210/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 58093 (53853)	Loss/tok 3.4715 (3.3575)	Learning Rate [0.0003125]
4: TRAIN [1][3210/3416]	Time 0.069 (0.058)	Data 0.00083 (0.00092)	Tok/s 57158 (53311)	Loss/tok 3.6376 (3.3541)	Learning Rate [0.0003125]
10: TRAIN [1][3210/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00097)	Tok/s 58080 (53774)	Loss/tok 3.2714 (3.3577)	Learning Rate [0.0003125]
9: TRAIN [1][3210/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00093)	Tok/s 57927 (53696)	Loss/tok 3.4542 (3.3614)	Learning Rate [0.0003125]
3: TRAIN [1][3210/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00098)	Tok/s 57227 (53224)	Loss/tok 3.2243 (3.3586)	Learning Rate [0.0003125]
7: TRAIN [1][3210/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00092)	Tok/s 56927 (53556)	Loss/tok 3.4328 (3.3527)	Learning Rate [0.0003125]
8: TRAIN [1][3210/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00097)	Tok/s 56943 (53632)	Loss/tok 3.3326 (3.3566)	Learning Rate [0.0003125]
1: TRAIN [1][3210/3416]	Time 0.069 (0.058)	Data 0.00090 (0.00091)	Tok/s 57397 (53036)	Loss/tok 3.6226 (3.3591)	Learning Rate [0.0003125]
6: TRAIN [1][3210/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00099)	Tok/s 56945 (53474)	Loss/tok 3.2512 (3.3587)	Learning Rate [0.0003125]
5: TRAIN [1][3210/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00098)	Tok/s 57037 (53407)	Loss/tok 3.4399 (3.3597)	Learning Rate [0.0003125]
4: TRAIN [1][3220/3416]	Time 0.046 (0.058)	Data 0.00084 (0.00092)	Tok/s 49769 (53328)	Loss/tok 3.1694 (3.3540)	Learning Rate [0.0003125]
5: TRAIN [1][3220/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00098)	Tok/s 49842 (53424)	Loss/tok 3.3354 (3.3598)	Learning Rate [0.0003125]
3: TRAIN [1][3220/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00098)	Tok/s 49629 (53241)	Loss/tok 3.0843 (3.3583)	Learning Rate [0.0003125]
6: TRAIN [1][3220/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00099)	Tok/s 49878 (53491)	Loss/tok 3.2623 (3.3586)	Learning Rate [0.0003125]
2: TRAIN [1][3220/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00098)	Tok/s 49494 (53153)	Loss/tok 3.1967 (3.3570)	Learning Rate [0.0003125]
7: TRAIN [1][3220/3416]	Time 0.046 (0.058)	Data 0.00088 (0.00092)	Tok/s 49778 (53573)	Loss/tok 3.2158 (3.3525)	Learning Rate [0.0003125]
8: TRAIN [1][3220/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00097)	Tok/s 49660 (53649)	Loss/tok 2.9009 (3.3562)	Learning Rate [0.0003125]
9: TRAIN [1][3220/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00093)	Tok/s 49576 (53713)	Loss/tok 2.9574 (3.3612)	Learning Rate [0.0003125]
0: TRAIN [1][3220/3416]	Time 0.047 (0.058)	Data 0.00084 (0.00091)	Tok/s 49277 (52955)	Loss/tok 3.1838 (3.3611)	Learning Rate [0.0003125]
15: TRAIN [1][3220/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00091)	Tok/s 50493 (54273)	Loss/tok 3.0161 (3.3552)	Learning Rate [0.0003125]
14: TRAIN [1][3220/3416]	Time 0.047 (0.058)	Data 0.00098 (0.00091)	Tok/s 50517 (54172)	Loss/tok 3.1697 (3.3587)	Learning Rate [0.0003125]
10: TRAIN [1][3220/3416]	Time 0.047 (0.058)	Data 0.00086 (0.00097)	Tok/s 49370 (53791)	Loss/tok 3.1113 (3.3576)	Learning Rate [0.0003125]
11: TRAIN [1][3220/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00097)	Tok/s 50543 (53871)	Loss/tok 3.2319 (3.3576)	Learning Rate [0.0003125]
13: TRAIN [1][3220/3416]	Time 0.047 (0.058)	Data 0.00091 (0.00099)	Tok/s 50520 (54069)	Loss/tok 3.0661 (3.3576)	Learning Rate [0.0003125]
12: TRAIN [1][3220/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00097)	Tok/s 50589 (53967)	Loss/tok 2.8775 (3.3616)	Learning Rate [0.0003125]
1: TRAIN [1][3220/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00091)	Tok/s 49378 (53053)	Loss/tok 3.4280 (3.3591)	Learning Rate [0.0003125]
12: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00082 (0.00097)	Tok/s 34285 (53966)	Loss/tok 2.9868 (3.3615)	Learning Rate [0.0003125]
13: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00099)	Tok/s 34354 (54069)	Loss/tok 3.2255 (3.3572)	Learning Rate [0.0003125]
11: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00090 (0.00097)	Tok/s 34283 (53870)	Loss/tok 2.9752 (3.3572)	Learning Rate [0.0003125]
10: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00097)	Tok/s 34285 (53790)	Loss/tok 2.7947 (3.3570)	Learning Rate [0.0003125]
14: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00091)	Tok/s 34336 (54172)	Loss/tok 2.8390 (3.3581)	Learning Rate [0.0003125]
15: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00091)	Tok/s 35526 (54273)	Loss/tok 3.1069 (3.3548)	Learning Rate [0.0003125]
0: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00081 (0.00091)	Tok/s 34346 (52954)	Loss/tok 3.0635 (3.3609)	Learning Rate [0.0003125]
9: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00093)	Tok/s 34255 (53712)	Loss/tok 3.1855 (3.3608)	Learning Rate [0.0003125]
8: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00086 (0.00097)	Tok/s 34244 (53648)	Loss/tok 2.8975 (3.3558)	Learning Rate [0.0003125]
2: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00098)	Tok/s 34313 (53152)	Loss/tok 3.0213 (3.3566)	Learning Rate [0.0003125]
7: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00092)	Tok/s 34242 (53571)	Loss/tok 3.0033 (3.3521)	Learning Rate [0.0003125]
6: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00099)	Tok/s 34300 (53490)	Loss/tok 2.8685 (3.3583)	Learning Rate [0.0003125]
5: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00099 (0.00098)	Tok/s 34307 (53422)	Loss/tok 2.9046 (3.3593)	Learning Rate [0.0003125]
4: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00087 (0.00092)	Tok/s 34288 (53327)	Loss/tok 2.9350 (3.3539)	Learning Rate [0.0003125]
3: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00098)	Tok/s 34303 (53240)	Loss/tok 2.8251 (3.3580)	Learning Rate [0.0003125]
1: TRAIN [1][3230/3416]	Time 0.052 (0.058)	Data 0.00097 (0.00091)	Tok/s 34346 (53052)	Loss/tok 3.1913 (3.3591)	Learning Rate [0.0003125]
4: TRAIN [1][3240/3416]	Time 0.067 (0.058)	Data 0.00086 (0.00092)	Tok/s 55061 (53329)	Loss/tok 3.3559 (3.3537)	Learning Rate [0.0003125]
5: TRAIN [1][3240/3416]	Time 0.067 (0.058)	Data 0.00092 (0.00098)	Tok/s 55098 (53424)	Loss/tok 3.3577 (3.3591)	Learning Rate [0.0003125]
6: TRAIN [1][3240/3416]	Time 0.067 (0.058)	Data 0.00097 (0.00099)	Tok/s 55149 (53492)	Loss/tok 3.2421 (3.3582)	Learning Rate [0.0003125]
7: TRAIN [1][3240/3416]	Time 0.067 (0.058)	Data 0.00089 (0.00092)	Tok/s 55040 (53573)	Loss/tok 3.3678 (3.3521)	Learning Rate [0.0003125]
2: TRAIN [1][3240/3416]	Time 0.068 (0.058)	Data 0.00087 (0.00098)	Tok/s 54865 (53154)	Loss/tok 3.4173 (3.3569)	Learning Rate [0.0003125]
8: TRAIN [1][3240/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00097)	Tok/s 54983 (53650)	Loss/tok 3.5029 (3.3557)	Learning Rate [0.0003125]
9: TRAIN [1][3240/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00093)	Tok/s 54932 (53713)	Loss/tok 3.4790 (3.3608)	Learning Rate [0.0003125]
0: TRAIN [1][3240/3416]	Time 0.068 (0.058)	Data 0.00083 (0.00091)	Tok/s 54659 (52957)	Loss/tok 3.4049 (3.3608)	Learning Rate [0.0003125]
10: TRAIN [1][3240/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 54872 (53791)	Loss/tok 3.4623 (3.3568)	Learning Rate [0.0003125]
15: TRAIN [1][3240/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00091)	Tok/s 54569 (54274)	Loss/tok 3.1945 (3.3549)	Learning Rate [0.0003125]
3: TRAIN [1][3240/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00098)	Tok/s 54961 (53242)	Loss/tok 3.3423 (3.3579)	Learning Rate [0.0003125]
12: TRAIN [1][3240/3416]	Time 0.068 (0.058)	Data 0.00080 (0.00097)	Tok/s 54714 (53967)	Loss/tok 3.7931 (3.3613)	Learning Rate [0.0003125]
14: TRAIN [1][3240/3416]	Time 0.068 (0.058)	Data 0.00098 (0.00091)	Tok/s 54626 (54173)	Loss/tok 3.5080 (3.3583)	Learning Rate [0.0003125]
11: TRAIN [1][3240/3416]	Time 0.068 (0.058)	Data 0.00101 (0.00097)	Tok/s 54728 (53871)	Loss/tok 3.2395 (3.3571)	Learning Rate [0.0003125]
13: TRAIN [1][3240/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00099)	Tok/s 54611 (54070)	Loss/tok 3.5170 (3.3571)	Learning Rate [0.0003125]
1: TRAIN [1][3240/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00091)	Tok/s 54854 (53054)	Loss/tok 3.2138 (3.3589)	Learning Rate [0.0003125]
6: TRAIN [1][3250/3416]	Time 0.059 (0.058)	Data 0.00108 (0.00099)	Tok/s 54092 (53504)	Loss/tok 3.2152 (3.3579)	Learning Rate [0.0003125]
5: TRAIN [1][3250/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00098)	Tok/s 53699 (53437)	Loss/tok 3.3474 (3.3589)	Learning Rate [0.0003125]
4: TRAIN [1][3250/3416]	Time 0.059 (0.058)	Data 0.00100 (0.00092)	Tok/s 52930 (53340)	Loss/tok 3.2509 (3.3535)	Learning Rate [0.0003125]
7: TRAIN [1][3250/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00092)	Tok/s 53911 (53585)	Loss/tok 3.1646 (3.3520)	Learning Rate [0.0003125]
8: TRAIN [1][3250/3416]	Time 0.060 (0.058)	Data 0.00120 (0.00097)	Tok/s 53778 (53662)	Loss/tok 3.5049 (3.3554)	Learning Rate [0.0003125]
10: TRAIN [1][3250/3416]	Time 0.060 (0.058)	Data 0.00113 (0.00097)	Tok/s 53628 (53803)	Loss/tok 3.2716 (3.3567)	Learning Rate [0.0003125]
9: TRAIN [1][3250/3416]	Time 0.060 (0.058)	Data 0.00107 (0.00093)	Tok/s 53764 (53725)	Loss/tok 3.3035 (3.3608)	Learning Rate [0.0003125]
3: TRAIN [1][3250/3416]	Time 0.059 (0.058)	Data 0.00115 (0.00098)	Tok/s 53174 (53253)	Loss/tok 3.5757 (3.3576)	Learning Rate [0.0003125]
2: TRAIN [1][3250/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00098)	Tok/s 52791 (53165)	Loss/tok 3.2255 (3.3568)	Learning Rate [0.0003125]
11: TRAIN [1][3250/3416]	Time 0.060 (0.058)	Data 0.00108 (0.00097)	Tok/s 53519 (53882)	Loss/tok 3.4123 (3.3572)	Learning Rate [0.0003125]
0: TRAIN [1][3250/3416]	Time 0.060 (0.058)	Data 0.00102 (0.00091)	Tok/s 52605 (52969)	Loss/tok 3.1938 (3.3606)	Learning Rate [0.0003125]
12: TRAIN [1][3250/3416]	Time 0.060 (0.058)	Data 0.00107 (0.00097)	Tok/s 53416 (53978)	Loss/tok 3.2770 (3.3613)	Learning Rate [0.0003125]
15: TRAIN [1][3250/3416]	Time 0.060 (0.058)	Data 0.00100 (0.00091)	Tok/s 53598 (54285)	Loss/tok 3.3109 (3.3547)	Learning Rate [0.0003125]
14: TRAIN [1][3250/3416]	Time 0.060 (0.058)	Data 0.00110 (0.00091)	Tok/s 53502 (54184)	Loss/tok 3.2926 (3.3581)	Learning Rate [0.0003125]
13: TRAIN [1][3250/3416]	Time 0.060 (0.058)	Data 0.00104 (0.00099)	Tok/s 53530 (54081)	Loss/tok 3.4435 (3.3568)	Learning Rate [0.0003125]
1: TRAIN [1][3250/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00091)	Tok/s 52739 (53066)	Loss/tok 3.3220 (3.3587)	Learning Rate [0.0003125]
9: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00093)	Tok/s 71893 (53718)	Loss/tok 3.4025 (3.3604)	Learning Rate [0.0003125]
10: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00105 (0.00097)	Tok/s 71855 (53795)	Loss/tok 3.3361 (3.3562)	Learning Rate [0.0003125]
8: TRAIN [1][3260/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 71765 (53654)	Loss/tok 3.2622 (3.3551)	Learning Rate [0.0003125]
11: TRAIN [1][3260/3416]	Time 0.070 (0.058)	Data 0.00093 (0.00097)	Tok/s 71787 (53875)	Loss/tok 3.3620 (3.3568)	Learning Rate [0.0003125]
1: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00095 (0.00091)	Tok/s 71058 (53060)	Loss/tok 3.1313 (3.3581)	Learning Rate [0.0003125]
7: TRAIN [1][3260/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00092)	Tok/s 71723 (53578)	Loss/tok 3.5476 (3.3518)	Learning Rate [0.0003125]
2: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00098)	Tok/s 70970 (53159)	Loss/tok 3.6025 (3.3565)	Learning Rate [0.0003125]
12: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00097 (0.00097)	Tok/s 71923 (53971)	Loss/tok 3.3721 (3.3609)	Learning Rate [0.0003125]
6: TRAIN [1][3260/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00099)	Tok/s 71601 (53497)	Loss/tok 3.1582 (3.3573)	Learning Rate [0.0003125]
15: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00091)	Tok/s 71905 (54278)	Loss/tok 3.4573 (3.3545)	Learning Rate [0.0003125]
4: TRAIN [1][3260/3416]	Time 0.070 (0.058)	Data 0.00086 (0.00092)	Tok/s 70846 (53334)	Loss/tok 3.4832 (3.3533)	Learning Rate [0.0003125]
0: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 71042 (52963)	Loss/tok 3.4795 (3.3605)	Learning Rate [0.0003125]
5: TRAIN [1][3260/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00098)	Tok/s 70788 (53430)	Loss/tok 3.3922 (3.3586)	Learning Rate [0.0003125]
3: TRAIN [1][3260/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00098)	Tok/s 70861 (53247)	Loss/tok 3.2364 (3.3571)	Learning Rate [0.0003125]
14: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00099 (0.00091)	Tok/s 72028 (54177)	Loss/tok 3.3804 (3.3579)	Learning Rate [0.0003125]
13: TRAIN [1][3260/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00099)	Tok/s 71855 (54074)	Loss/tok 3.3649 (3.3566)	Learning Rate [0.0003125]
12: TRAIN [1][3270/3416]	Time 0.058 (0.058)	Data 0.00101 (0.00097)	Tok/s 53753 (53966)	Loss/tok 3.1504 (3.3605)	Learning Rate [0.0003125]
11: TRAIN [1][3270/3416]	Time 0.058 (0.058)	Data 0.00093 (0.00097)	Tok/s 53663 (53870)	Loss/tok 3.3748 (3.3565)	Learning Rate [0.0003125]
13: TRAIN [1][3270/3416]	Time 0.058 (0.058)	Data 0.00113 (0.00099)	Tok/s 53701 (54070)	Loss/tok 3.3065 (3.3563)	Learning Rate [0.0003125]
10: TRAIN [1][3270/3416]	Time 0.059 (0.058)	Data 0.00105 (0.00097)	Tok/s 53576 (53790)	Loss/tok 3.3417 (3.3557)	Learning Rate [0.0003125]
14: TRAIN [1][3270/3416]	Time 0.058 (0.058)	Data 0.00115 (0.00091)	Tok/s 54198 (54172)	Loss/tok 3.5004 (3.3577)	Learning Rate [0.0003125]
9: TRAIN [1][3270/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00093)	Tok/s 53515 (53713)	Loss/tok 3.4967 (3.3602)	Learning Rate [0.0003125]
15: TRAIN [1][3270/3416]	Time 0.059 (0.058)	Data 0.00095 (0.00091)	Tok/s 54635 (54273)	Loss/tok 3.4674 (3.3545)	Learning Rate [0.0003125]
8: TRAIN [1][3270/3416]	Time 0.059 (0.058)	Data 0.00097 (0.00097)	Tok/s 53412 (53650)	Loss/tok 3.2593 (3.3549)	Learning Rate [0.0003125]
0: TRAIN [1][3270/3416]	Time 0.059 (0.058)	Data 0.00096 (0.00091)	Tok/s 53426 (52955)	Loss/tok 3.4912 (3.3600)	Learning Rate [0.0003125]
7: TRAIN [1][3270/3416]	Time 0.059 (0.058)	Data 0.00093 (0.00092)	Tok/s 53310 (53573)	Loss/tok 3.3830 (3.3516)	Learning Rate [0.0003125]
1: TRAIN [1][3270/3416]	Time 0.059 (0.058)	Data 0.00099 (0.00091)	Tok/s 53390 (53052)	Loss/tok 3.4827 (3.3579)	Learning Rate [0.0003125]
6: TRAIN [1][3270/3416]	Time 0.059 (0.058)	Data 0.00103 (0.00099)	Tok/s 53228 (53492)	Loss/tok 3.4763 (3.3571)	Learning Rate [0.0003125]
5: TRAIN [1][3270/3416]	Time 0.059 (0.058)	Data 0.00107 (0.00098)	Tok/s 53133 (53425)	Loss/tok 3.2901 (3.3584)	Learning Rate [0.0003125]
4: TRAIN [1][3270/3416]	Time 0.059 (0.058)	Data 0.00092 (0.00092)	Tok/s 53097 (53328)	Loss/tok 3.1483 (3.3529)	Learning Rate [0.0003125]
3: TRAIN [1][3270/3416]	Time 0.059 (0.058)	Data 0.00106 (0.00098)	Tok/s 53261 (53241)	Loss/tok 3.4894 (3.3569)	Learning Rate [0.0003125]
2: TRAIN [1][3270/3416]	Time 0.059 (0.058)	Data 0.00101 (0.00098)	Tok/s 52873 (53152)	Loss/tok 3.1677 (3.3562)	Learning Rate [0.0003125]
1: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00096 (0.00091)	Tok/s 49663 (53038)	Loss/tok 3.2437 (3.3576)	Learning Rate [0.0003125]
0: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00089 (0.00091)	Tok/s 49597 (52940)	Loss/tok 3.3806 (3.3596)	Learning Rate [0.0003125]
2: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00110 (0.00098)	Tok/s 49701 (53137)	Loss/tok 3.1865 (3.3560)	Learning Rate [0.0003125]
15: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00091)	Tok/s 49345 (54258)	Loss/tok 3.2552 (3.3542)	Learning Rate [0.0003125]
4: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00092)	Tok/s 49682 (53313)	Loss/tok 3.4326 (3.3526)	Learning Rate [0.0003125]
3: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00109 (0.00098)	Tok/s 49685 (53226)	Loss/tok 3.0068 (3.3565)	Learning Rate [0.0003125]
5: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00106 (0.00098)	Tok/s 49592 (53409)	Loss/tok 3.0559 (3.3580)	Learning Rate [0.0003125]
7: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00086 (0.00092)	Tok/s 49486 (53558)	Loss/tok 3.2605 (3.3513)	Learning Rate [0.0003125]
6: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00099 (0.00099)	Tok/s 49574 (53477)	Loss/tok 3.1035 (3.3568)	Learning Rate [0.0003125]
13: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00100 (0.00099)	Tok/s 49111 (54054)	Loss/tok 2.8811 (3.3560)	Learning Rate [0.0003125]
12: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00102 (0.00097)	Tok/s 49001 (53951)	Loss/tok 3.1806 (3.3602)	Learning Rate [0.0003125]
8: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00097)	Tok/s 49301 (53634)	Loss/tok 3.1176 (3.3544)	Learning Rate [0.0003125]
9: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00098 (0.00093)	Tok/s 49195 (53698)	Loss/tok 3.1311 (3.3596)	Learning Rate [0.0003125]
11: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00108 (0.00097)	Tok/s 49227 (53854)	Loss/tok 2.9710 (3.3559)	Learning Rate [0.0003125]
10: TRAIN [1][3280/3416]	Time 0.044 (0.058)	Data 0.00102 (0.00097)	Tok/s 49091 (53775)	Loss/tok 3.2104 (3.3557)	Learning Rate [0.0003125]
14: TRAIN [1][3280/3416]	Time 0.045 (0.058)	Data 0.00105 (0.00091)	Tok/s 48064 (54156)	Loss/tok 2.9894 (3.3572)	Learning Rate [0.0003125]
7: Upscaling, new scale: 2048.0
6: Upscaling, new scale: 2048.0
5: Upscaling, new scale: 2048.0
4: Upscaling, new scale: 2048.0
8: Upscaling, new scale: 2048.0
9: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
10: Upscaling, new scale: 2048.0
2: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
11: Upscaling, new scale: 2048.0
12: Upscaling, new scale: 2048.0
15: Upscaling, new scale: 2048.0
13: Upscaling, new scale: 2048.0
14: Upscaling, new scale: 2048.0
14: TRAIN [1][3290/3416]	Time 0.056 (0.058)	Data 0.00095 (0.00091)	Tok/s 53413 (54165)	Loss/tok 3.1215 (3.3566)	Learning Rate [0.0003125]
15: TRAIN [1][3290/3416]	Time 0.056 (0.058)	Data 0.00093 (0.00091)	Tok/s 53318 (54266)	Loss/tok 3.2834 (3.3538)	Learning Rate [0.0003125]
13: TRAIN [1][3290/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00099)	Tok/s 53398 (54063)	Loss/tok 3.1762 (3.3554)	Learning Rate [0.0003125]
0: TRAIN [1][3290/3416]	Time 0.057 (0.058)	Data 0.00096 (0.00091)	Tok/s 52055 (52949)	Loss/tok 3.4791 (3.3593)	Learning Rate [0.0003125]
12: TRAIN [1][3290/3416]	Time 0.056 (0.058)	Data 0.00107 (0.00097)	Tok/s 53067 (53959)	Loss/tok 3.3359 (3.3599)	Learning Rate [0.0003125]
11: TRAIN [1][3290/3416]	Time 0.056 (0.058)	Data 0.00105 (0.00097)	Tok/s 52244 (53862)	Loss/tok 2.9102 (3.3555)	Learning Rate [0.0003125]
10: TRAIN [1][3290/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00097)	Tok/s 52208 (53783)	Loss/tok 3.0575 (3.3555)	Learning Rate [0.0003125]
1: TRAIN [1][3290/3416]	Time 0.057 (0.058)	Data 0.00094 (0.00091)	Tok/s 51956 (53046)	Loss/tok 3.4029 (3.3575)	Learning Rate [0.0003125]
2: TRAIN [1][3290/3416]	Time 0.057 (0.058)	Data 0.00110 (0.00098)	Tok/s 51855 (53146)	Loss/tok 3.1370 (3.3558)	Learning Rate [0.0003125]
9: TRAIN [1][3290/3416]	Time 0.057 (0.058)	Data 0.00093 (0.00093)	Tok/s 52048 (53706)	Loss/tok 3.2776 (3.3593)	Learning Rate [0.0003125]
8: TRAIN [1][3290/3416]	Time 0.057 (0.058)	Data 0.00104 (0.00097)	Tok/s 51956 (53642)	Loss/tok 3.0705 (3.3541)	Learning Rate [0.0003125]
4: TRAIN [1][3290/3416]	Time 0.057 (0.058)	Data 0.00091 (0.00092)	Tok/s 51672 (53321)	Loss/tok 3.2652 (3.3524)	Learning Rate [0.0003125]
3: TRAIN [1][3290/3416]	Time 0.057 (0.058)	Data 0.00100 (0.00098)	Tok/s 51698 (53235)	Loss/tok 3.1287 (3.3564)	Learning Rate [0.0003125]
6: TRAIN [1][3290/3416]	Time 0.057 (0.058)	Data 0.00101 (0.00099)	Tok/s 51756 (53486)	Loss/tok 3.3300 (3.3565)	Learning Rate [0.0003125]
7: TRAIN [1][3290/3416]	Time 0.057 (0.058)	Data 0.00097 (0.00092)	Tok/s 51821 (53566)	Loss/tok 3.0595 (3.3510)	Learning Rate [0.0003125]
5: TRAIN [1][3290/3416]	Time 0.057 (0.058)	Data 0.00106 (0.00098)	Tok/s 51276 (53418)	Loss/tok 3.2779 (3.3577)	Learning Rate [0.0003125]
14: TRAIN [1][3300/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00091)	Tok/s 53494 (54161)	Loss/tok 3.1173 (3.3564)	Learning Rate [0.0003125]
15: TRAIN [1][3300/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00091)	Tok/s 53288 (54261)	Loss/tok 3.2461 (3.3537)	Learning Rate [0.0003125]
0: TRAIN [1][3300/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00091)	Tok/s 53261 (52946)	Loss/tok 3.3980 (3.3594)	Learning Rate [0.0003125]
13: TRAIN [1][3300/3416]	Time 0.051 (0.058)	Data 0.00097 (0.00099)	Tok/s 53444 (54059)	Loss/tok 3.2537 (3.3554)	Learning Rate [0.0003125]
11: TRAIN [1][3300/3416]	Time 0.051 (0.058)	Data 0.00088 (0.00097)	Tok/s 53530 (53858)	Loss/tok 3.0814 (3.3553)	Learning Rate [0.0003125]
12: TRAIN [1][3300/3416]	Time 0.052 (0.058)	Data 0.00115 (0.00097)	Tok/s 53419 (53955)	Loss/tok 3.2518 (3.3597)	Learning Rate [0.0003125]
1: TRAIN [1][3300/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00091)	Tok/s 53142 (53043)	Loss/tok 3.3106 (3.3573)	Learning Rate [0.0003125]
10: TRAIN [1][3300/3416]	Time 0.052 (0.058)	Data 0.00110 (0.00097)	Tok/s 53341 (53779)	Loss/tok 3.3131 (3.3553)	Learning Rate [0.0003125]
9: TRAIN [1][3300/3416]	Time 0.052 (0.058)	Data 0.00083 (0.00093)	Tok/s 53302 (53702)	Loss/tok 3.1485 (3.3591)	Learning Rate [0.0003125]
2: TRAIN [1][3300/3416]	Time 0.052 (0.058)	Data 0.00115 (0.00098)	Tok/s 52990 (53143)	Loss/tok 3.1537 (3.3557)	Learning Rate [0.0003125]
8: TRAIN [1][3300/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00097)	Tok/s 53164 (53638)	Loss/tok 3.2036 (3.3540)	Learning Rate [0.0003125]
4: TRAIN [1][3300/3416]	Time 0.052 (0.058)	Data 0.00092 (0.00092)	Tok/s 52933 (53318)	Loss/tok 3.2285 (3.3523)	Learning Rate [0.0003125]
7: TRAIN [1][3300/3416]	Time 0.052 (0.058)	Data 0.00091 (0.00092)	Tok/s 53075 (53562)	Loss/tok 3.1489 (3.3508)	Learning Rate [0.0003125]
5: TRAIN [1][3300/3416]	Time 0.052 (0.058)	Data 0.00111 (0.00098)	Tok/s 52909 (53415)	Loss/tok 3.3380 (3.3574)	Learning Rate [0.0003125]
3: TRAIN [1][3300/3416]	Time 0.052 (0.058)	Data 0.00102 (0.00098)	Tok/s 52871 (53232)	Loss/tok 3.2704 (3.3563)	Learning Rate [0.0003125]
6: TRAIN [1][3300/3416]	Time 0.052 (0.058)	Data 0.00100 (0.00099)	Tok/s 52953 (53482)	Loss/tok 3.4504 (3.3562)	Learning Rate [0.0003125]
1: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00081 (0.00091)	Tok/s 32825 (53036)	Loss/tok 2.8108 (3.3570)	Learning Rate [0.0003125]
15: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00102 (0.00091)	Tok/s 34110 (54252)	Loss/tok 3.0819 (3.3535)	Learning Rate [0.0003125]
0: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00090 (0.00091)	Tok/s 32731 (52939)	Loss/tok 2.7992 (3.3590)	Learning Rate [0.0003125]
2: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00121 (0.00098)	Tok/s 32827 (53135)	Loss/tok 2.7244 (3.3554)	Learning Rate [0.0003125]
14: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00104 (0.00091)	Tok/s 34015 (54152)	Loss/tok 3.0579 (3.3558)	Learning Rate [0.0003125]
4: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00092 (0.00092)	Tok/s 32860 (53310)	Loss/tok 2.6239 (3.3520)	Learning Rate [0.0003125]
5: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00113 (0.00098)	Tok/s 32856 (53407)	Loss/tok 2.9001 (3.3573)	Learning Rate [0.0003125]
3: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00098)	Tok/s 32843 (53224)	Loss/tok 2.9314 (3.3560)	Learning Rate [0.0003125]
13: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00117 (0.00099)	Tok/s 33945 (54050)	Loss/tok 2.8988 (3.3551)	Learning Rate [0.0003125]
12: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00107 (0.00097)	Tok/s 33958 (53946)	Loss/tok 3.0356 (3.3592)	Learning Rate [0.0003125]
11: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00101 (0.00097)	Tok/s 32763 (53849)	Loss/tok 2.8660 (3.3551)	Learning Rate [0.0003125]
10: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00110 (0.00097)	Tok/s 32585 (53770)	Loss/tok 2.7493 (3.3549)	Learning Rate [0.0003125]
9: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00087 (0.00093)	Tok/s 32638 (53693)	Loss/tok 2.9010 (3.3588)	Learning Rate [0.0003125]
7: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00094 (0.00092)	Tok/s 32685 (53554)	Loss/tok 2.8466 (3.3504)	Learning Rate [0.0003125]
8: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00100 (0.00097)	Tok/s 32637 (53630)	Loss/tok 2.9856 (3.3536)	Learning Rate [0.0003125]
6: TRAIN [1][3310/3416]	Time 0.047 (0.058)	Data 0.00097 (0.00099)	Tok/s 32707 (53474)	Loss/tok 2.7576 (3.3560)	Learning Rate [0.0003125]
2: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00116 (0.00098)	Tok/s 60439 (53126)	Loss/tok 3.3023 (3.3549)	Learning Rate [0.0003125]
1: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00089 (0.00091)	Tok/s 60308 (53026)	Loss/tok 3.3869 (3.3568)	Learning Rate [0.0003125]
3: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00103 (0.00098)	Tok/s 60410 (53215)	Loss/tok 3.5735 (3.3558)	Learning Rate [0.0003125]
14: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00096 (0.00091)	Tok/s 60346 (54145)	Loss/tok 3.4228 (3.3556)	Learning Rate [0.0003125]
0: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00095 (0.00091)	Tok/s 60232 (52928)	Loss/tok 3.3623 (3.3587)	Learning Rate [0.0003125]
4: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00097 (0.00092)	Tok/s 60355 (53302)	Loss/tok 3.2902 (3.3520)	Learning Rate [0.0003125]
12: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00105 (0.00097)	Tok/s 59969 (53939)	Loss/tok 3.3931 (3.3591)	Learning Rate [0.0003125]
15: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00110 (0.00091)	Tok/s 60974 (54246)	Loss/tok 3.4179 (3.3532)	Learning Rate [0.0003125]
5: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00112 (0.00098)	Tok/s 60297 (53399)	Loss/tok 3.4217 (3.3572)	Learning Rate [0.0003125]
13: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00091 (0.00099)	Tok/s 59929 (54043)	Loss/tok 3.3577 (3.3551)	Learning Rate [0.0003125]
6: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00094 (0.00099)	Tok/s 60197 (53466)	Loss/tok 3.4854 (3.3559)	Learning Rate [0.0003125]
8: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00093 (0.00097)	Tok/s 60005 (53622)	Loss/tok 3.5397 (3.3533)	Learning Rate [0.0003125]
10: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00102 (0.00097)	Tok/s 59849 (53762)	Loss/tok 3.3645 (3.3547)	Learning Rate [0.0003125]
7: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00088 (0.00092)	Tok/s 60045 (53546)	Loss/tok 3.4578 (3.3501)	Learning Rate [0.0003125]
9: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00086 (0.00093)	Tok/s 59895 (53685)	Loss/tok 3.5515 (3.3586)	Learning Rate [0.0003125]
11: TRAIN [1][3320/3416]	Time 0.068 (0.058)	Data 0.00092 (0.00097)	Tok/s 59830 (53841)	Loss/tok 3.6180 (3.3549)	Learning Rate [0.0003125]
10: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00097)	Tok/s 51783 (53750)	Loss/tok 3.2466 (3.3542)	Learning Rate [0.0003125]
11: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00104 (0.00097)	Tok/s 51700 (53830)	Loss/tok 3.3162 (3.3546)	Learning Rate [0.0003125]
9: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00093)	Tok/s 51840 (53673)	Loss/tok 3.3259 (3.3582)	Learning Rate [0.0003125]
8: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00088 (0.00097)	Tok/s 51846 (53610)	Loss/tok 3.2665 (3.3530)	Learning Rate [0.0003125]
12: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00102 (0.00097)	Tok/s 51556 (53928)	Loss/tok 3.2952 (3.3588)	Learning Rate [0.0003125]
7: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00085 (0.00092)	Tok/s 51853 (53534)	Loss/tok 3.0544 (3.3495)	Learning Rate [0.0003125]
13: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00099)	Tok/s 51447 (54031)	Loss/tok 3.2972 (3.3547)	Learning Rate [0.0003125]
14: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00099 (0.00091)	Tok/s 51293 (54134)	Loss/tok 3.1923 (3.3552)	Learning Rate [0.0003125]
5: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00109 (0.00098)	Tok/s 51643 (53386)	Loss/tok 3.1122 (3.3568)	Learning Rate [0.0003125]
6: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00099 (0.00099)	Tok/s 51740 (53454)	Loss/tok 3.5265 (3.3555)	Learning Rate [0.0003125]
15: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00106 (0.00091)	Tok/s 51251 (54234)	Loss/tok 3.1300 (3.3528)	Learning Rate [0.0003125]
2: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00113 (0.00098)	Tok/s 51355 (53112)	Loss/tok 3.1029 (3.3545)	Learning Rate [0.0003125]
4: TRAIN [1][3330/3416]	Time 0.048 (0.058)	Data 0.00086 (0.00092)	Tok/s 51479 (53288)	Loss/tok 3.3311 (3.3516)	Learning Rate [0.0003125]
0: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00091)	Tok/s 51003 (52912)	Loss/tok 3.1420 (3.3582)	Learning Rate [0.0003125]
3: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00098)	Tok/s 51372 (53201)	Loss/tok 3.3229 (3.3556)	Learning Rate [0.0003125]
1: TRAIN [1][3330/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00091)	Tok/s 51225 (53011)	Loss/tok 3.0735 (3.3564)	Learning Rate [0.0003125]
6: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00099)	Tok/s 55919 (53442)	Loss/tok 3.2235 (3.3551)	Learning Rate [0.0003125]
4: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00092)	Tok/s 55749 (53276)	Loss/tok 3.0191 (3.3512)	Learning Rate [0.0003125]
7: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00098 (0.00092)	Tok/s 55888 (53522)	Loss/tok 3.3980 (3.3493)	Learning Rate [0.0003125]
8: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00102 (0.00097)	Tok/s 55841 (53599)	Loss/tok 3.2866 (3.3529)	Learning Rate [0.0003125]
5: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00098)	Tok/s 55870 (53374)	Loss/tok 3.2294 (3.3565)	Learning Rate [0.0003125]
3: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00098)	Tok/s 55663 (53189)	Loss/tok 3.6350 (3.3554)	Learning Rate [0.0003125]
2: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00112 (0.00098)	Tok/s 55584 (53101)	Loss/tok 3.2749 (3.3539)	Learning Rate [0.0003125]
10: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00092 (0.00097)	Tok/s 55695 (53738)	Loss/tok 3.5819 (3.3541)	Learning Rate [0.0003125]
9: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00094 (0.00093)	Tok/s 55739 (53661)	Loss/tok 3.5503 (3.3579)	Learning Rate [0.0003125]
11: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00114 (0.00097)	Tok/s 55585 (53817)	Loss/tok 3.5496 (3.3543)	Learning Rate [0.0003125]
0: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00091)	Tok/s 55329 (52902)	Loss/tok 3.3572 (3.3579)	Learning Rate [0.0003125]
12: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00093 (0.00097)	Tok/s 55497 (53915)	Loss/tok 3.5541 (3.3586)	Learning Rate [0.0003125]
1: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00089 (0.00091)	Tok/s 55396 (53000)	Loss/tok 3.3841 (3.3561)	Learning Rate [0.0003125]
15: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00100 (0.00091)	Tok/s 56258 (54221)	Loss/tok 3.2719 (3.3525)	Learning Rate [0.0003125]
13: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00091 (0.00099)	Tok/s 56162 (54019)	Loss/tok 3.5023 (3.3545)	Learning Rate [0.0003125]
14: TRAIN [1][3340/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00091)	Tok/s 56261 (54121)	Loss/tok 3.5956 (3.3550)	Learning Rate [0.0003125]
3: TRAIN [1][3350/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00098)	Tok/s 71387 (53197)	Loss/tok 3.3001 (3.3550)	Learning Rate [0.0003125]
4: TRAIN [1][3350/3416]	Time 0.069 (0.058)	Data 0.00087 (0.00092)	Tok/s 72059 (53284)	Loss/tok 3.2503 (3.3509)	Learning Rate [0.0003125]
2: TRAIN [1][3350/3416]	Time 0.069 (0.058)	Data 0.00103 (0.00098)	Tok/s 71007 (53108)	Loss/tok 3.2901 (3.3537)	Learning Rate [0.0003125]
15: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00091)	Tok/s 72611 (54229)	Loss/tok 3.2603 (3.3522)	Learning Rate [0.0003125]
0: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00088 (0.00091)	Tok/s 70869 (52909)	Loss/tok 3.2591 (3.3574)	Learning Rate [0.0003125]
1: TRAIN [1][3350/3416]	Time 0.069 (0.058)	Data 0.00085 (0.00091)	Tok/s 70909 (53007)	Loss/tok 3.5490 (3.3559)	Learning Rate [0.0003125]
5: TRAIN [1][3350/3416]	Time 0.069 (0.058)	Data 0.00096 (0.00098)	Tok/s 72044 (53382)	Loss/tok 3.2990 (3.3564)	Learning Rate [0.0003125]
14: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00092)	Tok/s 71735 (54128)	Loss/tok 3.2073 (3.3546)	Learning Rate [0.0003125]
6: TRAIN [1][3350/3416]	Time 0.069 (0.058)	Data 0.00101 (0.00099)	Tok/s 72049 (53450)	Loss/tok 3.3975 (3.3550)	Learning Rate [0.0003125]
13: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00090 (0.00099)	Tok/s 71695 (54026)	Loss/tok 3.4893 (3.3541)	Learning Rate [0.0003125]
12: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00091 (0.00097)	Tok/s 71702 (53922)	Loss/tok 3.2412 (3.3581)	Learning Rate [0.0003125]
10: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00089 (0.00097)	Tok/s 71754 (53746)	Loss/tok 3.5003 (3.3539)	Learning Rate [0.0003125]
7: TRAIN [1][3350/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00092)	Tok/s 71999 (53530)	Loss/tok 3.2879 (3.3490)	Learning Rate [0.0003125]
8: TRAIN [1][3350/3416]	Time 0.069 (0.058)	Data 0.00088 (0.00097)	Tok/s 71883 (53606)	Loss/tok 3.3524 (3.3527)	Learning Rate [0.0003125]
11: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00097)	Tok/s 71699 (53825)	Loss/tok 3.2995 (3.3541)	Learning Rate [0.0003125]
9: TRAIN [1][3350/3416]	Time 0.070 (0.058)	Data 0.00087 (0.00093)	Tok/s 71813 (53669)	Loss/tok 3.4668 (3.3576)	Learning Rate [0.0003125]
15: TRAIN [1][3360/3416]	Time 0.044 (0.058)	Data 0.00095 (0.00091)	Tok/s 49375 (54237)	Loss/tok 3.1590 (3.3521)	Learning Rate [0.0003125]
0: TRAIN [1][3360/3416]	Time 0.044 (0.058)	Data 0.00087 (0.00091)	Tok/s 49357 (52918)	Loss/tok 2.9591 (3.3573)	Learning Rate [0.0003125]
14: TRAIN [1][3360/3416]	Time 0.044 (0.058)	Data 0.00091 (0.00092)	Tok/s 49140 (54136)	Loss/tok 3.2168 (3.3544)	Learning Rate [0.0003125]
1: TRAIN [1][3360/3416]	Time 0.044 (0.058)	Data 0.00077 (0.00091)	Tok/s 49300 (53016)	Loss/tok 3.1132 (3.3557)	Learning Rate [0.0003125]
13: TRAIN [1][3360/3416]	Time 0.044 (0.058)	Data 0.00090 (0.00099)	Tok/s 48984 (54034)	Loss/tok 3.3183 (3.3541)	Learning Rate [0.0003125]
12: TRAIN [1][3360/3416]	Time 0.045 (0.058)	Data 0.00098 (0.00097)	Tok/s 48897 (53931)	Loss/tok 3.1042 (3.3578)	Learning Rate [0.0003125]
2: TRAIN [1][3360/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00098)	Tok/s 49294 (53118)	Loss/tok 3.0923 (3.3536)	Learning Rate [0.0003125]
4: TRAIN [1][3360/3416]	Time 0.044 (0.058)	Data 0.00080 (0.00092)	Tok/s 49220 (53293)	Loss/tok 3.3043 (3.3507)	Learning Rate [0.0003125]
11: TRAIN [1][3360/3416]	Time 0.045 (0.058)	Data 0.00099 (0.00097)	Tok/s 48883 (53833)	Loss/tok 3.0191 (3.3539)	Learning Rate [0.0003125]
9: TRAIN [1][3360/3416]	Time 0.044 (0.058)	Data 0.00084 (0.00093)	Tok/s 48900 (53677)	Loss/tok 3.0870 (3.3574)	Learning Rate [0.0003125]
10: TRAIN [1][3360/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00097)	Tok/s 48860 (53754)	Loss/tok 3.0967 (3.3537)	Learning Rate [0.0003125]
3: TRAIN [1][3360/3416]	Time 0.044 (0.058)	Data 0.00097 (0.00098)	Tok/s 49292 (53206)	Loss/tok 3.1900 (3.3550)	Learning Rate [0.0003125]
5: TRAIN [1][3360/3416]	Time 0.044 (0.058)	Data 0.00104 (0.00098)	Tok/s 49096 (53391)	Loss/tok 3.1322 (3.3561)	Learning Rate [0.0003125]
7: TRAIN [1][3360/3416]	Time 0.044 (0.058)	Data 0.00085 (0.00092)	Tok/s 48929 (53538)	Loss/tok 3.0934 (3.3486)	Learning Rate [0.0003125]
8: TRAIN [1][3360/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00097)	Tok/s 48868 (53615)	Loss/tok 3.3056 (3.3526)	Learning Rate [0.0003125]
6: TRAIN [1][3360/3416]	Time 0.044 (0.058)	Data 0.00093 (0.00099)	Tok/s 48934 (53458)	Loss/tok 3.2815 (3.3549)	Learning Rate [0.0003125]
14: TRAIN [1][3370/3416]	Time 0.055 (0.058)	Data 0.00093 (0.00092)	Tok/s 51905 (54120)	Loss/tok 3.0352 (3.3540)	Learning Rate [0.0003125]
15: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00096 (0.00091)	Tok/s 51844 (54221)	Loss/tok 3.1359 (3.3519)	Learning Rate [0.0003125]
13: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00104 (0.00099)	Tok/s 51802 (54018)	Loss/tok 3.1261 (3.3537)	Learning Rate [0.0003125]
12: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00112 (0.00097)	Tok/s 51703 (53914)	Loss/tok 3.2563 (3.3576)	Learning Rate [0.0003125]
0: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00091)	Tok/s 50593 (52899)	Loss/tok 3.5109 (3.3571)	Learning Rate [0.0003125]
11: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00097)	Tok/s 51619 (53817)	Loss/tok 3.1269 (3.3535)	Learning Rate [0.0003125]
1: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00084 (0.00091)	Tok/s 50624 (52997)	Loss/tok 3.3625 (3.3554)	Learning Rate [0.0003125]
10: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00102 (0.00097)	Tok/s 51609 (53738)	Loss/tok 3.2854 (3.3532)	Learning Rate [0.0003125]
2: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00098 (0.00098)	Tok/s 50641 (53099)	Loss/tok 3.1528 (3.3531)	Learning Rate [0.0003125]
9: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00093)	Tok/s 51064 (53661)	Loss/tok 3.2631 (3.3570)	Learning Rate [0.0003125]
4: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00082 (0.00092)	Tok/s 50565 (53275)	Loss/tok 3.0338 (3.3503)	Learning Rate [0.0003125]
8: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00100 (0.00097)	Tok/s 50440 (53598)	Loss/tok 3.1324 (3.3523)	Learning Rate [0.0003125]
5: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00100 (0.00098)	Tok/s 50517 (53373)	Loss/tok 3.1045 (3.3558)	Learning Rate [0.0003125]
7: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00085 (0.00092)	Tok/s 50442 (53521)	Loss/tok 3.2954 (3.3482)	Learning Rate [0.0003125]
3: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00123 (0.00098)	Tok/s 50708 (53188)	Loss/tok 3.2358 (3.3547)	Learning Rate [0.0003125]
6: TRAIN [1][3370/3416]	Time 0.056 (0.058)	Data 0.00099 (0.00099)	Tok/s 50296 (53441)	Loss/tok 3.3887 (3.3544)	Learning Rate [0.0003125]
7: TRAIN [1][3380/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00092)	Tok/s 32499 (53522)	Loss/tok 3.1402 (3.3478)	Learning Rate [0.0003125]
14: TRAIN [1][3380/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00092)	Tok/s 33463 (54121)	Loss/tok 2.9658 (3.3535)	Learning Rate [0.0003125]
2: TRAIN [1][3380/3416]	Time 0.050 (0.058)	Data 0.00092 (0.00098)	Tok/s 32302 (53101)	Loss/tok 2.8725 (3.3527)	Learning Rate [0.0003125]
0: TRAIN [1][3380/3416]	Time 0.050 (0.058)	Data 0.00089 (0.00091)	Tok/s 32285 (52900)	Loss/tok 2.9406 (3.3570)	Learning Rate [0.0003125]
4: TRAIN [1][3380/3416]	Time 0.049 (0.058)	Data 0.00088 (0.00092)	Tok/s 32476 (53276)	Loss/tok 2.9855 (3.3501)	Learning Rate [0.0003125]
15: TRAIN [1][3380/3416]	Time 0.050 (0.058)	Data 0.00088 (0.00091)	Tok/s 33537 (54222)	Loss/tok 2.9490 (3.3519)	Learning Rate [0.0003125]
1: TRAIN [1][3380/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00091)	Tok/s 32317 (52999)	Loss/tok 2.9418 (3.3551)	Learning Rate [0.0003125]
12: TRAIN [1][3380/3416]	Time 0.050 (0.058)	Data 0.00102 (0.00097)	Tok/s 33473 (53916)	Loss/tok 3.0823 (3.3574)	Learning Rate [0.0003125]
5: TRAIN [1][3380/3416]	Time 0.049 (0.058)	Data 0.00093 (0.00098)	Tok/s 32496 (53374)	Loss/tok 2.9333 (3.3555)	Learning Rate [0.0003125]
11: TRAIN [1][3380/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00097)	Tok/s 33156 (53817)	Loss/tok 2.9162 (3.3532)	Learning Rate [0.0003125]
9: TRAIN [1][3380/3416]	Time 0.049 (0.058)	Data 0.00090 (0.00093)	Tok/s 32348 (53661)	Loss/tok 2.9074 (3.3567)	Learning Rate [0.0003125]
13: TRAIN [1][3380/3416]	Time 0.050 (0.058)	Data 0.00090 (0.00099)	Tok/s 33475 (54019)	Loss/tok 3.0804 (3.3533)	Learning Rate [0.0003125]
8: TRAIN [1][3380/3416]	Time 0.049 (0.058)	Data 0.00092 (0.00097)	Tok/s 32405 (53598)	Loss/tok 3.0229 (3.3519)	Learning Rate [0.0003125]
6: TRAIN [1][3380/3416]	Time 0.049 (0.058)	Data 0.00089 (0.00099)	Tok/s 32481 (53442)	Loss/tok 2.8476 (3.3544)	Learning Rate [0.0003125]
3: TRAIN [1][3380/3416]	Time 0.049 (0.058)	Data 0.00098 (0.00098)	Tok/s 32436 (53189)	Loss/tok 2.8891 (3.3544)	Learning Rate [0.0003125]
10: TRAIN [1][3380/3416]	Time 0.050 (0.058)	Data 0.00095 (0.00097)	Tok/s 32289 (53738)	Loss/tok 2.7530 (3.3529)	Learning Rate [0.0003125]
14: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00108 (0.00092)	Tok/s 67913 (54108)	Loss/tok 3.3108 (3.3530)	Learning Rate [0.0003125]
15: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00096 (0.00091)	Tok/s 67827 (54210)	Loss/tok 3.4991 (3.3515)	Learning Rate [0.0003125]
0: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00094 (0.00091)	Tok/s 66800 (52884)	Loss/tok 3.2178 (3.3569)	Learning Rate [0.0003125]
12: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00123 (0.00097)	Tok/s 67913 (53903)	Loss/tok 3.1751 (3.3570)	Learning Rate [0.0003125]
13: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00099)	Tok/s 67864 (54006)	Loss/tok 3.4803 (3.3531)	Learning Rate [0.0003125]
1: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00091)	Tok/s 66738 (52983)	Loss/tok 3.5202 (3.3550)	Learning Rate [0.0003125]
2: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00102 (0.00098)	Tok/s 66629 (53086)	Loss/tok 3.4978 (3.3524)	Learning Rate [0.0003125]
11: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00097)	Tok/s 67845 (53804)	Loss/tok 3.2826 (3.3527)	Learning Rate [0.0003125]
10: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00106 (0.00097)	Tok/s 67830 (53725)	Loss/tok 3.2631 (3.3526)	Learning Rate [0.0003125]
3: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00109 (0.00098)	Tok/s 66627 (53175)	Loss/tok 3.3360 (3.3540)	Learning Rate [0.0003125]
4: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00092 (0.00091)	Tok/s 66604 (53261)	Loss/tok 3.2605 (3.3497)	Learning Rate [0.0003125]
9: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00095 (0.00093)	Tok/s 67759 (53649)	Loss/tok 3.4847 (3.3563)	Learning Rate [0.0003125]
8: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00097 (0.00097)	Tok/s 67665 (53586)	Loss/tok 3.4384 (3.3517)	Learning Rate [0.0003125]
5: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00099 (0.00098)	Tok/s 66622 (53360)	Loss/tok 3.1746 (3.3550)	Learning Rate [0.0003125]
6: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00100 (0.00099)	Tok/s 66611 (53428)	Loss/tok 3.3186 (3.3541)	Learning Rate [0.0003125]
7: TRAIN [1][3390/3416]	Time 0.070 (0.058)	Data 0.00098 (0.00092)	Tok/s 67286 (53502)	Loss/tok 3.4206 (3.3475)	Learning Rate [0.0003125]
1: TRAIN [1][3400/3416]	Time 0.045 (0.058)	Data 0.00091 (0.00091)	Tok/s 29588 (52980)	Loss/tok 2.5227 (3.3544)	Learning Rate [0.0003125]
0: TRAIN [1][3400/3416]	Time 0.045 (0.058)	Data 0.00089 (0.00091)	Tok/s 29542 (52881)	Loss/tok 2.7085 (3.3565)	Learning Rate [0.0003125]
2: TRAIN [1][3400/3416]	Time 0.045 (0.058)	Data 0.00094 (0.00098)	Tok/s 29585 (53083)	Loss/tok 2.7306 (3.3521)	Learning Rate [0.0003125]
15: TRAIN [1][3400/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00091)	Tok/s 31628 (54206)	Loss/tok 2.7606 (3.3512)	Learning Rate [0.0003125]
14: TRAIN [1][3400/3416]	Time 0.046 (0.058)	Data 0.00099 (0.00092)	Tok/s 30756 (54105)	Loss/tok 2.7635 (3.3527)	Learning Rate [0.0003125]
3: TRAIN [1][3400/3416]	Time 0.045 (0.058)	Data 0.00109 (0.00098)	Tok/s 30085 (53172)	Loss/tok 2.6665 (3.3539)	Learning Rate [0.0003125]
4: TRAIN [1][3400/3416]	Time 0.045 (0.058)	Data 0.00090 (0.00091)	Tok/s 30972 (53259)	Loss/tok 2.7320 (3.3494)	Learning Rate [0.0003125]
13: TRAIN [1][3400/3416]	Time 0.046 (0.058)	Data 0.00090 (0.00099)	Tok/s 30696 (54003)	Loss/tok 2.6237 (3.3527)	Learning Rate [0.0003125]
5: TRAIN [1][3400/3416]	Time 0.045 (0.058)	Data 0.00097 (0.00098)	Tok/s 30947 (53357)	Loss/tok 2.7166 (3.3547)	Learning Rate [0.0003125]
12: TRAIN [1][3400/3416]	Time 0.046 (0.058)	Data 0.00106 (0.00097)	Tok/s 30695 (53900)	Loss/tok 2.7383 (3.3567)	Learning Rate [0.0003125]
10: TRAIN [1][3400/3416]	Time 0.046 (0.058)	Data 0.00098 (0.00097)	Tok/s 30725 (53722)	Loss/tok 2.7704 (3.3523)	Learning Rate [0.0003125]
6: TRAIN [1][3400/3416]	Time 0.046 (0.058)	Data 0.00102 (0.00099)	Tok/s 30877 (53425)	Loss/tok 2.7729 (3.3538)	Learning Rate [0.0003125]
9: TRAIN [1][3400/3416]	Time 0.046 (0.058)	Data 0.00092 (0.00093)	Tok/s 30726 (53646)	Loss/tok 2.7271 (3.3560)	Learning Rate [0.0003125]
8: TRAIN [1][3400/3416]	Time 0.046 (0.058)	Data 0.00094 (0.00097)	Tok/s 30743 (53583)	Loss/tok 2.6033 (3.3513)	Learning Rate [0.0003125]
7: TRAIN [1][3400/3416]	Time 0.046 (0.058)	Data 0.00093 (0.00092)	Tok/s 30799 (53499)	Loss/tok 2.5892 (3.3471)	Learning Rate [0.0003125]
11: TRAIN [1][3400/3416]	Time 0.047 (0.058)	Data 0.00096 (0.00097)	Tok/s 29982 (53801)	Loss/tok 2.7765 (3.3523)	Learning Rate [0.0003125]
10: Upscaling, new scale: 4096.0
12: Upscaling, new scale: 4096.0
14: Upscaling, new scale: 4096.0
11: Upscaling, new scale: 4096.0
13: Upscaling, new scale: 4096.0
15: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
10: TRAIN [1][3410/3416]	Time 0.051 (0.058)	Data 0.00103 (0.00097)	Tok/s 52254 (53709)	Loss/tok 3.3752 (3.3519)	Learning Rate [0.0003125]
12: TRAIN [1][3410/3416]	Time 0.051 (0.058)	Data 0.00104 (0.00097)	Tok/s 53454 (53888)	Loss/tok 3.2388 (3.3561)	Learning Rate [0.0003125]
9: Upscaling, new scale: 4096.0
14: TRAIN [1][3410/3416]	Time 0.051 (0.058)	Data 0.00099 (0.00092)	Tok/s 53744 (54093)	Loss/tok 3.4805 (3.3523)	Learning Rate [0.0003125]
8: Upscaling, new scale: 4096.0
11: TRAIN [1][3410/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00097)	Tok/s 52281 (53789)	Loss/tok 3.1285 (3.3519)	Learning Rate [0.0003125]
13: TRAIN [1][3410/3416]	Time 0.051 (0.058)	Data 0.00102 (0.00099)	Tok/s 53622 (53991)	Loss/tok 3.3973 (3.3523)	Learning Rate [0.0003125]
7: Upscaling, new scale: 4096.0
15: TRAIN [1][3410/3416]	Time 0.051 (0.058)	Data 0.00092 (0.00091)	Tok/s 53595 (54193)	Loss/tok 3.2276 (3.3507)	Learning Rate [0.0003125]
0: TRAIN [1][3410/3416]	Time 0.051 (0.058)	Data 0.00090 (0.00091)	Tok/s 52301 (52869)	Loss/tok 3.2392 (3.3559)	Learning Rate [0.0003125]
1: Upscaling, new scale: 4096.0
9: TRAIN [1][3410/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00093)	Tok/s 52039 (53633)	Loss/tok 3.2267 (3.3555)	Learning Rate [0.0003125]
5: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
4: Upscaling, new scale: 4096.0
8: TRAIN [1][3410/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00097)	Tok/s 51937 (53570)	Loss/tok 3.1659 (3.3509)	Learning Rate [0.0003125]
6: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
1: TRAIN [1][3410/3416]	Time 0.051 (0.058)	Data 0.00093 (0.00091)	Tok/s 52241 (52968)	Loss/tok 3.2535 (3.3539)	Learning Rate [0.0003125]
7: TRAIN [1][3410/3416]	Time 0.052 (0.058)	Data 0.00088 (0.00092)	Tok/s 51930 (53487)	Loss/tok 3.0213 (3.3466)	Learning Rate [0.0003125]
2: TRAIN [1][3410/3416]	Time 0.052 (0.058)	Data 0.00101 (0.00098)	Tok/s 52094 (53070)	Loss/tok 3.0683 (3.3515)	Learning Rate [0.0003125]
5: TRAIN [1][3410/3416]	Time 0.052 (0.058)	Data 0.00093 (0.00098)	Tok/s 51946 (53344)	Loss/tok 3.3378 (3.3543)	Learning Rate [0.0003125]
4: TRAIN [1][3410/3416]	Time 0.052 (0.058)	Data 0.00089 (0.00091)	Tok/s 51985 (53246)	Loss/tok 3.3252 (3.3489)	Learning Rate [0.0003125]
6: TRAIN [1][3410/3416]	Time 0.052 (0.058)	Data 0.00094 (0.00099)	Tok/s 51893 (53412)	Loss/tok 3.0592 (3.3533)	Learning Rate [0.0003125]
3: TRAIN [1][3410/3416]	Time 0.052 (0.058)	Data 0.00103 (0.00098)	Tok/s 51986 (53158)	Loss/tok 3.0086 (3.3534)	Learning Rate [0.0003125]
15: Running validation on dev set
0: Running validation on dev set
6: Running validation on dev set
1: Running validation on dev set
2: Running validation on dev set
14: Running validation on dev set
8: Running validation on dev set
13: Running validation on dev set
3: Running validation on dev set
10: Running validation on dev set
7: Running validation on dev set
12: Running validation on dev set
5: Running validation on dev set
4: Running validation on dev set
11: Running validation on dev set
9: Running validation on dev set
15: VALIDATION [1][0/5]	Time 0.023 (0.000)	Data 0.00212 (0.00000)	Tok/s 225305 (0)	Loss/tok 3.1229 (0.0000)	Learning Rate [0.0003125]
6: VALIDATION [1][0/5]	Time 0.028 (0.000)	Data 0.00208 (0.00000)	Tok/s 225061 (0)	Loss/tok 3.1583 (0.0000)	Learning Rate [0.0003125]
1: VALIDATION [1][0/5]	Time 0.037 (0.000)	Data 0.00213 (0.00000)	Tok/s 226287 (0)	Loss/tok 3.2836 (0.0000)	Learning Rate [0.0003125]
14: VALIDATION [1][0/5]	Time 0.023 (0.000)	Data 0.00216 (0.00000)	Tok/s 223936 (0)	Loss/tok 3.2953 (0.0000)	Learning Rate [0.0003125]
0: VALIDATION [1][0/5]	Time 0.061 (0.000)	Data 0.00211 (0.00000)	Tok/s 167525 (0)	Loss/tok 3.3471 (0.0000)	Learning Rate [0.0003125]
8: VALIDATION [1][0/5]	Time 0.026 (0.000)	Data 0.00212 (0.00000)	Tok/s 233433 (0)	Loss/tok 3.2679 (0.0000)	Learning Rate [0.0003125]
2: VALIDATION [1][0/5]	Time 0.036 (0.000)	Data 0.00297 (0.00000)	Tok/s 209774 (0)	Loss/tok 3.2206 (0.0000)	Learning Rate [0.0003125]
12: VALIDATION [1][0/5]	Time 0.024 (0.000)	Data 0.00213 (0.00000)	Tok/s 230089 (0)	Loss/tok 3.1436 (0.0000)	Learning Rate [0.0003125]
13: VALIDATION [1][0/5]	Time 0.025 (0.000)	Data 0.00211 (0.00000)	Tok/s 210956 (0)	Loss/tok 3.2551 (0.0000)	Learning Rate [0.0003125]
10: VALIDATION [1][0/5]	Time 0.025 (0.000)	Data 0.00212 (0.00000)	Tok/s 228104 (0)	Loss/tok 3.0975 (0.0000)	Learning Rate [0.0003125]
7: VALIDATION [1][0/5]	Time 0.028 (0.000)	Data 0.00223 (0.00000)	Tok/s 223783 (0)	Loss/tok 3.2560 (0.0000)	Learning Rate [0.0003125]
3: VALIDATION [1][0/5]	Time 0.032 (0.000)	Data 0.00213 (0.00000)	Tok/s 229608 (0)	Loss/tok 3.1400 (0.0000)	Learning Rate [0.0003125]
5: VALIDATION [1][0/5]	Time 0.030 (0.000)	Data 0.00284 (0.00000)	Tok/s 223208 (0)	Loss/tok 3.1453 (0.0000)	Learning Rate [0.0003125]
11: VALIDATION [1][0/5]	Time 0.026 (0.000)	Data 0.00307 (0.00000)	Tok/s 215150 (0)	Loss/tok 3.1161 (0.0000)	Learning Rate [0.0003125]
4: VALIDATION [1][0/5]	Time 0.033 (0.000)	Data 0.00275 (0.00000)	Tok/s 212607 (0)	Loss/tok 3.1087 (0.0000)	Learning Rate [0.0003125]
9: VALIDATION [1][0/5]	Time 0.028 (0.000)	Data 0.00271 (0.00000)	Tok/s 208086 (0)	Loss/tok 3.2430 (0.0000)	Learning Rate [0.0003125]
10: Running evaluation on test set
13: Running evaluation on test set
12: Running evaluation on test set
11: Running evaluation on test set
9: Running evaluation on test set
1: Running evaluation on test set
7: Running evaluation on test set
6: Running evaluation on test set
14: Running evaluation on test set
8: Running evaluation on test set
2: Running evaluation on test set
4: Running evaluation on test set
3: Running evaluation on test set
5: Running evaluation on test set
:::MLPv0.5.0 gnmt 1541782666.396400213 (train.py:459) eval_start: 1
0: Running evaluation on test set
15: Running evaluation on test set
3: TEST [1][0/2]	Time 1.101 (1.101)	Decoder iters 149.0 (149.0)	Tok/s 6953 (6953)
0: TEST [1][0/2]	Time 1.101 (1.101)	Decoder iters 71.0 (71.0)	Tok/s 6427 (6427)
1: TEST [1][0/2]	Time 1.101 (1.101)	Decoder iters 149.0 (149.0)	Tok/s 6958 (6958)
15: TEST [1][0/2]	Time 1.100 (1.100)	Decoder iters 79.0 (79.0)	Tok/s 7452 (7452)
4: TEST [1][0/2]	Time 1.101 (1.101)	Decoder iters 81.0 (81.0)	Tok/s 7195 (7195)
6: TEST [1][0/2]	Time 1.102 (1.102)	Decoder iters 149.0 (149.0)	Tok/s 7120 (7120)
11: TEST [1][0/2]	Time 1.102 (1.102)	Decoder iters 108.0 (108.0)	Tok/s 5839 (5839)
12: TEST [1][0/2]	Time 1.102 (1.102)	Decoder iters 63.0 (63.0)	Tok/s 5855 (5855)
2: TEST [1][0/2]	Time 1.102 (1.102)	Decoder iters 149.0 (149.0)	Tok/s 6826 (6826)
13: TEST [1][0/2]	Time 1.102 (1.102)	Decoder iters 80.0 (80.0)	Tok/s 6354 (6354)
5: TEST [1][0/2]	Time 1.103 (1.103)	Decoder iters 58.0 (58.0)	Tok/s 6006 (6006)
7: TEST [1][0/2]	Time 1.103 (1.103)	Decoder iters 74.0 (74.0)	Tok/s 6620 (6620)
10: TEST [1][0/2]	Time 1.104 (1.104)	Decoder iters 72.0 (72.0)	Tok/s 6051 (6051)
8: TEST [1][0/2]	Time 1.104 (1.104)	Decoder iters 79.0 (79.0)	Tok/s 6798 (6798)
14: TEST [1][0/2]	Time 1.104 (1.104)	Decoder iters 65.0 (65.0)	Tok/s 7485 (7485)
9: TEST [1][0/2]	Time 1.107 (1.107)	Decoder iters 65.0 (65.0)	Tok/s 6097 (6097)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
0: Target accuracy reached
8: Finished evaluation on test set
6: Finished evaluation on test set
2: Finished evaluation on test set
13: Finished evaluation on test set
10: Finished evaluation on test set
14: Finished evaluation on test set
3: Finished evaluation on test set
1: Finished evaluation on test set
4: Finished evaluation on test set
12: Finished evaluation on test set
7: Finished evaluation on test set
11: Finished evaluation on test set
15: Finished evaluation on test set
9: Finished evaluation on test set
0: Finished evaluation on test set
5: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1541782673.515100718 (train.py:464) eval_accuracy: {"epoch": 1, "value": 21.799999237060547}
:::MLPv0.5.0 gnmt 1541782673.515555143 (train.py:466) eval_target: 21.8
1: Summary: Epoch: 1	Training Loss 3.3523
2: Summary: Epoch: 1	Training Loss 3.3523
7: Summary: Epoch: 1	Training Loss 3.3523
14: Summary: Epoch: 1	Training Loss 3.3523
11: Summary: Epoch: 1	Training Loss 3.3523
10: Summary: Epoch: 1	Training Loss 3.3523
3: Summary: Epoch: 1	Training Loss 3.3523
6: Summary: Epoch: 1	Training Loss 3.3523
5: Summary: Epoch: 1	Training Loss 3.3523
12: Summary: Epoch: 1	Training Loss 3.3523
13: Summary: Epoch: 1	Training Loss 3.3523
4: Summary: Epoch: 1	Training Loss 3.3523
9: Summary: Epoch: 1	Training Loss 3.3523
8: Summary: Epoch: 1	Training Loss 3.3523
15: Summary: Epoch: 1	Training Loss 3.3523
2: Performance: Epoch: 1	Training: 856477 Tok/s
7: Performance: Epoch: 1	Training: 856477 Tok/s
1: Performance: Epoch: 1	Training: 856477 Tok/s
11: Performance: Epoch: 1	Training: 856477 Tok/s
10: Performance: Epoch: 1	Training: 856477 Tok/s
3: Performance: Epoch: 1	Training: 856477 Tok/s
14: Performance: Epoch: 1	Training: 856477 Tok/s
13: Performance: Epoch: 1	Training: 856477 Tok/s
6: Performance: Epoch: 1	Training: 856477 Tok/s
12: Performance: Epoch: 1	Training: 856477 Tok/s
5: Performance: Epoch: 1	Training: 856477 Tok/s
4: Performance: Epoch: 1	Training: 856477 Tok/s
9: Performance: Epoch: 1	Training: 856477 Tok/s
8: Performance: Epoch: 1	Training: 856477 Tok/s
15: Performance: Epoch: 1	Training: 856477 Tok/s
2: Finished epoch 1
7: Finished epoch 1
1: Finished epoch 1
11: Finished epoch 1
10: Finished epoch 1
14: Finished epoch 1
3: Finished epoch 1
13: Finished epoch 1
6: Finished epoch 1
12: Finished epoch 1
8: Finished epoch 1
4: Finished epoch 1
5: Finished epoch 1
9: Finished epoch 1
15: Finished epoch 1
:::MLPv0.5.0 gnmt 1541782673.515901089 (train.py:467) eval_stop
0: Summary: Epoch: 1	Training Loss: 3.3523	Validation Loss: 3.0513	Test BLEU: 21.80
0: Performance: Epoch: 1	Training: 856477 Tok/s	Validation: 2745511 Tok/s
0: Finished epoch 1
:::MLPv0.5.0 gnmt 1541782673.516504765 (train.py:488) run_stop: {"success": true}
:::MLPv0.5.0 gnmt 1541782673.516848564 (train.py:494) train_checkpoint
0: Saving model to results/gnmt_wmt16/model_best.pth
:::MLPv0.5.0 gnmt 1541782679.326445341 (train.py:498) run_final
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2018-11-09 04:58:09 PM
RESULT,RNN_TRANSLATOR,,494,nvidia,2018-11-09 04:49:55 PM
