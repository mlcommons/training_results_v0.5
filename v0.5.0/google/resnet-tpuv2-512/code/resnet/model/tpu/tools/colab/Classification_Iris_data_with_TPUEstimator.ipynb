{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Classification Model using TPUEstimator on Colab TPU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "a0TLC65g9W5n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Simple Classification Model using TPUEstimator on Colab TPU\n",
        "\n",
        "This notebook demonstrates using Cloud TPUs to build a simple classification model using iris dataset to predict the species of the flower. This model is using 4 input features ***(SepalLength, SepalWidth, PetalLength, PetalWidth)*** to determine one of these flower species ***(Setosa, Versicolor, Virginica)***.\n",
        "\n",
        "### Note: You will need a GCP account and a GCS bucket for this notebook to run!"
      ]
    },
    {
      "metadata": {
        "id": "ACiNzAp8AoWR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Imports"
      ]
    },
    {
      "metadata": {
        "id": "IgQge6h7AqDw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "#  you may not use this file except in compliance with the License.\n",
        "#  You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "#  Unless required by applicable law or agreed to in writing, software\n",
        "#  distributed under the License is distributed on an \"AS IS\" BASIS,0\n",
        "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "#  See the License for the specific language governing permissions and\n",
        "#  limitations under the License.\n",
        "\"\"\"An Example of a custom TPUEstimator for the Iris dataset.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7FCdy1aBAsXe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Resolve TPU Address and authenticate GCS Bucket"
      ]
    },
    {
      "metadata": {
        "id": "phzyD8iCAzcp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "use_tpu = True #@param {type:\"boolean\"}\n",
        "bucket = '' #@param {type:\"string\"}\n",
        "\n",
        "assert bucket, 'Must specify an existing GCS bucket name'\n",
        "print('Using bucket: {}'.format(bucket))\n",
        "\n",
        "if use_tpu:\n",
        "    assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU; did you request a TPU in Notebook Settings?'\n",
        "\n",
        "MODEL_DIR = 'gs://{}/{}'.format(bucket, time.strftime('tpuestimator-dnn/%Y-%m-%d-%H-%M-%S'))\n",
        "print('Using model dir: {}'.format(MODEL_DIR))\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with tf.Session(TF_MASTER) as sess:\n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU.\n",
        "else:\n",
        "  TF_MASTER=''\n",
        "\n",
        "with tf.Session(TF_MASTER) as session:\n",
        "  print ('List of devices:')\n",
        "  pprint.pprint(session.list_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r0AEjD1vKGXO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###FLAGS used as model params"
      ]
    },
    {
      "metadata": {
        "id": "0tcdTWw1KLiF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model specific parameters\n",
        "\n",
        "# TPU address\n",
        "tpu_address = TF_MASTER\n",
        "\n",
        "# Estimators model_dir\n",
        "model_dir = MODEL_DIR\n",
        "\n",
        "# This is the global batch size, not the per-shard batch.\n",
        "batch_size = 128\n",
        "\n",
        "# Total number of training steps.\n",
        "train_steps = 1000\n",
        "\n",
        "# Total number of evaluation steps. If '0', evaluation after training is skipped\n",
        "eval_steps = 4\n",
        "\n",
        "# Number of iterations per TPU training loop\n",
        "iterations = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I3Ckb7SEKSGO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Get input data and Define input functions"
      ]
    },
    {
      "metadata": {
        "id": "Y1qZ3cWyKb-b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
        "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
        "\n",
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
        "                    'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "PREDICTION_INPUT_DATA = {\n",
        "    'SepalLength': [6.9, 5.1, 5.9],\n",
        "    'SepalWidth': [3.1, 3.3, 3.0],\n",
        "    'PetalLength': [5.4, 1.7, 4.2],\n",
        "    'PetalWidth': [2.1, 0.5, 1.5],\n",
        "}\n",
        "\n",
        "PREDICTION_OUTPUT_DATA = ['Virginica', 'Setosa', 'Versicolor']\n",
        "\n",
        "def maybe_download():\n",
        "    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\n",
        "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
        "\n",
        "    return train_path, test_path\n",
        "\n",
        "def load_data(y_name='Species'):\n",
        "    \"\"\"Returns the iris dataset as (train_x, train_y), (test_x, test_y).\"\"\"\n",
        "    train_path, test_path = maybe_download()\n",
        "\n",
        "    train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0, dtype={'SepalLength': pd.np.float32,\n",
        "        'SepalWidth': pd.np.float32, 'PetalLength': pd.np.float32, 'PetalWidth': pd.np.float32, 'Species': pd.np.int32})\n",
        "    train_x, train_y = train, train.pop(y_name)\n",
        "\n",
        "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0, dtype={'SepalLength': pd.np.float32,\n",
        "        'SepalWidth': pd.np.float32, 'PetalLength': pd.np.float32, 'PetalWidth': pd.np.float32, 'Species': pd.np.int32})\n",
        "    test_x, test_y = test, test.pop(y_name)\n",
        "\n",
        "    return (train_x, train_y), (test_x, test_y)\n",
        "\n",
        "\n",
        "def train_input_fn(features, labels, batch_size):\n",
        "    \"\"\"An input function for training\"\"\"\n",
        "\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle, repeat, and batch the examples.\n",
        "    dataset = dataset.shuffle(1000).repeat()\n",
        "\n",
        "    dataset = dataset.apply(\n",
        "            tf.contrib.data.batch_and_drop_remainder(batch_size))\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def eval_input_fn(features, labels, batch_size):\n",
        "    \"\"\"An input function for evaluation\"\"\"\n",
        "    features=dict(features)\n",
        "    inputs = (features, labels)\n",
        "\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "    dataset = dataset.shuffle(1000).repeat()\n",
        "\n",
        "    dataset = dataset.apply(\n",
        "            tf.contrib.data.batch_and_drop_remainder(batch_size))\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def predict_input_fn(features, batch_size):\n",
        "    \"\"\"An input function for prediction\"\"\"\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(features)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ktD3gwqHKijt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Model and metric function"
      ]
    },
    {
      "metadata": {
        "id": "mf-xZIlJKn9j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def metric_fn(labels, logits):\n",
        "    \"\"\"Function to return metrics for evaluation\"\"\"\n",
        "\n",
        "    predicted_classes = tf.argmax(logits, 1)\n",
        "    accuracy = tf.metrics.accuracy(labels=labels,\n",
        "                                   predictions=predicted_classes,\n",
        "                                   name='acc_op')\n",
        "    return {'accuracy': accuracy}\n",
        "\n",
        "\n",
        "def my_model(features, labels, mode, params):\n",
        "    \"\"\"DNN with three hidden layers, and dropout of 0.1 probability.\"\"\"\n",
        "\n",
        "    # Create three fully connected layers each layer having a dropout\n",
        "    # probability of 0.1.\n",
        "    net = tf.feature_column.input_layer(features, params['feature_columns'])\n",
        "    for units in params['hidden_units']:\n",
        "        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n",
        "\n",
        "    # Compute logits (1 per class).\n",
        "    logits = tf.layers.dense(net, params['n_classes'], activation=None)\n",
        "\n",
        "    # Compute predictions.\n",
        "    predicted_classes = tf.argmax(logits, 1)\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        predictions = {\n",
        "            'class_ids': predicted_classes[:, tf.newaxis],\n",
        "            'probabilities': tf.nn.softmax(logits),\n",
        "            'logits': logits,\n",
        "        }\n",
        "        return tf.contrib.tpu.TPUEstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "    # Compute loss.\n",
        "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels,\n",
        "                                                  logits=logits)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.EVAL:\n",
        "        return tf.contrib.tpu.TPUEstimatorSpec(\n",
        "            mode=mode, loss=loss, eval_metrics=(metric_fn, [labels, logits]))\n",
        "\n",
        "    # Create training op.\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "        if use_tpu:\n",
        "            optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
        "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
        "        return tf.contrib.tpu.TPUEstimatorSpec(mode, loss=loss, train_op=train_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-HuwjdowKqbb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Main Function"
      ]
    },
    {
      "metadata": {
        "id": "gYByHnboKuQc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Fetch the data\n",
        "    (train_x, train_y), (test_x, test_y) = load_data()\n",
        "\n",
        "    # Feature columns describe how to use the input.\n",
        "    my_feature_columns = []\n",
        "    for key in train_x.keys():\n",
        "        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "\n",
        "    # Resolve TPU cluster and runconfig for this.\n",
        "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu_address)\n",
        "\n",
        "    run_config = tf.contrib.tpu.RunConfig(\n",
        "            model_dir=model_dir,\n",
        "            cluster=tpu_cluster_resolver,\n",
        "            session_config=tf.ConfigProto(\n",
        "                allow_soft_placement=True, log_device_placement=True),\n",
        "            tpu_config=tf.contrib.tpu.TPUConfig(iterations),\n",
        "            )\n",
        "\n",
        "    # Build 2 hidden layer DNN with 10, 10 units respectively.\n",
        "    classifier = tf.contrib.tpu.TPUEstimator(\n",
        "        model_fn=my_model,\n",
        "        use_tpu=use_tpu,\n",
        "        train_batch_size=batch_size,\n",
        "        eval_batch_size=batch_size,\n",
        "        predict_batch_size=batch_size,\n",
        "        config=run_config,\n",
        "        params={\n",
        "            'feature_columns': my_feature_columns,\n",
        "            # Two hidden layers of 10 nodes each.\n",
        "            'hidden_units': [10, 10],\n",
        "            # The model must choose between 3 classes.\n",
        "            'n_classes': 3,\n",
        "            'use_tpu': use_tpu,\n",
        "        })\n",
        "\n",
        "    # Train the Model.\n",
        "    classifier.train(\n",
        "            input_fn = lambda params: train_input_fn(\n",
        "                train_x, train_y, params[\"batch_size\"]),\n",
        "            max_steps=train_steps)\n",
        "\n",
        "    # Evaluate the model.\n",
        "    eval_result = classifier.evaluate(\n",
        "        input_fn = lambda params: eval_input_fn(\n",
        "            test_x, test_y, params[\"batch_size\"]),\n",
        "        steps=eval_steps)\n",
        "\n",
        "    print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
        "\n",
        "    # Generate predictions from the model\n",
        "    predictions = classifier.predict(\n",
        "        input_fn = lambda params: predict_input_fn(\n",
        "            PREDICTION_INPUT_DATA, params[\"batch_size\"]))\n",
        "\n",
        "    for pred_dict, expec in zip(predictions, PREDICTION_OUTPUT_DATA):\n",
        "        template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
        "\n",
        "        class_id = pred_dict['class_ids'][0]\n",
        "        probability = pred_dict['probabilities'][class_id]\n",
        "\n",
        "        print(template.format(SPECIES[class_id],\n",
        "                              100 * probability, expec))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HiDECOvpKvsr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Run It!!"
      ]
    },
    {
      "metadata": {
        "id": "hZWES3ZsKzNc",
        "colab_type": "code",
        "outputId": "fc4104e6-5b96-464c-d870-31aa059c7303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2629
        }
      },
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://download.tensorflow.org/data/iris_training.csv\n",
            "\r16384/2194 [================================================================================================================================================================================================================================] - 0s 0us/step\n",
            "Downloading data from http://download.tensorflow.org/data/iris_test.csv\n",
            "16384/573 [=========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "log_device_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      value: \"10.63.218.106:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd42de33410>, '_model_dir': 'gs://amangu-test-bucket/tpuestimator-dnn/2018-10-31-00-05-49', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tpu_config': TPUConfig(iterations_per_loop=500, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_cluster': <tensorflow.contrib.cluster_resolver.python.training.tpu_cluster_resolver.TPUClusterResolver object at 0x7fd432667b90>, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': None, '_evaluation_master': 'grpc://10.63.218.106:8470', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': 'grpc://10.63.218.106:8470'}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.63.218.106:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 3204130715220914658)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1757131222346187914)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 14189073471542166552)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 18089629823860601296)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 3346547477748453737)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6512962655626301676)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1886142505182871901)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 49656553673112525)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 1173330136390527977)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 8029696445054773714)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 867116612521745007)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 18125553718687585414)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From <ipython-input-6-c4f6e12e0926>:48: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gs://amangu-test-bucket/tpuestimator-dnn/2018-10-31-00-05-49/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 7 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.12402147, step = 500\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.07178347, step = 1000 (0.769 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.223\n",
            "INFO:tensorflow:examples/sec: 83228.5\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into gs://amangu-test-bucket/tpuestimator-dnn/2018-10-31-00-05-49/model.ckpt.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 0.07178347.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-31-00:06:43\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://amangu-test-bucket/tpuestimator-dnn/2018-10-31-00-05-49/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 9 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (4) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (4) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Evaluation [4/4]\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-31-00:06:54\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9667969, global_step = 1000, loss = 0.13143887\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: gs://amangu-test-bucket/tpuestimator-dnn/2018-10-31-00-05-49/model.ckpt-1000\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n",
            "\n",
            "Test set accuracy: 0.967\n",
            "\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://amangu-test-bucket/tpuestimator-dnn/2018-10-31-00-05-49/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 13 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "\n",
            "Prediction is \"Virginica\" (92.4%), expected \"Virginica\"\n",
            "\n",
            "Prediction is \"Setosa\" (98.3%), expected \"Setosa\"\n",
            "\n",
            "Prediction is \"Versicolor\" (95.8%), expected \"Versicolor\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}