# ResNet Run Instructions

## Get the data
We used TFRecords data generated by the MLPerf "reference" ResNet-50 v1.5. To
save looking around here is a copy of the info.

The following [script](https://github.com/tensorflow/tpu/blob/master/tools/datasets/imagenet_to_gcs.py)
was used to create TFRecords from ImageNet data using instructions in the
[README](https://github.com/tensorflow/tpu/tree/master/tools/datasets#imagenet_to_gcspy).
TFRecords can be created directly from [ImageNet](http://image-net.org) or from
the .tar files downloaded from image-net.org.

## Run the code

### System requirements
Local system is expected to have the following:
   * NVIDIA Driver 410.72
   * nvidia-docker2

### Run the code
Put the TFRecords (both training and validation) into `/data/imagenet/combined`.
Then execution the following:

```bash
export MLP_HOST_DATA_DIR=/data
bash run_and_time_8xV100.sh
```

To get the timing run the ml_compliance code or do the math on the run_start
and run_final. If there is a time in the script it is total time of the python
file and is slower than the official MLPerf calculation.

**Note:** Your log will be richer than the submission. We removed all but the
MLPerf log entires from the result_x.txt files to make then easier to read.

## Update
Code used for the benchmark was TF 1.12 with
7d5ef9170bfe69c31cd57b18c6491fdd16ee93d3 cherry-picked for cuDNN 7.4 support.
